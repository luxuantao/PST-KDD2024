<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Synthetic Disinformation Attacks on Automated Fact Verification Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yibing</forename><surname>Du</surname></persName>
							<email>yibingdu@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University ? EPFL</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
							<email>antoine.bosselut@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University ? EPFL</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
							<email>manning@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University ? EPFL</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Synthetic Disinformation Attacks on Automated Fact Verification Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated fact-checking is a needed technology to curtail the spread of online misinformation. One current framework for such solutions proposes to verify claims by retrieving supporting or refuting evidence from related textual sources. However, the realistic use cases for fact-checkers will require verifying claims against evidence sources that could be affected by the same misinformation. Furthermore, the development of modern NLP tools that can produce coherent, fabricated content would allow malicious actors to systematically generate adversarial disinformation for fact-checkers. In this work, we explore the sensitivity of automated factcheckers to synthetic adversarial evidence in two simulated settings: ADVERSARIAL ADDITION, where we fabricate documents and add them to the evidence repository available to the fact-checking system, and ADVERSARIAL MODIFICATION, where existing evidence source documents in the repository are automatically altered. Our study across multiple models on three benchmarks demonstrates that these systems suffer significant performance drops against these attacks. Finally, we discuss the growing threat of modern NLG systems as generators of disinformation in the context of the challenges they pose to automated fact-checkers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>From QAnon's deep state 1 to anti-vaccination campaigns <ref type="bibr" target="#b10">(Germani and Biller-Andorno 2021)</ref>, misinformation and disinformation have flourished in online ecosystems. As misinformation continues to induce harmful societal effects, factchecking online content has become critical to ensure trust in the information found online. 2 However, manual efforts to filter misinformation cannot keep pace with the scale of online information that must be reliably verified to avoid false claims spreading and affecting public opinion. 3 Consequently, new research in automated fact-checking explores designing systems that can rapidly validate political, medical, and other domain-specific claims made and shared online <ref type="bibr">(Thorne and Vlachos 2018;</ref><ref type="bibr" target="#b11">Guo, Zhang, and Lu 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence Selection</head><p>COVID-19 doesn't exist. 5G radio frequency communications have a damaging health impact and these are directly making people sick.</p><p>COVID-19 is caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Evidence Repository</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim Verification</head><p>Figure <ref type="figure">1</ref>: Outline of our two settings for adversarial injection of poisoned content into fact-checker evidence repositories.</p><p>A popular emergent paradigm in automated fact-checking, Fact Extraction and Verification (FEVER; <ref type="bibr">Thorne et al. 2018)</ref>, frames the problem as claim verification against a large repository of evidence documents. As one of the first large-scale datasets designed in this framework, FEVER was released with 185k annotated claims that could be verified against Wikipedia articles. When checking a claim, systems designed in this framework search for related documents in the database, and retrieve relevant supporting or refuting evidence from these sources. Then, these systems evaluate whether the retrieved evidence sentences validate or contradict the claim, or whether there is not enough information to make a judgment. More recently, the SCIFACT <ref type="bibr" target="#b42">(Wadden et al. 2020)</ref> and COVIDFACT <ref type="bibr" target="#b36">(Saakyan, Chakrabarty, and Muresan 2021)</ref> benchmarks re-purposed this framework for the sci-entific domain by releasing datasets of medical claims to be verified against scientific content <ref type="bibr">(Wang et al. 2020)</ref>. While this framework has led to impressive advances in fact verification performance <ref type="bibr" target="#b44">(Ye et al. 2020;</ref><ref type="bibr" target="#b33">Pradeep et al. 2021)</ref>, current benchmarks assume that the available evidence database contains only valid, factual information.</p><p>However, check-worthy claims are often made about new events that may not be verifiable against extensive catalogues, and that must be checked rapidly to avoid strategic disinformation spread <ref type="bibr" target="#b41">(Vosoughi, Roy, and Aral 2018)</ref>. Consequently, deployed fact-checkers will need to operate in settings where their available evidence is collected from contemporaneous reporting, which may be inadvertently sharing the same misinformation, or which may be intentionally influenced by systematic disinformation campaigns. Currently, malicious actors remain limited by the cost of running disinformation campaigns <ref type="bibr" target="#b9">(DiResta et al. 2018</ref>) and the risks of operational discovery,<ref type="foot" target="#foot_0">4</ref> impeding the scale at which they can deploy these campaigns, and thus the balance of real and false content that fact-checkers must distinguish. However, the development of NLP tools capable of generating coherent disinformation <ref type="bibr" target="#b46">(Zellers et al. 2019;</ref><ref type="bibr" target="#b5">Buchanan et al. 2021</ref>) would allow malicious actors to overload contemporaneous content with adversarial information <ref type="bibr" target="#b4">(Brundage et al. 2018</ref>) and bias the evidence bases used by automated fact-checkers.</p><p>Furthermore, even in settings where claims may be verified against established and trusted knowledge, misinformation can still find its way into repositories of documents used by fact-checking systems <ref type="bibr" target="#b21">(Kumar, West, and Leskovec 2016)</ref>. Wikipedia, for example, which underlies FEVER (and other benchmarks; <ref type="bibr" target="#b31">Petroni et al. 2021)</ref>, acknowledges that much of the content on the platform may be incorrect, and remain so for long periods of time. <ref type="foot" target="#foot_1">5</ref> For example, the Croatian Wikipedia was contaminated by pro-nationalist bias over a period of at least 10 years. <ref type="foot" target="#foot_2">6</ref> Moreover, studies have uncovered articles on Wikipedia that were edited to provide favorable accounts on specific topics (e.g., workers at a medical device company edited articles to present an optimistic view toward treatments that used their product<ref type="foot" target="#foot_3">7</ref> ). Modern NLP tools would allow malicious users to scale up production of disinformation on these platforms, and increase the perception of false consensus or debate on these topics.</p><p>In this paper, we evaluate whether automated disinformation generators can effectively contaminate the evidence sets of fact verification systems, and demonstrate that synthetic disinformation drastically lowers the performance of these systems. We define adversarial attacks in two settings: AD-VERSARIAL ADDITION (ADVADD; ?3), where syntheticallygenerated documents are added to the document base, and ADVERSARIAL MODIFICATION (ADVMOD; ?4), where additional automatically-generated information is inserted into existing documents. In both settings, we curate a large collection of adversarial disinformation documents that we inject into the pipelines of existing fact-checking systems developed for the FEVER, SCIFACT, and COVIDFACT shared tasks. <ref type="foot" target="#foot_4">8</ref>Our results demonstrate that these systems are significantly affected by the injection of poisoned content in their evidence bases, with large absolute performance drops on all models in both settings. Furthermore, our analysis demonstrates that these systems are sensitive to even small amounts of evidence contamination, and that synthetic disinformation is more influential at deceiving fact verification systems compared to human-produced false content. Finally, we provide a discussion of our most important findings, and their importance in the context of continued advances in NLP systems.<ref type="foot" target="#foot_5">9</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we review the formulation of automated fact checking as fact extraction and verification, and recent advances in automated generation of textual disinformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated Fact-checking: Task</head><p>Current systems research in automated fact-checking often follows the fact verification and extraction procedure of receiving a natural language claim (e.g., "Hypertension is a common comorbidity seen in COVID-19 patients"), collecting supporting evidence from a repository of available documents (e.g., scientific manuscripts), and making a prediction about the claim's veracity based off the collected supporting evidence. Below, we define the two stages of this pipeline: evidence retrieval and claim verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence retrieval</head><p>The evidence retrieval stage of fact verification systems is typically decomposed into two steps: document retrieval and sentence retrieval. During document retrieval, documents in the evidence repository that are relevant to the claim are selected. Existing methods typically use information retrieval methods to rank documents based on relevance <ref type="bibr">(Thorne et al. 2018;</ref><ref type="bibr" target="#b42">Wadden et al. 2020)</ref> or use public APIs of commercial document indices <ref type="bibr" target="#b12">(Hanselowski et al. 2019;</ref><ref type="bibr" target="#b36">Saakyan, Chakrabarty, and Muresan 2021)</ref> to crawl related documents. In the sentence retrieval stage, individual sentences from these retrieved documents are selected with respect to their relevance to the claim, often using textual entailment <ref type="bibr" target="#b12">(Hanselowski et al. 2019)</ref>, or sentence similarity <ref type="bibr">(Thorne et al. 2018)</ref> methods. Typically, the number of retrieved sentences is capped for computational efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim verification</head><p>The claim verification stage of the pipeline evaluates the veracity of the claim with respect to the evidence sentences retrieved in the previous stage. Depending on the content found in the supporting sentences, each claim can typically be classified as supported (SUP), refuted (REF), or not enough information (NEI, though some benchmarks omit this label). Systems must aggregate and weigh the evidence sentences to predict the most likely label.</p><p>FEVER Claim Starrcade was an annual professional wrestling event that began in 1988.</p><p>Original <ref type="bibr">Starrcade (1988)</ref> was the sixth annual Starrcade professional wrestling pay-per-view (PPV) event produced under the National Wrestling Alliance (NWA) banner . GROVER Starrcade was a monthly professional wrestling event for the decades between 1988 and 2003 that ran for the entirety of a weekend in Boston , Mass. Media Cloud Goldberg's perfect 173-0 streak ended at Starrcade 1998 after Kevin Nash scored the fateful pinfall with the help of Scott Hall and his taser gun.</p><p>SCIFACT Claim Taxation of sugar-sweetened beverages had no effect on the incidence rate of type II diabetes in India.</p><p>Original The 20% SSB tax was anticipated to reduce overweight and obesity prevalence by 3.0% ... and type 2 diabetes incidence by 1.6% ... among various Indian subpopulations over the period 2014-2023 GROVER ... analysis of a "cone-by-one" kind of survey question in India reached out to -9 145 trillion , including 2,557 separate instances of type II diabetes (which is comparable to the prevalence rate in Pakistan ... </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated Fact-checking: Datasets</head><p>We briefly describe the provenance and structure of our studied datasets and refer the reader to the original works for in-depth descriptions of the construction of these resources.</p><p>FEVER The FEVER testbed <ref type="bibr">(Thorne et al. 2018</ref>) is a dataset of <ref type="bibr">185,445 claims (145,449 train, 19,998 dev, 19,998 test)</ref> with corresponding evidence to validate them drawn from articles in Wikipedia. Because of its scale and originality, the FEVER dataset is one of the most popular benchmarks for evaluating fact verification systems <ref type="bibr" target="#b45">(Yoneda et al. 2018;</ref><ref type="bibr" target="#b28">Nie, Chen, and Bansal 2019;</ref><ref type="bibr" target="#b49">Zhou et al. 2019;</ref><ref type="bibr" target="#b48">Zhong et al. 2020;</ref><ref type="bibr" target="#b38">Subramanian and Lee 2020)</ref>.</p><p>SCIFACT The SCIFACT dataset <ref type="bibr" target="#b42">(Wadden et al. 2020</ref>) contains 1,409 expert-annotated scientific claims and associated paper abstracts. SCIFACT presents the challenge of understanding scientific writing as systems must retrieve relevant sentences from paper abstracts and identify if the sentences support or refute a presented scientific claim. It has emerged as a popular benchmark for evaluating scientific fact verification systems <ref type="bibr" target="#b33">(Pradeep et al. 2021)</ref>.</p><p>COVIDFACT The COVIDFACT dataset (Saakyan, Chakrabarty, and Muresan 2021) contains 1,296 crowdsourced claims crawled (and filtered) from the /r/COVID19 subreddit. The evidence is composed of documents provided with these claims when they were posted on the subreddit along with resources from Google Search queries for the claims. Refuted claims were automatically-generated by altering key words in the original claims.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic Disinformation Generation</head><p>Recent years have brought considerable improvements in the language generation capabilities of neural language models <ref type="bibr" target="#b24">(Lewis et al. 2020;</ref><ref type="bibr" target="#b15">Ji et al. 2020;</ref><ref type="bibr" target="#b3">Brown et al. 2020;</ref><ref type="bibr" target="#b13">Holtzman et al. 2020)</ref>, allowing users of these systems to pass off their generations as human-produced <ref type="bibr" target="#b14">(Ippolito et al. 2020</ref>). These advances have raised dual-use concerns as to whether these tools could be used to generate text for malicious purposes <ref type="bibr" target="#b34">(Radford et al. 2019;</ref><ref type="bibr">Bommasani et al. 2021)</ref>, which humans would struggle to detect <ref type="bibr" target="#b7">(Clark et al. 2021)</ref>.</p><p>Specific studies have focused on whether neural language models could be used to generate disinformation that influences human readers <ref type="bibr" target="#b19">(Kreps, McCain, and Brundage 2020;</ref><ref type="bibr" target="#b5">Buchanan et al. 2021</ref>). One such study directly explored this possibility by training GROVER, a large-scale, billionparameter language model on a large dataset of newswire text with the goal of generating text that resembles news <ref type="bibr" target="#b46">(Zellers et al. 2019)</ref>. In human evaluations of the model's generated text, the study found that human readers considered the synthetically-generated news to be as trustworthy as human-generated content. While the authors found that neural language models could identify fake, generated content when finetuned to detect distributional patterns in the generated text, they hypothesized that future detection methods would need to rely on external knowledge (e.g., FEVER).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ADVERSARIAL ADDITION: Evidence Repository Poisoning</head><p>In this section, we simulate the potential vulnerability of factchecking models to database pollution with misinformation documents by injecting synthetically-generated false documents into the evidence sets of fact verification models, and assess the impact on the performance of these systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>Our method, ADVERSARIAL ADDITION (ADVADD), uses GROVER to produce synthetic documents for a proposed claim, and makes these fake documents available to the fact verification system when retrieving evidence. As GROVER requires a proposed article title and publication venue (i.e., website link) as input to generate a fake article, we use each claim as a title and set the article venue to wikipedia.com. We generate 10 articles for each claim and split them into paragraphs (n.b., FEVER DB contains first paragraphs of Wikipedia articles and SCIFACT contains abstracts of scientific articles). Statistics for the number of documents generated for each benchmark are reported in Table <ref type="table" target="#tab_3">3</ref>. Additional implementation details for the experimental setting of each benchmark can be found in the Appendix.  Impact of ADVADD We report the overall (and claimstratified) performance change of the tested models in Table 2. For all models, we see a significant performance drop 10 https://competitions.codalab.org/competitions/18814#results 11 We discuss results related to SUP claims in the Appendix. when GROVER-generated paragraphs are introduced into the available evidence set (ADVADD-full), indicating that fact verification models are sensitive to synthetically-generated information. This drop approaches the performance of an oracle (ADVADD-oracle), where only GROVER-generated documents are made available as evidence.</p><p>As confirmation that these attacks work as expected, we depict in Figure <ref type="figure" target="#fig_1">2</ref> how model predictions change once the synthetic disinformation is added to the evidence set. A significant number of claims that were originally predicted as REF or NEI are now predicted as SUP with the injected poisoned evidence. Consequently, we conclude that the poisoned evidence affects the model's predictions in the intended way, and that cross-label changes for different pairings are rare. Furthermore, we also find that replacing the retrieved poisoned evidence with random retrieved evidence from FEVERDB does not cause the same performance drop (?7% vs. ?30%), indicating that these effects are caused by the injection of poisoned evidence, and not merely the replacement of potentially relevant evidence (see Appendix A for further details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of disinformation scale</head><p>We also evaluate a setting where the attack is limited to retrieving only a single contaminated evidence sentence (ADVADD-min). The performance drops in the min setting are still considerable, suggesting that even limited amounts of injected disinformation can significantly affect downstream claim verification performance.</p><p>Moreover, Figure <ref type="figure" target="#fig_2">3</ref> shows a histogram of the number of poisoned evidence sentences retrieved per claim and a strat- We note that claims labeled NEI are far more sensitive to the introduction of poisoned sentences than REF claims, even as the rate of contamination is approximately the same between both types of labels. While this result is promising because the model is more robust in the presence of even minimal refuting evidence, it also demonstrates that fact verification systems are more sensitive when no competing information is presented to a particular viewpoint (i.e., data voids; Boyd and Go?ebiewski 2018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GROVER Evidence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quality of poisoned evidence</head><p>We also evaluate whether poisoned evidence produced by ADVADD is of sufficient quality to bypass potential human detectors. For 500 REF and 500 NEI claims from FEVER, we ran a study on Mechanical Turk where we presented three workers with five retrieved evidence examples (which could be from ADVADD or from FEVERDB) and asked them to identify which examples were machine-generated. Our results show that humans underestimate the number of poisoned sentences (23.6% recall), and do not distinguish machine-from human-generated evidence (48.6% precision). While well-trained workers will improve at recognizing synthetic content, our results demonstrate the challenge of distinguishing these evidence sources for lay readers, pointing to the quality of the synthetic content, and the potential for such an attack to remain undetected. Comparison with human-compiled online evidence While we have shown that synthetic disinformation affects the performance of downstream claim verifiers when present in their evidence sets, the threat should be evaluated in comparison to the threat of already existing online misinformation on the same topic. Consequently, we use the MediaCloud 12 content analysis tool to crawl web content related to FEVER claims. We crawl English-language news since January 2018 that contains the keywords of a claim anywhere in their text and extract articles with a title that contains at least one keyword from the claim. Finally, we process these articles to have the same format as the original Wikipedia database, yielding 74M total available documents for retrieval (Table <ref type="table" target="#tab_3">3</ref>).</p><p>In Table <ref type="table" target="#tab_4">4</ref>, we report the performance of an ADVADD setting where only MediaCloud-crawled documents are available to the retriever compared to our original setting where GROVER-generated documents were available. We observe that evidence crawled from online content has less of an influence on downstream fact verification performance (?3% vs. ?40% performance drop). While we are able to retrieve far more documents from MediaCloud due to the size of the database (99% of claims retrieve a document from Media-Cloud), the sentences from ADVADD-GROVER documents are selected more frequently in the sentence retrieval step. While this gap would likely be less pronounced with more contentious claims that yield competing viewpoints (Bush and Zaheer 2019), these results demonstrate that synthetic disinformation can be much more targeted to a particular claim of interest. Figure <ref type="figure" target="#fig_2">3</ref> supports this conclusion, where we observe smaller performance drops for ADVADD-MediaCloud (c,d) compared to ADVADD-GROVER (a,b) even when all retrieved sentences are sourced from the poisoned evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SCIFACT Study</head><p>Setup For SCIFACT, we chose three systems for testing our attack: VeriSci <ref type="bibr" target="#b42">(Wadden et al. 2020)</ref>, ParagraphJoint <ref type="bibr" target="#b25">(Li, Burns, and Peng 2021)</ref>, and SciKGAT <ref type="bibr">(Liu et al. 2020a</ref>). The VeriSci model was released by the creators of the SCIFACT benchmark and retrieves relevant abstracts to a claim using TF-IDF. Table <ref type="table">5</ref>: Effect of ADVADD evidence on the SCIFACT benchmark. We bold performance drops relative to the original evidence.</p><p>on the SCIFACT leaderboard, uses a word embedding-based method to retrieve abstracts. Both use a RoBERTa-based module for rationale selection and label prediction. The SciKGAT model uses the same evidence retrieval as VeriSci, but the KGAT model <ref type="bibr">(Liu et al. 2020b</ref>) to verify claims. We use the 300 claims from the development set to evaluate our method. We generate GROVER articles as with FEVER, but we set the venue URL to medicalnewstoday.com, which produces articles more likely to reflect scientific and medical content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In Table <ref type="table">5</ref>, we observe large performance drops across all metrics for all models. Furthermore, we note that our disinformation generator, GROVER, is not trained on large quantities of scientific documents of the same format as the original evidence. Despite producing documents that are stylistically different, the disinformation is still retrieved as evidence, and affects the performance of the verifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COVIDFACT Study</head><p>Setup We run our analysis on the baseline system from <ref type="bibr" target="#b36">Saakyan, Chakrabarty, and Muresan (2021)</ref>. This model retrieves evidence documents for claims using Google Search and then selects evidence sentences based off high cosine similarity between sentence embeddings of the claims and individual evidence sentences <ref type="bibr" target="#b35">(Reimers and Gurevych 2019)</ref>.</p><p>A RoBERTa-based model predicts a veracity label. We generate ADVADD articles in the same manner as for SCIFACT, and run our analysis on the 271 REF claims from the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In both the Top-1 and Top-5 settings from Saakyan, Chakrabarty, and Muresan (2021), we observe a ?14.4% performance drop on REF claims (83.8% ? 69.4%). We note that COVIDFACT random and majority accuracy is only 67.6% due to a label imbalance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ADVERSARIAL MODIFICATION: Evidence Document Poisoning</head><p>In Section 3, we investigated the effect of adding disinformation documents to the evidence repositories of fact verification systems, simulating the setting where the dynamic pace of news might lead to fake information being used to verify real-time claims. However, even in settings where information has more time to settle and facts to crystallize, misinformation can still find its way into repositories of documents used by fact-checking systems. Motivated by the possibility of malicious edits being made to crowdsourced information resources, we explore how NLP methods could be used to automatically edit existing articles with fake content at scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head><p>Our method, ADVERSARIAL MODIFICATION (ADVMOD), simulates this setting in a two-stage process. First, we use offthe-shelf NLP tools to generate modified versions of the claim presented to the fact verifier. Then, we append our modified claims to articles in the evidence base that are relevant to the original claim. We modify the original claims in two ways.</p><p>In the paraphrase approach, we use a state-of-the-art paraphrasing model, PEGASUS <ref type="bibr" target="#b47">(Zhang et al. 2019)</ref>, to generate paraphrased versions of the original claim (see Table <ref type="table" target="#tab_7">7</ref> for examplea). These paraphrases generally retain the meaning of the claim, but often remove contextualizing information that would be found in the context of the article in which the new sentence is inserted. Because the paraphrase method attempts to produce synthetic evidence that is semantically equivalent to the original claim, we test its efficacy relative to a method that merely introduces irrelevant content to the evidence document. Motivated by <ref type="bibr" target="#b16">Jia and Liang (2017)</ref>, we alter a claim by applying heuristics such as number alteration, antonym substitution, and entity replacement with close neighbors according to embedding similarity <ref type="bibr" target="#b0">(Bojanowski et al. 2017</ref>). These modifications should not confuse humans, but would affect sensitive fact verification systems, providing a competitive baseline for assessing the strength of ADVMOD-paraphrase.</p><p>Finally, our oracle reports the performance when the claim itself is appended to an evidence document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Our results in Table <ref type="table" target="#tab_6">6</ref> demonstrate that injecting poisoned evidence sentences into existing documents is an effective method for fooling fact verification systems. Our ADV-MOD-paraphrase method causes a significant drop on all tested models for both REF and NEI labeled claims. Furthermore, we also note that ADVMOD-paraphrase achieves larger performance drops than the baseline method, ADV-MOD-KeyReplace, for most claim types (the KGAT model is slightly more sensitive to the baseline ADVMOD-KeyReplace for the NEI claims), indicating that injections of disinformative content are more effective than non-targeted perturbances to the evidence (e.g., ADVMOD-KeyReplace).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Adding synthetic content to the evidence bases of fact verifiers significantly decreases their performance. Below, we discuss interesting findings and limitations of our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic vs. human disinformation As mentioned in</head><p>Section 3, the performance of our test systems is more sensitive to poisoned evidence generated from GROVER than retrieved MediaCloud, even as the number of documents retrieved from MediaCloud far exceeds the number generated from GROVER. While FEVER claims may not generally be worth opposing online (leading to less directly adversarial content being retrieved from MediaCloud), we note that language models have no such limitations, and can generate large quantities of disinformation about any topic. Consequently, while misinformation already makes its way into retrieval search results <ref type="bibr" target="#b6">(Bush and Zaheer 2019)</ref>, language models could cheaply skew the distribution of content more drastically <ref type="bibr">(Bommasani et al. 2021)</ref>, particularly on topics that receive less mainstream coverage, but may be of import to a malicious actor <ref type="bibr" target="#b37">(Starbird et al. 2018)</ref>.</p><p>Language models as a defense In the ADVADD and ADV-MOD oracle settings, all tested systems performed better on claims labeled REF than for claims labeled NEI. This result implies that the GROVER-generated evidence was less adversarial for these claims, or that the pretrained models which these systems use to encode the claim and evidence sentences were more robust against claims that should be refuted. Consequently, we conclude that language models encode priors about the veracity of claims, likely from the knowledge they learn about entities during pretraining <ref type="bibr" target="#b32">(Petroni et al. 2019)</ref>, a conclusion also supported by contemporaneous work in using standalone language models as fact-checkers <ref type="bibr" target="#b23">(Lee et al. 2020</ref><ref type="bibr" target="#b22">(Lee et al. , 2021))</ref>. While this property can be an advantage in some settings (i.e., language models pretrained on reliable text repositories will be natural defenses against textual misinformation), it will also be a liability when previously learned erroneous knowledge will counteract input evidence that contradicts it. Finally, we note that the presence of implicit knowledge in language models affecting the interpretation of input evidence implies that the training corpora of these LMs could be attacked to influence downstream fact verification. Prior work has explored poisoning task-specific training datasets <ref type="bibr" target="#b43">(Wallace et al. 2021)</ref>. As disinformation becomes more prevalent online, the pretraining corpora of LMs will require more careful curation to avoid learning adversarial content.</p><p>Limitations We identify three main limitations to our study. First, the FEVER document retrievers use the MediaWiki API to collect relevant Wikipedia articles based on entity mentions in the claim. We assume our synthetic content could be included in the retrieved documents if it were titled with a mention of the named entities in the claim. For SCIFACT, this limitation is not present because synthetic abstracts are retrieved using statistical IR methods. Second, our method ADVADD uses the actual claim to generate the synthetic article. In the absence of explicit coordination, synthetic poisoned evidence would be generated without knowledge of the exact claim formulation, reducing the realistic correspondence between the claim and the synthetic disinformation.</p><p>If the GROVER model directly copied the claim during generation, performance drops might be overestimated based on unrealistically aligned evidence. For the ADVADD-full setting, we measure that this issue arises in ?20% of claims, which are predicted incorrectly more often, but does not affect the conclusions of our study. Finally, our FEVER and COVIDFACT studies are run using only claims labeled as REF and NEI, which we discuss in more detail in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we evaluate the robustness of fact verification models when we poison the evidence documents they use to verify claims. We develop two poisoning strategies motivated by real world capabilities: ADVADD, where synthetic documents are added to the evidence set, and ADVMOD, where synthetic sentences are added to existing documents in the evidence set. Our results show that these strategies significantly decrease claim verification accuracy. While these results are troubling, we are optimistic that improvements in automated synthetic content detection, particularly by online platforms with considerable resources, combined with human audits of fact-checker evidence (and their source), may still potentially mitigate many attempted disinformation campaigns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional ADVADD Results</head><p>Effect of increased evidence: When we increase the number of evidence sentences from 5 to 10 during the claim verification step, we see minimal difference in the performance drop. When only one adversarial sentence is inserted the performance drop decreases from 23.87% for 5 sentences to 23.69% for 10 sentences for REF claims. For NEI claims, the performance drop actually increases from 49.49% (5 sentences) to 50.81% (10 sentences).</p><p>Effect of random evidence: The performance drops reported in Section 3 might be due to correct evidence being removed from the retrieved set, rather than poisoned evidence being introduced. To test this possibility, we ran an experiment where we replace the retrieved poisoned evidence sentences with randomly chosen sentences from FEVERDB.</p><p>If poisoned evidence does not adversely affect the claim verifier beyond the replacement of potentially useful supporting sentences, we should expect minimal performance drop from this baseline. However, we find that when random sentences are inserted, the performance drop for the KGAT model shrinks from 30.05% to 6.63% for REF claims and from 53.42% to 7.73% for NEI claims. Similarly, in a proxy for the ADVADD-min setting, where only a single sentence is replaced, the shrink is from 28.87% to 1.86% for REF claims and from 49.49% to 7.01% for NEI claims. These results demonstrate that the performance drop comes from the addition of adversarial evidence instead of only the removal of possibly correct evidence, indicating that the claim verifier is directly sensitive to the content of poisoned evidence. Table <ref type="table">8</ref>: Effect of the sentence retriever on MLA and KGAT.</p><p>Effect of sentence retrieval performance Our results in Table <ref type="table" target="#tab_2">2</ref> show the MLA model <ref type="bibr" target="#b20">(Kruengkrai, Yamagishi, and Wang 2021</ref>) is more robust to poisoned evidence. To explore the cause of this finding, we swap the sentence retrievers of the KGAT and MLA models to disentangle the contributions of their sentence retrievers and claim verifiers. In Table <ref type="table">8</ref>, we find that when the MLA sentence retriever is paired with the KGAT claim verifier, the performance of this joint system (highlighted in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional ADVMOD Results</head><p>In Figure <ref type="figure" target="#fig_3">4</ref>, we report additional ADVMOD results measuring the performance change as a function of the amount of documents we re-write in the document base. Our results show that editing multiple documents is more likely to cause the prediction to flip. However, even a single edit to an evidence document can often cause a large performance drop.</p><p>Original </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Performance on Supports Labels</head><p>Our studies on the FEVER and COVIDFACT benchmarks focused on the claims labeled refutes (REF) and not enough information (NEI). Claims labeled as supports (SUP) were not included in the study due to the challenge of generating effective poisoned evidence for them. Generating poisoned evidence for FEVER NEI and REF claims is more straightforward because we can use variants of the claim (e.g., paraphrases) or the claim itself as input to GROVER to produce poisoned evidence. However, poisoned evidence can only be generated for SUP claims if suitable counterclaims can be formulated as an input to GROVER.</p><p>To test our method on SUP claims, counterclaims were generated in the following manner: we adapted the automatic counterclaim generation method from Saakyan, Chakrabarty, and Muresan (2021), which selects salient words in the original claim using an aggregate attention score for each token based on how much it is attended to by the other tokens in the sequence. Then, the most salient token is replaced by sampling from a masked language model. Once we generate a set of counterclaims using this method, we validate them using the decomposable attention NLI model of <ref type="bibr" target="#b29">Parikh et al. (2016)</ref> by selecting the ones with the highest contradiction score with respect to the original claim. Then, we provided these counterclaims as inputs to GROVER to generate poisoned evidence. However, we found this method was not effective for generating poisoned evidence. When we ran our ADVADD setting using the KGAT model, we observed a surprising performance increase from 86.2% to 87.5% on label prediction accuracy, indicating that the generated poisoned evidence unexpectedly helps the model make correct predictions.</p><p>Examples in Table <ref type="table" target="#tab_9">9</ref> depict the limitations of this approach. In the first example, the change made to generate the counterclaim does not change the semantics of the claim, merely changing the word "Potter" to "bee," which is not a coherent coherent counterclaim that would produce poisoned evidence from GROVER refuting the original claim. In the second example, the counterclaim is coherent, but does not semantically contradict from the original claim, making the poisoned evidence less likely to be retrieved when the original claim is provided to the fact verification model. Furthermore, we note the difficulty of generating counterclaims for many claims in FEVER. First, many of the original claims are not easily falsifiable (e.g., "Girl is an album"), making it challenging to formulate a suitable counterclaim. Other are statements that cannot be falsified without using explicit negation terms (e.g., "Stripes had a person appear in it"). As language models struggle to understand inferences of negated statements <ref type="bibr" target="#b18">(Kassner and Sch?tze 2020;</ref><ref type="bibr" target="#b17">Jiang et al. 2021)</ref>, GROVER may just as often generate content that ends up supporting the original claim, rather than contradicting it, when seeded with such explicitly negated counterclaims.</p><p>However, the focus of our study is whether syntheticallygenerated adversarial evidence could be generated at scale to mislead fact verification systems. While generating counterclaims automatically at scale is necessary to perform this study on FEVER SUP claims, an adversary would be more likely to generate synthetic content for a single claim (or related claims) of interest (rather than a large set). Consequently, they would be able to manually write the counterclaim that was needed to generate poisoned evidence, mitigating the need for automatic counterclaim generation methods. We evaluate this possibility by writing counterclaims for a sample of 100 FEVER SUP claims, allowing us to guarantee semantic contradiction of the original claim by the counterclaim (as seen in Table <ref type="table" target="#tab_9">9</ref>). However, we find that, once again, performance does not drop as the original performance on these claims was 92% and rose to 93% once the poisoned evidence from GROVER was available. Though manually writing contradicting statements guarantees coherence and quality of the counterclaim, GROVER may still fail to generate content as intended and may even affirm the original claim, possibly because the model has been trained on Wikipedia, indicating that GROVER may encode implicit knowledge about many of the entities for which it must produce poisoned evidence, as discussed in Section 5. For example, we note that one of the counterclaims from Table <ref type="table" target="#tab_9">9</ref> -"Bessie Smith was a vegetarian" -does not relate to singing at all. However, the GROVER model produces singing-related content anyway (Bessie Smith was a singer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Reproducibility Details</head><p>This paper relies on the existing FEVER, SCIFACT, and COVIDFACT datasets, which are publicly available. To test our method, we use the same evaluation metrics proposed by the dataset authors: label accuracy for FEVER <ref type="bibr">(Thorne et al. 2018)</ref>, the sentence selection, sentence label, abstract label, and abstract rationalized metrics for SCIFACT <ref type="bibr" target="#b42">(Wadden et al. 2020)</ref>, and the Top-1 and Top-5 label accuracy for COVIDFACT <ref type="bibr" target="#b36">(Saakyan, Chakrabarty, and Muresan 2021)</ref>. We also introduce our own datasets of adversarial evidence generated by GROVER and PEGASUS <ref type="bibr" target="#b47">(Zhang et al. 2019</ref>). They will be made publicly available with a license that allows for research use. For computational experiments in this paper, the main source code is available at: https://github.com/Yibing-Du/adversarial-factcheck These experiments were run on an NVIDIA Quadro RTX 8000 GPU. Because we do not train these models from scratch, but instead use existing released models, we only run each evaluation once since the result is deterministic. Consequently, there are no hyperparameters to tune. We use the default hyperparameters provided with the codebases of the models evaluated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Setup</head><label></label><figDesc>For the FEVER benchmark, we select three highranking models from the leaderboard 10 with open-source implementations: KGAT(Liu et al. 2020b), CorefBERT<ref type="bibr" target="#b44">(Ye et al. 2020)</ref>, and MLA<ref type="bibr" target="#b20">(Kruengkrai, Yamagishi, and Wang 2021)</ref>. For document retrieval, all models use the rule-based method developed by<ref type="bibr" target="#b12">Hanselowski et al. (2019)</ref>, which uses the MediaWiki API to retrieve relevant articles based on named entity mentions in the claim. For each claim and poisoned document, we extract all keywords and retrieve associated Wikipedia pages. If we find overlaps between the associated Wikipedia pages of a claim and a poisoned document, then the poisoned document is matched with the claim for document retrieval. Once the retrieved documents are available, the KGAT and CorefBERT models use a BERTbased<ref type="bibr" target="#b8">(Devlin et al. 2019</ref>) sentence retriever to rank evidence sentences based on relevance to the claim (trained using pairwise loss). The MLA sentence retriever expands on this approach with hard negative sampling from the same retrieved documents to more effectively discriminate context-relevant information that is irrelevant to the claim. Claim verifiers vary between models, but are generally based off pretrained language models (e.g., CorefBERT, MLA) or graph neural networks (e.g., KGAT). We use the REF and NEI claims from the FEVER development set to study how the preceding systems are affected by the introduction of poisoned evidence. 11</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: CorefBERT's predictions change from REF and NEI to SUP once ADVADD poisons the evidence set.</figDesc><graphic url="image-3.png" coords="4,353.71,192.66,170.08,141.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Degree of evidence poisoning and resulting REF (a,c) and NEI (b,d) claim verification accuracy for ADVADD-GROVER (a,b) ADVADD-MediaCloud (c,d)</figDesc><graphic url="image-6.png" coords="5,53.02,203.14,117.84,98.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Claim verification accuracy by model and poisoning technique for different amounts of ADVMOD evidence poisoning. The dashed line shows ADVMOD performance when the claim itself is added as a single evidence sentence.</figDesc><graphic url="image-12.png" coords="10,321.22,368.21,115.25,115.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Sample ADVADD document excerpts generated by GROVER for the FEVER and SCIFACT datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Original 73.05 74.03 72.07 70.76 72.50 69.01 75.92 78.71 73.13 ADVADD-min 34.80 47.22 22.38 34.08 48.63 19.52 60.93 73.04 48.81 ADVADD-full 28.59 39.63 17.54 29.02 42.45 15.59 51.86 71.84 31.87 ADVADD-oracle 21.18 27.09 15.26 23.43 31.47 15.38 29.05 29.76 28.33 Effect of ADVADD on FEVER claim verification. We bold the largest performance drop relative to the original evidence.</figDesc><table><row><cell></cell><cell cols="3">CorefBERT Acc.</cell><cell>KGAT Acc.</cell><cell>MLA Acc.</cell></row><row><cell cols="2">Evidence</cell><cell cols="2">(Ye et al. 2020)</cell><cell>(Liu et al. 2020b)</cell><cell>(Kruengkrai et al. 2021)</cell></row><row><cell></cell><cell cols="2">Total REF</cell><cell cols="2">NEI Total REF</cell><cell>NEI Total REF</cell><cell>NEI</cell></row><row><cell cols="2">Benchmark Evidence Source</cell><cell>N</cell><cell></cell></row><row><cell></cell><cell>FEVERDB</cell><cell cols="2">5,416,537</cell></row><row><cell>FEVER</cell><cell>GROVER Docs</cell><cell>995,829</cell><cell></cell></row><row><cell></cell><cell>MediaCloud Docs</cell><cell cols="2">74,273,342</cell></row><row><cell>SCIFACT</cell><cell>Scientific Abstracts GROVER Docs</cell><cell>5,183 21,963</cell><cell></cell></row><row><cell>COVIDFACT</cell><cell cols="2">Google Search Results 1,003 GROVER Docs 2,709</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Corpus statistics of evidence repositories</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Statistics and performance relative to the source of poisoned evidence: GROVER or MediaCloud</figDesc><table><row><cell>Source</cell><cell cols="2">Evidence Retrieval Document Sentence</cell></row><row><cell>GROVER</cell><cell>87%</cell><cell>65%</cell></row><row><cell>MediaCloud</cell><cell>99%</cell><cell>17%</cell></row><row><cell>Source</cell><cell cols="2">Claim Verification KGAT CorefBERT</cell></row><row><cell>Original</cell><cell>70.76</cell><cell>73.05</cell></row><row><cell>+ GROVER</cell><cell>29.02</cell><cell>28.59</cell></row><row><cell>+ MediaCloud</cell><cell>67.10</cell><cell>70.44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The ParagraphJoint model, one of the top systems</figDesc><table><row><cell>Model</cell><cell>Evidence Set</cell><cell cols="4">Sentence Sentence Abstract selection label label rationalized Abstract</cell></row><row><cell>VeriSci</cell><cell>Original</cell><cell>47.69</cell><cell>42.62</cell><cell>51.03</cell><cell>48.45</cell></row><row><cell>(Wadden et al. 2020)</cell><cell>ADVADD</cell><cell>27.05</cell><cell>23.50</cell><cell>25.57</cell><cell>24.33</cell></row><row><cell>SciKGAT</cell><cell>Original</cell><cell>55.61</cell><cell>51.69</cell><cell>58.04</cell><cell>57.41</cell></row><row><cell>(Liu et al. 2020a)</cell><cell>ADVADD</cell><cell>39.44</cell><cell>36.97</cell><cell>37.46</cell><cell>36.98</cell></row><row><cell>ParagraphJoint</cell><cell>Original</cell><cell>53.63</cell><cell>43.59</cell><cell>55.52</cell><cell>49.55</cell></row><row><cell cols="2">(Li, Burns, and Peng 2021) ADVADD</cell><cell>37.68</cell><cell>32.60</cell><cell>41.31</cell><cell>37.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Effect of ADVMOD on FEVER claim verification. We bold the largest performance drop relative to the original evidence.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">CorefBERT Acc.</cell><cell>KGAT Acc.</cell><cell>MLA Acc.</cell></row><row><cell cols="2">Evidence</cell><cell cols="3">(Ye et al. 2020)</cell><cell cols="2">(Liu et al. 2020b)</cell><cell>(Kruengkrai et al. 2021)</cell></row><row><cell></cell><cell></cell><cell cols="2">Total REF</cell><cell cols="2">NEI Total REF</cell><cell>NEI Total REF</cell><cell>NEI</cell></row><row><cell cols="2">Original</cell><cell cols="5">73.05 74.03 72.07 70.76 72.50 69.01 75.92 78.71</cell><cell>73.13</cell></row><row><cell cols="2">ADVMOD-KeyReplace</cell><cell cols="5">53.83 66.50 41.15 42.82 68.90 16.74 60.93 81.83</cell><cell>40.02</cell></row><row><cell cols="2">ADVMOD-paraphrase</cell><cell cols="5">32.62 36.66 28.58 37.22 51.74 22.70 52.72 70.57</cell><cell>34.86</cell></row><row><cell cols="2">ADVMOD-oracle (claim)</cell><cell>4.78</cell><cell>7.94</cell><cell cols="2">1.61 11.90 23.78</cell><cell>0.02 25.17 45.96</cell><cell>4.37</cell></row><row><cell>Original</cell><cell cols="4">Damon Albarn's debut album was released in 2011.</cell><cell></cell></row><row><cell>Paraphrase</cell><cell cols="3">Albarn's first album was released in 2011. His debut album was released in 2011.</cell><cell></cell><cell></cell></row><row><cell>KeyReplace</cell><cell cols="3">Matt Coldplay's debut album was released in 202. Stefan Blur's debut album was released in 1822.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Sample ADVMOD sentences</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>SUP Claim Ron Weasley is part of the Harry Potter series as the eponymous wizard's best friend. Manual Counterclaim Ron Weasley is part of the Harry Potter series as the eponymous wizard's worst enemy. GROVER Output According to the 'Harry Potter: The Story of Ron Weasley' campaign , the prince of Goblet of Fire and Hogwarts castle is part of the series as the eponymous wizard's worst enemy . Automatic Counterclaim Ron Weasley is part of the Harry bee series as the eponymous wizard's best friend. GROVER Output Unlike the remainder of Harry Potter , Ron Weasley is more than just a character on the Hogwarts kiddie roster. Manual Counterclaim Bessie Smith cannot sing. GROVER Output Bessie Smith , a kindergarten teacher in Chicago , Illinois , is scheduled to perform for the 2014 Eagles open game against the Giants on Monday Night Football (18:00 ET on ESPN) . Automatic Counterclaim Bessie Smith was a vegetarian. GROVER Output So how did Bessie Smith become a vegetarian ? The black American woman sat on the United States House Floor as a member of the Congressional Choir during the 70s , when , she actually was a vegan. Sample ADVADD document excerpts generated by GROVER for SUP claims in the FEVER dataset.</figDesc><table><row><cell>Original SUP Claim Bessie Smith was a singer.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>https://www.lawfareblog.com/outsourcing-disinformation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>https://en.wikipedia.org/wiki/ Wikipedia:Wikipedia is not a reliable source</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>https://meta.wikimedia.org/wiki/ Croatian Wikipedia Disinformation Assessment-2021</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>https://www.theatlantic.com/business/archive/2015/08/ wikipedia-editors-for-pay/393926/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p>We will release these documents under a Terms of Use to promote research in fact-checking systems in adversarial settings</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p>Our code can be found at: https://github.com/Yibing-Du/adversarial-factcheck</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>* Authors contributed equally 1 https://www.nytimes.com/article/what-is-qanon.html 2 https://nationalpress.org/topic/the-truth-about-fact-checking/ 3 https://fivethirtyeight.com/features/why-twitters-fact-checkof-trump-might-not-be-enough-to-combat-misinformation/</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Enriching Word Vectors with Subword Information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Transactions of the Association for Computational Linguistics</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Von Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunskill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Buch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Castellon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Chatterji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Creel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Q</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Doumbouya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Etchemendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ethayarajh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuditipudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Levent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Mirchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Munyikwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nilforoshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nyarko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ogut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Piech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Portelance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Roohani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>; R'e</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sadigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tram?r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<idno>ArXiv, abs/2108.07258</idno>
		<imprint/>
	</monogr>
	<note>and Liang, P. 2021. On the Opportunities and Risks of Foundation Models</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Data Voids: Where Missing Data Can Easily Be Exploited</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Go?ebiewski</surname></persName>
		</author>
		<ptr target="https://datasociety.net/wp-content/uploads/2018/05/DataSocietyDataVoidsFinal3.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.14165</idno>
		<title level="m">Language Models are Few-Shot Learners</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Toner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eckersley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Garfinkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dafoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scharre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeitzoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Filar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Roff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>?igeartaigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Belfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Crootof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yampolskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.07228</idno>
		<title level="m">The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Truth, Lies, and Automation: How Language Models Could Change Disinformation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Buchanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Musser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sedova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Center for Security and Emerging Technology</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Bing&apos;s Top Search Results Contain an Alarming Amount of Disinformation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaheer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Internet Observatory News</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">All That&apos;s &apos;Human&apos; Is Not Gold: Evaluating Human Evaluation of Generated Text</title>
		<author>
			<persName><forename type="first">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haduong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00061</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The tactics &amp; tropes of the Internet Research Agency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Diresta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ruppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Matney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Albright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1003&amp;context=senatedocs" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The antivaccination infodemic on social media: A behavioral analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Germani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Biller-Andorno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attention Guided Graph Convolutional Networks for Relation Extraction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="241" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hanselowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.01479</idno>
		<title level="m">UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The Curious Case of Neural Text Degeneration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno>ArXiv, abs/1904.09751</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic Detection of Generated Text is Easiest when Humans are Fooled</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duckworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Amazing World of Neural Language Generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</meeting>
		<imprint>
			<publisher>Online: Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial Examples for Evaluating Reading Comprehension Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">I&apos;m Not Mad&quot;: Commonsense Implications of Negation and Contradiction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sch?tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">All the News That&apos;s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kreps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Mccain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Political Science</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Multi-Level Attention Model for Evidence-Based Fact Checking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kruengkrai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yamagishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of ACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards Few-shot Fact-Checking via Perplexity</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Language Models as Fact Checkers?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<idno>ArXiv, abs/2006.04102</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.14500</idno>
		<title level="m">A Paragraph-level Multi-task Learning Model for Scientific Fact-Verification</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adapting Open Domain Fact Extraction and Verification to COVID-FACT through In-Domain Language Modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fine-grained Fact Verification with Kernel Graph Attention Network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Combining Fact Extraction and Verification with Neural Semantic Matching Networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Decomposable Attention Model for Natural Language Inference</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>T?ckstr?m</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Texas</forename><surname>Austin</surname></persName>
		</author>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">KILT: a Benchmark for Knowledge Intensive Language Tasks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Language Models as Knowledge Bases</title>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Scientific Claim Verification with VerT5erini</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<idno>ArXiv, abs/2010.11930</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Language Models are Unsupervised Multitask Learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/better-language-models/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">COVID-Fact: Fact Extraction and Verification of Real-World Claims on COVID-19 Pandemic</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saakyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ecosystem or Echo-System? Exploring Content Sharing across Alternative Media Domains</title>
		<author>
			<persName><forename type="first">K</forename><surname>Starbird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Van Koevering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yefimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scarnecchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online: Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7798" to="7809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Automated Fact Checking: Task Formulations, Methods and Future Directions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">FEVER: a Large-scale Dataset for Fact Extraction and VERification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The spread of true and false news online</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">6380</biblScope>
			<biblScope unit="page">359</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fact or Fiction: Verifying Scientific Claims</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Online: Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7534" to="7550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Concealed Data Poisoning Attacks on NLP Models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murdick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sheehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B S</forename><surname>Stilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><surname>Etzioni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.10706</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>and Kohlmeier, S. 2020. CORD-19: The COVID-19 Open Research Dataset</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Coreferential Reasoning Learning for Language Representation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online: Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">UCL Machine Reading Group: Four Factor Framework For Fact Finding (HexaF)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yoneda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In FEVER</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Defending Against Neural Fake News</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roesner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">PEGA-SUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.08777</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Reasoning Over Semantic-Level Graph for Fact Checking</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
