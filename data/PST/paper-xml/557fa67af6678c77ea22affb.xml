<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">&quot;An improved sphere covering bound for the codes with</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Gregory</forename><surname>Poltyrev</surname></persName>
							<affiliation key="aff0">
								<address>
									<postCode>26-30, 1992</postCode>
									<settlement>Udine</settlement>
									<region>October</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering-Systems Faculty of Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
								<address>
									<postCode>69978</postCode>
									<settlement>Tel-Aviv</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">&quot;An improved sphere covering bound for the codes with</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">610CB7528897464A1E1C560AB41BC51A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>R. StruiL, "On the structure of linear codes with covering radius two and three," IEEE Tmns. Inform. Theory, to appear in September 1994 issue of IEEE Transactions on Information Theory. G. J. M. van Wee, "Improved sphere bounds on the mering radius of codes," IEEE Tmns. Infirm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The estimation of decoding error probability of a linear code is a long-standing problem both in theory and practice. The most familiar upper bound on the error probability of a binary linear code used for a symmetric channel without memory is the so-called union bound. This bound can be calculated if the 0018-9448/94$04.00 0 1994 IEEE weight distribution of the codewords (the spectrum of the code) is known. The union bound is tight at low levels of noise, and is very useful for codes with moderate length when a low level of error probability (less than 10-3-10-4) is required. Under these conditions, sometimes only the first term of the spectrum, corresponding to the minimum distance of the code, is important. At the same time, the unian bound is a very poor estimate of the error probability at high noise levels, i.e., for error probability in the range 0.01-0.1 (which is an acceptable probability of error in decoding the inner code of some concatenated code construction). There have been a few attempts to improve the union bound El-31.</p><p>The problem of estimating the decoding error probability of a linear code is simplified considerably if one considers an ensemble of codes. Such an approach enables one to construct, by means of the random coding method, an upper bound for the ensemble-average error probability 141. Typically, the exponent E(R) of this bound, considered as the function of the coding rate R , consists of the following three regions [41: the "sphere packing bound'' (sp), for the region R,, I R s C; the "straight line bound" (SO, for the region R,, I R I R,,; and the "expurgated bound" (ep), for the region 0 &lt; R I Rc2, where C is the capacity of the channel, and R,, and R,, are the two critical rates corresponding to the boundaries of the sp and sl regions. It is also possible to calculate the average spectrum over the ensemble of linear binary codes. If we apply the union bound for a code with this average spectrum, we obtain an exponent that coincides with E(R) on the sl and ep regions (0 I R I R,,).</p><p>However, this is not true for the sp region (R,, I R I C ) and one wonders whether it is possible to make the error exponent to coincide with E(R) by means of some improved version of the bound. In general, the ability to approach E ( R ) at the sp region is a test for the quality of the bound. In this respect, as we shall see later, the answer to Berlekamp's question <ref type="bibr">[2]</ref>, if his tangential bound is asmyptotically "correct" at high noise level, is negative.</p><p>Clearly, one cannot express the exact value of the maximum likelihood decoding error probability for any nontrivial linear code in terms of its spectrum. Nevertheless, <ref type="bibr">Blokh and Zyablov [5]</ref> have shown that for any linear binary code with average spectrum, the exponent of the error probability of maximum likelihood decoding coincides with the random coding exponent. <ref type="bibr">CsiszC and Komer [6]</ref> have considered codes with fixed compG sition over an alphabet X of size q. They have proved that, if the fraction of codewords with a given conditional composition with regard to any fixed codeword coincides with the fraction of all q-ary sequences with this conditional composition in the space X", then the exponent of the decoding error probability for any discrete channel without memory coincides with the random coding exponent in the limit as n goes to infinity. (For the case q = 2, conditional composition of one sequence with regard to another is determined by the Hamming distance between them. In other words, the number of codewords having a fixed conditional composition with respect to a given codeword is equal to the number of codewords at a fixed Hamming distance from that codeword.) One may conclude that the spectrum can provide a tight estimate for the error probability of the average binary code. But, as we shall see in the example of the Gaussian channel with binary input, the computation of such a bound may require solving a rather difficult variational problem. Therefore a simpler, albeit less tight, bound may be preferable.</p><p>In this paper we investigate some bounds on the decoding error probability of a binary linear code in the binary symmetrical channel (BSC) and in the channel with additive white Gaussian noise (AWGN channel).</p><p>All the bounds that we shall consider are based on the following simple inequality, which is usually used for constructing upper bounds on the decoding error probability. Let C be a decoding error event and let A be some subset of noise vectors z ( z is a binary vector for the BSC case or a Gaussian vector for the AWGN channel case). Then the decoding error probability A satisfies the inequality (1)</p><p>For the case of BSC we choose as the set A a Hamming sphere and construct the so-called S bound (SB). We prove that for any sequence of codes with average spectrum, the exponent of the decoding error probability for the S bound asymptotically coincides with the random coding exponent (Theorem 1).</p><p>For the AWGN channel case we construct the so-called "tangential-sphere" bound (TSB), which is tighter than the "tangential" bound of Berlekamp. But as we shall see, even this bound does not achieve the random coding exponent at the sp region. The main reason is that this bound, which indeed holds for any code (not only binary) on a Euclidean sphere, approximates the decision regions of the code by means of symmetrical domains (cones). However, this approximation is not tight enough in the case of transmission of a binary code through the AWGN channel.</p><p>The organization of the paper is as follows. Sections 11 and I11 contain results for the BSC case. The bound on the decoding error probability and its properties are presented in Section 11.</p><p>The proof that the exponent of this bound coincides with the random coding exponent E(R) for all R (0 I R I C ) is given in Section 111. Sections IV and V contain results for the AWGN channel. Three bounds on the decoding error probability-the S-bound of Hughes, the tangential bound of Berlekamp, and the "tangential-sphere" bound-are given in Section IV. The asymptotic behavior of the exponents of these bounds for a code with an average spectrum is investigated in Section V. In Section VI some examples, illustrating all these bounds, are provided. The paper is concluded with a discussion on the derived results.</p><p>11. h UPPER BOUND ON THE DECODING ERROR PROBABILITY OF A BINARY LINEAR CODE: BSC CASE Consider transmission of a linear binary ( n , k ) code through a BSC with crossover probability p , where n is the l e s h of the code and R = k/n is its rate. Let S = (S,}, w = d, n be the spectrum of this code ( d is the minimum distance of the code and S, is the number of codewords with Hamming weight w).</p><p>For any linear code and any BSC, the decoding error probability A does not depend on the transmitted codeword and thus it is sufficient to consider only the transmission of the zero codeword (a sequence of n zeroes).</p><p>It is well known that the following union bound is true for A.</p><p>A I Pr (C, z E A ) + Pr ( z E A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A I S, 5 ( y ) p f ( l -PI"-',</head><p>( 2 )</p><formula xml:id="formula_0">w = d t = f ,</formula><p>where t, = ( [ w / 2 ] is the smallest integer larger than or equal to w / 2 .</p><p>The inequality (2) is called the union bound for the error probability of a binary linear code with fixed spectrum. This bound is tight if the minimum distance d is rather large and the crossover probability p of the BSC is small; more exactly, if td B np, but the union bound is too loose for large values of p . In this case the output sequences that are closer to several codewords than to the transmitted zero codeword, have the main influence on the value A. As a result, the probabilities of these sequences are counted many times in the bound (2). Now the upper bound for the probability A will be constructed, which improves the inequality (2) in the range of large values of crossover probability p.</p><p>Lemma 1 (SB: BSC case): The error probabilityh of any binary linear code with the spectrum' {S,}, w = d, n is upper bounded as follows:</p><formula xml:id="formula_1">A &lt; S, ( ; ) p q ( l -P ) ~-" Z ( m O -l ) mo-1 w = d ~= t , m o -n -l ,</formula><p>x "E ( w)p'(l -p ) n -w -k</p><formula xml:id="formula_2">k = 0 (3)</formula><p>where m , is the smallest integer such that Zm (4)</p><formula xml:id="formula_3">w = d q = t w</formula><p>Proof Let [,, be the number of errors occumng when a codeword of length n is transmitted. Let w be the weight of some incorrect codeword and let 6, and [,, -, be the number of errors occurring in the positions of 1 and 0, respectively, of this codeword. We shall use a Hamming sphere of radius m -1 as the set A in the inequality (1). Then for a BSC with a crossover probability p , we have</p><formula xml:id="formula_4">A I min (Pr (C, 5, &lt; m ) + Pr (5, 2 m ) ) .</formula><p>(5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2='td</head><p>For the first term it is possible to use the following union bound:</p><formula xml:id="formula_5">P r ( C , [ , &lt; m ) s S, P r ( t , = q ) Z(m-1) m -1 w = d ~= f , xPr(S,-, &lt; m -q). (<label>6</label></formula><formula xml:id="formula_6">)</formula><p>The substitution of ( <ref type="formula" target="#formula_5">6</ref>) and (5) and direct computation of the 0</p><p>The bound (3) can be used for any binary linear code provided its spectrum is known. We shall call this bound the S bound (SB). It follows from (4) that the value m,, which minimizes the bound (3), depends only on the spectrum of the code and does not depend on the crossover probability of the BSC. The next proposition establishes a connection between the covering radius of a binary ( n , k ) code and the value m,. Proposition: Let m, be the smallest integer that satisfies the inequality (4) and let r, be the covering radius of a binary linear, <ref type="figure">(n,</ref><ref type="figure">k</ref>  The error exponent coincides in the interval psp s p I a with the sphere packing bound and thus it is asymptotically tight in this interval. In the interval 0 I p I Pad, this exponent coincides with the error exponent of a code with two codewords whose Hamming distance is equal to a n .</p><p>For the ensemble of binary linear codes, it is also possible to calculate the average value of the spectrum:</p><formula xml:id="formula_7">ES, = 2nR n 2-n = 2n(h(o)-h(a)-o(n)), (<label>12</label></formula><formula xml:id="formula_8">)</formula><p>where w = on and limn+m o(n) = 0. It can be easily proved from (12), by means of the Chebyshev inequality, that there exist binary codes with the following spectra (see, for example [7, Theorem 41):</p><formula xml:id="formula_9">w = on 2 an, sw = { 0, w = o n &lt; a n .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( w )</head><p>(13)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2n(h(o)-h(a)+o(n)),</head><p>A code with the spectrum (13) will be called an "average code" or a code with an "average spectrum."</p><p>The following theorem derives that the S bound (3) implemented for a code with an "average spectrum" coincides asymptotically with the random coding bound.'</p><p>Theorem 1: For any binary linear code with an "average spectrum" (13) the S bound (3) satisfies</p><formula xml:id="formula_10">(14) A S -&lt; 2-n(E(R9p)-o(n)) , where lim, o(n) = O.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. UPPER BOUNDS ON THE DECODING ERROR PROBABILITY OF A BINARY LINEAR CODE: AWGN CHANNEL CASE</head><p>In this section we consider transmission of codewords of a binary linear (n, k ) code through an AWGN channel with maximum likelihood soft decision decoding. We will assume that 'The proofs of this theorem and Theorem 2 in Section IV are omitted based on the reservation of an anonymous referee that they "are trivial exercises to those familiar with the works of Elias and Fano, or Gallager's book."</p><p>where AI2(w) denotes the probability of error in decoding a code with two words whose Hamming distance is w, and There are two bounds that improve the union bound (15). The first is the Hughes bound [3], which is true for any code, not necessarily binary, with a given distribution of Euclidean distances between the codewords. The second is the "tangential union bound" of Berlekamp [2]. We shall construct an additional bound, the so-called "tangential-sphere bound," which is tighter than the previous known bounds.</p><p>The Hughes bound, as applied to a binary linear code, is formulated in the following lemma. where zr is the root of the following equation:</p><formula xml:id="formula_11">y ( 6 -2,) ) = 1, y = { X . n -w (21) w = d</formula><p>It is reasonable to combine the ideas leading to the sphere and tangential bounds in order to obtain an improved bound for the decoding error probability of binary linear code in the AWGN channel. Such a bound is established by the following lemma.</p><p>Lemma 4 (the tangential-sphere bound (TSB)): The error p r e ability A of any binary linear code with a spectrum (Sw}, w = d, n is upper bounded as follows:  where we have assumed that the component z2 is directed along the line that connects the transmitted codeword xo to the projection on the plane z, = z1 of some codeword with Hamming distance w apart (see Fig. <ref type="figure" target="#fig_3">1</ref>).</p><formula xml:id="formula_12">In (22), wzl = w ( 6 -z,Y/n -w ; rZI = to(&amp; -z1)2, to = tan2 Bo = ro/n,</formula><p>Differentiating over r the right side of (26) and using some straightforward transformations, we are led to (23). integrating (26) with respect to zl, under rZ1 = t,(hzl ), yields the bound (22).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>The second term in (22) is the probability that the output sequence of the AWGN channel falls outside of the cone Cn(t3,). The first term in (22) is the union bound for the conditional decoding error probability of a binary linear code, given that the channel output sequence belongs to the cone Cn(Bo). As we shall see, for large values of noise dispersion, the exponent of A is determined by the exponent of the second term of (22), i.e., by the probability of projecting outside the cone Cn(Bo). Thus the value of ro defines the maximum value of the angle B such that the cones corresponding to different codewords almost do not intersect. Unfortunately, since the codewords of any binary linear code are distributed nonuniformly on the Euclidean sphere, these cones do not form a dense packing of the Euclidean space. Hence we cannot anticipate that the TSB will be asymptotically tight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPONENT OF THE DECODING ERROR PROBABILITY FOR AN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AVERAGE BINARY LINEAR CODE: AWGN CHANNEL CASE</head><p>In the case of transmission through the AWGN channel, the random coding exponent E,(R, U'), where R is the code rate and U' is the noise dispersion, for the ensemble of all binary linear codes can be presented as follows (see, e.g., 191). It is possible to prove that for any binary linear code with average spectrum, the exponent of the tangential-sphere bound, which we have derived in the previous section, coincides with the random coding exponent EG(R, u 2 ) for 0 &lt; U' I U$, (i.e., in the "expurgated" and "straight line" parts. But, as we shall see, the TSB exponent does not coincide with E J R , U ' ) in the "sphere packing" part. By (30) and (311, if the code rate is close to the capacity of the channel, the decision regions (Voronoi regions for an "average" binary code are approximated asymptotically by the "high probability sets" of the distributions no spherical symmetry with respect to the transmitted codeword</p><p>x, unlike the Gaussian distribution. This is a result of the fact that, unlike a code over a "continuous alphabet," codewords of a binary "average" code are not uniformly distributed on the Euclidean sphere. The construction of the TSB, however, does not take into account the alphabet of the code. (The TSB applies to a code over any alphabet with a known Euclidean distance distribution.) It is possible to prove, using the methods of [61, that the random coding bound (31) holds asymptotically for any binary linear code with an "average" spectrum. However, approximating the decision regions of a code with fmite length and with specific spectrum by means of the "high probability sets" of distributions like f,(ylx,) is practically impossible. In the following theorem the TSB asymptotic exponent for an "average" binary linear code is derived? The comparison of this bound with the random coding exponent will allow us to reveal the inaccuracy of the TSB. linear code with an "average" spectrum is given by a,:</p><formula xml:id="formula_13">I U 2 I t o , (<label>32</label></formula><formula xml:id="formula_14">)</formula><p>where a is the root of the equation 1h ( a ) = R , pqo = tO(1to)', and 022"</p><p>(1 -w)(22', -1) ' to = min 0 (33)</p><formula xml:id="formula_15">1 + 2t0 -41 + 4u2(1 + to) 770 = 2 0 + to) 9 (35) 0,: = t o o -OrJ2 -0Jl -O J , (<label>36</label></formula><formula xml:id="formula_16">)</formula><p>and ots is the root of the following equation:</p><formula xml:id="formula_17">1 -0 20(1 - In -= 22(h(o)-h(a)) -1. (<label>37</label></formula><formula xml:id="formula_18">) 0</formula><p>It is also possible, of course, to obtain by Lemma 2 and 3 the asymptotic SB and TB exponents for an "average" code. In Figs. <ref type="figure">2</ref><ref type="figure" target="#fig_7">3</ref><ref type="figure" target="#fig_8">4</ref>, the random coding, SB, TB, and TSB exponents for "average" codes with rates R = 0.25, 0.5, 0.75 bit/smb, respectively, are shown. Also, Shannon's upper bound <ref type="bibr">[lo]</ref> for the decoding error exponent of any code in an AWGN channel with codewords belonging to the Euclidean sphere of radius 6, where n is the code length ( n + QJ), are shown on the same figures. This Shannon bound is the bound of density packing for the Euclidean space by means of cones with solid half-angle 0, Bounds on exponent of emr probability for an "average" code (AWGN) 0.2, , . where R is the code rate in bit/smb. In Figs. <ref type="figure">2</ref><ref type="figure" target="#fig_7">3</ref><ref type="figure" target="#fig_8">4</ref>, the values of tu, and the values of to given by Theorem 2, are also shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXAMPLES</head><p>In this section we present some examples of applying the foregoing bounds. We consider four primitive BCH codes with parameters (63,24), (63,30), (63,36), and (63,391. The spectra of these codes are close to the spectrum of the "average" code. In Table <ref type="table" target="#tab_0">I</ref> the first terms of the spectra of these codes, which have been calculated in [ U ] , are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Transmisswn through BSC</head><p>The bound (3) is plotted in Figs. <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref><ref type="figure">8</ref>. For comparison, we have exhibited also the union bound (21, the truncated union bound (the first term of (2)), and the sphere packing bound. The sphere packing bound for an (n, k) code is derived as follows. We find the integers t and N , N &lt; i(y</p><formula xml:id="formula_19">) + N = 2 " -k . i = O (38)</formula><p>Then the sphere packing bound for the decoding error probability of an ( n , k) code, used for transmission through a BSC with crossover probability p , is 1. <ref type="figure" target="#fig_7">( y ) p ' ( l --P ) " -~ + Np"'(1 -p ) " -* -l (39)</ref> -1</p><formula xml:id="formula_20">A 1 1 -(i</formula><p>The values of rsp = t + N( and mo, which are the solutions of (4), are provided by Table <ref type="table" target="#tab_0">I</ref> for the codes under consideration. One can see by Figs. 5-8 that the truncated union bound and the sphere packing bound are close to each other for large values of crossover probability, and both are considerably different from the tighter S bound (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Transmission through A WGN Channel</head><p>The sphere bound (171, the tangential bound (20), and the tangential-sphere bound (22) for the codes from Table <ref type="table" target="#tab_0">I</ref> are plotted in Figs. 9-12. In these figures, we have also shown the union bound ( U ) , the truncated union bound (the first term of (191, and the density packing bound of Shannon, which is true for any, not just binary, code. The density packing bound is equal to the probability that the output sequence of the AWGN channel will not be confined to the cone with a solid half-angle Osp centralized with respect to the transmitted codeword, where esp is determined by the rate R and the length n of the code.</p><p>For calculation of Os, , we used the following bounds of Shannon [lo]:</p><p>For n = 63, these bounds practically coincide. The values fsp = tan2 Osp and to = tan2 Bo (see Lemma 4) for the codes under investigation are given in Table <ref type="table" target="#tab_0">I</ref>.</p><p>VII. CONCLUSION As we have seen in Section 111, the S bound (3 asymptotically coincides with the random coding exponent in the case of transmission through a BSC. It is clear that for any sequence of "average" binary linear codes, with fixed rate R and length n going to infinity, the random coding exponent is asymptotically tight for all crossover probabilities such that p 5 pad or p 2 psp (see (10) and 11)). This statement is true for p &lt;pad because the random coding exponent is equal, in this case, to the exponent of the decoding error probability for a code with two words and with minimum distance equaling the minimum distance of an "average" code. The conclusion for p 2 psp follows by observing that the random coding exponent coincides with the exponent of the sphere packing bound. The question: "Is the random coding exponent asymptotically tight for pod 5 p I psp for any sequence of "average" codes?" remains open.</p><p>The optimal value of the radius m for the S bound (3) does not depend on the crossover probability p of the BSC and it  defines a lower bound on the covering radius of binary linear codes with a fixed spectrum. For all the examples considered above, the minimum distance of the code does not determine the error probability of maximum likelihood decoding, even â‚¬or quite low values of these probabilities. At the same time, any decoding algorithm, which can correct some combinations of t &lt; mo errors, will have a decoding error probability satisfying the S bound.</p><p>All three bounds considered in Section IV, namely, the SB, TB, and TSB, are applicable to codes over any alphabet if the Euclidean distance distribution of the code is known. However, the TB and TSB can be used only if all codewords have a fixed energy, whereas the SB (Hughes bound) is applicable for any code.</p><p>The "universality" of the SB, TB, and TSB (i.e., their independence on the code alphabet) is the main reason for their asymptotic nontightness. Furthermore, as we have seen in Section V (Figs. <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>), the difference between the random coding 0018-9448/94$04.00 0 1994 IEEE exponent and the TSB exponent for binary codes is not very large, especially in the case of lower rates. Thus we can anticipate that the TSB for specific codes must be tight enough. It is possible to show that the TSB exponent coincides asymptotically with the random coding exponent for an ensemble of codes, whose words are chosen according to the uniform distribution on a Euclidean sphere of fixed radius. The fact that the TSB exponent for an "average" code depends only on its Euclidean distance distribution allows the estimation of different ensembles over different alphabets by means of comparing only their "spectra" with the "spectrum" of the "average code" corresponding to the "optimal" ensemble. (A more detailed investigation of this problem is beyond the scope of this work.) Index Tenns--RLL code, BDB code, block-decodable code, principal state-set, look-ahead coding. <ref type="figure">A ( d ,</ref><ref type="figure">k</ref> ) runlength-limited (RLL) sequence is a binary sequence in which each run of like symbols has length between d + 1 and k + 1. RLL sequences as well as ( d , k ) sequences (binary sequences describing the transitions in RLL sequences) have found many applications in various high-capacity storage devices. The use of these sequences is discussed in detail in 131, where further references can be found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCITON</head><p>In this correspondence, we describe a (1,8) RLL blockdecodable rate 8/12 code with codeword length 12 bits. Here, block-decodable, a term introduced in [3], refers to the fact that each codeword, or block decodes into a unique (8-bit) source word, irrespective of context. Encoding can be achieved with a finite-state encoder; this encoder will be implicit in our descriptions of the code. Due to its format, this code has favorable error propagation properties, especially when used in combination with error-correcting codes such as Reed-Solomon codes over the finite field CF(28) (e.g., [41). The code belongs to the family of bounded delay block-decodable (BDB) codes with one symbol (here:bits) look-ahead during encoding [ 11.</p><p>Bounded delay (BD) codes, a family of codes employing look-ahead encoding techniques, were introduced by Franaszek [6]. He described a necessaq condition for their existence in terms of an approximate eigenvector, and showed how such a vector could be of help in code construction. (See also 171.) Franaszek also mentioned block-decodable BD codes, or "instantaneously decodable" codes as he named them.</p><p>Franaszek's methods do not constitute a polynomial-time algorithm. A breakthrough in that respect was the discovery of the ACH algorithm [5]. This algorithm produces a code by applying rounds of "state splitting" on the constraint graph. As in the BD method, the construction is guided by an approximate eigenvector.</p><p>Recently, the subject of code construction received new impetus with the work of SchouhamerImmink <ref type="bibr">[3]</ref>. In this paper, many new BDB (block-decodable) RLL codes, with sometimes surprisingly small codeword lengths, are constructed via lookahead techniques, based on state combination (as opposed to state splitting as in ACH) and guided by an approximate eigenvector with components equal to one or two.</p><p>Motivated by this work, the theoretical properties of BDB codes were investigated in [l] and <ref type="bibr">[2]</ref>. In <ref type="bibr">[l]</ref>, it is shown that one-symbol look-ahead BDB codes can be advantageously described as well as constructed in terms of principal state-sets. We will return to this shortly. A rate 2/3 BDB (1,8) RLL code with 8-bits look-ahead entails a partition of the collection of 12-bit codewords or blocks (12-bit words not violating the prescribed (1,8) runlength constraint) into 256 mutually' disjoint codeword classes, where each codeword class corresponds to a unique 8-bit source word (source symbol) and represents the alternative encodings of this source symbol. Of course, a description of the code in terms of this partition into codeword classes alone is not very satisfactory without a means to verify that one-symbol look-ahead encoding</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>) code with the spectrum {S,}. Then rc 2 m,. Proofi Let V(w, m ) = {x: 1x1 = m; ( x x,I I m, for all codewords xi such that (xi( = w}, where 1x1 is the weight of x. The term of the outer sum on the left side of (4) is the maximal number of binary sequences in the set V(w,m). Suppose that the covering radius rc = m , -1. Now it follows from the definition of m , (4) that there are binary sequences of the weight mo which do not belong to any Hamming sphere of radius m, 0 minimum over m proves (3). centered on a code word. Hence r, 2 m,. 111. THE ~N E N T OF THE DECODING ERROR PROBABIL~~ FOR AN AVERAGE BINARY L,INEAR CODE: BSC CASE Upper bounds on the ensemble-averaged error probability are well known (see, e.g., [4D. In the BSC case these bounds can be written as follows:A I 2-nE(R,P),(7)   where R is the code rate and p is the crossover probability of the BSC. For a fixed value of R , 0 s p &lt;pad, binary symbols are transmitted through the channel by means of signals of unit energy: 1 and -1, and that the dispersion of the Gaussian noise equals u 2 = N0/2, where No is the spectral density of the noise. Therefore the signal-to-noise ratio (SNR) of a transmitted symbol is l/No and the SNR per bit equals l/RNo, where R is the code rate; the squared Euclidean norm of every codeword is n; the Euclidean distance between two codewords whose Hamming distance is w equals 2 6 .The union bound for the probability of erro_lth in decoding a binary linear code with a spectrum {Sw}, w = d, n, in an AWGN channel is where a is the root of 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(A very simple proof of the Hughes bound is contained in [81.) Lemiqa 2 (the sphere bound of Hughes (SB)): The error pro&amp; bility A of any binary linear code with a spectrum {Sw}, w = d, n is upper bounded as follows: where and ro is a root of the following equation: where Ow = arccos(\/wlr). The tangential bound of Berlekamp 121 is based on the fact that all codewords of a binary code for transmission through an AWGN channel belong to the surface of a Euclidean sphere with radius 6. Lemma 3 (the tangential bound of Berlehmp (TB)): The error probability A of any binary linear code with a spectrum {Sw}, w = d, n is upper bounded as follows: w = d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and ro is the root of the following equation: where Ow = a r c c o s ( 6 / ( l -ob) and o = w / n . Proof Let Cn(e) be a circular cone with a half-angle 0 whose central line passes through the point 0 and the transmitted codeword x. Let us set A = Cn(t3) in the inequality (1). Then we have A I Pr ( C , z E &amp; ( e ) ) + Pr ( z E cn(e)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>IFig. 1 .</head><label>1</label><figDesc>Fig. 1. Construction of tangential-sphere bound.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Then the random coding exponent is given by where u2 = (21n(la/a))-'; U: is the root of equation Zfc(X;Y) = R; 0s; is the root of Zf(X,Y)lp=l = R; and the parameter p is the root of H((,,fG) = R for any u 2 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>f,(ylx,) = 17,"=,f,(yJ]xJ,), where x, = (xll .-. x,,,) is the codeword. It is easily seen by (28) that the distributions f,(ylx) have</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 2 :Fig, 2 .</head><label>22</label><figDesc>Fig, 2. Random coding, SB, TB, and TSB exponents .for "average" code with R = 0.25 bit/smb.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Random coding, SB, TB, and TSB exponents for "average" code w i t h R = 0.5 bit/".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Random coding, SB, TB, and TSB exponents for "average" code w i t h R = 0.75 bit/".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig. 5. Bounds on the decoding error probability of BCH (63,241 Fig. 6. Bounds on the decoding error probability of BCH (63,301 (BSC). (BSC).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>a</head><label></label><figDesc>codeword can be decoded without knowledge of preceding or succeed-Manuscript received January 11, 1993; revised August 26, 1993. The author is with Phillips Research Laboratories, 5600 JA Eind-IEEE Log Number 9403716. . hoven, The Netherlands. ing codewords. Th d e belongs to the class of bounded delay blockdecodable (BDB) codes with one symbol (8 bits) look-ahead. Due to its format, this code is particularly attractive for use in combination with emr-correcting codes such as Reed-Solomon codes over the finite field GF(2').</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PARAMETERS OF CODES</head><label>I</label><figDesc></figDesc><table><row><cell cols="2">w 15</cell><cell>16</cell><cell>17</cell><cell>18</cell><cell>19</cell><cell>20</cell><cell>21</cell><cell>22</cell><cell>I 'lp mo tlp to</cell></row><row><cell>(63,24)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>I</cell></row><row><cell cols="4">S , 651 1953 3024</cell><cell>7728</cell><cell>0</cell><cell>0</cell><cell>74449</cell><cell cols="2">142128 I 10.64 11 1.77 15</cell></row><row><cell cols="2">w 13</cell><cell>14</cell><cell>15</cell><cell>16</cell><cell>17</cell><cell>18</cell><cell>19</cell><cell>20</cell><cell>I rlp mo tlp to</cell></row><row><cell>(63,301</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>I</cell></row><row><cell cols="4">S , 1764 6300 7707</cell><cell cols="6">23121 177660 454020 352800 776160 I 8.17 9 1.28 1.12</cell></row><row><cell cols="2">w 11</cell><cell>12</cell><cell>13</cell><cell>14</cell><cell>15</cell><cell>16</cell><cell>17</cell><cell>18</cell><cell>I rlp *o tlp to</cell></row><row><cell>(63,361</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>I</cell></row><row><cell cols="10">S , 5670 24750 77616 277200 895755 2687265 7623504 194822881 6.11 7 0.97 0.82</cell></row><row><cell>w</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>14</cell><cell>15</cell><cell>16</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENIX</head><p>The author thanks J. Snyders and M. Feder for a series of very useful remarks and suggestions which undoubtedly improved the content of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Manuscript received March 3, 1992; revised June 10, 1993. This research was supported by the Ministry of Science and Technologv and by the Center for Absorption in Science of the Ministry of Absorption of Israel. This work was presented at Eurocode 92,</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(BSC).</p><p>Bounds on the decoding error probability of BCH (6324) (AWGN)</p><p>. .</p><p>-3 --3.5 -6 -" c a w additiie bound (AWGN).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new upper bound on the first-event error probability for maximum-likelihood decodig of k e d binary convolutional codes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cedervall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Johannesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sh</surname></persName>
		</author>
		<author>
			<persName><surname>Zigangirov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tmns. Znform. Theory</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="762" to="766" />
			<date type="published" when="1984-09">Sept. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The technology of error-correcting codes</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Berlekamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ZEEE</title>
		<meeting>ZEEE</meeting>
		<imprint>
			<date type="published" when="1980-05">May 1980</date>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="564" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the error probability of signals in additive white Gaussian noise</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Theory and Reliable Communication</title>
		<meeting><address><addrLine>New York Wiley</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Blokh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Zyablov</surname></persName>
		</author>
		<title level="m">Linear Concatenated Codes</title>
		<meeting><address><addrLine>Moskva</addrLine></address></meeting>
		<imprint>
			<publisher>Nauka</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note>in Russian</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph decomposition: A new key to coding theorems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csiszh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="12" />
			<date type="published" when="1981-01">Jan. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Existence of linear concatenated bionary codes with optimal correcting properties</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Blokh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Zyablov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prob. lnf. Tmnsm. (USSR)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3" to="10" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Techniques of bounding the probability of decoding error for block coded modulation structures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Herzberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Poltyrev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Theory</title>
		<imprint>
			<date type="published" when="1992-05">May 1992</date>
		</imprint>
	</monogr>
	<note>submitted to IEEE Tmns</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probability of error for optimal codes in a Gaussian channel</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Poltyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><surname>Dumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1382" to="1386" />
			<date type="published" when="1959-05">May 1959. Jan. 1991. 1982. July 1992</date>
		</imprint>
	</monogr>
	<note>Bell Syst. Tech. J.. A Block-Decodable (1,8</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Code</forename><surname>Henk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Hollmann</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Abstmct-We describe a ( d , k) = (1,8) runlength-limited (RLL) rate 8 / 12 code with k e d codeword length 12</title>
		<imprint/>
	</monogr>
	<note>The code is block-decodable</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
