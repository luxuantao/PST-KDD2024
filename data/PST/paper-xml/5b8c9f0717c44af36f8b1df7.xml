<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">API Method Recommendation without Worrying about the Task-API Knowledge Gap</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qiao</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
							<email>xin.xia@monash.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Monash University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
							<email>zhenchang.xing@anu.edu.au</email>
							<affiliation key="aff2">
								<orgName type="institution">Australian National University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Lo</surname></persName>
							<email>davidlo@smu.edu.sg</email>
							<affiliation key="aff3">
								<orgName type="institution">Singapore Management University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
							<email>wangxinyu@zju.edu.cn</email>
							<affiliation key="aff4">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">API Method Recommendation without Worrying about the Task-API Knowledge Gap</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F8751C14B133A476E495C53CA597737</idno>
					<idno type="DOI">10.1145/3238147.3238191</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>API Recommendation</term>
					<term>API Documentation</term>
					<term>Stack Overflow</term>
					<term>Word Embedding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Developers often need to search for appropriate APIs for their programming tasks. Although most libraries have API reference documentation, it is not easy to find appropriate APIs due to the lexical gap and knowledge gap between the natural language description of the programming task and the API description in API documentation. Here, the lexical gap refers to the fact that the same semantic meaning can be expressed by different words, and the knowledge gap refers to the fact that API documentation mainly describes API functionality and structure but lacks other types of information like concepts and purposes, which are usually the key information in the task description. In this paper, we propose an API recommendation approach named BIKER (Bi-Information source based KnowledgE Recommendation) to tackle these two gaps. To bridge the lexical gap, BIKER uses word embedding technique to calculate the similarity score between two text descriptions. Inspired by our survey findings that developers incorporate Stack Overflow posts and API documentation for bridging the knowledge gap, BIKER leverages Stack Overflow posts to extract candidate APIs for a program task, and ranks candidate APIs by considering the query's similarity with both Stack Overflow posts and API documentation. It also summarizes supplementary information (e.g., API description, code examples in Stack Overflow posts) for each API to help developers select the APIs that are most relevant to their tasks. Our evaluation with 413 API-related questions confirms the effectiveness of BIKER for both class-and method-level API recommendation, compared with state-of-the-art baselines. Our user study with 28 Java developers further demonstrates the practicality of BIKER for API search.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Application Programming Interfaces (APIs) in software libraries (e.g., Java SDK) play an important role in modern software development. With the help of APIs, developers can complete their programming tasks more efficiently. However, it is not easy to be familiar with all APIs in a large library. Thus, developers often need to check the API documentation to learn how to use an unfamiliar API for a programming task, and the prerequisite is that they already know which API to use but are just unfamiliar with the API. This situation can be referred to as "known unknowns".</p><p>However, a more practical scenario is that developers only have the requirement of a programming task, while they do not even know which API is worth learning (i.e., "unknown unknowns"). A possible solution is to use the natural language description of the programming task as a query, and use Information Retrieval (IR) approaches to obtain some candidate APIs whose documentation is similar to the query. However, this solution may not work well due to the lexical gap between the query and the API documentation. For example, given the query "How to initialize all values in an array to false?", the description of the most appropriate Java API method Arrays.fill is "Assigns the specified boolean value to each element of the specified array of booleans.", which does not contain any important keywords like initialize or false in the query.</p><p>Recently, a neural network-based approach called word embedding <ref type="bibr" target="#b26">[27]</ref> has been proposed to capture the semantic meaning of different words. It represents each word by a low dimensional vector, and semantically similar words (e.g., initialize and assign, false and boolean) would be close in the vector space. Ye et al. <ref type="bibr" target="#b48">[49]</ref> leveraged word embedding to bridge the lexical gap between the query of programming task and Java API documentation. However, by replicating their study, we observe two major problems, as listed below.</p><p>The first problem is that they investigated API recommendation at class-level only. Given the above query example, their approach recommends only the Arrays class and developers still have to check about 50 methods to locate Arrays.fill if they check the methods one by one in the default order in the Arrays documentation. While their approach can be applied for method-level recommendation, its effectiveness is unknown.</p><p>The second problem is that even if their approach could bridge the lexical gap, it is still difficult to find the relevant API whose description does not share semantically similar words with the query. For example, given the query "How to check whether a class exists?", the most relevant Java API method recommended by Ye et al.'s approach is org.omg.CORBA.Object._is_a, whose description is "Checks whether this object is an instance of a class that implements the given interface.", and the similarity score between this description and the query is 0.669, since the two sentences have semantically similar words (e.g., class and object) or exactly the same words. However, the truly relevant API for the query is java.lang.Class.forName, whose description is "Returns the Class object associated with the class with the given string name."; its similarity score with the query is only 0.377, since its description does not contain words similar to 'check', 'whether' or 'exists'. However, forName can be used to "check whether a class exists". We call such mismatches between a task description and the API documentation as task-API knowledge gap, and our observation is also consistent with previous studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b38">39]</ref>, which pointed out that API documentation mainly describes API functionality and structure, but lacks other types of information (e.g., concepts or purposes).</p><p>To bridge this task-API knowledge gap, we conduct a survey with developers from two IT companies to understand how developers search for APIs to resolve programming tasks and the developers' expectations on automatic API recommendation techniques. From 47 responses, we find that when developers search APIs, a typical information seeking process is to browse a number of Stack Overflow (SO) questions and pick out the APIs that seem to be useful according to the discussions. Thus, SO is often exploited as a bridge between the programming task and the needed API(s). This is feasible because SO discussions are task centric and can complement API documentation with the missing concepts and purposes <ref type="bibr" target="#b38">[39]</ref>. However, the decision on which API(s) to use is often not purely based on the SO discussions, and developers may further check API documentation to confirm the relevance of API(s). Furthermore, in the known unknowns setting, information like API description and code examples is crucial for determining which API(s) to use.</p><p>Inspired by this information seeking process, we propose an automatic approach named BIKER (Bi-Information source based KnowledgE Recommendation) which leverages both SO posts and API documentation to recommend APIs for a programming task. To bridge the knowledge gap, BIKER retrieves the top-k questions from SO that are semantically similar with the query. Since these questions and the query share similar purposes, the APIs mentioned in the questions are also likely to resolve the programming task in the query. In this way, we can greatly narrow down the search space of candidate APIs. To rank the relevance of a candidate API to the query, we consider the query's similarity with both the SO posts in which the candidate API is mentioned and the candidate API's official description. In this way, we can balance the API information from both the API designer and user perspectives. To bridge the lexical gap between semantically similar texts that are expressed by different words, we follow Ye et al. <ref type="bibr" target="#b48">[49]</ref> to use word embedding techniques to calculate the similarity score. In addition to recommending APIs, BIKER also summarizes supplementary information like official API description and code snippets in SO posts to help developers better understand why these APIs are recommended so that they can select the right API(s) more easily.</p><p>To evaluate BIKER, we manually selected 413 questions from SO that are seeking APIs to resolve programming tasks and labelled the ground-truth APIs for these questions based on their accepted answers. For class-level recommendation, we enrich our dataset with the dataset published by RACK <ref type="bibr" target="#b33">[34]</ref> which contains 150 questions and corresponding class-level APIs. Note that RACK only supports class-level recommendation. For class-level recommendation, BIKER achieves a mean reciprocal rank (MRR) and mean average precision (MAP) of 0.692 and 0.659 respectively, and this outperforms Ye et al.'s approach and the two state-of-the-art API recommendation approaches RACK <ref type="bibr" target="#b33">[34]</ref> and DeepAPI <ref type="bibr" target="#b20">[21]</ref> by at least 42% in MRR and 57% in MAP. For method-level recommendation, BIKER achieves an MRR and MAP of 0.573 and 0.521, and this outperforms Ye et al. 's approach and DeepAPI <ref type="bibr" target="#b20">[21]</ref> by 205% in MRR and 241% in MAP. Our evaluation also confirms the importance of SO information in API recommendation and the usefulness of incorporating SO information and API documentation. Finally, we conduct a user study in which 28 Java developers are divided into four groups using different tools to answer 10 API-method-related questions randomly sampled from the 413 questions. On average, compared with the other three groups (i.e., web search only, using DeepAPI and using BIKER with only API recommendation but no supplementary information), the group using the full version of BIKER can improve answer correctness by at least 11% and save answering time by at least 28%.</p><p>The main contributions of this paper are:</p><p>(1) We conduct a survey of developers' API search behavior and expectations, which suggests the necessity of incorporating SO posts and API documentation for effective API search. (2) Inspired by our survey results, we propose BIKER to recommend API methods by exploiting SO posts to bridge task-API knowledge gap, and by incorporating the information from both SO posts and API documentation for measuring API relevance and assisting developers in selecting recommended APIs. (3) Both our quantitative evaluation and user study show that BIKER can help developers find the correct APIs for Java programming tasks more efficiently and accurately, compared with state-of-the-art baselines. (4) We release the source code of BIKER and the dataset of our evaluation and user study<ref type="foot" target="#foot_0">1</ref> to help other researchers replicate and extend our study.</p><p>Paper Organization. The remainder of the paper is organized as follows. We present the survey to investigate how developers search for APIs and their expectations of an effective API recommendation tool in Section 2. We describe the technical details of BIKER in Section 3. We present our experimental setup and results in Section 4 and Section 5, respectively. We present the results of our user study in Section 6. We discuss threats to validity in Section 7. We present related work in Section 8. We conclude the paper and mention future work in Section 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DEVELOPERS' EXPECTATIONS ON API RECOMMENDATION</head><p>To gain insights into how developers search for APIs to resolve programming tasks and the developers' expectations on automatic API recommendation techniques, we conducted a survey with 130 Java developers from two IT companies (both are outsourcing companies with more than 2,000 employees) and received 47 replies.</p><p>Our survey includes the following questions: The survey responses suggest that apart from API documentation, SO is also an important resource for developers to search APIs. By interviewing with several respondents, we find that a typical API search process they adopt is to first browse several relevant SO questions and pick out the APIs that seem to be useful in the discussions. The interviewed developers suggest that SO discussions are usually centered on some programming tasks, which makes it easier for them to narrow down some candidate APIs that may support their tasks. They also suggest that if they still cannot decide which API is the right choice, they will further check the APIs' documentation or code examples.</p><p>This API search process inspires us to design BIKER that exploits SO posts to bridge task-API knowledge gap and incorporates the information from both SO questions and API documentation to measure the relevance of an API to the programming task description. As suggested by developers, BIKER also summarizes supplementary API information for each recommended API to help developers better understand what an API can do and select the right API(s) for their tasks more easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPROACH</head><p>Fig. <ref type="figure">1</ref> shows the overall framework of BIKER, which consists of three main components: building domain-specific language models for similarity calculation (Section 3.1), searching for relevant APIs based on SO posts and API documentation (Section 3.2), and summarizing API supplementary information (Section 3.3). Since BIKER recommends APIs at method level by default, we also introduce how to adapt BIKER for class-level recommendation in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Building Language Models for Similarity Calculation</head><p>To measure a query's similarity to a SO post or an API description, we need to build domain-specific language models. We first build a text corpus by extracting the text content from SO posts in HTML pages. We remove long code snippets enclosed in HTML tag ⟨pre⟩, but keep short code fragments in ⟨code⟩ in natural language sentences. We use NLTK package <ref type="bibr" target="#b9">[10]</ref> to tokenize the sentence. Note that if one is interested in a particular language or library's APIs, he may use a subset of SO post tagged with that library (e.g., Java). Using the SO corpus, we train a word embedding model using word2vec <ref type="bibr" target="#b26">[27]</ref>. Word embedding model provides the basic model to measure word similarity. Then we build the word IDF (inverse document frequency) vocabulary. A word's IDF represents the inverse of the number of SO posts that contain the word. We reduce each word in the corpus to its root form (aka. stemming) using the NLTK package <ref type="bibr" target="#b9">[10]</ref>. Thus, the words with the same root form will have the same IDF value. The more posts in which a word appears, the less likely the word carries important semantic information, and thus its IDF is lower. We use IDF as a weight on top of word embedding similarity. Finally, the words in API documentation would directly use this word embedding model and IDF vocabulary, since the text volume of SO posts is much larger than API documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Searching for Relevant APIs</head><p>Our API search component has three steps: retrieving similar SO questions to the query, detecting API entities in the SO posts, and calculating the query's similarity with SO posts and API descriptions for ranking the relevance of candidate APIs to the query. </p><formula xml:id="formula_0">sim(T → Q) = w ∈T sim(w, Q) * id f (w) w ∈T id f (w)<label>(1)</label></formula><p>where sim(w, Q) is the maximum value of sim(w, w ′ ) for each word w ′ ∈ Q, and sim(w, w ′ ) is the cosine similarity of the word embedding vectors of w and w</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>′</head><p>. The asymmetric similarity score sim(Q → T ) is computed analogously, by swapping T and Q in Equation <ref type="formula" target="#formula_0">1</ref>. Intuitively, a word with lower IDF value would contribute less to the similarity score. Finally, the similarity score between T and Q is computed as the harmonic mean of the two asymmetric scores:</p><formula xml:id="formula_1">sim(T , Q) = 2 * sim(T → Q) * sim(Q → T ) sim(T → Q) + sim(Q → T )<label>(2)</label></formula><p>The retrieved top-k similar questions will be used to detect candidate APIs for recommendation. In this paper, BIKER only retrieves the top-50 similar questions, since retrieving too many questions may introduce noise to the recommendation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Detecting API Entities.</head><p>After retrieving the top-k similar questions, BIKER uses several heuristic rules to extract API entities from each question's answers. These APIs are considered as candidate APIs for recommendation. If an API is not mentioned in any of the top-k similar questions, it is less likely to be the right API for the query. Thus, we do not consider all APIs of a language or library for recommendation. In this way, a lot of irrelevant APIs would be filtered out.</p><p>To detect API entities, we first manually checked a large number of API-related questions. We observe that an important API mentioned by developers is often highlighted with the HTML tag ⟨code⟩ or referenced by a hyperlink to the API's corresponding documentation page. Thus, BIKER detects API entities using the following two heuristics:</p><p>• BIKER checks every hyperlink in each answer and uses regular expressions to identify the hyperlink to a library's official API documentation site, for example, https://docs.oracle.com for Java API documentation. Then it uses regular expressions to detect the full name of the corresponding API method from the hyperlink and mark this method as a candidate API. For example, given the hyperlink https://docs.oracle.com/javase/8/docs/api/java/lang/C lass.html#forName(java.lang.String), it extracts the API method java.lang.Class.forName.</p><p>• BIKER first builds a dictionary that stores the names of all APIs of a language or library crawled from the language or library's official documentation site. Then it checks the plain text contained in every HTML tag ⟨code⟩ in each answer. If the text fully matches any API method in the dictionary, it is marked as a candidate API. Note that in most cases, developers would omit the package name of an API. For example, java.lang.Class.forName is usually written as Class.forName. Thus, our dictionary only stores the partially-qualified name of an API for string matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.3</head><p>Calculating Similarity Score for Ranking Candidate APIs. After obtaining a list of candidate APIs from the top-k similar questions, BIKER calculates the similarity score between each candidate API and the query. Given an API and a query Q, their similarity score is a combination of two scores, namely SimSO and SimDoc. Specifically, SimSO measures the similarity between the query and the question title T of a top-k similar question in which the API is mentioned, and SimDoc measures the similarity between the query and the API's description in official API documentation.</p><p>Suppose that among all the top-k similar questions, the API is mentioned in n questions, then SimSO is computed as:</p><formula xml:id="formula_2">SimSO(API, Q) = min(1, n i=1 sim(T i , Q) n × log 2 n)<label>(3)</label></formula><p>where sim(T i , Q) represents the similarity score between the query and the title of the i-th question that mentions the API, and sim(T i , Q) is calculated based on Equation <ref type="formula" target="#formula_1">2</ref>. SimSO considers two aspects. First, the score should be related to the similarity between each question and the query. Thus, it calculates the average of the similarity score between each question's title and the query. Second, if the API is mentioned in multiple questions, it is more likely to be the right API for the query. Thus, the score is further boosted based on the number of questions. We add a logarithm transformation log 2 n to control the scale of boosting. For example, the score would be boosted by 20% if the API is detected in 4 questions. We also restrict that the boosted score should not exceed 1.</p><p>The SimDoc is also calculated based on Equation <ref type="formula" target="#formula_1">2</ref>given the query Q and the API description D. Finally, the similarity score between the query and the API is the harmonic mean of the corresponding SimSO and SimDoc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Summarizing API Supplementary Information</head><p>After obtaining the ranked list of candidate APIs, BIKER summarizes supplementary information for each API in the list. We do this because our survey responses and interviews with developers suggest that developers usually need to check more information about API description and API usage examples to decide which API should be chosen for their tasks. Thus, the supplementary information summarized by BIKER considers three aspects, as listed below:</p><p>• Official API description: It presents the API designer's official description of an API so that API users can quickly check the API's functionality. • Title of similar questions: Based on the top-k similar questions, it extracts the title of all the questions whose answers mention the API. Then it ranks these questions by their titles' similarity scores with the query in descending order and present these questions titles (with hyperlinks to the corresponding webpage). To reduce information overloading, it only presents the top-3 questions. Thus, developers can compare question titles with their tasks. • Code Snippets: Based on the top-k similar questions, it checks each question's answers and extracts the code snippets containing the API. Specifically, given an API (e.g., Math.round), a code snippet is extracted if it satisfies both the following conditions:</p><p>1) The number of lines of code is no more than five; 2) The API's class name (i.e., Math) and method name (i.e., round) are both contained in the code snippet. The extracted code snippets are ranked by their corresponding questions' similarity scores with the query in descending order. To reduce information overloading, it presents only the top-3 code snippets. Thus, developers can check these code snippets to understand how to use the API.</p><p>To better illustrate the outcome of this summarization step, Table 1 presents an example of the summary results for the top-1 recommended API "java.lang.Runtime.exec", given the query "run linux commands in java code".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Adapting BIKER for Class-Level Recommendation</head><p>By default, BIKER recommends APIs at method-level. However, it can be easily adapted to support class-level recommendation. First, we need to revise the heuristic rules for detecting API entities. Specifically, we change the regular expressions so that it only extracts the API's class name (with full path of its package) from the hyperlink to an API documentation page. We also change the dictionary to store all APIs' class names for string matching. Second, we need to change the way of calculating SimDoc in the step of similarity score calculation. Although an API class has its own description like an API method, we do not use it since we observe that the description of an API class is rather long in most cases and it usually does not contain much useful information for specific task requirements. Thus, BIKER calculates the similarity score between the query and the description of each method in the class, and chooses the maximum score as the result of SimDoc for this API class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head><p>In this section, we describe the experimental setup that we follow to evaluate BIKER. The experimental environment is a laptop equipped with Intel(R) Core(TM) i7-6700HQ CPU and 16GB RAM, running Ubuntu 16.04 LTS (64-bit).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Collection and Tool Implementation</head><p>4.1.1 SO Text Corpus. We downloaded the official data dump <ref type="bibr" target="#b1">[2]</ref> of SO (published in: Dec 9th, 2017). As our current tool focuses on Java API, we extracted 1,347,908 questions that are tagged with "java". Based on these questions and their answers, we built a text corpus using the plain text in each post to train the word embedding model and build the IDF vocabulary. We used Gensim <ref type="bibr" target="#b34">[35]</ref> (a python package which implements word2vec <ref type="bibr" target="#b26">[27]</ref>) to train the word embedding model. 4.1.2 SO Question Base. To create the knowledge base of APIrelated questions for similar questions retrieval, we selected only the questions satisfying the following criteria: 1) the question should have positive score; and 2) at least 1 answer to the question contains API entities and the answer's score should be positive. Note that the API entities mentioned in a post were automatically detected by the heuristics described in Section 3.2.2. In this way, we collected 125,847 questions as the knowledge base of API-related SO questions. 4.1.3 Experimental Queries and Ground-Truth APIs. To create experimental queries for the evaluation of BIKER, we followed Ye et al. <ref type="bibr" target="#b48">[49]</ref> to select a small number of API-related questions satisfying the following criteria: 1) the score of the question itself should be at least 5. Ye et al. set this threshold to 20 but this leaves only 604 candidate questions which is too few; 2) the question's accepted answer should contain API entities and the answer's score should be positive.</p><p>In this way, we collected 3,395 questions in total. Among these questions, we randomly selected 1,000 questions. We manually checked each selected question's title to remove the questions that do not aim to search APIs for programming tasks. We examine only the question titles because we assume that developers would use BIKER like a search engine, and thus BIKER is not likely to receive a query with too many words. The first author and another PhD student independently labelled the questions to be removed. Typical examples of questions being removed are shown below:</p><p>• The question seeks for comparison of multiple APIs (e.g., Difference between HashSet and HashMap?). • The question seeks for the theories or algorithms behind an API (e.g., why HashMap Values are not cast in List?) • The question's title contains the word like 'this', 'that' or 'it', which makes its purpose unclear (e.g., how to parse this string in java?). • The question describes an error or a bug (e.g., IP Address not obtained in java).</p><p>We use Fleiss Kappa <ref type="bibr" target="#b17">[18]</ref> to measure the agreement between the two labelers. The Kappa value is 0.85, which indicates almost perfect agreement. After completing the manual labeling process, the two labelers and another post-doc discussed together their disagreements to reach a common decision. In this way, we collected 469 questions for further inspection.</p><p>By default, for each question, all the API entities in the accepted answer are considered as relevant APIs to resolve the question. However, some of the API entities may not be truly helpful and some truly helpful APIs may not be detected by our heuristic rules. Thus, the first author and the same PhD student manually checked each question's title, body and its accepted answer to fix this issue. The overall kappa value is 0.78, which indicates a substantial agreement, and the two labelers also discussed their disagreements with the same postdoc to reach a common decision.</p><p>Specifically, a small number of questions were removed since they cannot be easily resolved by Java APIs. For example, in the question "How can I set the System Time in Java?", the accepted answer clearly stated that Java does not have an API to do this. For most questions, we mainly relied on each question's accepted answer to decide the ground truth APIs. However, since both the two labelers have at least 3 years of Java development experience, if the question is asking a common programming task, we also checked the other answers to add other APIs that are also helpful but not mentioned in the accepted answer. For example, for the question "How to round a number to n decimal places in Java", the accepted answer only mentioned DecimalFormat.setRoundingMode, but the other two APIs (i.e., Math.round and BigDecimal.setScale) mentioned in other answers are also helpful.</p><p>After this manual labeling process, we got 413 questions along with their ground truth APIs as the testing dataset for the evaluation of BIKER. We use the title of these 413 questions as the query for API search. Note that these 413 questions and their duplicate questions were excluded from the SO question base. 4.1.4 Java API Dictionary and API Description. We downloaded the Java SE 8 API documentation <ref type="bibr" target="#b0">[1]</ref> and parsed the html file of each API class to extract all API methods, along with their descriptions. For simplicity, Java interfaces were also treated as Java classes. In total, we extracted 4,216 classes and 31,736 methods and built a Java API dictionary with the name of these API classes and methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Approaches</head><p>We compare the performance of BIKER with two baseline methods, as listed below:</p><p>Baseline 1 (RACK): Rahman et al. <ref type="bibr" target="#b33">[34]</ref> proposed RACK, which constructs a keyword-API mapping database where the keywords are extracted from SO questions and the mapped APIs are collected from corresponding accepted answers. Based on this database, RACK recommends a ranked list of API classes for a given natural language query. Note that we only compare BIKER with RACK at class-level, since RACK does not support recommendation at method-level. Although RACK also leverages SO to bridge the knowledge gap, it does not consider API documentation and its technique is different from BIKER.</p><p>Baseline 2 (DeepAPI): Gu et al. <ref type="bibr" target="#b20">[21]</ref> proposed DeepAPI, which adapts a Recurrent Neural Network (RNN) Encoder-Decoder model. DeepAPI encodes a word sequence (user query) into a fixed-length context vector, and generates an API-method sequence based on the context vector. For example, given the query "open a url", its first recommended result is "URL.new→URL.openConnection". Deep-API's technique is different from BIKER and their knowledge base is a large corpus of annotated API sequences extracted from code repositories.</p><p>Note that we do not choose Ye et al.'s approach <ref type="bibr" target="#b48">[49]</ref> as our baseline, since it can be considered as part of BIKER. If BIKER uses only Java API documentation, then BIKER is reduced to be the same as Ye et al.'s approach. We also have a research question (RQ2 in Section 5.2) to discuss the effectiveness of BIKER when using Java API documentation only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics</head><p>We evaluate BIKER and other baselines using MRR and MAP, which are classical evaluation metrics for information retrieval <ref type="bibr" target="#b24">[25]</ref>. MRR measures how far we need to check in the recommended list to find the first correct answer, while MAP considers the ranks of all correct answers. MRR and MAP are also widely used in previous software engineering studies <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b49">50]</ref>. In addition, we run the Wilcoxon signed-rank test <ref type="bibr" target="#b40">[41]</ref> with Bonferroni correction <ref type="bibr" target="#b5">[6]</ref> to check if the differences between the performance of BIKER and the baselines are statistically significant. We consider that one approach performs significantly better than the other one at the confidence level of 95% if the corresponding Wilcoxon signed-rank test result (i.e., p-value) is less than 0.05. We also use the Cliff's delta (δ ) <ref type="bibr" target="#b14">[15]</ref> to quantify the amount of difference between two approaches. The amount of difference is considered negligible (| δ |&lt; 0.147), small (0.147 ≤| δ |&lt; 0.33), moderate (0.33 ≤| δ |&lt; 0.474), or large (| δ |≥ 0.474), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">RQ1: How effective is BIKER? How much</head><p>improvement can it achieve over the baseline methods?</p><p>Motivation. BIKER aims to automatically recommend appropriate APIs for programming tasks described in natural language queries. Thus, for the approach to be useful, we need to see how accurate it is in API recommendation and how it compares with existing API recommendation methods.</p><p>Approach. To answer this research question, we compare BIKER with the two baselines (i.e., RACK and DeepAPI) using our testing dataset including 413 queries and ground-truth APIs. Since RACK's authors have published an executable tool <ref type="bibr" target="#b3">[4]</ref> for replication, we directly use this tool to compare with BIKER. For DeepAPI, the authors have deployed an online demo tool <ref type="bibr" target="#b2">[3]</ref>, which receives a user query and presents the recommendation results on the webpage. Thus, to compare with DeepAPI, we wrote a web-crawler to automatically send all queries in the testing dataset one by one and retrieve the recommendation results through HTTP requests. We also carefully checked the JavaScript code behind the webpage to make sure that we did the same text preprocessing for each query. Since DeepAPI recommends API sequence, we consider an API sequence is correct if any one of the APIs in the sequence is the ground truth API. This makes the fair comparison with DeepAPI. Finally, RACK's authors also published their testing dataset, which  contains 150 code search queries randomly chosen from several Java tutorial sites. Thus, we also evaluate all approaches using this dataset, which only supports class-level evaluation.</p><p>Results. Table <ref type="table" target="#tab_2">2</ref> presents the performance of BIKER and the two baselines for class-level recommendation. The results show that BIKER significantly outperforms RACK and DeepAPI in terms of MRR and MAP for both datasets, with an improvement of at least 42% in MRR and at least 57% in MAP. We also note that the MRR and MAP achieved by BIKER for RACK's dataset are relatively lower than those achieved for our dataset. By manually checking RACK's dataset, we find that about 19% of its questions include ground-truth APIs from third-party packages (e.g., MongoDB, Apache Commons, etc.) or Java EE, which is beyond the knowledge based of our current tool (i.e., we only consider APIs from Java SE). Except for the MRR and MAP comparison with RACK on our dataset and for the MAP comparison with DeepAPI on our dataset, the amount of difference between the compared methods for other comparisons is either small or negligible. Table <ref type="table" target="#tab_3">3</ref> presents the performance of BIKER and DeepAPI for method-level recommendation using our dataset. RACK and RACK's dataset are not used since RACK only supports class-level recommendation. The MRR and MAP achieved by BIKER is 0.573 and 0.521, respectively, which significantly outperforms DeepAPI by 205% in MRR and 241% in MAP. The amount of difference between the two approaches are large for both MRR and MAP.</p><p>To sum up, BIKER significantly outperforms the two state-ofthe-art baseline methods for both class-and method-level API recommendation. The advantage of BIKER is more evident for methodlevel API recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">RQ2: How effective is BIKER when using the two different information sources individually?</head><p>Motivation. BIKER leverages both SO posts and Java API documentation to calculate the similarity score between an API and the query. However, BIKER can still work if we only use one of the two information sources individually. Thus, we would like to investigate whether the combination of the two information sources results in better or poorer performance. Approach.</p><p>To answer this research question, we evaluate the performance of BIKER when using either SO posts or Java API documentation for calculating the query-API similarity score, and compare that performance with the performance of BIKER using both information sources. When using only SO, the candidate APIs are extracted from top-k similar questions, and the similarity score of each candidate API with the query is calculated based on only SO questions (i.e., SimSO). When using only Java API documentation, the list of candidate APIs is the list of all API methods (or classes) in Java API documentation, and the similarity score of each candidate API with the query is calculated based on Java API documentation (i.e., SimDoc). Note that the only-Java-API-documentation setting is essentially Ye et al. 's approach <ref type="bibr" target="#b48">[49]</ref>.</p><p>Results. Table <ref type="table" target="#tab_4">4</ref> presents the performance of BIKER when using each information source individually. In general, when combining both information sources together, BIKER performs better than using each information source individually. Comparing the improvement ratio over SO or Java documentation, we can see the importance of SO information in BIKER. Using only SO information, the performance is only 24% worse in MRR and 25% worse in MAP than using both information sources for class-level recommendation, and only 9% worse in both MRR and MAP for method-level recommendation. However, using only Java documentation, the performance becomes significantly worse than using two information sources. But using Java documentation as an additional information source can further improve the recommendation performance than using only SO information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">RQ3: How efficient is BIKER for practical use?</head><p>Motivation. During the model building process, BIKER needs to train word embedding model and build IDF vocabulary using the corpus extracted from more than one million SO questions. This would require substantial computational time, especially for the word embedding model. Another time-consuming process is to transform the title of all the 125,847 questions in question knowledge base and the description of all the 31,736 API methods into matrix representation based on each word's embedding vector and IDF value, so that we can compute the similarity score between the query and the documents efficiently. During the recommending process, given a query, BIKER needs to calculate the similarity between this query and each question in the question base, which could also be time-consuming. If BIKER cannot run with a reasonable runtime performance, developers may not be willing to use it in practice.</p><p>Approach. To answer this research question, we record model training time and query processing time of BIKER and the two baselines using our testing dataset for class-level API recommendation. The time cost for BIKER and DeepAPI do not change under method-level recommendation. Results. Table <ref type="table" target="#tab_5">5</ref> presents the model training time and the average query processing time of BIKER and the two baseline methods.</p><p>As reported by DeepAPI's authors <ref type="bibr" target="#b20">[21]</ref>, their approach takes 240 hours of model training, since their approach is based on RNN (i.e., a deep neural network), which is computationally expensive during training <ref type="bibr" target="#b19">[20]</ref>. The training time cost of RACK is unknown since it is not reported by the authors and it is not easy to replicate the training process without RACK's source code. BIKER takes 36 minutes to train, which is also relatively slow, and almost the whole time cost is due to training word embedding model. The word embedding model only needs to be trained once and it does not need to be updated frequently since the text corpus is already very large (i.e., extracted from 1.3 million questions). If we use pretrained word embedding model, we just need about 10 seconds to transform text into matrix representation. For the average query processing time, RACK is slowest (12.8 seconds) to process each query, while DeepAPI is the fastest (2.6 seconds). BIKER (2.8 seconds) is slightly slower than DeepAPI. The major computation cost of BIKER for query processing is due to the step of similar questions retrieval, where we need to compare the query with the titles of about 120 thousand questions. To improve the time efficiency, we can reduce the size of questions to be compared with some heuristic rules (e.g., only comparing with the question whose score is larger than k) or accelerate similarity score computation by GPU <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USER STUDY</head><p>In this section, we conduct a user study to investigate how developers interact with BIKER and whether it can help developers find correct APIs more efficiently and accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Study Design</head><p>6.1.1 Experimental Queries and Ground-Truth APIs. To conduct our user study, we randomly selected 10 questions from our testing dataset, as shown in Table <ref type="table">6</ref>. The last column shows the groundtruth answers, which refer to the APIs extracted from each question's accepted answer. Three questions (i.e., Q1, Q3 and Q10) require multiple APIs (i.e., an API sequence) to complete the programming task. 6.1.2 Participants. We recruited 28 participants from both university and IT companies. 16 of them (2 postdocs, 9 PhDs and 5 graduate students) are from the first author's university, and 12 of them are from two IT companies. All of them have Java developing experience in either commercial or open source projects, and the years of their developing experience vary from 1 year to 5 years, with an average of 2.9 years. 6.1.3 Experimental Groups. Next, we divided the participants uniformly based on years of development experience into four groups, with the following settings: 1) WSO: Find appropriate API methods by searching and browsing resources on the Internet (i.e., Web Search Only); 2) DeepAPI: Use DeepAPI's online tool; 3) BIKER-Simple: Use a simplified version of BIKER, which only recommends the name of APIs; 4) BIKER-Full: Use the fully-featured version of BIKER.</p><p>RACK is not evaluated since it does not support method-level recommendation and it runs much slower than DeepAPI and BIKER. The DeepAPI, BIKER-Simple and BIKER-Full groups are also allowed to search any resources on the Internet if the participants deem the information provided by the tool is not enough to answer the questions. Since the 10 questions were extracted from SO, to be fair across different techniques, we instructed the participants to ignore the 10 questions on SO when searching the Web. 6.1.4 Procedure. We deployed a simple website with 10 pages, each corresponding to one question. When a participant clicked the webpage of a question, a timer in the background would collect how much time he/she spent until submitting the answer. Participants were encouraged to complete each question without interruption and they would explicitly inform us if there was interruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results Analysis</head><p>We analyze two metrics with the user study results, as shown below:</p><p>• Correctness: This metric evaluates whether a participant can find the correct APIs. For the question that only needs one API method, correctness is 1 if the participant submitted the correct API, otherwise 0. For the question that needs an API sequence, correctness is the proportion of the correct APIs submitted by the participant among all APIs in the correct API sequence. Some questions can also be resolved using other APIs different from the ground-truth APIs. For example, BigDecimal.setScale or Math.round are also the correct answers for Q10. Thus, we manually check each participants' answers to make sure the correctness is also 1 if they submitted the correct but not groundtruth APIs. • Completion time: This metric evaluates how fast a participant can answer the question. One problem is that in some cases, the recorded completion time may not reflect the true effort needed to answer the question. For example, for the DeepAPI group, while 6 participants needed at least 30 seconds to answer Q9, there is 1 participant who only spent 12 seconds. By consulting with this participant, we found that he is a senior Java developer and he can directly answer this question without any tool's support. On the other hand, we recorded more than 20 minutes completion time for a single question for a few participants. They explained that they were interrupted by urgent tasks or bad network condition.</p><p>To avoid the effect of outliers, for each question, we report the median value of the time spent for each group. Table <ref type="table">7</ref> presents the results of user study. In general, participants in BIKER-Full group performed as well as or better than the other three groups for every question in terms of correctness, and they were the fastest to solve six out of the ten questions. On average, the full version of BIKER can improve correctness by at least 11% and save the time cost by at least 28%. We also note that the correctness of different groups vary a lot for several questions (e.g., Q3 and Q7). By manually checking the participants' answers, we have the following two findings:</p><p>First, although BIKER does not recommend API sequences, participants can find the necessary sequence by themselves with the help of code snippets provided by BIKER. For example, in Q3, all participants in BIKER-Simple group only chose the first recommended API "BigDecimal.stripTrailingZeroes" as their answers, possibly because the API's name seems to be the right choice and the key phrase in its documentation (i.e., with any trailing zeros removed) also seems to meet the task requirement. However, as shown in SO post, this API would transform a number like 600.0 into scientific notation. To fix this issue, developers need to call BigDecimal.toPlainString after stripping the trailing zeros. In BIKER-Full group, six out of the seven participants chose both the two APIs as their answers, since the code snippets with stripTrailingZeroes has clearly showed that toPlainString should be called before printing. Such phenomenon also appeared in the answers for Q1.</p><p>Second, in some cases, participants can find the correct APIs more easily or with more confidence if they have tool support. For example, both DeepAPI and BIKER recommended Class.isAssignableFrom as the top-1 or top-2 answer for Q7, which may help participants narrow down the search space. On the other hand, three out of the seven participants in WSO group submitted Class.isInstance or instanceof (not an API but Java operator), which are both incorrect. Actually, many developers are confused about the difference <ref type="bibr" target="#b4">[5]</ref> between Class.isInstance and Class.isAssignableFrom. Thus, it is not surprising that these participants submitted Class.isInstance, which is also "relevant" to the question, but cannot directly solve the task.</p><p>To sum up, BIKER can help developers find appropriate APIs more efficiently and accurately. This can be attributed to its capability of effectively narrowing down candidate APIs and providing supplementary information for understanding and selecting recommended APIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Participants' Comments</head><p>We encouraged the participants in BIKER-Full group to write their comments and suggestions for BIKER after the experiment. For the participants in the other three groups, we also showed them the results recommended by the full version of BIKER after they finished their tasks, and invited them to provide comments and feedbacks too. Among all the 28 participants, 13 participants provided some comments and suggestions. Based on these comments, we summarized several major aspects of BIKER that are liked or disliked by participants, as shown below:</p><p>• Positive Opinions -"Given the Javadoc and code snippets, I can easily decide whether this API is useful. I don't need to Google for more information in most cases, this saves me a lot of time. " -"Since the tool recommended 5 APIs, there must be some APIs not helpful to solve the question.</p><p>However, I especially appreciate the fact that some of these unrelated APIs also inspired me a lot. For example, in Q2, it also recommended the API for unmodifiable list and map, which would be useful if the scenario or requirement is broadened. " -"The code snippets is very useful. It gives me more confidence to make the final choice and shows me how to use the API. "</p><p>• Negative Opinions -"Although I can easily judge which API is correct with the information (like Javadoc) provided, sometimes I still don't know how to use it. Yes, your tool can provide code snippets for most APIs, but some APIs are not and sometimes they are just the exact APIs I want to further check! Is this a bug? For example, in Q6, you recommended BufferedReader.readLine as the first result, but no code snippet provided and the javadoc is also too simple... " -"The layout is not ideal. Sometimes it just looks like a mess, especially when every recommended API has multiple code snippets with many lines. " -"Sometimes the API name is already enough for me to judge. Why don't you make additional information folded up and let me to decide read it or not by myself?"</p><p>From these comments, we can see that participants can benefit from the supplementary information provided for each API. However, sometimes BIKER may fail to extract code snippets for some APIs, because we only scanned the top-k similar questions. We could improve this component by building a mapping database which stores the API and its code snippets extracted from more questions. Finally, as pointed out by the participants, we need to carefully design the layout or the way we present the supplementary information to make the useful information more usable, which is an important aspect of user experience to be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">THREATS TO VALIDITY</head><p>Threats to internal validity relates to the errors in the implementation of BIKER and the baseline methods. We have double checked our code to make sure that the questions in testing dataset are not included in the question base. For the baseline methods, we directly used their published tools. Thus, there is little threat to the approach implementation. The degree of participants' carefulness and effort spent in our user study may also affects the validity of our user study results. To reduce this threat, we recruited participants who express interests in our research and made the average years of development experience in each group as uniform as possible. Threats to external validity relates to the quality of our dataset and generalizability of our results. To ensure the quality of our dataset, we had two labelers to label the data and we relied on the accepted answer to label the ground-truth APIs. Although our dataset contains only 413 questions, most of these questions have a large number of view count. Among these 413 questions, about 70% of the questions in our dataset have their view count ranked within top-5% and 45% of the questions are ranked within top-1% among the 1.3 million java-tagged questions on SO. This indicates that if BIKER can solve these questions, it can benefit a large number of developers. We also used the dataset published by RACK to demonstrate the effectiveness of BIKER. Another threat is that BIKER only supports Java API recommendation. But this is an implementation limitation, rather than a methodological threat. It would not be difficult to adapt BIKER to support API recommendation for other programming languages, as long as we can obtain related SO questions and API documentation. Threats to construct validity relates to the suitability of our evaluation measures. We use MRR and MAP, which are classical evaluation measures for information retrieval <ref type="bibr" target="#b24">[25]</ref> and are also widely used in previous studies in software engineering <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b49">50]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RELATED WORK</head><p>API Recommendation: In addition to RACK and DeepAPI, there are other approaches for API recommendation. McMillan et al. <ref type="bibr" target="#b25">[26]</ref> proposed Portfolio to find relevant functions for a code search query from a large archive of C/C++ source code. Chan et al. <ref type="bibr" target="#b12">[13]</ref> further improved Portfolio by employing graph search approach. Raghothaman et al. <ref type="bibr" target="#b32">[33]</ref> proposed SWIM, a tool that learns common API usage patterns from open-source code repositories and synthesize idiomatic code describing the use of these APIs. In general, these methods do not leverage information from Q&amp;A websites like SO or do not incorporate information from SO and API documentation. We do not choose them as baselines since they have been reported as less optimal than RACK or DeepAPI. On the other hand, a number of previous studies (e.g., <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">51]</ref> have proposed different approaches to recommend code snippets for a programming task described in natural language. We did not compare BIKER with these approaches since we focus more on the recommendation of a specific API, which is different from the granularity of code snippet recommendation. Empirical Studies on Developers' Behaviors: In this paper, we conducted a survey to investigate developers' API search behaviors and expectations. A number of previous studies also focused on developers' behaviors and some of their findings are relevant to ours <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>. For example, in a study involving twenty developers, Duala-Ekoko and Robillard <ref type="bibr" target="#b15">[16]</ref> identified different types of questions that are commonly asked by developers when working with unfamiliar APIs and they analyzed the cause of the difficulties when answering questions about the use of APIs. Sadowski et al. <ref type="bibr" target="#b35">[36]</ref> investigated how developers search for code through a case study at Google. They found that developers search for code very frequently and generally seek answers to questions about how to use an API. Brandt et al. <ref type="bibr" target="#b10">[11]</ref> observed that developers mostly leverage online resources for just-in-time learning of new skills, and to clarify or remind themselves of existing knowledge. Our survey serves as a complement to these studies, since we focus on developers' API search behaviors and we reveal the information seeking process when developers perform API search. Mining API Usages: Many studies focused on mining API usages to help developers learn how to use an API. Moreno et al. <ref type="bibr" target="#b27">[28]</ref> proposed MUSE for mining and ranking actual code examples that show how to use a specific method. MUSE combines static slicing with clone detection, and uses heuristics to select and rank the code examples in terms of reusability, understandability, and popularity. Petrosyan et al. <ref type="bibr" target="#b30">[31]</ref> proposed an approach to discover tutorial sections that explain a given API type. Treude et al. <ref type="bibr" target="#b38">[39]</ref> proposed an approach to automatically augment API documentation with usage insights extracted from SO. Jiang et al. <ref type="bibr" target="#b22">[23]</ref> proposed FRAPT, an unsupervised approach for discovering relevant tutorial fragments for APIs. Nguyen et al. <ref type="bibr" target="#b29">[30]</ref> proposed API2VEC which uses word embedding to infer the semantic relations between APIs. Our work is a complement to these studies, since they assume that developers already know the name of an API for further investigation. These approaches could be integrated in BIKER to improve the quality of the supplementary information for the recommended APIs. Mining Developer Forums: Researchers leveraged the rich resources in developer forums to build tools for software engineering. Barua et al. <ref type="bibr" target="#b8">[9]</ref> used topic model to discover main topics discussed in SO, as well as their relationships and trends over time. Treude et al. 's study <ref type="bibr" target="#b37">[38]</ref> on how programmers ask and answer questions on the web found that Q&amp;A websites are particularly effective at code reviews and conceptual questions. Gao et al. <ref type="bibr" target="#b18">[19]</ref> proposed an approach to automatically fix recurring crash bugs by retrieving a list of Q&amp;A pages to generate edit scripts. Wong et al. <ref type="bibr" target="#b41">[42]</ref> proposed an approach to automatically generate code comments by mining comments extracted from Q&amp;A sites. Ponzanelli et al. <ref type="bibr" target="#b31">[32]</ref> proposed Prompter to automatically generate queries based on code context, and retrieve pertinent discussions from SO. Our work also leverages developer discussions in SO, but we focus on recommending APIs for programming tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION AND FUTURE WORK</head><p>In this paper, we propose BIKER to automatically recommend relevant APIs for a programming task described in natural language. Inspired by the information seeking process of developers, we leverage both Stack Overflow posts and API documentation to improve the effectiveness of BIKER, and summarize supplementary information for each recommended API to help developers better understand the API usage and determine their relevance to the query task. The evaluation with both our dataset and RACK's dataset confirms the effectiveness of BIKER. Our user study demonstrates that BIKER can help developers find the appropriate APIs more efficiently and accurately in practice. In the future, we will develop an automatic tool (e.g., a plugin in a web browser or IDE) to enable developers to use BIKER to search APIs for programming tasks. We will further improve the performance of BIKER and the interaction design of our tool as suggested by the participants in user study. Finally, we will extend BIKER to support more programming languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 . 2 . 1 Figure 1 :</head><label>3211</label><figDesc>Figure 1: Overall framework of BIKER is computed as a normalized, IDF-weighted sum of similarities between words in T and all words in Q:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>An example of API summaryQuery: run linux commands in java code API1: java.lang.Runtime.exec JavaDoc: Executes the specified string command in a separate process</figDesc><table><row><cell>Similar Questions</cell></row><row><cell>1. Run cmd commands through java</cell></row><row><cell>2. use cmd commands in java program</cell></row><row><cell>3. Unable to execute Unix command through Java code</cell></row><row><cell>Code Snippets</cell></row><row><cell>/**********code snippet 1 **********/</cell></row><row><cell>Process p = Runtime.getRuntime().exec(command);</cell></row><row><cell>/**********code snippet 2 **********/</cell></row><row><cell>Runtime.exec( -whatever cmd command you need to execute-)</cell></row><row><cell>/**********code snippet 3 **********/</cell></row><row><cell>String command1 = "mv $FileName /bgw/feeds/ibs/incoming/";</cell></row><row><cell>Runtime.getRuntime().exec(command1);</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance of BIKER and the baseline methods for class-level recommendation</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Class-Level Recommendation</cell><cell></cell></row><row><cell>Appraoch</cell><cell cols="2">Our Dataset</cell><cell cols="2">RACK's Dataset</cell></row><row><cell></cell><cell>MRR</cell><cell>MAP</cell><cell>MRR</cell><cell>MAP</cell></row><row><cell>BIKER</cell><cell>0.692</cell><cell>0.659</cell><cell>0.428</cell><cell>0.271</cell></row><row><cell>RACK</cell><cell>0.296</cell><cell>0.266</cell><cell>0.302</cell><cell>0.171</cell></row><row><cell>DeepAPI</cell><cell>0.462</cell><cell>0.420</cell><cell>0.276</cell><cell>0.149</cell></row><row><cell></cell><cell>134%</cell><cell>148%</cell><cell>42%</cell><cell>58%</cell></row><row><cell>Improve. RACK</cell><cell>p&lt;0.001</cell><cell>p&lt;0.001</cell><cell>p&lt;0.001</cell><cell>p&lt;0.001</cell></row><row><cell></cell><cell>| δ |=0.57</cell><cell>| δ |=0.59</cell><cell>| δ |=0.12</cell><cell>| δ |=0.17</cell></row><row><cell></cell><cell>50%</cell><cell>57%</cell><cell>55%</cell><cell>82%</cell></row><row><cell>Improve. DeepAPI</cell><cell>p&lt;0.001</cell><cell>p&lt;0.001</cell><cell>p&lt;0.001</cell><cell>p&lt;0.001</cell></row><row><cell></cell><cell>| δ |=0.33</cell><cell>| δ |=0.35</cell><cell>| δ |=0.28</cell><cell>| δ |=0.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance of BIKER and DeepAPI for methodlevel recommendation</figDesc><table><row><cell>Appraoch</cell><cell cols="2">Method-Level Recommendation (Our Dataset) MRR MAP</cell></row><row><cell>BIKER</cell><cell>0.573</cell><cell>0.521</cell></row><row><cell>DeepAPI</cell><cell>0.188</cell><cell>0.153</cell></row><row><cell>Improve.</cell><cell>205% (p&lt;0.001, | δ |=0.57)</cell><cell>241% (p&lt; 0.001, | δ |=0.59)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance of BIKER for our dataset when using one or both information sources</figDesc><table><row><cell>Info Source</cell><cell cols="2">Class-Level MRR MAP</cell><cell cols="2">Method-Level MRR MAP</cell></row><row><cell>Stack Overflow</cell><cell>0.559</cell><cell>0.529</cell><cell>0.524</cell><cell>0.476</cell></row><row><cell>Java Documentation</cell><cell>0.287</cell><cell>0.265</cell><cell>0.097</cell><cell>0.079</cell></row><row><cell>Both</cell><cell>0.692</cell><cell>0.659</cell><cell>0.573</cell><cell>0.521</cell></row><row><cell>Improve. SO</cell><cell>24%</cell><cell>25%</cell><cell>9%</cell><cell>9%</cell></row><row><cell>Improve. JavaDoc</cell><cell>141%</cell><cell>149%</cell><cell>491%</cell><cell>559%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Time cost for model training and query processing of BIKER and the baseline methods</figDesc><table><row><cell>Approach</cell><cell>Model Training Time</cell><cell>Query Processing Time</cell></row><row><cell>BIKER</cell><cell>36 minutes</cell><cell>2.8s / query</cell></row><row><cell>DeepAPI</cell><cell>240 hours</cell><cell>2.6s / query</cell></row><row><cell>RACK</cell><cell>unknown</cell><cell>12.8s / query</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The replication package can be downloaded at: https://github.com/tkdsheep/BIKER-ASE2018</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENTS We would like to thank Rahman et al. and Gu et al. for sharing their tools and dataset. We also appreciate the reviewers for their insightful comments to help us improve this paper. Xin Xia and Xinyu Wang are the corresponding authors. This research was partially supported by the National Key Research and Development Program of China (2018YFB1003904) and NSFC Program (No. 61602403).</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Completion Time WSO 132s 74s 91s 76s 57s 97s 146s 33s 53s 82s 84s DeepAPI 104s 93s 72s 87s 49s 44s 41s 73s 68s 21s 65s BIKER-Simple 113s 52s 43s 72s 53s 86s 61s 59s 45s 19s 60s BIKER-Full 81s 28s 65s 42s 44s 51s 32s 35s 29s 26s 43s</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.oracle.com/technetwork/java/javase/documentation/jdk8-doc-downloads-2133158.html" />
		<title level="m">SE 8 API documentation downloading site</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://archive.org/download/stackexchange" />
		<title level="m">Stack Overflow Data Dump</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">DeepAPI&apos;s online demo</title>
		<ptr target="http://www.cse.ust.hk/~xguaa/deepapi/tooldemo.html" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">RACK&apos;s dataset and tool demo</title>
		<ptr target="http://homepage.usask.ca/~masud.rahman/rack/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Stack Overflow question: Class.isInstance vs Class</title>
		<ptr target="https://stackoverflow.com/questions/3949260/java-class-isinstance-vs-class-isassignablefrom" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bonferroni and Šidák corrections for multiple comparisons</title>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Abdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Encyclopedia of measurement and statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="103" to="107" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bimodal modelling of source code and natural language</title>
		<author>
			<persName><forename type="first">Miltos</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2123" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inference of development activities from interaction with uninstrumented applications</title>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1313" to="1351" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">What are developers talking about? an analysis of topics and trends in stack overflow</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">W</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="619" to="654" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">NLTK: the natural language toolkit</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2004 on Interactive poster and demonstration sessions</title>
		<meeting>the ACL 2004 on Interactive poster and demonstration sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Two studies of opportunistic programming: interleaving web foraging, learning, and writing code</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Lewenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">R</forename><surname>Klemmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1589" to="1598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">NLP2Code: Code snippet content assist via natural language tasks</title>
		<author>
			<persName><forename type="first">Angus</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><surname>Treude</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Maintenance and Evolution (ICSME)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="628" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Searching connected API subgraph via text phrases</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Wing-Kwan Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering</title>
		<meeting>the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sniff: A search engine for java using free-form queries</title>
		<author>
			<persName><forename type="first">Shaunak</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudeep</forename><surname>Juvekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koushik</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Fundamental Approaches to Software Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="385" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Ordinal methods for behavioral data analysis</title>
		<author>
			<persName><forename type="first">Norman</forename><surname>Cliff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Asking and answering questions about unfamiliar APIs: An exploratory study</title>
		<author>
			<persName><forename type="first">Ekwa</forename><surname>Duala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Ekoko</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">P</forename><surname>Robillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE), 2012 34th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="266" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Understanding the efficiency of GPU algorithms for matrix-matrix multiplication</title>
		<author>
			<persName><forename type="first">Kayvon</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Sugerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware</title>
		<meeting>the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="133" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName><forename type="first">L</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">378</biblScope>
			<date type="published" when="1971">1971. 1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fixing recurring crash bugs via analyzing q&amp;a sites (T)</title>
		<author>
			<persName><forename type="first">Qing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hansheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE), 2015 30th IEEE/ACM International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deep learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2016">2016</date>
			<publisher>MIT press Cambridge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep API learning</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting>the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="631" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive synthesis using free-form queries</title>
		<author>
			<persName><forename type="first">Tihomir</forename><surname>Gvero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kuncak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An unsupervised approach for discovering relevant tutorial fragments for APIs</title>
		<author>
			<persName><forename type="first">He</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingxuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Software Engineering</title>
		<meeting>the 39th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="38" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Combining deep learning with information retrieval to localize buggy files for bug reports (n)</title>
		<author>
			<persName><forename type="first">An</forename><surname>Ngoc Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><forename type="middle">Tuan</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE), 2015 30th IEEE/ACM International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="476" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Prabhakar</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><surname>Schütze</surname></persName>
		</author>
		<title level="m">Introduction to Information Retrieval</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Portfolio: finding relevant functions and their usage</title>
		<author>
			<persName><forename type="first">Collin</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Grechanik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denys</forename><surname>Poshyvanyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Software Engineering</title>
		<meeting>the 33rd International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How can I use this method?</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Bavota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rocco</forename><surname>Oliveto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrian</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="880" to="890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Statistical translation of English texts to API code templates</title>
		<author>
			<persName><forename type="first">Anh</forename><surname>Tuan Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">C</forename><surname>Rigby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanh</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Karanfil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering Companion (ICSE-C)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="331" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploring API embedding for API usages and applications</title>
		<author>
			<persName><forename type="first">Trong</forename><surname>Duc Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><forename type="middle">Tuan</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><surname>Dang Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Discovering information explaining API types using text classification</title>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">P</forename><surname>Gayane Petrosyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renato</forename><forename type="middle">De</forename><surname>Robillard</surname></persName>
		</author>
		<author>
			<persName><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="869" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mining StackOverflow to turn the IDE into a self-confident programming prompter</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Ponzanelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Bavota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rocco</forename><surname>Oliveto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Lanza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Working Conference on Mining Software Repositories</title>
		<meeting>the 11th Working Conference on Mining Software Repositories</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SWIM: Synthesizing What I Mean-Code Search and Idiomatic Snippet Synthesis</title>
		<author>
			<persName><forename type="first">Mukund</forename><surname>Raghothaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youssef</forename><surname>Hamadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="357" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rack: Automatic api recommendation using crowdsourced knowledge</title>
		<author>
			<persName><forename type="first">Chanchal K</forename><surname>Mohammad Masudur Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Analysis, Evolution, and Reengineering (SANER), 2016 IEEE 23rd International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="349" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName><forename type="first">Radim</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">How developers search for code: a case study</title>
		<author>
			<persName><forename type="first">Caitlin</forename><surname>Sadowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">T</forename><surname>Stolee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Elbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2015 10th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="191" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improving bug localization using structured information retrieval</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ripon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarfraz</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dewayne</forename><forename type="middle">E</forename><surname>Khurshid</surname></persName>
		</author>
		<author>
			<persName><surname>Perry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="345" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">How do programmers ask and answer questions on the web?: Nier track</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Treude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ohad</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret-Anne</forename><surname>Storey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE), 2011 33rd International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="804" to="807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Augmenting api documentation with insights from stack overflow</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Treude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">P</forename><surname>Robillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="392" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Locus: Locating bugs from software changes</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shing-Chi</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="262" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Individual comparisons by ranking methods</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Wilcoxon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics bulletin</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="80" to="83" />
			<date type="published" when="1945">1945. 1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Autocomment: Mining question and answer sites for automatic comment generation</title>
		<author>
			<persName><forename type="first">Edmund</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinqiu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="562" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">What do developers search for on the web?</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavneet</forename><surname>Singh Kochhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="3149" to="3185" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Measuring program comprehension: A large-scale field study with professionals</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An effective change recommendation approach for supplementary bug fixes</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="455" to="498" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">AnswerBot: automated generation of answer summary to developersź technical questions</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the 32nd IEEE/ACM International Conference on Automated Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="706" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Domain-specific cross-language relevant question retrieval</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Mining Software Repositories</title>
		<meeting>the 13th International Conference on Mining Software Repositories</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="413" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Combining word embedding with information retrieval to recommend similar bug reports</title>
		<author>
			<persName><forename type="first">Xinli</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianling</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">From word embeddings to document similarities for improved information retrieval in software engineering</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th international conference on software engineering</title>
		<meeting>the 38th international conference on software engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="404" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Automatically recommending peer reviewers in modern code review</title>
		<author>
			<persName><forename type="first">Motahareh</forename><surname>Bahrami Zanjani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huzefa</forename><surname>Kagdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="530" to="543" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Bing developer assistant: improving developer productivity by recommending sample code</title>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anuj</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandrashekhar</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting>the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="956" to="961" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
