<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Dual Decomposition Approach to Feature Correspondence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
							<email>lorenzo@cs.dartmouth.edu</email>
						</author>
						<author>
							<persName><forename type="first">Vladimir</forename><surname>Kolmogorov</surname></persName>
							<email>vladimir.kolmogorov@ist.ac.at..</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Carsten</forename><surname>Rother</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">L</forename><surname>Torresani</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">V</forename><surname>Kolmogorov</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<address>
									<postCode>6211, 03755</postCode>
									<settlement>Dartmouth College, Sudikoff Lab, Hanover</settlement>
									<region>NH</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Science and Technology</orgName>
								<address>
									<addrLine>Am Campus 1</addrLine>
									<postCode>3400</postCode>
									<settlement>Klosterneuburg</settlement>
									<country>IST Austria, Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<addrLine>7 JJ Thomson Avenue</addrLine>
									<postCode>CB3 0FB</postCode>
									<settlement>Cambridge</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Dual Decomposition Approach to Feature Correspondence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">752E7536BAF7EC1507B9613DBD78B816</idno>
					<idno type="DOI">10.1109/TPAMI.2012.105</idno>
					<note type="submission">received 12 Aug. 2011; revised 13 Feb. 2012; accepted 21 Apr. 2012; published online 1 May 2012.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph matching</term>
					<term>feature correspondence</term>
					<term>dual decomposition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a new approach for establishing correspondences between sparse image features related by an unknown nonrigid mapping and corrupted by clutter and occlusion, such as points extracted from images of different instances of the same object category. We formulate this matching task as an energy minimization problem by defining an elaborate objective function of the appearance and the spatial arrangement of the features. Optimization of this energy is an instance of graph matching, which is in general an NP-hard problem. We describe a novel graph matching optimization technique, which we refer to as dual decomposition (DD), and demonstrate on a variety of examples that this method outperforms existing graph matching algorithms. In the majority of our examples, DD is able to find the global minimum within a minute. The ability to globally optimize the objective allows us to accurately learn the parameters of our matching model from training examples. We show on several matching tasks that our learned model yields results superior to those of state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ç 1 INTRODUCTION</head><p>F EATURE correspondence is the task of matching a sparse or dense set of image features across multiple images or volumes. It is one of the fundamental problems of computer vision and is a key ingredient in a wide range of applications, including object recognition, 3D reconstruction, mosaicing, motion segmentation, and image morphing. Several robust algorithms (see, e.g., <ref type="bibr" target="#b1">[3]</ref>, <ref type="bibr" target="#b22">[24]</ref>) exist for registration of images of static scenes and for visual correspondence under rigid motion. These methods typically exploit powerful constraints (e.g., epipolar constraints) to reduce the search space and disambiguate the correspondence problem. However, such constraints do not apply in the case of nonrigid motion or when matching different object instances. A popular approach in these cases is to discard the information about the spatial layout of features and to find correspondences using appearance only. For example, many object recognition methods <ref type="bibr" target="#b13">[15]</ref>, <ref type="bibr" target="#b14">[16]</ref>, <ref type="bibr" target="#b18">[20]</ref>, <ref type="bibr" target="#b38">[40]</ref>, <ref type="bibr" target="#b43">[45]</ref>, <ref type="bibr" target="#b45">[47]</ref>, <ref type="bibr" target="#b47">[49]</ref> represent images as orderless sets of local appearance descriptors known as bags of features. Recent work <ref type="bibr" target="#b9">[11]</ref> has suggested that for many correspondence problems, learned appearance-based models perform similarly or better than state-ofthe-art structural models exploiting information about spatial arrangement of features. This is primarily due to the challenges posed by the optimization and training of structural models, which often require approximate solution of NP-hard problems. In this paper, we contrast this theory and demonstrate that a complex structural model for image matching can be learned and optimized successfully so as to obtain results superior to those achievable with models neglecting the spatial arrangement of features. We cast the visual correspondence problem as an energy minimization task by defining a complex image matching objective depending on 1) feature appearance, 2) geometric compatibility of correspondences, and 3) spatial coherence of matched features. Additionally, we impose a uniqueness constraint allowing at most one match per feature. We introduce a novel algorithm to minimize this function based on the dual decomposition approach (DD) from combinatorial optimization, see, e.g., <ref type="bibr" target="#b4">[6]</ref>, <ref type="bibr" target="#b10">[12]</ref>, <ref type="bibr" target="#b42">[44]</ref>, <ref type="bibr" target="#b34">[36]</ref>, <ref type="bibr" target="#b35">[37]</ref>, <ref type="bibr" target="#b23">[25]</ref>. The DD method works by maximizing a lower bound on the energy function. The value of the lower bound can be used to gauge the distance from the global minimum and to decide when to stop the optimization in the event the global minimum cannot be found. For the majority of our examples DD finds the global minimum in reasonable time, and otherwise provides a solution whose cost is very close to the optimum. In contrast, previously proposed optimization methods such as <ref type="bibr" target="#b12">[14]</ref>, <ref type="bibr" target="#b15">[17]</ref>, <ref type="bibr" target="#b46">[48]</ref> often fail to compute good solutions for our energy function. Our experimental evaluation shows that the model and the algorithm presented in this paper can be applied to a wide range of image matching problems with results matching or exceeding those of existing algorithms <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b2">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Relation to Previous Work</head><p>Models for feature matching. Our approach is loosely related to algorithms that find visual correspondences by matching appearance descriptors under smooth, or piecewise smooth, spatial mappings. For example, Torr <ref type="bibr" target="#b40">[42]</ref> describes a technique for estimating sparse correspondences using RANSAC under the assumption that the images contain a common set of rigidly moving objects. However, this piece-wise rigid motion assumption is not appropriate for deformable objects, such as human faces, or for different instances of an object class, such as different cars, related by highly nonlinear mappings. Other approaches <ref type="bibr" target="#b31">[33]</ref>, <ref type="bibr" target="#b36">[38]</ref> have proposed constraining the correspondence problem by learning or hand-coding explicit models of how an object is allowed to deform using parametric 2D or 3D representations, such as linear eigenshapes or superquadrics. Unlike such approaches, our method does not make a parametric assumption about the transformation relating the input images, and thus can be used in a wider range of applications. Belongie et al. <ref type="bibr" target="#b2">[4]</ref> inject spatial smoothness in the match by means of an iterative technique that alternates between finding correspondences using shape features and computing a regularized transformation aligning the matching features. The shape descriptors are recomputed in each iteration after the warping. Since the objective is changed at each iteration, the convergence properties of this algorithm are not clear. Our approach is most closely related to the work of Berg et al. <ref type="bibr" target="#b3">[5]</ref>, and Leordeanu and Hebert <ref type="bibr" target="#b26">[28]</ref>, who formulate visual correspondence as a graph matching problem by defining an objective including terms based on appearance similarity as well as geometric compatibility between pairs of correspondences. Our model differs from those in <ref type="bibr" target="#b3">[5]</ref> and <ref type="bibr" target="#b26">[28]</ref> in several ways. The methods proposed in <ref type="bibr" target="#b3">[5]</ref> and <ref type="bibr" target="#b26">[28]</ref> handle outliers by removing low-confidence correspondences from the obtained solutions. Instead, we include in our energy an explicit occlusion cost as, for example, previously done in <ref type="bibr" target="#b41">[43]</ref>. Thus our algorithm solves for the outliers as part of the optimization. We add to the objective a spatial coherence term, favoring spatial aggregation of matched features, which reduces the correspondence error on our examples. We also show that geometric penalty functions defined in local neighborhoods provide more accurate correspondences than geometric costs defined over entire images, such as those used in <ref type="bibr" target="#b3">[5]</ref> and <ref type="bibr" target="#b26">[28]</ref>. Finally, we use the method of Liu et al. <ref type="bibr" target="#b29">[31]</ref> to learn the optimal parameter values for the model from examples, thus avoiding the need for manual parameter tuning.</p><p>Graph matching optimization. Graph matching is a challenging optimization problem that received considerable attention in the literature (see <ref type="bibr" target="#b11">[13]</ref> for a comprehensive survey of methods). Proposed techniques include the graduated assignment algorithm of Gold and Rangarajan <ref type="bibr" target="#b17">[19]</ref>, spectral relaxation methods <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr" target="#b12">[14]</ref>, the COMPOSE technique of Duchi et al. <ref type="bibr" target="#b15">[17]</ref>, and the algorithm based on covering trees proposed by Yarkony et al. <ref type="bibr" target="#b46">[48]</ref>. Maciel and Costeira <ref type="bibr" target="#b30">[32]</ref> reduce the problem to concave minimization and apply the exact method in <ref type="bibr" target="#b8">[10]</ref>. Torr <ref type="bibr" target="#b41">[43]</ref> and Schellewald and Schno ¨rr <ref type="bibr" target="#b33">[35]</ref> use semidefinite programming (SDP) relaxation for graph matching. Among these papers, only <ref type="bibr" target="#b30">[32]</ref> and <ref type="bibr" target="#b33">[35]</ref> report obtaining optimal (or near optimal) solutions. The method in <ref type="bibr" target="#b30">[32]</ref> was tested only on a single example with quadratic costs. We conjecture that on practical challenging instances this method will suffer from an exponential explosion. 1 As shown in <ref type="bibr" target="#b12">[14]</ref>, the SDP relaxation approach in <ref type="bibr" target="#b33">[35]</ref> scales quite poorly and is too expensive for problems of reasonable size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ENERGY FUNCTION</head><p>We now describe the energy function of our matching model. Let P 0 and P 00 be the sets of feature points extracted from the two input images. We denote with A P 0 Â P 00 the set of potential assignments between features in the two sets. We will use the terms assignment and correspondence interchangeably to indicate elements of A. We represent a matching configuration between the two point sets as a binary valued vector x x x x 2 f0; 1g A . Each correspondence a 2 A indexes an entry x a in the vector x x x x. A correspondence a is active if x a ¼ 1, and it is inactive otherwise. Fig. <ref type="figure">1</ref> illustrates a small example. We define an energy function Eðx x x xÞ modeling our matching problem assumptions. This will allow us to formulate the matching task as minimization of Eðx x x xÞ. In this paper, we consider matching problems where at most one active correspondence per feature is allowed. This requirement is known as the uniqueness constraint and it is commonly used in correspondence problems. In order to enforce this condition we define the constraint set M:</p><formula xml:id="formula_0">M ¼ x x x x 2 f0; 1g A X a2AðpÞ x a 1 8 p 2 P 8 &lt; : 9 = ; ;<label>ð1Þ</label></formula><p>where P ¼ P 0 [ P 00 is the set of features from both images and AðpÞ is the set of correspondences involving feature p.</p><p>The goal is to find the configuration x x x x 2 M minimizing Eðx x x xÞ. We define our energy as a weighted sum of four energy terms:</p><formula xml:id="formula_1">Eðx x x xÞ ¼ app E app ðx x x xÞ þ occl E occl ðx x x xÞ þ geom E geom ðx x x xÞ þ coh E coh ðx x x xÞ;<label>ð2Þ</label></formula><p>where app , occl , geom , and coh are scalar weights. We describe the energy terms below. Function E app ðx x x xÞ favors correspondences between features having similar appearance. We define this function as a sum of unary terms:</p><formula xml:id="formula_2">E app ðx x x xÞ ¼ X a2A app a x a :<label>ð3Þ</label></formula><p>For an assignment a ¼ ðp 0 ; p 00 Þ 2 A, app a is the distance between appearance descriptors (such as Shape Context <ref type="bibr" target="#b2">[4]</ref>) computed at points p 0 and p 00 in the respective images. We have used different appearance features depending on the task at hand (see Section 5).</p><p>Fig. <ref type="figure">1</ref>. An example of matching two feature point sets P 0 and P 00 , where jP 0 j ¼ 4 and jP 00 j ¼ 5. Apart from feature p 00 2 , all other features have exactly one match. This means jAj ¼ 20 with 4 active and 16 inactive correspondences. For instance, it is x ðp 0 1. The method in <ref type="bibr" target="#b30">[32]</ref> first selects a linear function E À which is an underestimator on the original objective function E, i.e., E À ðx x x xÞ Eðx x x xÞ for all feasible solutions x x x x. It then visits all feasible solutions x x x x with E À ðx x x xÞ Eðx x x x Ã Þ where Eðx x x x Ã Þ is the cost of the optimal solution. For each solution a linear program is solved.</p><p>The term E occl ðx x x xÞ imposes a penalty for unmatched features. We define E occl ðx x x xÞ to be the fraction of unmatched features in the smallest of the two feature sets. We can write this function as</p><formula xml:id="formula_3">E occl ðx x x xÞ ¼ 1 À 1 minf P 0 j j; P 00 j jg X a2A x a<label>ð4Þ</label></formula><p>by noting that P a2A x a is equal to the number of distinct matched features in P 0 and P 00 , 8x x x x 2 M. This result derives trivially from the uniqueness constraint.</p><p>The term E geom ðx x x xÞ is a measure of geometric compatibility between active correspondences. This term is similar to the distortion costs proposed in <ref type="bibr" target="#b3">[5]</ref> and <ref type="bibr" target="#b26">[28]</ref>. Note, however, that the energy terms used in these previous approaches include distortion costs for all pairs of matched features, which results in energy functions penalizing any deviation from a global rigid transformation. Instead, our function E geom ðx x x xÞ measures the geometric compatibility of correspondences only for neighboring features. We demonstrate that this model permits more flexible mappings between the two sets of features and yields more accurate correspondences. We use a "neighborhood system" N to specify the pairs of correspondences involved in our measure of geometric compatibility. N consists of all correspondence pairs defined over neighboring features N ¼ fhðp 0 ; p 00 Þ; ðq 0 ; q 00 Þi 2 AÂA j p 0 2 N q 0 _ q 0 2 N p 0 _ p 00 2 N q 00 _ q 00 2 N p 00 g; ð5Þ</p><p>where N p indicates the set of K nearest neighbors of p (computed in the set of features p) and K is a positive integer value controlling the size of the neighborhood, which we call geometric neighborhood size. In practice, we set K in the range of 2 to 6. E geom ðx x x xÞ is computed over pairs of active correspondences in the set N:</p><formula xml:id="formula_4">E geom ðx x x xÞ ¼ X ða;bÞ2N geom ab x a x b ;<label>ð6Þ</label></formula><formula xml:id="formula_5">where geom ab ¼ À e 2 a;b = 2 l À 1 Á þ ð1 À Þ À e 2 a;b = 2 À 1 Á ;<label>ð7Þ</label></formula><p>ðp 0 ;p 00 Þ;ðq 0 ;q 00 Þ ¼ kp 0 À q 0 k À kp 00 À q 00 k j j kp 0 À q 0 k þ kp 00 À q 00 k ; ð8Þ ðp 0 ;p 00 Þ;ðq 0 ;q 00 Þ ¼ arccos p 0 À q 0 kp 0 À q 0 k Á p 00 À q 00 kp 00 À q 00 k :</p><p>Intuitively, geom ðp 0 ;p 00 Þ;ðq 0 ;q 00 Þ computes the geometric agreement between neighboring correspondences ðp 0 ; p 00 Þ, ðq 0 ; q 00 Þ by evaluating how well the segment p 0 q 0 matches the segment p 00 q 00 in terms of both length and direction. The parameter is a scalar value trading off the importance of preserving distances versus preserving directions. Note that while the geometric term encourages the transformation relating the two images to be approximately rigid within small neighborhoods, it still allows the global mapping to be highly nonrigid. In practice, the degree of nonrigidity allowed by the energy can be tuned via two parameters: the geometric neighborhood size (K) and the scalar value ( geom ) defining the relative importance of the geometric term with respect to the other energy terms.</p><p>The term E coh ðx x x xÞ favors the spatial proximity of matched features. It incorporates our prior knowledge that matched features should form spatially coherent regions within each image, corresponding to common objects or parts in the image pair, in analogy to coherence on a pixel grid, used, for example, in image segmentation. We define the cost E coh ðx x x xÞ as the fraction of neighboring feature pairs with different matching status (this can be viewed as an MRF Potts model over feature occlusion). We now show how to write this function directly in terms of the solution x x x x. Let N P be the set of pairs of neighboring features in the two images:</p><formula xml:id="formula_7">N P ¼ fðp; qÞ 2 ðP 0 Â P 0 Þ [ ðP 00 Â P 00 Þ j p 2 N q _ q 2 N p g:<label>ð10Þ</label></formula><p>Then, we can express E coh ðx x x xÞ as a sum of unary and pairwise terms:</p><formula xml:id="formula_8">E coh ðx x x xÞ ¼ 1 jN P j X ðp;qÞ2NP V p;q ðx x x xÞ;<label>ð11Þ</label></formula><p>where</p><formula xml:id="formula_9">V p;q ðx x x xÞ ¼ X a2AðpÞ x a þ X b2AðqÞ x b À 2 X a2AðpÞ;b2AðqÞ x a x b :<label>ð12Þ</label></formula><p>V p;q ðx x x xÞ is equal to 0 if p; q are either both matched or both unmatched; V p;q ðx x x xÞ is equal to 1 otherwise. Feature correspondence as graph matching. The problem defined above can be written as</p><formula xml:id="formula_10">min x x x x2M Eðx x x x j " Þ ¼ X a2A " a x a þ X ða;bÞ2N " ab x a x b ;<label>ð13Þ</label></formula><p>where the constraint set M is given by (1). This problem is often referred to as graph matching in the literature <ref type="bibr" target="#b17">[19]</ref>, <ref type="bibr" target="#b9">[11]</ref>.</p><p>Features P 0 and P 00 are viewed as vertices of the two graphs. The pairwise term " ab x a x b with a ¼ ðp 0 ; p 00 Þ, b ¼ ðq 0 ; q 00 Þ encodes compatibility between edges ðp 0 ; q 0 Þ, ðp 00 ; q 00 Þ of the first and second graph, respectively, as well as spatial coherence of matched features, while unary term " a x a measures similarity of vertices and other effects such as occlusion. We use " to denote the vector obtained by concatenating the unary and pairwise vectors, i.e., " ¼ ð " a ; " ab Þ. We now address the question of how to optimize <ref type="bibr" target="#b11">(13)</ref>. Unfortunately, this problem is NP-hard <ref type="bibr" target="#b17">[19]</ref>. We propose using the problem decomposition approach (or dual decomposition) for graph matching, which we explain next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DECOMPOSITION APPROACH</head><p>On a high level, the idea is to decompose the original problem into several "easier" subproblems for which we can efficiently compute a global minimum (or obtain a good lower bound). Combining the lower bounds for individual subproblems will then provide a lower bound for the original problem. The decomposition and the corresponding lower bound will depend on a parameter vector . Hence, we then try to find a vector that maximizes the bound. This approach is well known in combinatorial optimization, where it is sometimes referred to as "dual decomposition" <ref type="bibr" target="#b4">[6]</ref>. It was applied to quadratic pseudo-Boolean functions (i.e., functions of binary variables with unary and pairwise terms) by Chardaire and Sutter <ref type="bibr" target="#b10">[12]</ref>. Their work is perhaps the closest to the method in this paper. As in <ref type="bibr" target="#b10">[12]</ref>, we use "small" subproblems for which the global minimum can be computed exactly in reasonable time. Our choice of subproblems for graph matching, however, is different from <ref type="bibr" target="#b10">[12]</ref>. In particular, we exploit the structure of the problem, i.e., the structure of the constraint set M and the neighborhood relations between points. In contrast, subproblems proposed in <ref type="bibr" target="#b10">[12]</ref> were for general quadratic pseudo-Boolean functions and the method was tested on randomly generated graphs.</p><p>In computer vision the decomposition approach is probably best known in the context of the MAP-MRF inference task. It was introduced by Wainwright et al. <ref type="bibr" target="#b42">[44]</ref>, who decomposed the problem into a convex combination of trees and proposed message passing techniques for optimizing vector . These techniques do not necessarily find the best lower bound (see <ref type="bibr" target="#b20">[22]</ref> or review article <ref type="bibr" target="#b44">[46]</ref>). Storvik and Dahl <ref type="bibr" target="#b39">[41]</ref>, Schlesinger and Giginyak <ref type="bibr" target="#b34">[36]</ref>, <ref type="bibr" target="#b35">[37]</ref>, and Komodakis et al. <ref type="bibr" target="#b23">[25]</ref> proposed using subgradient techniques <ref type="bibr" target="#b37">[39]</ref>, <ref type="bibr" target="#b4">[6]</ref> for MRF optimization which guarantee to converge to a vector giving the best possible lower bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graph Matching via Problem Decomposition</head><p>We now apply this approach to the graph matching problem given by <ref type="bibr" target="#b11">(13)</ref>. We decompose (13) into subproblems characterized by vectors , 2 I, with positive weights . (These weights are chosen a priori and may affect the speed of convergence of the subgradient method in Section 3.4.) Here, I is a finite set of subproblem indexes. We will require the vector ¼ ð j 2 IÞ to be a -reparameterization of the original parameter vector " (see ( <ref type="formula" target="#formula_10">13</ref>)) <ref type="bibr" target="#b42">[44]</ref>, i.e., X</p><formula xml:id="formula_11">2I ¼ " :<label>ð14Þ</label></formula><p>For each subproblem we will define a lower bound È ð Þ which satisfies</p><formula xml:id="formula_12">È ð Þ min x x x x2M Eðx x x x j Þ:<label>ð15Þ</label></formula><p>It is easy to see that the function</p><formula xml:id="formula_13">Èð Þ ¼ X 2I È ð Þ ð<label>16Þ</label></formula><p>is a lower bound on the original function. Indeed, if x x x x Ã is an optimal solution to (13), then from ( <ref type="formula" target="#formula_11">14</ref>)-( <ref type="formula" target="#formula_13">16</ref>) we get</p><formula xml:id="formula_14">Èð Þ X 2I min x x x x2M Eðx x x x j Þ X 2I Eðx x x x Ã j Þ ¼ Eðx x x x Ã j " Þ:</formula><p>In Section 3.2, we will describe the subproblems that we use. For each subproblem we have to specify the following: 1) constraints on vector , 2) function È ð Þ, 3) an algorithm for computing È ð Þ. In Section 3.4, we will discuss how to maximize the lower bound Èð Þ using the subproblem solutions. Finally, in Section 3.5, we will describe how to obtain solution x x x x 2 M for our original problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Matching Subproblems</head><p>Intuitively, a good decomposition should use subproblems that satisfy the following: 1) A subproblem should include as many variables as possible while ensuring that the computation time stays reasonable; 2) variables in a subproblem should not be independent, i.e., changing one of them should have some influence on other variables.</p><p>Motivated by these design principles, we considered three types of subproblems: a "linear" subproblem, a "maxflow" subproblem, and "local" subproblems. It will turn out that the first two subproblems are not so important in practice compared to the local subproblems, but we still decided to include them since they are rather natural and were used in the literature before (e.g., the first one was used in <ref type="bibr" target="#b15">[17]</ref>).</p><p>Linear subproblem. In our first subproblem, which we denote by the index "L," we require all pairwise terms to be zero: L ab ¼ 0 for ða; bÞ 2 N. In such a case ( <ref type="formula" target="#formula_10">13</ref>) can be solved exactly in polynomial time, for example using the Hungarian algorithm <ref type="bibr" target="#b0">[2]</ref>. (This is often known as the linear assignment problem.)</p><p>Maxflow subproblem. In the second subproblem, which we denote by the index "F ," we do not put any restrictions on the vector F . To get a lower bound, we ignore the uniqueness constraint P a2AðpÞ x a 1 and leave only the discreteness constraint: x a 2 f0; 1g. If the function Eðx x x x j F Þ is submodular (i.e., coefficients F ab are nonpositive for all pairwise terms ða; bÞ 2 N), then we can compute a global minimum using a maxflow algorithm. With arbitrary F ab the problem becomes NP-hard <ref type="bibr" target="#b5">[7]</ref>. We use the roof duality relaxation <ref type="bibr" target="#b19">[21]</ref>, <ref type="bibr" target="#b21">[23]</ref> to get a lower bound È F ð F Þ on the problem. It can be defined as the optimal value of the following linear program:</p><formula xml:id="formula_15">È F ð F Þ ¼ min x x x x X a2A F a x a þ X ða;bÞ2N F ab x ab ;<label>ð17Þ</label></formula><formula xml:id="formula_16">subject to 0 x a 1 8 a 2 A x ab x a ; x ab x b 8 ða; bÞ 2 N x ab ! x a þ x b À 1 8 ða; bÞ 2 N x ab ! 0 8 ða; bÞ 2 N: 8 &gt; &gt; &lt; &gt; &gt; :</formula><p>This relaxation can be solved in polynomial time by computing a maximum flow in a graph with 2ðjAj þ 1Þ nodes and OðjAj þ jNjÞ edges <ref type="bibr" target="#b6">[8]</ref>, <ref type="bibr" target="#b5">[7]</ref>.</p><p>Local subproblems. For our last set of subproblems we use an explicit search to compute the global minimum. We have tested two different techniques: a straightforward exhaustive search and a branch-and-bound search (see Section 3.3 for details). The latter one gives a considerable speed up, as we will document in Section 5.</p><p>For efficiency reasons, we need to make sure that subproblems are sufficiently small. We use the following technique: For each point p 2 P (we remind the reader that P ¼ P 0 [ P 00 ), we choose N d p P to be the set of K d nearest points in the same image where K d is a small constant, e.g., 2 or 3. (The superscript d stands for "decomposition.") We then consider the subproblem that involves only assignments in the set AðN d p Þ ¼ fðp 0 ; p 00 Þ 2 A j p 0 2 N d p _ p 00 2 N d p g and the edges between those assignments. More precisely, we require vector p corresponding to this subproblem to satisfy the following constraints:</p><formula xml:id="formula_17">p a ¼ 0; if a 6 2 AðN d p Þ; p ab ¼ 0; if a 6 2 AðN d p Þ or b 6 2 AðN d p Þ:</formula><p>These constraints imply that we can fix assignments a 2 A À AðN d p Þ to 0 when computing the minimum min x x x x2M Eðx x x x j p Þ. Then we get a graph matching problem where the set of points in one of the images is N d p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Solving Local Subproblems</head><p>As mentioned above, we used two strategies for computing the global minimum for local subproblems. These strategies are described below.</p><p>Exhaustive search. Assume that the set P 0 has a smaller size than P 00 (the other case is symmetric). First, we select an ordering of points in P 0 ; thus, we can assume that P 0 ¼ f1; 2; . . . ; jP 0 jg. We then use a depth-first search to go through all labelings x x x x 2 M. We start with the zero labeling, in which all assignments are passive. At depth d (d ¼ 1; . . . ; jP 0 j) we pick point p ¼ d 2 P 0 and explore jAðpÞj þ 1 possible branches for p. (In each branch we either make one of assignments in AðpÞ active or declare all assignments in AðpÞ to be passive.) If we detect a violation of the uniqueness constraint in P 00 , then we backtrack. For each depth d we maintain the cost of the current labeling. Updating this cost at depth d takes OðdÞ time. (For this we need to store an jAj Â jAj matrix of costs in the memory.) The running time of this approach is OðjP 0 j Á ðmax p2P 0 jAðpÞj þ 1Þ jP 0 j Þ.</p><p>Branch-and-bound search. Our second strategy is quite similar to the one above, but with the following difference: Consider the branch at depth d with the current labeling x x x x 2 M; thus, we made decisions for points f1; . . . ; dg &amp; f1; . . . ; jP 0 jg and x a ¼ 0 for all a ¼ ðp 0 ; p 00 Þ with p 0 2 fd þ 1; . . . ; jP 0 jg. We compute a lower bound on the energy of labelings in this branch via</p><formula xml:id="formula_18">E bound ðx x x x; dÞ ¼ Eðx x x xÞ þ X jP 0 j p¼dþ1 min a2AðpÞ xa 2f0;1g " bound a þ X b2A " ab x b " # x a ;</formula><p>where " bound a ¼ " a þ P jP 0 j p 0 ¼pþ1 minf0; min b2Aðp 0 Þ " ab g. Values " bound a are precomputed in OðjAj 2 Þ time; then computing E bound ðx x x x; dÞ takes Oðjfa ¼ ðp 0 ; p 00 Þ 2 A; p 0 &gt; dgj Á dÞ time. If E bound ðx x x x; dÞ is greater than or equal to the current best known energy, then we backtrack. To prune incorrect branches earlier, it is important to have a good initial labeling. We compute the initial labeling using two passes (forward and backward) of coordinate descent (ICM) applied to the zero labeling x x x x ¼ 0. Note the lower bound described above appears to be rather crude. One potential way of improving it (not addressed in this paper) is to somehow reparameterize vector first. Also, it is not difficult to design better bounds at the expense of additional computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Lower Bound Optimization</head><p>In the previous sections we described constraints on vector and a lower bound Èð Þ consisting of jP j þ 2 subproblems. It can be seen that È is a concave function of . Furthermore, the constraints on yield a convex set that we will denote as . This set is defined by the reparameterization ( <ref type="formula" target="#formula_11">14</ref>) and constraints on individual subproblems 2 given by equalities a ¼ 0, ab ¼ 0</p><p>for certain assignments a and edges ða; bÞ. Let I a ; I ab I be the subsets of subproblem indexes for which elements a , ab , respectively, are not constrained to be 0. Thus, assignment a 2 A is involved in subproblems 2 I a , and edge ða; bÞ 2 N is involved in subproblems 2 I ab . We have</p><formula xml:id="formula_19">¼ ¼ ð j 2 IÞ a ¼ 0 8a 2 A; 2 I À I a ab ¼ 0 8ða; bÞ 2 N; 2 I À I ab X ¼ " 9 &gt; = &gt; ; : 8 &gt; &lt; &gt; :</formula><p>Similarly to <ref type="bibr" target="#b10">[12]</ref>, <ref type="bibr" target="#b34">[36]</ref>, <ref type="bibr" target="#b35">[37]</ref>, <ref type="bibr" target="#b23">[25]</ref>, we use a projected subgradient method <ref type="bibr" target="#b37">[39]</ref>, <ref type="bibr" target="#b4">[6]</ref> for maximizing Èð Þ over . One iteration is given by</p><formula xml:id="formula_20">:¼ P ð þ gÞ;</formula><p>where P is the operator that projects a vector to , g is a subgradient of Èð Þ, and &gt; 0 is a step size.</p><p>Projection. To project vector to , we first compute vector ¼ P and then update as follows:</p><formula xml:id="formula_21">a :¼ 0 for 2 I À I a , ab :¼ 0 for 2 I À I ab , a :¼ a þ " a À a P 2I a 2 8 2 I a ; ab :¼ ab þ " ab À ab P 2I ab 2</formula><p>8 2 I ab :</p><formula xml:id="formula_22">Subgradient computation. A subgradient of function Èð Þ is given by g ¼ X 2I g ;</formula><p>where g is a subgradient of function È ð Þ. If the latter function is the global minimum of Eðx x x x j Þ (which is the case for 2 I À fF g), then we can take g a ¼ x a , g ab ¼ x a x b , where x is a global minimizer of Eðx x x x j Þ. For the maxflow subproblem a subgradient can be computed as g F ¼ x x x x F , where x x x x F is an optimal solution of linear program <ref type="bibr" target="#b15">(17)</ref>. For a formal proof we refer the reader to [6, Section 6.1].</p><p>To solve <ref type="bibr" target="#b15">(17)</ref>, we use the method of <ref type="bibr" target="#b6">[8]</ref> that reduces the problem to a minimum s-t cut/maximum flow problem in an appropriately constructed graph. We refer to <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b21">[23]</ref> for the description of this reduction; here we just mention one additional detail. The method produces a half-integer optimal solution x F a 2 f0; 0:5; 1g for all assignments a 2 A. Given this solution, we compute an optimal solution for variables x F ab by minimizing (17) while keeping variables x F a fixed. This minimization problem is easy to solve since the problem decouples. We obtain the following rule: If</p><formula xml:id="formula_23">ðx F a ; x F b Þ 6 ¼ ð0:5; 0:5Þ, then x F ab ¼ x F a x F b ; otherwise x F ab ¼ 0 if F ab 0 (i.e.</formula><p>, the corresponding term is submodular) and x F ab ¼ 0:5 if F ab &gt; 0.</p><p>Step size. An important issue in the subgradient method is the choice of the step size . We used an adaptive technique mentioned in <ref type="bibr" target="#b4">[6]</ref>. We set</p><formula xml:id="formula_24">¼ ðÈð Ã Þ þ À Èð ÞÞ=kgk 2 ,</formula><p>where is a constant (1 in our experiments), Ã is the best vector found so far (i.e., the vector giving the best lower bound), and is a positive number which is updated as follows: If the last iteration improved the best lower bound Èð Ã Þ, then is increased by a certain factor (1.5 in our experiments); otherwise it is decreased by a certain factor (0.95).</p><p>Restarting the subgradient method. In our implementation we also used the following technique borrowed from <ref type="bibr" target="#b28">[30]</ref>. If the best value of the lower bound Èð Ã Þ has not changed during iterations, then we replace with Ã . In the beginning ¼ 20 and, after every restart, it is updated as :¼ minf þ 10; 50g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Solution Computation</head><p>To conclude the description of the method, we need to specify how to obtain solution x x x x 2 M. If the linear subproblem were to be included in the decomposition, then it is natural to use its minimum x x x x L in each iteration since x x x x L is guaranteed to satisfy the uniqueness constraint. However, we excluded this subproblem for the experiments presented in this paper (for reasons explained below). Hence, we computed the solution in a given iteration as follows: Starting with labeling x x x x ¼ 0, we go through local subproblems 2 I À fL; F g and assignments a involved in (in a fixed order), set x a ¼ 1 if x a ¼ 1 and this operation preserves the uniqueness constraint on x x x x.</p><p>We maintain the solution with the smallest energy computed so far, and output it as a result of the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Properties of Decomposition</head><p>Of course, it is not necessary to use all subproblems described in Section 3.2. The only requirement is that each assignment a 2 A and edge ða; bÞ 2 N should be covered by at least one subproblem (i.e., I a and I ab should be nonempty); otherwise the projection operation would be undefined. In this section, we study how the choice of subproblems affects the optimal value of the lower bound max 2 Èð Þ. Without loss of generality we can assume ¼ 1 for all 2 I. (Indeed, weights may affect the speed of the subgradient method, but they do not affect the value of the optimal bound since the transformation :¼ =, :¼ Á with &gt; 0 preserves the bound.)</p><p>First, we compare the bound provided by our decomposition to the bound of the following approach. Let us rewrite the energy E (13) in such a way that the uniqueness constraint is implicitly encoded in the energy so that optimization can be performed in the full domain x x x x 2 f0; 1g A , without the restriction that x x x x 2 M. This new energy, which we denote by E 0 , consists of unary and quadratic terms. Thus, we can apply the roof duality relaxation <ref type="bibr" target="#b19">[21]</ref>, <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b21">[23]</ref> to get a lower bound on function <ref type="bibr" target="#b11">(13)</ref>. We will refer to this approach (and to this bound) as QPBO. Formally, the new function E 0 is obtained by replacing uniqueness constraints P a2AðpÞ x a 1 with pairwise terms Cx a x b for a; b 2 AðpÞ, a 6 ¼ b, where C is a sufficiently large constant: Clearly, the minimization problem,</p><formula xml:id="formula_25">E 0 ðx x x xÞ ¼ Eðx x x xÞ þ X p2P 0 [P 00</formula><formula xml:id="formula_26">min x x x x2f0;1g A E 0 ðx x x xÞ;<label>ð18Þ</label></formula><p>is equivalent to <ref type="bibr" target="#b11">(13)</ref>.</p><p>Let us now compare the bound of our decomposition method with the QPBO bound. (Later we will also explore the performance of QPBO experimentally.) Lemma 1. If the set I includes the linear and maxflow subproblems, then the optimal value of the lower bound Èð Ã Þ is the same as or larger than the QPBO bound.</p><p>A proof is given in Appendix A, which can be found in the Computer Society Digital Library at http://doi. ieeecomputersociety.org/10.1109/TPAMI.2012.105. In this proof, we derive the LP relaxation solved by the decomposition approach in the case when I ¼ fL; F g.</p><p>The next lemma shows that the linear and maxflow subproblems are often not essential. (A proof is given in Appendix B, which is available in the online supplemental material.) Lemma 2.</p><p>1. Suppose that for each point p 2 P there exists a local subproblem 2 I À fL; F g which covers all assignments in AðpÞ, i.e., 2 I a for all a 2 AðpÞ. Then adding or removing the linear subproblem will not affect the optimal value of the lower bound of the decomposition approach. 2. Suppose that each assignment a 2 A and each edge ða; bÞ 2 N are covered by at least one local subproblem, i.e., there exist subproblems 2 I À fL; F g with 2 I a and subproblems 2 I À fL; F g with 2 I ab . Then adding or removing the maxflow subproblem will not affect the optimal value of the lower bound.</p><p>It can be seen that our choice of local subproblems always satisfies conditions of part 1. Thus, the linear subproblem would not help (assuming that we can compute the optimal lower bound). Note, we described this subproblem partly because it was used in previous work: In <ref type="bibr" target="#b15">[17]</ref> Duchi et al. computed exact min-marginals for the linear subproblem in the belief propagation framework.</p><p>Next, we ask whether or not conditions of part 2 are satisfied. The answer depends on the structures of the neighborhood systems N p used for constructing the energy function and N d p used for constructing local subproblems. Recall that N p and N d p are controlled by parameters K and K d , respectively. If K K d , then conditions of part 2 are always satisfied; otherwise some edges may not be covered, and so including the maxflow subproblem may improve the optimal bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MODEL LEARNING</head><p>In most of our experiments we learned all model parameters from ground truth correspondences, as explained next. However, for some experiments there is no training data available. In that case we set all model parameters to the following default values:</p><formula xml:id="formula_27">app ¼ occl ¼ geom ¼ coh ¼ 1, ¼ 0:5, 2 l ¼ 0:5, 2</formula><p>¼ 0:9. The energy model defined in (2) is parameterized by a set of parameters, denoted here with ¼ f app ; occl ; geom ; coh ; ; 2 l ; 2 g. In addition, the energy depends on input features sets P 0 and P 00 extracted from the images. Here we highlight this dependence on parameters and input points, by writing the energy function as Eðx x x x; P 0 ; P 00 ; Þ. We now consider the problem of learning parameters from a set of n training matching examples defined by pairs of feature sets fðP 0 1 ; P 00 1 Þ; . . . ; ðP 0 n ; P 00 n Þg and "ground truth" correspondences fx x x x 1 ; . . . ; x x x x n g, typically specified by the user. We use the Nonlinear Inverse Optimization (NIO) algorithm described in <ref type="bibr" target="#b29">[31]</ref>. In our context, the objective of this method corresponds to minimizing the gap in energy value between the user-provided ground truth correspondences and the matching configurations estimated via energy optimization.</p><p>In other words, we minimize the following objective Gð Þ:</p><formula xml:id="formula_28">Gð Þ ¼ X n i¼1</formula><p>Eðx x x x i ; P 0 i ; P 00 i ; Þ À min</p><formula xml:id="formula_29">x x x x2M</formula><p>Eðx x x x; P 0 i ; P 00 i ; Þ:</p><p>Let ¼ f app ; occl ; geom ; coh g and 2 ¼ f 2 l ; 2 g. In order to avoid degenerate solutions with ¼ 0 and to obtain positive values for the term weights i and variances 2 i , we define reparameterizations i ¼ e i = P j e j , 2 i ¼ e i , and minimize G with respect to f ; g ¼ . As in <ref type="bibr" target="#b29">[31]</ref>, we optimize G via gradient descent with line search. The gradient of G is locally approximated by optimizing the energies given the current estimate of the parameters in each iteration. The learning procedure was initialized using default parameters (see above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We start with a description of the different methods considered in our experiments (Section 5.1). Then, in Section 5.2, we present results on various image datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Algorithms</head><p>In our experiments, we compare the following methods: DD: This is our dual decomposition procedure. We used K d ¼ minfK; 4g, where K is the geometric neighborhood size. Motivated by the insights in Section 3.6, we did not use the linear subproblem. We set ¼ 1 for all other subproblems . We used a maximum of 10,000 iterations and stopped earlier if the gap between the lower bound and the cost became smaller than 10 À6 . HUNG: As in <ref type="bibr" target="#b9">[11]</ref>, we also tested the Hungarian algorithm using an energy consisting only of linear terms. On problems with occlusions, we used our occlusion cost in addition to the appearance term, i.e., E HUNG ðx x x xÞ ¼ app E app ðx x x xÞ þ occl E occl ðx x x xÞ. The Hungarian method finds the global optimum for this energy. We denote with LearnHUNG the Hungarian method applied to a learned version of the linear matching problem: We use the algorithm of Caetano et al. <ref type="bibr" target="#b9">[11]</ref> to learn individual weights for the features of the descriptor definining the appearance term of <ref type="bibr" target="#b1">(3)</ref>.</p><p>FUSION: This algorithm was introduced in <ref type="bibr" target="#b25">[27]</ref> for MRF optimization with multiple labels. We propose using it for graph matching as follows: First, we generate 256 solutions by applying one pass of coordinate descent (ICM) to zero labeling using random orders. (Different orders of visiting assignments usually yield different solutions.) We then "fuse" together pairs of solutions using the binary tree structure until a single solution remains. Fusion of solutions x x x x 0 , x x x x 00 is defined as follows: First, we fix all assignments a 2 A for which x x x x 0 and x x x x 00 agree, i.e., x 0 a ¼ x 00 a . Then we convert the obtained graph matching problem to a quadratic pseudo-Boolean optimization problem as described in Section 3.6. Finally, we run the QPBO-PI method <ref type="bibr" target="#b32">[34]</ref> starting either with labeling x x x x 0 if Eðx x x x 0 j " Þ &lt; Eðx x x x 00 j " Þ or with x x x x 00 otherwise. The produced solution x x x x is guaranteed to have the same or smaller cost than the costs of x x x x 0 and x x x x 00 . In Fig. <ref type="figure">4b</ref>, we show a plot of the energy as a function of time. Clearly, this plot depends on the order of fusions. We used the following order: We always pick the leftmost node of the binary tree whose parents are available for fusion. Thus, the plots are independent of the number of initial solutions (256 in our case).</p><p>BP: We converted graph matching to a quadratic pseudo-Boolean optimization problem and ran the max-product belief propagation algorithm. We also tested applying the roof duality approach instead of BP, but the results were quite discouraging (see Section 5.2).</p><p>CTB: We tested the quadratic assignment solver proposed by Yarkony et al. <ref type="bibr" target="#b46">[48]</ref>, using software made available to us by the authors. This method operates in two stages: First, it uses tree-reweighted belief propagation to minimize a lower bound on the original objective defined by a covering tree of the matching graph; then, in a second stage, one-toone correspondences are established by applying bipartite linear matching to the min-marginal costs computed with the covering tree.</p><p>SMAC: We ran the spectral relaxation method of Cour et al. <ref type="bibr" target="#b12">[14]</ref> using the graduated assignment algorithm <ref type="bibr" target="#b17">[19]</ref> for discretization. Since SMAC imposes affine constraints on the solution, we applied this algorithm only to datasets without outliers, where the one-to-one affine constraint is satisfied. In principle, SMAC could handle outliers by the introduction of dummy nodes. However, this would increase the number of variables and potentially make the problem harder to solve. COMPOSE: We reimplemented the "COMPOSE" algorithm described in <ref type="bibr" target="#b15">[17]</ref>. The problem was cast as assigning a label from the set AðpÞ [ f''occlusion''g to each point p 2 P 0 . Min-marginals for the linear subnetwork were computed via OðjAj þ jP 0 jÞ calls to the Dijkstra algorithm. As in <ref type="bibr" target="#b15">[17]</ref>, we used Residual Belief Propagation (RPB) <ref type="bibr" target="#b16">[18]</ref> with damping ¼ 0:3 for computing pseudo min-marginals for the "smoothness" subnetwork containing pairwise terms ab x a x b . However, in our experiments messages did not converge, so we set an additional termination criterion for RBP: We stop it after passing 20jNj messages. As in <ref type="bibr" target="#b15">[17]</ref>, we computed the configuration by looking at individual messages at each node. We did not use damping for the outer loop since otherwise the produced configurations usually did not satisfy the uniqueness constraint. We also informally tested the COMPOSE method with our representation, which labels each assignment as 0 or 1. To compute min-marginals for the smoothness subnetwork we tried both a maxflow algorithm (in the case of submodular potentials) and RBP. However, it did not seem to improve the results, and the issue with convergence remained. IPFP: This is the Integer Projected Fixed Point method of Leordeanu et al. <ref type="bibr" target="#b27">[29]</ref>. It is an iterative procedure involving repeated alternation of two steps: The first step improves the current solution in the discrete domain via a linearization of the objective; in the second step the direction obtained from the first step is used to maximize the original quadratic energy in the continuous domain. As in <ref type="bibr" target="#b27">[29]</ref>, we test IPFP by itself (using a flat uniform continuous solution as initialization), but also by applying it to initial solutions computed via Spectral Matching <ref type="bibr" target="#b26">[28]</ref> (SM+IPFP), and the Hungarian method (HUNG+IPFP). We do not report the results obtained using only Spectral Matching since, as already observed in <ref type="bibr" target="#b27">[29]</ref>, we found them to be widely inferior to those produced by SM+IPFP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparative Results</head><p>Hotel sequence: wide baseline matching. In this section, we report results on the CMU "hotel" sequence. 2 As in previous work <ref type="bibr" target="#b9">[11]</ref>, we use this dataset to assess the performance of graph matching methods and ignore the rigid motion constraint that could be exploited using alternative widebaseline matching algorithms <ref type="bibr" target="#b40">[42]</ref>. We reproduce the experimental setup described in <ref type="bibr" target="#b9">[11]</ref> using the same manual labeling of 30 landmark points and the same subset of 105 frame pairs. As in this previous work, we adopt as unary terms the distances between Shape Context descriptors. However, we replace the pairwise terms proposed in <ref type="bibr" target="#b9">[11]</ref> with our geometric energy function E geom ðx x x xÞ, using K ¼ 2. Due to the absence of outliers, we remove E coh ðx x x xÞ from our energy and use a large constant value for occl . We set the remaining parameters to default values, as defined in Section 4. We set A ¼ P 0 Â P 00 . Fig. <ref type="figure" target="#fig_1">2a</ref> shows the matching error obtained by optimizing this model with different methods. We also include in the plot the performance of the Hungarian method (HUNG and LearnHUNG). For Learn-HUNG, we learned the feature weights using as training data the Hotel frames not included in the 105 test pairs (for a total of 3,655 training pairs). Note in the figure the large variations in matching accuracy obtained with the different approaches: BP and DD are by far the best methods with errors approaching 0 percent. Note that the error obtained with our model and our optimization is over 50 times smaller than the errors reported in <ref type="bibr" target="#b9">[11]</ref>. In particular, our approach greatly outperforms LearnHUNG, i.e., the Hungarian method applied to a learned appearance model. This clearly underscores the benefit of using the spatial arrangement of the points as additional information for the matching. As shown in Fig. <ref type="figure" target="#fig_1">2b</ref>, for all 105 image pairs, DD converged to the global minimum of our objective (convergence to the global minimum is detected when the lower bound and the energy have the same value). In 2 out of 105 test cases, BP yields a suboptimal solution that nevertheless matches the ground truth. The average runtime of our method on an Intel Core Duo CPU @ 3 GHz is 12.9 seconds per image pair when using exhaustive search to solve the local subproblems. The average runtime is reduced to 1.4 seconds when using the branch and bound strategy to compute the global minimum of the local subproblems. As a reference, SMAC and IPFP are by far the fastest quadratic assignment methods considered in our comparison, with average running times of 0.04 and 0.2 seconds, respectively. We found that on these matching problems, applying QPBO on the energy E 0 (18), does not provide any labeling at all.</p><p>House dataset: model and optimization comparison with CTB. In <ref type="bibr" target="#b46">[48]</ref>, Yarkony et al. provide an in-depth comparison between CTB and DD applied to wide baseline matching of images from the CMU "House" dataset. Their analysis suggests that when the two algorithms are applied to their proposed quadratic energy model (for details about the energy function see <ref type="bibr" target="#b46">[48]</ref>), CTB provides a significant speedup and a slightly better matching accuracy (85.6 percent for CTB versus 81.8 percent for DD). Using the software kindly provided by the authors, we were able to reproduce these results. However, using our branch and bound approach (instead of exhaustive search) to solve the local subproblems significantly reduces the computational cost gap between the two methods (average runtime is 14.6 seconds for CTB and 59.3 seconds for DD using branch and bound). Furthermore, we found that the two methods are fairly similar in terms of energy values, with DD being slightly superior: 49 out of 105 times DD returns lower energy values than CTB and 20 out of 105 times the two methods output the same value.</p><p>We also tried applying the two optimization methods to our energy model. We used the same features and settings as for the House dataset experiment. The results are summarized in Table 1 (top rows): When using our energy model, DD is far superior to CTB according to all performance measures (correspondence accuracy, frequency of convergence to global minumum, as well as runtime). One of the key differences between the energy model of <ref type="bibr" target="#b46">[48]</ref> and ours is that in the former the pairwise interaction terms are defined only between correspondences involving neighboring features in the reference (left) image whereas in our model we include pairwise terms when two points are neighbors in either image (see <ref type="bibr" target="#b3">(5)</ref>). As a consequence, the number of pairwise terms in the energy function of <ref type="bibr" target="#b46">[48]</ref> is much smaller than in our model and the corresponding graphical model over x x x x becomes sparse. This enables faster optimization by the treereweighted belief propagation employed by CTB. Conversely, for this dataset our higher connectivity model is more successfully optimized by DD. Overall, the combination of our energy model and our optimization method provides by far the best results in terms of both speed and accuracy. As a reference, on this sequence HUNG yields an accuracy of 44.6 percent. LearnHUNG achieves an accuracy of 68.2 percent when using the remaining House frames to learn the linear matching objective with the algorithm of Caetano et al. Again, this contrasts with the results of <ref type="bibr" target="#b9">[11]</ref>, where it was shown that linear matching applied to learned appearance models performed better than state-of-the-art quadratic assignment methods. Our powerful optimization method allows our approach to effectively exploit the spatial information in the quadratic objective and to greatly outperform learned linear matching models.</p><p>Matching MNIST digits. Here we describe experiments on images of handwritten digits from the MNIST dataset <ref type="bibr" target="#b24">[26]</ref>. For training, we randomly sampled from this dataset one image pair for each of the 10 digits. We repeated the same procedure to generate a test set of 10 pairs of the same digits. From each pair we extracted point sets P 0 and P 00 by uniformly sampling 100 points along the Canny edges of each image, using the procedure described in <ref type="bibr" target="#b2">[4]</ref>. We defined the unary potentials app ðp 0 ;p 00 Þ to be the euclidean distances between Shape Context descriptors computed at points in P 0 and P 00 . We formed the set of candidate assignments A 2 P 0 Â P 00 by selecting the five most similar features, in terms of Shape Context distance, for each point p 2 P . We collected ground truth correspondences in the set ðP 0 Â P 00 Þ for each of the 20 image pairs. The parameters of our model were learned from the 10 training image pairs with NIO (see Section 4). Fig. <ref type="figure">3a</ref> shows that the matching accuracy on the test set critically depends on the ability to globally optimize the energies during the model learning stage. The left plot reports the frequency of convergence to a global minimum during learning, plotted as a function of K (the number of nearest neighbors used for the computation of the geometric penalty terms). The second plot shows the test set matching error of DD with learned versus default parameters. Matching error here is measured as percentage of incorrect correspondences with respect to ground truth. <ref type="foot" target="#foot_0">3</ref>We can see that the matching is much more accurate when using the parameters for which DD more frequently reached global optimality during learning. Interestingly, although the frequency of global minimum convergence increases slightly when varying K from 2 to 4, the matching error remains roughly the same. This suggests that geometric penalty terms defined over small neighborhoods are sufficient to spatially regularize the correspondences. Thus, models involving geometric costs defined over all pairs of matched features, such as those used in <ref type="bibr" target="#b3">[5]</ref>, <ref type="bibr" target="#b26">[28]</ref>, may be unnecessarily restrictive for many applications, in addition to being more difficult to optimize.</p><p>Based on these results, we have used the model with K ¼ 3 for the subsequent MNIST experiments described below. Fig. <ref type="figure">4a</ref> shows the normalized energy values obtained by different optimization methods on the 10 test image pairs, using the learned parameters. For each family of results we performed an additive normalization so that for each image pair the energy of the best method becomes value 1. On 9 out of the 10 test image pairs, DD reaches global optimality and provides the minimum energy value on all examples. FUSION, BP, and COMPOSE find the global minimum only on two images. FUSION finds solutions with energy values very close to those obtained by DD. COMPOSE and BP provide considerably higher energy values on some of the examples.</p><p>We have also attempted to minimize the energy by running the QPBO algorithm on the equivalent quadratic pseudo-Boolean optimization problem, i.e., energy E 0 (18). This algorithm produces partial labelings that are part of a global optimum. However, we found that on our MNIST matching problems, QPBO labeled, on average, only 16 percent of the correspondences, with only 0.12 percent of these assignments corresponding to active correspondences. We also tried to apply the PROBE method <ref type="bibr" target="#b7">[9]</ref>, <ref type="bibr" target="#b32">[34]</ref> to get more labeled nodes. However, in practice we were unable to do so due to the high computational cost of running PROBE on our problem instances.</p><p>Fig. <ref type="figure">4b</ref> shows minimization performance as a function of time, evaluated on a sample image pair. Fig. <ref type="figure">4c</ref> shows how optimization performance translates into correspondence accuracy. Again, we find that DD and FUSION are the best methods. The parameters used for the energy of HUNG were learned from the training examples using NIO with Hungarian matching for optimization. On these instances the simple appearance-based model used by HUNG gives poor accuracy. We also evaluated variations of the energy model defined in (2), obtained by dropping the spatial coherence term and by forcing all points to be matched (implemented by fixing occl to a large value). The parameters of these modified models were learned again with NIO, using DD for optimization during both training and testing. We see from Fig. <ref type="figure">3b</ref> that both the spatial coherence prior and the occlusion term, make the matching The column "lower energy" lists the number of instances (in total 105) where the respective method was better than the other. Note, for some instances both methods have the same energy. The table clearly shows that DD applied to our model gives the best results.</p><p>considerably more accurate. We also report the matching error given by the model and optimization method of Belongie et al., which was applied in <ref type="bibr" target="#b2">[4]</ref> to MNIST digit examples. For this experiment, we use the source code provided by the authors and the settings described in <ref type="bibr" target="#b2">[4]</ref>.</p><p>Our approach performs better than this state-of-the-art method. Fig. <ref type="figure">5</ref> illustrates some of the matches obtained with DD and HUNG. Our model yields more accurate and geometrically consistent correspondences.</p><p>Estimating long range nonrigid motion. We now describe results on the task of estimating large-disparity motion. For this experiment we used four (time-separated) video frames of a child jumping. We matched each image to every other image, for a total of six matches. The motion between any pair of these pictures is very large and highly nonrigid. There is self-occlusion created by the motion of arms and torso, and occlusion due to a tricycle positioned between the child and the camera. Feature points were extracted by running the Harris corner detector on each image. We used euclidean distances of geometric blur descriptors <ref type="bibr" target="#b3">[5]</ref> computed at each feature point, both for selecting assignments in A (by choosing the five most similar features for each point p 2 P ) as well as for calculating the unary terms of our energy. We learned the parameters in our model by applying the NIO algorithm to ground truth correspondences of two image pairs from a separate sequence containing the same child walking. Here we report results using K ¼ 6. Fig. <ref type="figure" target="#fig_4">6</ref> shows two matching examples from this experiment and correspondences found with HUNG and DD. Note the ability of our system to cope well with occlusion and the presence of multiple motions. DD converged to a global minimum on all the image pairs in this experiment (see Figs. <ref type="figure">7a,</ref> and<ref type="figure">7b</ref>). Fig. <ref type="figure">7c</ref> reports the percentage of correspondence errors (including mismatches as well as missed assignments).</p><p>Matching faces. Our final experiment is carried out on a set of eight face images of distinct individuals with different facial expressions. We used two of these images for learning the model parameters given their manually labeled correspondences. We then exhaustively matched the remaining 6 images, for a total of 15 test image pairs. Point sets P 0 and P 00 and candidate assignments A for each image pair were formed by matching geometric blur descriptors <ref type="bibr" target="#b3">[5]</ref> computed along Canny edges in each image, using an iterative procedure. Starting from empty sets P 0 ¼ P 00 ¼ A ¼ fg, we alternate selection of a new point p from either the left or the right image by choosing the edge point (among those not yet considered) having minimum geometric blur distance to  points in the other image. We add the three best assignments involving point p to A and the corresponding points to P 0 and P 00 . We then introduce an inhibition window around point p so that no other points in that neighborhood will be selected. We repeat this procedure 600 times. On average, this yields point sets with more than 900 points in each image, and a set A with over 1,700 potential assignments. Here, we used geometric neighborhood size K ¼ 6, and again defined the unary term to be the euclidean distance between geometric blur descriptors. Fig. <ref type="figure">8a</ref> shows the normalized energy values obtained with the optimization methods in our comparison. FUSION is the best performing method 93.33 percent of the times, while DD is the best on the remaining 6.67 percent cases. On all image pairs DD and FUSION obtain very similar values, but on none of these challenging matches are they able to reach the lower bound. By dropping the value of K to 4, we found that DD can reach the global minimum in most of the cases, although the correspondences are slightly less accurate than when using K ¼ 6. Here BP performs rather poorly. Fig. <ref type="figure">8b</ref> illustrates the correspondences found by HUNG and DD on one of these image pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We have introduced novel models and optimization algorithms for feature correspondence. We believe we are the first to demonstrate graph matching techniques capable of reaching global optimality on various real-world image matching problems.</p><p>There are several directions for future work that could potentially improve our method. The subgradient ascent scheme that we employ is known to have a slow convergence rate (sublinear in the worst case); one could test alternative techniques from the convex optimization literature. Also, the branch-and-bound computation for local subproblems could potentially be sped up by exploiting a better bound (the bound described in Section 3.3 appears to be rather weak).</p><p>A software implementation of our method is available online [1].  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results on the Hotel sequence (jP 0 j ¼ jP 00 j ¼ 30; jAj ¼ 900). (a) Mismatch percentages for HUNG and different optimization methods applied to our energy model. (b) Frequency of convergence to global minimum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.</head><label></label><figDesc>Fig. Experiments the MNIST dataset. (a) Normalized energy values. (b) Optimization performance versus runtime. (c) Mismatch error comparison between HUNG and different optimization methods using our energy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .Fig. 5 .</head><label>35</label><figDesc>Fig. 3. Evaluation on MNIST digits ( P 0 j j ¼ P 00 j j ¼ 100; A j j ¼ 695 on average). (a) Correlation between learning accuracy and matching performance: The left plot shows the frequency of global minimum convergence during learning versus K; the right plot shows mismatch error on test set. (b) Mismatch error with different energy models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Estimating human motion ( P 0 j j ¼ 118; P 00 j j ¼ 172; A j j ¼ 1;128 on average). Correspondences computed with (a) the Hungarian method and (b) DD. Correct correspondences are shown in blue, missed assignments in green, and incorrect correspondences in red.</figDesc><graphic coords="11,46.85,181.49,100.70,123.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Experiments on human motion frames. (a) Frequency of convergence to global minimum. (b) Normalized energy values. (c) Correspondence error.</figDesc><graphic coords="11,209.09,606.17,154.22,99.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 House</head><label>1</label><figDesc>Data Set Experiment: Performance of DD and CTB Applied to Our Energy Model (Top Two Rows) and the Model of<ref type="bibr" target="#b46">[48]</ref> (Bottom Two Rows)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>In order to account for a certain degree of inherent ambiguity in the selection of ground truth correspondences on these images, we did not consider it an error if a point was assigned to any of the 3-nearest neighbors of the correct feature. Declaring a point with a ground truth correspondence an outlier (or vice versa) was counted as an error.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors are grateful to Timothee Cour, Praveen Srinivasan, and Jianbo Shi for providing the software of their SMAC algorithm. They thank John Duchi, Gal Elidan, and Danny Tarlow for sharing code and answering questions about the COMPOSE method. They thank Julian Yarkony and Charless Fowlkes for making the code implementing their CTB algorithm available to them. Thanks to Tiberio Caetano for providing the software implementing the "learning graph matching" method as well as the Hotel and House feature data. Finally, they are grateful to Marius Leordeanu for making the code for his IPFP algorithm publicly available. This research was funded in part by Microsoft Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Magnanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orlin</surname></persName>
		</author>
		<title level="m">Network Flows: Theory, Algorithms, and Applications</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Binocular Stereo Algorithm for Reconstructing Sloping, Creased, and Broken Surfaces in the Presence of Half-Occlusion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>Fourth IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shape Matching and Object Recognition Using Shape Contexts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="522" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shape Matching and Object Recognition Using Low Distortion Correspondence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nonlinear Programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
			<affiliation>
				<orgName type="collaboration">Athena Scientific</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pseudo-Boolean Optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Math</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="155" to="225" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Network Flows and Minimization of Quadratic Pseudo-Boolean Functions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<idno>RRR 17-1991</idno>
	</analytic>
	<monogr>
		<title level="j">RUTCOR</title>
		<imprint>
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Preprocessing of Unconstrained Quadratic Binary Optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tavares</surname></persName>
		</author>
		<idno>RRR 10-2006</idno>
	</analytic>
	<monogr>
		<title level="j">RUTCOR</title>
		<imprint>
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Solving Certain Nonconvex Quadratic Minimization Problems by Ranking the Extreme Points</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cabot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Francis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="86" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Graph Matching</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Caetano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>11th IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Decomposition Method for Quadratic Zero-One Programming</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chardaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="704" to="712" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Thirty Years of Graph Matching in Pattern Recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Foggia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sansone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="265" to="298" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Balanced Graph Matching</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems</title>
		<meeting>Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visual Categorization with Bags of Keypoints</title>
		<author>
			<persName><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Statistical Learning in Computer Vision</title>
		<meeting>Workshop Statistical Learning in Computer Vision</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Selection of Scale-Invariant Parts for Object Class Recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dorko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>Ninth IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using Combinatorial Optimization within Max-Product Belief Propagation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Elidan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems</title>
		<meeting>Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Residual Belief Propagation: Informed Scheduling for Asynchronous Message Passing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Elidan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Conf. Uncertainty in AI</title>
		<meeting>22nd Conf. Uncertainty in AI</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Graduated Assignment Algorithm for Graph Matching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="388" />
			<date type="published" when="1996-04">Apr. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Pyramid Match Kernel: Discriminative Classification with Sets of Image Features</title>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>10th IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Roof Duality, Complementation and Persistency in Quadratic 0-1 Optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Simeone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="121" to="155" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Convergent Tree-Reweighted Message Passing for Energy Minimization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1568" to="1583" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Minimizing Non-Submodular Functions with Graph Cuts-A Review</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1274" to="1279" />
			<date type="published" when="2007-07">July 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Computing Visual Correspondence with Occlusions Using Graph Cuts</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Eighth IEEE Int&apos;l Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">MRF Optimization via Dual Decomposition: Message-Passing Revisited</title>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tziritas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>11th IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradient-Based Learning Applied to Document Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">LogCut-Efficient Graph Cut Optimization for Markov Random Fields</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>11th IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Spectral Technique for Correspondence Problems Using Pairwise Constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leordeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>10th IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An Integer Projected Fixed Point Method for Graph Matching and Map Inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leordeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1114" to="1122" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convergence and Computational Analyses for Some Variable Target Value and Subgradient Deflection Methods</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sherali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="409" to="428" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning Physics-Based Motion Style with Nonlinear Inverse Optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Popovi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1071" to="1081" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Global Solution to Sparse Correspondence Problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Maciel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Costeira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="199" />
			<date type="published" when="2002-02">Feb. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-Level Shape Representation Using Global Deformations and Locally Adaptive Finite Elements</title>
		<author>
			<persName><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Badler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="61" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Optimizing Binary MRFs via Extended Roof Duality</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic Subgraph Matching Based on Convex Relaxation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schellewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schno ¨rr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Int&apos;l Conf. Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<meeting>Fifth Int&apos;l Conf. Energy Minimization Methods in Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Solution to Structural Recognition (MAX,+)-Problems by Their Equivalent Transformations. Part 1</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Giginyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Systems and Computers</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Solution to Structural Recognition (MAX,+)-Problems by Their Equivalent Transformations. Part 2</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Giginyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Systems and Computers</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Modal Matching for Correspondence and Recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="545" to="561" />
			<date type="published" when="1995-06">June 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Z</forename><surname>Shor</surname></persName>
		</author>
		<title level="m">Minimization Methods for Nondifferentiable Functions</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discovering Object Categories in Image Collections</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Lagrangian-Based Methods for Finding MAP</title>
		<author>
			<persName><forename type="first">G</forename><surname>Storvik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="469" to="479" />
			<date type="published" when="2000-03">Mar. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Geometric Motion Segmentation and Model Selection</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Trans. Royal Soc</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="page" from="1321" to="1340" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Solving Markov Random Fields Using Semi Definite Programming</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Artificial Intelligence and Simulation Conf</title>
		<meeting>Artificial Intelligence and Simulation Conf</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">MAP Estimation via Agreement on Trees: Message-Passing and Linear-Programming Approaches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3697" to="3717" />
			<date type="published" when="2005-11">Nov. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Recognition with Local Features: The Kernel Recipe</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wallraven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>Ninth IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Linear Programming Approach to Max-Sum Problem: A Review</title>
		<author>
			<persName><forename type="first">T</forename><surname>Werner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1165" to="1179" />
			<date type="published" when="2007-07">July 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Categorizing Nine Visual Classes Using Local Appearance Descriptors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arregui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR Workshop Learning for Adaptable Visual Systems</title>
		<meeting>ICPR Workshop Learning for Adaptable Visual Systems</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Covering Trees and Lower-Bounds on Quadratic Assignment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yarkony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Ihler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Carsten Rother received the diploma degree with distinction in 1999 from the University of Karlsruhe, Germany, and the PhD degree from the Royal Institute of Technology Stockholm, Sweden, supervised by Stefan Carlsson and Jan-Olof Eklundh. Since 2003, he has been a researcher at Microsoft Research Cambridge, United Kingdom. His research interests include the field of &quot;physics-based scene recovery and understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<idno>RR-5737</idno>
	</analytic>
	<monogr>
		<title level="m">He has published more than 65 articles (h-index 29) in international conferences and journals. He won best paper honorable mention awards at ACCV &apos;10, CHI &apos;07, CVPR &apos;05, and the best paper award at the Indian Conference on Computer Vision &apos;10. He was awarded the DAGM Olympus prize in 2009. He has influenced various Microsoft products</title>
		<meeting><address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">Nov. 2005. 2001</date>
		</imprint>
		<respStmt>
			<orgName>INRIA Rhone-Alpes</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>SIGGRAPH, ICCV, ECCV, CVPR, and NIPS). and has been an area chair for ICCV &apos;11, ECCV &apos;12, BMVC &apos;08-&apos;12, and DAGM &apos;10-&apos;12. He is a member of the IEEE. . For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
