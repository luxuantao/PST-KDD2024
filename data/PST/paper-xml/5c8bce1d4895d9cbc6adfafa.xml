<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning a Hierarchical Embedding Model for Personalized Product Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachuse s Amherst Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
							<email>yongfeng@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachuse s Amherst Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Keping</forename><surname>Bi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachuse s Amherst Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of So ware</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Cro</surname></persName>
							<email>cro@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachuse s Amherst Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning a Hierarchical Embedding Model for Personalized Product Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">52CD115DA571B0755644CD38B3EF598C</idno>
					<idno type="DOI">10.1145/3077136.3080813</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Product Search</term>
					<term>Personalization</term>
					<term>Latent Space Model</term>
					<term>Representation Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Product search is an important part of online shopping. In contrast to many search tasks, the objectives of product search are not con ned to retrieving relevant products. Instead, it focuses on nding items that satisfy the needs of individuals and lead to a user purchase. e unique characteristics of product search make search personalization essential for both customers and e-shopping companies. Purchase behavior is highly personal in online shopping and users o en provide rich feedback about their decisions (e.g. product reviews). However, the severe mismatch found in the language of queries, products and users make traditional retrieval models based on bag-of-words assumptions less suitable for personalization in product search. In this paper, we propose a hierarchical embedding model to learn semantic representations for entities (i.e. words, products, users and queries) from di erent levels with their associated language data. Our contributions are three-fold: (1) our work is one of the initial studies on personalized product search;</p><p>(2) our hierarchical embedding model is the rst latent space model that jointly learns distributed representations for queries, products and users with a deep neural network; (3) each component of our network is designed as a generative model so that the whole structure is explainable and extendable. Following the methodology of previous studies, we constructed personalized product search benchmarks with Amazon product data. Experiments show that our hierarchical embedding model signi cantly outperforms existing product search baselines on multiple benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Product search represents a special retrieval scenario where users submit queries to retrieve products from a search engine. e most direct application of product search is online shopping. E-shopping Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '17, August 07-11, 2017, Shinjuku, Tokyo, Japan © 2017 ACM. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.doi.org/10.1145/3077136.3080813 has become an important part of our lives today. About 8% (more than 300 billion dollars) of U.S. retail sales came from e-commerce and 71% of U.S. customers shopped online in 2015 <ref type="foot" target="#foot_0">1</ref> . In a typical e-shopping scenario, users express their needs through queries submi ed to a product search engine and explore the retrieved results to nd items of interest (e.g., search on Amazon.com). erefore, the quality of product search directly a ects both user satisfaction with online shopping and the pro ts of e-commerce companies.</p><p>In contrast to traditional ad-hoc retrieval tasks, the concept of relevance can be highly personal in product search. Ad-hoc retrieval tasks, such as web search, focus on retrieving documents that satisfy a user's information need, which is usually related to the query topic. Although personalization is important in web search, it is not as fundamental as it is in product search since users actually want to purchase items from the result list, which is a more personal behavior. On the one hand, while multiple items could be topic-related with a user's query, only a few are actually purchased and di erent individuals have di erent opinions even on the same product (such as music CDs). Product search without considering users' di erences will not satisfy the needs of all customers. On the other hand, personalization has explicit bene ts for e-commerce companies as it potentially increases the chance of users to see the products that they are likely to buy. Retrieving relevant products is less important than nding potential items for purchase because the la er brings direct pro ts to sellers. Even a small improvement on personalized product search could be worth millions of dollars.</p><p>Personalization in product search has both potentials and pitfalls. Users of e-shopping websites o en provide rich feedback about their purchases. e reviews wri en by customers provide information about both product properties and user preferences, which give the search engine more opportunities to learn and understand each individual. Using the review text, however, is not trivial because of the the signi cant vocabulary mismatch between the language of queries, products and users <ref type="bibr" target="#b29">[30]</ref>. For example, the words used in reviews of a TV may not be found in the descriptions of a camera. Without capturing their semantic meanings, user reviews cannot provide useful information for personalized product search on a new query.</p><p>e main focus of this paper is to tackle the problem of personalized product search based on language data (i.e. words and reviews). Despite its importance in e-commerce, personalized product search has not been extensively studied so far. To the best of our knowledge, previous work focuses on product recommendation in a non-search scenario <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> or general product search without personalization <ref type="bibr" target="#b29">[30]</ref>. To ll this gap, we propose a hierarchical embedding model speci cally designed for personalized product search. Inspired by recent progress in distributed representation learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref>, we construct a deep neural network and jointly learn latent representations for queries, products and users. Our hierarchical embedding model has three merits. First, it is a vector space model that represents queries, products and users with latent representations.</p><p>e vocabulary mismatch problems in personalized product search can be e ectively alleviated by conducting product retrieval in our latent semantic space. Second, our model is intentionally designed as a generative model. e likelihood of observed user-query-item triples can be directly inferred with their distributed representations, which makes the whole framework explainable and extendable. Last, our model is trained with stochastic gradient decent, which is e cient for training on GPUs and deployment in real systems. Following the methodology proposed by Gysel et al. <ref type="bibr" target="#b29">[30]</ref>, we constructed personalized product search benchmarks on Amazon product data and conducted empirical experiments to evaluate the e ectiveness of our model. Our hierarchical embedding model signi cantly outperforms baselines including unigram-based retrieval models and the state-of-the-art latent space model for product retrieval.</p><p>is demonstrates the potential of personalization with language data in product search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>ere are three lines of research that are directly related to our work: product search, search personalization, and latent space models for information retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Product Search</head><p>e search function is important for exploring and nding products <ref type="bibr" target="#b13">[14]</ref>. Most of the basic product information (i.e. brands, types and categories) can be structured and stored with relational databases. Considerable work has been done on searching products based on their structured aspects <ref type="bibr" target="#b16">[17]</ref>. Despite their important applications in e-commerce, searching with structured data is not enough to satisfy the needs of e-shopping users. First, queries of product search users are o en in natural language and are hard to structure. Duan et al. <ref type="bibr" target="#b9">[10]</ref> noticed that, while languages like SQL are e ective for querying structured databases, people tend not to use them in practice because they are di cult to learn. ey <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> propose a probabilistic mixture model to analyze product search logs from a ribute levels and extend product databases with language modeling approaches to enable conditional search on speci cations. Duan et al. <ref type="bibr" target="#b7">[8]</ref> also tried to learn query representations for structured product data. Second, there is a gap between the language of product descriptions and free-form user queries. Nurmi et al. <ref type="bibr" target="#b22">[23]</ref> reported that users' shopping lists o en di er from the product information maintained by retailers. ey designed a grocery retrieval system to directly retrieve products using the shopping lists wri en in natural language. Gysel et al. <ref type="bibr" target="#b29">[30]</ref> also noticed the vocabulary mismatch problem existing in product search and introduced a latent vector space model that maps queries and products into a hidden semantic space for product retrieval. ese studies are important steps toward language-based product search, but they ignore the e ect of users in online shopping and only use the topic relevance between queries and products as their measurement of retrieval quality. In this paper, we focus on personalizing product search for each individual and use the actual purchase behavior as our gold standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Search Personalization</head><p>To the best of our knowledge, there are two types of personalized search: search on a personal collections (e.g. email search <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24]</ref>), and search on a general corpus with personalized result lists (e.g. web search <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29]</ref>). e product search discussed in this paper is more related to studies on the la er since product collections are equally accessible for most users. In web search, research on personalization focuses on constructing user models with user-speci c contents (i.e. queries), behaviors (i.e. click, clicked pages), contexts (i.e. location, time) and uses them to re ne the ranked list produced by a global retrieval model <ref type="bibr" target="#b10">[11]</ref>. Agichtein et al. <ref type="bibr" target="#b0">[1]</ref> studied the clicks of users and introduced a behavior model to measure user preferences with the features extracted from queries, web pages and click-through logs. Teevan et al. <ref type="bibr" target="#b28">[29]</ref> measure the ambiguity of web queries and propose a ranking model that incorporates personalizations with di erent strengths on di erent queries. In this paper, we focus on a di erent search scenario where users provide explicit feedback (product reviews) on some search results. To the best of our knowledge, our work is the rst study that uses deep neural networks to learn user models from language data for personalized product search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Latent Space Models</head><p>Latent space models have been widely studied for information retrieval.</p><p>e basic idea of latent space models is to project both queries and documents into a high dimensional semantic space so that we can directly match their conceptual meanings and avoid vocabulary mismatch problems. Deerwester et al. <ref type="bibr" target="#b6">[7]</ref> introduced Latent Semantic Indexing (LSI) and constructed latent vectors for words and documents by factorizing the corpus matrix of term frequency with singular value decomposition (SVD). Hofmanm <ref type="bibr" target="#b12">[13]</ref> and Blei et al. <ref type="bibr" target="#b3">[4]</ref> proposed pLSI and LDA by assuming that words are sampled from a xed number of topics and documents are topic distributions. More recently, distributed representation learning with deep neural networks has a racted more a entions. Mikolov et al. <ref type="bibr" target="#b19">[20]</ref> proposed a word2vec model which can e ciently learn high quality word embeddings on a large corpus. Le and Mikolov <ref type="bibr" target="#b14">[15]</ref> constructed paragraph vector models to simultaneously learn distributed representations for words and documents. It has been shown that the paragraph vector model with distributed bag-ofwords assumption (PV-DBOW) implicitly factorizes a tf-icf matrix and constructs a language model that is e ective for semantic matching in information retrieval <ref type="bibr" target="#b1">[2]</ref>. Inspired by these studies, we design a hierarchical embedding model to jointly learn distributed representations of words, queries, products and users for personalized product search.</p><p>Session 6A: Personalization and Privacy SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan q u i M uq = q + (1 )u</p><p>Figure <ref type="figure">1</ref>: Personalized product search in a latent space with query q, user u, personalized search model M uq and item i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HIERARCHICAL EMBEDDING MODEL FOR PERSONALIZED PRODUCT SEARCH</head><p>In this section, we discuss how we tackle the problem of personalized product search with our hierarchical embedding model. In our model, queries, users and items are projected into a single latent space so that their relationships can be directly measured by their similarities. We propose a uni ed framework which jointly learns di erent level embeddings through maximizing the likelihood of purchased user-item pair given corresponding queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Personalized Product Search in Latent Semantic Space</head><p>For personalized product search, we consider two important factors when designing our retrieval model. e rst is query intent, which determines whether an item is relevant to a query in general. e second is user preference, which decides whether an item satis es the special need of a particular user. Although the preference of a user may vary depending on the intent of a query, it is unrealistic to construct query-dependent user models because we do not have adequate training data for each user-query pair. For simplicity, we assume that user preferences are independent from query intents and build query-independent user models for personalized product search.</p><p>To conduct product search in semantic space and to balance the pro t and risk of personalization, we project both queries and users into a single latent space and explicitly control their weights in personalized product search model. Inspired by the design of word embedding models <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, we design the latent representations of queries and users to have good compositionality so that the personalized search model could be directly computed as the linear combination of query models and user models. Formally, suppose that the query intent of a query q in semantic space is represented with a vector q ∈ R α and the user preference of a user u is represented with u ∈ R α , we de ne the personalized search model for (u, q) as:</p><formula xml:id="formula_0">M uq = λq + (1 -λ)u (1)</formula><p>where λ is a hyper-parameter that controls the weight of query model q and user model u.</p><p>We search products with M uq following the framework of vector space retrieval models. Vector space models measure the relevance of query-document pair with the similarity of their vector representations. Similarly, we rank items according to the similarity between their latent representations and M uq . Let i ∈ R α be the latent representation of item i, then the score of i with model M uq can be computed as:</p><formula xml:id="formula_1">Score (i |u, q) = f (i, M uq ) = f (i, λq + (1 -λ)u) (2)</formula><p>where f is a similarity function prede ned for the latent space of queries, users and items. An illustration of our personalized product search in vector space is shown in Figure <ref type="figure">1</ref>. e similarity function f in latent space models can be arbitrarily designed in many forms.</p><p>In our experiments, we tried both cosine similarity and dot product (the sum of element-wise multiplications). We observed that cosine similarity yielded be er performance in most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hierarchical Embedding Model</head><p>We now describe our hierarchical embedding model for personalized product search in detail. In our model, queries, users and items are represented with their associated text data. We de ne language models for users and items based on their distributed representations and assume that items are generated from a personalized search model constructed with query and user embeddings. We jointly learn embeddings for words, queries, users and items with this hierarchical structure by directly maximizing the likelihood of observed query-user-item triples. e overall structure of our hierarchical embedding model is shown in Figure <ref type="figure">2</ref>. Our model can be broadly separated into three parts. e rst part of our model maps words to their corresponding word embeddings and constructs distributed representations for users and items by requiring them to predict the words from their associated reviews (R u and R i ). e second part of our model builds query embeddings with query keywords and function ϕ. Finally, the third part of our model ne-tunes the representations of queries, users and items by requiring the composition of query and user embeddings -the personalized search model M uq -to predict the purchased item. Given this structure, we can directly compute the likelihood of a query-user-item triple and train our model by maximizing the log likelihood of training data.</p><p>Embedding-based User/Item Language Model. Inspired by the paragraph vector models <ref type="bibr" target="#b14">[15]</ref>, we learn the distributed representations for users and items by constructing language models with word embeddings. Formally, given e ∈ R α as the latent representation of an entity (which could be either a user or an item) and w ∈ R α as the embedding of a word w, the probability that w is generated from the language model of e is de ned as:</p><formula xml:id="formula_2">P (w |e) = exp(w • e) w ∈V w exp(w • e)<label>(3)</label></formula><p>where V w is the corpus vocabulary and P (w |e) is computed as a so max over e and w. For simplicity, we assume that words can be generated by user models and item models independently. e use of embedding-based language models have two merits. First, through matching with distributed representations, the embedding-based language model alleviates the problem of vocabulary mismatch. It can directly measure the semantic similarity between words and entities in latent space. Second, the construction of embedding-based language models requires no priori knowledge about the corpus's topic distribution (e.g., the topic number in LDA <ref type="bibr" target="#b3">[4]</ref>). It can automatically cluster entities based on the characteristics of input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+ ( )</head><p>, ,</p><formula xml:id="formula_3">w u 2 R u w q 2 q w i 2 R i w u w q w u w u … w q w q u q u i i w i w i w i … ) ) Embedding look up</formula><p>)</p><p>) )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M uq</head><p>Figure <ref type="figure">2</ref>: e structure of our hierarchical embedding model for personalized product search. R u , R i denote the sets of reviews for user u and item i; w u , w i , w q denote the words in R u , R i and query q; and M uq is the personalized search model constructed with query models and user models.</p><p>ery Embeddings. As the number of possible queries is very large, query embeddings learned o -line cannot be generalized in practice.</p><p>erefore, to construct distributed representations for queries on the y, we de ne a projection function ϕ for queries and use the embeddings of query words as its inputs:</p><formula xml:id="formula_4">q = ϕ ({w q |w q ∈ q})<label>(4)</label></formula><p>Previous studies have proposed several methods to combine word embeddings to form a query embedding. e most simplest way is to aggregate and average the embeddings of query words directly <ref type="bibr" target="#b30">[31]</ref>, which can be formulated as:</p><formula xml:id="formula_5">ϕ ({w q |w q ∈ q}) = w q ∈q w q |q| (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where |q| is the length of query q. An extension of this method is to add a non-linear projection layer over the average word embeddings and form a new embedding vector <ref type="bibr" target="#b29">[30]</ref>:</p><formula xml:id="formula_7">ϕ ({w q |w q ∈ q}) = tanh(W • w q ∈q w q |q| + b)<label>(6)</label></formula><p>where W ∈ R α ×α and b ∈ R α are parameters learned on a separate training set. Further, a more complex model that considers query structures is to sequentially input the query words into a recurrent neural network (RNN) and use the nal network state as the latent query representation <ref type="bibr" target="#b24">[25]</ref>:</p><formula xml:id="formula_8">o t = (1 -a t ) o t -1 + a t s t a t = σ (W w a w t q + W s a o t -1 ) r t = σ (W w r w t q + W s r o t -1 ) s t = tanh W w w t q + W s (r t o t -1 )<label>(7)</label></formula><p>where s t ∈ R α is the state vector on t step, w t q is the tth word in query q, is the element-wise product, σ (x ) = 1 1+e -x is a sigmoid function and W x ,W s ,W x a ,W s a ,W x r ,W s r ∈ R α ×α are parameters in the RNN with Gated Recurrent Unit <ref type="bibr" target="#b4">[5]</ref>. e ϕ ({w q |w q ∈ q}), namely the embedding of q, is equal to the nal network state s |q | .</p><p>As far as we know, there is no query embedding method that satis es the needs of all search scenarios. For example, the mean vector of word embeddings works well on short queries while the recurrent network performs be er on long queries with complex linguistic structures. In our experiments, we explored all the methods above to identify the most e ective model for query embedding in personalized product search.</p><p>Item Generation Model. To ne tune the embeddings of queries, users and items, we further construct an generative model for items that requires user embeddings and query embeddings to predict the items related to them. For users, related items are those purchased by the user; for queries, related items are those relevant to the query. e probability that an item is generated from a user model and a query model together is computed with their embedding representations and a so max function:</p><formula xml:id="formula_9">P (i |u, q) = Score (i |u, q) = exp i • (λq + (1 -λ)u) i ∈V i exp i • (λq + (1 -λ)u)<label>(8)</label></formula><p>where V i is the set of all possible items and λ is the weight of query model in the nal ranking function (Equation <ref type="formula">2</ref>). e design of the item generation model aims to regularize the representations of users, queries and items so that relevant queryitem pairs and preferable user-item pairs have high similarity in the nal embedding space. Also, it forms a hierarchical structure that connects the learning of embeddings from di erent levels. With it, we can directly compute the likelihood of observed user-query-item triples in our hierarchical embedding model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint Learning Framework</head><p>As mentioned previously, we learn the distributed representations of queries, users and items in our hierarchical embedding model by maximizing the likelihood of observed user-query-item triples. Let R u and R i be the sets of product reviews that are associated with user u and item i respectively, then the log likelihood of observing a query-user-item triple with corresponding reviews in our model can be computed as</p><formula xml:id="formula_10">L(R u , R i , u, i, q) = log P (R u , R i , u, i, q)<label>(9)</label></formula><p>In our model, words in R i are generated by the language model of i and words in R u are generated by the language model of u. us, R i is independent of u, q, R u while R u is independent of i, q, R i .</p><p>Session 6A: Personalization and Privacy SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan</p><p>Because we assume that user preferences and query intents are independent in personalized product search, we have the following:</p><formula xml:id="formula_11">L(R u , R i , u, i, q) = log P (R i , i |u, q)P (R u , u, q)</formula><p>= log P (R i |i)P (i |u, q)P (R u |u)P (u)P (q)</p><p>= log P (i |u, q)P (u)P (q)</p><formula xml:id="formula_12">w i ∈R i P (w i |i) w u ∈R u P (w u |u) = log P (i |u, q) + w i ∈R i log P (w i |i) + w u ∈R u log P (w u |u)<label>(10)</label></formula><p>where P (u) and P (q) are prede ned as uniform distributions, which could be ignored in the computation of log likelihood. erefore, the log likelihood of a query-user-item triple is actually the sum of log likelihood for the user language model, the item language model and the item generation model. Directly computing the log likelihood of a query-user-item triple, however, is not practical due to the so max function used in our hierarchical embedding model (Equation 3&amp;8). For e cient training, we adopt a negative sampling strategy to approximate the somax function in our model. Negative sampling was rst proposed by Mikolov et al. <ref type="bibr" target="#b19">[20]</ref> and has been extensively used in machine learning and information retrieval <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref>. It has been shown to be e ective for approximating so max functions and factorizing the mutual information matrix of two related entities <ref type="bibr" target="#b15">[16]</ref>. e basic idea of negative sampling is to sample data from the corpus with a prede ned distribution and form negative samples to approximate the denominator of so max functions. In our model, the negative samples for language models are the words randomly sampled from the corpus. e log likelihood of a user model or an item model with negative sampling is:</p><formula xml:id="formula_13">log P (w i |i) = log σ (w i • i) + k • E w ∼P w [log σ (-w • i)] log P (w u |u) = log σ (w u • u) + k • E w ∼P w [log σ (-w • u)] (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>where k is the number of negative samples and P w is a noise distribution for words. In our experiments, we de ne P w as the unigram distribution raised to the 3/4rd power <ref type="bibr" target="#b19">[20]</ref>. Similarly, we compute the log likelihood of our item generation model by conducting negative sampling on items:</p><formula xml:id="formula_15">log P (i |u, q) = log σ i • (λq + (1 -λ)u) + k • E i ∼P i log σ -i • (λq + (1 -λ)u)<label>(12)</label></formula><p>where P i is the uniform noise distribution for items.</p><p>We use stochastic gradient descent to learn the parameters of our hierarchical embedding model. All embeddings are trained simultaneously with this joint learning framework. Also, similar to previous studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30]</ref>, we add L2 regularizations on the distributed representations of words, users and items. e nal optimization goal is:</p><formula xml:id="formula_16">L = u,i,q L(R u , R i , u, i, q) +γ ( w ∈V w w 2 + u ∈V u u 2 + i ∈V i i 2 ) = u,i,q w i ∈R i log σ (w i • i) + k • E w ∼P w [log σ (-w • i)] + w u ∈R u log σ (w u • u) + k • E w ∼P w [log σ (-w • u)] + log σ i • (λq + (1 -λ)u) + k • E i ∼P i log σ -i • (λq + (1 -λ)u) +γ ( w ∈V w w 2 + u ∈V u u 2 + i ∈V i i 2 ) (<label>13</label></formula><formula xml:id="formula_17">)</formula><p>where γ is the strength of L2 regularization; V w , V u and V i are the set of all possible words, users and items respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head><p>In this section, we introduce our experimental se ings for personalized product search. We describe how to extract search queries from product corpus and give details about our data partitions. We also describe the baseline methods used in our experiments and the training se ings for our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We used the Amazon product dataset<ref type="foot" target="#foot_2">2</ref> as our experiment corpus.</p><p>is dataset is a well-known benchmark for product recommendation. It includes millions of customers and products as well as rich metadata such as reviews, product descriptions and product categories. In our experiments, we used four subsets from the Amazon product dataset, which are Electronics, Kindle Store, CDs &amp; Vinyl and Cell Phones &amp; Accessories. e rst three are large-scale datasets that cover three common types of products (electronic devices, books and music). e last one is a small dataset which is used to test our models in situations where text data are limited. Speci cally, we use the 5-core data provided by McAuley et al. <ref type="bibr" target="#b17">[18]</ref> where each user and each item has at least 5 associated reviews. In these datasets, a user has to purchase an item before writing a review for it. erefore, we extract purchase user-item pairs directly based on user reviews. e objective of personalized product search in our experiments is to nd items that are both relevant to the query and purchased by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">ery Extraction</head><p>As far as we know, there is no publicly available dataset that contains search queries for product search. Previous studies in eshopping has described directed product search as users search for "a producer's name, a brand or a set of terms which described the category of the product" <ref type="bibr" target="#b26">[27]</ref>. erefore, a common queryextraction method for product search research is to extract queries from the category information of each product.</p><p>Following the paradigm used by Gysel et al. <ref type="bibr" target="#b29">[30]</ref>, we extract the search queries for each item with a three-step process. First, we  <ref type="bibr" target="#b29">[30]</ref> from Amazon product data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Electronics:</head><p>video games playstation accessory kit so ware operate system microso window Kindle Store:</p><p>store kindle ebook cookbook food wine bake dessert books health tness weight loss diet</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CDs &amp; Vinyl:</head><p>musical instrument general accessory sheet music folder digital music hard rock thrash speed metal</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cell Phones &amp; Accessories:</head><p>cell phone accessory international charger cell phone accessory case sleeve extract category information for each item from the metadata of products. en, we concatenate the terms from a single hierarchy of categories to form a topic string. Final, stopwords and duplicate words are removed from the topic string and we use it as a query for the corresponding item. To ensure the quality of extracted queries, we ignore the category hierarchies with only one level as those categories are usually non-descriptive for items (e.g. "CDs &amp; Vinyl"). Also, we try to maintain more terms from the sub-categories by removing duplicate words sequentially from the rst level to the last level (e.g. Camera, Photo → Digital Camera Lenses would be converted to "photo digital camera lenses"). Some example queries are shown in Table <ref type="table" target="#tab_1">2</ref>.</p><p>For personalized product search, we construct user-query pairs by linking user-item pairs with each item's queries. If a user purchased an item, the pairing of this user with any query associated with the item are valid user-query pairs. Only the items that are purchased by the user and belong to the query are considered as relevant to the user-query pair. For simplicity, we do not conduct any ltering or initial retrieval in our experiments and use all possible items within each dataset as the candidate items for each query. erefore, the relevant items for each user-query pair are very sparse and the personalized product search se ings in our experiments are di cult by nature. More statistics about the subsets of Amazon product data are shown in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Methodology</head><p>We partitioned each dataset into a training set and a test set according to the following instructions. First, we randomly hide 30% of reviews for each user from the training process. User-item pairs from those reviews are used to represent purchase behaviors in the test data. Second, we randomly select 30% queries as the initial test query set. A er that, if all queries of a training item are in the test query set, we randomly select one query and put it back to the training query set. erefore, each item has at least one query in the training data. Finally, we match all test queries with users to form the nal test data. e basic intuition of our se ing is to ensure that every query and query-user-item triple in the test set is new and unobserved in the training process. Although the number of queries is limited, we have adequate user-query pairs due to the large number of users.</p><p>e statistics for data partitions in each Amazon dataset are also shown in Table <ref type="table" target="#tab_0">1</ref>.</p><p>For each user-query pair, we compute evaluation metrics based on the top 100 items retrieved by each model. e ranking metrics we used are mean average precision (MAP), mean reciprocal rank (MRR) and normalized discounted cumulative gain (NDCG). Reciprocal rank is the precision on the rank of the rst relevant result, which is actually the inversed rank value for the rst user purchase in the retrieved items. In other words, MRR indicates the expected number of items that a user needs to explore before nding the "right" product. NDCG is a common metric for multi-label ranking problems. Although we only have binary labels in our se ings of personalized product search, the value of NDCG shows how Session 6A: Personalization and Privacy SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan good the ranking is compared to the optimal ranked list. In our experiments, we compute NDCG at 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Baselines</head><p>For model evaluation, we used three types of baselines: the query likelihood model <ref type="bibr" target="#b25">[26]</ref> (namely the standard language modeling approach), an extended query likelihood with user models, and the latent semantic entity model <ref type="bibr" target="#b29">[30]</ref>. e rst two are retrieval models based on bag-of-words representations and the last one is a state-of-the-art latent space model for product search. ery Likelihood Model. e query likelihood model (QL) is a language modeling approach proposed by Ponte and Cro <ref type="bibr" target="#b25">[26]</ref>. It is an unigram model that ranks documents based on the log likelihood of query words in the document's language models. Given a query Q, the probability that Q is generated from a document D is computed as</p><formula xml:id="formula_18">P Q L (Q |D) = w ∈Q t f w,Q log t f w, D + µP (w |C) |D| + µ (<label>14</label></formula><formula xml:id="formula_19">)</formula><p>where t f w, D is the frequency of word w in D, |D| is the length of D, µ is a parameter for Dirichlet smoothing and P (w |C) is a background language model computed as the frequency of w divided by the total number of terms in the corpus C. In our experiments, the document for an item is constructed with the item's reviews. e value of µ are tuned around the average length of each document in the training data (from 1000 to 3000). Extended ery Likelihood with User Models. e original QL model is not a personalized retrieval model, so we extended it to consider the e ect of users in personalized product search. Based on similar assumptions, we de ne a user-query likelihood model (UQL) that ranks documents according to both the likelihood of query words and the words associated with each user. Formally, let U be the set of words wri en by a user u, then the likelihood of user-query pair (U , Q ) in document model D is</p><formula xml:id="formula_20">P U Q L (U , Q |D) = λP Q L (Q |D) + (1 -λ)P Q L (U |D)<label>(15)</label></formula><p>Similar to Equation <ref type="formula">2</ref>, we use λ to control the weights of U in retrieval. We tuned λ from 0.0 to 1.0 and show the results in Section 5.1&amp;5.2. To improve e ciency, we removed stop words and used y of the most frequent words in U to compute</p><formula xml:id="formula_21">P U Q L (U , Q |D).</formula><p>Latent Semantic Entity. e latent semantic entity model (LSE) proposed by Gysel et al. <ref type="bibr" target="#b29">[30]</ref> is a latent space model speci cally designed for product search. LSE learns item representations with their associated text data. Speci cally, it extracts n-grams from the reviews of an item and projects them into a latent entity space with their word embeddings:</p><formula xml:id="formula_22">f E (s) = tanh(W E • ( 1 |s | w ∈s w ) + b) (<label>16</label></formula><formula xml:id="formula_23">)</formula><p>where |s | is the length of a n-gram s, w ∈ R α is the word embedding of word w, f E (s) ∈ R β is the representation of s in the latent entity space, and W E ∈ R α ×β , b ∈ R β are parameters learned in the training process. LSE constructs distributed representation e for item e by maximizing the similarity between e and its n-grams in the latent entity space. Similarly to our hierarchical model, LSE uses negative sampling to de ne its loss function. However, our model approximates item embeddings by sampling negative words for each item while LSE approximates n-gram representations by sampling negative items for each n-gram. From the perspective of a generative model, the basic assumption of LSE is that each n-gram is a potential query that could generate the corresponding item. erefore, LSE can directly use Equation <ref type="formula" target="#formula_22">16</ref>to compute the latent representations of queries and do product search by ranking items with their similarities to the query embedding. For simplicity, we set equal sizes for word embeddings and item embeddings (α = β) in LSE and tuned them from 100 to 500. e best embedding size is 400 for Electronics, 300 for Kindle Store, 500 for CDs &amp; Vinyl and 400 for Cell Phones &amp; Accessories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Model Training</head><p>Both LSE and our models are trained on a Nvidia Titan X GPU with 20 epochs. We set the initial learning rate as 0.5 and gradually decreased it to 0.0 in the training process. We used stochastic gradient decent with batch size 64 and clipped the global norm of parameter gradients with 5 to avoid unstable gradient updates. To speed up training on large datasets (Electronics, Kindle Store and CDs &amp; Vinyl), we subsampled words with probability 10 4 • c f w /|C | where c f w is the corpus frequency of word w and |C | is the length of the corpus. For LSE and our models, we set negative sampling number as 5 and tuned L2 regularization strength γ from 0.0 to 0.005. We tuned the weight of query model λ (Equation 2&amp;15) from 0.0 to 1.0 and tested embedding size from 100 to 500. e e ect of λ and embedding size are shown in Section 5.2&amp;5.3. e training of LSE and our models (except HEM R N N ) usually takes 7-8 hours to nish 20 epoch (about 100k words per second) on our largest dataset (Electronics). e source code can be found in the link below <ref type="foot" target="#foot_3">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS AND DISCUSSION</head><p>Now we report our results on personalized product search benchmarks. We rst show the overall retrieval performance of our hierarchical embedding models and baselines on di erent Amazon product datasets. en we discuss the e ect of user models in personalized product search. A er that, we analyze the parameter sensitivity of embedding size in our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Retrieval Performance</head><p>Table <ref type="table">3</ref> shows the overall results of baselines and our models on the personalized product search benchmarks of Amazon data Electronics, Kindle Store, CDs &amp; Vinyl and Cell Phones &amp; Accessories. In the Table <ref type="table">3</ref>, QL represents the query likelihood model <ref type="bibr" target="#b25">[26]</ref>; UQL represents the extended query likelihood with user models; LSE represents the model of Latent Semantic Entity <ref type="bibr" target="#b29">[30]</ref>, and HEM denotes our hierarchical embedding models with ϕ function as mean vector (mean, Equation <ref type="formula" target="#formula_5">5</ref>), projected mean (pm, Equation <ref type="formula" target="#formula_7">6</ref>) and recurrent neural network (RN N , Equation <ref type="formula" target="#formula_8">7</ref>). We conducted signi cant tests over QL, UQL and LSE for all models. All metrics reported in Table <ref type="table">3</ref> are computed based on user purchases, which means that the personalized product search task is di cult by nature and even a small improvement could potentially lead to large pro ts for e-shopping companies.</p><p>Table <ref type="table">3</ref>: Comparison of baselines and our hierarchical embedding models on the Amazon product search datasets. MAP and MRR are computed with top 100 items while NDCG is computed with top 10 items. * , + and ‡ denote signi cant di erences to QL, UQL and LSE in Fisher randomization test <ref type="bibr" target="#b27">[28]</ref> with p ≤ 0.01. e best performance is highlighted in boldface. e language for queries in Electronics and Cell Phones &amp; Accessories showed high correlations with the language for user purchases. For example, the MAP of QL is much higher on Electronics and Cell Phones &amp; Accessories (0.289 and 0.081) than it is on Kindle Store and CDs &amp; Vinyl (0.011 and 0.008).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Electronics</head><p>e relative performance of unigram models (QL and UQL) compared to latent space models (LSE, HEM) also varies on di erent datasets. On "easy" datasets such as Electronics and Cell Phones and Accessories, the performance of QL and UQL is comparable or be er than the latent space baseline (LSE) and some variations of our hierarchical embedding models (HEM mean and HEM R N N ). On di cult datasets like Kindle Store and CDs &amp; Vinyl, however, vocabulary mismatch problems are more severe and unigram models are signi cantly worse than latent space models. Overall, our best model (HEM pm ) outperformed QL and UQL on all four datasets. e improvement of MAP over QL and UQL is 0.019 (7%) on Electronics, 0.018 (164%) and 0.015 (107%) on Kindle Store, 0.026 (325%) and 0.016 (89%) on CDs &amp; Vinyl, and 0.043 (53%) on Cell Phones and Accessories. ese results indicate that exact keyword matching is not enough to predict user purchases in product search. In many cases, the semantic relationships between queries, users and products considerably a ect the purchase decisions of users.</p><p>Compared to LSE, we notice that the HEM models indeed produce be er results on the tasks of personalized product search. Our best model (HEM pm ) outperformed LSE on MAP for 0.075 (32%) on Electronics, 0.023 (383%) on Kindle Store, 0.016 (89%) on CDs &amp; Vinyl and 0.026 (27%) on Cell Phones &amp; Accessories. ere are two potential reasons for the good performance of our models. First, compared to LSE, our models explicitly construct user models with user's reviews. Purchase is a personal behavior and user models enable us to retrieve products according the preference of each individual. Second, our models are designed based on more general assumptions for queries, users and items. In LSE, each n-gram is considered as a potential query. Gysel et al. <ref type="bibr" target="#b29">[30]</ref> conducted negative sampling by sampling items for each n-gram, which basically assumes that items are generated from models of n-grams. In contrast, we assume that words are generated from the models of items and items are generated from both query models and user models. We believe that items are more complex concepts and should be placed at a higher level than basic semantic units like words and n-grams.</p><p>e main di erences between the variations of our hierarchical embedding models in Table <ref type="table">3</ref> are their ϕ functions for query embedding. According to our experiments, HEM pm is the most e ective and robust model while HEM mean is the worst one. Previous studies <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> have shown that, despite the good compositionality of word embeddings, aggregating word embeddings directly to form query embeddings for information retrieval is not promising. In our experiments, we observed inferior performance for HEM mean in Table <ref type="table">3</ref>. A er adding a non-linear projection layer over the average word embeddings, however, our HEM pm obtained signi cantly be er results on almost all datasets. is indicates that the relation between queries and words is non-linear in semantic space. Also, we notice that the performance of the projected mean (pm) on three of our datasets is even be er than RNN, which is considered to be a complex and powerful neural network in general. One possible reason is that the queries used in our personalized product search benchmarks are mostly keyword-based queries. As discussed in previous studies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>, keyword-based queries in document retrieval and entity retrieval tend to be simple in structure and do not have complicated compositional meanings. erefore, using neural networks as complex as RNN in our hierarchical embedding models brings li le bene t to the process of query modeling and potentially increases the risk of model over-ing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Personalization Weight</head><p>In our hierarchical embedding models, we de ne a hyper-parameter λ to control the weight of user models in personalized product search. To analyze the e ect of personalization in our models, we plot the MAP value of baselines and HEM pm with respect to λ in Figure <ref type="figure" target="#fig_0">3</ref>. When λ is equal to 1.0, our model purely relies on query models to retrieve items for all users; when λ is equal to 0.0, our model only uses user models to nd items for each individual.</p><p>As we can see in Figure <ref type="figure" target="#fig_0">3</ref>, the optimal performance of our hierarchical embedding models is a tradeo between query relevance and user preference. e personalized search model of the hierarchical embedding model is the linear composition of query models (query embeddings) and user models (user embeddings). When we do not consider queries in personalized product search (λ = 0.0), HEM pm ranks items purely based on the preference of users and had poor performance on all datasets. When we conducted product search without personalization (λ = 1.0), HEM pm obtained fair results on Electronics and Cell Phones &amp; Accessories but still performed worse than our best models. e best value of λ for HEM pm is 0.7 on Electronics, 0.5 on Kindle Store, CDs &amp; Vinyl and Cell Phones &amp; Accessories. As λ increased from 0.0 to 1.0, the performance of UQL increased in the beginning and decreased a er 0.1 on Kindle Store and 0.3 CDs &amp; Vinyl. On Electronics and Cell Phones &amp; Accessories, however, the best UQL is the UQL with λ = 1.0, which is actually a QL model without using user reviews.</p><p>As discussed previously, the types of products not only in uence the di culty of product search but also a ect the usefulness of personalization. According to our experiments, the needs of personalization on books (Kindle Store) and music (CDs &amp; Vinyl) are higher than those on electronic devices (Electronics). Also, because each item belongs to one query in Electronics and Cell Phones &amp; Accessories on average, the test queries are strong lters for items by themselves, which partially explains why using only the query models (λ = 1.0) still produced good results on these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Embedding Size</head><p>To analyze the e ect of embedding sizes and potentially provide guides for future studies, we show the results of our hierarchical embedding models with di erent embedding sizes in Figure <ref type="figure" target="#fig_2">4</ref>. e horizontal axes represent the size of embedding vectors for queries, users and items in our experiments.</p><p>Similar to personalization weights, we observed that the needs of high dimensional embedding vectors vary on di erent datasets. On Cell Phones &amp; Accessories and Kindle Store, HEM pm with embedding size 100 obtained the best performance on MAP. Higher embedding sizes brought no improvement but higher training cost and overing risks on these datasets. On Electronics and CDs &amp; Vinyl, we observed be er performance of HEM pm with embedding size larger than 100. e best embedding sizes for Electronics and CDs &amp; Vinyl are 400 and 300. Overall, the performance of HEM pm are robust to the change of embedding sizes and outperformed the baseline models in most cases.</p><p>Arora et al. <ref type="bibr" target="#b2">[3]</ref> conducted both empirical and theoretical analyses on word embedding models and argued that low dimension vectors (i.e. 300 dimensions) were already enough to encode the information needed by many natural language processing tasks. Because our models incorporate more complicated relationships between queries, users and items, larger embedding sizes could potentially lead to be er performance in personalized product search. Nonetheless, we suggest starting with relatively low dimensional vectors and increasing embedding sizes la er if necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we introduce a hierarchical embedding model for personalized product search. Our model is a latent space retrieval model which projects queries, users and items into a semantic space and conducts product retrieval according to the semantic similarity between items and the composition of query and user models (the personalized search model). We design our neural embedding model in a generative way so that the distributed representations of queries, users, and items can be learned through optimizing the likelihood of observed query-user-item triples. Our results showed that our model signi cantly outperformed the state-of-the-art baselines on Amazon benchmarks and indicate that personalization with review text is fruitful for product search.</p><p>In our experiments, the performance of personalized product search and the importance of user models vary considerably from one dataset to another. We explained this phenomenon empirically according to the general statistics of di erent datasets such as the number of reviews per item, the number of queries per items etc., but more quantitative analyses are still required if we want to understand each dataset in detail. ose analyses would provide  e performance of HEM pm and baselines on the Amazon personalized product search benchmark datasets with di erent embedding size α.</p><p>e red solid line with triangles represents the numbers of HEM pm ; the blue, green and cyan dashed lines with circles, squares and pentagons are results for LSE, QL and UQL respectively. important guidelines for system design in e-shopping websites. Also, in our work, we only explored the potential of language data in personalized product search. In e-shopping websites, however, there is other user feedback that we haven't used, such as clicks, ratings and frequently asked questions (FAQ). How to e ectively combine information from di erent resources for personalized product search remains to be an open question. We believe that studies in this direction would have great potential and real in uence on e-commerce in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3:e performance of HEM pm and baselines on the Amazon personalized product search benchmark datasets with di erent query model weight λ. e red solid line with represents the numbers of HEM pm ; the blue, green and cyan dashed lines with circles, squares and pentagons are results for LSE, QL and UQL respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4:e performance of HEM pm and baselines on the Amazon personalized product search benchmark datasets with di erent embedding size α.e red solid line with triangles represents the numbers of HEM pm ; the blue, green and cyan dashed lines with circles, squares and pentagons are results for LSE, QL and UQL respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics for the 5-core data for Electronics, Kindle Store, CDs &amp; Vinyl and Cell Phones &amp; Accessories [18].</figDesc><table><row><cell></cell><cell>Electronics</cell><cell>Kindle Store</cell><cell>CDs &amp; Vinyl</cell><cell>Cell Phones &amp; Accessories</cell></row><row><cell>Corpus</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Number of reviews</cell><cell>1,689,188</cell><cell>982,618</cell><cell>1,097,591</cell><cell>194,439</cell></row><row><cell>Review length</cell><cell>118.27±158.12</cell><cell>112.21±129.52</cell><cell>174.57±177.05</cell><cell>93.50±131.65</cell></row><row><cell>Number of items</cell><cell>63,001</cell><cell>61,934</cell><cell>64,443</cell><cell>10,429</cell></row><row><cell>Review per item</cell><cell>26.81±75.82</cell><cell>15.87±21.42</cell><cell>17.03±28.15</cell><cell>18.64±34.24</cell></row><row><cell>Number of users</cell><cell>192,403</cell><cell>68,223</cell><cell>75,258</cell><cell>27,879</cell></row><row><cell>Review per user</cell><cell>8.78±8.26</cell><cell>14.40±24.61</cell><cell>14.58±39.13</cell><cell>6.97±4.55</cell></row><row><cell>eries</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Number of queries</cell><cell>989</cell><cell>4,603</cell><cell>694</cell><cell>165</cell></row><row><cell>ery length</cell><cell>6.40±1.64</cell><cell>7.07±1.89</cell><cell>5.71±1.62</cell><cell>5.93±1.57</cell></row><row><cell>eries per item</cell><cell>1.02±0.23</cell><cell>5.08±2.04</cell><cell>4.04±1.92</cell><cell>1.11±0.38</cell></row><row><cell>eries per user</cell><cell>8.13±5.84</cell><cell>35.65±37.48</cell><cell>21.75±16.53</cell><cell>4.95±2.60</cell></row><row><cell>Train/Test</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Number of reviews</cell><cell>1,275,432/413,756</cell><cell>720,006/262,612</cell><cell>804,090/293,501</cell><cell>150,048/44,391</cell></row><row><cell>Number of queries</cell><cell>904/85</cell><cell>3313/1290</cell><cell>534/160</cell><cell>134/31</cell></row><row><cell>Number of user-query pairs</cell><cell>1,204,928/5,505</cell><cell>1,490,349/232,668</cell><cell>1,287,214/45,490</cell><cell>114,177/665</cell></row><row><cell>Relevant items per pairs</cell><cell cols="3">1.12±0.48/1.01±0.09 1.87±3.30/1.48±1.94 2.57±6.59/1.30±1.19</cell><cell>1.52±1.13/1.00±0.05</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Example queries extracted following the paradigm proposed by Gysel et al.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>As shown inTable 3, the overall performance of baselines and our models varies considerably on di erent product datasets. According to the results for baseline models (QL, UQL and LSE), Electronics and Cell Phones &amp; Accessories are "easy" datasets while Kindle Store and CDs &amp; Vinyl are "hard" datasets. Empirically, there are multiple reasons that make Electronics and Cell Phones &amp; Accessories much easier then Kindle Store and CDs &amp; Vinyl in personalized product search. From the perspective of data content, Kindle Store and CDs &amp; Vinyl contain items about books and music while Electronics and Cell Phones &amp; Accessories consist of items about electronic devices. e tastes of books and music are more personal and di cult to capture compared to electronic devices. Also, the average reviews per item in Kindle Store and CDs &amp; Vinyl are lower (15.87 and 17.03) than those in Electronics and Cell Phones &amp; Accessories (26.81 and 18.64), which makes the modeling of items less adequate in both baselines and our models. From the perspective of queries, most items in Electronics and Cell Phones &amp; Accessories are related only to 1 query while items in Kindle Store and CDs &amp; Vinyl are related to 4 or 5 queries on average. For each user, there are more items that belong to the same queries but haven't been purchased in Kindle Store and CDs &amp; Vinyl.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Kindle Store</cell><cell></cell><cell></cell><cell>CDs &amp; Vinyl</cell><cell></cell><cell cols="3">Cell Phones &amp; Accessories</cell></row><row><cell>Model</cell><cell>MAP</cell><cell>MRR</cell><cell>NDCG</cell><cell>MAP</cell><cell>MRR</cell><cell>NDCG</cell><cell>MAP</cell><cell>MRR</cell><cell>NDCG</cell><cell>MAP</cell><cell>MRR</cell><cell>NDCG</cell></row><row><cell>QL</cell><cell>0.289  †</cell><cell>0.289  †</cell><cell>0.316  †</cell><cell>0.011  †</cell><cell>0.012  †</cell><cell>0.013  †</cell><cell>0.009</cell><cell>0.011</cell><cell>0.010</cell><cell>0.081</cell><cell>0.081</cell><cell>0.092</cell></row><row><cell>UQL</cell><cell>0.289  †</cell><cell>0.289  †</cell><cell>0.316  †</cell><cell>0.014  *  †</cell><cell>0.016  *  †</cell><cell>0.019  *  †</cell><cell>0.018  *</cell><cell>0.021  *</cell><cell>0.021  *</cell><cell>0.081</cell><cell>0.081</cell><cell>0.092</cell></row><row><cell>LSE</cell><cell>0.233</cell><cell>0.234</cell><cell>0.239</cell><cell>0.006</cell><cell>0.007</cell><cell>0.007</cell><cell>0.018  *</cell><cell>0.022  *</cell><cell>0.020  *</cell><cell>0.098  * +</cell><cell>0.098  * +</cell><cell>0.084</cell></row><row><cell>HEM me an</cell><cell>0.071</cell><cell>0.071</cell><cell>0.091</cell><cell>0.015  * + †</cell><cell>0.019  * + †</cell><cell>0.018  *  †</cell><cell>0.029  * + †</cell><cell>0.035  * + †</cell><cell>0.034  * + †</cell><cell>0.047</cell><cell>0.047</cell><cell>0.053</cell></row><row><cell>HEM pm</cell><cell cols="3">0.308  * + † 0.309  * + † 0.329  †</cell><cell>0.029  * + †</cell><cell>0.035  * + †</cell><cell>0.033  * + †</cell><cell cols="3">0.034  * + † 0.040  * + † 0.040  * + †</cell><cell cols="3">0.124  * + 0.124  * + 0.153  * + †</cell></row><row><cell>HEM R N N</cell><cell>0.198</cell><cell>0.198</cell><cell>0.214</cell><cell cols="3">0.033  * + † 0.039  * + † 0.038  * + †</cell><cell>0.023  * + †</cell><cell>0.027  * + †</cell><cell>0.026  * + †</cell><cell>0.053</cell><cell>0.053</cell><cell>0.071</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>h ps://www.readycloud.com/info/ecommerce-statistics-all-retailers-should-know Session 6A: Personalization and Privacy SIGIR'17, August 7-11,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2017, Shinjuku, Tokyo, Japan</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>h p://jmcauley.ucsd.edu/data/amazon/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>h ps://ciir.cs.umass.edu/downloads/HEM/ Session 6A: Personalization and Privacy SIGIR'17, August 7-11, 2017, Shinjuku, Tokyo, Japan</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGMENTS</head><p>is work was supported in part by the Center for Intelligent Information Retrieval and in part by NSF IIS-1160894. Any opinions, ndings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily re ect those of the sponsor.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning user interaction models for predicting web search result preferences</title>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ragno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM SIGIR</title>
		<meeting>the 29th ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of the paragraph vector model for information retrieval</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM ICTIR&apos;16</title>
		<meeting>the ACM ICTIR&apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Risteski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03520</idno>
		<title level="m">Rand-walk: A latent variable model approach to word embeddings</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>David M Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01">2003. Jan (2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Microso Cambridge at TREC 14: Enterprise Track</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName><forename type="first">Sco</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American society for information science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">391</biblScope>
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mining Coordinated Intent Representation for Entity Search and Recommendation</title>
		<author>
			<persName><forename type="first">Huizhong</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM CIKM</title>
		<meeting>the 24th ACM CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A probabilistic mixture model for mining and analyzing product search log</title>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Huizhong Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinxing</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Ga Ani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM CIKM</title>
		<meeting>the 22nd ACM CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2179" to="2188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Supporting keyword search in product database: a probabilistic approach</title>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Huizhong Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinxing</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Ga Ani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1786" to="1797" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Personalized Search: Potential and Pitfalls</title>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In NTCIR</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM CIKM</title>
		<meeting>the 25th ACM CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGIR</title>
		<meeting>the 22nd ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">e e ectiveness of Web search engines for retrieving relevant ecommerce links</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><forename type="middle">R</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><surname>Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1075" to="1098" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName><forename type="first">Le</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural word embedding as implicit matrix factorization</title>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-facet product information search and retrieval using semantically annotated product family ontology</title>
		<author>
			<persName><forename type="first">Soon</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnson</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wing</forename><surname>Bun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="479" to="493" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Inferring networks of substitutable and complementary products</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD</title>
		<meeting>the 21th ACM SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Targe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th ACM SIGIR</title>
		<meeting>the 38th ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
	<note>Qinfeng Shi, and Anton van den Hengel</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">E cient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Enhancing collaborative web search with personalization: groupization, smart spli ing, and group hit-highlighting</title>
		<author>
			<persName><forename type="first">Meredith</forename><surname>Ringel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morris</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Bush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM conference on Computer supported cooperative work</title>
		<meeting>the 2008 ACM conference on Computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="481" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Product retrieval for grocery stores</title>
		<author>
			<persName><forename type="first">Eemil</forename><surname>Pe Eri Nurmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wray</forename><surname>Lagerspetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrik</forename><surname>Buntine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joonas</forename><surname>Floréen</surname></persName>
		</author>
		<author>
			<persName><surname>Kukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM SIGIR</title>
		<meeting>the 31st ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="781" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Experiments with Language Models for Known-Item Finding of E-mail Messages</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>In TREC</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval</title>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinying</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rabab</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on ASLP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="694" to="707" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A language modeling approach to information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM SIGIR</title>
		<meeting>the 21st ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Product search in e-shopping: a review and research propositions</title>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Rowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of consumer marketing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="20" to="35" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A comparison of statistical signi cance tests for information retrieval evaluation</title>
		<author>
			<persName><forename type="first">James</forename><surname>Mark D Smucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName><surname>Cartere E</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM CIKM</title>
		<meeting>the sixteenth ACM CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">To personalize or not to personalize: modeling queries with variation in user intent</title>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Liebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM SIGIR</title>
		<meeting>the 31st ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning latent vector spaces for product search</title>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Van Gysel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM CIKM</title>
		<meeting>the 25th ACM CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th ACM SIGIR</title>
		<meeting>the 38th ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="363" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Estimating embedding vectors for queries</title>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM ICTIR&apos;16</title>
		<meeting>the ACM ICTIR&apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="123" to="132" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
