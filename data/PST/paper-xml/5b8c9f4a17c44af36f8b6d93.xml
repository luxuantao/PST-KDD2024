<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Very Brief Introduction to Machine Learning With Applications to Communication Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Osvaldo</forename><surname>Simeone</surname></persName>
						</author>
						<title level="a" type="main">A Very Brief Introduction to Machine Learning With Applications to Communication Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A3CEFD0C69C85B631E9F50E7E48CCF9D</idno>
					<idno type="DOI">10.1109/TCCN.2018.2881442</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCCN.2018.2881442, IEEE Transactions on Cognitive Communications and Networking</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given the unprecedented availability of data and computing resources, there is widespread renewed interest in applying data-driven machine learning methods to problems for which the development of conventional engineering solutions is challenged by modelling or algorithmic deficiencies. This tutorial-style paper starts by addressing the questions of why and when such techniques can be useful. It then provides a high-level introduction to the basics of supervised and unsupervised learning. For both supervised and unsupervised learning, exemplifying applications to communication networks are discussed by distinguishing tasks carried out at the edge and at the cloud segments of the network at different layers of the protocol stack, with an emphasis on the physical layer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>After the "AI winter" of the 80s and the 90s, interest in the application of data-driven Artificial Intelligence (AI) techniques has been steadily increasing in a number of engineering fields, including speech and image analysis <ref type="bibr" target="#b0">[1]</ref> and communications <ref type="bibr" target="#b1">[2]</ref>. Unlike the logic-based expert systems that were dominant in the earlier work on AI (see, e.g., <ref type="bibr" target="#b2">[3]</ref>), the renewed confidence in datadriven methods is motivated by the successes of pattern recognition tools based on machine learning. These tools rely on decades-old algorithms, such as backpropagation <ref type="bibr" target="#b3">[4]</ref>, the Expectation Maximization (EM) algorithm <ref type="bibr" target="#b4">[5]</ref>, and Q-learning <ref type="bibr" target="#b5">[6]</ref>, with a number of modern algorithmic advances, including novel regularization techniques and adaptive learning rate schedules (see review in <ref type="bibr" target="#b6">[7]</ref>). Their success is built on the unprecedented availability of data and computing resources in many engineering domains.</p><p>While the new wave of promises and breakthroughs around machine learning arguably falls short, at least for now, of the requirements that drove early AI research <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, learning algorithms have proven to be useful in a number of important applications -and more is certainly on the way. <ref type="bibr">King</ref> This paper provides a very brief introduction to key concepts in machine learning and to the literature on machine learning for communication systems. Unlike other review papers such as <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>, the presentation aims at highlighting conditions under which the use of machine learning is justified in engineering problems, as well as specific classes of learning algorithms that are suitable for their solution. The presentation is organized around the description of general technical concepts, for which an overview of applications to communication networks is subsequently provided. These applications are chosen to exemplify general design criteria and tools and not to offer a comprehensive review of the state of the art and of the historical progression of advances on the topic.</p><p>We proceed in this section by addressing the question "What is machine learning?", by providing a taxonomy of machine learning methods, and by finally considering the question "When to use machine learning?".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. What is Machine Learning?</head><p>In order to fix the ideas, it is useful to introduce the machine learning methodology as an alternative to the conventional engineering approach for the design of an algorithmic solution. As illustrated in Fig. <ref type="figure" target="#fig_1">1</ref>(a), the conventional engineering design flow starts with the acquisition of domain knowledge: The problem of interest is studied in detail, producing a mathematical model that capture the physics of the set-up under study. Based on the model, an optimized algorithm is produced that offers performance guarantees under the assumption that the given physics-based model is an accurate representation of reality.</p><p>As an example, designing a decoding algorithm for a wireless fading channel under the conventional engineering approach would require the development, or the selection, of a physical model for the channel connecting transmitter and receiver. The solution would be obtained by tackling an optimization problem, and it would yield optimality guarantees under the given channel model. Typical example of channel models include Gaussian and fading channels (see, e.g., <ref type="bibr" target="#b11">[12]</ref>).  In contrast, in its most basic form, the machine learning approach substitutes the step of acquiring domain knowledge with the potentially easier task of collecting a sufficiently large number of examples of desired behaviour for the algorithm of interest. These examples constitute the training set. As seen in Fig. <ref type="figure" target="#fig_1">1(b)</ref>, the examples in the training set are fed to a learning algorithm to produce a trained "machine" that carries out the desired task. Learning is made possible by the choice of a set of possible "machines", also known as the hypothesis class, from which the learning algorithm makes a selection during training. An example of an hypothesis class is given by a neural network architecture with learnable synaptic weights. Learning algorithms are generally based on the optimization of a performance criterion that measures how well the selected "machine" matches the available data.</p><p>For the problem of designing a channel decoder, a machine learning approach can hence operate even in the absence of a well-established channel model. It is in fact enough to have a sufficiently large number of examples of received signals -the inputs to the decoding machine -and transmitted messages -the desired outputs of the decoding machine -to be used for the training of a given class of decoding functions <ref type="bibr" target="#b12">[13]</ref>. Moving beyond the basic formulation described above, machine learning tools can integrate available domain knowledge in the learning process. This is indeed the key to the success of machine learning tools in a number of applications. A notable example is image processing, whereby knowledge of the translational invariance of visual features is reflected in the adoption of convolutional neural networks as the hypothesis class to be trained. More generally, as illustrated in Fig. <ref type="figure" target="#fig_2">2</ref>, domain knowledge can dictate the choice of a specific hypothesis class for use in the training process. Examples of applications of this idea to communication systems, including to the problem of decoding, will be discussed later in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Taxonomy of Machine Learning Methods</head><p>There are three main classes of machine learning techniques, as discussed next.</p><p>• Supervised learning: In supervised learning, the training set consists of pairs of input and desired output, and the goal is that of learning a mapping between input and output spaces. As an illustration, in Fig. <ref type="figure" target="#fig_3">3</ref>(a), the inputs are points in the twodimensional plane, the outputs are the labels assigned to each input (circles or crosses), and the goal is to learn a binary classifier. Applications include the channel decoder discussed above, as well as email spam classification on the basis of examples of spam/ non-spam emails. • Unsupervised learning: In unsupervised learning, the training set consists of unlabelled inputs, that is, of inputs without any assigned desired output. For instance, in Fig. <ref type="figure" target="#fig_3">3</ref>(b), the inputs are again points in the two-dimensional plane, but no indication is provided by the data about the corresponding desired output. Unsupervised learning generally aims at discovering properties of the mechanism generating the data. In the example of Fig. <ref type="figure" target="#fig_3">3</ref>(b), the goal of unsupervised learning is to cluster together input points that are close to each other, hence assigning a label -the cluster index -to each input point (clusters are delimited by dashed lines).</p><p>Applications include clustering of documents with similar topics. It is emphasized that clustering is only one of the learning tasks that fall under the category of unsupervised learning (see Sec. V). • Reinforcement learning: Reinforcement learning lies, in a sense, between supervised and unsupervised learning. Unlike unsupervised learning, some form of supervision exists, but this does not come in the form of the specification of a desired output for every input in the data. Instead, a reinforcement learning algorithm receives feedback from the environment only after selecting an output for a given input or observation. The feedback indicates the degree to which the output, known as action in reinforcement learning, fulfils the goals of the learner. Reinforcement learning applies to sequential decision making problems in which the learner interacts with an environment by sequentially taking actions -the outputs -on the basis of its observationsits inputs -while receiving feedback regarding each selected action. Most current machine learning applications fall in the supervised learning category, and hence aim at learning an existing pattern between inputs and outputs. Supervised learning is relatively well-understood at a theoretical level <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, and it benefits from wellestablished algorithmic tools. Unsupervised learning has so far defied a unified theoretical treatment <ref type="bibr" target="#b15">[16]</ref>. Nevertheless, it arguably poses a more fundamental practical problem in that it directly tackles the challenge of learning by direct observation without any form of explicit feedback. Reinforcement learning has found extensive applications in problems that are characterized by clear feedback signals, such as win/lose outcomes in games, and that entail searches over large trees of possible action-observation histories <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>This paper only covers supervised and unsupervised learning. Reinforcement learning requires a different analytical framework grounded in Markov Decision Processes and will not be discussed here (see <ref type="bibr" target="#b16">[17]</ref>). For a broader discussion on the technical aspects of supervised and unsupervised learning, we point to <ref type="bibr" target="#b18">[19]</ref> and references therein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. When to Use Machine Learning?</head><p>Based on the discussion in Sec. I-A, the use of a machine learning approach in lieu of a more conventional engineering design should be justified on a case-bycase basis on the basis of its suitability and potential advantages. The following criteria, inspired by <ref type="bibr" target="#b19">[20]</ref>, offer useful guidelines on the type of engineering tasks that can benefit from the use of machine learning tools. 1. The traditional engineering flow is not applicable or is undesirable due to a model deficit or to an algorithm deficit <ref type="bibr" target="#b20">[21]</ref>.</p><p>• With a model deficit, no physics-based mathematical models exist for the problem due to insufficient domain knowledge. As a result, a conventional model-based design is inapplicable.</p><p>• With an algorithm deficit, a well-established mathematical model is available, but existing algorithms optimized on the basis of such model are too complex to be implemented for the given application.</p><p>In this case, the use of hypothesis classes including efficient "machines", such as neural network of limited size or with tailored hardware implementations (see, e.g., <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> and references therein), can yield lower-complexity solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>A sufficiently large training data sets exist or can be created.</p><p>3. The task does not require the application of logic, common sense, or explicit reasoning based on background knowledge.</p><p>4. The task does not require detailed explanations for how the decision was made. The trained machine is by and large a black box that maps inputs to outputs. As such, it does not provide direct means to ascertain why a given output has been produced in response to an input, although recent research has made some progress on this front <ref type="bibr" target="#b23">[24]</ref>. This contrasts with engineered optimal solutions, which can be typically interpreted on the basis of physical performance criteria. For instance, a maximum likelihood decoder chooses a given output because it minimizes the probability of error under the assumed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>The phenomenon or function being learned is stationary for a sufficiently long period of time. This is in order to enable data collection and learning.</p><p>6. The task has either loose requirement constraints, or, in the case of an algorithm deficit, the required performance guarantees can be provided via numerical simulations. With the conventional engineering approach, theoretical performance guarantees can be obtained that are backed by a physics-based mathematical model. These guarantees can be relied upon insofar as the model is trusted to be an accurate representation of reality. If a machine learning approach is used to address an algorithm deficit and a physics-based model is available, then numerical results may be sufficient in order to compute satisfactory performance measures. In contrast, weaker guarantees can be offered by machine learning in the absence of a physics-based model. In this case, one can provide performance bounds only under the assumptions that the hypothesis class is sufficiently general to include "machines" that can perform well on the problem and that the data is representative of the actual data distribution to be encountered at runtime (see, e.g., <ref type="bibr">[19][Ch. 5]</ref>). The selection of a biased hypothesis class or the use of an unrepresentative data set may hence yield strongly suboptimal performance. We will return to these criteria when discussing applications to communication systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MACHINE LEARNING FOR COMMUNICATION NETWORKS</head><p>In order to exemplify applications of supervised and unsupervised learning, we will offer annotated pointers to the literature on machine learning for communication systems. Rather than striving for a comprehensive, and historically minded, review, the applications and references have been selected with the goal of illustrating key aspects regarding the use of machine learning in engineering problems. Throughout, we focus on tasks carried out at the network side, rather than at the users, and organize the applications along two axes. On one, with reference to Fig. <ref type="figure" target="#fig_4">4</ref>, we distinguish tasks that are carried out at the edge of the network, that is, at the base stations or access points and at the associated computing platforms, from tasks that are instead responsibility of a centralized cloud processor connected to the core network (see, e.g., <ref type="bibr" target="#b24">[25]</ref>). The edge operates on the basis of timely local information collected at different layers of the protocol stack, which may include all layers from the physical up to the application layer. In contrast, the centralized cloud processes longer-term and global information collected from multiple nodes in the edge network, which typically encompasses only the higher layers of the protocol stack, namely networking and application layers. Examples of data that may be available at the cloud and at the edge can be found in Table <ref type="table">I</ref> and Table <ref type="table">II</ref>, respectively.</p><p>As a preliminary discussion, it is useful to ask which tasks of a communication network, if any, may benefit from machine learning through the lens of the criteria reviewed in Sec. I-C. First, as seen, there should be either a model deficit or an algorithm deficit that prevents the use of a conventional model-based engineering design. As an example of model deficit, proactive resource allocation that is based on predictions of human behaviour, e.g., for caching popular contents, may not benefit from wellestablished and reliable models, making a data-driven approach desirable (see, e.g., <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>). For an instance of algorithm deficit, consider the problem of channel decoding for channels with known and accurate models based on which the maximum likelihood decoder entails an excessive complexity.</p><p>Assuming that the problem at hand is characterized by model or algorithm deficits, one should then consider the rest of the criteria discussed in Sec. I-C. Most are  The remaining two criteria need to be checked on a case-by-case basis. First, the phenomenon or function being learned should not change too rapidly over time. For example, designing a channel decoder based on samples obtained from a limited number of realizations of a given propagation channel requires the channel is stationary over a sufficiently long period of time (see <ref type="bibr" target="#b27">[28]</ref>).</p><p>Second, in the case of a model deficit, the task should have some tolerance for error in the sense of not requiring provable performance guarantees. For instance, the performance of a decoder trained on a channel lacking a well-established channel model, such as a biological communication link, can only be relied upon insofar as one trusts the available data to be representative of the complete set of possible realizations of the problem under study. Alternatively, under an algorithm deficit, a physics-based model, if available, can be possibly used to carry out computer simulations and obtain numerical performance guarantees.</p><p>In Sec. IV and Sec. VI, we will provide some pointers to specific applications to supervised and unsupervised learning, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SUPERVISED LEARNING</head><p>As introduced in Sec. I, supervised learning aims at discovering patterns that relate inputs to outputs on the basis of a training set of input-output examples. We can distinguish two classes of supervised learning problems depending on whether the outputs are continuous or discrete variables. In the former case, we have a regression problem, while in the latter we have a classification problem. We discuss the respective goals of the two problems next. This is followed by a formal definition of classification and regression, and by a discussion of the methodology and of the main steps involved in tackling the two classes of problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Goals</head><p>As illustrated in Fig. <ref type="figure">5</ref>, in a regression problem, we are given a training set D of N training points (x n , t n ), with n = 1, ..., N , where the variables x n are the inputs, also known as covariates, domain points, or explanatory variables; while the variables t n are the outputs, also known as dependent variables, labels, or responses. In regression, the outputs are continuous variables. The problem is to predict the output t for a new, that is, as of yet unobserved, input x.</p><p>As illustrated in Fig. <ref type="figure">6</ref>, classification is similarly defined with the only caveat that the outputs t are discrete variables that take a finite number of possible values. The value of the output t for a given input x indicates the class to which x belongs. For instance, the label t is a binary variable as in Fig. <ref type="figure">6</ref> for a binary classification problem. Based on the training set D, the goal is to predict the label, or the class, t for a new, as of yet unobserved, input x.</p><p>To sum up, the goal of both regression and classification is to derive from the training data set D a predictor t(x) that generalizes the input-output mapping in D to inputs x that are not present in D. As such, learning is markedly distinct from memorizing: while memorizing would require producing a value t n for some recorded input x n in the training set, learning is about generalization from the data set to the rest of the relevant input space.</p><p>The problem of extrapolating a predictor from the training set is evidently impossible unless one is willing to make some assumption about the underlying inputoutput mapping. In fact, the output t may well equal any value for an unobserved x if nothing else is specified about the problem. This impossibility is formalized by the no free-lunch theorem: without making assumptions about the relationship between input and output, it is not possible to generalize the available observations outside the training set <ref type="bibr" target="#b13">[14]</ref>. The set of assumptions made in order to enable learning are known as inductive bias.</p><p>As an example, for the regression problem in Fig. <ref type="figure">5</ref>, a possible inductive bias is to postulate that the inputoutput mapping is a polynomial function of some order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Defining Supervised Learning</head><p>Having introduced the goal of supervised learning, we now provide a more formal definition of the problem. Throughout, we use Roman font to denote random variables and the corresponding letter in regular font for realizations.</p><p>As a starting point, we assume that the training set D is generated as</p><formula xml:id="formula_0">(x n , t n ) ∼ i.i.d. p(x, t), n = 1, ..., N ,<label>(1)</label></formula><p>that is, each training sample pair (x n , t n ) is generated from the same true joint distribution p(x, t) and the sample pairs are independent identically distributed (i.i.d.).</p><p>As discussed, based on the training set D, we wish to obtain a predictor t(x) that performs well on any possible relevant input x. This requirement is formalized by imposing that the predictor is accurate for any test pair (x, t) ∼ p(x, t), which is generated independently of all the pairs in the training set D.</p><p>The quality of the prediction t(x) for a test pair (x, t) is measured by a given loss function (t, t) as (t, t(x)). Typical examples of loss functions include the quadratic loss (t, t) = (t -t) 2 for regression problems; and the error rate (t, t) = 1(t = t), which equals 1 when the prediction is incorrect, i.e., t = t, and 0 otherwise, for classification problems.</p><p>The formal goal of learning is that of minimizing the average loss on the test pair, which is referred to as the generalization loss. For a given predictor t, this is defined as</p><formula xml:id="formula_1">L p ( t) = E (x,t)∼p(x,t) [ (t, t(x))].<label>(2)</label></formula><p>The generalization loss (2) is averaged over the distribution of the test pair (x, t). Before moving on to the solution of the problem of minimizing the generalization loss, we mention that the formulation provided here is only one, albeit arguably the most popular, of a number of alternative formulations of supervised learning. The frequentist framework described above is in fact complemented by other viewpoints, including Bayesian and Minimum Description Length (MDL) (see <ref type="bibr" target="#b18">[19]</ref> and references therein).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. When The True Distribution p(x, t) is Known: Inference</head><p>Consider first the case in which the true joint distribution p(x, t) relating input and output is known. This scenario can be considered as an idealization of the situation resulting from the conventional engineering design flow when the available physics-based model is accurate (see Sec. I). Under this assumption, the data set D is not necessary, since the mapping between input and output is fully described by the distribution p(x, t).</p><p>If the true distribution p(x, t) is known, the problem of minimizing the generalization loss reduces to a standard inference problem, i.e., an estimation problem in a regression set-up, in which the outputs are continuous variables, or a detection problem in a classification setup, in which the outputs are finite discrete variables.</p><p>In an inference problem, the optimal predictor t can be directly computed from the posterior distribution</p><formula xml:id="formula_2">p(t|x) = p(x, t) p(x) ,<label>(3)</label></formula><p>where p(x) is the marginal distribution of the input x. The latter can be computed from the joint distribution p(x, t) by summing or integrating out all the values of t.</p><p>In fact, given a loss function (t, t), the optimal predictor for any input x is obtained as</p><formula xml:id="formula_3">t * (x) = arg min t E t∼p(t|x) [ (t, t)|x].<label>(4)</label></formula><p>In words, the optimal predictor t * (x) is obtained by identifying the value (or values) of t that minimizes the average loss, where the average is taken with respect to the posterior distribution p(t|x) of the output given the input. Given that the posterior p(t|x) yields the optimal predictor, it is also known as the true predictive distribution.</p><p>The optimal predictor (4) can be explicitly evaluated for given loss functions. For instance, for the quadratic loss, which is typical for regression, the optimal predictor is given by the mean of the predictive distribution, or the posterior mean, i.e.,</p><formula xml:id="formula_4">t * (x) = E t∼p(t|x) [t|x],<label>(5)</label></formula><p>while, with the error rate loss, which is typical for classification, problems, the optimal predictor is given by the maximum of the predictive distribution, or the maximum a posteriori (MAP) estimate, i.e.,</p><formula xml:id="formula_5">t * (x) = arg max t p(t|x).<label>(6)</label></formula><p>For a numerical example, consider binary inputs and outputs and the joint distribution p(x, t) such that p(0, 0) = 0.05, p(0, 1) = 0.45, p(1, 0) = 0.4 and p(1, 1) = 0.1. The predictive distribution for input x = 0 is then given as p(t = 1|x = 0) = 0.9, and hence we have the optimal predictor given by the average t * (x = 0) = 0.9 × 1 + 0.1 × 0 = 0.9 for the quadratic loss, and by the MAP solution t * (x = 0) = 1 for the error rate loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. When the True Distribution p(x, t) is Not Known: Machine Learning</head><p>Consider now the case of interest in which domain knowledge is not available and hence the true joint distribution is unknown. In such a scenario, we have a learning problem and we need to use the examples in the training set D in order to obtain a meaningful predictor that approximately minimizes the generalization loss. At a high level, the methodology applied by machine learning follows three main steps, which are described next.</p><p>1. Model selection (inductive bias): As a first step, one needs to commit to a specific class of hypotheses that the learning algorithm may choose from. The hypothesis class is also referred to as model. The selection of the hypothesis class characterizes the inductive bias mentioned above as a pre-requisite for learning. In a probabilistic framework, the hypothesis class, or model, is defined by a family of probability distributions parameterized by a vector θ. Specifically, there are two main ways of specifying a parametric family of distributions as a model for supervised learning:</p><p>• Generative model: Generative models specify a family of joint distributions p(x, t|θ); • Discriminative model: Discriminative models parameterize directly the predictive distribution as p(t|x, θ).</p><p>Broadly speaking, discriminative models do not make any assumptions about the distribution of the inputs x and hence may be less prone to bias caused by a misspecification of the hypothesis class. On the flip side, generative models may be able to capture more of the structure present in the data and consequently improve the performance of the predictor <ref type="bibr" target="#b28">[29]</ref>. For both types of models, the hypothesis class is typically selected from a common set of probability distributions that lead to efficient learning algorithms in Step 2. Furthermore, any available basic domain knowledge can be in principle incorporated in the selection of the model (see also Sec. VII).</p><p>2. Learning: Given data D, in the learning step, a learning criterion is optimized in order to obtain the parameter vector θ and identify a distribution p(x, t|θ) or p(t|x, θ), depending on whether a generative or discriminative model was selected at Step 1.</p><p>3. Inference: In the inference step, the learned model is used to obtain the predictor t(x) by using ( <ref type="formula" target="#formula_3">4</ref>) with the learned model in lieu of the true distribution. Note that generative models require the calculation of the predictive distribution p(t|x) via marginalization, while discriminative models provide directly the predictive distribution. As mentioned, the predictor should be evaluated on test data that is different from the training set D. As we will discuss, the design cycle typically entails a loop between validation of the predictor at Step 3 and model selection at Step 1.</p><p>The next examples illustrate the three steps introduced above for a binary classification problem.</p><p>Example 1: Consider a binary classification problem in which the input is a generic D-dimensional vector x = [x 1 , ..., x D ] T and the output is binary, i.e., t ∈ {0, 1}. The superscript "T " represents transposition. In</p><p>Step 1, we select a model, that is, a parameterized family of distributions. A common choice is given by logistic regression <ref type="foot" target="#foot_0">1</ref> , which is a discriminative model whereby the predictive distribution p(t|x, θ) is parameterized as illustrated in Fig. <ref type="figure">7</ref>. The model first computes</p><formula xml:id="formula_6">D fixed features φ(x) = [φ 1 (x) • • • φ D (x)]</formula><p>T of the input, where a feature is a function of the data. Then, it computes the predictive probability as</p><formula xml:id="formula_7">p(t = 1|x, w) = σ(w T φ(x)), (<label>7</label></formula><formula xml:id="formula_8">)</formula><p>where w is the set of learnable weights -i.e., the parameter θ defined above -and σ(a) = (1 + exp(-a)) -1 is the sigmoid function.</p><p>Under logistic regression, the probability that the label is t = 1 increases as the linear combination of features becomes more positive, and we have p(t = 1|x, w) &gt; 0.5 for w T φ(x) &gt; 0. Conversely, the probability that the label is t = 0 increases as the linear combination of features becomes more negative, with p(t = 0|x, w) &gt; 0.5 for w T φ(x) &lt; 0. As a specific instance of this problem, if we wish to classify emails between spam and non-spam ones, possible useful features may count the number of times that certain suspicious words appear in the text.</p><p>Step 2 amounts to the identification of the weight vector w on the basis of the training set D with the ideal goal of minimizing the generalization loss (2). This step will be further discussed in the next subsection. Finally, in Step 3, the optimal predictor is obtained by assuming that the learned model p(t|x, w) is the true predictive distribution. Assuming an error rate loss function, following the discussion in Sec. III-C, the optimal predictor is given by the MAP choice t * (x) = 1 if w T φ(x) &gt; 0 and t * (x) = 0 otherwise. It is noted that the linear combination w T φ(x) is also known as logit or log-likelihood ratio (LLR). This rule can be seen to correspond to a linear classifier <ref type="bibr" target="#b18">[19]</ref>. The performance Fig. <ref type="figure">7</ref>. An illustration of the hypothesis class p(t|x, w) assumed by logistic regression using a neural network representation: functions φi, with i = 1, ..., D , are fixed and compute features of the input vector x = [x1, ..., xD]. The learnable parameter vector θ here corresponds to the weights w used to linearly combine the features in <ref type="bibr" target="#b6">(7)</ref>.</p><p>of the predictor should be tested on new, test, inputoutput pairs, e.g., new emails in the spam classification example.</p><p>Example 2: Logistic regression requires to specify a suitable vector of features φ(x). As seen in the email spam classification example, this entails the availability of some domain knowledge to be able to ascertain which functions of the input x may be more relevant for the classification task at hand. As discussed in Sec. I, this knowledge may not be available due to, e.g., cost or time constraints. Multi-layer neural networks provide an alternative model choice at Step 1 that obviates the need for hand-crafted features. The model is illustrated in Fig. <ref type="figure">8</ref>. Unlike linear regression, in a multi-layer neural network, the feature vector φ(x) used by the last layer to compute the logit, or LLR, that determines the predictive probability <ref type="bibr" target="#b6">(7)</ref> is not fixed a priori. Rather, the feature vector is computed by the previous layers. To this end, each neuron, represented as a circle in Fig. <ref type="figure">8</ref>, computes a fixed non-linear function, e.g., sigmoid, of a linear combination of the values obtained from the previous layer. The weights of these linear combinations are part of the learnable parameters θ, along with the weights of the last layer. By allowing the weights at all layers of the model to be trained simultaneously, multi-layer neural networks enable the joint learning of the last-layer linear classifier and of the features φ(x) the classifier operates on. As a notable example, deep neural networks are characterized by a large number of intermediate layers that tend to learn increasingly abstract features of the input <ref type="bibr" target="#b6">[7]</ref>.</p><p>In the rest of this section, we first provide some technical details about Step 2, i.e., learning, and then we return to Step 1, i.e., model selection. As it will be seen, this order is dictated by the fact that model selection requires some understanding of the learning process. Fig. <ref type="figure">8</ref>. An illustration of the hypothesis class p(t|x, w) assumed by multi-layer neural networks. The learnable parameter vector θ here corresponds to the weights w L used at the last layer to linearly combine the features φ(x) and the weight matrices W 1 , ..., W L-1 used at the preceding layers in order to compute the feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Learning</head><p>Ideally, a learning rule should obtain a predictor that minimizes the generalization error (2). However, as discussed in Sec. III-C, this task is out of reach without knowledge of the true joint distribution p(x, t). Therefore, alternative learning criteria need to be considered that rely on the training set D rather than on the true distribution.</p><p>In the context of probabilistic models, the most basic learning criterion is Maximum Likelihood (ML). ML selects a value of θ in the parameterized family of models p(x, t|θ) or p(t|x, θ) that is the most likely to have generated the observed training set D. Mathematically, ML solves the problem of maximizing the log-likelihood function maximize ln p(D|θ)</p><p>over θ, where p(D|θ) is the probability of the data set D for a given value of θ. Given the assumption of i.i.d. data points in D (see Sec. III-B), the log-likelihood can be written as</p><formula xml:id="formula_10">ln p(D|θ) = N n=1 ln p(t n |x n , θ),<label>(9)</label></formula><p>where we have used as an example the case of discriminative models. Note that most learning criteria used in practice can be interpreted as ML problems, including the least squares criterion -ML for Gaussian modelsand cross-entropy -ML for categorical models.</p><p>The ML problem (8) rarely has analytical solutions and is typically addressed by Stochastic Gradient Descent (SGD). Accordingly, at each iteration, subsets of examples, also known as mini-batches, are selected from the training set, and the parameter vector is updated in the direction of gradient of the log-likelihood function as evaluated on these examples. The resulting learning rule can be written as</p><formula xml:id="formula_11">θ new ← θ old + γ∇ θ ln p(t n |x n , θ)| θ=θ old , (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where we have defined as γ &gt; 0 the learning rate, and, for simplicity of notation, we have considered a minibatch given by a single example (x n , t n ). It is noted that, with multi-layer neural networks, the computation of the gradient ∇ θ ln p(t n |x n , θ) yields the standard backpropagation algorithm <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b18">[19]</ref>. The learning rate is an example of hyperparameters that define the learning algorithm. Many variations of SGD have been proposed that aim at improving convergence (see, e.g., <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b18">[19]</ref>). ML has evident drawbacks as an indirect means of minimizing the generalization error. In fact, ML only considers the fit of the probabilistic model on the training set without any consideration for the performance on unobserved input-output pairs. This weakness can be somewhat mitigated by regularization <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b18">[19]</ref> during learning and by a proper selection of the model via validation, as discussed in the next subsection. Regularization adds a penalty term to the log-likelihood that depends on the model parameters θ. The goal is to prevent the learned model parameters θ to assume values that are a priori too unlikely and that are hence possible symptoms of overfitting. As an example, for logistic regression, one can add a penalty that is proportional to the norm ||w|| 2 of the weight vector w in order to prevent the weights to assume excessively high values when fitting the data in the learning step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Model Selection</head><p>We now discuss the first, key, step of model selection, which defines the inductive bias adopted in the learning process. In order to illustrate the main ideas, here we study a particular aspect of model selection, namely that of model order selection. To this end, we consider a hierarchical set of models of increasing complexity and we address the problem of selecting (in Step 1) the order, or the complexity, of the specific model to be posited for learning (in Step 2). As an example of model order selection, one may fix a set of models including multilayer networks of varying number of intermediate layers and focus on determining the number of layers. It is emphasized that the scope of model selection goes much beyond model order selection, including the possible incorporation of domain knowledge and the tuning of the hyperparameters of the learning algorithm.</p><p>For concreteness, we focus on the regression problem illustrated in Fig. <ref type="figure">5</ref> and assume a set of discriminative models p(t|x, w) under which the output t is distributed as</p><formula xml:id="formula_13">M m=0 w m x m + N (0, 1). (<label>11</label></formula><formula xml:id="formula_14">) 0 0.2 0.4 0.6 0.8 1 -3 -2 -1 0 1 2 3 = 9 M M= 1 M= 3</formula><p>Fig. <ref type="figure">9</ref>. Training set in Fig. <ref type="figure">5</ref>, along with a predictor trained by using the discriminative model <ref type="bibr" target="#b10">(11)</ref> and ML for different values of the model order M .</p><p>In words, the output t is given by a polynomial function of order M of the input x plus zero-mean Gaussian noise of power equal to one. The learnable parameter vector θ is given by the weights w = [w 0 , ..., w M -1 ] T . Model selection, to be carried out in Step 1, amounts to the choice of the model order M .</p><p>Having chosen M in Step 1, the weights w can be learned in Step 2 using ML, and then the optimal predictor can be obtained for inference in Step 3. Assuming the quadratic loss, the optimal predictor is given by the posterior mean t(x) = M m=0 w m x m for the learned parameters w. This predictor is plotted in Fig. <ref type="figure">9</ref> for different values of M , along with the training set of Fig. <ref type="figure">5</ref>.</p><p>With M = 1, the predictor t(x) is seen to underfit the training data. This is in the sense that the model is not rich enough to capture the variations present in the training data, and, as a result, we obtain a large training loss</p><formula xml:id="formula_15">L D (w) = 1 N N n=1 (t n t(x n )) 2 . (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>The training loss measures the quality of the predictor defined by weights w on the points in the training set. In contrast, with M = 9, the predictor fits well the training data -so much so that it appears to overfit it. In other words, the model is too rich and, in order to account for the observations in the training set, it appears to yield inaccurate predictions outside it. As a compromise between underfitting and overfitting, the selection M = 3 seems to be preferable. As implied by the discussion above, underfitting can be detected by observing solely the training data via the evaluation of the training loss <ref type="bibr" target="#b11">(12)</ref>. In contrast, over-fitting cannot be ascertained on the basis of the training data as it refers to the performance of the predictor outside D. It follows that model selection cannot be carried out by observing only the training set. Rather, some information must be available about the generalization performance of the predictor. This is typically obtained by means of validation. In its simplest instantiation, validation partitions the available data into two sets, a training set D and a validation set. The training set is used for learning as discussed in Sec. III-E, while the validation set is used to estimate the generalization loss. This is done by computing the average in ( <ref type="formula" target="#formula_15">12</ref>) only over the validation set. More sophisticated forms of validation exist, including cross-validation <ref type="bibr" target="#b6">[7]</ref>.</p><p>Keeping some data aside for validation, one can obtain a plot as in Fig. <ref type="figure" target="#fig_7">10</ref>, where the training loss ( <ref type="formula" target="#formula_15">12</ref>) is compared with the generalization loss (2) estimated via validation. The figure allows us to conclude that, when M is large enough, the generalization loss starts increasing, indicating overfitting. Note, in contrast, that underfitting is detectable by observing the training loss. A figure such as Fig. <ref type="figure" target="#fig_7">10</ref> can be used to choose a value of M that approximately minimizes the generalization loss.</p><p>More generally, validation allows for model selection, as well as for the selection of the parameters used by learning the algorithm, such as the learning rate γ in <ref type="bibr" target="#b9">(10)</ref>. To this end, one compares the generalization loss, estimated via validation, for a number of models and then chooses the one with the smallest estimated generalization loss.</p><p>Finally, it is important to remark that the performance of the model selected via validation should be estimated on the basis of a separate data set, typically called the test set. This is because the generalization loss estimated using validation is a biased estimate of the true generalization loss (2) due to the process of model selection. In particular, the loss on the validation set will tend to be small, since the model was selected during validation with the aim of minimizing it. Importantly, the test set should never be used during the three steps that make up the machine learning methodology and should ideally only be used once to test the trained predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. APPLICATIONS OF SUPERVISED LEARNING TO COMMUNICATION SYSTEMS</head><p>In this section, we provide some pointers to existing applications of supervised learning to communication networks. The discussion is organized by following the approach described in Sec. II. Accordingly, we distinguish between tasks carried out at edge and cloud (see  Fig. <ref type="figure" target="#fig_4">4</ref>), as well as at different layers of the protocol stack. We refer to Table <ref type="table">I</ref> and Table <ref type="table">II</ref> for of data types that may be available at the edge and cloud segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. At the Edge</head><p>Consider first tasks to be carried out at the edge, i.e., at the base stations or at the associated edge computing platform.</p><p>1) Physical Layer: For the physical layer, we focus first on the receiver side and then on the transmitter. At the receiver, a central task that can potentially benefit from machine learning is channel detection and decoding. This amounts to a multi-class classification problem, in which the input x is given by the received baseband signal and the output is the label of the correct transmitted message (e.g., the transmitted bits) <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b29">[30]</ref>. When can machine learning help? Recalling the discussion in Sec. II, we should first ask whether a modelling or algorithmic deficit exists. A model deficit may occur when operating over channels that do not have well-established mathematical models, such as for molecular communications <ref type="bibr" target="#b30">[31]</ref>. Algorithm deficit is more common, given that optimal decoders over a number of well-established channel models tend to be computationally complex. This is the case for channels with strong non-linearities, as recognized as early as the nineties in the context of satellite communication <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b31">[32]</ref> and more recently for optical communications <ref type="bibr" target="#b32">[33]</ref>; or for modulation schemes such as continuous phase modulation <ref type="bibr" target="#b33">[34]</ref> -another work from the nineties -or in multi-user networks <ref type="bibr" target="#b34">[35]</ref>.</p><p>Assuming that the problem at hand is characterized by a modelling or algorithmic deficit, then one should also check the remaining criteria listed in Sec. II, particularly those regarding the rate of change of the phenomenon under study and the requirements in terms of performance guarantees. For channel decoding, the presence of fast-varying channels may make the first criterion hard to be satisfied in practice (unless channel estimation is made part of the learning process); while stringent reliability requirements may preclude the use of machine learning in the presence of a model deficit.</p><p>As mentioned, a generally beneficial idea in the use of data-aided methods is that of incorporating domain knowledge in the definition of the hypothesis class. As notable examples related to channel decoding, in <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, knowledge of the near-optimality of message passing methods for the decoding of sparse graphical codes is used to set up a parameterized model that borrows the message passing structure and that is trained to decode more general codes. A related approach is investigated in <ref type="bibr" target="#b37">[38]</ref> for polar codes.</p><p>Another useful idea is that of directly integrating algorithms designed using the standard engineering flow with trained machines. Instances of this idea include <ref type="bibr" target="#b38">[39]</ref> in which a conventional channel decoder is deployed in tandem with a channel equalizer at its input that is trained to compensate for hardware impairments. A related approach is proposed in <ref type="bibr" target="#b39">[40]</ref>, whereby a conventional decoder is implemented within a turbo-like iterative loop with a machine learning-based regressor that has the role of estimating the channel noise.</p><p>Other tasks that can potentially benefit from machine learning at the receiver's side include modulation classification, which is a classification problem justified by the complexity of optimal solutions (algorithm deficit) <ref type="bibr" target="#b40">[41]</ref>; localization, which is a regression problem, typically motivated by the lack of tractable channels for complex propagation environments (model deficit) <ref type="bibr" target="#b41">[42]</ref>; and channel state information-based authentication, a classification problem made difficult by the absence of well-established models relating channel features with devices' identities (model deficit) <ref type="bibr" target="#b42">[43]</ref>.</p><p>Turning to the transmitter side, most emerging applications tackle the algorithmic deficit related to the complexity of the non-convex programs that typically underlie power control and precoding optimization for the downlink. Notably, in <ref type="bibr" target="#b43">[44]</ref>, a training set is obtained by running a non-convex solver to produce an optimized output power vector for given input channels. Note that the approach does not directly optimize the performance criterion of interest, such as the sum-rate. Rather, it relies on the assumption that similar inputsthe channel coefficients -generally yield similar optimal solutions -the power allocation vector. if the analytical model available based on domain knowledge is only a coarse approximation of the physical model, the resulting training set can be used to augment the data in order to carry out a preliminary training of a machine learning model <ref type="bibr" target="#b44">[45]</ref>  <ref type="foot" target="#foot_1">2</ref> .</p><p>For an application at a full-duplex transceiver, we refer to <ref type="bibr" target="#b46">[47]</ref>, which learns to cancel self-interference in order to overcome the lack of well-established models for the transmitter-receiver chain of non-linearities.</p><p>2) Link and Medium Access Control Layers: At the medium access control layer, we highlight some applications of machine learning that tackle the lack of mathematical models for complex access protocols and communication environments. In <ref type="bibr" target="#b47">[48]</ref>, a mechanism is proposed to predict whether a channel decoder will succeed on the basis of the outputs of the first few iterations of the iterative decoding process. This binary is useful in order to request an early retransmission at the link layer using Automatic Retransmission Request (ARQ) or Hybrid ARQ (HARQ) in order to reduce latency. At the medium access control layer, data-aided methods can instead be used to predict the availability of spectrum in the presence of interfering incumbent devices with complex activation patterns for cognitive radio applications <ref type="bibr" target="#b48">[49]</ref> (see also <ref type="bibr" target="#b49">[50]</ref>). An approach that leverages depth images to detect the availability of mmwave channels is proposed in <ref type="bibr" target="#b50">[51]</ref>.</p><p>3) Network and Application Layers: A task that is particularly well-suited for machine learning is the caching of popular contents for reduced latency and network congestion <ref type="bibr" target="#b51">[52]</ref>. Caching may take place at the edge and, more traditionally, within the core network segment. Caching at the edge has the advantage of catering directly to the preference of the local population of users, but it generally suffers from a reduced hit rate due to the smaller available storage capacity. Optimizing the selection of contents to be stored at the edge can be formulated as a classification problem that can benefit from a data-driven approach in order to adapt to the specific features of the local traffic <ref type="bibr" target="#b51">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. At the Cloud</head><p>We now turn to some relevant tasks to be carried out at the cloud at both network and application layers.</p><p>1) Network: The main task of the network layer is routing (see <ref type="bibr" target="#b52">[53]</ref> for further discussion). Considering a software-defined networking implementation, routing requires the availability at a network controller of information regarding the quality of individual communication links in the core network, as well as regarding the status of the queues at the network routers. In the presence of wireless or optical communications, the quality of a link may not be available at the network controller, but it may be predicted using available historical data <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b53">[54]</ref> in the absence of agreed-upon dynamic availability models. In a similar manner, predicting congestion can be framed as a data-aided classification problem <ref type="bibr" target="#b54">[55]</ref>.</p><p>2) Application: Finally, a relevant supervised learning task is that of traffic classification, whereby data streams are classified on the basis of some extracted features, such as packet sizes and inter-arrival times, in terms of their applications, e.g., Voice over IP. <ref type="bibr" target="#b55">[56]</ref> V. UNSUPERVISED LEARNING As introduced in Sec. I, unlike supervised learning, unsupervised learning tasks operate over unlabelled data sets consisting solely of the inputs x n , with n = 1, ..., N , and the general goal is that of discovering properties of the data. We start this section by reviewing some of the typical specific unsupervised learning tasks. We then cover methodology, models, and learning, including advanced methods such as Generative Adversarial Networks (GANs) <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Goals and Definitions</head><p>In unsupervised learning, taking a frequentist formulation (see Sec. III-A), we are given a training set D consisting of N i.i.d. samples x n ∼ p(x) with n = 1, ..., N generated from an unknown true distribution p(x). The high-level goal is that of learning some useful properties of the distribution p(x). More specifically, we can identify the following tasks.</p><p>• Density estimation: Density estimation aims at estimating directly the distribution p(x). This may be useful, for example, for use in plug-in estimators of information-theoretic quantities, for the design of compression algorithms, or to detect outliers; • Clustering: Clustering aims at partitioning all points in the data set D in groups of similar objects, where the notion of similarity is domain-dependent; • Dimensionality reduction, representation, and feature extraction: These three related tasks represent each data point x n in a different space, typically of lower dimensionality, in order to highlight independent explanatory factors and/or to ease visualization, interpretation, or the implementation of successive tasks, e.g., classification; • Generation of new samples: Given the data set D, we wish to learn a machine that produces samples that are approximately distributed according to p(x). As an example, if the data set contains images of celebrities, the idea is to produce plausible images of non-existent celebrities. This can be useful, e.g., to produce artificial scenes for video parameterizes or films. As suggested by the variety of tasks listed above, unsupervised learning does not have a formal unified formulation as supervised learning. Nevertheless, the general methodology follows three main steps in a manner similar to supervised learning (see Sec. III-D). In Step 1 (model selection), a model, or a hypothesis class, is selected, defining the inductive bias of the learning process. This is done by positing family of probability distributions p(x|θ) parameterized by a vector θ. In Step 2 (learning), the data D is used to optimize a learning criterion with the aim of choosing a value for the parameter vector θ. Finally, in Step 3, the trained model is leveraged in order to carry out the task of interest, e.g., clustering or sample generation.</p><p>In the following, we discuss Step 1 (model selection) and Step 2 (learning). For the formulation of specific tasks to be carried out at Step 3, we refer to, e.g., <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b56">[57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Models</head><p>Unsupervised learning models, selected at Step 1 of the machine learning process, typically involve a hidden or latent (vector of) variables z n for each data point x n . For example, in a clustering problem, the latent variable z n represents the cluster index of x n . Latent variables are hidden or unobserved in the sense that they do not appear for any of the data points x n in D. 3 The relationship between latent variables z n and observable variables x n can be modelled in different ways, giving rise to a number of different types of models for unsupervised learning. These are illustrated in Fig. <ref type="figure" target="#fig_8">11</ref> and<ref type="figure">discussed  next</ref>.</p><p>By way of a short round-up of types of models, with reference to Fig. <ref type="figure" target="#fig_8">11</ref>, directed generative models, illustrated by Fig. <ref type="figure" target="#fig_8">11(a)</ref>, posit that there exist hidden causes z yielding the observation x. Undirected generative models, represented in Fig. <ref type="figure" target="#fig_8">11(b</ref>) model the mutual correlation between x and z. Discriminative models, illustrated by Fig. <ref type="figure" target="#fig_8">11(c</ref>) model the extraction of the latent representation z from x. Finally, autoencoders, represented in Fig. <ref type="figure" target="#fig_8">11(d</ref>) assume that x is encoded into a latent representation z in such as way that x can then be approximately recovered from z. In the following, we provide some additional details about directed generative 3 Problems in which some of the inputs in D are labelled by a value zn are filed under the rubric of semi-supervised learning <ref type="bibr" target="#b28">[29]</ref>. models and autoencoders, and we point to <ref type="bibr" target="#b18">[19]</ref> and references therein for a discussion about the remaining models.</p><p>As illustrated in Fig. <ref type="figure" target="#fig_8">11</ref>(a), directed generative models assume that each data point x is caused<ref type="foot" target="#foot_2">4</ref> by a hidden variable z. This is in the sense that the joint distribution p(x, z|θ) is parameterized as p(x, z|θ) = p(z|θ)p(x|z, θ), where p(z|θ) is the distribution of the hidden cause and p(x|z, θ) is the conditional distribution of the data x given the cause z. As a result, under a directed generative model, the distribution of an observation x = x can be written as</p><formula xml:id="formula_17">p(x|θ) = z p(z|θ)p(x|z, θ) = E z∼p(z|θ) [ln p(x|z, θ)],<label>(13)</label></formula><p>where the sum in the second term should be replaced by an integration for continuous hidden variables, and the last equality expresses the marginalization over z as an expectation.</p><p>As an example, for the problem of document clustering, variable x represents a document in the training set and z is interpreted as a latent topic that "causes" the generation of the document. Model selection requires the specification of a parameterized distribution p(z|θ) over the topics, e.g., a categorical distribution with parameters equals to the probability of each possible value, and the distribution p(x|z, θ) of the document given a topic. Basic representatives of directed generative models include mixture of Gaussians and likelihood-free models <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b57">[58]</ref>.</p><p>As represented in Fig. <ref type="figure" target="#fig_8">11(d)</ref>, autoencoders model encoding from data x to hidden variables z, as well as decoding from hidden variables back to data. Accordingly, model selection for autoencoders requires the specification of a parameterized family of encoders p(z|x, θ) and decoders p(x|z, θ). As an example, autoencoders can be used to learn how to compress an input signal x into a representation z in a smaller space so as to ensure that x can be recovered from z within an admissible level of distortion. Representatives of autoencoders, which correspond to choices for the encoder and decoder families of distributions, include Principal Component Analysis (PCA), dictionary learning, and neural networkbased autoencoders <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learning</head><p>We now discuss to be carried out as Step 2.</p><p>For brevity, we focus on directed generative models and refer to <ref type="bibr" target="#b18">[19]</ref> and references therein for a treatment of learning for the other models in Fig. <ref type="figure" target="#fig_8">11</ref>. In this regard, we note that the problem of training autoencoders is akin to supervised learning in the sense that autoencoders specify the desired output for each input in the training set.</p><p>As for supervised learning, the most basic learning criterion for probabilistic models is ML. Following the discussion in Sec. III-E, ML tackles the problem of maximizing the log-likelihood of the data, i.e., maximize θ ln p(x|θ) = ln E z∼p(z|θ) [ln p(x|z, θ)]. <ref type="bibr" target="#b13">(14)</ref> Note that problem <ref type="bibr" target="#b13">(14)</ref> considers only one data point x in the data set for the purpose of simplifying the notation, but in practice the log-likelihood needs to be summed over the N examples in D.</p><p>Unlike the corresponding problem for supervised learning <ref type="bibr" target="#b7">(8)</ref>, the likelihood in ( <ref type="formula">14</ref>) requires an average over the hidden variables. This is because the value of the hidden variables z is not known, and hence the probability of the observation x needs to account for all possible values of z weighted by their probabilities p(z|θ). This creates a number of technical challenges. First, the objective in ( <ref type="formula">14</ref>) is generally more complex to optimize, since the average over z destroys the typical structure of the model p(x|z, θ), whose logarithm is often selected as a tractable function (see, e.g., logistic regression). Second, the average in ( <ref type="formula">14</ref>) cannot be directly approximated using Monte Carlo methods if the goal is to optimize over the model parameters given that the distribution p(z|θ) generally depends on θ itself.</p><p>To tackle these issues, a standard approach is based on the introduction of a variational distribution q(z) over the hidden variables and on the optimization of a tractable lower bound on the log-likelihood known as the Evidence Lower BOund (ELBO). To elaborate, for any fixed value x and any distribution q(z) on the latent variables z (possibly dependent on x), the ELBO L(q, θ) is defined as L(q, θ) = E z∼q(z) [ln p(x|z, θ)]-KL(q(z)||p(z|θ)), <ref type="bibr" target="#b14">(15)</ref> where KL(q||p) = E z∼q(z) [ln(q(z)/p(z))] is the Kullback-Leibler (KL) divergence. The latter is a measure of the distance between the two distributions, as we will further discuss in Sec. V-D (see <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b59">[60]</ref>). The analytical advantages of the ELBO L(q, θ) over the original log-likelihood are that: (i) it entails an expectation of the logarithm of the model p(x|z, θ), which, as mentioned, is typically a tractable function; and (ii) the average is over a fixed distribution q(z), which does not depend on the model parameter θ.</p><p>Using Jensen's inequality, it can be seen that the ELBO ( <ref type="formula">15</ref>) is a global lower bound on the log-likelihood function, that is,</p><formula xml:id="formula_18">ln p(x|θ) ≥ L(q, θ).<label>(16)</label></formula><p>An illustration of the lower bounding property of the ELBO can be found in Fig. <ref type="figure" target="#fig_9">12</ref>. An important feature of this inequality is that the ELBO "touches" the loglikelihood function at values θ 0 , if any, for which the distribution q(z) satisfies the equality q(z) = p(z|x, θ 0 ).</p><p>In words, the ELBO is tight if the variational distribution is selected to equal the posterior distribution of the hidden variables given the observation x under the model parameter θ 0 . Stated less formally, in order to ensure that the ELBO is tight at a value θ 0 , one needs to solve the problem of inferring the distribution of the hidden variables z given the observation x under the model identified by the value θ 0 . The property <ref type="bibr" target="#b15">(16)</ref> leads to the natural idea of the Expectation-Maximization (EM) algorithm as a means to tackle the ML problem. As illustrated in Fig. <ref type="figure" target="#fig_10">13</ref>, EM maximizes the ELBO iteratively, where the ELBO at each iteration is computed to be tight at the current iterate for θ. More formally, the EM algorithm can be summarized as follows <ref type="foot" target="#foot_3">5</ref> . The model vector is initialized to some value θ old and then for each iteration the following two steps are performed. • Expectation, or E, step: For fixed parameter vector θ old , solve the problem maximize q L(q, θ old ).</p><p>The solution of this problem is given by q new (z) = p(z|x, θ old ). In fact, as discussed, the tightest (i.e., largest) value of the ELBO is obtained by choosing the variational distribution q(z) as the posterior of the latent variables under the current model θ old . This step can be interpreted as estimating the latent variables z, via the predictive distribution p(z|x, θ old ), assuming that the current model θ old is correct. • Maximization, or M, step: For fixed variational distribution q new (z), solve the problem</p><formula xml:id="formula_21">maximize θ L(q new , θ) = E z∼q new (z) [ln p(x, z|θ)] .<label>(19)</label></formula><p>This optimization is akin to that carried out in the corresponding supervised learning problem with known latent variables z with the difference that these are randomly selected from the fixed variational distribution q new (z) obtained in the E step. Given that the EM algorithm maximizes at each step a lower bound on the log-likelihood that is tight at the current iterate θ old , EM guarantees decreasing objective values along the iterations, which ensures convergence to a local optimum of the original problem. We refer to <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref> for detailed examples.</p><p>The EM algorithm is generally impractical for largescale problems due to the complexity of computing the posterior of the latent variables in the E step and of averaging over such distribution in the M step. Many state-of-the-art solutions to the problem of unsupervised learning with probabilistic models entail some approximation of the EM algorithm. Notably, the E step can be approximated by parametrizing the variational distribution with some function q(z|ϕ), or q(z|x, ϕ) to include the dependence on x, and by maximizing ELBO over the variational parameters ϕ. This approach underlies the popular variational autoencoder technique <ref type="bibr" target="#b6">[7]</ref>. In the M step, instead, one can approximate the expectation in <ref type="bibr" target="#b18">(19)</ref> using Monte Carlo stochastic approximation based on randomly sampled values of z from the current distribution q(z). Finally, gradient descent can be used to carry out the mentioned optimizations for both E and M steps (see, e.g., <ref type="bibr" target="#b61">[62]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Advanced Learning Methods</head><p>As discussed in the previous section, ML is generally prone to overfitting for supervised learning. For unsupervised learning, the performance of ML depends on the task of interest. For example, consider the tasks of density estimation or of generation of new samples (see Sec. V-A). In order to illustrate some of the typical issues encountered when applying the ML criterion, in Fig. <ref type="figure" target="#fig_11">14</ref> we report a numerical result for a problem in which the true data distribution p(x) is multi-modal and the model distribution p(x|θ) is assumed to be a mixture of Gaussians, i.e., a directed generative model. The ML problem is tackled by using EM based on samples generated from the true distribution (see <ref type="bibr" target="#b18">[19]</ref> for details). The learned distribution is seen to be a rather"blurry" estimate that misses the modes of p(x) in an attempt of being inclusive of the full support of p(x). Being a poor estimate of the true distribution, the learned model can clearly also be problematic for sample generation in the sense that samples generated from the model would tend to be quite different from the data samples. In the rest of this section, we briefly review advanced methods that address this limitation of ML.</p><p>In order to move beyond ML, we first observe that ML can be proven to minimize the KL divergence</p><formula xml:id="formula_22">KL(p D (x)||p(x|θ)) = E z∼pD(x) ln p D (x) p(x|θ)<label>(20)</label></formula><p>between the empirical distribution, or histogram, of the data</p><formula xml:id="formula_23">p D (x) = N [x] N ,<label>(21)</label></formula><p>where N [x] counts the number of occurrences of value x in the data, and the parameterized model distribution p(x|θ). In other words, ML fits the model to the histogram of the data by using the KL divergence as a measure of fitness. Indeed, as mentioned in Sec. V-C, the KL divergence is a quantitative measure of "difference" between two distributions. More precisely, as per <ref type="bibr" target="#b19">(20)</ref>, the KL divergence KL(p||q) quantifies the difference between two distributions p(x) and q(x) by evaluating the average of the LLR ln(p(x)/q(x)) with respect to p(x).</p><p>Consider now the problem illustrated in Fig. <ref type="figure" target="#fig_1">15</ref>, in which a discriminator wishes to distinguish between two hypotheses, namely the hypothesis that the data x is a sample from distribution p(x) and the hypothesis that it is instead generated from q(x). To fix the ideas, one can focus as an example on the case where p(x) and q(x) are two Gaussian distributions with different means. To this end, the discriminator computes a statistic, that is, a function, T (x) of the data x, and then decides for the former hypothesis if T (x) is sufficiently large and for 𝑇(𝑥) 𝑥~𝑝(𝑥) 𝑥~𝑞(𝑥) 𝑝 𝑥 if 𝑇 𝑥 large discriminator 𝑞 𝑥 if 𝑇 𝑥 small Fig. <ref type="figure" target="#fig_1">15</ref>. Discriminator between the hypotheses x ∼ p(x) and x ∼ q(x) based on the statistic T (x). The performance of the optimal discriminator function T (x) under different design criteria yields a measure of the difference between the two distributions. the latter hypothesis otherwise. Intuitively, one should expect that, the more distinct the two distributions p(x) and q(x) are, the easier it is to design a discriminator that is able to choose the correct hypothesis with high probability.</p><p>The connection between the hypothesis testing problem in Fig. <ref type="figure" target="#fig_1">15</ref> and the KL divergence becomes evident if one recalls that the LLR ln(p(x)/q(x)) is known to be the best statistic T (x) in the Neyman-Pearson sense <ref type="bibr" target="#b62">[63]</ref>. The KL divergence is hence associated to a particular way of evaluating the performance of the discriminator between the two distributions. Considering a broader formulation of the problem of designing the discriminator in Fig. <ref type="figure" target="#fig_1">15</ref>, one can generalize the notion of KL divergence to the class of f -divergences. These are defined as</p><formula xml:id="formula_24">D f (p||q) = max T (x) E x∼p(x) [T (x)] -E x∼q(x) [g(T (x))],<label>(22)</label></formula><p>for some concave increasing function g(•). The expression above can be interpreted as measuring the performance of the best discriminator T (x) when the design criterion is given by the right-hand side of <ref type="bibr" target="#b21">(22)</ref>, i.e., E x∼p(x) [T (x)] -E x∼q(x) [g(T (x))], for a given function g(•). Note that this criterion is indeed larger for a discriminator that is able to output a large value of the statistic T (x) under p(x) and a small value under q(x). The KL divergence corresponds to a specific choice of such function (see <ref type="bibr" target="#b18">[19]</ref> for details).</p><p>In order to move beyond ML, one can then consider fitting the model distribution to the data histogram by using a divergence measure that is tailored to the data and that captures the features of the empirical distribution that are most relevant for a given application. Such a divergence measure can be obtained by choosing a suitable function g(•) in <ref type="bibr" target="#b21">(22)</ref> and by optimizing <ref type="bibr" target="#b21">(22)</ref>  </p><formula xml:id="formula_25">E x∼pD(x) [T ϕ (x)] -E x∼p(x|θ) [g(T ϕ (x))].<label>(23)</label></formula><p>This can be famously interpreted as a game between the learner, which optimizes the model parameters θ, and the discriminator, which tries to find the best function T ϕ (x) to distinguish between data and generated samples. The resulting method, known as GAN, has recently led to impressive improvements of ML for sample generation <ref type="bibr" target="#b63">[64]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. APPLICATIONS OF UNSUPERVISED LEARNING TO COMMUNICATION SYSTEMS</head><p>In this section, we highlight some applications of unsupervised learning to communication networks.</p><p>A. At the Edge 1) Physical Layer: Let us first consider some applications of autoencoders at the physical layer as implemented by the network edge nodes. A fundamental idea is to treat the chain of encoder, channel, and decoder in a communication link as an autoencoder, where, with reference to Fig. <ref type="figure" target="#fig_8">11(d)</ref>, the input message is x, the transmitted codewords and received signals represent the intermediate representation z, and the output of the decoder should match the input <ref type="bibr" target="#b29">[30]</ref>. Note that, for this autoencoder, the mapping p(x|z) can only be partially learned, as it includes not only the encoder but also the communication channel, while the conditional distribution p(x|z) defining the decoder can be learned. We should now ask when this viewpoint can be beneficial in light of the criteria reviewed in Sec. I-C.</p><p>To address this question, one should check whether a model or algorithm deficit exists to justify the use of machine learning tools. Training an autoencoder requires the availability of a model for the channel, and hence a model deficit would make this approach inapplicable unless further mechanisms are put in place (see below). Examples of algorithm deficit include channels with complex non-linear dynamical models, such as optical links <ref type="bibr" target="#b64">[65]</ref>; Gaussian channels with feedback, for which optimal practical encoding schemes are not known <ref type="bibr" target="#b65">[66]</ref>; multiple access channels with sparse transmission codes <ref type="bibr" target="#b66">[67]</ref>; and joint source-channel coding <ref type="bibr" target="#b67">[68]</ref>.</p><p>Other applications at the physical layer leverage the use of autoencoders as compressors (see Sec. V-B) or denoisers. For channels with a complex structure with unavailable channel models or with unknown optimal compression algorithms, autoencoders can be used to compress channel state information for the purpose of feedback on frequency-division duplex links <ref type="bibr" target="#b68">[69]</ref>.</p><p>Autoencoders can also be used for their capacity to denoise the input signal by means of filtering through the lower dimensional representation z. This is done in <ref type="bibr" target="#b69">[70]</ref> for the task of localization on the basis of the received baseband signal. To this end, an autoencoder is learned for every reference position in space with the objective of denoising signals received from the given location. At test time, the location that corresponds to the autoencoder with the smallest reconstruction error is taken as an estimate of the unknown transmitting device.</p><p>We now review some applications of the generative models illustrated in Fig. <ref type="figure" target="#fig_8">11(a)</ref>. A natural idea is that of using generative models to learn how to generate samples from a given channel <ref type="bibr" target="#b70">[71]</ref>, <ref type="bibr" target="#b71">[72]</ref>. This approach is sound for scenarios that lack tractable channel models. As a pertinent example, generative models can be used to mimic and identify non-linear channels for satellite communications <ref type="bibr" target="#b1">[2]</ref>. The early works on the subject carried out in the nineties are also notable for the integration of the domain knowledge into the definition of machine learning models (see Sec. IV). In fact, mindful of the strong linear components of the channels, these works posit a learnable model that includes linear filters and non-linearities <ref type="bibr" target="#b1">[2]</ref>.</p><p>Another approach that can be considered as unsupervised was proposed in <ref type="bibr" target="#b72">[73]</ref> in order to solve the challenging problem of power control for interference channels. The approach tackles the resulting algorithm deficit by means of a direct optimization of the sum-rate with the aim of obtaining the power allocation vector (as fractions of the maximal available powers) at the output of a neural network. Related supervised learning methods were discussed in Sec. IV. A similar approach -also based on the idea of directly maximizing the criterion of interest so as to obtain an approximate solution at the output of a neural network -was considered in <ref type="bibr" target="#b73">[74]</ref> for minimum mean squared error channel estimation with non-Gaussian channels, e.g., multi-path channels.</p><p>2) Medium Access Layer: At the medium access layer, generative models have been advocated in <ref type="bibr" target="#b74">[75]</ref> as a way to generate new examples so as to augment a data set used to train a classifier for spectrum sensing (see Sec. IV). An unsupervised learning task that has found many applications in communications is clustering. For example, in <ref type="bibr" target="#b75">[76]</ref>, clustering is used to support radio resource allocation in a heterogeneous network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. At the Cloud</head><p>1) Network Layer: Another typical application of clustering is to enable hierarchical clustering for routing in self-organizing multi-hop networks. Thanks to clustering, routing can be carried out more efficiently by routing first at the level of clusters, and then locally within each cluster <ref type="bibr" target="#b76">[77]</ref>. For an application of the unsupervised learning task of density estimation, consider the problem of detecting anomalies in networks. For instance, by learning the typical distribution of the features of a working link, one can identify malfunctioning ones. This approach may be applied, e.g., to optical networks <ref type="bibr" target="#b53">[54]</ref>.</p><p>2) Application Layer: Finally, we point to two instances of unsupervised learning at the application layer that are usually carried out at data centers in the cloud. These tasks follow a conceptually different approach as they are based on discovering structure in graphs. The first problem is community detection in social networks. This amounts to a clustering problem whereby one wishes to isolate communities of nodes in a social graph on the basis of the observation of a realization of the underlying true graph of relationships <ref type="bibr" target="#b77">[78]</ref>. Another application is the ranking of webpages based on the graph of hyperlinks carried out by PageRank <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b78">[79]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUDING REMARKS</head><p>In the presence of modelling or algorithmic deficiencies in the conventional engineering flow based on the acquisition of domain knowledge, data-driven machine learning tools can speed up the design cycle, reduce the complexity and cost of implementation, and improve over the performance of known algorithms. To this end, machine learning can leverage the availability of data and computing resources in many engineering domains, including modern communication systems. Supervised, unsupervised, and reinforcement learning paradigms lend themselves to different tasks depending on the availability of examples of desired behaviour or of feedback. The applicability of learning methods hinges on specific features of the problem under study, including its time variability and its tolerance to errors. As such, a datadriven approach should not be considered as a universal solution, but rather as a useful tool whose suitability should be assessed on a case-by-case basis. Furthermore, machine learning tools allow for the integration of traditional model-based engineering techniques and of existing domain knowledge in order to leverage the complementarity and synergy of the two solutions (see Fig. <ref type="figure" target="#fig_2">2</ref>).</p><p>As a final note, while this paper has focused on applications of machine learning to communication systems, communication is conversely a key element of distributed machine learning platforms. In these systems, learning tasks are carried out at distributed machines that need to coordinate via communication, e.g., by transferring the results of intermediate computations. A recent line of work investigates the resulting interplay between computation and communication <ref type="bibr" target="#b79">[80]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Conventional engineering design flow; and (b) baseline machine learning methodology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Machine learning methodology that integrates domain knowledge during model selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of (a) supervised learning and (b) unsupervised learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. A generic cellular wireless network architecture that distinguishes between edge segment, with base stations, access points, and associated computing resources, and cloud segment, consisting of core network and associated cloud computing platforms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 ?Fig. 5 .</head><label>55</label><figDesc>Fig. 5. Illustration of the supervised learning problem of regression: Given input-output training examples (xn, tn), with n = 1, ..., N , how should we predict the output t for an unobserved value of the input x?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5 ?Fig. 6 .</head><label>56</label><figDesc>Fig. 6. Illustration of the supervised learning problem of classification: Given input-output training examples (xn, tn), with n = 1, ..., N , how should we predict the output t for an unobserved value of the input x?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Training loss and generalization loss, estimated via validation, as a function of the model order M for the example in Fig. 9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Illustration of typical unsupervised learning models: (a) directed generative models; (b) undirected generative models; (c) discriminative models; and (d) autoencoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The ELBO (15) is a global lower bound on the log-likelihood that is tight at values of the model parameters θ0 for which equality (17) holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig.<ref type="bibr" target="#b12">13</ref>. Illustration of the EM algorithm: At each iteration, a tight ELBO is evaluated in the E step by solving the problem of estimating the latent variables (via the posterior distribution p(z|x, θ)), and then the ELBO is maximized in the M step by solving a problem akin to supervised learning with the estimated latent variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig.<ref type="bibr" target="#b13">14</ref>. Illustration of the limitations of ML unsupervised learning, here obtained via the EM algorithm: The ML solution tends to be blurry, missing the modes of the true distribution p(x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>@kcl.ac.uk). This work has received funding from the European Research Council (ERC) under the European Union Horizon 2020 research and innovation program (grant agreement 725731).</figDesc><table><row><cell>'s</cell><cell>College</cell><cell>London,</cell><cell>United</cell><cell>Kingdom</cell><cell>(email:</cell></row><row><cell cols="2">osvaldo.simeone</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCCN.2018.2881442, IEEE Transactions on Cognitive Communications and Networking</figDesc><table /><note><p>2332-7731 (c) 2018 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>over a parameterized (differentiable) discriminator function T ϕ (x). Integrating the evaluation of the divergence with the problem of learning the model parameters yields the This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCCN.2018.2881442, IEEE Transactions on Cognitive Communications and Networking</figDesc><table><row><cell cols="2">min-max problem</cell></row><row><cell>min θ</cell><cell>max ϕ</cell></row></table><note><p>2332-7731 (c) 2018 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The term "regression" may be confusing, since the model applies to classification.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>This can be thought of as an example of experience learning as part of small-sample learning techniques<ref type="bibr" target="#b45">[46]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The use of the term "cause" is meant to be taken in an intuitive, rather than formal, way. For a discussion on the study of causality, we refer to<ref type="bibr" target="#b7">[8]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>EM is an instance of the more general Majorization-Minimization algorithm<ref type="bibr" target="#b60">[61]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>2332-7731 (c) 2018 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>-R. Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal processing magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Applications of neural networks to digital communications-a survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ibnkahla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal processing</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1185" to="1215" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
		</author>
		<title level="m">Common Sense, the Turing Test, and the Quest for Real AI: Reflections on Natural and Artificial Intelligence</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>California Univ San Diego La Jolla Inst for Cognitive Science, Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the royal statistical society. Series B</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning form delayed rewards</title>
		<author>
			<persName><forename type="first">C</forename><surname>Watkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>King&apos;s College, University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph. D. thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Deep learning</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The Book of Why: The New Science of Cause and Effect</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Machine learning in wireless sensor networks: Algorithms, strategies, and applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1996" to="2018" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Machine learning paradigms for next-generation wireless networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hanzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="105" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep Learning in Physical Layer Communications</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><forename type="middle">F</forename><surname>Juang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-07">Jul. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Error control coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Costello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">On deep learning-based channel decoding</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cammerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brink</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Understanding machine learning: From theory to algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A Closer Look at Memorization in Deep Networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jastrze ¸bski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The elements of statistical learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="485" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page">484</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A brief introduction to machine learning for engineers</title>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="200" to="431" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What can machine learning do? Workforce implications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="issue">6370</biblScope>
			<biblScope unit="page" from="1530" to="1534" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning and information theory: An emerging interface</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ISIT</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Tutorial</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Loihi: A neuromorphic manycore processor with on-chip learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chinya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Choday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dimou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Imam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="99" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Training probabilistic spiking neural networks with first-to-spike decoding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rajendran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10704</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning to explain: An information-theoretic perspective on model interpretation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.07814</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Machine Learning at the Edge: A Data-Driven Architecture with Applications to 5G Cellular Networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Polese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kounev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-08">Aug. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wireless caching: Technical misconceptions and business barriers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Paschos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bastug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Land</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Caire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Debbah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Machine learning for wireless networks with artificial intelligence: A tutorial on neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Challita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Debbah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.02913</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A statistical learning approach to ultra-reliable low latency communication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Angjelichinoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Trillingsgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Popovski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05515</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A taxonomy for semi-supervised learning methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">An introduction to machine learning communications systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1702</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Neural network detection of data sequences in communication systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Farsad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldsmith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02046</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Equalisation of satellite mobile channels with neural network techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouchired</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roviras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Castanié</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Space Communications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="209" to="220" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A supervised learning approach for routing optimizations in wireless sensor networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Peh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop on Multi-hop ad hoc Networks</title>
		<meeting>Int. Workshop on Multi-hop ad hoc Networks</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Neural net-based continuous phase modulation receivers</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Veciana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1396" to="1408" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-N</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-07">Jul. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep learning methods for improved decoding of linear codes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marciano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lugosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burshtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Be'ery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="131" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural offset min-sum decoding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lugosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE int. Symp. Information Theory</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1361" to="1365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Scaling deep learning-based decoding of polar codes via partitioning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cammerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE GLOBECOM 2017</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Online label recovery for deep learning-based communication through error correcting codes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schibisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cammerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dörner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Brink</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00747</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An iterative bp-cnn architecture for channel decoding</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="144" to="159" />
			<date type="published" when="2018-02">Feb 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modulation classification of mimo-ofdm signals by independent component analysis and support vector machines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Agirman-Tosun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Haimovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dabin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kanterakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASILOMAR 2011</title>
		<meeting>ASILOMAR 2011</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1903" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Indoor location system based on discriminant-adaptive neural network in ieee 802.11 environments</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-N</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1973" to="1978" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Supervised and Semi-Supervised Deep Neural Networks for CSI-Based Authentication</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-07">Jul. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to optimize: Training deep neural networks for wireless resource management</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Signal Processing Advances in Wireless Communications (SPAWC)</title>
		<imprint>
			<date type="published" when="2017">2017, 2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Model-Aided Wireless Artificial Intelligence: Embedding Expert Knowledge in Deep Neural Networks Towards Wireless Systems Optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zappone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Renzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Debbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-08">Aug. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Small Sample Learning in Big Data Era</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-08">Aug. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Non-linear digital self-interference cancellation for in-band full-duplex radios using neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Balatsoukas-Stimming</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00379</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Enhanced Machine Learning Techniques for Early HARQ Feedback Prediction in 5G</title>
		<author>
			<persName><forename type="first">N</forename><surname>Strodthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Göktepe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schierl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hellge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-07">Jul. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A neural network based spectrum prediction scheme for cognitive radio</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Tumuluru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Communications (ICC 2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Estimating the number of receiving nodes in 802.11 networks via machine learning techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Del Testa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Danieletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Di Nunzio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Communications Conference (GLOBECOM)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Machinelearning-based future received signal strength prediction using depth images for mmwave communications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Okamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nishio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morikura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miyatake</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09698</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Echo state networks for proactive caching in cloud-based radio access networks with mobile users</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Debbah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3520" to="3535" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cognition-based networks: A new perspective on network optimization using learning and distributed intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zanella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Testolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D F</forename><surname>De Grazia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1512" to="1530" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">A survey on application of machine learning techniques in optical networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Musumeci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rottondi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Macaluso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zibar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruffini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tornatore</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07976</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On removing routing protocol from future wireless networks: A real-time deep learning approach for intelligent traffic control</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Fadlullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Akashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mizutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="154" to="160" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A survey of techniques for internet traffic classification using machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Armitage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="56" to="76" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">recognition and machine learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of information theory</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Introducing information measures via inference [lecture notes]</title>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="167" to="171" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Majorization-minimization algorithms in signal processing, communications, and machine learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Palomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="794" to="816" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.0030</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">An introduction to signal detection and estimation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">NIPS 2016 tutorial: Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">End-to-end deep learning of optical fiber communications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Karanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chagnon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Thouin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bülow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lavery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bayvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmalen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.04097</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Deepcode: Feedback codes via deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00801</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep learningaided scma</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Letters</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="720" to="723" />
			<date type="published" when="2018-04">April 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Deep Joint Source-Channel Coding for Wireless Image Transmission</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bourtsoulatze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Burth</forename><surname>Kurka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gunduz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-09">Sep. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Deep learning for massive mimo csi feedback</title>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-T</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>IEEE Wireless Communications Letters</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">3-d ble indoor localization based on denoising autoencoder</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">760</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Approximating the void: Learning stochastic channel models from observation with variational generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>West</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06350</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Channel agnostic end-to-end learning based communication systems with conditional gan</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><forename type="middle">F</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sivanesan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00447</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Towards Optimal Power Control via Ensembling Deep Neural Networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-07">Jul. 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Learning the mmse channel estimator</title>
		<author>
			<persName><forename type="first">D</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Utschick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Generative adversarial learning for spectrum sensing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Davaslioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Sagduyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.00709</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Clustering and resource allocation for dense femtocells in a two-tier cellular ofdma network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abdelnasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1628" to="1641" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A survey on clustering algorithms for wireless sensor networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Younis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer communications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2826" to="2841" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Exact recovery in the stochastic block model</title>
		<author>
			<persName><forename type="first">E</forename><surname>Abbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Bandeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.3267</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The PageRank citation ranking: Bringing order to the web</title>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stanford InfoLab, Tech. Rep</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Redundancy techniques for straggler mitigation in distributed optimization and learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Karakus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Diggavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05397</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
