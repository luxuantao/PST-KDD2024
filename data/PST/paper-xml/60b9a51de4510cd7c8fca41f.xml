<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Disentangling User Interest and Conformity for Recommendation with Causal Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yu</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chen</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Depeng</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
							<email>liyong07@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Disentangling User Interest and Conformity for Recommendation with Causal Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FF9971EA84DDD6E1AE16D26A3EA83E08</idno>
					<idno type="DOI">10.1145/3442381.3449788</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender systems</term>
					<term>popularity bias</term>
					<term>causal embedding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommendation models are usually trained on observational interaction data. However, observational interaction data could result from users' conformity towards popular items, which entangles users' real interest. Existing methods tracks this problem as eliminating popularity bias, e.g., by re-weighting training samples or leveraging a small fraction of unbiased data. However, the variety of user conformity is ignored by these approaches, and different causes of an interaction are bundled together as unified representations, hence robustness and interpretability are not guaranteed when underlying causes are changing. In this paper, we present DICE, a general framework that learns representations where interest and conformity are structurally disentangled, and various backbone recommendation models could be smoothly integrated. We assign users and items with separate embeddings for interest and conformity, and make each embedding capture only one cause by training with cause-specific data which is obtained according to the colliding effect of causal inference. Our proposed methodology outperforms state-of-the-art baselines with remarkable improvements on two real-world datasets on top of various backbone models. We further demonstrate that the learned embeddings successfully capture the desired causes, and show that DICE guarantees the robustness and interpretability of recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Collaborative filtering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years have witnessed great success in recommender systems, which provide users with personalized contents by mining user preference from the observational interaction data <ref type="bibr" target="#b35">[36]</ref>. However, observational interaction data exhibits strong popularity bias <ref type="bibr" target="#b11">[12]</ref>, which entangles users' real interest. A user might click an item simply because many other users have clicked it, e.g. in e-commerce platforms items are often displayed with their sales values. In fact, those interactions are mainly driven by users' conformity, rather than real interest. As a crucial factor for decision making, conformity describes how users tend to follow other people. Meanwhile, conformity towards an item varies according to different users. In order to capture users' pure interest that is independent with conformity, existing approaches track this problem as eliminating popularity bias, a static and global term from the perspective of items, while ignoring the variety of users' conformity. For example, a sport lover purchases a bicycle with high sales value due to his unique tastes on specific characteristics (e.g. tire size or speed capacity), while an office worker might purchase the same bicycle only because of its high sales. Using uniform popularity bias fails to distinguish these two users' different conformity, since popularity score of an item will be the same for all users. Therefore, disentangling user interest and conformity is crucial enhance recommendation quality.</p><p>In this work, we take a different approach from user's perspective. Instead of eliminating popularity bias from the perspective of items, we propose to decompose the observed interactions into two factors in the user side, interest and conformity, and learn disentangled representations for them. Disentangling these two factors is challenging and has not been well explored. Specifically, we face three key challenges. First, conformity depends on both user and item. One user's conformity varies on different items, as well as conformity towards one item from different users. Thus, a scalar bias term for user or item is insufficient, as adopted by existing algorithms <ref type="bibr" target="#b3">[4]</ref>. Second, learning disentangled representations is intrinsically difficult, especially when only observational interaction data is available. In other words, we only have access to the effect, but not the causes, since there is no labeled ground-truth value for interest and conformity. Third, a click interaction can come from one or both causes of interest and conformity. Therefore, it requires careful design to aggregate and balance the two causes.</p><p>Although it is a challenging task, learning disentangled representations of interest and conformity has two main advantages over approaches that only learn a unified embedding for a user or item: (1) Robustness. Real-world recommender systems are often trained and updated continuously using real-time user interactions, which forms a feedback loop as illustrated in Figure <ref type="figure">1</ref>, with training data and test data NOT independent and identically distributed (IID) <ref type="bibr" target="#b12">[13]</ref>. Causal modeling on the effect (click) and cause (interest and conformity) can lead to more robust models, with stronger generalization ability, especially in non-IID situations where underlying causes are changing <ref type="bibr" target="#b40">[41]</ref>.</p><p>(2) Interpretability. Interpretable recommendation can benefit both users and platforms of recommender systems, since it improves user-friendliness and facilitates algorithm developing. By disentangling underlying causes, each recommendation score is decomposed as an aggregation of interest score and conformity score. Therefore, explanations towards the two causes can be easily made according to corresponding scores.</p><p>In this paper, we present a general framework for Disentangling Interest and Conformity with Causal Embedding (DICE). To capture the variety of conformity, we propose to learn comprehensive embeddings separately for conformity, which is independent with user interest. Instead of using simple scalar popularity value as existing approach, we develop particular methodologies in order to learn disentangled representations for interest and conformity. Specifically, we describe the causal model of how each interaction data is generated. Based on the causal model, we propose particular negative sampling strategies for specific causes based on the colliding effect of causal inference <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>, and learn separate embeddings for interest and conformity with cause-specific data. Meanwhile, we add direct supervision on the disentanglement between the two parts of embeddings. To generate final recommendation considering both user interest and conformity, we exploit multi-task and curriculum learning, which successfully balances the two causes.</p><p>We evaluate the proposed method on two large-scale benchmark datasets collected from real-world applications. Experimental results show that DICE outperforms state-of-the-art baselines with over 15% improvements in terms of Recall and NDCG. To investigate the robustness of DICE, we extract test data that is non-IID with training data by conducting intervention on conformity. We demonstrate that DICE consistently beats baseline methods under non-IID situations. Furthermore, we provide analytical results on the quality of learned embeddings, which illustrate superior interpretability of the proposed method.</p><p>In summary, the main contributions of this paper are as follows:</p><p>• To the best of our knowledge, this is the first work to formulate the problem of disentangling user interest and conformity for recommender systems. We tackle the causal recommendation problem from the perspective of users and show that disentangling these two factors is essential for recommender systems, with respect to robustness and interpretability. The remainder of this paper is as follows. We first introduce the motivation and formulate the problem in Section 2. We then elaborate the proposed DICE framework in Section 3. We conduct experiments in Section 4, after that we discuss related works in Section 5. Finally, we conclude this paper in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MOTIVATION AND PROBLEM OVERVIEW</head><p>Motivation. Algorithms that disentangle underlying semantics have superior generalization ability over entangled approaches.</p><p>Here we focus on a specific form of generalization ability that is not from one data point to another data point in the same distribution, but from one distribution to another distribution. Figure <ref type="figure">2</ref> shows an example of shape recognition, which follows the non-IID condition on training data and test data. Suppose we are developing a shape recognition model, where we learn representations from original pictures and predict their shapes based on the learned representations. It seems like a normal task, however there are traps in it. In fact, models are easily misled by training data, since rectangles are blue and large, triangles are green and small, circles are orange and medium size. As a consequence, a model can predict shapes from color or size, rather than outline. Moreover, if test data is generated from the same distribution (i.e. IID with training data), bad models that pay attention to color or size would perform well on test set and we might not even notice what was going wrong. Fortunately, we force training data and test data NOT to be IID as shown in Figure <ref type="figure">2</ref> where color and size are totally different with training  data, and evaluate whether our models are robust under this intervened environment. Then only those models that disentangle the underlying semantics (shape, color and size) can survive in our test.</p><p>With respect to recommender systems, a click interaction can be triggered by users' real interest, or their conformity towards popular items. In IID situations, it is not necessary for models to distinguish between users' interest and conformity, thus models tend to recommend items according to their popularity values, due to their larger amount of training instances. However, users' conformity at training time and serving time are distinct, since recommender system is a live interactive system shown in Figure <ref type="figure">1</ref>. Therefore, it is essential for recommendation algorithms to be robust in such non-IID situation, especially when underlying causes are different. In this work, we extend conventional causal recommendation algorithms that perform unbiased learning from biased data <ref type="bibr" target="#b25">[26]</ref>, and propose to disentangle user interest and conformity. Based on recent advancements in causal recommendation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b29">30]</ref>, we construct datasets with training data and test data NOT IID. We evaluate the proposed methodology compared with state-of-the-art baseline approaches, and particularly investigate their robustness under non-IID circumstances by interventions. Problem Formulation. Here we formulate the problem of disentangling user interest and conformity. Suppose the dataset O is composed of N instances of (u, i, p), where p is the popularity of item i, i.e. the number of interactions on item i. Output: A predictive model estimating whether a user will click an item considering both interest and conformity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DICE: THE PROPOSED APPROACH</head><p>We propose a general framework, named DICE, to learn disentangled representations for interest and conformity. Figure <ref type="figure" target="#fig_2">3</ref> illustrates the holistic design of DICE. To tackle the previously introduced three challenges, our proposed framework is composed of the following three stages: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Causal Embedding</head><p>In this section, we first describe the causal model of how each interaction data is generated from interest and conformity. Then we provide the structural causal model (SCM) and causal graph for click, interest and conformity, based on which we propose to utilize separate embeddings for interest and conformity, solving the first challenge of varying conformity.</p><p>How each interaction data is generated? A click record of a user on an item mainly reflects two aspects: (1) the user's interest in the item's characteristics, (2) the user's conformity towards the item's popularity. A click can come from one or both of the two aspects. We propose an additive model to describe how each click record is generated from interest and conformity. Formally, the matching score of a given user u and item i is attained as follow:</p><formula xml:id="formula_0">S ui = S interest ui + S conformity ui ,<label>(1)</label></formula><p>where S ui represents the overall matching score, while S interest ui and S conformity ui stand for a specific cause. This additive model is justified because users tend to have both particularity and conformity when interacting with recommender systems <ref type="bibr" target="#b30">[31]</ref>. Meanwhile, additive models are widely adopted in causal inference and have been shown effective in a bunch of applications <ref type="bibr" target="#b37">[38]</ref>. In addition, multiplicative model is also adopted in related literature <ref type="bibr" target="#b48">[49]</ref>, which decomposes the click probability as production of exposure probability and the conditional click probability given exposure. However, such multiplicative model entangles interest and conformity from the perspective of user, since users' conformity still takes effect given the exposed items. It is worthwhile to notice that there may be causes other than interest or conformity that lead to a click interaction, but we propose to grasp these two principle factors. Meanwhile, the proposed methodology is a general framework which can be extended to scenarios with multiple causes. SCM and causal graph for click, interest and conformity. Based on our proposed causal model in <ref type="bibr" target="#b0">(1)</ref>, we now provide the SCM of our proposed DICE framework, ζ DICE , along with causal graph in Figure <ref type="figure" target="#fig_2">3(a)</ref>:</p><formula xml:id="formula_1">X int ui f 1 (u, i, N int ), X con ui f 2 (u, i, N con ), Y cl ick ui f 3 (X int ui , X con ui , N cl ick ),<label>(2)</label></formula><p>where N int , N con and N  <ref type="formula" target="#formula_1">2</ref>) explains the logic on how effect (click) is generated from causes (interest and conformity). However, particular forms of function families in f 1 , f 2 and f 3 are still to be determined. As introduced previously, conformity of different users towards the same item are diverse, and so does conformity of the same user towards different items. In other words, conformity depends on both users and items, as well as interest. Therefore, function families for f 1 and f 2 should better support such flexibility in interest and conformity. We now introduce our proposed design using separate embeddings. Separate embeddings for interest and conformity In the proposed DICE framework, we adopt two sets of embeddings to separately capture interest and conformity, instead of using scalar popularity values as in existing approach <ref type="bibr" target="#b3">[4]</ref>, since scalar values are insufficient to capture the diversity of user conformity. As shown in Figure <ref type="figure" target="#fig_2">3(b)</ref>, each user has an interest embedding u (int) and a conformity embedding u (con) , and each item also has i (int) and i (con) for the two causes <ref type="foot" target="#foot_0">1</ref> . We use inner product to compute matching score for both causes. Based on the additive causal model in Equation (1), we sum up the two matching scores from corresponding causes, to estimate the overall score on whether a user will click an item. Therefore, the recommendation score for user u and item i is formulated as:</p><formula xml:id="formula_2">s int ui = ⟨u (int) , i (int) ⟩, s con ui = ⟨u (con) , i (con) ⟩, s cl ick ui = s int ui + s con ui ,<label>(3)</label></formula><p>where ⟨•, •⟩ means inner product of two embeddings. Figure <ref type="figure" target="#fig_2">3</ref>(b) demonstrates the disentanglement design of interest embeddings and conformity embeddings. From the perspective of SCM, we restrict the family of functions for f 1 and f 2 as inner product between two sets of learnable embeddings, and set f 3 as a concise additive model which is commonly used in practice <ref type="bibr" target="#b37">[38]</ref>. By optimizing in two high-dimensional spaces rather than finding the optimal scalar value in 1-D space like existing solutions, diversity of user conformity can be automatically captured in the proposed DICE framework, hence we solve the first challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Disentangled Representation Learning</head><p>In this section, we elaborate our designs on disentangling the two causal embeddings for interest and conformity. We propose to train different embeddings with cause-specific data, and decompose the problem into four tasks of conformity modeling, interest modeling, estimating clicks and an extra discrepancy task.</p><p>Mining Cause-specific Data. Disentanglement between interest embedding and conformity embedding means that each embedding captures only one factor, and squeezes out the second factor to the other embedding. To achieve such target, a common and reasonable idea is to train different embeddings with cause-specific data. However, we only have access to the effect, which is the observational click data, but we are nearly ignorant on whether the click is caused by interest or conformity. In other words, an equality in ( <ref type="formula" target="#formula_0">1</ref>) is insufficient to recover interest and conformity, because there are infinite solutions to it when there are no ground-truth for two addends and only the summation is available. Therefore, we explore from observational interactions and discover cause-specific data which means those interactions are sourced from individual cause with high probability. The cause-specific data paves the way for disentangling the two underlying causes, interest and conformity. We first introduce several notations. We use M I to denote the matrix of interest matching score for all users and items, and M C for conformity matching score. M I and M C are in R M ×N , where M and N are the number of users and items. In the causal graph in Figure <ref type="figure" target="#fig_2">3</ref>(a), the three nodes form a immorality, and click is the collider of interest and conformity <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>. In fact, the two causes of a collider are independent variables. However, if we condition on the collider, the two causes become correlated with each other, and we call it colliding effect. For example, whether a man is popular depends on both his appearance and temper. Appearance and temper are usually independent, and popularity is the collider of appearance and temper (appearance → popularity ← temper). Given a popular man who is not good-looking, then he is good-tempered with high probability. Similarly, an unpopular but good-looking man is most likely bad-tempered. Therefore, in our task of disentangling interest and conformity, the colliding effect can be utilized to obtain samples that are mostly resulted from one cause. Specifically, we emphasize on two particular cases in M I and M C which are cause-specific: Case 1: The negative item is less popular than the positive item. If a user u clicks a popular item a, while does not click an unpopular item b, then we are not sure whether the user's interest on a is stronger than b, because users have conformity towards popular items. In other words, the click can come from the second cause (conformity). Meanwhile, we can also safely conclude that the overall score of the two causes of a is larger than b. Hence we have two inequalities in this case:</p><formula xml:id="formula_3">M C ua &gt; M C ub , M I ua + M C ua &gt; M I ub + M C ub .<label>(4)</label></formula><p>Case 2: The negative item is more popular than the positive item. However, if a user clicks an unpopular item c, while does not click a popular item d, then the colliding effect can bring more information. Since c is less popular than d which serves as a reasonable proxy for conformity, the click on c is largely due to the user's interest. Therefore, we have three inequalities in this case, with one extra inequality on interest than the previous case:</p><formula xml:id="formula_4">M I uc &gt; M I ud , M C uc &lt; M C ud , M I uc + M C uc &gt; M I ud + M C ud .<label>(5)</label></formula><p>We use O to denote all training instances, which is divided into O 1 and O 2 . Specifically, O 1 denotes those instances where negative samples are less popular than positive samples, and O 2 denotes the opposite cases. Correspondingly, O 1 contains the data that inequalities of (4) in Case 1 hold true, thus O 1 can be utilized to learn conformity and click. O 2 contains the data that fits Case 2, hence it can be exploited to learn interest, conformity and click.</p><p>By extending one equality to multiple inequalities, we transform the problem from learning absolute values to learning relative relations, which makes the task of disentangling interest and conformity solvable. Specifically, based on these derived inequalities, we obtain user-item interactions that mainly result from one specific cause, and leverage these interactions to optimize corresponding embeddings. Take the famous matrix factorization algorithm for recommendation as an example, usually we optimize a user embedding matrix and an item embedding matrix to best regress the original interaction matrix, say M cl ick . This classical approach unifies all possible causes into one bundled representation for a user or item, thus different causes are entangled, leading to inferior robustness and interpretability under non-IID circumstances, which is quite common in recommender systems. Moreover, debias algorithms such as IPS can not fully solve this problem, since they still adopt unified representations. In contrast to existing approaches, we first decompose the original click matrix M click into two cause-specific matrices, M I and M C , for interest and conformity respectively. Then two sets of embeddings are adopted, in order to capture interest and conformity separately, and they are further combined to regress click. Different causes are thus disentangled, which achieves better robustness under interventions. We now introduce our causal learning methodology.</p><p>With cause-specific data O 1 and O 2 , it is possible to model interest and conformity separately. Meanwhile, we propose to estimate click behaviors by combining the two causes, which is the main task for recommendation. Moreover, we further add a discrepancy task in order to make the two sets of embeddings independent with each other, which enhances disentanglement. Therefore, we decompose the problem of disentangling interest and conformity into four tasks, which are conformity modeling, interest modeling, estimating clicks and discrepancy task. We utilize BPR <ref type="bibr" target="#b38">[39]</ref> to model the pairwise quantitative relations in (4) and <ref type="bibr" target="#b4">(5)</ref>. Each positive sample is paired with certain number of negative samples, and each training instance is a triplet (u, i, j) containing user ID, positive item ID and negative item ID. We now introduce the four tasks in sequence. Conformity Modeling For instances in both O 1 and O 2 , we have inequalities for conformity modeling, which are the inequalities for M C . Notice that the directions of inequality are different in the two cases. We use these conformity-specific data to optimize conformity embeddings. BPR loss function is exploited to regress M C with conformity embeddings. Therefore, the loss function for conformity modeling is formulated as:</p><formula xml:id="formula_5">L O 1 conformity = (u,i, j)∈ O 1</formula><p>BPR(⟨u (con) , i (con) ⟩, ⟨u (con) , j (con) ⟩),</p><formula xml:id="formula_6">L O 2 conformity = (u,i, j)∈ O 2</formula><p>-BPR(⟨u (con) , i (con) ⟩, ⟨u (con) , j (con) ⟩),</p><formula xml:id="formula_7">L O 1 +O 2 conformity = L O 1 conformity + L O 2 conformity .<label>(6)</label></formula><p>Interest Modeling In O 2 , negative items are more popular than positive items, and those interactions are largely due to users' interest. These data is interest-specific, and we have inequalities for interest modeling. We also use BPR to optimize interest embeddings to learn such pairwise preference, in order to regress M I . The loss function only takes effect for instances in O 2 :</p><formula xml:id="formula_8">L O 2 interest = (u,i, j)∈ O 2 BPR(⟨u (int) , i (int) ⟩, ⟨u (int) , j (int) ⟩).<label>(7)</label></formula><p>Estimating Clicks This is the main target for recommender systems, and we combine the two causes to estimate clicks as introduced in (3), with a concise additive model. For each instance in training set O, which is the union of O 1 and O 2 , we use BPR to maximize the margin between scores of positive items and negative items, so as to regress M click . The loss function for click estimation is thus formulated as follow:</p><formula xml:id="formula_9">L O 1 +O 2 click = (u,i, j)∈ O BPR(⟨u t , i t ⟩, ⟨u t , j t ⟩).<label>(8)</label></formula><p>u t , i t and j t are concatenation of interest embedding and conformity embedding for user and item: (con) , i t = i (int) ∥i (con) , j t = j (int) ∥j (con) ,</p><formula xml:id="formula_10">u t = u (int) ∥u</formula><p>where ∥ means concatenation of two embeddings. We use the concatenation form here for simplicity, which is equivalent to the summation form in (3). The BPR loss pushes the recommendation score for the positive item i to be higher than the negative item j.</p><p>Interest modeling and conformity modeling disentangle the two causes by training different embeddings with different causespecific data. Meanwhile, the main task on estimating clicks also strengthens this disentanglement as a constraint. For example, in terms of a training instance (u, i, j) where negative item j is more popular than positive item i, interest modeling task forces the two sets of embeddings to learn that user u's interest in i is larger than j, and conformity modeling task forces them to learn that user u's conformity towards item i' is less than j. Meanwhile, estimating clicks forces them to learn that the overall strength on i is larger than j. Therefore, what the model really learns is that the advantage of i over j with respect to interest dominates the disadvantage in conformity, which can be best learned by capturing only one cause with one embedding. Discrepancy Task Besides the three tasks above that disentangle interest and conformity by optimizing different embeddings with cause-specific data, we impose direct supervision on the embedding distribution to reinforce this disentanglement. Suppose E (int) and E (con) represent two sets of embeddings of all users and items. We examine three candidate discrepancy loss functions, which are L1-inv, L2-inv and distance correlation (dCor). L1-inv and L2-inv maximize L1 and L2 distances between E (int) and E (con) respectively. We refer to <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> for details on dCor. From high level, dCor is a more reasonable choice, since it focuses on the correlations of pairwise distances between interest embeddings and conformity embeddings. The three options for discrepancy loss function are -L1(E (int) , E (con) ), -L2(E (int) , E (con) ) and dCor (E (int) , E (con) ). We will compare them in experiments.</p><p>Figure <ref type="figure" target="#fig_2">3</ref>(b) illustrates the four decomposed tasks using disentangled embeddings for interest and conformity. By training different embeddings with cause-specific data and imposing direct supervision on the embedding distribution, we solve the second challenge of learning disentangled representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multi-task Curriculum Learning</head><p>In the proposed framework, we overcome the last challenge of aggregating interest and conformity by multi-task curriculum learning. To be specific, we train causal embeddings with the four above tasks simultaneously, and combine these loss functions together:</p><formula xml:id="formula_12">L = L O 1 +O 2 click + α(L O 2 interest + L O 1 +O 2 conformity ) + βL discrepancy .<label>(10)</label></formula><p>Since estimating clicks is the main task for recommendation, α and β should be less than 1 from intuition. Meanwhile, discrepancy task directly influences the distribution of embeddings, thus too large β would negatively impact interest and conformity modeling.</p><p>As introduced previously, we obtain two or three inequalities when the negative sample is less or more popular than the positive sample, respectively. Notice that those inequalities will hold true with high probability when the popularity gap is sufficiently large. Therefore, we develop Popularity based Negative Sampling with Margin (PNSM) to guarantee those quantitative relations. Specifically, if the popularity of the positive sample is p, then we will sample negative instances from items with popularity larger than p + m up , or lower than pm down , where m up and m down are positive margin values. By sampling negative items with popularity margin, we gain high confidence in our causal models. Later experiments show that popularity based negative sampling with margin is of crucial importance for learning disentangled and robust representations.</p><p>Inspired by curriculum learning <ref type="bibr" target="#b6">[7]</ref>, we adopt an easy-to-hard strategy on training DICE by adding decay on margin values and loss weights. Specifically, when margin values m up and m down are large, we have high confidence on those inequalities for interest and conformity modeling, which means the tasks are easier and we set high loss weights α for L interest and L conformity . As we train the model, we increase the difficulty by decaying margin values, as well as loss weights α, by a factor of 0.9 after each epoch. With curriculum learning, the proposed approach learns stronger disentanglement for high-confidence samples. Furthermore, this adaptive design also makes the proposed method not sensitive to initial values of hyper-parameters. We will compare the performance of curriculum learning with normal learning in experiments. Interest and conformity are elegantly aggregated by multi-task curriculum learning, hence the last challenge is addressed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we conduct experiments to show the effectiveness of the proposed framework. Specifically, we aim to answer the following research questions:</p><p>• RQ1: How does our proposed DICE framework perform compared with state-of-the-art causal recommendation methods under non-IID circumstances? Particularly, is it necessary to replace scalar bias term with embedding? • RQ2: Can the proposed DICE framework guarantee interpretability and robustness? • RQ3: What is the role of each component in the proposed methodology, including negative sampling, conformity modeling, curriculum learning, and discrepancy loss? • RQ4: What is the effect of intervened data inserted into training set? How does DICE perform when no intervened training data is available?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Datasets We conduct experiments on two million-scale datasets collected from real-world applications, Movielens-10M dataset <ref type="bibr" target="#b19">[20]</ref> and Netflix Prize dataset <ref type="bibr" target="#b7">[8]</ref>, and Table <ref type="table" target="#tab_4">1</ref> lists the statistics of two datasets.</p><p>Data Preprocessing In order to measure the performance of causal learning under non-IID circumstances, intervened test sets are needed, and thus all datasets are transformed following the standard protocol introduced in related literatures <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b29">30]</ref>. We binarize the datasets by keeping ratings of five stars as one, and others as zero. To conduct intervention on conformity, we randomly sample 40% of the records with equal probability in terms of items, and leave the other 60% as training data. In other words, items are sampled with probability as inverse popularity, which means Recommendation Models Causal approaches usually serve as additional methods upon backbone recommendation models. We use the most adopted recommendation model, Matrix Factorization (MF) <ref type="bibr" target="#b28">[29]</ref> to compare different approaches. Meanwhile, we also incorporate the state-of-the-art collaborate filtering model, Graph Convolutional Networks (GCN) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b49">50]</ref>, to investigate whether algorithms generalize across different recommendation models. Specifically, we use BPR-MF <ref type="bibr" target="#b38">[39]</ref> and LightGCN <ref type="bibr" target="#b20">[21]</ref>, which are both state-of-the-art recommendation models. Experiment Setups For IPS based models, we fix the embedding size as 128. While for CausE and DICE, the embedding size is fixed as 64, since they contain two sets of embeddings. Therefore, the number of parameters are the same for all methods to guarantee fair comparison. We set α as 0.1 and β as 0.01, which shows great performance and agnostic to both datasets and backbone models in experiments. We use BPR <ref type="bibr" target="#b38">[39]</ref> as the loss function for all baselines. We use Adam <ref type="bibr" target="#b26">[27]</ref> for optimization. Other hyper-parameters for our method and baselines are tuned by grid search. The code and data are available at https://github.com/tsinghua-fib-lab/DICE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison (RQ1)</head><p>4.2.1 Overall Performance. We compare our approach with the following state-of-the-art causal recommendation methods:</p><p>• IPS <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b39">40]</ref>: IPS eliminates popularity bias by re-weighting each instance according to item popularity. Specifically, weight for an instance is set as the inverse of corresponding item popularity value, hence popular items are imposed lower weights, while the importance for long-tail items are boosted. • IPS-C [10]: This method adds max-capping on IPS value to reduce the variance of IPS. • IPS-CN <ref type="bibr" target="#b17">[18]</ref>: This method further adds normalization which also achieved lower variance than plain IPS, at the expense of introducing a small amount of bias. • IPS-CNSR <ref type="bibr" target="#b17">[18]</ref>: Smoothing and re-normalization are added to attain more stable output of IPS. • CausE <ref type="bibr" target="#b8">[9]</ref>: This method requires a large biased dataset and a small unbiased dataset. Each user or item has two embeddings to perform matrix factorization (MF) on the two datasets respectively, and L1 or L2 regularization is exploited to force the two sets of embeddings similar with each other.</p><p>We also include simple MF and GCN without using any causal methods for comparison. We evaluate top-k recommendation performance for implicit feedback <ref type="bibr" target="#b38">[39]</ref>, which is the most common setting for recommendation. We adopt three frequently used metrics, which are Recall, Hit Ratio and NDCG.</p><p>Results on two datasets are listed in Table <ref type="table" target="#tab_5">2</ref>. We have the following observations:</p><p>• Our proposed DICE framework outperforms baselines with significant improvements with respect to all metrics on both datasets. For example, DICE makes over 15% improvements with respect to NDCG@50 using MF as backbone on Moveilens-10M dataset, and over 20% improvements with respect to Recall@20 using GCN as backbone on Netflix dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.2</head><p>Comparison between Embedding and Scalar. Using a scalar bias term for each item and user is frequently adopted to capture the influence of popularity <ref type="bibr" target="#b3">[4]</ref>. However, it is insufficient to express the diversity of user conformity. For example, user a has stronger conformity towards item s than user b, thus bias term for user a should be higher than user b. However, user a would have weaker conformity towards item t than user b, which requires bias term for user a to be lower than user b. It is common in practice since users tend to have different conformity in their familiar and unfamiliar fields, such as categories of items or genres of movies. The above contradiction demonstrates the limited power of using scalar values to capture user conformity. In our work, we propose to exploit embeddings instead of simple scalars. By raising dimensions of solution space, the diversity of user conformity is guaranteed. For example, the above contradiction can be easily resolved by using 2-D vectors for user conformity and item popularity, rather than 1-D scalars.</p><p>We compare the proposed DICE framework using embeddings with existing algorithms using scalar values. We include bias terms for both users and items. Specifically, we compare DICE with BIAS-U (adding scalar bias term for each user), BIAS-I (adding scalar bias term for each item) and BIAS-UI (adding scalar bias term for each user and item) on both MF and GCN. Figure <ref type="figure" target="#fig_3">4</ref> shows the results on the two datasets. DICE outperforms all other models with scalar bias terms with significant margin, proving that simple scalar values are insufficient to capture the diversity of user conformity. Experiments on both MF and GCN show that it is necessary to use embeddings rather than scalar values for conformity modeling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Interpretability and Robustness (RQ2)</head><p>As introduced previously, disentangled algorithms are generally more interpretable and robust than entangled competitors. In this section, we investigate whether the proposed DICE framework has such advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.3.1</head><p>Interpretability based on Disentangled Embedding. We investigate the quality of embedding disentanglement in DICE. As there is ground-truth for popularity, which serves as a pseudo proxy for conformity. We first study whether conformity embeddings capture the desired cause. Here we introduce another two versions of the framework, DICE-int and DICE-con. They only use interest or conformity embeddings for recommendation, respectively. Note that in DICE we concatenate the two embeddings. We compare the overlapped recommended items of all methods with ItemPop, which recommends the top popular items. Intersection Over Union (IOU) is used as the metric. Figure <ref type="figure" target="#fig_4">5</ref>(a) illustrates the results on Movielens-10M dataset. We observe that using conformity embeddings greatly simulates the ItemPop algorithm, and the overlapped items even surpass 50% when TopK is above 40. Compared with other baselines like IPS and CausE with IOU less than 20%, DICE-con is much more similar to ItemPop, which validates that conformity embeddings indeed capture the desired cause. The IOU value of DICE-con around 0.5 demonstrates that users tend to confirm with popular items, but different users have their own variance in conformity. If all the users are of the same conformity towards popular items, the IOU value would be close to 1. On the other hand, there is almost no overlapped items between DICE-int and ItemPop, proving that conformity information is almost fully squeezed out from interest embeddings. Therefore, interpretations for interest and conformity can be made based on corresponding embeddings. Besides calculating the similarity with ItemPop, we visualize the learned item embeddings in DICE using t-SNE <ref type="bibr" target="#b33">[34]</ref>. Figure <ref type="figure" target="#fig_4">5(b)</ref> shows the learned item embeddings on two datasets, where crosses represent interest embeddings and dots represent conformity embeddings. With special causal learning design and direct supervision on disentanglement, the two sets of embeddings are far from each other, separated by a linear classifier (red line in the figure). Moreover, we divide all the items to three groups based on their popularity, which are popular, normal and unpopular. In Figure <ref type="figure" target="#fig_4">5</ref>(b), items of different groups are painted in different colors. We observe that conformity embeddings are layered according to item popularity, where items of similar popularity are near in the embedding space. Notice that if we use scalar values, items of the three groups will form three segments in a straight line, which is insufficient to capture the diversity of conformity. On the other hand, with respect to interest embeddings, items of different popularity are mixed with each other. Visualizations of the learned item embeddings illustrate the high quality of disentanglement in the proposed framework. Based on disentangled embeddings, reasonable interpretations can be made, which is crucial for recommendation. We also compare the item embedding quality of DICE with baseline methods, including MF, CausE and IPS. Our proposed methodology learns highly interpretable representations for user conformity, and successfully captures the diversity of conformity by using embeddings instead of scalars.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Robustness under Intervention.</head><p>Algorithms that disentangle underlying causes are generally more robust than entangled approaches under intervention <ref type="bibr" target="#b40">[41]</ref>. In our experiments, we conduct intervention by constructing a different test set which is non-IID with training set, in terms of conformity. Users have access to all items with equal probability, rather than seeing more popular items in training set. Specifically, the probability of an instance to be included into test set is the inverse of its corresponding item popularity value. Notice that we cap the probability at 0.9 to avoid too many cold-start items in test set, which controls the strength of intervention. With lower capping value, we impose weaker intervention, hence users are more likely to be exposed with popular items. On the contrary, larger capping value attains stronger intervention and different items receive more equal opportunity to be recommended. Therefore, it provides an elegant way to evaluate the robustness of recommender systems under distinct levels of intervention, by simply changing the capping value. In our experiments, we investigate how the proposed framework performs at different strength of intervention, as well as state-of-the-art methods. Figure <ref type="figure">6</ref> shows the results of DICE and IPS-CNSR. We compare the performance of the two approaches with capping value as 0.5, 0.7, and 0.9. The three cases represent quite different interventions on user conformity, since users are more likely to conform towards popular items when capping value is 0.5 due to larger exposure probability for popular items, while they tend to interact according to their real interest when capping value is 0.9 since items are exposed in an almost random manner. Results in Figure <ref type="figure">6</ref> illustrates that the proposed DICE framework outperforms IPS-CNSR consistently </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Study on DICE (RQ3)</head><p>Ablation studies on DICE are also conducted to investigate the effectiveness of several components, including negative sampling, conformity modeling, curriculum learning and discrepancy loss. to gain high confidence of our causal models. Specifically, when the popularity gap between negative item and positive item is sufficiently large, those derived inequalities on interest and conformity would hold true with high probability. Therefore, we sample items that are significantly more or less popular than the positive item. We require that the popularity gap is larger than a margin value.</p><p>In this section, we compare PNSM with the commonly used fully random negative sampling strategy. Table <ref type="table" target="#tab_7">3</ref> shows the results on Movielens-10M dataset. We observe that popularity based negative sampling with margin significantly outperforms random negative sampling. Specifically, Recall and NDCG of PNSM are better than RANDOM with over 20% improvements. PNSM also improves Hit Ratio@20 and Hit Ratio@50 by over 10%. Results of PNSM and RANDOM verify that sampling negative items with large popularity margin is crucial in the proposed framework. It is reasonable since the proposed causal learning methodology depends on those derived inequalities from causal model 1, which will hold true with high probability when the negative items are significantly more or less popular than the positive one. We also investigate the effect of conformity modeling in DICE. Specifically, we remove the conformity modeling task in DICE and compare it with the full version of DICE. We found that recommendation performance does not decrease much, however, removing conformity modeling task indeed influences the learned embeddings. Figure <ref type="figure">7</ref> illustrates the learned conformity embeddings in DICE with and without conformity modeling task. We observe that in DICE with conformity modeling task, embeddings are layered according to item popularity, and items of similar popularity are near in the embedding space. However, when we remove the conformity modeling task, the distribution of conformity embeddings becomes messy, and there are more outliers in all groups. To be specific, popular items and normal items tend to overlap with each other in the embedding space. Meanwhile, there are also a fraction of normal items lying in the layer of unpopular items. Conformity modeling task leverages the popularity gap between positive item and negative item to learn pairwise relationships using separate embeddings. From the embedding visualization in Figure <ref type="figure">7</ref>, we can confirm the effect of conformity modeling task in DICE on learning high-quality interpretable representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.4.3</head><p>Impact of Curriculum Learning. In the proposed framework, we adopt multi-task curriculum learning to aggregate different causes. Specifically, we make several hyper-parameters adaptive to form a easy-to-hard curriculum for causal learning. These hyperparameters include loss weight α and negative sampling margin values m up and m down . As we train the causal embeddings, we decay these hyper-parameters by a factor of 0.9 to increase the difficulty. In experiments, we initialize these hyper-parameters with different values, and investigate the effect of curriculum learning. Figure <ref type="figure">8</ref>(a) shows the results of curriculum learning and normal learning on different initial values of loss weight α. We can observe that curriculum learning is consistently better than normal cases. Meanwhile, curriculum learning is not sensitive to initial value due to the easy-to-hard decaying strategy, while normal training without adaptive hyper-parameters is not as stable as curriculum learning and performance drops at large α values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.4.4</head><p>Impact of Discrepancy Loss. We provide three options for discrepancy loss, L1-inv, L2-inv and dCor. We examine the three candidates on two datasets with two backbones. Overall, dCor attains better performance than L1-inv and L2-inv with over 2% improvements. However, dCor relies on heavy matrix computations which is much more time-consuming than L1-inv and L2-inv. Specifically, training with dCor (about 100s per epoch) as discrepancy loss is much slower than L1-inv and L2-inv (about 44s per epoch), which means L1-inv and L2-inv might be more appropriate for large scale applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Study on Intervened Training Data (RQ4)</head><p>In previous experiments, all the algorithms are trained with a large fraction of normal data (60%) and a small fraction of intervened data (10%). Adding extra intervened data is not only a hard requirement of certain baseline method (CausE), but also reduces the difficulty of causal learning. However, intervened data is often too expensive to obtain in real-world recommender systems, e.g. random recommendation policy will greatly damage user experience. Therefore, in this section, we investigate how different algorithms perform when we change the proportion of intervened training data, and we also include the most challenging task of not using any intervened data for training. Figure <ref type="figure">8</ref>(b) demonstrates the performance of DICE, CausE and IPS-CNSR using different proportion of intervened data. Without surprise all the methods got improved performance when we add more intervened data into training set, since it allows models to get access to intervention information which is more similar to test cases. Meanwhile, the proposed DICE framework achieves remarkable improvements against baselines in all cases from 0% to 20%. The proposed DICE framework can still disentangle interest and conformity with even no intervened data, and outperforms other baselines significantly. Notice that there is no result for CausE at 0% since CausE requires intervened training data.</p><p>To summarize, we conduct extensive experiments to evaluate the performance of DICE. We compare it with state-of-the-art baseline methods under non-IID circumstances, and DICE outperforms other methods with significant improvements. We emphasize that it is crucial to use embeddings instead of scalars to fully capture the variety of user conformity, which is also proved by experiments against biased MF and biased GCN. Since the main advantages of disentangled algorithms over entangled algorithms are interpretability and robustness, we further conduct experiments to show DICE indeed provides interpretable results and guarantees robustness under intervention. Moreover, we conduct ablation studies to investigate the role of negative sampling, conformity modeling and curriculum learning. At last, we also study the impact of the proportion of intervened training data and different options for discrepancy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Causal Recommendation. Existing causal solutions for recommender systems formulate the problem as eliminating popularity bias, from the perspective of items <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b42">43]</ref>. A bunch of algorithms for unbiased recommendation are proposed in recent literatures, aiming to reduce popularity bias as much as possible <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49]</ref>. Among them, Inverse Propensity Scoring (IPS) based methods are mostly adopted and achieve state-of-the-art performance. IPS re-weights each instance as the inverse of corresponding item popularity value, thus popular items are imposed lower weights, while the long-tail items are boosted. IPS guarantees zero bias, however, it is with high variance. A series of variants have been proposed to attain more stable results based on IPS. Bottou et al. <ref type="bibr" target="#b9">[10]</ref> add max-capping on IPS value, Gruson et al. <ref type="bibr" target="#b17">[18]</ref> further add normalization, and smoothing and re-normalization are also added to reduce the variance of IPS <ref type="bibr" target="#b17">[18]</ref>. IPS and its variants attain unbiased or low-biased recommendation, only from the perspective of items, while ignoring the variety of users' conformity. Imposing different weights is insufficient to comprehensively capture user conformity, since it inherently depends on both user and item.</p><p>Besides IPS, Bonner et al. <ref type="bibr" target="#b8">[9]</ref> proposed CausE that performs two MF on a large biased dataset and a small unbiased dataset respectively. L1 or L2 regularization are exploited to force the two factorized embeddings similar with each other. However, conformity is still not taken into consideration in CausE. In recommendation with explicit feedback (e.g. rating prediction), Sinha et al. <ref type="bibr" target="#b41">[42]</ref> decomposed observed ratings to the union of real ratings and recommender influence. With several strong assumptions, they attained a closed-form solution to recover real ratings from observational ratings based on SVD. However, these assumptions turn out to be invalid in the more prevalent implicit feedback setting.</p><p>Unlike aforementioned approaches that ignore user conformity and bundle different causes into unified representations, our approach achieves causal recommendation with disentangled embeddings for user interest and conformity. To our knowledge, our proposed methodology is the first attempt to tackle the causal recommendation problem from the perspective of users, attaining superior robustness and interpretability by disentangling user interest and conformity. Disentangled Representation Learning. Learning representations in which different semantics are disentangled is crucial for robust use of neural models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b43">44]</ref>. Existing approaches mainly focus on computer vision <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28]</ref>. For example, β-VAE <ref type="bibr" target="#b21">[22]</ref> learns interpretable representations from raw images in an unsupervised manner. Disentangled representation learning in recommender systems was not explored until recently <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b46">47]</ref>. Ma et al. <ref type="bibr" target="#b32">[33]</ref> proposed to use Variational Auto-Encoder to disentangle macro-level concept such as intention on different items, and disentangle micro-level factors like color or size of an item. Wang et al. <ref type="bibr" target="#b46">[47]</ref> utilized Graph Convolutional Networks to learn disentangled representations for different latent user intentions. These methods decompose user intent into finer granularity, such as the brand or color of an item, while ignoring user conformity, which is essential for recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we propose a general framework for disentangling user interest and conformity for recommendation with causal embedding. We develop a concise additive causal model and formulate this model with both causal graph and SCM. Separate embeddings are adopted for interest and conformity according to the proposed SCM. We extract cause-specific data from observational interactions and train different embeddings with different cause-specific data to achieve disentanglement between interest and conformity. The two causes are aggregated and balanced by multi-task curriculum learning. Based on concise and reasonable causal models, DICE consistently outperforms state-of-the-art algorithms with remarkable improvements. Experiments show that DICE is more robust under non-IID circumstances, compared with other baselines. Analysis on disentanglement demonstrates that user interest and conformity are largely independent in the two sets of embeddings. The learned embeddings are of high quality and interpretability, which is promising to explore novel applications using the learned disentangled representations. DICE decomposes each click interaction into two causes, interest and conformity. A particular meaningful direction for future work is extending DICE to include finer level of causes. For example, the macro-level cause interest could be further divided into micro-level causes such as intentions towards the brand, price or color of items. Overall, we believe disentangling interest and conformity opens new doors for understanding user-item interactions of recommender systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Feedback loop of recommender system. Users interact with the model according to user intention, and the model is trained with users' interaction data. training data test data representation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Causal graph and causal embeddings. (a) We make concise causal modeling on each click that it results from two independent causes, interest and conformity. (b) We adopt separate embeddings for interest and conformity, thus each user or item has two embeddings. We force each embedding to capture only one cause by training different embeddings with causespecific data and adding direct disentanglement supervision, under the framework of multi-task curriculum learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison between using embeddings and using scalars on two datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (a) Overlapped items with ItemPop. Larger IOU means recommendation result is more similar to ItemPop which recommends top popular items. (b) Visualization of the learned item embeddings of DICE on Movielens-10M and Netflix dataset. Interest embeddings are represented by crosses, and conformity embeddings are represented by dots.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4. 4 . 1</head><label>41</label><figDesc>Impact of Negative Sampling. As introduced previously, we adopt Popularity based Negative Sampling with Margin (PNSM)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :Figure 7 :Figure 8 :</head><label>678</label><figDesc>Figure 6: Performance comparison between DICE and IPS-CNSR under different levels of intervention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>cl ick are independent noises. SCM ζ DICE expresses causal dependence of interest, conformity and click, where f 1 , f 2 and f 3 are the underlying causal mechanisms for interest X int , conformity X con , and click Y cl ick respectively.</figDesc><table><row><cell>Practically, those</cell></row><row><cell>causal mechanisms are decided by optimizing within a given family</cell></row><row><cell>of functions [38], such as deep neural networks. When we consider</cell></row><row><cell>interventions on user conformity, we simply replace X con ui with pre-assigned values.</cell></row><row><cell>SCM ζ DICE in (</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets. (Ent. stands for entropy value of the number of interactions for all items. Larger entropy value of test data shows the non-IID condition.In summary, we propose an additive causal model on user interest and conformity. Based on SCM ζ DICE , we develop separate causal embeddings for individual cause, which capture the diversity of conformity and interest. A bunch of inequalities are derived from our causal model, decomposing the causal learning task into conformity modeling, interest modeling, estimating clicks and discrepancy task. Disentangled representations for underlying causes are obtained by training different embeddings with cause-specific data. To attain robust recommendation, multi-task curriculum learning is adopted to aggregate the two causes. Meanwhile, our causal framework is based on how data is generated and hence they are model-independent. Therefore, the proposed DICE methodology provides a highly general framework for disentangling user interest and conformity, which can be smoothly integrated into existing recommendation models. In our experiments, we successfully develop DICE on top of state-of-the-art recommender systems based on Graph Convolutional Networks.</figDesc><table><row><cell>Dataset</cell><cell cols="4">User Item Interaction Ent. Train Ent. Test</cell></row><row><cell cols="2">Movielens-10M 37962 4819</cell><cell>1371473</cell><cell>6.22</cell><cell>7.97</cell></row><row><cell>Netflix</cell><cell>32450 8432</cell><cell>2212690</cell><cell>6.85</cell><cell>8.54</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Overall performance on Movielens-10M dataset and Netflix dataset.</figDesc><table><row><cell cols="2">Dataset</cell><cell></cell><cell>TopK = 20</cell><cell>Movielens-10M</cell><cell>TopK = 50</cell><cell></cell><cell>TopK = 20</cell><cell>Netflix</cell><cell>TopK = 50</cell><cell></cell></row><row><cell>Model</cell><cell>Method</cell><cell>Recall</cell><cell>HR</cell><cell>NDCG Recall</cell><cell>HR</cell><cell>NDCG Recall</cell><cell>HR</cell><cell>NDCG Recall</cell><cell>HR</cell><cell>NDCG</cell></row><row><cell></cell><cell>None</cell><cell cols="9">0.1286 0.4429 0.0846 0.2346 0.6295 0.1170 0.1122 0.5194 0.0943 0.1928 0.6749 0.1185</cell></row><row><cell></cell><cell>IPS</cell><cell cols="9">0.1335 0.4434 0.0852 0.2376 0.6288 0.1174 0.1058 0.4882 0.0864 0.1855 0.6562 0.1112</cell></row><row><cell></cell><cell>IPS-C</cell><cell cols="9">0.1367 0.4564 0.0875 0.2429 0.6383 0.1203 0.1119 0.5046 0.0919 0.1938 0.6700 0.1174</cell></row><row><cell>MF</cell><cell>IPS-CN</cell><cell cols="9">0.1412 0.4700 0.0925 0.2509 0.6477 0.1264 0.1080 0.5042 0.0935 0.1912 0.6621 0.1185</cell></row><row><cell></cell><cell cols="10">IPS-CNSR 0.1365 0.4588 0.0895 0.2419 0.6366 0.1219 0.1110 0.5159 0.0948 0.1937 0.6713 0.1192</cell></row><row><cell></cell><cell>CausE</cell><cell cols="9">0.1157 0.4066 0.0744 0.2121 0.5924 0.1037 0.0935 0.4641 0.0782 0.1651 0.6272 0.0994</cell></row><row><cell></cell><cell>DICE</cell><cell cols="9">0.1634 0.5197 0.1084 0.2872 0.6975 0.1468 0.1258 0.5545 0.1070 0.2164 0.7090 0.1345</cell></row><row><cell></cell><cell>None</cell><cell cols="9">0.1378 0.4625 0.0898 0.2513 0.6505 0.1247 0.1026 0.4908 0.0870 0.1842 0.6609 0.1112</cell></row><row><cell></cell><cell>IPS</cell><cell cols="9">0.1394 0.4645 0.0919 0.2538 0.6473 0.1275 0.1101 0.5091 0.0950 0.1941 0.6657 0.1203</cell></row><row><cell></cell><cell>IPS-C</cell><cell cols="9">0.1478 0.4829 0.0971 0.2654 0.6632 0.1339 0.1157 0.5219 0.1004 0.2037 0.6816 0.1270</cell></row><row><cell>GCN</cell><cell>IPS-CN</cell><cell cols="9">0.1119 0.3997 0.0701 0.2281 0.6112 0.1057 0.0726 0.3991 0.0643 0.1472 0.5841 0.0866</cell></row><row><cell></cell><cell cols="10">IPS-CNSR 0.1300 0.4427 0.0852 0.2336 0.6282 0.1171 0.0826 0.4337 0.0715 0.1589 0.6124 0.0940</cell></row><row><cell></cell><cell>CausE</cell><cell cols="9">0.1027 0.3729 0.0632 0.2044 0.5811 0.0941 0.0838 0.4289 0.0677 0.1569 0.6119 0.0902</cell></row><row><cell></cell><cell>DICE</cell><cell cols="9">0.1812 0.5563 0.1228 0.3100 0.7216 0.1629 0.1420 0.5910 0.1217 0.2367 0.7340 0.1499</cell></row><row><cell cols="6">popular items are less selected. Moreover, we cap the probability</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">at 0.9 to limit the number of items that do not show in training set</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">[9]. Finally, we obtain a 70/10/20 split for training set (60% normal</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">and 20% intervened), validation set (10% intervened) and test set</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p><p><p>(20% intervened)</p>. Test data can be regarded as recommendation result under a fully random policy. As a consequence, conformity in test data is distinct from that in training data, since users have access to all items with equal probability in test data, rather than seeing more popular items in training data. We refer to</p><ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b29">30]</ref> </p>for details on extracting an intervened test set from original interaction data. To show that training data and test data are non-IID, we count the number of interactions for each item and calculate the entropy, hence larger entropy value indicates that different items are of more equal probability to be exposed to users. As illustrated in Table</p>1</p>, entropy on test data is much larger than that on training data for both datasets. In other words, models are trained on normal data, while evaluated on intervened data.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Results show that the disentanglement design of interest embeddings and conformity embeddings successfully distinguish the two causes of user interactions. It allows the framework to capture invariant interest from training data, and adapt to intervened conformity in test cases. • DICE is highly general framework which can be combined with various recommendation models. Besides attaining the best performance on both datasets, the proposed DICE framework also outperforms all other baselines with both recommendation models, MF and GCN. The proposed concise causal model is sourced from how the data is generated, thus the proposed framework is independent with backbone recommendation models. Results based on MF and GCN illustrate that DICE is a general framework, which can be smoothly integrated into various embedding based recommendation algorithms. • Entangled causal models are not stable on different datasets and metrics. From the results in Table 2, entangled causal models like IPS and CausE can not make improvements consistently on different datasets and metrics. For example, IPS-CN achieves the second best performance on Movielens-10M dataset, but fails to make improvements on Netflix dataset with MF as recommendation model. In addition, IPS-CNSR attains decent performance with respect to NDCG on Netflix dataset with MF as recommendation model, but it is even worse than None (no causal model) in terms of another metric, HR. Without disentangling interest and conformity, those causal models are not stable on different datasets and metrics. In contrast, the disentangled DICE framework attains consistent improvements by disentangling the underlying causes.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Comparison between the proposed negative sampling strategy PNSM with traditional random strategy on Movielens-10M dataset.</figDesc><table><row><cell></cell><cell></cell><cell>Top-K=20</cell><cell></cell><cell></cell><cell>Top-K=50</cell></row><row><cell>Name</cell><cell>Recall</cell><cell>HR</cell><cell cols="2">NDCG Recall</cell><cell>HR</cell><cell>NDCG</cell></row><row><cell>PNSM</cell><cell cols="6">0.1634 0.5197 0.1084 0.2872 0.6975 0.1468</cell></row><row><cell cols="2">RANDOM 0.1274</cell><cell>0.4394</cell><cell>0.0843</cell><cell>0.2306</cell><cell>0.6255</cell><cell>0.1160</cell></row><row><cell cols="7">under all degrees of intervention, which proves the robustness of</cell></row><row><cell cols="5">disentangling user interest and conformity.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Formally, users should have interest and conformity embeddings, and items should have characteristic and popularity embeddings. We overload the usage of interest and conformity on items to simplify expressions and avoid confusions.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by The National Key Research and Development Program of China under grant 2020AAA0106000, the National Natural Science Foundation of China under U1936217, 61971267, 61972223, 61941117, 61861136003, U19A2079.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Controlling popularity bias in learning-to-rank recommendation</title>
		<author>
			<persName><forename type="first">Himan</forename><surname>Abdollahpouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bamshad</forename><surname>Mobasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="42" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A General Framework for Counterfactual Learning-to-Rank</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenta</forename><surname>Takatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using novelty score of unseen items to handle popularity bias in recommender systems</title>
		<author>
			<persName><forename type="first">Punam</forename><surname>Bedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjali</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chhavi</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 International Conference on Contemporary Computing and Informatics (IC3I)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="934" to="939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The bellkor 2008 solution to the netflix prize</title>
		<author>
			<persName><forename type="first">M</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics Research Department at AT&amp;T Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical biases in Information Retrieval metrics for recommender systems</title>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Bellogín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iván</forename><surname>Cantador</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval Journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="606" to="634" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasim</forename><surname>Rahaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olexa</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10912</idno>
		<title level="m">A metatransfer objective for learning to disentangle causal mechanisms</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The netflix prize</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Lanning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD cup and workshop</title>
		<meeting>KDD cup and workshop</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Causal embeddings for recommendation</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flavian</forename><surname>Vasile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="104" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Counterfactual reasoning and learning systems: The example of computational advertising</title>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joaquin</forename><surname>Quiñonero-Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><forename type="middle">X</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elon</forename><surname>Portugaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Snelson</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="3207" to="3260" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Probabilistic Reformulation of Memory-Based Collaborative Filtering: Implications on Popularity Biases</title>
		<author>
			<persName><forename type="first">Rocío</forename><surname>Cañamares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Should i follow the crowd? a probabilistic analysis of the effectiveness of popularity in recommender systems</title>
		<author>
			<persName><forename type="first">Rocío</forename><surname>Cañamares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="415" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How algorithmic confounding in recommendation systems increases homogeneity and decreases utility</title>
		<author>
			<persName><forename type="first">Allison Jb</forename><surname>Chaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><forename type="middle">E</forename><surname>Engelhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="224" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hande</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03240</idno>
		<title level="m">Fuli Feng, Meng Wang, and Xiangnan He. 2020. Bias and Debias in Recommender System: A Survey and Future Directions</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning disentangled joint continuous and discrete representations</title>
		<author>
			<persName><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="710" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07728</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Offline a/b testing for recommender systems</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Gilotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clément</forename><surname>Calauzènes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Nedelec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Dollé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="198" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Offline Evaluation to Make Decisions About PlaylistRecommendation Algorithms</title>
		<author>
			<persName><forename type="first">Alois</forename><surname>Gruson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Charbuillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samantha</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Tardieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="420" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The MovieLens Datasets: History and Context</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maxwell Anuntitled.Texd Konstan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2827872</idno>
		<ptr target="https://doi.org/10.1145/2827872" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Interact. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2015-12">2015. Article 19 (Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</title>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iclr</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to decompose and disentangle representations for video prediction</title>
		<author>
			<persName><forename type="first">Jun-Ting</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De-An</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><forename type="middle">F</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">What recommenders recommend: an analysis of recommendation biases and possible countermeasures</title>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iman</forename><surname>Kamehkhosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jugovac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="427" to="491" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Degenerate feedback loops in recommender systems</title>
		<author>
			<persName><forename type="first">Ray</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tor</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">András</forename><surname>György</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2019 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="383" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unbiased learning-to-rank with biased feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Causal inference for recommendation</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Causation: Foundation to Application, Workshop at UAI. AUAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Are You Influenced by Others When Rating? Improve Rating Prediction by Conformity Modeling</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
		<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="269" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunnar</forename><surname>Raetsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4114" to="4124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning disentangled representations for recommendation</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5712" to="5723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008. 2008</date>
			<pubPlace>Nov</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malcolm</forename><surname>Slaney</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.5267</idno>
		<title level="m">Collaborative filtering and the missing at random assumption</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Naumov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dheevatsa</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hao-Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narayanan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongsoo</forename><surname>Sundaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udit</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carole-Jean</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisson</forename><forename type="middle">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmytro</forename><surname>Azzolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Dzhulgakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilia</forename><surname>Mallevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghai</forename><surname>Cherniavskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghuraman</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ansha</forename><surname>Krishnamoorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Kondratenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianjie</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><surname>Smelyanskiy</surname></persName>
		</author>
		<idno>CoRR abs/1906.00091</idno>
		<ptr target="https://arxiv.org/abs/1906.00091" />
		<title level="m">Deep Learning Recommendation Model for Personalization and Recommendation Systems</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The book of why: the new science of cause and effect</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Elements of causal inference</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.2618</idno>
		<title level="m">Bayesian personalized ranking from implicit feedback</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Recommendations as treatments: debiasing learning and evaluation</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10500</idno>
		<title level="m">Causality for Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deconvolving feedback loops in recommender systems</title>
		<author>
			<persName><forename type="first">Ayan</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">F</forename><surname>Gleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Ramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3243" to="3251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Item popularity and recommendation accuracy</title>
		<author>
			<persName><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM conference on Recommender systems</title>
		<meeting>the fifth ACM conference on Recommender systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Suter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ðorđe</forename><surname>Miladinović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00007</idno>
		<title level="m">Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Gábor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">L</forename><surname>Székely</surname></persName>
		</author>
		<author>
			<persName><surname>Rizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brownian distance covariance</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="1236" to="1265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Measuring and testing dependence by correlation of distances</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gábor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">L</forename><surname>Székely</surname></persName>
		</author>
		<author>
			<persName><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName><surname>Nail K Bakirov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The annals of statistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2769" to="2794" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Disentagnled Graph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongye</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>Xiangnan He, Tonog Xu, and Tat-Seng Chua</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The deconfounded recommender: A causal inference approach to recommendation</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06581</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>Serge Belongie, and Deborah Estrin</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
