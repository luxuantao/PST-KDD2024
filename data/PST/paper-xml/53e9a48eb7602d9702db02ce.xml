<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stable Concurrent Synchronization in Dynamic System Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-06-02">June 2, 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Quang-Cuong</forename><surname>Pham</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Département d&apos;Informatique École Normale Supérieure</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jean-Jacques</forename><surname>Slotine</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Nonlinear Systems Laboratory</orgName>
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stable Concurrent Synchronization in Dynamic System Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-06-02">June 2, 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">F50DBF97EFE1D467B3B7EB8BF0C053CD</idno>
					<idno type="arXiv">arXiv:q-bio.NC/0510051v3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In a network of dynamical systems, concurrent synchronization is a regime where multiple groups of fully synchronized elements coexist. In the brain, concurrent synchronization may occur at several scales, with multiple "rhythms" interacting and functional assemblies combining neural oscillators of many different types. Mathematically, stable concurrent synchronization corresponds to convergence to a flow-invariant linear subspace of the global state space. We derive a general condition for such convergence to occur globally and exponentially. We also show that, under mild conditions, global convergence to a concurrently synchronized regime is preserved under basic system combinations such as negative feedback or hierarchies, so that stable concurrently synchronized aggregates of arbitrary size can be constructed. Robustnesss of stable concurrent synchronization to variations in individual dynamics is also quantified. Simple applications of these results to classical questions in systems neuroscience and robotics are discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Distributed synchronization phenomena are the subject of intense research. In the brain, such phenomena are known to occur at different scales, and are heavily studied at both the anatomical and computational levels. In particular, synchronization has been proposed as a general principle for temporal binding of multisensory data <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b31">32]</ref>, and as a mechanism for perceptual grouping <ref type="bibr" target="#b50">[51]</ref>, neural computation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b49">50]</ref> and neural communication <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref>. Similar mathematical models describe fish schooling or certain types of phase-transition in physics <ref type="bibr" target="#b44">[45]</ref>.</p><p>In an ensemble of dynamical elements, concurrent synchronization is defined as a regime where the whole system is divided into multiple groups of fully synchronized elements <ref type="foot" target="#foot_0">1</ref> , but elements from different groups are not necessarily synchronized <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b35">36]</ref> and can be of entirely different dynamics <ref type="bibr" target="#b10">[11]</ref>. It can be easily shown that such a regime corresponds to a flow-invariant linear subspace of the global state space. Concurrent synchronization phenomena are likely pervasive in the brain, where multiple "rhythms" are known to coexist <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b38">39]</ref>, neurons can exhibit many qualitatively different types of oscillations <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b15">16]</ref>, and functional models often combine multiple oscillatory dynamics.</p><p>In this paper, we introduce a simple sufficient condition for a general dynamical system to converge to a flow-invariant subspace. Our analysis is built upon nonlinear contraction theory <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b47">48]</ref>, and thus it inherits many of the theory's features :</p><p>• global exponential convergence and stability are guaranteed,</p><p>• convergence rates can be explicitly computed as eigenvalues of well-defined symmetric matrices,</p><p>• robustness to variations in dynamics can be easily quantified,</p><p>• under simple conditions, convergence to a concurrently synchronized state can be preserved through system combinations.</p><p>As we shall see, under simple conditions on the coupling strengths, architectural symmetries <ref type="bibr" target="#b11">[12]</ref> and/or diffusion-like couplings create globally stable concurrent synchronization phenomena. This is illustrated in figure <ref type="figure">1</ref>, which is very loosely inspired by oscillations in the thalamocortical system <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39]</ref>. Qualitatively, global stability of the concurrent synchronization is in the same sense that an equilibrium point is globally stable -any initial conditions will lead back to it, in an exponential fashion. But of course it can yield extremely complex, coordinated behaviors.</p><p>Section 2 recalls key concepts of nonlinear contraction theory and derives a theoretical tool for studying global convergence to a flow-invariant subspace. Section 3 presents the paper's main mathematical results, relating stable concurrent synchronization to coupling structures and flow-invariant subspaces created by symmetries or diffusion-like couplings. Robustnesss of concurrent synchronization to variations in individual dynamics is also quantified, showing in particular how approximate symmetries lead to quasi-synchronization. Section 4, motivated by evolution and development, studies conditions under which concurrent synchronization can be preserved through combinations of multiple concurrently synchronized regimes. Finally, section 5 discusses potential applications of these results to general questions in systems neuroscience and robotics. Figure <ref type="figure">1</ref>: An example of concurrent synchronization. Systems and connections of the same shape (and color) have identical dynamics (except black arrows, which represent arbitrary connections, and dashed arrows, which represent diffusive connections). This paper shows that under simple conditions on the coupling strengths, the group of (green) squares globally exponentially synchronizes (thus providing synchronized input to the outer elements), and so does the group of (yellow) diamonds, regardless of the specific dynamics, connections, or inputs of the other systems.</p><p>2 Basic Tools</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Nonlinear contraction theory</head><p>This section reviews basic results of nonlinear contraction theory <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48]</ref>, which is the main stability analysis tool used in the paper. Essentially, a nonlinear time-varying dynamic system will be called contracting if initial conditions or temporary disturbances are forgotten exponentially fast, i.e., if trajectories of the perturbed system return to their nominal behavior with an exponential convergence rate. It turns out that relatively simple algebraic conditions can be given for this stability-like property to be verified, and that this property is preserved through basic system combinations.</p><p>While we shall derive global properties of nonlinear systems, many of our results can be expressed in terms of eigenvalues of symmetric matrices <ref type="bibr" target="#b13">[14]</ref>. Given a square matrix A, the symmetric part of A is denoted by A s . The smallest and largest eigenvalues of A s are denoted by λ min (A) and λ max (A). Given these notations, the matrix A is positive definite (denoted A &gt; 0) if λ min (A) &gt; 0, and it is negative definite (denoted A &lt; 0) if λ max (A) &lt; 0. Finally, a square matrix A(x, t) is uniformly positive definite if ∃β &gt; 0, ∀x, ∀t : λ min (A(x, t)) ≥ β, and it is uniformly negative definite if ∃β &gt; 0, ∀x, ∀t : λ min (A(x, t)) ≤ -β.</p><p>The basic theorem of contraction analysis, derived in <ref type="bibr" target="#b26">[27]</ref>, can be stated as:</p><p>Theorem 1 (Contraction) Consider, in R n , the deterministic system</p><formula xml:id="formula_0">ẋ = f(x, t)<label>(1)</label></formula><p>where f is a smooth nonlinear function. Denote the Jacobian matrix of f with respect to its first variable by ∂f ∂x . If there exists a square matrix Θ(x, t) such that Θ(x, t) ⊤ Θ(x, t) is uniformly positive definite and the matrix</p><formula xml:id="formula_1">F = Θ + Θ ∂f ∂x Θ -1</formula><p>is uniformly negative definite, then all system trajectories converge exponentially to a single trajectory, with convergence rate | sup x,t λ max (F)| &gt; 0. The system is said to be contracting, F is called its generalized Jacobian, and Θ(x, t) ⊤ Θ(x, t) its contraction metric.</p><p>It can be shown conversely that the existence of a uniformly positive definite metric M(x, t) = Θ(x, t) ⊤ Θ(x, t) with respect to which the system is contracting is also a necessary condition for global exponential convergence of trajectories <ref type="bibr" target="#b26">[27]</ref>. Furthermore, all transformations Θ corresponding to the same M lead to the same eigenvalues for the symmetric part F s of F <ref type="bibr" target="#b42">[43]</ref>, and thus to the same contraction rate | sup x,t λ max (F)|.</p><p>In the linear time-invariant case, a system is globally contracting if and only if it is strictly stable, and F can be chosen as a normal Jordan form of the system with Θ the coordinate transformation to that form <ref type="bibr" target="#b26">[27]</ref>. Contraction analysis can also be derived for discrete-time systems and for classes of hybrid systems <ref type="bibr" target="#b27">[28]</ref>.</p><p>Finally, it can be shown that contraction is preserved through basic system combinations (such as parallel combinations, hierarchies, and certain types of negative feedback, see <ref type="bibr" target="#b26">[27]</ref> for details), a property which we shall extend to the synchronization context in this paper (section 4).</p><p>Theorem 2 (Contraction and robustness) Consider a contracting system ẋ = f(x, t), with Θ = I and contraction rate λ. Let P 1 (t) be a trajectory of the system, and let P 2 (t) be a trajectory of the disturbed system</p><formula xml:id="formula_2">ẋ = f(x, t) + d(x, t)</formula><p>Then the distance R(t) between P 1 (t) and P 2 (t) verifies R(t) ≤ sup x,t d(x, t) /λ after exponential transients of rate λ.</p><p>For a proof and generalisation of this theorem, see section 3.7 in <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Convergence to a flow-invariant subspace</head><p>We now derive a simple tool upon which the analyses of this paper will be based. The derivation is inspired by the idea of "partial" contraction, introduced in <ref type="bibr" target="#b47">[48]</ref>, which consists in applying contraction tools to virtual auxiliary systems so as to address questions more general than trajectory convergence. Consider again, in R n , the deterministic system</p><formula xml:id="formula_3">ẋ = f(x, t)<label>(2)</label></formula><p>where f is a smooth nonlinear function. Assume that there exists a flow-invariant linear subspace M (i.e. a linear subspace M such that ∀t : f(M, t) ⊂ M), which implies that any trajectory starting in M remains in M. Let p = dim(M), and consider an orthonormal basis (e 1 , . . . , e n ) where the first p vectors form a basis of M and the last n -p a basis of M ⊥ . Define an (n -p) × n matrix V whose rows are e ⊤ p+1 , . . . , e ⊤ n . V may be regarded as a projection<ref type="foot" target="#foot_1">2</ref> on M ⊥ , and it verifies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20]</ref> :</p><formula xml:id="formula_4">V ⊤ V + U ⊤ U = I n VV ⊤ = I n-p x ∈ M ⇐⇒ Vx = 0</formula><p>where U is the matrix formed by the first p vectors.</p><p>Theorem 3 Consider a linear flow-invariant subspace M and the associated orthonormal projection matrix V. A particular solution x p (t) of system (2) converges exponentially to M if the system</p><formula xml:id="formula_5">ẏ = Vf(V ⊤ y + U ⊤ Ux p (t), t)<label>(3)</label></formula><p>is contracting with respect to y.</p><p>If the above contraction condition is fullfilled for all x p , then starting from any initial conditions, all trajectories of system (2) will exponentially converge to M. If furthermore all the contraction rates for (3) are lower-bounded by some λ &gt; 0, uniformly in x p and in a common metric, then the convergence to M will be exponential with rate λ (see figure <ref type="figure" target="#fig_0">2</ref>).</p><p>Proof : Let z p = Vx p . By construction, x p converges to the subspace M if and only if z p converges to 0. Multiplying (2) by V on the left, we get</p><formula xml:id="formula_6">żp = Vf(V ⊤ z p + U ⊤ Ux p , t)<label>(4)</label></formula><p>From (4), y(t) = z p (t) is a particular solution of system (3). In addition, since U ⊤ Ux p ∈ M and the linear subspace M is flow-invariant, one has f(U ⊤ Ux p ) ∈ M = Null(V), and hence y(t) = 0 is another particular solution of system (3). If system (3) is contracting with respect to y, then all its solutions converge exponentially to a single trajectory, which implies in particular that z p (t) converges exponentially to 0.</p><p>The remainder of the theorem is immediate.</p><formula xml:id="formula_7">Corollary 1 A simple sufficient condition for global exponential convergence to M is that V ∂f ∂x V ⊤ &lt; 0 uniformly (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>shrinking length in the orthogonal subspace a given trajectory the corresponding trajectory in the invariant subspace of dimension p of dimension n-p or more generally, that there exists a constant invertible transform Θ on M ⊥ such that</p><formula xml:id="formula_9">ΘV ∂f ∂x V ⊤ Θ -1 &lt; 0 uniformly<label>(6)</label></formula><p>Proof : The Jacobian of (3) with respect to y is</p><formula xml:id="formula_10">V ∂f ∂x V ⊤ y + U ⊤ Ux p (t), t V ⊤</formula><p>so that the result is immediate by applying Theorem 1. Remarks</p><p>• Non-orthonormal bases. In practice, the subspace M is often defined by the conjunction of (n-p) linear constraints. In a synchronization context, for instance, each of the constraints may be, e.g., of the form x i = x j where x i and x j are subvectors of the state x. This provides directly a (generally not orthonormal) basis (e ′ p+1 , . . . , e ′ n ) of M ⊥ , and thus a matrix V ′ whose rows are e ′ p+1 ⊤ , . . . , e ′ n ⊤ , and which verifies</p><formula xml:id="formula_11">V ′ = TV with T an invertible (n -p) × (n -p) matrix. We have x ∈ M ⇐⇒ V ′ x = 0 and V ∂f ∂x V ⊤ &lt; 0 ⇐⇒ V ′ ∂f ∂x V ′ ⊤ &lt; 0<label>(7)</label></formula><p>Consider for instance three systems of dimension m and two systems of dimension p, and assume that M = {x 1 = x 2 , x 5 = -10x 4 } is the synchronization subspace of interest (with x i denoting the state of each individual system). One has directly</p><formula xml:id="formula_12">V ′ = I m -I m 0 • • • 0 0 • • • 0 10I p I p</formula><p>Note however that the equivalence in equation <ref type="bibr" target="#b6">(7)</ref> does not yield the same upper bound for the eigenvalues of the two matrices. Thus, in order to compute explicitly the convergence rate to M, one has to revert to the orthonormal version, using e.g. a Gram-Schmidt procedure <ref type="bibr" target="#b13">[14]</ref> on the rows of V ′ .</p><p>• More general invariant subspaces. This theorem can be extended straightforwardly to time-varying affine invariant subspaces of the form m(t)+M (apply the theorem to x(t) = x(t) -m(t)). Preliminary results have also been obtained for nonlinear invariant manifolds <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Global synchronization in networks of coupled identical dynamical elements</head><p>In this section, we provide by using theorem 3 a unifying and systematic view on several prior results in the study of synchronization phenomena (see e.g. <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b25">26]</ref> and references therein). Consider first a network containing n identical dynamical elements with diffusive couplings <ref type="bibr" target="#b47">[48]</ref> ẋi = f(x i , t)</p><formula xml:id="formula_13">+ j =i K ij (x j -x i ) i = 1, . . . , n<label>(8)</label></formula><p>Let L be the Laplacian matrix of the network (</p><formula xml:id="formula_14">L ii = j =i K ij , L ij = -K ij for j = i), and 3 ⌢ x =    x 1 . . . x n    , ⌢ f( ⌢ x, t) =    f(x 1 , t) . . . f(x n , t)   </formula><p>Equation ( <ref type="formula" target="#formula_13">8</ref>) can be rewritten in matrix form</p><formula xml:id="formula_15">⌢ x = ⌢ f( ⌢ x, t) -L ⌢ x<label>(9)</label></formula><p>The Jacobian matrix of this system is </p><formula xml:id="formula_16">J = ⌢ G -L, where ⌢ G( ⌢ x, t) =    ∂f ∂x (x 1 , t) 0 0 0 . . . 0 0 0 ∂f ∂x (x n , t)    Let now (</formula><formula xml:id="formula_17">f( ⌢ x * , t) -L ⌢ x * =    f(x * 1 , t) . . . f(x * 1 , t)    ∈ M</formula><p>which means that M is flow-invariant. Consider, as in section 2.2, the projection matrix V on M ⊥ . Since V is built from orthonormal vectors,</p><formula xml:id="formula_18">λ max (V ⌢ G( ⌢ x, t)V ⊤</formula><p>) is upper-bounded by max i λ max ∂f ∂x (x i , t) . Thus, by virtue of theorem 3, a simple sufficient condition for global exponential synchronization is</p><formula xml:id="formula_19">λ min (VLV ⊤ ) &gt; sup a,t λ max ∂f ∂x (a, t)<label>(10)</label></formula><p>Furthermore, the synchronization rate, i.e. the rate of convergence to the synchronization subspace, is the contraction rate of the auxiliary system <ref type="bibr" target="#b2">(3)</ref>.</p><p>Let us now make some brief remarks.</p><p>(i) Undirected<ref type="foot" target="#foot_3">4</ref> diffusive networks. In this case, it is well known that L is symmetric positive semi-definite, and that M is a subset of the eigenspace corresponding to the eigenvalue 0 <ref type="bibr" target="#b6">[7]</ref>. Furthermore, if the network is connected, this eigenspace is exactly M, and therefore VLV ⊤ is positive definite (its smallest eigenvalue is called the network's algebraic connectivity <ref type="bibr" target="#b6">[7]</ref>). Assume now that L is parameterized by a positive scalar k (i.e. L = kL 0 , for some L 0 ), and that ∂f ∂x is upper-bounded. Then, for large enough k (i.e. for strong enough coupling strength), all elements will synchronize exponentially.</p><p>(ii) Network of contracting elements. If the elements x i are already contracting when taken in isolation (i.e. ∂f ∂x is uniformly negative definite), then in presence of weak or non-existent couplings (VLV ⊤ = 0), the Jacobian matrix J of the global system will remain uniformly negative definite <ref type="bibr" target="#b47">[48]</ref>. Thus, the projected Jacobian matrix will be a fortiori uniformly negative definite, implying exponential convergence to the synchronized state.</p><p>One can also obtain this conclusion by using a "pure" contraction analysis. Indeed, choose a particular initial state where x 1 (0) = . . . = x n (0). The trajectory starting with that initial state verifies ∀t, x 1 (t) = . . . = x n (t) by flow-invariance. Since the global system is contracting, any other initial conditions will lead exponentially to that particular trajectory, i.e., starting with any initial conditions, the system will exponentially converge to a synchronized state.</p><p>(iii) Nonlinear couplings. Similarly to <ref type="bibr" target="#b47">[48]</ref>, the above result actually extends to nonlinear couplings described by a Laplacian matrix L( ⌢ x, t). Replacing the auxiliary system (3) by</p><formula xml:id="formula_20">ẏ = V ⌢ f(V ⊤ y + U ⊤ U ⌢ x p , t) -VL( ⌢ x p , t)(V ⊤ y + U ⊤ U ⌢ x p )</formula><p>the same steps show that global synchronization is achieved exponentially for</p><formula xml:id="formula_21">inf ⌢ x,t λ min (VL( ⌢ x, t)V ⊤ ) &gt; sup a,t λ max ∂f ∂x (a, t)</formula><p>(iv) Leader-followers network. Assume that there exists a leader x ℓ in the network <ref type="bibr" target="#b47">[48]</ref>, i.e., an element which has no incoming connections from the other elements, ẋℓ = f(x ℓ , t). Convergence to M (guaranteed by satisfying ( <ref type="formula" target="#formula_19">10</ref>)) then implies that all the network elements will synchronize to the leader trajectory x ℓ (t).</p><p>(v) Non-diffusive couplings. Note that the above results are actually not limited to diffusive couplings but apply to any system of the general form <ref type="bibr" target="#b8">(9)</ref>. This point will be further illustrated in sections 3.1 and 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Main discussion</head><p>In nonlinear contraction theory, the analysis of dynamical systems is greatly simplified by studying stability and nominal motion separately. We propose a similar point of view for analyzing synchronization in networks of dynamical systems. In section 3.1, we study specific conditions on the coupling structure which guarantee exponential convergence to a linear subspace. In section 3.2, we examine how symmetries and/or diffusion-like couplings can give rise to specific flow-invariant subspaces corresponding to concurrent synchronized states.</p><p>3.1 Some coupling structures and conditions for exponential synchronization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Balanced diffusive networks</head><p>A balanced network <ref type="bibr" target="#b32">[33]</ref> is a directed diffusive network which verifies the following equality for each node i (see figure <ref type="figure" target="#fig_2">3</ref> for an example)</p><formula xml:id="formula_22">j =i K ij = j =i K ji</formula><p>Because of this property, the symmetric part of the Laplacian matrix of the network is itself the Laplacian matrix of the underlying undirected graph to the network 5 . Thus, the positive definiteness of VLV ⊤ for a balanced network is equivalent to the connectedness of some well-defined undirected graph.  </p><formula xml:id="formula_23">L =     4 -2 0 -2 -3 3 0 0 -1 -1 2 0 0 0 -2 2     0.5 0.5 1 1 2.5 1 2 3 4</formula><p>Its underlying undirected graph, with Laplacian matrix</p><formula xml:id="formula_24">L s = L+L ⊤ 2 =     4 -2.5 -0.5 -1 -2.5 3 -0.5 0 -0.5 -0.5 2 -1 -1 0 -1 2    </formula><p>For general directed diffusive networks, finding a simple condition implying the positive definiteness of VLV ⊤ (such as the connectivity condition in the case of undirected networks) still remains an open problem. However, given a particular example, one can compute VLV ⊤ and determine directly whether it is positive definite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Extension of diffusive connections</head><p>In some applications <ref type="bibr" target="#b48">[49]</ref>, one might encounter the following dynamics</p><formula xml:id="formula_25">ẋ1 = f 1 (x 1 , t) + kA ⊤ (Bx 2 -Ax 1 ) ẋ2 = f 2 (x 2 , t) + kB ⊤ (Ax 1 -Bx 2 )</formula><p>Here x 1 and x 2 can be of different dimensions, say d 1 and d 2 . A and B are constant matrices of appropriate dimensions. The Jacobian matrix of the overall system is</p><formula xml:id="formula_26">J = ∂f 1 ∂x 1 ∂f 2 ∂x 2 -kL, where L = A ⊤ A -A ⊤ B -B ⊤ A B ⊤ B</formula><p>Note that L is symmetric positive semi-definite. Indeed, one immediately verifies that</p><formula xml:id="formula_27">∀x 1 , x 2 : x 1 x 2 L x 1 x 2 = (Ax 1 -Bx 2 ) ⊤ (Ax 1 -Bx 2 ) ≥ 0 Consider now the linear subspace of R d 1 × R d 2 defined by M = x 1 x 2 ∈ R d 1 × R d 2 : Ax 1 -Bx 2 = 0</formula><p>and use as before the orthonormal projection V on M ⊥ , so that VLV ⊤ is positive definite. Assume furthermore that M is flow-invariant, i.e.</p><formula xml:id="formula_28">∀(x 1 , x 2 ) ∈ R d 1 × R d 2 , [Ax 1 = Bx 2 ] ⇒ [Af 1 (x 1 ) = Bf 2 (x 2 )]</formula><p>and that the Jacobian matrices of the individual dynamics are upper-bounded. Then large enough k, i.e. for example</p><formula xml:id="formula_29">kλ min (VLV ⊤ ) &gt; max i=1,2 sup a i ,t λ max ∂f i ∂x i (a i , t)</formula><p>ensures exponential convergence to the subspace M.</p><p>The state corresponding to M can be viewed as an extension of synchronization states to systems of different dimensions. Indeed, in the case where x 1 and x 2 have the same dimension and where A = B are non singular, we are in the presence of classical diffusive connections, which leads us back to the discussion of section 2.3.</p><p>As in the case of diffusive connections, one can consider networks of so-connected elements, for example :</p><formula xml:id="formula_30">   ẋ1 = f 1 (x 1 , t) + A ⊤ B (B A x 2 -A B x 1 ) + A ⊤ C (C A x 3 -A C x 1 ) ẋ2 = f 2 (x 2 , t) + B ⊤ C (C B x 3 -B C x 2 ) + B ⊤ A (A B x 1 -B A x 2 ) ẋ3 = f 3 (x 2 , t) + C ⊤ A (A C x 1 -C A x 3 ) + C ⊤ B (B C x 2 -C B x 3 ) leads to a positive semi-definite Laplacian matrix   A ⊤ B A B -A ⊤ B B A 0 -B ⊤ A A B B ⊤ A B A 0 0 0 0   +   0 0 0 0 B ⊤ C B C -B ⊤ C C B 0 -C ⊤ B B C C ⊤ B C B   +   A ⊤ C A C 0 -A ⊤ C C A 0 0 0 -C ⊤ A A C 0 C ⊤ A C A  </formula><p>and potentially a flow-invariant subspace</p><formula xml:id="formula_31">M = {A B x 1 = B A x 2 } ∩ {B C x 2 = C B x 3 } ∩ {C A x 3 = A C x 1 }</formula><p>The above coupling structures can be implemented in nonlinear versions of the predictive hierarchies used in image processing (e.g. <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b37">38]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Excitatory-only networks</head><p>One can also address the case of networks with excitatory-only connections. Consider for instance the following system and its Jacobian matrix</p><formula xml:id="formula_32">6 ẋ1 = f (x 1 , t) + kx 2 ẋ2 = f (x 2 , t) + kx 1 J = ∂f ∂x (x 1 , t) 0 0 ∂f ∂x (x 2 , t) + k 0 1 1 0</formula><p>6 For the sake of clarity, the elements are assumed to be 1-dimensional. However, the same reasoning applies for the multidimensional case as well: instead of span Clearly, span{(1, 1)} is flow-invariant. Applying the methodology described above, we choose V = 1 √ 2 (1, -1), so that the projected Jacobian matrix is 1 2 ∂f ∂x (x 1 , t) + ∂f ∂x (x 2 , t)k. Thus, for k &gt; sup a,t ∂f ∂x (a, t), the two elements synchronize exponentially. In the case of diffusive connections, once the elements are synchronized, the coupling terms disappear, so that each individual element exhibits its natural, uncoupled behavior. This is not the case with excitatory-only connections. This is illustrated in figure <ref type="figure" target="#fig_3">4</ref> using FitzHugh-Nagumo oscillator models (see appendix A for the contraction analysis of coupled FitzHugh-Nagumo oscillators). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Rate models for neuronal populations</head><p>In computational neuroscience, one often uses the following simplified equations to model the dynamics of neuronal populations</p><formula xml:id="formula_33">τ ẋi = -x i + Φ j =i k ij x j (t) + u i (t)</formula><p>Assume that the external inputs u i (t) are all equal, and that the synaptic connections k ij verify ∃c, ∀i, j =i k ij = c (i.e., that they induce input-equivalence, see section 3.2). Then the synchronization subspace {x 1 = . . . = x n } is flow-invariant. Furthermore, since each element, taken in isolation, is contracting with contraction rate 1/τ , synchronization should occur when the coupling is not too strong (see remark (ii) in section 2.3).</p><p>Specifically, consider first the case where Φ is a linear function : Φ(x) = µx. The Jacobian matrix of the global system is then -I n + µK, where K is the matrix of k ij . Using the result of remark (ii) in section 2.3, a sufficient condition for the system to be contracting (and thus synchronizing) is that the couplings are weak enough (or more precisely, such that µλ max (K) &lt; 1).</p><p>The same condition is obtained if Φ is now e.g. a multidimentional sigmoid of maximum slope µ (see remark (iii) in section 2.3).</p><p>Besides the synchronization behavior of these models, their natural contraction property for weak enough couplings of any sign is interesting in its own right. Indeed, given a set of (not necessarily equal) external inputs u i (t), all trajectories of the global system will converge to a unique trajectory, independently of initial conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Symmetries, diffusion-like couplings, flow-invariant subspaces and concurrent synchronization</head><p>Synchronized states can be created in at least two ways : by architectural and internal 7 symmetries <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b35">36]</ref> or by diffusion-like couplings <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b1">2]</ref>. Actually, we shall see that both, together or separately, can create flow-invariant subspaces corresponding to concurrently synchronized states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Symmetries and input-equivalence</head><p>In section 2.3, we argued that, in the case of coupled identical elements, the global synchronization subspace M represents a flow-invariant linear subspace of the global state space. However, several previous works have pointed out that larger (less restrictive) flow-invariant subspaces may exist if the network exhibits symmetries <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b35">36]</ref>, even when the systems are not identical <ref type="bibr" target="#b10">[11]</ref>.</p><p>The main idea behind these works can be summarized as follows. Assume that the network is divided into k aspiring synchronized groups S 1 , . . . , S k 8 . The flow-invariant subspace corresponding to this regime (in the sequel, we shall call such a subspace a concurrent synchronization subspace), namely</p><formula xml:id="formula_34">{(x 1 ; . . . ; x n ) : ∀1 ≤ m ≤ k, ∀i, j ∈ S m : x i = x j }</formula><p>is flow-invariant if, for each S m , the following conditions are true :</p><p>(i) if i, j ∈ S m , then they have a same individual (uncoupled) dynamics (ii) if i, j ∈ S m , and if they receive their input from elements i ′ and j ′ respectively, then i ′ and j ′ must be in a same group S m ′ , and the coupling functions (the synapses) i ′ → i and j ′ → j must be identical. If i and j have more than one input, they must have the same number of inputs, and the above conditions must be true for each input. In this case, we say that i and j are input-symmetric, or more precisely, input-equivalent (since formally "symmetry" implies the action of a group).</p><p>One can see here that symmetry, or more generally input-equivalence, plays a key role in concurrent synchronization. For a more detailed discussion, the reader is referred to <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. 7 Internal symmetries can easily be analyzed within our framework as leading to flow-invariant subspaces, and we shall use this property in section 5.3 for building central pattern generators. However, they will not be discussed in detail in this article. The interested reader can consult <ref type="bibr" target="#b5">[6]</ref>.</p><p>8 Some groups may contain a single element, see section 4.2.3.</p><p>Remark : One can thus turn on/off a specific symmetry by turning on/off a single connection. This has similarities to the fact that a single inhibitory connection can turn on/off an entire network of synchronized identical oscillators <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Diffusion-like couplings</head><p>The condition of input-equivalence can be relaxed when some connections within a group are null when the connected elements are in the same state. Such connections are pervasive in the literature : diffusive connections (in a neuronal context, they correspond to electrical synapses mediated by gap junctions <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b8">9]</ref>, in an automatic control context, they correspond to poursuit or velocity matching strategies <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b25">26]</ref>, . . . ), connections in the Kuramoto model <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b44">45]</ref> (i.e. in the form ẋi = f (x i , t)</p><formula xml:id="formula_35">+ j k ij sin(x j -x i )), etc.</formula><p>Indeed, consider for instance diffusive connections and assume that</p><formula xml:id="formula_36">• i, i ′ , j, j ′ ∈ S m • i ′ → i has the form K 1 (x i ′ -x i ) • j ′ → j has the form K 2 (x j ′ -x j ) with possibly K 1 = K 2</formula><p>Here, i and j are not input-equivalent in the sense we defined above, but the subspace</p><formula xml:id="formula_37">{x i = x j = x i ′ = x j ′ } is still flow-invariant.</formula><p>Indeed, once the system is on this synchronization subspace, we have x i = x i ′ , x j = x j ′ , so that the diffusive couplings i ′ → i and j ′ → j vanish. One can also view the network as a directed graph G, where the elements are represented by nodes, and connections i → j by directed arcs i → j. Then, the above remark can be reformulated as 1 : for all m, color the nodes of S m with a color m, 2 : for all m, erase the arcs representing diffusion-like connections and joining two nodes in S m , 3 : check whether the initial coloring is balanced (in the sense of <ref type="bibr" target="#b10">[11]</ref>) with respect to the so-obtained graph.</p><p>It should be clear by now that our framework is particularly suited to analyze concurrent synchronization. Indeed, a general methodology to show global exponential convergence to a concurrent synchronization regime consists in the following two steps</p><p>• First, find an flow-invariant linear subspace by taking advantage of potential symmetries in the network and/or diffusion-like connections.</p><p>• Second, compute the projected Jacobian matrix on the orthogonal subspace and show that it is uniformly negative definite (by explicitly computing its eigenvalues or by using results regarding the form of the network, e.g. remark (i) in section 2.3 or section 3.1). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Illustrative examples</head><formula xml:id="formula_38">M 1 = {x 1 = x 2 , x 3 = x 4 }, M 2 = {x 1 = x 3 , x 2 = x 4 }, and M 3 = {x 1 = x 4 , x 2 = x 3 }.</formula><p>Any of these subspaces is a strict superset of the global sync subspace, and therefore one should expect that the convergence to any of the concurrent sync state is "easier" than the convergence to the global sync state <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b35">36]</ref>. This can be quantified from <ref type="bibr" target="#b9">(10)</ref>, by noticing that</p><formula xml:id="formula_39">M A ⊃ M B ⇒ M ⊥ A ⊂ M ⊥ B ⇒ λ min (V A LV ⊤ A ) ≥ λ min (V B LV ⊤ B )<label>(11)</label></formula><p>While in the case of identical systems and relatively uniform topologies, this "percolation" effect may often be too fast to observe, <ref type="bibr" target="#b10">(11)</ref> applies to the general concurrent synchronization case and quantifies the associated and possibly very distinct time-scales.</p><p>(ii) The second network has only one non-trivial flow-invariant subspace {x 1 = x 2 , x 3 = x 4 }.</p><p>(iii) If the dashed blue arrows represent diffusive connections then the third network will have one non-trivial flow-invariant subspace {x 2 = x 3 = x 4 , x 5 = x 6 = x 7 }, even if these extra diffusive connections obviously break the symmetry.</p><p>Let's study in more detail this third network, in which the connections between the round element and the square ones are modelled by trigonometric functions (we shall see in section 4.2.3 that their exact form has no actual influence on the convergence rate).</p><formula xml:id="formula_40">                   v1 = f (v 1 ) + a 1 cos(v 2 ) + a 2 sin(v 3 ) v2 = g(v 2 ) + a 4 sin(v 1 ) + c 1 v 6 v3 = g(v 3 ) + a 4 sin(v 1 ) + b 1 (v 2 -v 3 ) + b 2 (v 4 -v 3 ) + c 1 v 5 v4 = g(v 4 ) + a 4 sin(v 1 ) + b 3 (v 3 -v 4 ) + c 1 v 7 v5 = h(v 5 ) + c 2 v 2 + (d 2 v 7 -d 1 v 5 ) v6 = h(v 6 ) + c 2 v 3 + (d 2 v 5 -d 1 v 6 ) v7 = h(v 7 ) + c 2 v 4 + (d 2 v 6 -d 1 v 7 )</formula><p>The Jacobian matrix of the couplings is</p><formula xml:id="formula_41">L =           0 a 1 v2 sin(v 2 ) -a 2 v3 cos(v 3 ) 0 0 0 0 -a 4 v1 cos(v 1 ) 0 0 0 0 -c 1 0 -a 4 v1 cos(v 1 ) -b 1 b 1 + b 2 -b 2 -c 1 0 0 -a 4 v1 cos(v 1 ) 0 -b 3 b 3 0 0 -c 1 0 -c 2 0 0 d 1 0 -d 2 0 0 -c 2 0 -d 2 d 1 0 0 0 0 -c 2 0 -d 2 d 1          </formula><p>As we remarked previously, the concurrent synchronization regime {v</p><formula xml:id="formula_42">2 = v 3 = v 4 , v 5 = v 6 = v 7 } is possible.</formula><p>Bases of the linear subspaces M and M ⊥ corresponding to this regime are</p><formula xml:id="formula_43">          1 0 0 0 0 0 0           ,           0 1 1 1 0 0 0           ,           0 0 0 0 1 1 1          </formula><p>for M, and</p><formula xml:id="formula_44">           0 √ 6 3 - √ 6 6 - √ 6 6 0 0 0            ,           0 0 - √ 2 2 √ 2 2 0 0 0           ,            0 0 0 0 √ 6 3 - √ 6 6 - √ 6 6            ,           0 0 0 0 0 - √ 2 2 √ 2 2           for M ⊥ .</formula><p>Group together the vectors of the basis of M ⊥ into a matrix V and compute</p><formula xml:id="formula_45">VL s V ⊤ =      b 1 2 - √ 3(2b 1 +b 2 -b 3 ) 6 c 1 -2c 2 4 -c 1 √ 3 4 - √ 3(2b 1 +b 2 -b 3 ) 6 b 1 +2(b 2 +b 3 ) 2 -c 1 √ 3 4 -c 1 +2c 2 4 c 1 -2c 2 4 -c 1 √ 3 4 2d 1 +d 2 2 0 -c 1 √ 3 4 -c 1 +2c 2 4 0 2d 1 +d 2 2      As a numerical example, let b 1 = 3α, b 2 = 4α, b 3 = 5α, c 1 = α, c 2 = 2α, d 1 = 3α, d 2 = 4α</formula><p>and evaluate the eigenvalues of VL s V ⊤ . We obtain approximately 1.0077α for the smallest eigenvalue. Using again FitzHugh-Nagumo oscillators and based on their contraction analysis in appendix A, concurrent synchronization should occur for α &gt; 10.25. A simulation is shown in figure <ref type="figure" target="#fig_6">6</ref>. One can see clearly that, after a transient period, oscillators 2, 3, 4 are in perfect sync, as well as oscillators 5, 6, 7, but that the two groups are not in sync with each other.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Robustness of synchronization</head><p>So far, we have been considering exact synchronization of identical elements. However this assumption may seem unrealistic, since real systems are never absolutely identical. We use here the robustness result for contracting systems (see theorem 2) to guarantee approximate synchronization even when the elements are not identical.</p><p>Consider, as in section 2.3, a network of n dynamical elements ẋi = f i (x i , t)</p><formula xml:id="formula_46">+ j =i K ij (x j -x i ) i = 1, . . . , n<label>(12)</label></formula><p>with now possibly f i = f j for i = j. This can be rewritten as</p><formula xml:id="formula_47">   ẋ1 . . . ẋn    =    c(x 1 , t) . . . c(x n , t)    -L    x 1 . . . x n    +    f 1 (x 1 , t) -c(x 1 , t) . . . f n (x n , t) -c(x n , t)    (<label>13</label></formula><formula xml:id="formula_48">)</formula><p>where c is some function to be defined later. Keeping the notations introduced in section 2.3, one has</p><formula xml:id="formula_49">⌢ x = ⌢ c( ⌢ x, t) -L ⌢ x + d( ⌢ x, t)</formula><p>where d( ⌢ x, t) stands for the last term of equation <ref type="bibr" target="#b12">(13)</ref>. Consider now the projected auxiliary system on</p><formula xml:id="formula_50">M ⊥ ẏ = V ⌢ c(V ⊤ y + UU ⊤ ⌢ x, t) -VLV ⊤ y + Vd(V ⊤ y + UU ⊤ ⌢ x, t)<label>(14)</label></formula><p>Assume that the connections represented by L are strong enough (in the sense of equation ( <ref type="formula" target="#formula_19">10</ref>)), so that the undisturbed version of ( <ref type="formula" target="#formula_50">14</ref>) is contracting with rate λ &gt; 0.</p><p>Let D = sup ⌢ x,t Vd( ⌢ x, t) , where D can be viewed as a measure of the dissimilarity of the elements. Since y = 0 is a particular solution of the undisturbed system, theorem 2 implies that the distance R(t) between any trajectory of ( <ref type="formula" target="#formula_50">14</ref>) and 0 verifies, after a transient period, R(t) ≤ D/λ. In the x-space, it means that any trajectory will eventually be contained in a boundary layer of thickness D/λ around the synchronization subspace M.</p><p>The choice of c can now be specified so as to minimize D/λ. Neglecting for simplicity the variation of λ, a possible choice for c(x, t) is then the center of the ball of smallest radius containing f 1 (x, t), . . . , f n (x, t), with D being the radius of that ball.</p><p>Consider for instance, the following system (similar to the model used for coincidence detection in <ref type="bibr" target="#b47">[48]</ref> and section 5.1)</p><formula xml:id="formula_51">ẋi = f (x i ) + I i + k(x 0 -x i )</formula><p>where</p><formula xml:id="formula_52">I min ≤ I i ≤ I max , ∀i In this case, choosing c(x) = f (x) + Imax+I min 2</formula><p>, one can achieve the bound D/λ, where λ is the contraction rate of f and D = Imax-I min 2 . Remark : Assume that two spiking neurons are approximately synchronized, as just discussed. Then, since spiking induces large abrupt variations, the neurons must spike approximately at the same time. More specifically, if the bound on their trajectory discrepancy guaranteed by the above robustness result is significantly smaller than spike size, then this bound will automatically imply that the two neurons spike approximately at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Combinations of concurrently synchronized groups</head><p>This section shows that, under mild conditions, global convergence to a concurrently synchronized regime is preserved under basic system combinations, and thus that stable concurrently synchronized aggregates of arbitrary size can be systematically constructed. The results, derived for two groups, extend by recursion to arbitrary numbers of groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The input-equivalence preservation assumption</head><p>Consider two independent groups of dynamical elements, say S 1 and S 2 . For each group i (i = 1, 2), assume that a flow-invariant subspace M i corresponding to a concurrently synchronized regime exists. Assume furthermore that contraction to this subspace can be shown, i.e. V i J i V ⊤ i &lt; 0 for some projection matrix V i on M ⊥ i . Connect now the elements of S 1 to the elements of S 2 , while preserving inputequivalence for each aspiring synchronized subgroup of S 1 and S 2 . Thus, the combined concurrent synchronization subspace M 1 × M 2 remains a flow-invariant subspace of the new global space. A projection matrix on (M 1 × M 2 ) ⊥ can be V = W 1 0 0 W 2 where each V i has been rescaled into W i to preserve orthonormality. Specific mechanisms facilitating input-equivalence preservation will be discussed in section 4.2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Typology of combinations</head><p>Let us now study several combination operations of concurrently synchronized groups and discuss how they can preserve convergence to a combined concurrent sync state.</p><p>In 4.2.1 and 4.2.2, the input-equivalence preservation condition of section 4.1 is implicitly assumed, and the results reflect similar combination properties of contracting systems <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref>. More generally, as long as input-equivalence is preserved, any combination property for contracting systems can be easily "translated" into a combination property for synchronizing systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Negative feedback combination</head><p>The Jacobian matrices of the couplings are of the form J 12 = -kJ ⊤ 21 , with a positive constant. Thus, the Jacobian matrix of the global system can be written as</p><formula xml:id="formula_53">J = J 1 -kJ ⊤ 21 J 21 J 2</formula><p>As in equation ( <ref type="formula" target="#formula_9">6</ref>) of section 2.2, consider a transform Θ over (</p><formula xml:id="formula_54">M 1 × M 2 ) ⊥ Θ = I 0 0 √ kI</formula><p>The corresponding generalized projected Jacobian matrix on (</p><formula xml:id="formula_55">M 1 × M 2 ) ⊥ is Θ(VJV ⊤ )Θ -1 = W 1 J 1 W 1 ⊤ 1 √ k W 1 (-kJ ⊤ 21 )W 2 ⊤ √ kW 2 J 21 W 1 ⊤ W 2 J 2 W 2 ⊤</formula><p>&lt; 0 uniformly so that global exponential convergence to the combined concurrent synchronization state can be then concluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Hierarchical combination</head><p>Assume that the elements in S 1 provide feedforward to elements in S 2 but do not receive any feedback from them. Thus, the Jacobian matrix of the global system is</p><formula xml:id="formula_56">J = J 1 0 J 21 J 2 . Assume now that W 2 J 21 W 1</formula><p>⊤ is uniformly bounded and consider the coordinate transform Θ ǫ = I 0 0 ǫI . Compute the generalized projected Jacobian</p><formula xml:id="formula_57">Θ ǫ (VJV ⊤ )Θ -1 ǫ = W 1 J 1 W 1 ⊤ 0 ǫW 2 J 21 W 1 ⊤ W 2 J 2 W 2 ⊤ Since W 2 J 21 W 1 ⊤ is bounded, and W 1 (J 1 )W 1 ⊤ and W 2 (J 2 )W 2 ⊤ are both negative definite, Θ ǫ (VJV ⊤ )Θ -1</formula><p>ǫ will be negative definite for small enough ǫ. Note that classical graph algorithms <ref type="bibr" target="#b21">[22]</ref> allow large system aggregates to be systematically decomposed into hierarchies (directed acyclic graphs, feedforward networks) of simpler subsystems (strongly connected components) <ref type="bibr" target="#b45">[46]</ref>. Input-equivalence then needs only be verified top-down.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Case S 1 has a single element</head><p>Denote this element by e 1 (figure <ref type="figure">1</ref> shows such a configuration where e 1 is the round red central element, and where S 2 is the set of the remaining elements). Connections from (resp. to) e 1 will be called 1→2 (resp. 2→1) connections. Then some simplifications can be made :</p><p>• Input-equivalence is preserved whenever, for each aspiring synchronized subgroup of S 2 , the 1→2 connections are identical for each element of this subgroup (in figure <ref type="figure">1</ref>, the connections from e 1 to the yellow diamond elements are the same).</p><p>In particular, one can add/suppress/modify any 2→1 connection without altering input-equivalence.</p><p>• Since dim(M ⊥ 1 ) = 0 (a single element is always synchronized with itself), one has (M 1 × M 2 ) ⊥ = M ⊥ 2 . Thus, concurrent synchronization (and the rate of convergence) of the combined system only depends on the parameters and the states of the elements within S 2 . In particular, it neither depends on the actual state of e 1 , nor on the connections from/to e 1 (in figure <ref type="figure">1</ref>, the black arrows towards the red central element are arbitrary).</p><p>In practice, the condition of identical 1→2 connections is quite pervasive. In a neuronal context, one neuron with high fan-out may have 10 4 identical outgoing connections.</p><p>It is therefore quite easy to preserve an existing concurrent synchonization behavior while adding groups consisting of a single element. Thus, stable concurrent synchronization can be easily built one element at a time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">The diffusive case</head><p>We stick with the case where S 1 consists of a single element, but make now the additionnal requirement that the 1→2 connections and the internal connections within S 2 are diffusive (so far in this section 4, we have implicitly assumed that the connections from S i to S j only involve the states of elements in S i ). The Jacobian matrix of the combined system is now of the form</p><formula xml:id="formula_58">J =       ∂g(x 1 ,t) ∂x 1 ∂f 1 (x 2 ,t) ∂x 2 . . . ∂fq(xn,t) ∂xn       +      * * * * k 1 -k 1 . . . . . . k q -k q      - 0 0 0 L int</formula><p>where the first matrix describes the internal dynamics of each element, the second, the diffusive connections between e 1 and S 2 (where S 2 has q aspiring synchronized subgroups), and the third, the internal diffusive connections within S 2 . Hence, the projected Jacobian matrix on (</p><formula xml:id="formula_59">M 1 × M 2 ) ⊥ = M ⊥ 2 is V 2   ∂f 1 (x 2 ,t) ∂x 2 . . . ∂fq(xn,t) ∂xn    V ⊤ 2 -V 2    k 1 . . . k q    V ⊤ 2 -V 2 L int V ⊤ 2</formula><p>An interpretation of this remark is that there are basically three ways to achieve concurrent synchronization within S 2 , regardless of the behavior of element e 1 and of its connections :</p><p>(i) one can increase the strengths k 1 , . . . , k q of the 1→2 connections (which corresponds to adding inhibitory damping to S 2 ), so that each element of S 2 becomes contracting. In this case, all these elements will synchronize because of their contracting property even without any direct coupling among them (L int = 0) (this possibility of synchronization without direct coupling is exploited in the coincidence detection algorithm of <ref type="bibr" target="#b49">[50]</ref>, and again in section 5.1 of this paper),</p><p>(ii) or one can increase the strength L int of the internal connections among the elements of S 2 ,</p><p>(iii) or one can combine the two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Parallel combination</head><p>The elementary fact that, if VJ i V ⊤ &lt; 0 for a set of subsystem Jacobian matrices J i , then V ( i α i (t)J i ) V ⊤ &lt; 0 for positive α i (t), can be used in many ways. Note that it does not represent a combination of different groups as in the above paragraphs, but rather a superposition of different dynamics within one group. One such interpretation, as in <ref type="bibr" target="#b42">[43]</ref> for contracting systems, is to assume that for a given system ẋ = f(x, t), several types of additive couplings L i (x, t) lead stably to the same invariant set, but to different synchronized behaviors. Then any convex combination (α i (t) ≥ 0, i α i (t) = 1) of the couplings will lead stably to the same invariant set. Indeed,</p><formula xml:id="formula_60">f(x, t) - i α i (t)L i (x, t) = i α i (t) [f(x, t) -L i (x, t)] &lt; 0</formula><p>The L i (x, t) can be viewed as synchronization primitives to shape the behavior of the combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Examples</head><p>In conclusion, let us briefly discuss some general directions of application of the above results to a few classical problems in systems neuroscience and robotics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Coincidence detection for multiple groups</head><p>Coincidence detection is a classic mechanism proposed for segmentation and classification. In an image for instance, elements moving at a common velocity are typically interpreted as being part of a single object, and this even when the image is only composed of random <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>As mentioned in section 4.2, the possibility of decentralized synchronization via central diffusive couplings can be used in building a coincidence detector. In <ref type="bibr" target="#b49">[50]</ref>, inspired in part by <ref type="bibr" target="#b0">[1]</ref>, the authors consider a leader-followers network of FitzHugh-Nagumo<ref type="foot" target="#foot_5">9</ref> oscillators, where each follower oscillator i (an element of S 2 , see section 4.2.4) receives an external input I i as well as a diffusive coupling from the leader oscillator (the element e 1 of S 1 ). Oscillators i and j receiving the same input (I i = I j ) synchronize, so that choosing the system output as 1≤i≤n [ vi ] + captures the moment when a large number of oscillators receive the same input.</p><p>However, the previous development also implies that this very network can detect the moments when several groups of identical inputs exist. Furthermore, it is possible to identify the number of such groups and their relative size. Indeed, assume that the inputs are divided into k groups, such that for each group S m , one has ∀i, j ∈ S m , I i = I j . Since the oscillators in S m only receive as input (a) the output of the leader, which is the same for everybody and (b) the external input I i , which is the same for every oscillator in group S m , they are input-symmetric and should synchronize with each other (cf. section 3.2 and section 4.2.4).</p><p>Some simulation results are shown in figure <ref type="figure" target="#fig_7">7</ref>. Note that contrast between groups could be further enhanced by using nonlinear "synapses", e.g. introducing inputdependent delays, which would preserve the symmetries. Similarly, any feedback mechanism to the leader oscillator would also preserve the input-symmetries.</p><p>Finally, adding all-to-all identical connections between the follower oscillators would preserve the input-symmetries and further increase the convergence rate, but at the price of vastly increased complexity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fast symmetry detection</head><p>Symmetry, in particular bilateral symmetry, has also been shown to play a key role in human perception <ref type="bibr" target="#b2">[3]</ref>. Consider a group of oscillators having the same individual dynamics and connected together in a symmetric manner. If we present to the network an input having the same symmetry, some of the oscillators will synchronize as predicted by the theoretical results of section 3.2.</p><p>One application of this idea is to build a fast bilateral symmetry detector (figures 8, 9, 10), extending the oscillator-based coincidence detectors of the previous section. Although based on a radically different mechanism, this symmetry detector is also somewhat reminiscent of the device in <ref type="bibr" target="#b2">[3]</ref>.</p><p>Some variations are possible : (i) Other types of invariance. It is easy to modify the network in order to deal with multi-order (as opposed to bilateral) symmetry, or other types of invariance (translation, rotation, . . . ). In each case, the network should have the same invariance pattern as what it is supposed to detect.</p><p>Image to be processed Every oscillator has the same dynamics as its mirror image and the two are coupled through diffusive connection. The inputs are provided to the detector through the bottom (red) layer. Then "information" travels bottom-up : each layer is connected to the layer right above it. Top-down feedback is also possible. Assume now that a mirror symmetric image is submitted to the network. The network, which is mirror symmetric by construction, now receives a mirror symmetric input. Thus, the concurrent synchronization subspace where each oscillator is exactly in the same state as its mirror image oscillator is flow-invariant. Furthermore, the diffusive connections, if they are strong enough (see 2.</p><p>2), guarantee contraction on the orthogonal space. By using the theoretical results above, one can deduce the exponential convergence to the concurrent synchronization regime. In particular, the difference between the top two oscillators should converge exponentially to zero.</p><p>(ii) Since the exponential convergence rate is known, the network may be used to track time-varying inputs, as in the coincidence detection algorithm of <ref type="bibr" target="#b49">[50]</ref>.</p><p>(iii) Multidimensional inputs. Coincidence detectors and symmetry detectors may also handle multidimensional inputs. Two approaches are possible. One can either "hash" each multidimensional input into a one-dimensional input, and give the set of so-obtained one-dimensional inputs to the network. Or one can process each dimension independently in separate networks and then combine the results in a second step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Central pattern generators</head><p>In an animal/robotics locomotion context, central pattern generators are often modelled as coupled nonlinear oscillators delivering phase-locked signals. We consider here a system of three coupled 2-dimensional Andronov-Hopf oscillators <ref type="bibr" target="#b17">[18]</ref>, very similar to the ones used in the simulation of salamander locomotion <ref type="bibr" target="#b14">[15]</ref> :</p><formula xml:id="formula_61">     ẋ1 = f(x 1 ) + k(R 2π 3 x 2 -x 1 ) ẋ2 = f(x 2 ) + k(R 2π 3 x 3 -x 2 ) ẋ3 = f(x 3 ) + k(R 2π 3 x 1 -x 3 )</formula><p>Figure <ref type="figure">9</ref>: Simulation on an artificial image.</p><p>We create a 56 × 60 pixels symmetric image from a real picture of one of the authors. We give it as input to a network similar to the one in figure <ref type="figure" target="#fig_8">8</ref>. The first (bottom) layer of the network is composed of 7 × 6 = 42 FitzHugh-Nagumo oscillators (21 pairs) each receiving the sum of the intensities of 8 × 8 = 64 pixels, thus covering at every instant an active window of 56 × 48 pixels. The second layer consists of 4 oscillators, each receiving inputs from 9 or 12 oscillators of the first layer. The third layer is composed of 2 oscillators. At t = 0, the active window is placed on the left of the image (red box) and, as t increases, it slides towards the right. At t = T /2, where T is the total time of the simulation, the position of the window is exactly at the center of the image (green box) (see the simulation results in figure <ref type="figure">10</ref>).</p><p>where f is the dynamics of an Andronov-Hopf oscillator and the matrix R 2π 3 describes a 2π</p><p>3 planar rotation :</p><formula xml:id="formula_62">f x y = x -y -x 3 -xy 2 x + y -y 3 -yx 2 R 2π 3 = -1 2 - √ 3 2 √ 3 2 -1<label>2</label></formula><p>We can rewrite the dynamics as ⌢</p><formula xml:id="formula_63">x = ⌢ f( ⌢ x) -kL ⌢ x, where L =    I 2 -R 2π 3 0 0 I 2 -R 2π 3 -R 2π 3 0 I 2    First, observe that the linear subspace M = R 2 2π 3 (x), R 2π 3 (x), x : x ∈ R 2 is flow-invariant 10</formula><p>, and that M is also a subset of Null(L s ). Next, remark that the characteristic polynomial of L s is X 2 (X -3/2) 4 so that the eigenvalues of L s are 0, with multiplicity 2, and 3/2, with multiplicity 4. Now since M is 2-dimensional, it is exactly the nullspace of L s , which implies in turn that M ⊥ is the eigenspace corresponding to the eigenvalue 3/2. Moreover, the eigenvalues of the symmetric part of</p><formula xml:id="formula_64">∂ ⌢ f ∂ ⌢ x (x, y) are 1 -(x 2 + y 2</formula><p>) and 1 -3(x 2 + y 2 ), which are upper-bounded by 1. Thus, for k &gt; 2/3 (see equation ( <ref type="formula" target="#formula_19">10</ref>) in section 2.3), the three systems will globally exponentially converge to a ± 2π 3 -phase-locked state (i. e. a state in which the difference of the phases of two consecutive elements is constant and equals ± 2π</p><p>3 ). A computer simulation is presented in figure <ref type="figure">11</ref>. Relaxing the symmetry or the diffusivity condition : In the previous example, the flow-invariance of the phase-locked state is due to (a) the internal symmetry of the individual dynamics f, (b) the global symmetry of the connections and (c) the "diffusivity" of the connections (of the form k(Rx 2 -x 1 )). Observe now, as in section 3.2, that this flow-invariance can be preserved when one out of the two conditions (b) and (c) is relaxed. Consider for example the two following systems :</p><formula xml:id="formula_65">• Symmetric but not "diffusive" :      ẋ1 = f(x 1 ) + kR 2π 3 x 2 ẋ2 = f(x 2 ) + kR 2π 3 x 3 ẋ3 = f(x 3 ) + kR 2π 3 x 1</formula><p>(the connections are "excitatory-only" in the sense of section 3.1.3).</p><p>• "Diffusive" but not symmetric :</p><formula xml:id="formula_66">   ẋ1 = f(x 1 ) + k 1 (R 1 x 2 -x 1 ) ẋ2 = f(x 2 ) + k 2 (R 2 x 3 -x 2 ) ẋ3 = f(x 3 ) + k 3 (R 3 x 1 -x 3 )</formula><p>where the R i represent any planar rotations such that R 1 R 2 R 3 = I 2 (i.e., any arbitrary phase-locking).</p><p>By keeping in mind that for any planar rotation R and state x, one has f(Rx) = R(f(x)), it is immediate to show the flow-invariance of R 2 in the first case, and of {(R 1 R 2 (x), R 1 (x), x) : x ∈ R 2 } in the second case. Note however that the computations of the projected Jacobian matrices are different, and that in the first case the limit cycle's radius varies with k (cf. section 3.1.3). Finally, note that (i) All the results of this section can be immediately extended to systems with more oscillators.</p><p>(ii) As compared to results based only on phase oscillators, this analysis guarantees global exponential convergence, rather than assuming that synchronization is already essentially achieved. In addition, it exhibits none of the topological difficulties that may arise when coupling large numbers of phase oscillators.</p><p>(iii) If f is less symmetric, only connections that exhibit the same symmetry as f can lead to a non-trivial flow-invariance subspace.</p><p>(iv) It is also possible to extend this study to systems composed of oscillators with larger dimensions (living in R 3 for example), although a locomotion interpretation may be less relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Filtered connections and automatic gait selection</head><p>Replacing ordinary connections in the CPG described in section 5.3 by filters enables frequency-based symmetry selection. This idea may have powerful applications, one of which could be automatic gait selection in locomotion.</p><p>Consider for example the mechanism described in figure <ref type="figure" target="#fig_11">12</ref>. At low frequencies, the 1 ↔ 3 and 2 ↔ 4 connections are filtered out, so that the actual connections are 1 ↔ 2 and 3 ↔ 4 (anti-synchronization) and 3 → 2 and 4 → 1 (quarter-period delay). The only non-trivial flow-invariant subspace is then {x 1 = R π 2 (x 3 ) = -x 2 = R 3π 2 (x 4 )}. On the contrary, the 3 → 2 and 4 → 1 connections are filtered out at high frequencies, so that the flow-invariant subspace becomes {x 1 = x 3 = -x 2 = -x 4 }.</p><p>Similarly to section 5.3, strong enough coupling gains ensure convergence to either of these two subspaces, according to the frequency at which the oscillators are running. The connections from the command box set the same frequency for the four oscillators. The 1 ↔ 2 and 3 ↔ 4 arrows represent permanent anti-synchronization connections (i.e. connection j → i is of the form k(-x jx i )). The 1 ↔ 3 and 2 ↔ 4 arrows represent synchronization connections and they are high-pass filtered. Finally, the 3 → 2 and 4 → 1 arrows stand for quarter-period delay connections (i.e. connection j → i is of the form k(R -π 2 x jx i ), see section 5.3) and they are low-pass filtered.</p><p>Note that standard techniques allow sharp causal filters with frequency-independent delays to be constructed easily <ref type="bibr" target="#b33">[34]</ref>.</p><p>An analogy with horse gaits could be made in this simplified setup, by associating the low-frequency regime with the walk (left fore, right hind, right fore, left hind), and the high-frequency regime with the trot (left fore and right hind simultaneously, then right fore and left hind simultaneously). Transitions between the two regimes would occur automatically according to the speed of the horse (the frequency of its gait).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Temporal binding</head><p>The previous development has suggested a mechanism for stable accumulation and interaction of concurrently synchronized groups, showing that the simple conditions for contraction to a linear subspace, combined with the high fan-out of typical neurons, increased the plausibility of large concurrently synchronized structures being created in the central nervous system in the course of evolution and development. The recently established pervasiveness of electrical synapses <ref type="bibr" target="#b8">[9]</ref> would also be consistent with such architectures.</p><p>More speculatively, different "rhythms" (α, β, γ, δ) are known to coexist in the brain, which, in the light of the previous analysis, may be interpreted and modelled as concurrently synchronized regimes. Since contracting systems driven by periodic inputs will have states of the same period <ref type="bibr" target="#b26">[27]</ref>, different but synchronized computations could be robustly carried out by specialized areas in the brain using synchronized elements as their inputs. Such a temporal "binding" <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9]</ref> mechanism would also complement the general argument in <ref type="bibr" target="#b43">[44]</ref> that multisensory integration may occur through the interaction of contracting computational systems connected through an extensive network of feedback loops. In this context, and along the lines of section 4.2, a translation to concurrent synchronization of recent results on centralized contracting combinations <ref type="bibr" target="#b45">[46]</ref> may be particularly relevant. Making these observations precise is the subject of future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Convergence to a linear flow-invariant subspace</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A balanced network with Laplacian matrix</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: From left to right : a single oscillator, two oscillators coupled through diffusive connections, two oscillators coupled through excitatory-only connections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Three example networks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Simulation result for network 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Simulation results for the coincidence detector. The network is composed of one leader with a constant input I 0 = 25, and 80 followers whose inputs vary with time as shown in the upper figure. The lower figure plots the system output 1≤i≤80 [ vi ] + against time. One can clearly observe the existence of two successive, well separated spikes per period in a time interval around t = 250. Furthermore, one spike is about twice as large as the other one. This agrees with the inputs, since around t = 250, they are divided into two groups : 1/3 of them with value 37, 2/3 with value 30.</figDesc><graphic coords="23,124.97,223.99,360.00,120.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: A fast bilateral symmetry detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Figure 10: Result for the simulation of figure 9. The figure shows |v 1 -v 2 | where v 1 and v 2 are the voltages of the two FN oscillators in the top layer. One can clearly observe that, around t = T /2 (T = 520 in this simulation), there is a short time interval during which the two oscillators are fully synchronized.</figDesc><graphic coords="26,130.02,97.80,349.95,139.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>2π 3 (x), R 2π 3 (</head><label>33</label><figDesc>x), x : x ∈ R 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: A CPG with filtered connections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>e 1 , . . . , e d ) be a basis of the state space of one element and consider the following vectors of the global state space</figDesc><table><row><cell cols="8">case, all coupling forces equal zero, and the individual dynamics are the same for every</cell></row><row><cell>element. Hence</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>⌢</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>⌢ e 1 =</cell><cell>  </cell><cell>e 1 . . .</cell><cell>   , . . . ,</cell><cell>⌢ e d =</cell><cell>  </cell><cell>e d . . .</cell><cell>   ,</cell></row><row><cell></cell><cell></cell><cell>e 1</cell><cell></cell><cell></cell><cell></cell><cell>e d</cell><cell></cell></row><row><cell cols="8">Let M = span{ ⌢ e 1 , . . . , x  *  ∈ M if and only if x  *  ⌢ e d } be the "diagonal" subspace spanned by the ⌢ 1 = . . . = x  *  n , i.e. all elements are in synchrony. In such a ⌢ e i . Note that</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In the literature, this phenomenon is often called poly-, or cluster or partial synchronization. However, the last term can also designate a regime where the elements are not fully synchronized but behave coherently<ref type="bibr" target="#b44">[45]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>For simplicity we shall call V a "projection", although the actual projection matrix is in fact V ⊤ V.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The overscript ⌢ denotes a vector in the global state space, obtained by grouping together the states of the elements.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>"Undirected" is to be understood here in the graph-theoretical sense, i.e. : for all i, j, the connection from i to j is the same as the one from j to i. Therefore, an undirected network can be represented by an undirected graph, where each edge stands for two connections, one in each direction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>In fact, it is easy to see that the symmetric part of the Laplacian matrix of a directed graph is the Laplacian matrix of some undirected graph if and only if the directed graph is balanced.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p>See appendix A.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6"><p>As it is suggested in footnote 7, the flow-invariance of M can be understood here as being "created" by the internal symmetries of the oscillators' dynamics.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Jake Bouvrie, Nicolas Tabareau and Sacha Zyto for stimulating and to an anonymous reviewer for thoughtful suggestions to improve the presentation. The first author would like to thank CROUS, Paris for financial support.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A FitzHugh-Nagumo oscillators Some of our simulations involve coupled FitzHugh-Nagumo neural oscillators <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31]</ref> </p><p>In this paper, we use the following parameters values : α = 6, β = 3, γ = 0.09. The contraction analysis of FitzHugh-Nagumo oscillators can be adapted from <ref type="bibr" target="#b47">[48]</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simple Networks for Spike-Timing-Based Computation, with Application to Olfactor Processing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="843" to="852" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cluster Synchronization in Threedimensional Lattices of Diffusively Coupled Oscillators</title>
		<author>
			<persName><forename type="first">V</forename><surname>Belykh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Belykh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nevidin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. of Bifurcation and Chaos</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="755" to="779" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Vehicles: Experiments in Synthetic Psychology, chap. 9</title>
		<author>
			<persName><forename type="first">V</forename><surname>Braitenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">What is the Function of the Claustrum</title>
		<author>
			<persName><forename type="first">F</forename><surname>Crick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil. Trans. Roy. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page" from="1271" to="1279" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Helmholtz Machine. Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coupled cells with internal symmetry</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dionne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Golubitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nonlinearity</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="559" to="599" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Algebraic Connectivity of Graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fiedler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Czechoslovak Mathematical Journal</title>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Impulses and Physiological States in Theoretical Models of Nerve Membrane</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fitzhugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biophys. Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="445" to="466" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gap Junctions among Dendrites of Cortical GABAergic Neurons Establish a Dense and Widespread Intercolumnar Network</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kosaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Galuske</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3434" to="3443" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Invariant Pattern Recognition using Bayesian Inference on Hierarchical Sequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hawkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Synchrony versus Symmetry in Coupled Cells</title>
		<author>
			<persName><forename type="first">M</forename><surname>Golubitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Equadiff 2003: Proceedings of the International Conference on Differential Equations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Patterns of Symmetry in Coupled Cell Networks with Multiple Arrows</title>
		<author>
			<persName><forename type="first">M</forename><surname>Golubitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Török</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Appl. Dynam. Sys</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="100" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Complementary Brain : a Unifying View of Brain Specialization and Modularity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="233" to="246" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">Matrix Analysis</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Simulation and Robotic Studies of Salamander Locomotion : Applying Neurobiological Principles to the Control of Locomotion in Robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ijspeert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Crespi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Cabelguen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple Model of Spiking Neuron</title>
		<author>
			<persName><forename type="first">E</forename><surname>Izhikevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1569" to="1572" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bursts as a Unit of Neural Information : Selective Communication via Resonance</title>
		<author>
			<persName><forename type="first">E</forename><surname>Izhikevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Walcott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hoppensteadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="161" to="167" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Izhikevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kuramoto</surname></persName>
		</author>
		<title level="m">Weakly Coupled Oscillators. Encyclopedia of Mathematical Physics</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Coordination of Groups of Mobile Autonomous Agents using Nearest Neighbor Rules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jadbabaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Morse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="988" to="1001" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the Stability of the Kuramoto Model of Coupled Nonlinear Oscillators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jadbabaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Motee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barahona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the American Control Conf</title>
		<meeting>the American Control Conf<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07-02">June 30-July 2, 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Kandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jessel</surname></persName>
		</author>
		<title level="m">Principles of Neural Science</title>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note>th ed.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Knuth</surname></persName>
		</author>
		<title level="m">The Art of Computer Programming</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd Ed</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The Quest for Consciousness</title>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Roberts and Company Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A model of in neocortical architecture</title>
		<author>
			<persName><forename type="first">E</forename><surname>Körner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-O</forename><surname>Gewaltig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Körner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rodemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7-8</biblScope>
			<biblScope unit="page" from="989" to="1005" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Temporal Binding via Cortical Coincidence Detection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Llinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Leznik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Urbano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PNAS</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="449" to="454" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Local Control Strategies for Groups of Mobile Autonomous Agents</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Francis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="622" to="629" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On Contraction Analysis for Nonlinear Systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lohmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatica</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="671" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Nonlinear Process Control Using Contraction Theory</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lohmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">A.I.Ch.E. Journal</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="588" to="597" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Likelihood Calculation for a Class of Multiscale Stochastic Models, with Application to Texture Discrimination</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luettgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="194" to="207" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The Cerebral Cortex</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mountcastle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An Active Pulse Transmission Line Simulating Nerve Axon</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nagumo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoshizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Inst. Radio Engineers</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="2061" to="2070" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hemodynamic Signals Correlate Tightly with Synchronized Gamma Oscillations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Niessing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ebisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niessing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Galuske</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="page" from="948" to="951" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Consensus Problems in Networks of Agents With Switching Topology and Time-Delays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olfati-Saber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1520" to="1533" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Oppenheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buck</surname></persName>
		</author>
		<title level="m">Discrete-Time Signal Processing, 2nd Edition</title>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Q.-C</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
		<title level="m">Attractors. MIT-NSL Report 0505</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Pogromsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Santoboni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nijmeijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Partial Synchronization : from Symmetry towards Stability</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="65" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Predictive Coding in the Visual Cortex</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="10" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bayesian Inference and Attention in the Visual Cortex</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroreport</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1843" to="1848" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Normal and Pathological Communication in the Brain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schnitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="285" to="296" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neuronal Coherence as a Mechanism of Effective Corticospinal Interaction</title>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Schoffelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Oostenveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="page" from="111" to="113" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Model for Synchronization of Pancreatic I3-cells by Gap Junction coupling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rinzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biophys. Journal</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="547" to="559" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visual Feature Integration and the Temporal Correlation Hypothesis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="555" to="586" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modular Stability Tools for Distributed Computation and Control</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adaptive Control and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="397" to="416" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Modularity, Evolution, and the Binding Problem : A View from Stability Theory</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lohmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">From Kuramoto to Crawford : Exploring the Onset of Synchronization in Populations of Coupled Oscillators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Tabareau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
		<title level="m">Notes on Contraction Theory. MIT-NSL Report 0503</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="3198" to="3203" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On Partial Contraction Analysis for Coupled Nonlinear Oscillators</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="53" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
		<idno>Variables. PS/0512070</idno>
		<title level="m">Contraction Analysis of Time-Delayed Communications Using Simplified Wave</title>
		<imprint>
			<date type="published" when="2005-12-25">25 Dec 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fast Computation with Neural Oscillators</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fast Synchronization of Perceptual Grouping in Laminar Visual Cortical Circuits</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yazdanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="707" to="718" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Partial Synchronization and Spontaneous Spatial Ordering in Coupled Chaotic Systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">26211</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
