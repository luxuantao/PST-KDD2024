<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Privacy-Aware Recommendation with Private-Attribute Protection using Adversarial Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-11-22">22 Nov 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
							<email>gbeigi@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>Arizona</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ahmadreza</forename><surname>Mosallanezhad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>Arizona</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruocheng</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>Arizona</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hamidreza</forename><surname>Alvari</surname></persName>
							<email>halvari@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>Arizona</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Nou</surname></persName>
							<email>asnou@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>Arizona</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
							<email>huan.liu@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>Arizona</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Privacy-Aware Recommendation with Private-Attribute Protection using Adversarial Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-11-22">22 Nov 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:1911.09872v1[cs.SI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems → Recommender systems</term>
					<term>• Security and privacy → Social network security and privacy</term>
					<term>Privacy protections Privacy-Aware Recommendation</term>
					<term>Private-Attribute Protection</term>
					<term>Adversarial Learning</term>
					<term>Privacy</term>
					<term>Utility</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommendation is one of the critical applications that helps users find information relevant to their interests. However, a malicious attacker can infer users' private information via recommendations. Prior work obfuscates user-item data before sharing it with recommendation system. This approach does not explicitly address the quality of recommendation while performing data obfuscation. Moreover, it cannot protect users against private-attribute inference attacks based on recommendations. This work is the first attempt to build a Recommendation with Attribute Protection (RAP) model which simultaneously recommends relevant items and counters private-attribute inference attacks. The key idea of our approach is to formulate this problem as an adversarial learning problem with two main components: the private attribute inference attacker, and the Bayesian personalized recommender. The attacker seeks to infer users' private-attribute information according to their items list and recommendations. The recommender aims to extract users' interests while employing the attacker to regularize the recommendation process. Experiments show that the proposed model both preserves the quality of recommendation service and protects users against private-attribute inference attacks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommendation systems play an important role in helping users find relevant and reliable information that is of potential interest <ref type="bibr" target="#b28">[29]</ref>. These systems build profiles that represent user's interests <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b27">28]</ref> and recommend relevant items to the users based on the constructed profiles <ref type="bibr" target="#b39">[40]</ref>. Despite the effectiveness of recommendation systems, they can be sources of user privacy breach. Existing work has shown that if malicious attackers have access to the system's output and unrestricted auxiliary information about their targets, they are able to extract their entire user-item interactions history <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref>. One main reason is that recommendation systems' outputs (i.e., product recommendation) are partially derived from other users' choices (i.e., user-item interactions history). Thus, privacy concerns arise.</p><p>One of privacy issues is the re-identification attack where a malicious adversary attempts to infer user's actual ratings by seeking if a target user is in the database <ref type="bibr" target="#b6">[7]</ref>. Prior research on privacy preserving recommendation systems has extensively addressed this type of privacy breach. Common techniques include (1) modifying the output of the recommendation system algorithm so that the absence or presence of a single rating or an entire user data is masked (i.e., differential privacy based techniques) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">45]</ref>; and (2) coarsening the user's interactions history by adding dummy items and ratings such that the adversary cannot deduce the user's actual ratings and preferences (i.e., perturbation based techniques) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41]</ref>.</p><p>Another privacy issue is the disclosure of user private-attribute information through leaked users' interactions history <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b42">43]</ref>. Private attribute information contains those attributes that users do not wish to disclose such as age, gender, occupation and location. This type of privacy breach is known as the private-attribute inference attack in which the adversary's goal is to infer private attributes of target users given their interactions history. Little has been done to protect users against this attack of private-attribute inference <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b42">43]</ref> with focus on anonymizing user-item data before publishing it. Data obfuscation comes at the cost of utility loss where utility is defined as the quality of service users receive. The existing work addresses the utility loss by minimizing the amount of changes made to the data <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">43]</ref>. However, in the context of recommendation, the utility loss due to this approach can lead to degraded recommendation results. Moreover, just sharing perfectly obfuscated user-item data with a recommendation system does not necessarily prevent the adversary from inferring users' private information in future when they receive and accept new recommendations (e.g., when purchasing new products).</p><p>This research aims to devise a mechanism to counter privateattribute inference attacks in the context of recommendation systems. We propose a privacy-aware Recommender with Attribute Protection, namely RAP, which offers relevant products in a way that makes any inference of user's private attributes difficult from his interactions history and recommendations. The proposed model seeks to concurrently prevent the leakage of users' private attribute information while retaining high utility for users.</p><p>Recommendation while countering private-attribute inference attack can be naturally formulated as a problem of adversarial learning <ref type="bibr" target="#b18">[19]</ref>. In our proposed RAP, there are two components: a Bayesian personalized ranking recommender and a private-attribute inference attacker (illustrated in Figure <ref type="figure">.</ref> 1). The private-attribute inference attacker seeks to accurately infer users' private attribute information. The attacker aims to iteratively adapt its model with respect to the existing recommender. The recommender extracts latent representations of users and items for personalized recommendation, and simultaneously utilizes the private-attribute inference attacker to regularize the recommendation process by incorporating necessary constraints to fool the attacker. Therefore, RAP optimizes a composition of two conflicting objectives, modeled as a min-max game between recommender and attacker components. Its objective is to recommend relevant, ranked items to users such that a potential adversary cannot infer their private attribute information.</p><p>In essence, we investigate the following research issues: (1) whether we can develop a personalized privacy-aware recommendation system to guard against private-attribute inference attacks; and (2) how we can ensure that the user's private attributes are effectively obscured after receiving personalized recommendation. Our research on these issues results in a novel framework RAP with the following main contributions:</p><p>• To the best of our knowledge, this is the first effort in proposing a recommendation system with guarding against the inference of private attribute information while maintaining the user utility. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM STATEMENT</head><p>Before formally defining our problem, we first describe the notations used in this paper. Let I = {i 1 , ..., i M } denotes items, and U = {u 1 , ..., u N } denotes users. Also, I h represents the set of items rated by user h, and R h is set of items recommended to h. P = {p 1 , ..., p T } denotes a set of T private attributes (e.g., age, gender). R represents user-item rating matrix. The goal is to recommend products to people that would be interesting for them. However, we want to protect people's privacy against a malicious adversary who attempts to infer their private attribute information according to the user's list of items information. Items list S h for each user h is union of his previously rated and newly recommended items, i.e., S h = {I h ∪ R h }. In particular, the malicious attacker has a framework which takes a target user's interactions and infers the user's private attribute:</p><p>Problem 1. We aim to learn a function f that can recommend interesting and relevant products R h to each user u h such that, 1) the adversary cannot infer the targeted user's private attribute information P from the user's list of items information, S h = {I h ∪ R h } and 2) the set of recommended items R h is interesting for the user. The problem can be formally defined as: R h = f (I h , R, P) Note that, the goal is to protect users against a malicious adversary who has access to the users' items list, but not against the recommender which is trusted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>Explosive growth of the Web has raised numerous challenges for online users including disinformation spread <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> and threats to users' privacy <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>. Addressing user privacy issues has been studied from different aspects such as textual information <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, web browsing histories <ref type="bibr" target="#b5">[6]</ref>, private-attributes disclosure <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24]</ref> and recommendation systems <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b44">45]</ref> (for a comprehensive survey refer to <ref type="bibr" target="#b6">[7]</ref>). Our work is related to a number of research which we discuss below while we elaborate on the differences between our work and them. Privacy and Recommendation Systems. Existing privacy preserving works in recommendation systems focus on protecting users against re-identification attacks in which an adversary tries to infer a targeted user's actual ratings and investigate if the target is in the database. They could be categorized into differential privacy based <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">45]</ref> and perturbation based <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41]</ref> approaches. Some methods utilize differential privacy strategy <ref type="bibr" target="#b13">[14]</ref> to modify the answers of the recommendation algorithm so the the presence of a user's data (either a single user-item rating or entire user's history) is masked by increasing the chance that two arbitrary records have close probabilities to generate the same noisy data. McSherry et al. <ref type="bibr" target="#b32">[33]</ref> utilize differential privacy to construct private covariance matrices to be further used by recommender. Another work <ref type="bibr" target="#b25">[26]</ref> clusters users w.r.t. the social relations and generates differentially private average of users' preferences in each cluster. Hua et al. <ref type="bibr" target="#b22">[23]</ref> propose a private matrix factorization which adds noise to item vectors to make them differentially private. Bassily et al. <ref type="bibr" target="#b4">[5]</ref> modify user-item ratings data to satisfy differential privacy and then share it with recommender. Another work <ref type="bibr" target="#b44">[45]</ref> makes items list differentially private and then sends it to recommender. Perturbation based techniques obfuscate user's interactions history by adding fake items and ratings to it. Rebollo et al. <ref type="bibr" target="#b40">[41]</ref> propose an information theoretic based privacy metric and then find the obfuscation rate for generating forged user profiles so that the privacy risk is minimized. Similarly, <ref type="bibr" target="#b36">[37]</ref> proposes to add or remove items and ratings from user profiles minimize privacy risk. Polat et al. <ref type="bibr" target="#b37">[38]</ref> use a randomized perturbation technique by sharing disguised z-score for items a given user have rated. In another work <ref type="bibr" target="#b31">[32]</ref>, similar users are grouped to each other. Aggregated ratings of the users within the same group is then used to estimate a group preference vector. Similar to <ref type="bibr" target="#b37">[38]</ref>, randomness is then added to the preference vector to be shared with the recommender. Attribute Inference Attacks and Defenses Private-attribute inference attack focuses on inferring users' private attribute information from their publicly available information. These attacks could be categorized into three groups.A group of these attacks leverages a target user's friends' information <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b30">31]</ref> and community membership information <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b43">44]</ref> to infer target's private attributes. Second group of these attacks are those works which leverage users' behavioral information such as movie-rating behavior <ref type="bibr" target="#b42">[43]</ref> and Facebook likes <ref type="bibr" target="#b29">[30]</ref> to infer their private attribute information. The third group of works exploits both friend and behavioral information <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25]</ref>. Gong et al. <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> make a social-behavior-attribute network in which all users' behavioral and friendship information is integrated in a unified framework. Private attributes are then inferred through a vote distribution attack model. Another work <ref type="bibr" target="#b24">[25]</ref> incorporates structural and behavioral information from users who do not have the attribute in the training process, i.e. negative training samples.</p><p>Little work focuses on protecting users against private-attribute inference attacks <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">43]</ref>. In <ref type="bibr" target="#b42">[43]</ref>, a predefined number of dummy items is added to each user's profile which are negatively correlated with his actual attributes before publishing anonymized user-item ratings data. In a recent paper <ref type="bibr" target="#b23">[24]</ref>, after a value is sampled for the given private attribute w.r.t. a certain probability distribution which is different from the user's actual attribute, the minimum noise is found and added to the user-item data via adapting evasion attacks such that the malicious attacker predicts the sampled attribute value as the user's private attributes.</p><p>Our work is different from the existing works. First, existing privacy preserving recommendation systems do not specifically target the private-attribute inference attacks. Second, existing defenses against this attack <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">43]</ref> address the utility loss by minimizing the amount of changes made to the data. However, in scope of recommendation systems, this approach can mean neglecting the quality of received services, i.e., poor recommendation results. Third, sharing anonymized data with recommender does not preclude the malicious attacker to infer private attribute information when users receive new recommendations. All of these limitations arises the need for having a recommendation system guarding against the inference of private attribute while maintaining the user utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RECOMMENDATION WITH ATTRIBUTE PROTECTION (RAP)</head><p>Our proposed recommendation framework, RAP, aims to concurrently recommend interesting items to users and protect them against private attribute leakage. The entire model is illustrated in Figure <ref type="figure">.</ref> 1. This framework consists of two major components, 1) a Bayesian personalized recommender, and 2) a private-attribute inference attacker. The personalized ranking recommender D R aims to extract users' actual preferences and recommend relevant items to them. The private-attribute inference attacker D P seeks to develop a model which can deduce users' private information w.r.t. the existing recommendation system. Recommendation component then utilizes D P to guide the recommendation process by ensuring that the union of previously rated and newly recommended items does not leak user's attributes and further fools the adversary in D P .</p><p>Inspired by adversarial machine learning, we model this objective as a min-max game between two components, i.e. attacker D P seeks to maximize its gain and recommender D R aims to minimize both its recommendation loss and attacker D P 's gain. The final output of RAP for each user, is a list of top-K items which are interesting yet safe for them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Bayesian Personalized Recommendation</head><p>In this section, we propose a new Bayesian personalized recommendation model. The proposed model structure is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. This model first extracts users and items latent embeddings and then utilizes learning to rank approach to recommend items to users. Learning to rank methods have been introduced to optimize recommendation systems toward personalized ranking. Inspired by recent success of Bayesian Personalized Ranking (BPR) <ref type="bibr" target="#b41">[42]</ref> in image and friend recommendation systems <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35]</ref>, we choose BPR aver other approaches. The idea behind BPR is that observed useritem interactions should be ranked higher than unobserved ones. Learning from implicit feedback, BPR goal is to maximize the margin between an observed user-item interaction and its unobserved counterparts. In particular, BPR behavior could be interpreted as a classifier in which given a positive triplet instance of user h and items j and k, (h, j, k), it determines whether the user-item interaction (h, j) should have a higher rank score than (h, k).</p><p>This recomemndation component has three inputs, the user h and items j and k.We denote the user and items indices by a tuple of vectors (u h , i j , i k ) which are one-hot encodings of users and items. Since there are N users and M items, the dimensions of u h , i j , and i k are M, N and N , respectively. Following the input layer, each input layer is fully connected to the corresponding embedding layer to learn the latent representation of the users and items, q h ∈ R d , p j ∈ R d , where d is the number of dimensions. The embedding dimensions for both users and items are the same:</p><formula xml:id="formula_0">q h = W h u h , p j = W j i j , p k = W k i k (1)</formula><p>where W h , W j and W k are embedding matrices for users and items.</p><p>In the next layer, user and item embedding vectors are passed to the hidden layers H h , H j , and H k for further calculations. For example, the hidden layer produces H h for user h as:</p><formula xml:id="formula_1">H h = ReLU (wq h + b H ) (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where ReLU is simply defined as ReLU (x) = max(0, x) and w and b H are the weights and bias for units, respectively. Using H h , H j , and H k , the next layer produces the user's preference ŷhj , ŷhk toward items j and k, respectively. For example: </p><formula xml:id="formula_3">ŷhj = ReLU (w o [H h ; H j ] + b o )<label>(3)</label></formula><formula xml:id="formula_4">L D R = 1 N N h=1 (h, j,k )∈ D h − ln δ (( ŷhj (θ R )− ŷhk (θ R )).д(h, j, k))+λ θ R ∥θ R ∥ 2</formula><p>(4) where, д(h, j, k) is the ground truth value for our model training:</p><formula xml:id="formula_5">д(h, j, k) = 1, if user u h prefers item i j over item i k −1, otherwise<label>(5)</label></formula><p>where set D h = {(h, j, k)|j ∈ I h and k ∈ I/ I h } also denotes the training pairwise instances in which I and I h represent the whole set of items and the set of items rated by user u, respectively. Moreover, y hj is the actual rating that user h gives to item j. θ R is also defined as</p><formula xml:id="formula_6">θ R = {W U , W I , w, b H , w o , b o } such that W U = {W 1 , .., W N } and W I = {W 1 , .</formula><p>., W M } represent the set of embedding matrices for N users and M items, respectively. The proposed model considers the recommendation problem as a binary classification problem to ensure that the pairwise preference relations hold.</p><p>After training the recommendation model, given a user h, for every item j that the user has not rated, i.e., j ∈ {I/ I h }, his preference score ŷhj is predicted by the recommender. In order to calculate the preference score ŷhj , we pass the tuple (h, j, j) to the recommender, and get ŷhj and ŷ′ hj as the model's output. The final preference score of user h toward item j is calculated as ŷhj = 0.5( ŷhj + ŷ′ hj ). All of the unrated items will be then sorted based on their preference scores descendingly and the top-K items are then returned as the recommendation R h to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training an Attacker against Inferring Private Attribute Information</head><p>The goal of our model is to recommend ranked items to users such that any potential adversary cannot infer users' private attribute information such as age, gender and occupation. However, a challenge is that the recommendation system does not know the malicious attacker's model. To address this challenge, we add a private-attribute inference attacker D P component to our model which seeks to learn a classifier that can accurately identify the private information of users from their previous interactions. Then, we leverage this component to regularize the recommendation process by incorporating necessary constraints in order to fool the adversary D P and further avoid the leakage of private attributes after recommendation. This part is discussed in details in Section. 4.3.</p><p>The goal of the private-attribute attacker is now to predict target user h's private attribute information by leveraging the information of his latent representation as well as the the latent representation of his items list. The user h's items list S h = {I h ∪ R h } includes both items I h that user has rated previously and new recommended items R h . Given T private attributes (e.g., age, gender), the set of {θ P t } T t =1 represents all the parameters included in the private-attribute inference attacker component D P . The output of the private attribute attacker component for user h w.r.t. t-th private attribute is the probability that user h has t-th attribute.</p><p>We use p h,t to represent the actual value for user h's t-th private attribute. The structure of private attribute inference attacker is represented in Fig. <ref type="figure" target="#fig_3">3</ref>. The input to this model for each user h is the latent embedding representations of each item p j in his items list p j ∈ S h , j = 1, 2, ..., |S h | and h's latent embedding representation q h . Given the input, the items embeddings are passed to a singlelayer recurrent neural network (RNN) and the output of RNN (z |S h | ) is then concatenated with user's embedding. The last layer produces the predicted t-th sensitive attribute for user h, ph,t :</p><formula xml:id="formula_7">ph,t = so f tmax(w t [z | S h | ; q h ] + b t )<label>(6)</label></formula><p>where [.; .] represents concatenation. Also, w t and b t are the weights and bias for units, respectively and are shared among all users due to the model simplicity. We then minimize the private-attribute inference attacker component loss function L D t P for all private attributes by seeking the optimal parameters {θ t P } T t =1 . The objective function for all users can be formally written as follows:</p><formula xml:id="formula_8">L D P = 1 N N h=1 1 T T t =1 L D t P ( ph,t , p h,t )<label>(7)</label></formula><p>where L D t P denotes the cross entropy loss for t-th private attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Adversarial Learning for Recommendation with Private-Attribute Protection</head><p>Thus far, we have discussed how we 1) learn users and items representations to recommend ranked items to each user based on his personalized preferences; and 2) train an attacker which can accurately infer a target user's private attribute information given a list of his rated items and received recommendations. We stress that the adversary always has the upper hand and his privateattribute inference attack in order to minimize his inference loss w.r.t. the existing recommendation system. The final objective is thus to recommend relevant ranked items to users such that a potential adversary cannot infer their private attribute information. To achieve two goals together, we design an optimization problem to minimize the recommendation loss of our model and maximize the inference loss of a determined attacker who adaptively minimizes his loss. Inspired by the idea of adversarial learning, we model this optimization as a min-max game between two components, Bayesian personalized recommender and private-attribute attacker.</p><p>In our proposed model, the adversary tries to adapt itself and gets the maximum gain, while the recommendation system seeks to recommend ranked items to users. The recommended items not only align well with the users' preferences, but also minimize the adversary's gain. We reformulate the objective function of the recommendation system as minimizing attacker's gain and recommendation loss simultaneously:</p><formula xml:id="formula_9">min θ R L D R private-attribute attacker −α max {θ t P } T t =1</formula><p>L D P privacy-aware recommendation system <ref type="bibr" target="#b7">(8)</ref> The inner part learns the most determined adversary which adaptively minimizes its loss regarding private-attribute inference given the users and items information. The outer part seeks to both minimize the recommendation loss and fool the given adversary. The parameter α controls the contribution of the private-attribute inference attacker in the learning process. Objective function in Create a mini-batch U b of b users with their private-attribute and item-rating information from U 3:</p><p>Train the recommendation with attribute protection via Eq. 10 w.r.t. θ R 4:</p><p>For each user h in U b , calculate the top-K recommended items R h 5:</p><p>Train the private-attribute inference attacker D P (i.e., {θ t P } T t =1 ) via Eq. 7 given the users' information including their list of items information, i.e., S h = {I h ∪ R h } 6: until Convergence Eq. 8 can be written as follows:</p><formula xml:id="formula_10">min θ R max {θ t P } T t =1 1 N N h=1 (h, j,k)∈D h − ln δ (( ŷhj (θ R ) − ŷhk (θ R )).д(h, j, k))<label>(9)</label></formula><formula xml:id="formula_11">− α 1 T T t =1 L D t P ( ph,t , p h,t ) + λΩ(θ )</formula><p>where θ = {θ R , {θ t P } T t =1 } is the set of all parameters to be learned, Ω(θ ) is the L 2 norm regularizer on the parameters, and λ is a scalar to control the contribution of the regularization Ω(θ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Optimization Algorithm</head><p>The optimization process is illustrated in Algorithm 1. First, we create a mini-batch sample U b of b users from the training data and serve their private attribute and item-rating information to the model. Next, we train the Bayesian personalized recommender D R according to the Eq. 10 w.r.t. θ R in Line 3. Then, for each user h in U b we calculate the top-K recommended items R h and accordingly make his list of items, S h . The private-attribute inference attacker component is then trained according to the users and item embeddings information using Eq. 7 in Line 5. After training RAP, for each user h, a list of top-K items R h will be returned as recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section we conduct experiments to evaluate the efficiency of the proposed framework in terms of both privacy and quality of the recommendation. We aim to answer the following questions: • Q1 -Privacy: How does RAP perform in preventing leakage of users' private information? • Q2 -Utility: How does RAP perform in recommending relevant items to users? • Q3 -Utility-Privacy Relation: Does the improvement in privacy result in sacrificing the utility of recommendation system?</p><p>To answer the first question (Q1), we examine our model against different private information with different distributions, such as age, gender, and occupation. Then, we evaluate the effectiveness of RAP in preventing leakage of users' private information given union of users' previously rated and newly recommended items. Addressing leakage of private attribute information may result in recommendation performance deterioration. Therefore, to answer the second question (Q2), we examine the performance of RAP in terms of the quality of the recommendation. Finally, to answer the third question (Q3), we investigate the loss in recommendation performance when enhancing privacy of users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>We use publicly available data MovieLens <ref type="bibr" target="#b19">[20]</ref>. This dataset includes 100, 000 ratings by 943 users on 1,682 movies. Each user has rated at least 20 movies and the rating scores are between 1 and 5. In the collected dataset, each user is associated with three private attributes, gender (male/female), age, and occupation. For this paper, we follow the setting of <ref type="bibr" target="#b21">[22]</ref> and categorize age attribute into three groups, over-45, under-35, and between 35 and 45. In total, 21 possible occupations have been considered for this data. The average number of rated items for each user is 129.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setting</head><p>Here, we first explain how we design experiments to evaluate utility and privacy. Then, we discuss evaluation metrics and baselines. Implementation Details: The parameters for recommendation and attacker components are determined through grid search. For the Bayesian personalized ranking recommendation component, we set the dimension of first layer as d = 70. Accordingly, size of user and item embedding vectors is d = 70. The dimension of hidden layer is also set as 20. For the private-attribute inference attacker component, we use single layer RNN with the dimension of input layer set as d = 70. User and item embeddings are then passed from recommendation component to the attacker component. The dimension of hidden layer is set as 100. The parameters α and λ are also determined through cross-validation, α = 1 and λ = 0.01.</p><p>We initialize the weight matrices in both components with random values uniformly distributed in [0, 1]. The error gradient is back propagated from output to input and parameters in each layer are updated. The optimization algorithm used for gradient update is Adam's algorithm <ref type="bibr" target="#b26">[27]</ref>. The loss generally converges after 20 epochs. The batch size we use in experiments is b = 32. Recommendation Evaluation: We evaluate the performance of recommendation by examining the quality of recommended items for all users. We follow the setting of <ref type="bibr" target="#b23">[24]</ref> to set-up the experimental settings. To do so, we split the data for train and test as follows. For each user h in the data, we randomly select l rated items for test set and the remaining n h − l items for training set, where n h is the number of rated items for user h. We set the item rating for those in the test set as zero. We vary the value of l as {35, 40, 45}. Then, the top-K items are then returned to each user as the recommendation. Note that we assume RAP has access to the users' private attribute information during the training process. Private-Attribute Evaluation: We evaluate privacy of users in terms of their robustness against the malicious attribute inference attacks in which the adversary's goal is to infer users' private attributes. In particular, the malicious attacker learns a multi-class classifier which takes a target user h list of items information, i.e. S h = {I h ∪ R h }, where I h is set of h's rated items and R h is set of items recommended to h. The adversary then infers the user's private attributes, i.e., gender, age, and occupation.</p><p>We use a Neural Network (NN) model as the adversary's classifier. Note that RAP is not aware of the adversary's model. In this attack, the adversary deploys a feed-forward network with a single hidden layer to perform the attack. The input to this model is one-hot encoding of each user, S h = {I h ∪ R h }. Since there are M items in the dataset, the dimension of input vector is M. The input layer is then fully connected to the hidden layer with dimension of hidden state set as 100 and a so f tmax layer used as the output layer. The dimension of the hidden layer is determined through grid search. We note that Gong et al. <ref type="bibr" target="#b35">[36]</ref> also proposed an attribute inference attack which leverages both social friends and rating behavior. However, their attack is not applicable to our problem as we focus on leveraging only user-item rating information.</p><p>We follow the setting of <ref type="bibr" target="#b23">[24]</ref> to set-up the experiments. We split the data to train and test sets by sampling 80% of the users in the dataset uniformly at random as the training set and use the remaining users as testing set. We assume that the users in the training set has publicly disclosed their private information while the users in the testing set keep those attribute information private. Then, for each user in the test set, we randomly select l rated items and remove them from the user's rating history by setting the their rating as zero. We keep the user-item ratings for users in the training set intact (i.e., original user-item ratings). Trained RAP model is deployed on the users in the test set and top-l recommended items R h are added to the users' previously rated items I h , in order to make S h = {I h ∪ R h }. We vary value of l as {35, 40, 45}.</p><p>The adversary's classifier is trained on the training set and evaluated on the users in the test set. Note that we assume that the malicious attacker knows the original intact user-item interactions for those users in the training set and seeks to predict private attribute information of the users in the test set, given their S h . We evaluate a malicious attack for each private attribute. Evaluation Metrics: We use the following metrics for evaluating RAP performance w.r.t. malicious private-attribute inference (i.e., privacy) and product recommendation (i.e., utility):</p><p>• Private-Attribute Evaluation: Since distribution of data for different private attribute values is imbalance, we report micro-AUC <ref type="bibr" target="#b14">[15]</ref> of the adversary's classifier. Micro-AUC <ref type="bibr" target="#b14">[15]</ref> gives a more accurate assessment. Lower AUC demonstrates higher privacy in terms of obscuring private attributes. • Recommendation Evaluation: We use standard metrics that are widely used in other related works <ref type="bibr" target="#b45">[46]</ref>, i.e., P@K and R@K. P@K: P@K represents the ratio of test cases which has been successfully recommended in a top-K position in a ranking list to value of K. For each user, we measure P@K as:</p><formula xml:id="formula_12">P@K = |{test items} ∩ {top-K returned items}| K<label>(10)</label></formula><p>R@K: R@K defines the ratio of top-K recommended items which are in the test set to the number of items to be recommended in the test. For each user in the data, we measure R@K as follows:</p><formula xml:id="formula_13">R@K = |{test items} ∩ {top-K returned items}| |{test items}|<label>(11)</label></formula><p>We then report the average of R@K and P@K for all users in the dataset and set the number of returned items as  <ref type="table">1</ref>: RAP Performance. Higher P@K and R@K values show higher utility, while lower AUC indicates higher privacy.</p><formula xml:id="formula_14">K = 35. Model # test items (l ) 35 40 45 Gen Age Occ P @K R@K Gen Age Occ P @K R@K Gen Age Occ P @K R@K Original 0.</formula><p>Baseline Methods: We compare RAP with the following baselines:</p><p>• Original: This baseline is a variant of RAP which recommends items for each user without incorporating the private-attribute inference attacker component, i.e., α = 0. • LDP-SH <ref type="bibr" target="#b4">[5]</ref>: This method adds noise to user-item ratings based on ϵ-differential privacy. It requires categorical data which for our case, each user-item rating can be viewed as categorical data taking values {0, 0.2, 0.4, 0.6, 0.8, 1}.</p><p>• BlurMe <ref type="bibr" target="#b42">[43]</ref>: This method perturbs user-item ratings before sending to recommendation system. It adds new items to each user's profile that are negatively correlated with the user's actual private attributes and then adds the average rating score to those items. BlurMe needs to be deployed for each attribute separately.</p><p>To have a fair comparison between RAP and two baselines, we anonymze the user-item rating data w.r.t. baselines. The noisy manipulated data is used to train the recommendation model. We use matrix factorization model as the recommendation framework for both baselines. The discussed procedure is then used for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Privacy Analysis (Q1)</head><p>The results against the malicious private-attribute inference attack (Section 5.2) are demonstrated in Table <ref type="table">.</ref> 1. We observe that increasing the number of test items (l) results in decrease of AUC score for all frameworks. This is because for each target user h in the test set, l recommended items R h have been added to user's item list S h . Therefore, increase of l can decrease the malicious attacker's chance for correctly inferring users' private attribute information. Moreover, RAP has significantly lower AUC score in comparison to Original for all three private attributes and thus outperforms Original in terms of obscuring users' private attribute information. RAP also has significantly better performance in hiding private information in comparison to LDB-SH. The reason is that LDB-SH aims to achieve a privacy goal that is different from preventing leakage of private information. This confirms that although adding noise and satisfying ϵ-differential privacy can indirectly benefit private attribute leakage, it does not directly target this problem. These results show the importance of private-attribute inference attacker component in obfuscating private information. We also observe that RAP hides more private information rather than BlurMe (lower AUC score). This demonstrates that providing obfuscated user-item rating data to the recommendation system, does not necessarily guarantee preventing future private attribute leakage when user receives (and accordingly buy) more recommended products. Moreover, BlurMe needs to be deployed for each private attribute separately while RAP considers three private attributes all together.</p><p>These results confirm the efficiency of RAP in obscuring users' private attribute information and demonstrate that despite the fact that RAP is not aware of the adversary's inference model, it is prepared against the malicious attacker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Utility Analysis (Q2)</head><p>The results for recommendation task for different methods and different number of test items (l) are shown in Table <ref type="table">.</ref> 1. We observe that increasing the number of test items (l) results in increasing R@K and decreasing P@K for all methods. Note that the higher the P@K and R@K score values are, the higher recommendation quality is. Another observation is that LDP-SH has the worst performance amongst all methods, i.e., lowest P@K and R@K scores. This is because of the way LDP-SH adds noise to the user data without considering the quality of recommendation service in practice which can result in degraded recommendation results. BlurMe has also lower performance than RAP as it neglects quality of recommendation results. These results confirm the effectiveness of Bayesian personalized recommendation component which helps RAP to take the utility into consideration in practice. Moreover, quality of recommendation results for RAP method is comparable to the Original approach. This means that RAP can accurately capture users' actual preferences and interests (i.e., high utility).</p><p>The results confirm the effectiveness of RAP in understanding users' actual preferences and recommending ranked relevant products that are interesting yet safe products to users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Utility-Privacy Relation (Q3)</head><p>We compare the privacy and utility results in Table <ref type="table">.</ref> 1 for all methods. We observe that LDP-SH has the worst results in terms of both preserving privacy and recommendation performance. Another observation is that BlurMe improves privacy compared to the Original method, but it loses utility in terms of recommendation system performance. This is in contrast with the results of RAP, which has outperformed BlurMe and LDP-SH in terms of recommendation and has comparable results with Original. RAP has also achieved the lowest AUC score and therefore highest privacy among all other methods. Comparing RAP with other methods confirms that approaching utility loss by minimizing the amount of data changes results in loss of quality of recommendation system in practice. This is reflected as degraded recommendation results for baseline approaches. Moreover, these results confirm the effectiveness of Bayesian personalized recommendation component in RAP, which helps us to consider quality of recommendation in practice. Results also demonstrate the complementary roles of both    recommendation and private attribute components which guide each other through both privacy and utility issues. This results in a privacy-aware recommendation system which is prepared for private attribute inference attack and understands users' preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Impact of Different Components</head><p>Here, we investigate the impact of different private attribute components on obscuring users' private information. We define three variants of our proposed framework, i.e., RAPAge, RAPGen, and RAPOcc. In each of these variants, the model is trained with the corresponding private-attribute inference attacker component, e.g. RA-PAge is trained solely with age inference attacker component and does not utilize any other private-attribute attackers during training phase. Results are shown in Table <ref type="table">.</ref> 2. We observe that for gender attribute, RAPGen has the best performance in terms of obscuring gender attribute comparing to the other approaches (i.e., lowest AUC score). This is in contrast to quality of RAPGen performance for recommendation task which is lower than original proposed model RAP. For other private attributes, RAP still outperforms RAPOcc and RAPAge in terms of obscuring age and occupation attributes. Moreover, results show that using one private-attribute attacker compromises the effectiveness model for obfuscating other private attributes. For the recommendation task, we surprisingly observe that using solely one of the private-attribute attackers in training process can result in performance reduction in comparison to RAP in terms of P@K and R@K. This means that focusing merely on obscuring one private attribute can result in more recommendation performance degradation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Probing Further</head><p>RAP has one important parameter α which controls the contribution from private-attribute attacker component. In this section, we probe further to investigate the effect of this parameter by varying it as {0.25, 0.5, 0.75, 1}. For this experiment, we set the number of test items l = 35. We also set the number of top-K returned items as K = 35 for calculating P@K. Note that P@K and R@K are equal in this scenario as K = l = 35. Results are shown in the Fig. <ref type="figure" target="#fig_6">4</ref>. Although α controls the contribution of private-attribute inference attacker component, we surprisingly observe that with the increase of α, the AUC score for attribute inference attack decreases at first up to the point that α = 0.5 and then it increases. This means that private information were obscured more accurately at the beginning with the increase of α and less later. Moreover, with the increase of α, the performance of recommendation task decreases, i.e., lower P@K. This shows that increasing the contribution of private-attribute attacker component leads to decrease in the quality of recommendation framework. Another observation is that setting α = 0.25 leads to improvement in hiding private attribute information in comparison to the results of using Original (or when α = 0). This result shows the importance of the RAP's private-attribute attacker component in preserving privacy of users. Another observation is that after α = 0.5, continuously increasing α increases the AUC for malicious private-attribute inference attack, i.e., degrades the performance of hiding private information. The reason is that the model could overfit by increasing the value of α and lead to an inaccurate estimation of privacy protection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose an adversarial learning-based recommendation with attribute protection model, RAP, which guards users against private-attribute inference attack while maintaining utility. RAP recommends interesting yet safe products to users such that a malicious attacker cannot infer their private attribute from users' interactions history and recommendations. RAP has two main components, Bayesian personalized recommender, and private-attribute inference attacker. Our empirical results show the effectiveness of RAP in both protecting users against private-attribute inference attacks and preserving quality of recommendation results. RAP also consistently achieves better performance compared to the state-ofthe-art related work. One extension to this work is to study the possibility of extending differential privacy mechanism for this type of attack in recommender systems. It would be also interesting to investigate personalized utility-privacy trade-off by tweaking framework parameters to fit the specific needs of individuals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The architecture of Recommendation with Protection (RAP) with two components: a Bayesian personalized recommender and a private-attribute inference attacker.</figDesc><graphic url="image-1.png" coords="2,323.96,83.68,228.23,152.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of the Bayesian personalized recommendation component.</figDesc><graphic url="image-2.png" coords="4,53.80,83.69,240.22,143.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>where b o is the bias parameter in the output layer. The activation function is RelU function and [.; .] represents concatenation. Note that due to the model simplicity, all users share the same latent representation learning parameters {w, b H } and {w o , b o } in the hidden layer and output layer, respectively.We use BPR to learn how to rank in the problem of recommendation. The final objective function is to minimize the following loss function w.r.t. θ R :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the private-attribute inference attacker component for one attribute.</figDesc><graphic url="image-3.png" coords="4,317.96,83.69,240.24,141.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>0.5397 0.7319 0.152 0.152 0.5714 0.5270 0.7315 0.147 0.168 0.5278 0.5262 0.7312 0.142 0.183 RAPAge 0.6450 0.5948 0.7528 0.150 0.150 0.5489 0.5938 0.7522 0.146 0.167 0.5475 0.5909 0.7497 0.141 0.182 RAPGen 0.5332 0.6789 0.7558 0.151 0.151 0.5298 0.6614 0.7556 0.145 0.166 0.5211 0.6415 0.7555 0.141 0.181 RAPOcc 0.6571 0.6949 0.7468 0.147 0.147 0.6485 0.6871 0.7466 0.141 0.161 0.6454 0.6853 0.7438 0.135 0.174</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Attribute Age (b) Attribute Gender (c) Attribute Occupation (d) Recommendation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance results for private-attribute inference attack and recommendation task for different values of α</figDesc><graphic url="image-4.png" coords="8,53.80,209.61,144.00,70.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Algorithm 1 The Learning Process of RAP model Input: Items set I, training user data U, training user-item matrix data R, batch size b, θ R , {θ t P } T t =1 , α, λ and K. Output: Trained recommendation with protection RAP.</figDesc><table /><note>1: repeat 2:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Impact of different private-attribute attacker components on RAP in terms of utility and privacy.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This material is based upon the work supported, in part, by NSF #1614576, ARO W911NF-15-1-0328 and ONR N00014-17-1-2605.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detection of Violent Extremists in Social Media</title>
		<author>
			<persName><forename type="first">Hamidreza</forename><surname>Alvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumajyoti</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Shakarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 2nd International Conference on Data Intelligence and Security (ICDIS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="43" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Less is More: Semi-Supervised Causal Inference for Detecting Pathogenic Users in Social Media</title>
		<author>
			<persName><forename type="first">Hamidreza</forename><surname>Alvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elham</forename><surname>Shaabani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumajyoti</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Shakarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of The 2019 World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Early identification of pathogenic social media accounts</title>
		<author>
			<persName><forename type="first">Hamidreza</forename><surname>Alvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elham</forename><surname>Shaabani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Shakarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Intelligence and Security Informatics (ISI)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hawkes Process for Understanding the Influence of Pathogenic Social Media Accounts</title>
		<author>
			<persName><forename type="first">Hamidreza</forename><surname>Alvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Shakarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 2nd International Conference on Data Intelligence and Security (ICDIS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="36" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Local, private, efficient protocols for succinct histograms</title>
		<author>
			<persName><forename type="first">Raef</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the forty-seventh annual ACM symposium on Theory of computing</title>
				<meeting>the forty-seventh annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="127" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Protecting user privacy: An approach for untraceable web browsing history and unambiguous user profiles</title>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruocheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Nou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
				<meeting>the Twelfth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="213" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.02191</idno>
		<title level="m">Privacy in social media: Identification, mitigation and applications</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Similar but different: Exploiting usersâĂŹ congruity for recommendation systems</title>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="129" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying novel privacy issues of online users on social media platforms by Ghazaleh Beigi and Huan Liu with Martin Vesely as coordinator</title>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGWEB Newsletter Winter</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruocheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03189</idno>
		<title level="m">I Am Not What I Write: Privacy Preserving Text Representation Learning</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Privacy Preserving Text Representation Learning</title>
		<author>
			<persName><forename type="first">Ghazaleh</forename><surname>Beigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruocheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM Conference on Hypertext and Social Media</title>
				<meeting>the 30th ACM Conference on Hypertext and Social Media</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="275" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Privacy Risks of Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Ann</forename><surname>Joseph A Calandrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Kilzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">W</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Felten</surname></persName>
		</author>
		<author>
			<persName><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (SP), 2011 IEEE Symposium</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="231" to="246" />
		</imprint>
	</monogr>
	<note>You Might Also Like</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BayDNN: Friend Recommendation with Bayesian Personalized Ranking Deep Neural Network</title>
		<author>
			<persName><forename type="first">Daizong</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Shao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Hua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM CIKM</title>
				<meeting>the ACM CIKM</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Applications of Models of Computation</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An introduction to ROC analysis</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">You Are Who You Know and How You Behave: Attribute Inference Attacks via Users&apos; Social Friends and Behaviors</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="979" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attribute Inference Attacks in Online Social Networks</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Privacy and Security (TOPS)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint link prediction and attribute inference using a social-attribute network</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lester</forename><surname>Mackey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eui</forename><surname>Chul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emil</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elaine</forename><forename type="middle">Runting</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>TIST)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis)</title>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inferring privacy information from social networks</title>
		<author>
			<persName><forename type="first">Jianming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wesley</forename><forename type="middle">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligence and Security Informatics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="154" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tagging performance correlates with author age</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="483" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Differentially Private Matrix Factorization</title>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1763" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename><surname>Nzhenqiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th {USENIX} Security Symposium ({USENIX} Security 18)</title>
				<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">AttriInfer: Inferring user attributes in online social networks using markov random fields</title>
		<author>
			<persName><forename type="first">Jinyuan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binghui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW</title>
				<meeting>the WWW</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1561" to="1569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A Privacy-Preserving Framework for Personalized, Social Recommendations</title>
		<author>
			<persName><forename type="first">Zach</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>EDBT 582</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recommender systems: from algorithms to user experience</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User modeling and user-adapted interaction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Collaborative filtering with temporal dynamics</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Private traits and attributes are predictable from digital records of human behavior</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Stillwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="5802" to="5805" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Inferring private information using social network data</title>
		<author>
			<persName><forename type="first">Jack</forename><surname>Lindamood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Heatherly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kantarcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavani</forename><surname>Thuraisingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW. ACM</title>
				<meeting>WWW. ACM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1145" to="1146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A privacy preserving group recommender based on cooperative perturbation</title>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanli</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Differentially private recommender systems: building privacy into the net</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
				<meeting>SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">You are who you know: inferring user profiles in online social networks</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bimal</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM. ACM</title>
				<meeting>WSDM. ACM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Neural Personalized Ranking for Image Recommendation</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haokai</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM WSDM</title>
				<meeting>the 11th ACM WSDM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">You Are Who You Know and How You Behave: Attribute Inference Attacks via Users&apos; Social Friends and Behaviors</title>
		<author>
			<persName><forename type="first">Gong</forename><surname>Nzhenqiang</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th {USENIX} Security Symposium</title>
		<title level="s">{USENIX} Security</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Optimal forgery and suppression of ratings for privacy enhancement in recommendation systems</title>
		<author>
			<persName><forename type="first">Javier</forename><surname>Parra-Arnau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Rebollo-Monedero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Forné</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1586" to="1631" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Privacy-preserving collaborative filtering using randomized perturbation techniques</title>
		<author>
			<persName><forename type="first">Huseyin</forename><surname>Polat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Privacy risks in recommender systems</title>
		<author>
			<persName><forename type="first">Naren</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">J</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Batul</forename><forename type="middle">J</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Ananth Y Grama</surname></persName>
		</author>
		<author>
			<persName><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="54" to="62" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Getting to know you: learning new user preferences in recommender systems</title>
		<author>
			<persName><forename type="first">Al</forename><surname>Mamunur Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Istvan</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Cosley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shyong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">M</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th international conference on Intelligent user interfaces</title>
				<meeting>the 7th international conference on Intelligent user interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An information-theoretic privacy criterion for query forgery in information retrieval</title>
		<author>
			<persName><forename type="first">David</forename><surname>Rebollo-Monedero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Parra-Arnau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Forné</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Security Technology</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="146" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence</title>
				<meeting>the twenty-fifth conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">BlurMe: Inferring and obfuscating user gender based on ratings</title>
		<author>
			<persName><forename type="first">Udi</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smriti</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stratis</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM conference on Recommender systems</title>
				<meeting>the sixth ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles</title>
		<author>
			<persName><forename type="first">Elena</forename><surname>Zheleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th international conference on World wide web</title>
				<meeting>the 18th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Differential privacy for collaborative filtering recommender algorithm</title>
		<author>
			<persName><forename type="first">Xue</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM on International Workshop on Security And Privacy Analytics</title>
				<meeting>the 2016 ACM on International Workshop on Security And Privacy Analytics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improving recommendation lists through topic diversification</title>
		<author>
			<persName><forename type="first">Cai-Nicolas</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Lausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th international conference on World Wide Web</title>
				<meeting>the 14th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
