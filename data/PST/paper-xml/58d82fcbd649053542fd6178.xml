<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE CONCRETE DISTRIBUTION: A CONTINUOUS RELAXATION OF DISCRETE RANDOM VARIABLES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-03-05">5 Mar 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DeepMind</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DeepMind</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yee</forename><surname>Whye Teh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DeepMind</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">THE CONCRETE DISTRIBUTION: A CONTINUOUS RELAXATION OF DISCRETE RANDOM VARIABLES</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-03-05">5 Mar 2017</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1611.00712v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The reparameterization trick enables optimizing large scale stochastic computation graphs via gradient descent. The essence of the trick is to refactor each stochastic node into a differentiable function of its parameters and a random variable with fixed distribution. After refactoring, the gradients of the loss propagated by the chain rule through the graph are low variance unbiased estimators of the gradients of the expected loss. While many continuous random variables have such reparameterizations, discrete random variables lack useful reparameterizations due to the discontinuous nature of discrete states. In this work we introduce CONCRETE random variables-CONtinuous relaxations of disCRETE random variables. The Concrete distribution is a new family of distributions with closed form densities and a simple reparameterization. Whenever a discrete stochastic node of a computation graph can be refactored into a one-hot bit representation that is treated continuously, Concrete stochastic nodes can be used with automatic differentiation to produce low-variance biased gradients of objectives (including objectives that depend on the log-probability of latent stochastic nodes) on the corresponding discrete graph. We demonstrate the effectiveness of Concrete relaxations on density estimation and structured prediction tasks using neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Software libraries for automatic differentiation (AD) <ref type="bibr" target="#b0">(Abadi et al., 2015;</ref><ref type="bibr" target="#b39">Theano Development Team, 2016)</ref> are enjoying broad use, spurred on by the success of neural networks on some of the most challenging problems of machine learning. The dominant mode of development in these libraries is to define a forward parametric computation, in the form of a directed acyclic graph, that computes the desired objective. If the components of the graph are differentiable, then a backwards computation for the gradient of the objective can be derived automatically with the chain rule. The ease of use and unreasonable effectiveness of gradient descent has led to an explosion in the diversity of architectures and objective functions. Thus, expanding the range of useful continuous operations can have an outsized impact on the development of new models. For example, a topic of recent attention has been the optimization of stochastic computation graphs from samples of their states. Here, the observation that AD "just works" when stochastic nodes<ref type="foot" target="#foot_0">1</ref> can be reparameterized into deterministic functions of their parameters and a fixed noise distribution <ref type="bibr" target="#b22">(Kingma &amp; Welling, 2013;</ref><ref type="bibr">Rezende et al., 2014)</ref>, has liberated researchers in the development of large complex stochastic architectures (e.g. <ref type="bibr" target="#b14">Gregor et al., 2015)</ref>.</p><p>Computing with discrete stochastic nodes still poses a significant challenge for AD libraries. Deterministic discreteness can be relaxed and approximated reasonably well with sigmoidal functions or the softmax (see e.g., <ref type="bibr" target="#b12">Grefenstette et al., 2015;</ref><ref type="bibr" target="#b10">Graves et al., 2016)</ref>, but, if a distribution over discrete states is needed, there is no clear solution. There are well known unbiased estimators for the gradi-The paper is organized as follows. We provide a background on stochastic computation graphs and their optimization in Section 2. Section 3 reviews a reparameterization for discrete random variables, introduces the Concrete distribution, and discusses its application as a relaxation. Section 4 reviews related work. In Section 5 we present results on a density estimation task and a structured prediction task on the MNIST and Omniglot datasets. In Appendices C and F we provide details on the practical implementation and use of Concrete random variables. When comparing the effectiveness of gradients obtained via Concrete relaxations to a state-of-the-art-method (VIMCO, <ref type="bibr" target="#b27">Mnih &amp; Rezende, 2016)</ref>, we find that they are competitive-occasionally outperforming and occasionally underperforming-all the while being implemented in an AD library without special casing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>2.1 OPTIMIZING STOCHASTIC COMPUTATION GRAPHS Stochastic computation graphs (SCGs) provide a formalism for specifying input-output mappings, potentially stochastic, with learnable parameters using directed acyclic graphs (see <ref type="bibr" target="#b38">Schulman et al. (2015)</ref> for a review). The state of each non-input node in such a graph is obtained from the states of its parent nodes by either evaluating a deterministic function or sampling from a conditional distribution. Many training objectives in supervised, unsupervised, and reinforcement learning can be expressed in terms of SCGs.</p><p>To optimize an objective represented as a SCG, we need estimates of its parameter gradients. We will concentrate on graphs with some stochastic nodes (backpropagation covers the rest). For simplicity, we restrict our attention to graphs with a single stochastic node X. We can interpret the forward pass in the graph as first sampling X from the conditional distribution p φ (x) of the stochastic node given its parents, then evaluating a deterministic function f θ (x) at X. We can think of f θ (X) as a noisy objective, and we are interested in optimizing its expected value L(θ, φ) = E X∼p φ (x) [f θ (X)] w.r.t. parameters θ, φ.</p><p>In general, both the objective and its gradients are intractable. We will side-step this issue by estimating them with samples from p φ (x). The gradient w.r.t. to the parameters θ has the form</p><formula xml:id="formula_0">∇ θ L(θ, φ) = ∇ θ E X∼p φ (x) [f θ (X)] = E X∼p φ (x) [∇ θ f θ (X)]</formula><p>(1) and can be easily estimated using Monte Carlo sampling:</p><formula xml:id="formula_1">∇ θ L(θ, φ) 1 S S s=1 ∇ θ f θ (X s ),<label>(2)</label></formula><p>where X s ∼ p φ (x) i.i.d. The more challenging task is to compute the gradient w.r.t. the parameters φ of p φ (x). The expression obtained by differentiating the expected objective,</p><formula xml:id="formula_2">∇ φ L(θ, φ) = ∇ φ p φ (x)f θ (x) dx = f θ (x)∇ φ p φ (x) dx,<label>(3)</label></formula><p>does not have the form of an expectation w.r.t. x and thus does not directly lead to a Monte Carlo gradient estimator. However, there are two ways of getting around this difficulty which lead to the two classes of estimators we will now discuss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">SCORE FUNCTION ESTIMATORS</head><p>The score function estimator <ref type="bibr">(SFE, Fu, 2006)</ref>, also known as the REINFORCE <ref type="bibr">(Williams, 1992)</ref> or likelihood-ratio estimator <ref type="bibr" target="#b9">(Glynn, 1990)</ref>, is based on the identity ∇ φ p φ (x) = p φ (x)∇ φ log p φ (x), which allows the gradient in Eq. 3 to be written as an expectation:</p><formula xml:id="formula_3">∇ φ L(θ, φ) = E X∼p φ (x) [f θ (X)∇ φ log p φ (X)] .<label>(4)</label></formula><p>Estimating this expectation using naive Monte Carlo gives the estimator</p><formula xml:id="formula_4">∇ φ L(θ, φ) 1 S S s=1 f θ (X s )∇ φ log p φ (X s ),<label>(5)</label></formula><p>where X s ∼ p φ (x) i.i.d. This is a very general estimator that is applicable whenever log p φ (x) is differentiable w.r.t. φ. As it does not require f θ (x) to be differentiable or even continuous as a function of x, the SFE can be used with both discrete and continuous random variables.</p><p>Though the basic version of the estimator can suffer from high variance, various variance reduction techniques can be used to make the estimator much more effective <ref type="bibr" target="#b11">(Greensmith et al., 2004)</ref>.</p><p>Baselines are the most important and widely used of these techniques <ref type="bibr">(Williams, 1992)</ref>. A number of score function estimators have been developed in machine learning <ref type="bibr" target="#b30">(Paisley et al., 2012;</ref><ref type="bibr" target="#b13">Gregor et al., 2013;</ref><ref type="bibr" target="#b33">Ranganath et al., 2014;</ref><ref type="bibr">Mnih &amp; Gregor, 2014;</ref><ref type="bibr">Titsias &amp; Lázaro-Gredilla, 2015;</ref><ref type="bibr" target="#b15">Gu et al., 2016)</ref>, which differ primarily in the variance reduction techniques used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">REPARAMETERIZATION TRICK</head><p>In many cases we can sample from p φ (x) by first sampling Z from some fixed distribution q(z) and then transforming the sample using some function g φ (z). For example, a sample from Normal(µ, σ 2 ) can be obtained by sampling Z from the standard form of the distribution Normal(0, 1) and then transforming it using g µ,σ (Z) = µ + σZ. This two-stage reformulation of the sampling process, called the reparameterization trick, allows us to transfer the dependence on φ from p into f by writing f θ (x) = f θ (g φ (z)) for x = g φ (z), making it possible to reduce the problem of estimating the gradient w.r.t. parameters of a distribution to the simpler problem of estimating the gradient w.r.t. parameters of a deterministic function.</p><p>Having reparameterized p φ (x), we can now express the objective as an expectation w.r.t. q(z):</p><formula xml:id="formula_5">L(θ, φ) = E X∼p φ (x) [f θ (X)] = E Z∼q(z) [f θ (g φ (Z))].<label>(6)</label></formula><p>As q(z) does not depend on φ, we can estimate the gradient w.r.t. φ in exactly the same way we estimated the gradient w.r.t. θ in Eq. 1. Assuming differentiability of f θ (x) w.r.t. x and of g φ (z) w.r.t. φ and using the chain rule gives</p><formula xml:id="formula_6">∇ φ L(θ, φ) = E Z∼q(z) [∇ φ f θ (g φ (Z))] = E Z∼q(z) [f θ (g φ (Z))∇ φ g φ (Z)] .<label>(7)</label></formula><p>The reparameterization trick, introduced in the context of variational inference independently by <ref type="bibr" target="#b23">Kingma &amp; Welling (2014</ref><ref type="bibr">), Rezende et al. (2014</ref><ref type="bibr" target="#b40">), and Titsias &amp; Lázaro-Gredilla (2014)</ref>, is usually the estimator of choice when it is applicable. For continuous latent variables which are not directly reparameterizable, new hybrid estimators have also been developed, by combining partial reparameterizations with score function estimators <ref type="bibr">(Ruiz et al., 2016;</ref><ref type="bibr" target="#b29">Naesseth et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">APPLICATION: VARIATIONAL TRAINING OF LATENT VARIABLE MODELS</head><p>We will now see how the task of training latent variable models can be formulated in the SCG framework. Such models assume that each observation x is obtained by first sampling a vector of latent variables Z from the prior p θ (z) before sampling the observation itself from p θ (x | z).</p><p>Thus the probability of observation x is p θ (x) = z p θ (z)p θ (x | z). Maximum likelihood training of such models is infeasible, because the log-likelihood (LL) objective .</p><formula xml:id="formula_7">L(θ) = log p θ (x) = G 2 G 2 + + log ↵ 1 log ↵ 1 log ↵ 2 log ↵ 2 log ↵ 3 log ↵ 3 argmax i {x i } argmax i {x i } G 1 G 1 G 3 G 3 (a) Discrete(α) G 2 G 2 + + exp(xi/ ) P i exp(xi/ ) exp(xi/ ) P i exp(xi/ ) log ↵ 1 log ↵ 1 log ↵ 2 log ↵ 2 log ↵ 3 log ↵ 3 G 1 G 1 G 3 G 3 (b) Concrete(α, λ)</formula><formula xml:id="formula_8">log E Z∼p θ (z) [p θ (x | Z)</formula><p>] is typically intractable and does not fit into the above framework due to the expectation being inside the log. The multi-sample variational objective <ref type="bibr" target="#b4">(Burda et al., 2016)</ref>,</p><formula xml:id="formula_9">L m (θ, φ) = E Z i ∼q φ (z|x) log 1 m m i=1 p θ (Z i , x) q φ (Z i | x) . (<label>8</label></formula><formula xml:id="formula_10">)</formula><p>provides a convenient alternative which has precisely the form we considered in Section 2.1. This approach relies on introducing an auxiliary distribution q φ (z | x) with its own parameters, which serves as approximation to the intractable posterior p θ (z | x). The model is trained by jointly maximizing the objective w.r.t. to the parameters of p and q. The number of samples used inside the objective m allows trading off the computational cost against the tightness of the bound. For m = 1, L m (θ, φ) becomes is the widely used evidence lower bound <ref type="bibr">(ELBO, Hoffman et al., 2013)</ref> on log p θ (x), while for m &gt; 1, it is known as the importance weighted bound <ref type="bibr" target="#b4">(Burda et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE CONCRETE DISTRIBUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DISCRETE RANDOM VARIABLES AND THE GUMBEL-MAX TRICK</head><p>To motivate the construction of Concrete random variables, we review a method for sampling from discrete distributions called the Gumbel-Max trick <ref type="bibr" target="#b24">(Luce, 1959;</ref><ref type="bibr">Yellott, 1977;</ref><ref type="bibr" target="#b31">Papandreou &amp; Yuille, 2011;</ref><ref type="bibr" target="#b17">Hazan &amp; Jaakkola, 2012;</ref><ref type="bibr" target="#b26">Maddison et al., 2014)</ref>. We restrict ourselves to a representation of discrete states as vectors d ∈ {0, 1} n of bits that are one-hot, or n k=1 d k = 1. This is a flexible representation in a computation graph; to achieve an integral representation take the inner product of d with (1, . . . , n), and to achieve a point mass representation in R m take W d where W ∈ R m×n .</p><p>Consider an unnormalized parameterization (α 1 , . . . , α n ) where α k ∈ (0, ∞) of a discrete distribution D ∼ Discrete(α)-we can assume that states with 0 probability are excluded. The Gumbel-Max trick proceeds as follows: sample U k ∼ Uniform(0, 1) i.i.d. for each k, find k that maximizes {log α k − log(− log U k )}, set D k = 1 and the remaining D i = 0 for i = k. Then</p><formula xml:id="formula_11">P(D k = 1) = α k n i=1 α i . (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>In other words, the sampling of a discrete random variable can be refactored into a deterministic function-componentwise addition followed by argmax-of the parameters log α k and fixed distribution − log(− log U k ). See Figure <ref type="figure" target="#fig_0">1a</ref> for a visualization.</p><p>The apparently arbitrary choice of noise gives the trick its name, as − log(− log U ) has a Gumbel distribution. This distribution features in extreme value theory <ref type="bibr" target="#b16">(Gumbel, 1954)</ref> where it plays a central role similar to the Normal distribution: the Gumbel distribution is stable under max operations, and for some distributions, the order statistics (suitably normalized) of i.i.d. draws approach the Gumbel in distribution. The Gumbel can also be recognized as a − log-transformed exponential random variable. So, the correctness of (9) also reduces to a well known result regarding the argmin of exponential random variables. See <ref type="bibr" target="#b18">(Hazan et al., 2016)</ref> for a collection of related work, and particularly the chapter <ref type="bibr" target="#b25">(Maddison, 2016)</ref> for a proof and generalization of this trick.</p><p>(a) λ = 0</p><formula xml:id="formula_13">(b) λ = 1/2 (c) λ = 1 (d) λ = 2</formula><p>Figure <ref type="figure">2</ref>: A discrete distribution with unnormalized probabilities (α 1 , α 2 , α 3 ) = (2, 0.5, 1) and three corresponding Concrete densities at increasing temperatures λ. Each triangle represents the set of points (y 1 , y 2 , y 3 ) in the simplex ∆ 2 = {(y 1 , y 2 , y 3 ) | y k ∈ (0, 1), y 1 + y 2 + y 3 = 1}. For λ = 0 the size of white circles represents the mass assigned to each vertex of the simplex under the discrete distribution. For λ ∈ {2, 1, 0.5} the intensity of the shading represents the value of p α,λ (y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CONCRETE RANDOM VARIABLES</head><p>The derivative of the argmax is 0 everywhere except at the boundary of state changes, where it is undefined. For this reason the Gumbel-Max trick is not a suitable reparameterization for use in SCGs with AD. Here we introduce the Concrete distribution motivated by considering a graph, which is the same as Figure <ref type="figure" target="#fig_0">1a</ref> up to a continuous relaxation of the argmax computation, see Figure <ref type="figure" target="#fig_0">1b</ref>. This will ultimately allow the optimization of parameters α k via gradients.</p><p>The argmax computation returns states on the vertices of the simplex</p><formula xml:id="formula_14">∆ n−1 = {x ∈ R n | x k ∈ [0, 1], n k=1 x k = 1}.</formula><p>The idea behind Concrete random variables is to relax the state of a discrete variable from the vertices into the interior where it is a random probability vector-a vector of numbers between 0 and 1 that sum to 1. To sample a Concrete random variable</p><formula xml:id="formula_15">X ∈ ∆ n−1 at temperature λ ∈ (0, ∞) with parameters α k ∈ (0, ∞), sample G k ∼ Gumbel i.i.d. and set X k = exp((log α k + G k )/λ) n i=1 exp((log α i + G i )/λ) . (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>The softmax computation of (10) smoothly approaches the discrete argmax computation as λ → 0 while preserving the relative order of the Gumbels log α k + G k . So, imagine making a series of forward passes on the graphs of Figure <ref type="figure" target="#fig_0">1</ref>. Both graphs return a stochastic value for each forward pass, but for smaller temperatures the outputs of Figure <ref type="figure" target="#fig_0">1b</ref> become more discrete and eventually indistinguishable from a typical forward pass of Figure <ref type="figure" target="#fig_0">1a</ref>.</p><p>The distribution of X sampled via (10) has a closed form density on the simplex. Because there may be other ways to sample a Concrete random variable, we take the density to be its definition.</p><formula xml:id="formula_17">Definition 1 (Concrete Random Variables). Let α ∈ (0, ∞) n and λ ∈ (0, ∞). X ∈ ∆ n−1 has a Concrete distribution X ∼ Concrete(α, λ)</formula><p>with location α and temperature λ, if its density is:</p><formula xml:id="formula_18">p α,λ (x) = (n − 1)! λ n−1 n k=1 α k x −λ−1 k n i=1 α i x −λ i . (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>Proposition 1 lists a few properties of the Concrete distribution. (a) is confirmation that our definition corresponds to the sampling routine (10). (b) confirms that rounding a Concrete random variable results in the discrete random variable whose distribution is described by the logits log α k , (c) confirms that taking the zero temperature limit of a Concrete random variable is the same as rounding. Finally, (d) is a convexity result on the density. We prove these results in Appendix A.</p><p>Proposition 1 (Some Properties of Concrete Random Variables). Let X ∼ Concrete(α, λ) with location parameters α ∈ (0, ∞) n and temperature λ ∈ (0, ∞), then </p><formula xml:id="formula_20">(a) (Reparameterization) If G k ∼ Gumbel i.i.d., then X k d = exp((log α k +G k )/λ) n i=1 exp((log αi+Gi)/λ) , (b) (Rounding) P (X k &gt; X i for i = k) = α k /( n i=1 α i ), (c) (Zero temperature) P (lim λ→0 X k = 1) = α k /( n i=1 α i ), (a) λ = 0 (b) λ = 1/2 (c) λ = 1 (d) λ = 2</formula><formula xml:id="formula_21">(d) (Convex eventually) If λ ≤ (n − 1) −1 , then p α,λ (x) is log-convex in x.</formula><p>The binary case of the Gumbel-Max trick simplifies to passing additive noise through a step function. The corresponding Concrete relaxation is implemented by passing additive noise through a sigmoid-see Figure <ref type="figure" target="#fig_1">3</ref>. We cover this more thoroughly in Appendix B, along with a cheat sheet (Appendix F) on the density and implementation of all the random variables discussed in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">CONCRETE RELAXATIONS</head><p>Concrete random variables may have some intrinsic value, but we investigate them simply as surrogates for optimizing a SCG with discrete nodes. When it is computationally feasible to integrate over the discreteness, that will always be a better choice. Thus, we consider the use case of optimizing a large graph with discrete stochastic nodes from samples.</p><p>First, we outline our proposal for how to use Concrete relaxations by considering a variational autoencoder with a single discrete latent variable. Let P a (d) be the mass function of some ndimensional one-hot discrete random variable with unnormalized probabilities a ∈ (0, ∞) n and p θ (x|d) some distribution over a data point x given d ∈ (0, 1) n one-hot. The generative model is then p θ,a (x, d) = p θ (x|d)P a (d). Let Q α (d|x) be an approximating posterior over d ∈ (0, 1) n onehot whose unnormalized probabilities α(x) ∈ (0, ∞) n depend on x. All together the variational lowerbound we care about stochastically optimizing is</p><formula xml:id="formula_22">L 1 (θ, a, α) = E D∼Qα(d|x) log p θ (x|D)P a (D) Q α (D|x) ,<label>(12)</label></formula><p>with respect to θ, a, and any parameters of α. First, we relax the stochastic computation D ∼ Discrete(α(x)) by replacing D with a Concrete random variable Z ∼ Concrete(α(x), λ 1 ) with density q α,λ1 (z|x). Simply replacing every instance of D with Z in Eq. 12 will result in a non-interpretable objective, which does not necessarily lowerbound log p(x), because</p><formula xml:id="formula_23">E Z∼q α,λ 1 (a|x) [− log Q α (Z|x)/P a (Z)]</formula><p>is not a KL divergence. Thus we propose "relaxing" the terms P a (d) and Q α (d|x) to reflect the true sampling distribution. Thus, the relaxed objective is:</p><formula xml:id="formula_24">L 1 (θ, a, α) relax E Z∼q α,λ 1 (z|x) log p θ (x|Z)p a,λ2 (Z) q α,λ1 (Z|x)<label>(13)</label></formula><p>where p a,λ2 (z) is a Concrete density with location a and temperature λ 2 . At test time we evaluate the discrete lowerbound L 1 (θ, a, α). Naively implementing Eq. 13 will result in numerical issues. We discuss this and other details in Appendix C.</p><p>Thus, the basic paradigm we propose is the following: during training replace every discrete node with a Concrete node at some fixed temperature (or with an annealing schedule). The graphs are identical up to the softmax / argmax computations, so the parameters of the relaxed graph and discrete graph are the same. When an objective depends on the log-probability of discrete variables in the SCG, as the variational lowerbound does, we propose that the log-probability terms are also "relaxed" to represent the true distribution of the relaxed node. At test time the original discrete loss is evaluated. This is possible, because the discretization of any Concrete distribution has a closed form mass function, and the relaxation of any discrete distribution into a Concrete distribution has a closed form density. This is not always possible. For example, the multinomial probit model-the Gumbel-Max trick with Gaussians replacing Gumbels-does not have a closed form mass.</p><p>The success of Concrete relaxations will depend on the choice of temperature during training. It is important that the relaxed nodes are not able to represent a precise real valued mode in the interior of the simplex as in Figure <ref type="figure">2d</ref>. If this is the case, it is possible for the relaxed random variable to communicate much more than log 2 (n) bits of information about its α parameters. This might lead the relaxation to prefer the interior of the simplex to the vertices, and as a result there will be a large integrality gap in the overall performance of the discrete graph. Therefore Proposition 1 (d) is a conservative guideline for generic n-ary Concrete relaxations; at temperatures lower than (n − 1) −1 we are guaranteed not to have any modes in the interior for any α ∈ (0, ∞) n . We discuss the subtleties of choosing the temperatures in more detail in Appendix C. Ultimately the best choice of λ and the performance of the relaxation for any specific n will be an empirical question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Perhaps the most common distribution over the simplex is the Dirichlet with density p α (x)</p><formula xml:id="formula_25">∝ n k=1 x α k −1 k on x ∈ ∆ n−1 .</formula><p>The Dirichlet can be characterized by strong independence properties, and a great deal of work has been done to generalize it <ref type="bibr" target="#b5">(Connor &amp; Mosimann, 1969;</ref><ref type="bibr" target="#b1">Aitchison, 1985;</ref><ref type="bibr" target="#b34">Rayens &amp; Srinivasan, 1994;</ref><ref type="bibr" target="#b6">Favaro et al., 2011)</ref>. Of note is the Logistic Normal distribution <ref type="bibr" target="#b2">(Atchison &amp; Shen, 1980)</ref>, which can be simulated by taking the softmax of n − 1 normal random variables and an nth logit that is deterministically zero. The Logistic Normal is an important distribution, because it can effectively model correlations within the simplex <ref type="bibr">(Blei &amp; Lafferty, 2006)</ref>. To our knowledge the Concrete distribution does not fall completely into any family of distributions previously described. For λ ≤ 1 the Concrete is in a class of normalized infinitely divisible distributions (S. Favaro, personal communication), and the results of <ref type="bibr" target="#b6">Favaro et al. (2011)</ref> apply.</p><p>The idea of using a softmax of Gumbels as a relaxation for a discrete random variable was concurrently considered by <ref type="bibr" target="#b20">(Jang et al., 2016)</ref>, where it was called the Gumbel-Softmax. They do not use the density in the relaxed objective, opting instead to compute all aspects of the graph, including discrete log-probability computations, with the relaxed stochastic state of the graph. In the case of variational inference, this relaxed objective is not a lower bound on the marginal likelihood of the observations, and care needs to be taken when optimizing it. The idea of using sigmoidal functions with additive input noise to approximate discreteness is also not a new idea. <ref type="bibr">(Frey, 1997)</ref> introduced nonlinear Gaussian units which computed their activation by passing Gaussian noise with the mean and variance specified by the input to the unit through a nonlinearity, such as the logistic function. <ref type="bibr" target="#b36">Salakhutdinov &amp; Hinton (2009)</ref> binarized real-valued codes of an autoencoder by adding (Gaussian) noise to the logits before passing them through the logistic function. Most recently, to avoid the difficulty associated with likelihood-ratio methods <ref type="bibr" target="#b23">(Kočiský et al., 2016)</ref> relaxed the discrete sampling operation by sampling a vector of Gaussians instead and passing those through a softmax.</p><p>There is another family of gradient estimators that have been studied in the context of training neural networks with discrete units. These are usually collected under the umbrella of straightthrough estimators <ref type="bibr" target="#b3">(Bengio et al., 2013;</ref><ref type="bibr" target="#b32">Raiko et al., 2014)</ref>. The basic idea they use is passing forward discrete values, but taking gradients through the expected value. They have good empirical performance, but have not been shown to be the estimators of any loss function. This is in contrast to gradients from Concrete relaxations, which are biased with respect to the discrete graph, but unbiased with respect to the continuous one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">PROTOCOL</head><p>The aim of our experiments was to evaluate the effectiveness of the gradients of Concrete relaxations for optimizing SCGs with discrete nodes. We considered the tasks in <ref type="bibr" target="#b27">(Mnih &amp; Rezende, 2016)</ref>: structured output prediction and density estimation. Both tasks are difficult optimization problems involving fitting probability distributions with hundreds of latent discrete nodes. We compared the performance of Concrete reparameterizations to two state-of-the-art score function estimators: VIMCO <ref type="bibr" target="#b27">(Mnih &amp; Rezende, 2016)</ref> for optimizing the multisample variational objective (m &gt; 1) and NVIL <ref type="bibr">(Mnih &amp; Gregor, 2014)</ref> for optimizing the single-sample one (m = 1). We performed the experiments using the MNIST and Omniglot datasets. These are datasets of 28 × 28 images of handwritten digits (MNIST) or letters (Omniglot). For MNIST we used the fixed binarization of <ref type="bibr" target="#b37">Salakhutdinov &amp; Murray (2008)</ref>  training/validation/testing sets. For Omniglot we sampled a fixed binarization and used the standard 24,345/8,070 split into training/testing sets. We report the negative log-likelihood (NLL) of the discrete graph on the test data as the performance metric.</p><p>All of our models were neural networks with layers of n-ary discrete stochastic nodes with values on the corners of the hypercube {−1, 1} log 2 (n) . The distributions were parameterized by n real values log α k ∈ R, which we took to be the logits of a discrete random variable D ∼ Discrete(α) with n states. Model descriptions are of the form "(200V-200H∼784V)", read from left to right. This describes the order of conditional sampling, again from left to right, with each integer representing the number of stochastic units in a layer. The letters V and H represent observed and latent variables, respectively. If the leftmost layer is H, then it was sampled unconditionally from some parameters. Conditioning functions are described by {-, ∼}, where "-" means a linear function of the previous layer and "∼" means a non-linear function. A "layer" of these units is simply the concatenation of some number of independent nodes whose parameters are determined as a function the previous layer. For example a 240 binary layer is a factored distribution over the {−1, 1} 240 hypercube. Whereas a 240 8-ary layer can be seen as a distribution over the same hypercube where each of the 80 triples of units are sampled independently from an 8 way discrete distribution over {−1, 1} 3 . All models were initialized with the heuristic of <ref type="bibr" target="#b8">Glorot &amp; Bengio (2010)</ref> and optimized using Adam <ref type="bibr" target="#b21">(Kingma &amp; Ba, 2014)</ref>. All temperatures were fixed throughout training. Appendix D for hyperparameter details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">DENSITY ESTIMATION</head><p>Density estimation, or generative modelling, is the problem of fitting the distribution of data. We took the latent variable approach described in Section 2.4 and trained the models by optimizing the variational objective L m (θ, φ) given by Eq. 8 averaged uniformly over minibatches of data points x. Both our generative models p θ (z, x) and variational distributions q φ (z | x) were parameterized with neural networks as described above. We trained models with L m (θ, φ) for m ∈ {1, 5, 50} and approximated the NLL with L 50,000 (θ, φ) averaged uniformly over the whole dataset.</p><p>The results are shown in Table <ref type="table" target="#tab_0">1</ref>. In general, VIMCO outperformed Concrete relaxations for linear models and Concrete relaxations outperformed VIMCO for non-linear models. We also tested the effectiveness of Concrete relaxations on generative models with n-ary layers on the L 5 (θ, φ) objective.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">STRUCTURED OUTPUT PREDICTION</head><p>Structured output prediction is concerned with modelling the high-dimensional distribution of the observation given a context and can be seen as conditional density estimation. We considered the task of predicting the bottom half x 1 of an image of an MNIST digit given its top half x 2 , as introduced by <ref type="bibr" target="#b32">Raiko et al. (2014)</ref>. We followed <ref type="bibr" target="#b32">Raiko et al. (2014)</ref> in using a model with layers of discrete stochastic units between the context and the observation. Conditioned on the top half x 2 the network samples from a distribution p φ (z | x 2 ) over layers of stochastic units z then predicts x 1 by sampling from a distribution p θ (x 1 | z). The training objective for a single pair (x 1 , x 2 ) is</p><formula xml:id="formula_26">L SP m (θ, φ) = E Zi∼p φ (z|x2) log 1 m m i=1 p θ (x 1 | Z i ) .</formula><p>This objective is a special case of L m (θ, φ) (Eq. 8) where we use the prior p φ (z|x 2 ) as the variational distribution. Thus, the objective is a lower bound on log p θ,φ (x 1 | x 2 ).</p><p>We trained the models by optimizing L SP m (θ, φ) for m ∈ {1, 5, 50} averaged uniformly over minibatches and evaluated them by computing L SP 100 (θ, φ) averaged uniformly over the entire dataset. The results are shown in Figure <ref type="figure" target="#fig_2">4</ref>. Concrete relaxations more uniformly outperformed VIMCO in this instance. We also trained n-ary (392V-240H-240H-240H-392V) models on the L SP 1 (θ, φ) objective using the best temperature hyperparameters from density estimation. 4-ary achieved a test/train NLL of 55.4/46.0 and 8-ary achieved 54.7/44.8. As opposed to density estimation, increasing arity uniformly improved the models. We also investigated the hypothesis that for higher temperatures Concrete relaxations might prefer the interior of the interval to the boundary points {−1, 1}. Figure <ref type="figure" target="#fig_2">4</ref> was generated with binary (392V-240H-240H-240H-392V) model trained on L SP 1 (θ, φ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We introduced the Concrete distribution, a continuous relaxation of discrete random variables. The Concrete distribution is a new distribution on the simplex with a closed form density parameterized by a vector of positive location parameters and a positive temperature. Crucially, the zero temperature limit of every Concrete distribution corresponds to a discrete distribution, and any discrete distribution can be seen as the discretization of a Concrete one. The application we considered was training stochastic computation graphs with discrete stochastic nodes. The gradients of Concrete relaxations are biased with respect to the original discrete objective, but they are low variance unbiased estimators of a continuous surrogate objective. We showed in a series of experiments that stochastic nodes with Concrete distributions can be used effectively to optimize the parameters of a stochastic computation graph with discrete stochastic nodes. We did not find that annealing or automatically tuning the temperature was important for these experiments, but it remains interesting and possibly valuable future work. A PROOF OF PROPOSITION 1</p><p>Let X ∼ Concrete(α, λ) with location parameters α ∈ (0, ∞) n and temperature λ ∈ (0, ∞).</p><formula xml:id="formula_27">1. Let G k ∼ Gumbel i.i.d., consider Y k = exp((log α k + G k )/λ) n i=1 exp((log α i + G i )/λ) Let Z k = log α k + G k , which has density α k exp(−z k ) exp(−α k exp(−z k ))</formula><p>We will consider the invertible transformation</p><formula xml:id="formula_28">F (z 1 , . . . , z n ) = (y 1 , . . . , y n−1 , c)</formula><p>where</p><formula xml:id="formula_29">y k = exp(z k /λ)c −1 c = n i=1 exp(z i /λ) then F −1 (y 1 , . . . , y n−1 , c) = (λ(log y 1 + log c), . . . , λ(log y n−1 + log c), λ(log y n + log c))</formula><p>where</p><formula xml:id="formula_30">y n = 1 − n−1 i=1 y i . This has Jacobian        λy −1 1 0 0 0 . . . 0 λc −1 0 λy −1 2 0 0 . . . 0 λc −1 0 0 λy −1 3 0 . . . 0 λc −1 . . . −λy −1 n −λy −1 n −λy −1 n −λy −1 n . . . −λy −1 n λc −1       </formula><p>by adding y i /y n times each of the top n−1 rows to the bottom row we see that this Jacobian has the same determinant as</p><formula xml:id="formula_31">       λy −1 1 0 0 0 . . . 0 λc −1 0 λy −1 2 0 0 . . . 0 λc −1 0 0 λy −1 3 0 . . . 0 λc −1 . . . 0 0 0 0 . . . 0 λ(cy n ) −1       </formula><p>and thus the determinant is equal to </p><formula xml:id="formula_32">α i exp(−λ log y i − λr)) = letting γ = log( n n=1 α k y −λ k ) λ n n k=1 α k n i=1 y λ+1 i exp(γ) exp(−nλr + γ) exp(− exp(−λr + γ)) = integrating out r λ n n k=1 α k n i=1 y λ+1 i exp(γ) exp(−γn + γ)Γ(n) λ = λ n−1 n k=1 α k n i=1 y λ+1 i (exp(−γn)Γ(n)) = (n − 1)!λ n−1 n k=1 α k y −λ−1 k ( n n=1 α k y −λ k ) n Thus Y d = X.</formula><p>2. Follows directly from (a) and the Gumbel-Max trick <ref type="bibr" target="#b25">(Maddison, 2016)</ref>.</p><p>3. Follows directly from (a) and the Gumbel-Max trick <ref type="bibr" target="#b25">(Maddison, 2016)</ref>. 4. Let λ ≤ (n − 1) −1 . The density of X can be rewritten as</p><formula xml:id="formula_33">p α,λ (x) ∝ n k=1 α k y −λ−1 n i=1 α i y −λ i = n k=1 α k y λ(n−1)−1 k n i=1 α i j =i y λ j</formula><p>Thus, the log density is up to an additive constant C</p><formula xml:id="formula_34">log p α,λ (x) = n k=1 (λ(n − 1) − 1) log y k − n log   n k=1 α k j =k y λ j   + C If λ ≤ (n − 1) −1 ,</formula><p>then the first n terms are convex, because − log is convex. For the last term, − log is convex and non-increasing and j =k y λ j is concave for λ ≤ (n − 1) −1 . Thus, their composition is convex. The sum of convex terms is convex, finishing the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B THE BINARY SPECIAL CASE</head><p>Bernoulli random variables are an important special case of discrete distributions taking states in {0, 1}. Here we consider the binary special case of the Gumbel-Max trick from Figure <ref type="figure" target="#fig_0">1a</ref> along with the corresponding Concrete relaxation.</p><p>Let D ∼ Discrete(α) for α ∈ (0, ∞) 2 be a two state discrete random variable on {0, 1} 2 such that D 1 + D 2 = 1, parameterized as in Figure <ref type="figure" target="#fig_0">1a</ref> by α 1 , α 2 &gt; 0:</p><formula xml:id="formula_35">P(D 1 = 1) = α 1 α 1 + α 2 (14)</formula><p>The distribution is degenerate, because D 1 = 1 − D 2 . Therefore we consider just D 1 . Under the Gumbel-Max reparameterization, the event that D 1 = 1 is the event that</p><formula xml:id="formula_36">{G 1 + log α 1 &gt; G 2 + log α 2 } where G k ∼ Gumbel i.i.d. The difference of two Gumbels is a Logistic distribution G 1 − G 2 ∼ Logistic, which can be sampled in the following way, G 1 − G 2 d = log U − log(1 − U )</formula><p>where U ∼ Uniform(0, 1). So, if α = α 1 /α 2 , then we have</p><formula xml:id="formula_37">P(D 1 = 1) = P(G 1 + log α 1 &gt; G 2 + log α 2 ) = P(log U − log(1 − U ) + log α &gt; 0) (15) Thus, D 1 d = H(log α + log U − log(1 − U ))</formula><p>, where H is the unit step function.</p><p>Correspondingly, we can consider the Binary Concrete relaxation that results from this process.</p><p>As in the n-ary case, we consider the sampling routine for a Binary Concrete random variable X ∈ (0, 1) first. To sample X, sample L ∼ Logistic and set</p><formula xml:id="formula_38">X = 1 1 + exp(−(log α + L)/λ)<label>(16)</label></formula><p>We define the Binary Concrete random variable X by its density on the unit interval. Definition 2 (Binary Concrete Random Variables). Let α ∈ (0, ∞) and λ ∈ (0, ∞). X ∈ (0, 1) has a Binary Concrete distribution X ∼ BinConcrete(α, λ) with location α and temperature λ, if its density is:</p><formula xml:id="formula_39">p α,λ (x) = λαx −λ−1 (1 − x) −λ−1 (αx −λ + (1 − x) −λ ) 2 . (<label>17</label></formula><formula xml:id="formula_40">)</formula><p>We state without proof the special case of Proposition 1 for Binary Concrete distributions Proposition 2 (Some Properties of Binary Concrete Random Variables). Let X ∼ BinConcrete(α, λ) with location parameter α ∈ (0, ∞) and temperature λ ∈ (0, ∞), then</p><formula xml:id="formula_41">(a) (Reparameterization) If L ∼ Logistic, then X d = 1 1+exp(−(log α+L)/λ) , (b) (Rounding) P (X &gt; 0.5) = α/(1 + α), (c) (Zero temperature) P (lim λ→0 X = 1) = α/(1 + α), (d) (Convex eventually) If λ ≤ 1, then p α,λ (x) is log-convex in x.</formula><p>We can generalize the binary circuit beyond Logistic random variables. Consider an arbitrary random variable X with infinite support on R. If Φ : R → [0, 1] is the CDF of X, then</p><formula xml:id="formula_42">P(H(X) = 1) = 1 − Φ(0)</formula><p>If we want this to have a Bernoulli distribution with probability α/(1 + α), then we should solve the equation</p><formula xml:id="formula_43">1 − Φ(0) = α 1 + α .</formula><p>This gives Φ(0) = 1/(1 + α), which can be accomplished by relocating the random variable Y with CDF Φ to be X = Y − Φ −1 (1/(1 + α)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C USING CONCRETE RELAXATIONS</head><p>In this section we include some tips for implementing and using the Concrete distribution as a relaxation. We use the following notation</p><formula xml:id="formula_44">σ(x) = 1 1 + exp(−x) n LΣE k=1 {x k } = log n k=1 exp(x k )</formula><p>Both sigmoid and log-sum-exp are common operations in libraries like TensorFlow or theano.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 THE BASIC PROBLEM</head><p>For the sake of exposition, we consider a simple variational autoencoder with a single discrete random variable and objective L 1 (θ, a, α) given by Eq. 8 for a single data point x. This scenario will allow us to discuss all of the decisions one might make when using Concrete relaxations.</p><p>In particular, let P a (d) be the mass function of some n-dimensional one-hot discrete D ∼ Discrete(a) with a ∈ (0, ∞) n , let p θ (x|d) be some likelihood (possibly computed by a neural network), which is a continuous function of d and parameters θ, let D ∼ Discrete(α(x)) be a onehot discrete random variable in (0, 1) n whose unnormalized probabilities α(x) ∈ (0, ∞) n are some function (possible a neural net with its own parameters) of x. Let Q α (d|x) be the mass function of D. Then, we care about optimizing</p><formula xml:id="formula_45">L 1 (θ, a, α) = E D∼Qα(d|x) log p θ (x|D)P a (D) Q α (D|x)<label>(18)</label></formula><p>with respect to θ, a, and any parameters in α from samples of the SCG required to simulate an estimator of L 1 (θ, a, α).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 WHAT YOU MIGHT RELAX AND WHY</head><p>The first consideration when relaxing an estimator of Eq. 18 is how to relax the stochastic computation. The only sampling required to simulate L 1 (θ, a, α) is D ∼ Discrete(α(x)). The corresponding Concrete relaxation is to sample Z ∼ Concrete(α(x), λ 1 ) with temperature λ 1 and location parameters are the the unnormalized probabilities α(x) of D. Let density q α,λ1 (z|x) be the density of Z. We get a relaxed objective of the form:</p><formula xml:id="formula_46">E D∼Qα(d|x) [ • ] → E Z∼q α,λ 1 (z|x) [ • ]<label>(19)</label></formula><p>This choice allows us to take derivatives through the stochastic computaitons of the graph.</p><p>The second consideration is which objective to put in place of [ • ] in Eq. 19. We will consider the ideal scenario irrespective of numerical issues. In Subsection C.3 we address those numerical issues. The central question is how to treat the expectation of the ratio P a (D)/Q α (D|x) (which is the KL component of the loss) when Z replaces D.</p><p>There are at least three options for how to modify the objective. They are, (20) replace the discrete mass with Concrete densities, (21) relax the computation of the discrete log mass, (22) replace it with the analytic discrete KL.</p><formula xml:id="formula_47">E Z∼q α,λ 1 (z|x) log p θ (x|Z) + log p a,λ2 (Z) q α,λ1 (Z|x) (20) E Z∼q α,λ 1 (z|x) log p θ (x|Z) + n i=1 Z i log P a (d (i) ) Q α (d (i) |x) (21) E Z∼q α,λ 1 (z|x) [log p θ (x|Z)] + n i=1 Q α (d (i) |x) log P a (d (i) ) Q α (d (i) |x)<label>(22)</label></formula><p>where d (i) is a one-hot binary vector with d (i) i</p><p>= 1 and p a,λ2 (z) is the density of some Concrete random variable with temperature λ 2 with location parameters a. Although ( <ref type="formula" target="#formula_47">22</ref>) or ( <ref type="formula">21</ref>) is tempting, we emphasize that these are NOT necessarily lower bounds on log p(x) in the relaxed model. ( <ref type="formula">20</ref>) is the only objective guaranteed to be a lower bound:</p><formula xml:id="formula_48">E Z∼q α,λ 1 (z|x) log p θ (x|Z) + log p a,λ2 (Z) q α,λ1 (Z|x) ≤ log p θ (x|z)p a,λ2 (z) dx.<label>(23)</label></formula><p>For this reason we consider objectives of the form (20). Choosing ( <ref type="formula" target="#formula_47">22</ref>) or ( <ref type="formula">21</ref>) is possible, but the value of these objectives is not interpretable and one should early stop otherwise it will overfit to the spurious "KL" component of the loss. We now consider practical issues with (20) and how to address them. All together we can interpret q α,λ1 (z|x) as the Concrete relaxation of the variational posterior and p a,λ2 (z) the relaxation of the prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 WHICH RANDOM VARIABLE TO TREAT AS THE STOCHASTIC NODE</head><p>When implementing a SCG like the variational autoencoder example, we need to compute logprobabilities of Concrete random variables. This computation can suffer from underflow, so where possible it's better to take a different node on the relaxed graph as the stochastic node on which loglikelihood terms are computed. For example, it's tempting in the case of Concrete random variables to treat the Gumbels as the stochastic node on which the log-likelihood terms are evaluated and the softmax as downstream computation. This will be a looser bound in the context of variational inference than the corresponding bound when treating the Concrete relaxed states as the node.</p><p>The solution we found to work well was to work with Concrete random variables in log-space.</p><p>Consider the following vector in R n for location parameters α ∈ (0, ∞) n and λ ∈ (0, ∞) and</p><formula xml:id="formula_49">G k ∼ Gumbel, Y k = log α k + G k λ − n LΣE i=1 log α i + G i λ</formula><p>Y ∈ R n has the property that exp(Y ) ∼ Concrete(α, λ), therefore we call Y an ExpConcrete(α, λ). The advantage of this reparameterization is that the KL terms of a variational loss are invariant under invertible transformation. exp is invertible, so the KL between two ExpConcrete random variables is the same as the KL between two Concrete random variables. The log-density log κ α,λ (y) of an ExpConcrete(α, λ) is also simple to compute:</p><formula xml:id="formula_50">log κ α,λ (y) = log((n − 1)!) + (n − 1) log λ + n k=1 log α k − λy k − n n LΣE k=1 {log α k − λy k } for y ∈ R n such that LΣE n k=1 {y k } = 0.</formula><p>Note that the sample space of the ExpConcrete distribution is still interpretable in the zero temperature limit. In the limit of λ → 0 ExpConcrete random variables become discrete random variables over the one-hot vectors of d ∈ {−∞, 0} n where LΣE n k=1 {d k } = 0. exp(Y ) in this case results in the one-hot vectors in {0, 1} n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3.1 n-ARY CONCRETE</head><p>Returning to our initial task of relaxing L 1 (θ, a, α), let Y ∼ ExpConcrete(α(x), λ 1 ) with density κ α,λ1 (y|x) be the ExpConcrete latent variable corresponding to the Concrete relaxation q α,λ1 (z|x) of the variational posterior Q α (d|x). Let ρ a,λ1 (y) be the density of an ExpConcrete random variable corresponding to the Concrete relaxation p a,λ2 (z) of P a (d). All together we can see that</p><formula xml:id="formula_51">E Z∼q α,λ 1 (z|x) log p θ (x|Z) + log p a,λ2 (Z) q α,λ1 (Z|x) = E Y ∼κ α,λ 1 (y|x) log p θ (x| exp(Y )) + log ρ a,λ2 (Y ) κ α,λ1 (Y |x)<label>(24)</label></formula><p>Therefore, we used ExpConcrete random variables as the stochastic nodes and treated exp as a downstream computation. The relaxation is then,</p><formula xml:id="formula_52">L 1 (θ, a, α) relax E Y ∼κ α,λ 1 (y|x) log p θ (x| exp(Y )) + log ρ a,λ2 (Y ) κ α,λ1 (Y |x) ,<label>(25)</label></formula><p>and the objective on the RHS is fully reparameterizable and what we chose to optimize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3.2 BINARY CONCRETE</head><p>In the binary case, the logistic function is invertible, so it makes most sense to treat the logit plus noise as the stochastic node. In particular, the binary random node was sample from:</p><formula xml:id="formula_53">Y = log α + log U − log(1 − U ) λ<label>(26)</label></formula><p>where U ∼ Uniform(0, 1) and always followed by σ as downstream computation. log U − log(1 − U ) is a Logistic random variable, details in the cheat sheet, and so the log-density log g α,λ (y) of this node (before applying σ) is log g α,λ (y) = log λ − λy + log α − 2 log(1 + exp(−λy + log α))</p><p>All together the relaxation in the binary special case would be</p><formula xml:id="formula_54">L 1 (θ, a, α) relax E Y ∼g α,λ 1 (y|x) log p θ (x|σ(Y )) + log f a,λ2 (Y ) g α,λ1 (Y |x) ,<label>(27)</label></formula><p>where f a,λ2 (y) is the density of a Logistic random variable sampled via Eq. 26 with location a and temperature λ 2 .</p><p>This section had a dense array of densities, so we summarize the relevant ones, along with how to sample from them, in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 CHOOSING THE TEMPERATURE</head><p>The success of Concrete relaxations will depend heavily on the choice of temperature during training. It is important that the relaxed nodes are not able to represent a precise real valued mode in the interior of the simplex as in Figure <ref type="figure">2d</ref>. For example, choosing additive Gaussian noise ∼ Normal(0, 1) with the logistic function σ(x) to get relaxed Bernoullis of the form σ( + µ) will result in a large mode in the centre of the interval. This is because the tails of the Gaussian distribution drop off much faster than the rate at which σ squashes. Even including a temperature parameter does not completely solve this problem; the density of σ(( + µ)/λ) at any temperature still goes to 0 as its approaches the boundaries 0 and 1 of the unit interval. Therefore (d) of Proposition 1 is a conservative guideline for generic n-ary Concrete relaxations; at temperatures lower than (n − 1) −1 we are guaranteed not to have any modes in the interior for any α ∈ (0, ∞) n . In the case of the Binary Concrete distribution, the tails of the Logistic additive noise are balanced with the logistic squashing function and for temperatures λ ≤ 1 the density of the Binary Concrete distribution is log-convex for all parameters α, see Figure <ref type="figure" target="#fig_1">3b</ref>. Still, practice will often disagree with theory here. The peakiness of the Concrete distribution increases with n, so much higher temperatures are tolerated (usually necessary).</p><p>For n = 1 temperatures λ ≤ (n − 1) −1 is a good guideline. For n &gt; 1 taking λ ≤ (n − 1) −1 is not necessarily a good guideline, although it will depend on n and the specific application. As n → ∞ the Concrete distribution becomes peakier, because the random normalizing constant n k=1 exp((log α k + G k )/λ) grows. This means that practically speaking the optimization can tolerate much higher temperatures than (n − 1) −1 . We found in the cases n = 4 that λ = 1 was the best temperature and in n = 8, λ = 2/3 was the best. Yet λ = 2/3 was the best single performing temperature across the n ∈ {2, 4, 8} cases that we considered. We recommend starting in that ball-park and exploring for any specific application.</p><p>When the loss depends on a KL divergence between two Concrete nodes, it's possible to give the nodes distinct temperatures. We found this to improve results quite dramatically. In the context of our original problem and it's relaxation:</p><formula xml:id="formula_55">L 1 (θ, a, α) relax E Y ∼κ α,λ 1 (y|x) log p θ (x| exp(Y )) + log ρ a,λ2 (Y ) κ α,λ1 (Y |x) ,<label>(28)</label></formula><p>Both λ 1 for the posterior temperature and λ 2 for the prior temperature are tunable hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EXPERIMENTAL DETAILS</head><p>The basic model architectures we considered are exactly analogous to those in <ref type="bibr" target="#b4">Burda et al. (2016)</ref> with Concrete/discrete random variables replacing Gaussians.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 -VS ∼</head><p>The conditioning functions we used were either linear or non-linear. Non-linear consisted of two tanh layers of the same size as the preceding stochastic layer in the computation graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 n-ARY LAYERS</head><p>All our models are neural networks with layers of n-ary discrete stochastic nodes with log 2 (n)dimensional states on the corners of the hypercube {−1, 1} log 2 (n) . For a generic n-ary node sampling proceeds as follows. Sample a n-ary discrete random variable D ∼ Discrete(α) for α ∈ (0, ∞) n . If C is the log 2 (n) × n matrix, which lists the corners of the hypercube {−1, 1} log 2 (n) as columns, then we took Y = CD as downstream computation on D. The corresponding Concrete relaxation is to take X ∼ Concrete(α, λ) for some fixed temperature λ ∈ (0, ∞) and set Ỹ = CX. For the binary case, this amounts to simply sampling U ∼ Uniform(0, 1) and taking Y = 2H(log U − log(1 − U ) + log α) − 1. The corresponding Binary Concrete relaxation is Ỹ = 2σ((log U − log(1 − U ) + log α)/λ) − 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 BIAS INITIALIZATION</head><p>All biases were initialized to 0 with the exception of the biases in the prior decoder distribution over the 784 or 392 observed units. These were initialized to the logit of the base rate averaged over the respective dataset (MNIST or Omniglot).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 CENTERING</head><p>We also found it beneficial to center the layers of the inference network during training. The activity in (−1, 1) d of each stochastic layer was centered during training by maintaining a exponentially decaying average with rate 0.9 over minibatches. This running average was subtracted from the activity of the layer before it was updated. Gradients did not flow throw this computation, so it simply amounted to a dynamic offset. The averages were not updated during the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 HYPERPARAMETER SELECTION</head><p>All models were initialized with the heuristic of <ref type="bibr" target="#b8">Glorot &amp; Bengio (2010)</ref> and optimized using Adam <ref type="bibr" target="#b21">(Kingma &amp; Ba, 2014)</ref> with parameters β 1 = 0.9, β 2 = 0.999 for 10 7 steps on minibatches of size 64. Hyperparameters were selected on the MNIST dataset by grid search taking the values that performed best on the validation set. Learning rates were chosen from {10 −4 , 3 • 10 −4 , 10 −3 } and weight decay from {0, 10 −2 , 10 −1 , 1}. Two sets of hyperparameters were selected, one for linear models and one for non-linear models. The linear models' hyperparameters were selected with the 200H-200H-784V density model on the L 5 (θ, φ) objective. The non-linear models' hyperparameters were selected with the 200H∼200H∼784V density model on the L 5 (θ, φ) objective. For density estimation, the Concrete relaxation hyperparameters were (weight decay = 0, learning rate = 3 • 10 −4 ) for linear and (weight decay = 0, learning rate = 10 −4 ) for non-linear. For structured prediction Concrete relaxations used (weight decay = 10 −3 , learning rate = 3 • 10 −4 ).</p><p>In addition to tuning learning rate and weight decay, we tuned temperatures for the Concrete relaxations on the density estimation task. We found it valuable to have different values for the prior and posterior distributions, see Eq. 28. In particular, for binary we found that (prior λ 2 = 1/2, posterior λ 1 = 2/3) was best, for 4-ary we found (prior λ 2 = 2/3, posterior λ 1 = 1) was best, and (prior λ 2 = 2/5, posterior λ 1 = 2/3) for 8-ary. No temperature annealing was used. For structured prediction we used just the corresponding posterior λ 1 as the temperature for the whole graph, as there was no variational posterior.</p><p>We performed early stopping when training with the score function estimators (VIMCO/NVIL) as they were much more prone to overfitting. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visualization of sampling graphs for 3-ary discrete D ∼ Discrete(α) and 3-ary Concrete X ∼ Concrete(α, λ). White operations are deterministic, blue are stochastic, rounded are continuous, square discrete. The top node is an example state; brightness indicates a value in [0,1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A visualization of the binary special case. (a) shows the discrete trick, which works by passing a noisy logit through the unit step function. (b), (c), (d) show Concrete relaxations; the horizontal blue densities show the density of the input distribution and the vertical densities show the corresponding Binary Concrete density on (0, 1) for varying λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results for structured prediction on MNIST comparing Concrete relaxations to VIMCO. When m = 1 VIMCO stands for NVIL. The plot on the right shows the objective (lower is better) for the continuous and discrete graph trained at temperatures λ. In the shaded region, units prefer to communicate real values in the interior of (−1, 1) and the discretization suffers an integrality gap. learned during training. The best 4-ary model achieved test/train NLL of 88.7/85.0, the best 8-ary model achieved 89.1/85.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>α k exp(−λ log y k − λ log c) exp(−α k exp(−λ log y k − λ log c)) c n i=1 y i with r = log c change of variables we have density λ n n k=1 α k exp(−λr) exp(−α k exp(−λ log y k − λr))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>and the standard 50,000/10,000/10,000 split into Published as a conference paper at ICLR 2017 Density estimation with binary latent variables. When m = 1, VIMCO stands for NVIL.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">MNIST NLL</cell><cell></cell><cell></cell><cell cols="2">Omniglot NLL</cell><cell></cell></row><row><cell>binary</cell><cell></cell><cell>Test</cell><cell></cell><cell>Train</cell><cell></cell><cell>Test</cell><cell></cell><cell>Train</cell><cell></cell></row><row><cell>model</cell><cell cols="9">m Concrete VIMCO Concrete VIMCO Concrete VIMCO Concrete VIMCO</cell></row><row><cell>(200H -784V)</cell><cell>1 5 50</cell><cell>107.3 104.9 104.3</cell><cell>104.4 101.9 98.8</cell><cell>107.5 104.9 104.2</cell><cell>104.2 101.5 98.3</cell><cell>118.7 118.0 118.9</cell><cell>115.7 113.5 113.0</cell><cell>117.0 115.8 115.8</cell><cell>112.2 110.8 110.0</cell></row><row><cell>(200H</cell><cell>1</cell><cell>102.1</cell><cell>92.9</cell><cell>102.3</cell><cell>91.7</cell><cell>116.3</cell><cell>109.2</cell><cell>114.4</cell><cell>104.8</cell></row><row><cell>-200H</cell><cell>5</cell><cell>99.9</cell><cell>91.7</cell><cell>100.0</cell><cell>90.8</cell><cell>116.0</cell><cell>107.5</cell><cell>113.5</cell><cell>103.6</cell></row><row><cell>-784V)</cell><cell>50</cell><cell>99.5</cell><cell>90.7</cell><cell>99.4</cell><cell>89.7</cell><cell>117.0</cell><cell>108.1</cell><cell>113.9</cell><cell>103.6</cell></row><row><cell>(200H ∼784V)</cell><cell>1 5 50</cell><cell>92.1 89.5 88.5</cell><cell>93.8 91.4 89.3</cell><cell>91.2 88.1 86.4</cell><cell>91.5 88.6 86.5</cell><cell>108.4 107.5 108.1</cell><cell>116.4 118.2 116.0</cell><cell>103.6 101.4 100.5</cell><cell>110.3 102.3 100.8</cell></row><row><cell>(200H</cell><cell>1</cell><cell>87.9</cell><cell>88.4</cell><cell>86.5</cell><cell>85.8</cell><cell>105.9</cell><cell>111.7</cell><cell>100.2</cell><cell>105.7</cell></row><row><cell>∼200H</cell><cell>5</cell><cell>86.3</cell><cell>86.4</cell><cell>84.1</cell><cell>82.5</cell><cell>105.8</cell><cell>108.2</cell><cell>98.6</cell><cell>101.1</cell></row><row><cell>∼784V)</cell><cell>50</cell><cell>85.7</cell><cell>85.5</cell><cell>83.1</cell><cell>81.8</cell><cell>106.8</cell><cell>113.2</cell><cell>97.5</cell><cell>95.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Michalis Titsias and Miguel Lázaro-Gredilla. Local expectation gradients for black box variational inference. In NIPS, 2015. Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229-256, 1992. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, 2015. John I Yellott. The relationship between luce's choice axiom, thurstone's theory of comparative judgment, and the double exponential distribution. Journal of Mathematical Psychology, 15(2): 109-144, 1977.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Density estimation using Concrete relaxations with distinct arity of layers.</figDesc><table><row><cell>E EXTRA RESULTS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">MNIST NLL Omniglot NLL</cell></row><row><cell></cell><cell cols="3">m Test Train</cell><cell>Test</cell><cell>Train</cell></row><row><cell>binary</cell><cell>1</cell><cell>91.9</cell><cell>90.7</cell><cell>108.0</cell><cell>102.2</cell></row><row><cell>(240H</cell><cell>5</cell><cell>89.0</cell><cell>87.1</cell><cell>107.7</cell><cell>100.0</cell></row><row><cell>∼784V)</cell><cell cols="2">50 88.4</cell><cell>85.7</cell><cell>109.0</cell><cell>99.1</cell></row><row><cell>4-ary</cell><cell>1</cell><cell>91.4</cell><cell>89.7</cell><cell>110.7</cell><cell>1002.7</cell></row><row><cell>(240H</cell><cell>5</cell><cell>89.4</cell><cell>87.0</cell><cell>110.5</cell><cell>100.2</cell></row><row><cell>∼784V)</cell><cell cols="2">50 89.7</cell><cell>86.5</cell><cell>113.0</cell><cell>100.0</cell></row><row><cell>8-ary</cell><cell>1</cell><cell>92.5</cell><cell>89.9</cell><cell>119.61</cell><cell>105.3</cell></row><row><cell>(240H</cell><cell>5</cell><cell>90.5</cell><cell>87.0</cell><cell>120.7</cell><cell>102.7</cell></row><row><cell>∼784V)</cell><cell cols="2">50 90.5</cell><cell>86.7</cell><cell>121.7</cell><cell>101.0</cell></row><row><cell>binary</cell><cell>1</cell><cell>87.9</cell><cell>86.0</cell><cell>106.6</cell><cell>99.0</cell></row><row><cell>(240H∼240H</cell><cell>5</cell><cell>86.6</cell><cell>83.7</cell><cell>106.9</cell><cell>97.1</cell></row><row><cell>∼784V)</cell><cell cols="2">50 86.0</cell><cell>82.7</cell><cell>108.7</cell><cell>95.9</cell></row><row><cell>4-ary</cell><cell>1</cell><cell>87.4</cell><cell>85.0</cell><cell>106.6</cell><cell>97.8</cell></row><row><cell>(240H∼240H</cell><cell>5</cell><cell>86.7</cell><cell>83.3</cell><cell>108.3</cell><cell>97.3</cell></row><row><cell>∼784V)</cell><cell cols="2">50 86.7</cell><cell>83.0</cell><cell>109.4</cell><cell>96.8</cell></row><row><cell>8-ary</cell><cell>1</cell><cell>88.2</cell><cell>85.9</cell><cell>111.3</cell><cell>102.5</cell></row><row><cell>(240H∼240H</cell><cell>5</cell><cell>87.4</cell><cell>84.6</cell><cell>110.5</cell><cell>100.5</cell></row><row><cell>∼784V)</cell><cell cols="2">50 87.2</cell><cell>84.0</cell><cell>111.1</cell><cell>99.5</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">For our purposes a stochastic node of a computation graph is just a random variable whose distribution depends in some deterministic way on the values of the parent nodes.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Jimmy Ba for the excitement and ideas in the early days, Stefano Favarro for some analysis of the distribution. We also thank Gabriel Barth-Maron and Roger Grosse.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distribution and Domains Reparameterization/How To Sample</head><p>Mass/Density</p><p>Table <ref type="table">3</ref>: Cheat sheet for the random variables we use in this work. Note that some of these are atypical parameterizations, particularly the Bernoulli and Logistic random variables. The table only assumes that you can sample uniform random numbers U ∼ Uniform(0, 1). From there on it may define random variables and reuse them later on. For example, L ∼ Logistic is defined in the second row, and after that point L represents a Logistic random variable that can be replaced by log U − log(1 − U ). Whenever random variables are indexed, e.g. G k , they represent separate independent calls to a random number generator.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals</title>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="http://tensorflow.org/.Softwareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu,</pubPlace>
		</imprint>
	</monogr>
	<note>TensorFlow: Large-scale machine learning on heterogeneous systems</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A general class of distributions on the simplex</title>
		<author>
			<persName><surname>Aitchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B</title>
		<imprint>
			<biblScope unit="page" from="136" to="146" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Logistic-normal distributions: Some properties and uses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Atchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><forename type="middle">M</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Léonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<editor>David Blei and John Lafferty</editor>
		<imprint>
			<date type="published" when="2006">2013. 2006</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Correlated topic models</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<title level="m">Importance weighted autoencoders. ICLR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Concepts of independence for proportions with a generalization of the dirichlet distribution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><surname>Mosimann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">325</biblScope>
			<biblScope unit="page" from="194" to="206" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On a class of distributions on the simplex</title>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgia</forename><surname>Hadjicharalambous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Prünster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2987" to="3004" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Continuous sigmoidal belief networks trained using slice sampling</title>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS, 1997. Michael C Fu. Gradient estimation. Handbooks in operations research and management science</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="575" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Aistats</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Likelihood ratio gradient estimation for stochastic systems</title>
		<author>
			<persName><forename type="first">Glynn</forename><surname>Peter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malcolm</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agnieszka</forename><surname>Grabska-Barwińska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><forename type="middle">Gómez</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Agapiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="issue">7626</biblScope>
			<biblScope unit="page" from="471" to="476" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Variance reduction techniques for gradient estimates in reinforcement learning</title>
		<author>
			<persName><forename type="first">Evan</forename><surname>Greensmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to transduce with unbounded memory</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1828" to="1836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.8499</idno>
		<title level="m">Deep autoregressive networks</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Draw: A recurrent neural network for image generation</title>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.04623</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">MuProp: Unbiased backpropagation for stochastic neural networks</title>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Statistical theory of extreme values and some practical applications: a series of lectures</title>
		<author>
			<persName><forename type="first">Emil</forename><surname>Julius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gumbel</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Number</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the partition function and random maximum a-posteriori perturbations</title>
		<author>
			<persName><forename type="first">Tamir</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Perturbation, Optimization, and Statistics</title>
		<author>
			<persName><forename type="first">Tamir</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stochastic variational inference</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Matthew D Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">William</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1303" to="1347" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-11">November 2016</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Auto-encoding variational bayes. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semantic parsing with semi-supervised sequential autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling ; Tomáš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><surname>Hermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2014">2014. 2016</date>
		</imprint>
	</monogr>
	<note>Auto-encoding variational bayes. ICLR</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Individual Choice Behavior: A Theoretical Analysis</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Luce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959">1959</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Poisson process model for Monte Carlo</title>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Perturbation, Optimization, and Statistics, chapter 7</title>
				<editor>
			<persName><forename type="first">Tamir</forename><surname>Hazan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks</title>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Variational inference for monte carlo objectives</title>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Alex Graves, and koray kavukcuoglu. Recurrent Models of Visual Attention</title>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">Jr</forename><surname>Christian A Naesseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">W</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05683</idno>
		<title level="m">Rejection sampling variational inference</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Variational bayesian inference with stochastic search</title>
		<author>
			<persName><forename type="first">John</forename><surname>William Paisley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Perturb-and-map random fields: Using discrete optimization to learn and sample from energy models</title>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2989</idno>
		<title level="m">Techniques for learning binary stochastic feedforward neural networks</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Black box variational inference</title>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">S</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cidambi</forename><surname>Rayens</surname></persName>
		</author>
		<author>
			<persName><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="1994">1994. 2014</date>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="1465" to="1470" />
		</imprint>
	</monogr>
	<note>Dependence properties of generalized liouville distributions on the simplex</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Michalis</forename><forename type="middle">K</forename><surname>Francisco Jr Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02287</idno>
		<title level="m">The generalized reparameterization gradient</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic hashing</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="969" to="978" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of deep belief networks</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gradient estimation using stochastic computation graphs</title>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theophane</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<author>
			<persName><forename type="first">Theano</forename><surname>Development</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Team</forename></persName>
		</author>
		<idno>prints, abs/1605.02688</idno>
		<ptr target="http://arxiv.org/abs/1605.02688" />
		<imprint>
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Doubly stochastic variational bayes for non-conjugate inference</title>
		<author>
			<persName><forename type="first">Michalis</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Lázaro-Gredilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<editor>
			<persName><forename type="first">Tony</forename><surname>Jebara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
