<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fully Hyperbolic Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-09-17">17 Sep 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Keegan</forename><surname>Lensink</surname></persName>
							<email>klensink@eoas.ubc.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of British Columbia</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Xtract AI</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eldad</forename><surname>Haber</surname></persName>
							<email>ehaber@eoas.ubc.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of British Columbia</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Xtract AI</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bas</forename><surname>Peters</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Computational Geosciences Inc</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fully Hyperbolic Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-17">17 Sep 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1905.10484v2[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional Neural Networks (CNN) have recently seen tremendous success in various computer vision tasks. However, their application to problems with high dimensional input and output, such as high-resolution image and video segmentation or 3D medical imaging, has been limited by various factors. Primarily, in the training stage, it is necessary to store network activations for back propagation. In these settings, the memory requirements associated with storing activations can exceed what is feasible with current hardware, especially for problems in 3D. Previously proposed reversible architectures allow one to recalculate activations in the backwards pass instead of storing them. For computer visions tasks, only block reversible networks have been possible because pooling operations are not reversible. Block-reversibility still requires storing a number of activations that grows with the number of blocks. Motivated by the propagation of signals over physical networks, that are governed by the hyperbolic Telegraph equation, in this work we introduce a fully conservative hyperbolic network for problems with high dimensional input and output. We introduce a coarsening operation that allows completely reversible CNNs by using the Discrete Wavelet Transform and its inverse to both coarsen and interpolate the network state and change the number of channels. This means that during training we do not need to store any of the activations from the forward pass, and can train arbitrarily deep networks. We show that fully reversible networks are able to achieve results comparable to the state of the art in image depth estimation and full 3D video segmentation, with a much lower memory footprint that is a constant independent of the network depth.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep Convolutional Neural Networks have recently solved some very challenging problems in computer vision ranging from image classification, segmentation, deblurring, shape from shading, and more <ref type="bibr" target="#b7">(Krizhevsky, Sutskever, and Hinton 2012;</ref><ref type="bibr" target="#b13">Ronneberger, Fischer, and Brox 2015;</ref><ref type="bibr" target="#b14">Tao et al. 2018;</ref><ref type="bibr" target="#b1">Bengio 2009;</ref><ref type="bibr" target="#b8">LeCun, Bengio, and Hinton 2015;</ref><ref type="bibr" target="#b4">Goodfellow, Bengio, and Courville 2016;</ref><ref type="bibr" target="#b4">Hammernik et al. 2017;</ref><ref type="bibr" target="#b0">Avendi, Kheradvar, and Jafarkhani 2016)</ref>.</p><p>The recent success of neural networks has been attributed to three main factors. First, the massive amount of data that is being collected allows the training of complex models with hundreds of millions of parameters. Second, stochastic gradient descent has worked surprisingly well for such problems despite their non-convexity. Lastly, the ability to accelerate training through the use of graphical processing units (GPU's) has made training complex models on the previously mentioned massive amounts of data feasible. Specifically related to the latter points, new and better neural networks architectures such as ResNet <ref type="bibr" target="#b5">(He et al. 2016</ref>) and the UNet <ref type="bibr" target="#b13">(Ronneberger, Fischer, and Brox 2015)</ref> have been proposed that increase the networks stability, permitting the effective utilization of computational resources, obtaining a less nonlinear problem, and reducing training costs.</p><p>While such advances have been key to recent progress, we continue to face a number of challenges that current algorithms have yet to solve. As we push the scale at which deep learning is applied, computational time and memory requirements are quickly exceeding what is possible with current hardware. Memory is especially an issue with deep networks or when the size of the input and output are large. Examples include semantic segmentation and image deblurring or cases where 3D convolutions are required such as medical imaging, seismic applications, and video processing. In these cases, memory constraints are a limiting factor when dealing with large scale problems in reasonable computational time and resources. In the training phase, all previous states of the network, i.e. its activations, must be stored in order to compute the gradient. In the inference stage it is common for successful architectures to store various previous states <ref type="bibr" target="#b13">(Ronneberger, Fischer, and Brox 2015)</ref> or multiple scales <ref type="bibr" target="#b15">(Zhao et al. 2017)</ref>, again requiring the network to store activations. For these problems, the memory requirements are quickly over-reaching our ability to store the activations of the network.</p><p>Beyond just the obvious implications of working with large scale data, such as videos, network depth and width are a significant factor in the memory footprint of a network. For fixed width networks, the depth of the network allows us to obtain more nonlinear models and obtain more expressive networks <ref type="bibr" target="#b5">(Hanin 2017)</ref>. Moreover, for problems in vision, networks depth plays another important role, since convolution is a local operation information propagates a fixed distance each layer. This implies that the output is determined with information available from a limited patch of the input, the size of which is determined by the number of layers and the width of the convolution kernel. The size of this patch is know as the receptive field <ref type="bibr">(Luo et al. 2016)</ref>. By coarsening the image, the receptive field of the network grows and allows learning non-local relations. However, coarsening the image comes with the price of reducing the resolution of the final output. For problems such as classification this is not an issue as we desire a reduction in dimensionality, however for problems with high dimensional output, e.g. semantic segmentation, high resolution output is required. In these cases, the image is still coarsened to achieve the desired receptive field, however interpolation is used to regain resolution. A consequence of this is that fine image details or high frequency content is typically missing since the coarsening and subsequent interpolation is not conservative. This is the reason skip connections need to be used in the U-Net architecture <ref type="bibr" target="#b13">(Ronneberger, Fischer, and Brox 2015)</ref>.</p><p>Width allows the network to learn more features, increasing the capability of the network to learn. However, the width comes at considerable price in terms of memory and computational effort. While it is clear that while network depth and width are a significant factor in the memory footprint, they are critical to the networks success.</p><p>In this work we introduce a new network architecture that addresses all the above difficulties. The network is fully conservative and reversible. Unlike any reversible network known to us, our network communicates in a reversible way between scales, and therefore does not require U-net like skip connections. Our formulation is motivated by the propagation of signals over physical networks. In physical networks, such as biological nets, signals can propagate in both directions. Indeed, a continuous formulation of a network involves the Telegraph equation (see <ref type="bibr" target="#b15">(Zhou and Luo 2018)</ref> and references within) which, upon discretization leads to a different formulation than the canonical ResNet. Similar to signal propagation in physical networks, our propagation is fully conservative. Conservation implies that, although our network has some similarities to the structure of a ResNet, when we coarsen the image we do not lose information and we can exactly recover any previous state of the network. This means that in the training phase we do not need to store all of the activations, and the memory footprint is independent of the network's depth. Additionally, in the inference phase we do not need to store previous states of the network since our network does not loose information. Furthermore, for high resolution images and video we facilitate networks with complete receptive fields by removing the memory limitations related to deep networks. the global signature of our network allows us to connect all pixels in the image, thus the network has the full image as its field of view. This allows us to learn local as well as global features, in contrast to other reversible architectures.</p><p>The rest of the paper is structured as follows. In Section 3 we review background material on ResNets, reversible ResNets, and wavelets. We discuss how one can combine low resolution channels in order to obtain a single high resolution image and introduce our new network architecture. In Section 4 we experiment with our network on a number of problems and show its efficiency and finally, in Section 5 we summarize the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Contributions and prior work</head><p>Various researchers developed neural networks based on partial differential equations (PDEs) to gain insight and control of the stability with an increasing number of layers, in order to avoid exploding and vanishing gradients. By basing the networks on certain PDEs, one can achieve reversibility, such that not all network states need to be stored to be able to compute a gradient. Published networks in <ref type="bibr" target="#b3">(Chang et al. 2018;</ref><ref type="bibr" target="#b3">Gomez et al. 2017</ref>) are block-reversible, meaning that the network is reversible only in between pooling operations that change resolution and the number of channels. This means that block reversible networks still require storing the network state before coarsening/refining layers. We propose a fully reversible network where the coarsening/refining operations are also reversible/invertible. The required storage to compute gradients becomes independent of the network depth, as well as the number of coarsening/refining operations. This allows us to work with arbitrarily large images as there are no memory limitations preventing the use of a network that achieves a complete receptive field, as opposed to a block reversible network where memory limitations restrict the possible number of coarsening/refining layers as demonstrated in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>We propose to use the discrete wavelet transform as an invertible pooling operator to coarsen the image and increase the number of channels, as well as the reverse operation. In this work we show experiments with the Haar transform, however we show that in theory this is possible with any wavelet and that it is even possible to learn an invertible operator. While the wavelet transform has been used before in neural networks as a fixed operator <ref type="bibr" target="#b9">(Liu et al. 2018a;</ref><ref type="bibr" target="#b3">Fujieda, Takayama, and Hachisuka 2017)</ref>, their use to achieve full reversibility is new. Simple invertible pooling operations have previously been proposed (Dinh, Sohl-Dickstein, and Bengio 2016), however their motivation is not based on PDEs so they do not provide the same insights on network stability and they were not proposed in the context of reducing the memory footprint.</p><p>Experimentally, we show that the proposed reversible network, with fixed Haar transform coarsening/refinement and channel count changes, performs well on large 3D video segmentation and 2D single image depth estimation. Because the required memory for computing gradients does not increase with network depth, we can train the network from video to video without cutting the video into shorter clips. This approach leads to a relatively simple algorithm and can take long temporal structure into account. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the additional benefits we obtain by combining PDE-based reversible networks with wavelet-based reversible pooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Building Blocks of the Fully Hyperbolic Network</head><p>We start by reviewing the architecture of a canonical ResNet as presented in <ref type="bibr" target="#b5">(He et al. 2016)</ref>. A ResNet is a particular architecture of a neural network. Let Y 0 represent the data or initial state, which we view as a matrix where each column (vector) in the matrix is a particular example. Let us focus on one example. For problems in imaging we can reorganize the example as a tensor which represents a vector image with n c channels and a resolution of n x × n y . The initial state Y 0 is transformed by the network using the following expression</p><formula xml:id="formula_0">Y j+1 = W j Y j + f (Y j , θ j ) (3.1)</formula><p>Here, Y j is the state at layer j and θ j are network parameters, e.g. convolution kernels, normalization parameters, and biases, and finally f is a nonlinear function. The matrix W j is the identity matrix if the number of channels in Y j+1 is equal to the number of channels in Y j and is chosen as zero otherwise. In this work we particularly use convolutional neural networks with θ j = {K j , b j }, where K j are convolution kernels and b j are biases (for batch norm we do not use bias but use batch norm parameters). We choose a symmetric nonlinear function that can be expressed as</p><formula xml:id="formula_1">f (Y j , θ j ) = −K j f (K j Y j + b j ),</formula><p>which has been shown to have favorable theoretical and experimental properties (Ruthotto and Haber 2018). For many, if not most, applications the number of channels grows with depth, while at the same time the state becomes coarser. Since this is typically done using non-invertible coarsening or pooling the network loses information. Consider average pooling, which corresponds to linear interpolation and has been proven to work well on a number of applications. Despite its success, average pooling is not reversible, meaning that given the state Y j we can compute Y j+1 , however if we are given Y j+1 it is not trivial to compute Y j .</p><p>A reversible network has a few advantages. One of the most important being that it does not require the storage of the activations when computing the gradients, allowing for arbitrary long networks independent of memory <ref type="bibr" target="#b3">(Chang et al. 2018;</ref><ref type="bibr" target="#b3">Gomez et al. 2017)</ref>. In order to obtain a reversible network it was proposed in <ref type="bibr" target="#b3">(Chang et al. 2018)</ref> to use a hyperbolic network with the form</p><formula xml:id="formula_2">Y j+1 = 2W j Y j − W j−1 Y j−1 + f (W j Y j , θ j ) (3.2)</formula><p>Here, again, we use W j−1 and W j when the resolution is changed and the number of channels are increased and set W j−1 = W j = I when the resolution does not change. The network is clearly reversible since, as long as the number of channels are not changed and W = I, given Y j+1 and Y j it is straight forward to compute Y j−1 . Reversibility allows for the computation of the gradient without the storage of the activations. This is done by stepping backwards and computing the states and their derivatives in the backward pass. This of course does not come for free as the computational cost for computing derivatives is doubled. However, for problems with deep networks, memory is typically the limiting factor in training and not the computational cost.</p><p>The origin of such a network can be traced to a nonlinear Telegraph equation (Zhou and Luo 2018) which can be written as</p><formula xml:id="formula_3">Ÿ = f (Y, θ(t)). (3.3)</formula><p>The Telegraph equation describes the propagation of signals over physical and biological networks and therefore it is straight forward to extend its use to deep neural networks where signals are propagated over artificial networks. A leapfrog finite difference discretization of the second derivative reads</p><formula xml:id="formula_4">Ÿ ≈ 1 h 2 (Y j+1 − 2Y j + Y j−1 ) .</formula><p>This leads to the proposed network (3.2) where the h 2 term is absorbed into the network parameters. The network is named hyperbolic as it imitates a nonlinear hyperbolic differential equation (3.3).</p><p>For hyperbolic networks where W j is not invertible for every layer, the network is only reversible in blocks where W j = W j−1 = I. In such cases, one can compute Y j−1 given Y j+1 and Y j , removing the need to store activations as they can recomputed in the backward pass. However, since activations still need to be stored in cases where W j is not invertible the memory footprint depends on the number of non invertible W j , as shown in Figure <ref type="figure" target="#fig_0">1</ref>. In the context of a CNN with non-invertible W j , e.g. average pooling, this means that one would need to store the two states preceeding every layer that changes the resolution of the state. In some cases, such as encoder-decoder architectures, this can lead to a significant increase in the network's memory footprint, see Figure <ref type="figure" target="#fig_0">1</ref>. For large scale problems and deep networks, where the memory required to store activations exceeds what is possible with current hardware, this may be the only feasible way to compute gradients.</p><p>Let us now introduce a hyperbolic network that is fully reversible and overcomes the above issues. We are interested in problems where both the input and the output are large and dense, e.g. image and video segmentation, as this is where the memory footprint of the network is particularly important. For these problems it is common to use an encoder-decoder architecture (Shelhamer, Long, and Darrell 2017). When such a network is applied to the data, going from the low resolution latent state to high resolution output requires interpolation. However, interpolating the low level features introduces interpolation artifacts and damps high frequencies. To regain high Figure <ref type="figure">2</ref>: A sketch of a 12 layer hyperbolic network for high dimensional output problems. The first layer opens the image up to the desired size of the output. The hyperbolic network uses two skip connections to compute the next layer. The DWT and its inverse are used to coarsen the state and increase the number of channels without losing information. In cases where the skip connection connects states that are different dimensions, the appropriate transform is applied. frequencies, the interpolated image is then supplemented with previous states, such as at different scales (Zhao et al. 2017) or higher resolutions <ref type="bibr" target="#b13">(Ronneberger, Fischer, and Brox 2015)</ref>. Unfortunately, in order to have a reversible encoder-decoder network, it is necessary to remove irregular skip connections that introduce dependencies between distant states of the network. The removal of these skip connections and the introduction of reversible pooling is required in order to design a reversible network with constant memory requirements during training, independent of network depth. Additionally, the latent space of a hyperbolic network will not have lost any information, so it will not be necessary to use previous states to re-introduce information via long skip connections.</p><p>To this end we focus our attention on the layers where the resolution and number of channels are changed. Let Y j be the j-th state obtained at layer j. Our goal is to obtain a new state Y j that has a coarser resolution with more channels. This of course can be done by simply convolving Y j by a few kernels and then, coarsening each one of them which can be written as</p><formula xml:id="formula_5">Y j =     P P . . . P         A 1 A 2 . . . A n     Y j (3.4)</formula><p>Here, A i are convolution matrices and P are restriction matrices. The resulting state Y j has now n channels, and each channel has a lower resolution compared to the original state. Consider the matrix</p><formula xml:id="formula_6">W j =     PA 1 PA 2 . . . PA n     (3.5)</formula><p>Figure <ref type="figure">3</ref>: A picture of a clown transformed using the Haar wavelet transform that include a low resolution image, a horizontal, vertical and diagonal derivatives.</p><p>In general, the matrix, W j is rectangular or not invertible. However, if we construct the matrix in a way that it is square and invertible then it is possible to decrease the resolution and add channels or to increase the resolution and reduce the number of channels without losing any information and without interpolation. This will enable us to compute Y j−1 given Y j+1 and Y j even when W j = W j−1 = I, meaning that we will have a fully reversible network.</p><p>While it is possible to learn the matrices A i , this may add considerable complexity to the method. This is because, while it is straight forward to build W j as square, it is not obvious how to enforce its invertibility. Furthermore, even if the matrix is invertible, inverting it may not be simple, making the process too expensive for practical purposes. Although it is difficult to learn an appropriate matrix W, it is possible to choose one that posses all the above qualities.</p><p>We propose to use the discrete wavelet transformation (DWT) as the invertible operator W that coarsens and increases the number of channels. The DWT is a linear transformation of a discrete grid function <ref type="bibr" target="#b15">(Truchetet and Laligant 2004)</ref>, and is commonly used in image processing. In its simplest form at a single level, the DWT applies four filters to an image and decomposes it into four coarser images each containing distinct information. The important point is that the DWT is invertible, that is, it is possible to use the four low resolution images in order to explicitly and exactly reconstruct the fine resolution image. A simple example is plotted in Figure <ref type="figure">3</ref>.</p><p>While there are many possible wavelets that can be used, here we chose to use the Haar wavelet. The Haar wavelet uses four simple filters and can be interpreted as simple convolution with subsampling (stride). The first is simply an averaging kernel that performs image sub-sampling. The final three are a vertical derivative, a horizontal derivative, and a diagonal derivative. In essence, the wavelet transform gives a recipe to either coarsen the image and increase the number of channels or reduce the number of channels and increase the resolution. This is exactly the property that is needed for our network. Another advantage of using the DWT is that it decreases the number of parameters of the network, since the parameters of the opening channels are pre-determined and need not be learned.</p><p>Using the above ingredients the hyperbolic network is simply (3.2) with W j being the wavelet transform. For the dense input and output problems that we are considering, we require a downward pass where the image is coarsened and the number of channels are increased and an upward pass where the image is refined and the number of channels are decreased such that</p><formula xml:id="formula_7">Y j+1 = 2W j Y j − W j−1 Y j−1 + f (W i Y j , θ j ) j = 1 . . . n (3.6) Y j+1 = 2W −1 j Y j − W −1 j−1 Y j−1 + f (W −1 i Y j , θ j ) j = n + 1 . . . 2n.</formula><p>(3.7)</p><p>The final output has the same resolution as the input image and, since both parts of the network are reversible, the entire network is reversible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Numerical Experiments with Hyperbolic Networks</head><p>In this section we experiment with our network on two different problems that require large and dense input and output.</p><p>The first is the estimation of depth from images given by the NYU Depth V2 dataset and the second is 3D volumetric segmentation of videos. While we do not show any particular instances of our network that exceed what is possible with current hardware, we chose these two tasks because they are problems in which it's entirely possible to work on data resolutions where the memory footprint becomes prohibitively large. We show in these numerical experiments that the DWT is an appropriate choice for an invertible pooling operator and that despite the required changes to the network architecture for reversibility hyperbolic networks still produce accurate results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Depth Estimation from NYU Depth V2</head><p>In this experiment we use our architecture on the the NYU-Depth dataset. The data is a set of images recorded by both visible and depth cameras from a Microsoft Kinect. The data contain four different scenes and our goal network is to use the visible images in order to predict the depth images. Rather than using all images, we train a 40 block hyperbolic network on a subset of classroom images. The first 20 blocks are from the downward pass and the remaining 20 are from an upward pass. We coarsen the images every five steps, resulting in four coarsening steps followed by four reconstruction steps. An example of one of the images its depth map and the recovered depth map using our network is plotted in Figure <ref type="figure" target="#fig_1">4</ref>. The HyperNet has roughly 56M parameters. An equivalent ResNet has close to 62M parameters due to the opening layers and an equivalent UNet has close to 66M parameters. We used 500 epochs to fit the data. The initial L2 misfit is 2.3 and we are able to reduce this misfit to 0.01 in 150 epochs. The results on a validation image is presented in Figure <ref type="figure" target="#fig_1">4</ref> where good agreement of our prediction is achieved. Quantitatively, the results are similar to those obtained in <ref type="bibr" target="#b12">(Riegler et al. 2015)</ref> where a non-reversible network was used and training requires significantly more memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training a video-to-video network for single video semantic segmentation</head><p>With a semantic segmentation of video or other 3D data volumes, we hope to exploit the similarity between the timeframes and obtain better results compared to single image segmentation. The obvious challenge is memory: the cubic memory scaling with input size prohibits the storage of activations for deep and wide convolutional neural networks on a GPU, as required by automatic differentiation software. Workarounds for the memory issues are often based on 2D slices to reduce the input size. Approaches range from slice-by-slice to sophisticated algorithms that combine neuralnetworks (encoder-decoder, GANs, recurrent networks) with other processing to arrive at hybrid methods that detect and propagate the segmentation in time, based on a one or a few reference segmentation slices. See, e.g., <ref type="bibr" target="#b10">(Liu et al. 2018b;</ref><ref type="bibr" target="#b10">Oh et al. 2018;</ref><ref type="bibr" target="#b2">Caelles et al. 2019)</ref> for some recent examples that include literature review.</p><p>Existing 3D CNNs are limited to low-resolution video or a small number of time-frames. <ref type="bibr" target="#b6">(Hou, Chen, and Shah 2017)</ref> use only eight time-frames at once, which limits the temporal information than can be exploited. <ref type="bibr" target="#b15">(Tran et al. 2016</ref>) use 16 frames starting at a resolution of 128 × 171. 3D data volumes also arise in the segmentation of medical imaging data. For example, <ref type="bibr">(Çiçek et al. 2016</ref>) use a 3D U-net with 14 3D convolution layers and an input size of 132 × 132 × 116 × 3. Our input size is about seven times larger and we have a deeper network with 20 3D convolutional layers.</p><p>To highlights the benefits of conservative hyperbolic networks that are fully reversible, we present a simple approach to RGB video segmentation. The input and output are the full RGB video and segmented video, respectively. We derive the gradient of the loss function by hand and implement the computations without automatic differentiation software. In this way, we need to store activations of a few layers of the network. The peak memory then depends on the maximal width and does not grow with depth. The end-to-end (voxel to voxel) training is a simple method in the sense that we do not need multiple networks or design algorithms to propagate 2D segmentations forward or backward in time or take previous time slices into account explicitly. The scope of this example is different from most image/video semantic segmentation methods. Commonly, networks train on large numbers of examples with full supervision (fully annotated videos) and provide quick inference afterward on a new example. Here, we show that we can train a network on a single video, given a few segmented timeslices of that same video. We never have access to the fully annotated video. Whereas in image segmentation, the evaluation/testing images come without any corresponding labels, other works on video segmentation also provide partial labels (e.g., for a few time-slices) for evaluation and testing. The task in this example is thus a type of interpolation and extrapolation of the provided labels, guided by the RGB video. We note that the benefit of not requiring a training dataset comes at the cost of not having a real-time segmentation method.  For each video, we train or retrain or update our network. Using annotated (parts of) slices to complete the 3D annotation is also referred to as semi-automated or semi-supervised in some literature. Moreover, it is not exclusive to video processing and also appears in medical image segmentation <ref type="bibr">(Çiçek et al. 2016</ref>) and geophysical data processing <ref type="bibr" target="#b11">(Peters, Granek, and Haber 2019)</ref>.</p><p>We test our network and proposed methodology on the Davis video dataset <ref type="bibr" target="#b10">(Perazzi et al. 2016)</ref>. The results are without pre-training the network, and no pre/post-processing was applied. The input size for our network is 240 × 424 × 72 × 6. We arrive at six channels by repeating the RGB channels twice. The output is at the same resolution. There are 20 layers that each use 3×3×3 convolutional kernels. For this example, we use two coarsening steps (Haar transforms) which leads to a maximum channel count of 6 × 8 × 8 = 384 in the middle of the network. The label for training constists of three time-slices: slice 5, 30, and 69, see Figure <ref type="figure" target="#fig_2">5</ref>. The true label and prediction corresponding are shown in Figure <ref type="figure" target="#fig_3">6</ref> and Figure <ref type="figure" target="#fig_5">8</ref> shows quantitative information for the full consists.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work we have introduced a new architecture for deep neural networks. The architecture is motivated by the propagation of signals over physical networks where hyperbolic equations are used to describe the behavior of signal propagation. The network can be interpreted as a leapfrog discretization of the nonlinear Telegraph equation. The equation and its corresponding discretization are conservative, which implies that the network propagates the energy of the initial condition throughout all layers without decay. Similar to other networks, in order to obtain non-local behavior coarsening is used and, at the same time, the number of channels is increased. In order to coarsen the image conservatively, we use the discrete wavelet transform. Such a transform has a natural property that it increases the number of channels while reducing the resolution, while conserving all the information in the image due its invertibility.</p><p>There are a number of advantages to hyperbolic networks and to our fully conservative networks in particular, the biggest of which is reversibility. Such a network does not require the storage of activations in order to compute derivatives. This enables the training of deep networks even for problems where the input and output size is very large, with only doubling the computational cost of the backward propagation.</p><p>In our numerical experiments we show that despite the constraints introduced to enforce reversibility, the proposed hyperbolic network is able to succeed in tasks that commonly require large memory footprints, such as 3D video segmentation. We believe that for large scale problems and for problems in 3D, fully reversible networks will be a key in efficient training and inference.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Memory comparison related to the activations (network states) stored in the forward-pass through the network for computing gradients. Figure displays a Resnet-based encoder-decoder network, block-reversible network (Chang et al. 2018), and the proposed fully reversible network. Left: assumes 50 layer network with 4 coarsening and refinement stages. Middle: 300 3 input and fixed number of coarsening steps. Right: 50 layers and 300 3 input size.</figDesc><graphic url="image-1.png" coords="3,59.85,54.00,226.80,97.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example from the validation set of the NYU Depth V2 dataset and our hyperbolic nets prediction.</figDesc><graphic url="image-7.png" coords="6,54.00,199.08,252.00,188.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The training label consists of a 3D volume with just 3D annotated slices</figDesc><graphic url="image-8.png" coords="6,319.50,223.74,252.00,188.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Three orthogonal slices through the data and prediction for the video-to-video training. Training only used 3 labeled time-slices.</figDesc><graphic url="image-9.png" coords="6,319.50,429.62,252.00,188.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Prediction overlaid on the data (Bear video, displayed in grayscale).</figDesc><graphic url="image-10.png" coords="7,54.00,111.08,252.01,158.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Accuracy in terms of overal pixel percentage, per class and intersection over union per class.</figDesc><graphic url="image-11.png" coords="7,54.00,424.03,252.00,189.00" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A combined deeplearning and deformable-model approach to fully automatic segmentation of the left ventricle in cardiac mri</title>
		<author>
			<persName><forename type="first">Kheradvar</forename><surname>Avendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jafarkhani ; Avendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kheradvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jafarkhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="108" to="119" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><surname>Caelles</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12161</idno>
		<title level="m">Fast video object segmentation with spatio-temporal gans</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The reversible residual network: Backpropagation without storing activations</title>
		<author>
			<persName><forename type="first">Chang</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07394</idno>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention -MICCAI 2016</title>
				<meeting><address><addrLine>Cham; Fujieda, Takayama</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2018. 2018. 2016. 2016. 2016. 2017. 2017. 2017</date>
			<biblScope unit="page" from="2211" to="2221" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>3d u-net: Learning dense volumetric segmentation from sparse annotation</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning a variational network for reconstruction of accelerated mri data</title>
		<author>
			<persName><forename type="first">Bengio</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Courville ; Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klatzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kobler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Sodickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Knoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3055" to="3071" />
			<date type="published" when="2016">2016. 2016. 2017</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Deep Learning</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Universal function approximation by deep neural nets with bounded width and relu activations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hanin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02691v3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2017. 2017. 2016. 2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Deep residual learning for image recognition</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An end-to-end 3d convolutional neural network for action detection and segmentation in videos</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shah ; Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01111</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Sutskever</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hinton ; Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Bengio</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hinton ; Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-level wavelet-cnn for image restoration</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
				<imprint>
			<date type="published" when="2018">2018a. 2018a</date>
			<biblScope unit="page" from="886" to="88609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Understanding the effective receptive field in deep convolutional neural networks</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2018b. 2018b. 2016. 2018. 2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="724" to="732" />
		</imprint>
	</monogr>
	<note>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiresolution neural networks for tracking seismic horizons from few training images</title>
		<author>
			<persName><forename type="first">Granek</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haber ; Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Granek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Haber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interpretation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="E201" to="E213" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Depth restoration via joint training of a global regression model and cnns</title>
		<author>
			<persName><surname>Riegler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">58</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">Fischer</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Brox ; Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ruthotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.04272</idno>
	</analytic>
	<monogr>
		<title level="m">Deep neural networks motivated by partial differential equations</title>
				<imprint>
			<date type="published" when="2015">2015. 2015. 2018. 2018. 2017. 2017</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="640" to="651" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Fully convolutional networks for semantic segmentation</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Scale-recurrent network for deep image deblurring</title>
		<author>
			<persName><surname>Tao</surname></persName>
		</author>
		<idno>CoRR abs/1802.01770</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A crank-nicolson collocation spectral method for the twodimensional telegraph equations</title>
		<author>
			<persName><forename type="first">Tran</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wavelets in industrial applications: a review. Wavelet Applications in Industrial Processing II 5607</title>
				<imprint>
			<date type="published" when="2004">2016. 2016. 2004. 2017. 2017. 2018. 2018. 2018</date>
			<biblScope unit="page">137</biblScope>
		</imprint>
	</monogr>
	<note>Deep end2end voxel2voxel prediction</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
