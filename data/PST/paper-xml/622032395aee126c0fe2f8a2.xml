<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SelfKG: Self-Supervised Entity Alignment in Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-02">2 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<email>liuxiao21@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haoyun</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinghao</forename><surname>Wang</surname></persName>
							<email>xinghao-18@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zeyi</forename><surname>Chen</surname></persName>
							<email>chenzeyi19@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Evgeny</forename><surname>Kharlamov</surname></persName>
							<email>evgeny.kharlamov@de.bosch.com</email>
							<affiliation key="aff1">
								<orgName type="department">Bosch Center for AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<email>yuxiaod@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SelfKG: Self-Supervised Entity Alignment in Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-02">2 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3485447.3511945</idno>
					<idno type="arXiv">arXiv:2203.01044v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Computing methodologies → Neural networks;</term>
					<term>Information systems → Information integration Knowledge Graphs, Self-Supervised Learning, Entity Alignment</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Entity alignment, aiming to identify equivalent entities across different knowledge graphs (KGs), is a fundamental problem for constructing Web-scale KGs. Over the course of its development, the label supervision has been considered necessary for accurate alignments. Inspired by the recent progress of self-supervised learning, we explore the extent to which we can get rid of supervision for entity alignment. Commonly, the label information (positive entity pairs) is used to supervise the process of pulling the aligned entities in each positive pair closer. However, our theoretical analysis suggests that the learning of entity alignment can actually benefit more from pushing unlabeled negative pairs far away from each other than pulling labeled positive pairs close. By leveraging this discovery, we develop the self-supervised learning objective for entity alignment. We present SelfKG with efficient strategies to optimize this objective for aligning entities without label supervision. Extensive experiments on benchmark datasets demonstrate that SelfKG without supervision can match or achieve comparable results with state-of-the-art supervised baselines. The performance of SelfKG suggests that self-supervised learning offers great potential for entity alignment in KGs. The code and data are available at https://github.com/THUDM/SelfKG.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Knowledge graphs (KGs) have found widespread adoption in various Web applications, such as search <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b23">24]</ref>, recommendation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19]</ref>, and question answering <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b45">46]</ref>. Constructing largescale KGs has been a very challenging task. While we can extract new facts from scratch, aligning existing (incomplete) KGs together is practically necessary for real-world application scenarios. Over the past years, the problem of entity alignment <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b38">39]</ref>, or namely ontology mapping <ref type="bibr" target="#b19">[20]</ref> and schema matching <ref type="bibr" target="#b20">[21]</ref>, has been a fundamental problem for the Web research community.</p><p>Recently, the representation learning-based alignment methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref> have emerged as the mainstream solutions for entity alignment due to their superior flexibility and accuracy. However, their success relies heavily on the supervision provided by human labeling, which can be biased and arduously expensive to obtain for Web-scale KGs. In light of this fundamental challenge, we aim to explore the potential to align entities across KGs without label supervision (i.e., self-supervised entity alignment).</p><p>To achieve this, we revisit the common process of the established supervised entity alignment approaches. Conceptually, for each paired entities from two KGs, the goal of the existing learning objectives is to make them more similar to each other if they are actually the same entity (i.e., a positive pair), otherwise dissimilar if they are different entities (i.e., a negative pair). In the embedding space, this goal is pursued by pulling aligned entities closer and pushing different entities farther away.</p><p>We identify the parts where supervision is required in this process. At first place, the supervision serves to pull aligned entities closer. Secondly, another issue arises is the procedure of generating label-aware negative pairs. For every entity in a KG, in the training its negative pairs are formed by randomly sampling entities from the other KG while excluding the groundtruth. If without supervision, it is likely that the implicitly aligned entities are sampled as negative pairs, thus spoiling the training (i.e., collision).</p><p>Contributions. We introduce the problem of self-supervised <ref type="bibr" target="#b22">[23]</ref> entity alignment in KGs. To address it, we present the SelfKG framework, which does not rely on labeled entity pairs to align entities. It consists of three technical components: 1) relative similarity metric, 2) self-negative sampling, and 3) multiple negative queues.</p><p>To get rid of label supervision, we theoretically develop the concept of relative similarity metric (RSM), which enables the selfsupervised learning objective. The core idea of RSM is that instead of directly pulling the aligned entities closer in the embedding space, it attempts to push not-aligned negatives far away, thus avoiding the usage of the supervision of positive pairs. In a relative sense, the (implicitly) aligned entities can be considered to be dragged together when optimizing for RSM.</p><p>By design, to address the dilemma between supervision with label-aware negative sampling and collision of false-negative samples without it, SelfKG further propose the self-negative sampling strategy, that is, for every entity in a KG, we form its negative pairs by directly sampling entities from the same KG. In other words, SelfKG solely relies on negative entity pairs that are randomly sampled from the input KGs . We theoretically show that this strategy remains effective for aligning entities across KGs.</p><p>Finally, our theoretical analysis also shows that the selfsupervised loss' error term decays faster as the number of negative samples increases, i.e., a large number of negative samples can benefit SelfKG. However, encoding massive negative samples on the fly is computationally very expensive. We address this by extending the MoCo technique <ref type="bibr" target="#b15">[16]</ref> to support two negative queues, each of which corresponds to the two KGs for alignments, ensuring an efficient increase of negative samples.</p><p>Empirically, we conduct extensive experiments to demonstrate the premise of self-supervised entity alignment in KGs. We compare the proposed SelfKG method against 24 supervised and one unsupervised baselines on two widely-used entity alignment benchmarks datasets-DWY100K and DBP15K. The results suggest that SelfKG without using any labels can match or achieve comparable performance with the state-of-the-art supervised baselines (Cf. Figure <ref type="figure" target="#fig_0">1</ref>). This demonstrates the power of self-supervised learning for entity alignment as well as our design choices of SelfKG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM DEFINITION</head><p>We introduce the problem of entity alignment in KGs. Conceptually, a KG can be represented as a set of triples 𝑇 , each of which denotes the relation 𝑟 𝑖 𝑗 ∈ 𝑅 between two entities 𝑥 𝑖 ∈ 𝐸 and 𝑥 𝑗 ∈ 𝐸. In this work, we denote a KG as 𝐺 = {𝐸, 𝑅,𝑇 } where 𝐸, 𝑅, and 𝑇 are its entity set, relation set, and triple set, respectively.</p><p>Given two KGs, 𝐺 𝑥 = {𝐸 𝑥 , 𝑅 𝑥 ,𝑇 𝑥 } and 𝐺 𝑦 = {𝐸 𝑦 , 𝑅 𝑦 ,𝑇 𝑦 }, the set of the existing aligned entity pairs is defined as 𝑆 = {(𝑥, 𝑦)|𝑥 ∈ 𝐸 𝑥 , 𝑦 ∈ 𝐸 𝑦 , 𝑥 ⇔ 𝑦}, where ⇔ represents equivalence. The goal of entity alignment between 𝐺 𝑥 and 𝐺 𝑦 is to find the equivalent entity from 𝐸 𝑥 for each entity in 𝐸 𝑦 , if existed.</p><p>Recently, a significant line of work has been focusing on embedding-based techniques for aligning entities in the vector space, e.g., training a neural encoder 𝑓 to project each entity 𝑥 ∈ 𝐸 into a latent space. Among these attempts, most of them focus on the (semi-) supervised setting in the sense that part of 𝑆 is used for training the alignment models <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref>. Due to the limited alignment labels across KGs in the real world, we instead propose to study to what extent the entity alignment task can be solved in an unsupervised or self-supervised setting, under which none of the existing alignments in 𝑆 is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SELF-SUPERVISED ENTITY ALIGNMENT</head><p>In this section, we discuss the role that the supervision plays in entity alignment and then present the strategies that can help align entities without label supervision. To this end, we present the SelfKG framework for self-supervised entity alignment across KGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The SelfKG Framework</head><p>To enable learning without label information, the main goal of SelfKG is to design a self-supervised objective that can guide its learning process. To achieve this, we propose the concept of relative similarity metric (Cf. Section 3.2) between entities across two KGs. To further improve the self-supervised optimization of SelfKG, we introduce the techniques of self-negative sampling (Cf. Section 3.3) and multiple negative queues (Cf. <ref type="bibr">Section 3.4)</ref>.</p><p>Next, we introduce the initialization of entity embeddings in SelfKG, which is largely built upon existing techniques, including the uni-space learning and GNN based neighborhood aggregator.</p><p>Uni-space learning. The idea of uni-space learning has been adopted by recent (semi-) supervised entity alignment techniques <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref>. Herein, we present how we leverage it for supporting SelfKG's self-supervised learning setting.</p><p>Straightforwardly, embedding entities from different KGs into a uni-space can greatly benefit the alignment task. With labeled entity pairs, it is natural to leverage supervision to align different spaces into one, e.g., merging aligned entities for training <ref type="bibr" target="#b14">[15]</ref>, or learning projection matrices with abundant training labels to project entities from different embedding spaces into a uni-space <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>In terms of multi-lingual datasets (e.g., DBP15K), the issue is more challenging. Thanks to the pre-trained language models <ref type="bibr" target="#b13">[14]</ref>, high-quality multi-lingual initial embeddings are now available. For example, the multi-lingual BERT has been used in recent work <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b51">52]</ref>. In SelfKG, we adopt LaBSE <ref type="bibr" target="#b8">[9]</ref>-a state-of-the-art multi-lingual pre-trained language model trained on 109 different languages-for embedding different knowledge graphs into a uni-space.</p><p>Neighborhood aggregator. To further improve the entity embeddings, the neighborhood aggregation is used to aggregate neighbor entities' information to the center entity <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b41">42]</ref>. In this work, we directly use a single-head graph attention network <ref type="bibr" target="#b36">[37]</ref> with one layer to aggregate pre-trained embeddings of one-hop neighbors.</p><p>Note that leveraging multi-hop graph structures has been recently explored for the problem of entity alignment. Though some studies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref> claim that they benefit from multi-hop neighbors, other works <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b50">51]</ref> argue that one-hop neighbors provides enough information for most situations. In our ablation study (Cf. Section 4.2), we find that the multi-hop information actually harms the performance of SelfKG, which is probably resulted from the distant neighbor noises that may be unignorable in a self-supervised setting. Therefore, to demonstrate the minimum requirement of self-supervision for entity alignment, we only involve one-hop neighbor entities during the aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relative Similarity Metric</head><p>Self-negative Sampling</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Matemáticas</head><p>Math push pull</p><p>x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4 1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6</p><formula xml:id="formula_0">O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_1">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_2">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 3  </p><formula xml:id="formula_3">0 n v n J k y K B l K c C y m N n r q T x J g V 4 = " &gt; A A A C t X i c j V L L S g M x F D 0 d X 7 V W r W s 3 g 0 V w V T J u d C n o w m U F + 4 B a Z C Z N a + y 8 T D J C K f 6 A W z 9 O / A P 9 C 2 / i C G o R z T A z J + f e c 5 K b m y i P p T a M v V S 8 p e W V 1 b X q e m 2 j X t v c 2 m 7 U u z o r F B c d n s W Z 6 k e h F r F M R c d I E 4 t + r k S Y R L H o R d N T G + / d C 6 V l l l 6 a W S 6 G S T h J 5 V j y 0 B D V v m 4 0 W Y u 5 4 S + C o A R N l C N r P O M K I 2 T g K J B A I I U h H C O E p m e A A A w 5 c U P M i V O E p I s L P K B G 2 o K y B G W E x E 7 p O 6 H Z o G R T m l t P 7 d S c V o n p V a T 0 s U + a j P I U Y b u a 7 + K F c 7 b s b 9 5 z 5 2 n 3 N q N / V H o l x B r c E P u X 7 j P z v z p b i 8 E Y x 6 4 G S T X l j r H V 8 d K l c K d i d + 5 / q c q Q Q 0 6 c x S O K K 8 L c K T / P 2 X c a 7 W q 3 Z x u 6 + K v L t K y d 8 z K 3 w J v d J f U 3 + N n N R d A 9 b A W s F V w w V L G L P R x Q G 4 9 w g n O 0 0 S H L E R 7 x 5 J 1 5 t 9 7 d x z 3 w K u W F 2 M G 3 4 e l 3 4 Y W M 3 A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n c h Y R V Z W / B e s O H k X j 5 U e e r U b p C Y = " &gt; A A A C u X i c j V J d S 8 M w F D 2 r X 3 N O n b 7 6 U h y C T 6 P 1 R R 8 F Q X z c w H 3 A F G m z b I Z l b U l S c Q x / g a / 6 2 8 R / o P / C m 9 i B O k R T 2 p 6 c e 8 9 J b m 7 i T A p t g u C 1 5 C 0 t r 6 y u l d c r G 9 X N r e 3 a T r W j 0 1 w x 3 m a p T F U v j j S X I u F t I 4 z k v U z x a B J L 3 o 3 H Z z b e v e N K i z S 5 N N O M X 0 + i U S K G g k W G q N b 9 T a 0 e N A I 3 / E U Q F q C O Y j T T 2 g u u M E A K h h w T c C Q w h C U i a H r 6 C B E g I + 4 a M + I U I e H i H A + o k D a n L E 4 Z E b F j + o 5 o 1 i / Y h O b W U z s 1 o 1 U k v Y q U P g 5 I k 1 K e I m x X 8 1 0 8 d 8 6 W / c 1 7 5 j z t 3 q b 0 j w u v C b E G t 8 T + p Z t n / l d n a z E Y 4 s T V I K i m z D G 2 O l a 4 5 O 5 U 7 M 7 9 L 1 U Z c s i I s 3 h A c U W Y O e X 8</formula><formula xml:id="formula_4">Y = " &gt; A A A C u X i c j V J d S 8 M w F D 2 r X 3 N O n b 7 6 U h y C T 6 P 1 R R 8 F Q X z c w H 3 A F G m z b I Z l b U l S c Q x / g a / 6 2 8 R / o P / C m 9 i B O k R T 2 p 6 c e 8 9 J b m 7 i T A p t g u C 1 5 C 0 t r 6 y u l d c r G 9 X N r e 3 a T r W j 0 1 w x 3 m a p T F U v j j S X I u F t I 4 z k v U z x a B J L 3 o 3 H Z z b e v e N K i z S 5 N N O M X 0 + i U S K G g k W G q N b 9 T a 0 e N A I 3 / E U Q F q C O Y j T T 2 g u u M E A K h h w T c C Q w h C U i a H r 6 C B E g I + 4 a M + I U I e H i H A + o k D a n L E 4 Z E b F j + o 5 o 1 i / Y h O b W U z s 1 o 1 U k v Y q U P g 5 I k 1 K e I m x X 8 1 0 8 d 8 6 W / c 1 7 5 j z t 3 q b 0 j w u v C b E G t 8 T + p Z t n / l d n a z E Y 4 s T V I K i m z D G 2 O l a 4 5 O 5 U 7 M 7 9 L 1 U Z c s i I s 3 h A c U W Y O e X 8</formula><formula xml:id="formula_5">n B I p B V c C q v 9 y 2 T V c c U m 2 M g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I 3 u i w K 4 r I F + 4 B a J E m n d e g 0 C Z m J W I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 G l 8 r z X g r O w u L S 8 U l w t r a 1 v b G 6 V t 3 d a M s m z i D W j R C R Z J w w k E z x m T c W V Y J 0 0 Y 8 E 4 F K w d j s 5 0 v H 3 L M s m T + F J N U t Y b B 8 O Y D 3 g U K K I a d 9 f l i l f 1 z H L n g W 9 B B X b V k / I L r t B H g g g 5 x m C I o Q g L B J D 0 d O H D Q 0 p c D 1 P i M k L c x B n u U S J t T l m M M g J i R / Q d 0 q 5 r 2 Z j 2 2 l M a d U S n C H o z U r o 4 I E 1 C e R l h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w Q + 5 d u l v l f n a 5 F Y Y A T U w O n m l L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E q d x n + I Z 4 c g o Z 3 1 2 j U a a 2 n V v A x N / M 5 m a 1 f v I 5 u Z 4 1 7 e k A f s / x z k P W k d V 3 6 v 6 D a 9 S O 7 W j L m I P + z i k e R 6 j h g v U 0</formula><p>T T e j 3 j C s 3 P u C E c 6 + W e q U 7 C a X X x b z s M H a d y P e Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_6">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_7">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_8">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_9">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9</formula><p>T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4 1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0</p><formula xml:id="formula_10">A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9</formula><p>T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4 1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0</p><formula xml:id="formula_11">A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9</formula><p>T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b   </p><formula xml:id="formula_12">+ N u V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_13">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_14">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_15">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 f b X y P f g = = &lt; / l a t e x i t &gt; y 1</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q</p><formula xml:id="formula_16">X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; /</formula><p>l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q</p><formula xml:id="formula_17">X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; /</formula><p>l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q</p><formula xml:id="formula_18">X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; / l a t e x i t &gt; y 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5 8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n 1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5 8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n 1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5 8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n 1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5 8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n 1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; y 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8 I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8 I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8 I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8 I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4 1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_19">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_20">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 3  </p><formula xml:id="formula_21">0 n v n J k y K B l K c C y m N n r q T x J g V 4 = " &gt; A A A C t X i c j V L L S g M x F D 0 d X 7 V W r W s 3 g 0 V w V T J u d C n o w m U F + 4 B a Z C Z N a + y 8 T D J C K f 6 A W z 9 O / A P 9 C 2 / i C G o R z T A z J + f e c 5 K b m y i P p T a M v V S 8 p e W V 1 b X q e m 2 j X t v c 2 m 7 U u z o r F B c d n s W Z 6 k e h F r F M R c d I E 4 t + r k S Y R L H o R d N T G + / d C 6 V l l l 6 a W S 6 G S T h J 5 V j y 0 B D V v m 4 0 W Y u 5 4 S + C o A R N l C N r P O M K I 2 T g K J B A I I U h H C O E p m e A A A w 5 c U P M i V O E p I s L P K B G 2 o K y B G W E x E 7 p O 6 H Z o G R T m l t P 7 d S c V o n p V a T 0 s U + a j P I U Y b u a 7 + K F c 7 b s b 9 5 z 5 2 n 3 N q N / V H o l x B r c E P u X 7 j P z v z p b i 8 E Y x 6 4 G S T X l j r H V 8 d K l c K d i d + 5 / q c q Q Q 0 6 c x S O K K 8 L c K T / P 2 X c a 7 W q 3 Z x u 6 + K v L t K y d 8 z K 3 w J v d J f U 3 + N n N R d A 9 b A W s F V w w V L G L P R x Q G 4 9 w g n O 0 0 S H L E R 7 x 5 J 1 5 t 9 7 d x z 3 w K u W F 2 M G 3 4 e l 3 4 Y W M 3 A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n c h Y R V Z W / B e s O H k X j 5 U e e r U b p C Y = " &gt; A A A C u X i c j V J d S 8 M w F D 2 r X 3 N O n b 7 6 U h y C T 6 P 1 R R 8 F Q X z c w H 3 A F G m z b I Z l b U l S c Q x / g a / 6 2 8 R / o P / C m 9 i B O k R T 2 p 6 c e 8 9 J b m 7 i T A p t g u C 1 5 C 0 t r 6 y u l d c r G 9 X N r e 3 a T r W j 0 1 w x 3 m a p T F U v j j S X I u F t I 4 z k v U z x a B J L 3 o 3 H Z z b e v e N K i z S 5 N N O M X 0 + i U S K G g k W G q N b 9 T a 0 e N A I 3 / E U Q F q C O Y j T T 2 g u u M E A K h h w T c C Q w h C U i a H r 6 C B E g I + 4 a M + I U I e H i H A + o k D a n L E 4 Z E b F j + o 5 o 1 i / Y h O b W U z s 1 o 1 U k v Y q U P g 5 I k 1 K e I m x X 8 1 0 8 d 8 6 W / c 1 7 5 j z t 3 q b 0 j w u v C b E G t 8 T + p Z t n / l d n a z E Y 4 s T V I K i m z D G 2 O l a 4 5 O 5 U 7 M 7 9 L 1 U Z c s i I s 3 h A c U W Y O e X 8</formula><formula xml:id="formula_22">Y = " &gt; A A A C u X i c j V J d S 8 M w F D 2 r X 3 N O n b 7 6 U h y C T 6 P 1 R R 8 F Q X z c w H 3 A F G m z b I Z l b U l S c Q x / g a / 6 2 8 R / o P / C m 9 i B O k R T 2 p 6 c e 8 9 J b m 7 i T A p t g u C 1 5 C 0 t r 6 y u l d c r G 9 X N r e 3 a T r W j 0 1 w x 3 m a p T F U v j j S X I u F t I 4 z k v U z x a B J L 3 o 3 H Z z b e v e N K i z S 5 N N O M X 0 + i U S K G g k W G q N b 9 T a 0 e N A I 3 / E U Q F q C O Y j T T 2 g u u M E A K h h w T c C Q w h C U i a H r 6 C B E g I + 4 a M + I U I e H i H A + o k D a n L E 4 Z E b F j + o 5 o 1 i / Y h O b W U z s 1 o 1 U k v Y q U P g 5 I k 1 K e I m x X 8 1 0 8 d 8 6 W / c 1 7 5 j z t 3 q b 0 j w u v C b E G t 8 T + p Z t n / l d n a z E Y 4 s T V I K i m z D G 2 O l a 4 5 O 5 U 7 M 7 9 L 1 U Z c s i I s 3 h A c U W Y O e X 8 n H 2 n 0 a 5 2 e 7 a R i 7 + 5 T M v a O S t y c 7 z b X V K D w 5 / t X A S d o 0 Y Y N M J W g D L 2 s I 9 D a u M x T n G B J t</formula><formula xml:id="formula_23">h n B I p B V c C q v 9 y 2 T V c c U m 2 M g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I 3 u i w K 4 r I F + 4 B a J E m n d e g 0 C Z m J W I r + g F v 9 N v E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + 8 N U 8 G l 8 r z X g r O w u L S 8 U l w t r a 1 v b G 6 V t 3 d a M s m z i D W j R C R Z J w w k E z x m T c W V Y J 0 0 Y 8 E 4 F K w d j s 5 0 v H 3 L M s m T + F J N U t Y b B 8 O Y D 3 g U K K I a d 9 f l i l f 1 z H L n g W 9 B B X b V k / I L r t B H g g g 5 x m C I o Q g L B J D 0 d O H D Q 0 p c D 1 P i M k L c x B n u U S J t T l m M M g J i R / Q d 0 q 5 r 2 Z j 2 2 l M a d U S n C H o z U r o 4 I E 1 C e R l h f Z p r 4 r l x 1 u x v 3 l P j q e 8 2 o X 9 o v c b E K t w Q + 5 d u l v l f n a 5 F Y Y A T U w O n m l L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E q d x n + I Z 4 c g o Z 3 1 2 j U a a 2 n V v A x N / M 5 m a 1 f v I 5 u Z 4 1 7 e k A f s / x z k P W k d V 3 6 v 6 D a 9 S O 7 W j L m I P + z i k e R 6 j h g v U 0</formula><p>T T e j 3 j C s 3 P u C E c 6 + W e q U 7 C a X X x b z s M H a d y P e Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_24">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_25">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9 T 6 y u</formula><p>T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_26">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9</formula><p>T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_27">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9</formula><p>T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4</p><formula xml:id="formula_28">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z 9 d o 5 G m d t 3 b w M T f T K Z m 9</formula><p>T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M y i E m F n n t f + q N J v n S M V F X u 6 3 4       </p><formula xml:id="formula_29">1 g = " &gt; A A A C x H i c j V H L S s N A F D 2 N r / q u u n Q T L I K r k o i g y 6 I g L l u w D 6 h F k n R a Q 6 d J m J m I p e g P u N V v E / 9 A / 8 I 7 4 x T U I j o h y Z l z 7 z k z 9 9 4 w 4 7 F U n v d a c O b m F x a X i s s r q 2 v r G 5 u l r e 2 m T H M R s U a U 8 l S 0 w 0 A y H i e s o W L F W T s T L B i F n L X C 4 Z m O t 2 6 Z k H G a X K p x x r q j Y J D E / T g K F F H 1 u + t S 2 a t 4 Z r m z w L e g D L t q a e k F V + g h R Y Q c I z A k U I Q 5 A k h 6 O v D h I S O u i w l x g l B s 4 g z 3 W C F t T l m M M g J i h / Q d 0 K 5 j 2 Y T 2 2 l M a d U S n c H o F K V 3 s k y a l P E F Y n + a a e G 6 c N f u b 9 8 R 4 6 r u N 6 R 9 a r x G x C j f E / q W b Z v 5 X p 2 t R 6 O P E 1 B B T T Z l h d H W R d c l N V / T N 3 S 9 V K X L I i N O 4 R 3 F B O D L K a Z</formula><formula xml:id="formula_30">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_31">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_32">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_33">V N Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d F k U x G U L 9 g G 1 S J J O 6 9 A 0 C T M T o R T 9 A b f 6 b e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 4 b Z j G X y v N e C 8 7 C 4 t L y S n G 1 t L a + s b l V 3 t 5 p y T Q X E W t G a Z y K T h h I F v O E N R V X M e t k g g X j M G b t c H S u 4 + 0 7 J i R P k y s 1 y V h v H A w T P u B R o I h q T G 7 K F a / q m e X O A 9 + C C u y q p + U X X K O P F B F y j M G Q Q B G O E U D S 0 4 U P D x l x P U y J E 4 S 4 i T P c o 0 T a n L I Y Z Q T E j u g 7 p F 3 X s g n t t a c 0 6 o h O i e k V p H R x Q J q U 8 g R h f Z p</formula><formula xml:id="formula_34">X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A</formula><formula xml:id="formula_35">X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A</formula><formula xml:id="formula_36">X K M = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f v t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; / l a t e x i t &gt; y 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5</formula><p>8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n</p><formula xml:id="formula_37">1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5</formula><p>8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n</p><formula xml:id="formula_38">1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5</formula><p>8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n</p><formula xml:id="formula_39">1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g M 2 v h h t u c 1 L 6 5 m D G W c k k a b F c O Z c = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 3 F V w b S F W k u S T u v Q N A m T i R K K G 3 / A r X 6 Z + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 6 9 5</formula><p>8 z c e 7 0 4 4 I m 0 r N e C M T e / s L h U X C 6 t r K 6 t b 5 Q 3 t 5 p J l A q f O X 4 U R K L t u Q k L e M g c y W X A 2 r F g 7 t g L W M s b n a p 4 6 5 a J h E f h p c x i 1 h 2 7 w 5 A P u O 9 K o p y s V 7 s + 6 J U r V t X S y 5 w F d g 4 q y F c j K r / g C n</p><formula xml:id="formula_40">1 E 8 J F i D I Y Q k n A A F w k 9 H d i w E B P X x Y Q 4 Q Y j r O M M 9 S q R N K Y t R h k v s i L 5 D 2 n V y N q S 9 8 k y 0 2 q d T A n o F K U 3 s k S a i P E F Y n W b q e K q d F f u b 9 0 R 7 q r t l 9 P d y r z G x E j f E / q W b Z v 5 X p 2 q R G O B Y 1 8 C p p l g z q j o / d 0 l 1 V 9 T N z S 9 V S X K I i V O 4 T 3 F B 2 N f K a Z 9 N r U l 0 7 a q 3 r o 6 / 6 U z F q r 2 f 5 6 Z 4 V 7 e k A d s / x z k L m r W q b V X t i 8 N K / S Q f d R E 7 2 M U + z f M I d Z y h A Y e 8 O R 7 x h G f j 3 I i N O y P 7 T D U K u W Y b 3 5 b x 8 A G q + J D C &lt; / l a t e x i t &gt; y 0</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8</p><formula xml:id="formula_41">I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C</formula><p>s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8</p><formula xml:id="formula_42">I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C</formula><p>s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8</p><formula xml:id="formula_43">I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K Y 0 k M A = &lt; /</formula><p>l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l R n B K 5 + a 4 u x n 7 P T 8    </p><formula xml:id="formula_44">I 2 N 3 v O m 1 0 N w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u t g X i Q T J R Q 3 / o B b / T L x D / Q v v D O m o B b R C U n O n H v P m b n 3 e r E v U m l Z r y V j Z n Z u f q G 8 W F l a X l l d q 6 5 v t N I o S x h 3 W O R H S c d z U + 6 L k D t S S J 9 3 4 o S 7 g e f z t n d z o u L t W 5 6 k I g o v Z B 7 z X u C O Q j E U z J V E O X n f u t r r V 2 t W 3 d L L n A Z 2 A W o o V j O q v u A S A 0 R g y B C A I 4 Q k 7 M N F S k 8 X N i z E x P U w J i 4 h J H S c 4 x 4 V 0 m a U x S n D J f a G v i P a d Q s 2 p L 3 y T L W a 0 S k + v Q k p T e y Q J q K 8 h L A 6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K Y 0 k M A = &lt; / l a t e x i t &gt; x 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z W w J g c U Q H y v J K z n Y s a k 1 d R Z 5 O J I = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 1 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G 7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 P Q k L 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z W w J g c U Q H y v J K z n Y s a k 1 d R Z 5 O J I = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 1 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G 7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 P Q k L 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z W w J g c U Q H y v J K z n Y s a k 1 d R Z 5 O J I = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 1 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G 7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 P Q k L 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z W w J g c U Q H y v J K z n Y s a k 1 d R Z 5 O J I = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 1 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G 7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 P Q k L 8 = &lt; / l a t e x i t &gt; x 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + u V 2 I 5 I c O W f D x d 3 E z / I 1 d 9 F S D 7 k = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 9 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G</formula><formula xml:id="formula_45">= " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 9 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G</formula><formula xml:id="formula_46">= " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 9 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G</formula><formula xml:id="formula_47">= " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 9 t V e t 1 y x q p Z e 5 j S w c 1 B B v u p R + Q W X 6 C E C Q 4 Y A H C E k Y R 8 u U n r a s G E h J q 6 D M X E J I a H j H P c o k T a j L E 4 Z L r F D + g 5 o 1 8 7 Z k P b K M 9 V q R q f 4 9 C a k N L F D m o j y E s L q N F P H M + 2 s 2 N + 8 x 9 p T 3 W 1 E f y / 3 C o i V u C b 2 L 9 0 k 8 7 8 6 V Y t E H 0 e 6 B k E 1 x Z p R 1 b H c J d N d U T c 3 v 1 Q l y S E m T u E e x R P C T C s n f T a 1 J t W 1 q 9 6 6 O v 6 m M x W r 9 i z P z f C u b k k D t n + O c x o 0 9 q u 2 V b X P D y q 1 4 3 z U R W x h G 7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 Y y k M A = &lt; / l a t e x i t &gt; x 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K U d C P L 1 B p 6 v / r T C p X 4 s t A d 5 O 4 C w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 + 1 d 7 3 X L F q l p 6 m d P A z k E F + a p H 5 R d c o o c I D B k C c I S Q h H 2 4 S O l p w 4 a F m L g O x s Q l h I S O c 9 y j R N q M s j h l u M Q O 6 T u g X T t n Q 9 o r z 1 S r G Z 3 i 0 5 u Q 0 s Q O a S L K S w i r 0 0 w d z 7 S z Y n / z H m t P d b c R / b 3 c K y B W 4 p r Y v 3 S T z P / q V C 0 S f R z p G g T V F G t G V c d y l 0 x 3 R d 3 c / F K V J I e Y O I V 7 F E 8 I M 6 2 c 9 N n U m l T X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P 4 5 z m n Q 2 K / a V t U + P 6 j U j v N R F 7 G F b e z S P A 9 R w y n q c M h b 4 B F P e D b O j N i 4 N U a f q U Y h 1 2 z i 2 z I e P g C o l J D B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K U d C P L 1 B p 6 v / r T C p X 4 s t A d 5 O 4 C w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 + 1 d 7 3 X L F q l p 6 m d P A z k E F + a p H 5 R d c o o c I D B k C c I S Q h H 2 4 S O l p w 4 a F m L g O x s Q l h I S O c 9 y j R N q M s j h l u M Q O 6 T u g X T t n Q 9 o r z 1 S r G Z 3 i 0 5 u Q 0 s Q O a S L K S w i r 0 0 w d z 7 S z Y n / z H m t P d b c R / b 3 c K y B W 4 p r Y v 3 S T z P / q V C 0 S f R z p G g T V F G t G V c d y l 0 x 3 R d 3 c / F K V J I e Y O I V 7 F E 8 I M 6 2 c 9 N n U m l T X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P 4 5 z m n Q 2 K / a V t U + P 6 j U j v N R F 7 G F b e z S P A 9 R w y n q c M h b 4 B F P e D b O j N i 4 N U a f q U Y h 1 2 z i 2 z I e P g C o l J D B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K U d C P L 1 B p 6 v / r T C p X 4 s t A d 5 O 4 C w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 + 1 d 7 3 X L F q l p 6 m d P A z k E F + a p H 5 R d c o o c I D B k C c I S Q h H 2 4 S O l p w 4 a F m L g O x s Q l h I S O c 9 y j R N q M s j h l u M Q O 6 T u g X T t n Q 9 o r z 1 S r G Z 3 i 0 5 u Q 0 s Q O a S L K S w i r 0 0 w d z 7 S z Y n / z H m t P d b c R / b 3 c K y B W 4 p r Y v 3 S T z P / q V C 0 S f R z p G g T V F G t G V c d y l 0 x 3 R d 3 c / F K V J I e Y O I V 7 F E 8 I M 6 2 c 9 N n U m l T X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P 4 5 z m n Q 2 K / a V t U + P 6 j U j v N R F 7 G F b e z S P A 9 R w y n q c M h b 4 B F P e D b O j N i 4 N U a f q U Y h 1 2 z i 2 z I e P g C o l J D B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K U d C P L 1 B p 6 v / r T C p X 4 s t A d 5 O 4 C w = " &gt; A A A C y H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X R j b i q Y N p C r S W Z T u v Q v E g m a i l u / A G 3 + m X i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 W J f p N K y X g v G z O z c / E J x s b S 0 v L K 6 V l 7 f a K R R l j D u s M i P k p b n p t w X I X e k k D 5 v x Q l 3 A 8 / n T W 9 4 o u L N G 5 6 k I g o v 5 C j m n c A d h K I v m C u J c u 6 6 + 1 d 7 3 X L F q l p 6 m d P A z k E F + a p H 5 R d c o o c I D B k C c I S Q h H 2 4 S O l p w 4 a F m L g O x s Q l h I S O c 9 y j R N q M s j h l u M Q O 6 T u g X T t n Q 9 o r z 1 S r G Z 3 i 0 5 u Q 0 s Q O a S L K S w i r 0 0 w d z 7 S z Y n / z H m t P d b c R / b 3 c K y B W 4 p r Y v 3 S T z P / q V C 0 S f R z p G g T V F G t G V c d y l 0 x 3 R d 3 c / F K V J I e Y O I V 7 F E 8 I M 6 2 c 9 N n U m l T X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P 4 5 z m n Q 2 K / a V t U + P 6 j U j v N R F 7 G</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relative Similarity Metric</head><p>We present the self-supervised loss for entity alignment across KGs. First, we analyze the supervised NCE loss for entity alignment. Then, we introduce the relative similarity metric for avoiding labeled pairs. We finally derive the self-supervised NCE for SelfKG.</p><p>In representation learning, the margin loss <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b34">35]</ref> and crossentropy loss <ref type="bibr" target="#b49">[50]</ref> have been widely adopted as the similarity metric. Without loss of generality, they can be expressed in the form of Noise Contrastive Estimation (NCE) <ref type="bibr" target="#b12">[13]</ref>.</p><p>In the context of entity alignment, the NCE loss can be formalized as follows. Let 𝑝 x , 𝑝 y be the distributions of two KGs 𝐺 x , 𝐺 y , and 𝑝 𝑝𝑜𝑠 denote the representation distribution of the positive entity pairs (𝑥, 𝑦) ∈ R 𝑛 × R 𝑛 . Given a pair of aligned entities (𝑥, 𝑦) ∼ 𝑝 pos , negative samples {𝑦 − 𝑖 } 𝑀 𝑖=1 i.i.d.</p><p>∼ 𝑝 y , the temperature 𝜏, and the encoder 𝑓 satisfies ∥𝑓 (•)∥ = 1, we have the supervised NCE loss as</p><formula xml:id="formula_48">L NCE ≜ − log 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏 = − 1 𝜏 𝑓 (𝑥) T 𝑓 (𝑦) alignment + log(𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 + ∑︁ 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏 ) uniformity .<label>(1)</label></formula><p>where the "alignment" term is to draw the positive pair close and the "uniformity" term is to push the negative pairs away. We illustrate how this NCE loss can be further adjusted for a selfsupervised setting. An example of "pulling" and "pushing" entity pairs in KGs can be found in Figure <ref type="figure" target="#fig_17">2 (left)</ref>. Previous studies have shown that the NCE loss has the following asymptotic properties: Theorem 1. (Absolute similarity metric (ASM) <ref type="bibr" target="#b37">[38]</ref>) For a fixed 𝜏 &gt; 0, as the number of negative samples 𝑀 → ∞, the (normalized) contrastive loss L NCE (i.e., L ASM ) converges to its limit with an absolute deviation decaying in O (𝑀 −2/3 ). If a perfectly-uniform encoder 𝑓 exists, it forms the exact minimizer of the uniformity term.</p><p>Proof. Please refer to <ref type="bibr" target="#b37">[38]</ref>. □ Theorem 1 makes the NCE loss an absolute similarity metric that requires supervision. However, note that despite potential ambiguity and heterogeneity for entities in KGs, the aligned pairs should share similar semantic meanings, if not exactly the name. Furthermore, the pre-trained word embeddings are known to capture this semantic similarity by projecting similar entities close in the embedding space, which can thus ensure a relatively large 𝑓 (𝑥) 𝑇 𝑓 (𝑦) in Eq. 1, i.e., the "alignment" term.</p><p>Therefore, to optimize the NCE loss, the main task is then to optimize the "uniformity" term in Eq. 1 rather than the "alignment" term. Considering the boundedness property of 𝑓 , we can instantly draw an unsupervised upper bound of L ASM by as follows.</p><p>Proposition 1. Relative similarity metric (RSM). For a fixed 𝜏 &gt; 0 and encoder 𝑓 satisfies ∥𝑓 (•)∥ = 1, we always have the following relative similarity metric plus an absolute deviation controlled by a constant as an upper bound for L ASM :</p><formula xml:id="formula_49">L RSM = − 1 𝜏 + E {𝑦 − 𝑖 } 𝑀 𝑖=1 i.i.d. ∼ 𝑝y log(𝑒 1/𝜏 + ∑︁ 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 ) /𝜏 ) ≤ L ASM ≤ L RSM + 1 𝜏 1 − min (𝑥,𝑦) ∼𝑝pos 𝑓 (𝑥) T 𝑓 (𝑦) .<label>(2)</label></formula><p>Proof. Please refer to Appendix A.1. □ By optimizing L RSM , the aligned entities are relatively drawn close by pushing non-aligned ones farther away. In other words, if we cannot draw the aligned entities close (e.g., no positive labels), we can instead push those not-aligned ones far away enough.</p><p>By analyzing the commonly-used NCE loss for entity alignment, we find that the training can benefit more from pushing those randomly-sampled (negative) pairs far away than pulling aligned (positive) ones close. Thus, in SelfKG, we focus only on attempting to pushing the negatives far away such that we can get rid of the usage of positive data (i.e., labels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Self-Negative Sampling</head><p>In the analysis above, we demonstrate that to align entities without supervision, the focus of SelfKG is on sampling negative entity pairs-one from KG 𝐺 𝑥 and the other from KG 𝐺 𝑦 . During negative sampling, without supervision for label-aware negative sampling, it is likely that the underlyingly aligned entity pair is sampled as a negative one, i.e., collision happens. Normally, this collision probability can be ignored if a few negatives are sampled; but we discover that a large number of negative samples can be crucial to the success of SelfKG (Cf. Figure <ref type="figure" target="#fig_21">4</ref>), under which the collision probability is non-negligible (Cf. Table <ref type="table" target="#tab_1">4</ref>), causing a performance drop by up to 7.7% relatively. To mitigate the issue, we propose to sample negatives 𝑥 − 𝑖 from 𝐺 𝑥 for entity 𝑥 ∈ 𝐺 𝑥 , given that we are learning from the uni-space of 𝐺 𝑥 and 𝐺 𝑦 . By doing so, we would avoid the conflict by simply excluding 𝑥, namely selfnegative sampling.</p><p>However, there may be two other issues aroused consequently. First, due to the real-world noisy data quality, there may often exist several duplicated 𝑥 in 𝐺 𝑥 , which could be possibly sampled as negatives. Note that this is also a challenge faced by the supervised setting, where a few duplicated 𝑦 may also exist in 𝐺 𝑦 . By following the outline of proof in <ref type="bibr" target="#b37">[38]</ref>, we show that a certain amount of noise will not influence the convergence of the NCE loss.</p><p>Theorem 2. (Noisy ASM) Let the average duplication factors 𝜆 ∈ N + , 𝜏 ∈ R + be constants. The noisy ASM is denoted as follows and it still converges to the same limit of ASM with the absolute deviation decaying in O (𝑀 −2/3 ). Proof. Please refer to Appendix A.2. □ The second issue is that by changing the negative samples from 𝑦 − 𝑖 ∈ 𝐺 𝑦 to 𝑥 − 𝑖 ∈ 𝐺 𝑥 , we need to confirm whether the L RSM would still be effective for entity alignment. Empirically, for a selected negative sample 𝑦 − 𝑗 ∈ 𝐺 𝑦 , we can expect there to be some partially similar 𝑥 − 𝑖 ∈ 𝐺 𝑥 . Since the encoder 𝑓 is shared for 𝐺 𝑥 and 𝐺 𝑦 , the optimization of 𝑓 (𝑥 − 𝑖 ) will also contribute to the optimization of 𝑓 (𝑦 − 𝑗 ). To justify this, we provide the following theorem. Proof. Please refer to Appendix A.3. □ Wang et al. <ref type="bibr" target="#b37">[38]</ref> suggests that under the condition of 𝑝 x = 𝑝 y , the encoder 𝑓 can be attained approximately as the minimizer of the uniform loss. Specifically, 𝑓 follows the uniform distribution on the hypersphere. In SelfKG, the uni-space learning condition ensures the ultimate unified representation for both KGs. The initial 𝑝 𝑥 and 𝑝 𝑦 are similar but not identical, which indicates that the selfnegative sampling is essential. However, as the training continues, the encoder will be improved as Theorem 2 guarantees to make two KGs more aligned. In other words, the entity embeddings of 𝐺 𝑥 and 𝐺 𝑦 could be viewed as the samples from one single distribution in a larger space, i.e., 𝑝 x = 𝑝 y . This in turn allows the existence of 𝑓 to be more realizable.</p><p>In practice, we jointly optimize the loss on both 𝐺 𝑥 and 𝐺 𝑦 as follows, which is also illustrated in Figures 2 (right) and 3. L = L RSM|𝜆,x (𝑓 ; 𝜏, 𝑀, 𝑝 x ) + L RSM|𝜆,y (𝑓 ; 𝜏, 𝑀, 𝑝 y ).</p><p>(5)</p><p>In addition, as the error term of L 𝜆 (𝑓 ; 𝜏, 𝑀, 𝑝 x ) decays in O (𝑀 −2/3 ) (Cf. Theorem 2), we use a comparatively large number of negative samples to boost the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Multiple Negative Queues</head><p>Enlarging the number of negative samples can naturally result in additional computational cost, as encoding massive negative samples on the fly is quite expensive. To address this issue, we propose to extend the MoCo technique <ref type="bibr" target="#b15">[16]</ref> for SelfKG. In Moco, a negative queue is maintained to store the previously-encoded batches as the encoded negative samples, which host thousands of encoded negative samples at limited cost.</p><p>To adapt to the self-negative sampling strategy in SelfKG, we practically maintain two negative queues, associating with the two input KGs, respectively. An illustrative example is shown in Figure <ref type="figure" target="#fig_20">3</ref>. In the beginning, we would not implement the gradient update until one of the queues reaches the predefined length 1+𝐾 where '1' is for the current batch and 𝐾 is for the number of previous batches </p><formula xml:id="formula_50">(1 + 𝐾) × 𝑁 &lt; min(|𝐸 𝑥 |, |𝐸 𝑦 |),<label>(6)</label></formula><p>it is guaranteed that we would not sample out entities in the current batch. As a result, the real number of negative samples used for the current batch is (1 + 𝐾) × 𝑁 − 1.</p><p>Momentum update <ref type="bibr" target="#b15">[16]</ref>. The main challenge brought by negative queues is the obsolete encoded samples, especially for those encoded at the early stage of training, during which the model parameters vary drastically. Thus, the end-to-end training, which only uses one frequently-updated encoder, may actually harm the training. To mitigate this, we adopt the momentum training strategy, which maintains two encoders-the online encoder and the target encoder. While the online encoder's parameter 𝜃 online is instantly updated with the backpropagation, the target encoder 𝜃 target for encoding the current batch and then pushing into the negative queue is asynchronously updated with momentum by:</p><formula xml:id="formula_51">𝜃 target ← 𝑚 • 𝜃 target + (1 − 𝑚) • 𝜃 online , 𝑚 ∈ [0, 1)<label>(7)</label></formula><p>A proper momentum is not only important for steady training but may also influence the final performance by avoiding representation collapse (Cf. Figure <ref type="figure" target="#fig_21">4</ref>). We present a series of related hyper-parameter studies in Section 4.</p><p>Summary. We present SelfKG for self-supervised entity alignment. Figure <ref type="figure" target="#fig_17">2</ref> illustrates that: 1. relative similarity metric (RSM) pushes the non-aligned entities (𝑦 − 0 , 𝑦 − 1 and 𝑦 − 2 ) of 𝑥 far enough, instead of directly pulling underlyingly-aligned 𝑦 close to 𝑥 (labeled pairs), enabling learning without label supervision; 2. self-negative sampling samples negative entities for 𝑥 from 𝐺 𝑥 to avoid sampling the true 𝑦 as its negative. Figure <ref type="figure" target="#fig_20">3</ref> illustrates the training of SelfKG. It leverages existing techniques-embeddings from pre-trained language models and neighborhood aggregator-to initialize entity embeddings into a uni-space. The technical contributions of SelfKG lie in:</p><p>(1) the design of the self-supervised loss in Eq. 2 enabled by our relative similarity metric (RSM) in KGs;</p><p>Table <ref type="table">1</ref>: Statistics of DWY100K and DBP15K. About the definition of neighbor similarity, please refer to Section 4. "#Link" is the number of aligned entity pairs. "#Test Link" is the number of aligned pairs for test.</p><p>We observe that SelfKG beats all previous supervised ones except for HMAN <ref type="bibr" target="#b42">[43]</ref>, CEAFF <ref type="bibr" target="#b48">[49]</ref> and BERT-INT <ref type="bibr" target="#b34">[35]</ref>. There is a gap between supervised state-of-the-arts and SelfKG, which indicates that multi-lingual alignment is surely more complicated than the monolingual setting. We also observe a clear gap between different language datasets. DBP15K zh_en is the one with the lowest Hit@1, DBP15K ja_en is the middle, and DBP15K fr_en has the highest score. However, if we recall the neighbor similarity scores presented in Table <ref type="table">1</ref>, it is the DBP15K zh_en that has the highest neighbor similarity. This discovery indicates that the difference in performance can be mostly attributed to challenges brought by multi-lingual setting instead of structural similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study</head><p>We conduct extensive ablation studies respectively on DWY100K and DBP15K for SelfKG. We ablate components regarding the different types of information it brings in. In addition, we conduct studies over some important hyper-parameters using DBP15K zh_en dataset as an example.</p><p>In Table <ref type="table" target="#tab_1">4</ref>, we present the ablation study for SelfKG on both DWY100K and DBP15K, including ablation of neighborhood aggregator and ablation of the self-supervised contrastive training objective based on relative similarity metric (RSM) (i.e., use the original encoding outputs from the LaBSE). We first observe that the LaBSE provides rather good initialization. However, merely the LaBSE is not enough. As we can see, on DWY100K, the LaBSE is benefited substantially from our RSM, with an absolute gain over 10% on DWY100K dbp_wd and 5% on DBP15K. The use of neighborhood aggregator boosts SelfKG on both DWY100K and DBP15K, which indicates the importance of introducing neighbor information.</p><p>Besides, we test the performance of SelfKG without self-negative sampling strategy, which means we sample negative entities from the target KG as most baselines do but without labels (which may introduce the true positive ones). The results show that self-negative sampling is necessary for SelfKG, which brings absolute gains of 2-7%. While the strategy increase in performance can be partly attributed to avoid of collision, careful readers may think of why possibly-existed duplicated entities does not harm as much as the collision. It can be potentially explained that the entity alignment task evaluates alignment accuracy across different KGs (e.g., 𝐺 𝑥 and 𝐺 𝑦 ) rather than within one KG (e.g., 𝐺 𝑥 ). Even though we might sample duplicated entities in 𝐺 𝑥 and push them away, it might generate only limited influence on their similarities with the target entity 𝑦 in 𝐺 𝑦 .</p><p>Impact of the quality of pre-trained uni-space embedding.</p><p>To clarify the influence of different pre-trained word embeddings, we conduct an experiment that replaces the LaBSE embedding we use in SelfKG with FastText embeddings, which is widely used in baseline methods.</p><p>First, comparing FastText results with and without training, the after-training results are consistently higher by 8.5%-17.2% than before-training results in Table <ref type="table" target="#tab_2">5</ref>. These results also outperform all previous unsupervised baselines, indicating the effectiveness of SelfKG when being applied to any embedding initialization.</p><p>Second, comparing FastText results with LaBSE results, we also confirm that a stronger pre-trained language model like LaBSE will boost SelfKG's performance compared to FastText word embeddings. This is also the case in baseline methods, such as HMAN <ref type="bibr" target="#b42">[43]</ref> and BERT-INT <ref type="bibr" target="#b34">[35]</ref>, who leverage multi-lingual BERT as their encoders. Despite better pre-trained embeddings, in our ablation study (Cf. Table <ref type="table" target="#tab_2">4 and Table 5</ref>), we show that the "-w.o. RSM + neighbors" (i.e. LaBSE before SelfKG training) can be significantly improved by 6.4%-28.2% with SelfKG, which demonstrates the usefulness of our method.</p><p>Impact of relation information and multi-hop structure information. To better examine whether relational structural information will help in the self-supervised setting (which might have different results from previous supervised observations), we first conduct experiments on incorporating multi-hop information and then integrate relation information. Table <ref type="table" target="#tab_3">6</ref> shows the results on DBP15K when multi-hop neighbors (more specifically, 20-nearestneighbor subgraph) are leveraged instead of 1-hop ones. We observe that the performance is actually worse. This is probably because of the heterogeneity of different knowledge graphs and also because the neighbor noises may be amplified in a self-supervised setting. Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@ Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@ Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@ Based on the 1-hop restriction, as for incorporating relation information, we combine relation name embeddings and their corresponding tail entity name embeddings as the new 1-hop neighbor embeddings. We can see that the results are improved by a slight margin with relation information, which demonstrates that relational information is of a little usefulness.</p><p>Impact of hyper-parameters. The main hyper-parameters in SelfKG are 1) negative queue size and batch size (which influence the capacity of negative samples), and 2) momentum coefficient 𝑚 that controls SelfKG's training stability.</p><p>As pointed out in Theorem 1 and 2, the error term of contrastive loss decays with O (𝑀 −2/3 ), which indicates the importance of enlarging the number of negative samples. Fixing batch size to 64, we change the sizes of the negative queue and derive the curve in Figure <ref type="figure" target="#fig_21">4</ref>. The performance increase is not obvious when queue size is between 10 0 and 10 1 ; but as it grows to 10 2 , the improvement becomes significant. Fixing queue size to 64, along the increase of batch size, the improvement is more stable ranging from 10 1 to 10 2 .</p><p>For momentum coefficient 𝑚, we discover that a properly large 𝑚 such as 0.9999 is usually better for SelfKG. Besides, a proper 𝑚 is also critical for better training stability (Cf. Figure <ref type="figure" target="#fig_21">4</ref>). A small momentum leads to faster convergence, but also representation collapse and consequent poorer performance. A too-large momentum (e.g., 0.99999) converges too slow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">SelfKG v.s. Supervised SelfKG</head><p>In practice, we often encounter low-data resource situations where there is very limited supervision. To justify SelfKG's scalability, we compare self-supervised SelfKG with its supervised counterpart SelfKG (sup) on DBP15K zh_en across different data resource settings. SelfKG (sup) follows the conventional supervised entity alignment methods using Absolute Similarity Metric as presented in Eq. 3.</p><p>In our preliminary experiment, we find that the original DBP15k's data split (30% labels for training and 70% for testing) is not sufficient to present SelfKG (sup)'s advantage, resulting in a Hit@1 of 0.744 for SelfKG (sup) and 0.745 for SelfKG. So we construct a new split of DBP15K zh_en that contains 20% for testing and 80% for constructing different sizes of training set. The result is presented in Figure <ref type="figure" target="#fig_7">5</ref>, where the horizontal axis indicates the ratio of training labeled entities for SelfKG (sup) to all entities. We observe that SelfKG is approximately comparable to SelfKG (sup) using an amount of 25% labeled entities, which accords with our observation in the aforementioned preliminary experiment. When using less than 25% amount of labeled entities, SelfKG performs much better than SelfKG (sup), which demonstrates the effectiveness of SelfKG in low supervised data resource settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Entity alignment. Entity alignment, also named entity resolution, ontology alignment, or schema matching, is a fundamental problem in the knowledge graph community <ref type="bibr" target="#b47">[48]</ref> that has been researched for decades. Before the deep learning era, most approaches focus on designing proper similarity factors and Bayesian-based probability estimation. <ref type="bibr" target="#b33">[34]</ref> develops the idea of transforming the alignment into minimizing the risk of decision making. RiMOM <ref type="bibr" target="#b19">[20]</ref> proposes a multi-strategy ontology alignment framework, which leverages primary similarity factors with the Cartesian product to align concepts unsupervisedly. <ref type="bibr" target="#b20">[21]</ref> argues for rule-based linking and design  a rule discovery algorithm. <ref type="bibr" target="#b52">[53]</ref> develops an efficient multi-network linking algorithm based on the factor graph model. Recently, embedding-based methods have drawn people's attention due to their flexibility and effectiveness. TransE <ref type="bibr" target="#b0">[1]</ref> is the very beginning to introduce the embedding method to represent relational data. <ref type="bibr" target="#b3">[4]</ref> develops the knowledge graph alignment strategy based on TransE. <ref type="bibr" target="#b29">[30]</ref> argues for a cross-lingual entity alignment task and constructs the dataset from DBpedia. <ref type="bibr" target="#b50">[51]</ref> proposes to embed entity ego-network to vectors for the alignment. <ref type="bibr" target="#b38">[39]</ref> introduces the GCN to model both the entity and relation in knowledge graphs to perform the alignment. <ref type="bibr" target="#b35">[36]</ref> argues that we can use attributes and structure to supervise each other mutually. BERT-INT <ref type="bibr" target="#b34">[35]</ref> proposes an interactive entity alignment strategy based on BERT and substantially improves the supervised entity alignment performance on public benchmarks. <ref type="bibr" target="#b49">[50]</ref> designs heterogeneous graph attention networks to perform large-scale entity linking across the open academic graph.</p><p>However, most embedding-based methods nowadays rely heavily on supervised data, hindering their application in real web-scale noisy data. As a prior effort, in <ref type="bibr" target="#b21">[22]</ref> authors present self-supervised pre-training for concept linking but with downstream supervised classification. In this work, we endeavor to investigate the potential of a completely self-supervised approach without using labels to reduce the cost of entity alignment while improving performance.</p><p>Self-supervised learning. Self-supervised learning <ref type="bibr" target="#b22">[23]</ref>, which learns the co-occurrence relationships in the data without human supervision, is a data-efficient and powerful machine learning paradigm. We can divide them into two categories: generative and contrastive.</p><p>Generative self-supervised learning is often related to pretraining. For instance, BERT <ref type="bibr" target="#b5">[6]</ref>, GPT <ref type="bibr" target="#b26">[27]</ref>, XLNet <ref type="bibr" target="#b44">[45]</ref> and so on <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref> develop the field of language model pre-training, which boost the development of natural language processing. The contrastive self-supervised learning is recently proposed by MoCo and SimCLR <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16]</ref> in computer vision to conduct successful vision pretraining. The core idea of leveraging the instance discrimination and contrastive loss has been proved to be especially useful for downstream classification tasks. Self-supervised learning has also been applied to graph pre-training tasks, such as in GCC <ref type="bibr" target="#b25">[26]</ref>, the authors pre-train the structural representation of subgraphs using contrastive learning and transfer the model to other graphs. <ref type="bibr" target="#b46">[47]</ref> proposes adding augmentations to sampled graphs following Sim-CLR's strategy to promote graph pre-training performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we re-examine the use and effect of supervision in the entity alignment problem, which targets aligning entities with identical meanings across different knowledge graphs. Based on the three insights we derive-uni-space learning, relative similarity metric, and self-negative sampling, we develop a self-supervised entity alignment algorithm-SelfKG-to automatically align entities without training labels. The experiments on two widely-used benchmarks DWY100K and DBP15K show that SelfKG is able to beat or match most of the supervised alignment methods which leverage the 100% of the training datasets. Our discovery indicates a huge potential to get rid of supervision in the entity alignment problem, and more studies are expected for a deeper understanding of self-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A.1 Proof to Proposition 1</head><p>Proof. Notice that 𝑥 𝑥+𝑎 is increasing w.r.t 𝑥 ∈ R, 𝑥 ≥ 0, where 𝑎 ∈ R, 𝑎 &gt; 0 is a constant. Then we have:</p><formula xml:id="formula_52">L RSM = E {𝑦 − 𝑖 } 𝑀 𝑖=1 i.i.d. ∼ 𝑝y       − log 𝑒 1 𝜏 𝑒 1 𝜏 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏       ≤ E (𝑥,𝑦) ∼𝑝pos {𝑦 − 𝑖 } 𝑀 𝑖=1 i.i.d. ∼ 𝑝y       − log 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏       = L ASM .<label>(8)</label></formula><p>On the other hand,  Proof. We follow the outline of Wang's proof <ref type="bibr" target="#b37">[38]</ref>. where the last equality is by the S.L.L.N. (Strong Law of Large Numbers) and the Continuous Mapping Theorem.</p><formula xml:id="formula_53">L ASM ≤ E (𝑥,𝑦) ∼𝑝pos {𝑦 − 𝑖 } 𝑀 𝑖=1 i.i.d. ∼ 𝑝y        − log 𝑒 min 𝑓 (𝑥 ) T 𝑓<label>(</label></formula><p>The convergence speed is derived as follows, where 𝜆 ≥ 1 and −1 ≤ 𝑓 (𝑥) 𝑇 𝑓 (𝑦), 𝑓 (𝑥) 𝑇 𝑓 (𝑦 − 𝑖 ) ≤ 1.</p><p>For one side: </p><formula xml:id="formula_54">L ASM|𝜆,</formula><p>where the second inequality follows the Jensen Inequality based on the the concavity of log.</p><p>For the other side: </p><formula xml:id="formula_56">𝑀 − 2 3 𝑒 1 𝜏 𝑒 1 𝜏 − 𝑒 − 1 𝜏 ,<label>(12)</label></formula><p>where the first inequality follows an application of Lagrange's mean-value theorem, and the last inequality follows the bound from Chebychev's inequality, which can refer to <ref type="bibr" target="#b37">[38]</ref>.</p><p>Therefore, The noisy ASM still converges to the same limit of ASM with absolute deviation decaying in O (𝑀 −2/3 ), combing the derivations of both sides above. □</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof to Theorem 3</head><p>Let Ω x , Ω y be the space of knowledge graph triplets, 𝑛 ∈ N. Let {𝑥 − 𝑖 : Ω x → R 𝑛 } 𝑀 𝑖=1 , {𝑦 − 𝑖 : Ω y → R 𝑛 } 𝑀 𝑖=1 be i.i.d random variables with distribution 𝑝 x , 𝑝 y . S 𝑑−1 denotes the uni-sphere in R 𝑛 . If there exists a random variable 𝑓 : R 𝑛 → S 𝑑−1 s.t. 𝑓 (𝑥 − 𝑖 ), 𝑓 (𝑦 − 𝑖 ) satisfy the same distribution on S 𝑑−1 , 1 ≤ 𝑖 ≤ 𝑀., then we have Proof.  </p><p>Then 𝑆 = 1 + 𝑇 , therefore</p><formula xml:id="formula_58">𝑆 ≤ 1 + 𝑒 1 𝜏 − 𝑒 − 1 𝜏 𝜆 𝑀 𝑒 1 𝜏 + 𝑒 − 1 𝜏 &lt; 1 + 𝑒 1 𝜏 − 𝑒 − 1 𝜏 𝑒 − 1 𝜏 = 1 + 𝑒 2 𝜏 − 1 = 𝑒 2 𝜏 .<label>(17)</label></formula><p>Therefore, |log 𝑆 | &lt; 2 𝜏 . By the S.L.L.N., lim 𝑀→∞ 𝑇 = 0, therefore, lim 𝑀→∞ log 𝑆 = 0. Because |log 𝑆 | is bounded, with Dominated Covergence Theorem, the sign of mathematical expectation (i.e. integral) can be exchanged with the sign of limit: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>□</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Details on Implementation</head><p>A.4.1 Dataset. For both DWY100K <ref type="foot" target="#foot_0">3</ref> and DBP15K <ref type="foot" target="#foot_1">4</ref> datasets we used, we do simple data processing on the original datasets built in BootEA <ref type="bibr" target="#b30">[31]</ref> and JAPE <ref type="bibr" target="#b29">[30]</ref> respectively. The process of data processing is as follows: Firstly, we remove the redundant prefixes of the URLs representing the entities, leaving the meaningful entity names at the end. For example, in DBP15K zh_en dataset, there is an entity represented by "http://dbpedia.org/resource/2012_Summer_Olympics". We remove the substring in front of "2012_Summer_Olympics" to remove the useless part. Then we replace the underscores used to connect words in the entity names with spaces, so that the entities can be represented by their original entity names. In addition, we replace the indices that represent entities in DWY100K dbp_wd (e.g., Q123) with strings of entity names. The purpose of this step is to make the entity names as original as possible to let our model better extract the character-level information and the semantic-level information with useful data. Then, we need to map every entity to a unique index in every pair of KGs respectively. The pairs of KGs are the subdatasets of DWY100K and DBP15K: DWY100K dbp_wd , DWY100K dbp_yg , DBP15K zh_en , DBP15K ja_en and DBP15K fr_en . We use DBP15K dataset provided in <ref type="bibr" target="#b41">[42]</ref> and the DWY100K dataset provided in <ref type="bibr" target="#b29">[30]</ref> as our original dataset and follow the indices they created in our experiments since they have already done this processing step.</p><p>As for obtaining 1-hop neighbors, we treat the KGs as undirected graphs, that means we use the relational triples in the datasets to find all the entities connected to an entity regardless of the direction of the connection.</p><p>Finally, we reconstruct Dataset and use DataLoader of Pytorch's torch.utils.data package to packet our data and create batches. Because we do not use any labels in our model for training, we set the indices of the entities as the y data which is usually used to contain the labels in Dataset package. As for the x data which is the training data in Dataset package, we set the entity names of the center entities and the corresponding neighbors with the adjacency matrix of the center entities as the x data.</p><p>A.4.2 Implementation Notes. Our model is implemented using Python package Pytorch 1.7.1. <ref type="foot" target="#foot_2">5</ref> The experiments were conducted on a GNU/Linux server with 8 Tesla V100 SXM2 GPU and 32G GPU RAM mainly, and also 56 Intel(R) Xeon(R) Gold 5120 CPU(2.20GHz), 500G RAM.</p><p>For both experiments on DWY100K and DBP15K, we randomly select 5% links from the training set in the original datasets as our validation set and evaluate our model's performance both on the validation set and the testing set. We stop the training progress once our model reaches the best performance on the validation set and record Hit@1 and Hit@10 results on the testing set.</p><p>A.4.3 Similarity Search. In order to evaluate our model on the validation set and the test set efficiently, we apply Faiss<ref type="foot" target="#foot_3">6</ref> , a library for efficient similarity search.</p><p>In the evaluation period, we apply the IndexFlatL2 as indexer, which is based on ℓ 2 distance. Once the indices are built, via the kd-tree algorithm used in Faiss, the top 1 and top 10 closest entities in the target KG of every entity in the source KG can be found efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Runtime</head><p>On the time efficiency of using large number negative samples in SelfKG, by leveraging multiple negative queues with Moco <ref type="bibr" target="#b15">[16]</ref>, the running time of SelfKG is significantly reduced even when the sample size is large, making it similar to the common negative sampling method adopted in state-of-the-art baseline methods. Details are discussed in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Limitations</head><p>There are mainly two limitations in SelfKG. Firstly, SelfKG requires good embeddings to ensure the unified representation for both KGs. As we clarified in Section 4.2, we confirm that a better pre-trained language model like LaBSE will boost the performance of SelfKG. This issue is also commonly faced by other embedding-based entity alignment methods. Secondly, SelfKG still underperforms some supervised state-of-the-art methods. Some of the supervised methods such as BERT-INT <ref type="bibr" target="#b34">[35]</ref> can reach almost an accuracy of 100% on both DBP15K and DWY100K, which outperforms our self-supervised solution. The gap is expected since supervision does provide much useful information for the alignment task. The ultimate goal of selfsupervised methods is to match or even beat supervised methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Hit@1 on DWY100K and DBP15K for SelfKG (0% of training labels) and SOTA supervised (100% of training labels) entity alignment. Without using any labels, the selfsupervised SelfKG outperforms most of supervised models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>n H 2 n 0 a 5 2 e 7 a R i 7 + 5 T M v a O S t y c 7 z b X V K D w 5 / t X A S d o 0 Y Y N M J W g D L 2 s I 9 D a u M x T n G B J t r O 8 h F P e P b O P e n p z 6 v g l Y o 7 s Y t v w 8 s / A D O S j k 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n c h Y R V Z W / B e s O H k X j 5 U e e r U b p C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>n H 2 n 0 a 5 2 e 7 a R i 7 + 5 T M v a O S t y c 7 z b X V K D w 5 / t X A S d o 0 Y Y N M J W g D L 2 s I 9 D a u M x T n G B J t r O 8 h F P e P b O P e n p z 6 v g l Y o 7 s Y t v w 8 s / A D O S j k 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O 5 r q h</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>n H 2 n 0 a 5 2 e 7 a R i 7 + 5 T M v a O S t y c 7 z b X V K D w 5 / t X A S d o 0 Y Y N M J W g D L 2 s I 9 D a u M x T n G B J t r O 8 h F P e P b O P e n p z 6 v g l Y o 7 s Y t v w 8 s / A D O S j k 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n c h Y R V Z W / B e s O H k X j 5 U e e r U b p C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>9 d o 5 G</head><label>5</label><figDesc>m d t 3 b w M T f T K Z m 9 T 6 y u T n e 9 S 1 p w P 7 P c c 6 C 5 m H F 9 y p + / a h c P b W j L m I X e z i g e R 6 j i g v U 0 D D e j 3 j C s 3 P u c E c 6 + W e q U 7 C a H X x b z s M H a x y P f Q = = &lt; / l a t e x i t &gt; y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N e 2 1 9 F M G E 9 f 9 p 0 J y c n z r b + N u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>1 &lt;</head><label>1</label><figDesc>r 4 r l x 1 u x v 3 l P j q e 8 2 o X9 o v c b E K t w S + 5 d u l v l f n a 5 F Y Y B T U w O n m j L D 6 O o i 6 5 K b r u i b u 1 + q U u S Q E a d x n + K C c G S U s z 6 7 R i N N 7 b q 3 g Y m / m U z N 6 n 1 k c 3 O 8 6 1 v S g P 2 f 4 5 w H r a O q 7 1 X 9 x n G l d m Z H X c Q e 9 n F I 8 z x B D Z e o o 2 m 8 H / G E Z + f C i R 3 p 5 J + p T s F q d v F t O Q 8 fb X y P f g = = &lt; / l a t e x i t &gt; y l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; /l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>6 z d T x T D s r 9 j f v s f Z U d 8 v p 7 x V e A b E S 1 8 T + p Z t k / l e n a p E Y 4 k j X I K i m W D O q O l a 4 Z L o r 6 u b m l 6 o k O c T E K T y g e E K Y a e W k z 6 b W p L p 2 1 V t X x 9 9 0 p m L V n h W 5 G d 7 V L W n A 9 s 9 x T o P W f t 2 2 6 v b 5 Q a 1 x X I y 6 j C 1 s Y 5 f m e Y g G T t G E Q 9 4 C j 3 j C s 3 F m x M a d k X + m G q V C s 4 l v y 3 j 4 A K i W k M E = &lt; /l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b T 3 Z C T 4 v P 4 v a F 4 E 9 x q w s 9 6 w Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 Y y k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + u V 2 I 5 I c O W f D x d 3 E z / I 1 d 9 F S D 7 k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 Y y k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + u V 2 I 5 I c O W f D x d 3 E z / I 1 d 9 F S D 7 k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>7 s 0 z 0 P U c I o 6 H P I W e M Q T n o 0 z I z Z u j d F n q l H I N Z v 4 t o y H D 6 Y y k M A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + u V 2 I 5 I c O W f D x d 3 E z / I 1 d 9 F S D 7 k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A conceptual comparison of SelfKG and supervised approaches. SelfKG employs the relative similarity metric (RSM) and self-negative sampling to avoid the use of supervision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>L</head><label></label><figDesc>ASM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝y) = E 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 𝜆𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦)/𝜏 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Theorem 3. (Noisy RSM with self-negative sampling) Let Ω x , Ω y be the spaces of KG triples, respectively, {𝑥 − 𝑖 : Ω x → R 𝑛 } 𝑀 𝑖=1 , {𝑦 − 𝑖 : Ω y → R 𝑛 } 𝑀 𝑖=1 be i.i.d random variables with distribution 𝑝 x , 𝑝 y , respectively, and S 𝑑−1 denote the uni-sphere in R 𝑛 . If there exists a random variable 𝑓 : R 𝑛 → S 𝑑−1 s.t. 𝑓 (𝑥 − 𝑖 ) and 𝑓 (𝑦 − 𝑖 ) satisfy the same distribution on S 𝑑−1 , 1 ≤ 𝑖 ≤ 𝑀., we then have: lim 𝑀→∞ | L RSM|𝜆,x (𝑓 ; 𝜏, 𝑀, 𝑝 x ) − L RSM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝 y ) | = 0.(4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The training process of SelfKG. It leverages a negative queue for each KG to provide massive negative samples (up to 4k at a time) for calculating the self-supervised contrastive loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Study on (a) negative queue size, (b) batch size, and (c) momentum on DBP15K zh_en . (c) presents the test Hit@1 curve throughout the training epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: SelfKG vs. SelfKG (sup) on DBP15K. SelfKG works well in a low-data resource setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>lim 𝑀→∞ [ L ASM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝y) − log 𝑀 ] 𝑦) ∼𝑝pos 𝑓 (𝑥) T 𝑓 (𝑦) + E 𝑥 i.i.d. −i.i.d. ∼ 𝑝y 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − )/𝜏</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>≤ 𝑒 1 EE</head><label>1</label><figDesc>lim 𝑀→∞ [ L ASM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝y) − log 𝑀 ] − [ L ASM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝y) − log 𝑀 ] 𝑦 −i.i.d. ∼ 𝑝y 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − ) /𝜏 − 𝜆 𝑀 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦) /𝜏 + 𝑦 −i.i.d. ∼ 𝑝y 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − ) /𝜏 −</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>lim𝑀→∞L</head><label></label><figDesc>RSM|𝜆,x (𝑓 ; 𝜏, 𝑀, 𝑝 x ) − L RSM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝 y ) = 0.<ref type="bibr" target="#b12">(13)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>log 1 + 1 𝜏 1 𝜏 1 𝜏𝜆𝑒 1 𝜏 + 𝑀𝑒 − 1 𝜏 𝜆𝑒 1 𝜏 + 𝑀𝑒 1 𝜏≥ 1 𝜏𝑖 ) /𝜏 1 𝑀 𝜆𝑒 1 𝜏 1 𝜏 − 𝑒 − 1 𝜏 𝜆 𝑀 𝑒 1 𝜏 + 𝑒 − 1</head><label>111111111111111</label><figDesc>𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑥 − 𝑖 ) /𝜏 − 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 ) /𝜏 𝜆𝑒 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 ) + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑥 − 𝑖 ) /𝜏 𝜆𝑒 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 ) /𝜏 , then 𝑆 ≥ 𝑒 − 2 𝜏 . (15) Let 𝑇 = 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑥 − 𝑖 )/𝜏 − 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏 𝜆𝑒 + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏 , therefore |𝑇 | = 1 𝑀 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑥 − 𝑖 ) /𝜏 − 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − + 𝑖 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 ) /𝜏 ≤ 𝑒 𝜏 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>lim 𝑀→∞ L RSM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝x) − L RSM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝y)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 :</head><label>4</label><figDesc>Ablation Study of SelfKG's components and strategies on DWY100K and DBP15K.</figDesc><table><row><cell>Model</cell><cell>DWY100K dbp_wd DWY100K dbp_yg</cell><cell>DBP15K zh_en</cell><cell>DBP15K ja_en</cell><cell>DBP15K fr_en</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 :</head><label>5</label><figDesc>Ablation Study on quality of pre-trained uni-space embedding on DWY100K and DBP15K.</figDesc><table><row><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 :</head><label>6</label><figDesc>Ablation Study of multi-hop structure and relation information on DBP15K.</figDesc><table><row><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>𝑦) /𝜏 𝑒 min 𝑓 (𝑥 ) T 𝑓 (𝑦) /𝜏 + 𝑖 𝑒</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 ) /𝜏</cell><cell>      </cell></row><row><cell>≤</cell><cell cols="3">E (𝑥,𝑦) ∼𝑝pos {𝑦 − 𝑖 } 𝑀 𝑖=1 i.i.d. ∼ 𝑝y       </cell><cell>− log</cell><cell>𝑒</cell><cell>𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏</cell><cell>      </cell></row><row><cell cols="2">≤ L RSM +</cell><cell>𝜏 1</cell><cell cols="2">1 −</cell><cell>min</cell></row></table><note>min 𝑓 (𝑥 ) T 𝑓 (𝑦) /𝜏 𝑒 1 𝜏 + 𝑖 𝑒 (𝑥,𝑦)∼𝑝pos 𝑓 (𝑥) T 𝑓 (𝑦) .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>x ( 𝑓 ; 𝜏, 𝑀, 𝑝y) − log 𝑀 − lim</figDesc><table><row><cell>≤</cell><cell></cell><cell></cell><cell></cell><cell cols="2">E</cell><cell></cell><cell></cell><cell>log</cell><cell>𝜆</cell><cell>𝑒 1/𝜏 +</cell><cell>1</cell><cell>∑︁</cell><cell>𝑒</cell><cell>𝑓 (𝑥 ) T 𝑓 (𝑦 − 𝑖 )/𝜏</cell></row><row><cell></cell><cell></cell><cell></cell><cell>𝑥</cell><cell cols="3">i.i.d. ∼ 𝑝x</cell><cell></cell><cell></cell><cell>𝑀</cell><cell>𝑀</cell><cell>𝑖</cell></row><row><cell></cell><cell cols="5">{𝑦 − 𝑖 } 𝑀 𝑖=1</cell><cell cols="3">i.i.d. ∼ 𝑝y</cell></row><row><cell cols="7">− E 𝑥 i.i.d. ∼ 𝑝x       log</cell><cell cols="2">E 𝑦 −i.i.d. ∼ 𝑝y</cell><cell>𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − )/𝜏</cell><cell>     </cell></row><row><cell cols="5">≤ E 𝑥 i.i.d. ∼ 𝑝x      </cell><cell cols="3">log</cell><cell cols="2">E 𝑦 −i.i.d. ∼ 𝑝y</cell><cell>𝜆 𝑀</cell><cell>𝑒 1/𝜏 + 𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − )/𝜏 − log</cell><cell>E 𝑦 −i.i.d. ∼ 𝑝y</cell><cell>𝑒 𝑓 (𝑥 ) T 𝑓 (𝑦 − ) /𝜏</cell><cell>     </cell></row><row><cell cols="4">≤ E</cell><cell></cell><cell></cell><cell>𝜆</cell><cell cols="2">𝑒 2/𝜏</cell></row><row><cell></cell><cell>𝑥</cell><cell cols="3">∼ 𝑝x i.i.d.</cell><cell></cell><cell>𝑀</cell><cell></cell><cell></cell></row><row><cell>=</cell><cell cols="2">𝜆</cell><cell cols="3">𝑒 2/𝜏 ,</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">𝑀</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>𝑀→∞[ L ASM|𝜆,x ( 𝑓 ; 𝜏, 𝑀, 𝑝y) − log 𝑀 ]</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0">Can be downloaded from https://github.com/nju-websoft/BootEA</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1">Can be downloaded from https://github.com/syxu828/Crosslingula-KG-Matching</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2">More details can be found in our code https://github.com/THUDM/SelfKG</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3">https://github.com/facebookresearch/faiss</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work is supported by the NSFC for Distinguished Young Scholar (61825602), NSFC (61836013), and Tsinghua-Bosch Joint ML Center. Haoyun Hong is supported by Tsinghua University Initiative Scientific Research Program and DCST Student Academic Training Program.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>(2) the strategy of self-negative sampling that furthers Eq. 2 into Eq. 5 to avoid false-negative samples; (3) the extension of MoCo <ref type="bibr" target="#b15">[16]</ref> to two negative queues to support an efficient usage of massive negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT</head><p>We evaluate SelfKG on two widely-acknowledged public benchmarks: DWY100K and DBP15K. DWY100K is a monolingual dataset and DBP15K is a multi-lingual dataset.</p><p>DWY100K. The DWY100K dataset used here is originally built by <ref type="bibr" target="#b30">[31]</ref>. DWY100K consists of two large datasets: DWY100K dbp_wd (DBpedia to Wikidata) and DWY100K dbp_yg (DBpedia to YAGO3). Each dataset contains 100,000 pairs of aligned entities. However, the entity in the "wd" (Wikidata) part of DWY100K dbp_wd are represented by indices (e.g., Q123) instead of URLs containing entity names, and we search their entity names via the Wikidata 1 API for python.</p><p>DBP15K. The DBP15K dataset is originally built by <ref type="bibr" target="#b29">[30]</ref> 2 and translated into English by <ref type="bibr" target="#b41">[42]</ref>. The DBP15K consists of three crosslingual datasets: DBP15K zh_en (Chinese to English), DBP15K ja_en (Japanese to English) and DBP15K fr_en (French to English). All three datasets are created from multi-lingual DBpedia, and each contains 15,000 pairs of aligned entities. We report results on both original and translated version. The statistics of DWY100K and DBP15K we use in our work are shown in Table <ref type="table">1</ref>. Beyond basic information, we also present a study on datasets' average (1-hop) neighbor similarity, which is the ratio of aligned neighbors of a pair of aligned entities, indicating how noisy the neighborhood information is. We observe that DWY100K's neighborhood information is quite useful, while DBP15K's neighborhood information can be very noisy.</p><p>Experiment Setup. We follow the original split of DWY100K <ref type="bibr" target="#b30">[31]</ref> and DBP15K <ref type="bibr" target="#b29">[30]</ref> which are shown in Table <ref type="table">1</ref>. For SelfKG, we randomly take out 5% from the original training set as a dev set for early stopping. We use Hit@𝑘 (𝑘 = 1, 10) to evaluate our model's performance as most works do. The similarity score is calculated using the ℓ 2 distance of two entity embeddings. The batch size is set to 64, momentum 𝑚 is set to 0.9999, temperature 𝜏 is set to 0.08, and queue size is set to 64. We use a learning rate of 10 −6 with Adam on a Ubuntu server with NVIDIA V100 GPUs (32G).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>In this part, we report the results of SelfKG and baselines on DWY100K and DBP15K. For all the baselines, we take the reported scores from the corresponding papers, or directly from the tables in BERT-INT <ref type="bibr" target="#b34">[35]</ref>, CEAFF <ref type="bibr" target="#b48">[49]</ref> or NAEA <ref type="bibr" target="#b54">[55]</ref>. According to the used proportion of the training labels, we categorize all the models into two types:</p><p>• Supervised: 100% of the aligned entity links in the training set is leveraged • Unsupervised &amp; Self-supervised: 0% of the training set is leveraged.</p><p>Overall performance on DWY100K. From Table <ref type="table">2</ref>, we observe that SelfKG outperforms all the supervised and unsupervised models except for supervised CEAFF <ref type="bibr" target="#b48">[49]</ref> and BERT-INT <ref type="bibr" target="#b34">[35]</ref>. However, without any supervision, SelfKG only falls behind supervised stateof-the-art CEAFF on DWY100K dbp_wd by a minimal margin of 1.2%. The reason why DWY100K dbp_yg enables SelfKG to achieve such high accuracy is that the names of its aligned entity pairs are of great similarity respectively, which makes this dataset more easier. The inspiring result implies that at least for monolingual datasets like DWY100K, supervision is not quite necessary for entity alignment.</p><p>Overall performance on DBP15K. For the DBP15K dataset, we find that different baselines use different versions of DBP15K in implementation. For example, BERT-INT <ref type="bibr" target="#b34">[35]</ref> uses the original multi-lingual version built by <ref type="bibr" target="#b29">[30]</ref>, while some other methods including RDGCN <ref type="bibr" target="#b39">[40]</ref> and DGMC <ref type="bibr" target="#b9">[10]</ref> uses machine translation (Google translation) to translate non-English datasets (i.e., zh, ja, fr) of DBP15K into English. If DBP15K is translated, it should not be considered as a multi-lingual setting to some extend. For fair comparison, we report SelfKG's results on both settings.</p><p>Table <ref type="table">3</ref>: Results on DBP15K. Methods marked with " * " use a translated version of DBP15K <ref type="bibr" target="#b41">[42]</ref>.Bold results are our best result; underline results are best baseline results.</p><p>Model DBP15K zh_en DBP15K ja_en DBP15K fr_en macro Hit@1 Hit@1 Hit@10 Hit@1 Hit@10 Hit@1 Hit@10 Supervised MTransE <ref type="bibr" target="#b3">[4]</ref> 0 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-Channel Graph Neural Network for Entity Alignment</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1452" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge Alignment</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<editor>PAKDD</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multilingual knowledge graph embeddings for cross-lingual knowledge alignment</title>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingtao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">All nlp tasks are generation tasks: A general pretraining framework</title>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10360</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Knowledge graph based search system</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eder</forename></persName>
		</author>
		<idno>App. 13/404</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">109</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">US Patent</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Fangxiaoyu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01852</idno>
		<title level="m">Language-agnostic bert sentence embedding</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep Graph Matching Consensus</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to exploit long-term relational dependencies in knowledge graphs</title>
		<author>
			<persName><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2505" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey on knowledge graph-based recommender systems</title>
		<author>
			<persName><forename type="first">Qingyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIStats</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Pre-trained models: Past, present and future</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<publisher>AI Open</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A joint embedding method for entity alignment of knowledge bases</title>
		<author>
			<persName><forename type="first">Yanchao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCKS</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised entity alignment via joint knowledge embedding model and cross-graph model</title>
		<author>
			<persName><forename type="first">Chengjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2723" to="2732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">AliMeKG: Domain Knowledge Graph Construction and Application in E-commerce</title>
		<author>
			<persName><forename type="first">Feng-Lin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hehong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiqing</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2581" to="2588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rimom: A dynamic multistrategy ontology alignment framework</title>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiong</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1218" to="1232" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rule-based method for entity resolution</title>
		<author>
			<persName><forename type="first">Lingli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="250" to="263" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">OAG_know: Self-supervised Learning for Linking Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jibing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Self-supervised learning: Generative or contrastive</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Knowledge graph refinement: A survey of approaches and evaluation methods</title>
		<author>
			<persName><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="489" to="508" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Semisupervised entity alignment via knowledge graph embedding with awareness degree difference</title>
		<author>
			<persName><forename type="first">Shichao</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Hoehndorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangliang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3130" to="3136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Gcc: Graph contrastive coding for graph neural network pre-training</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno>SIGKDD. 1150-1160</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modeling multi-mapping relations for precise cross-lingual entity alignment</title>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment via joint attribute-preserving embedding</title>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bootstrapping Entity Alignment with Knowledge Graph Embedding</title>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="4396" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Transedge: Translating relation-contextualized embeddings for knowledge graphs</title>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="612" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Knowledge graph alignment network with gated multi-hop neighborhood aggregation</title>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Using Bayesian decision for ontology mapping</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bangyong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kehong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JWS</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="243" to="262" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">BERT-INT: a BERT-based interaction model for knowledge graph alignment</title>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<idno>IJCAI. 3174-3180</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Entity alignment between knowledge graphs using attribute embeddings</title>
		<author>
			<persName><forename type="first">Jianzhong</forename><surname>Bayu Distiawan Trisedya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cross-lingual knowledge graph alignment via graph convolutional networks</title>
		<author>
			<persName><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingsong</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Yuting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Jointly Learning Entity and Relation Representations for Entity Alignment</title>
		<author>
			<persName><forename type="first">Yuting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="240" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Aligning Cross-Lingual Entities with Multi-Aspect Information</title>
		<author>
			<persName><forename type="first">Hsiu-Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4431" to="4441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">COTSAE: CO-Training of Structure and Attribute Embeddings for Entity Alignment</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasha</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3025" to="3032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with augmentations</title>
		<author>
			<persName><forename type="first">Yuning</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongduo</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A comprehensive survey of entity alignment for knowledge graphs</title>
		<author>
			<persName><forename type="first">Kaisheng</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Weixin</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiuyang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuemin</forename><surname>Lin</surname></persName>
		</author>
		<title level="m">Collective Embedding-based Entity Alignment via Adaptive Features</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Oag: Toward linking large-scale heterogeneous entity graphs</title>
		<author>
			<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2585" to="2595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Mego2vec: Embedding matched ego networks for user alignment across social networks</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengmei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="327" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multi-view Knowledge Graph Embedding for Entity Alignment</title>
		<author>
			<persName><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingbing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5429" to="5435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cosnet: Connecting heterogeneous social networks with local and global consistency</title>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1485" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Iterative Entity Alignment via Joint Knowledge Embeddings</title>
		<author>
			<persName><forename type="first">Ruobing</forename><surname>Hao Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="4258" to="4264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Qiannan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianlong</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1943" to="1949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Relation-Aware Neighborhood Matching Model for Entity Alignment</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhonghai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingpeng</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4749" to="4756" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
