<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dan</forename><forename type="middle">C</forename><surname>Cires</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Alessandro</forename><surname>Giusti</surname></persName>
							<email>alessandrog@idsia.ch</email>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6900</postCode>
									<settlement>Lugano</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6900</postCode>
									<settlement>Lugano</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6900</postCode>
									<settlement>Lugano</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8111EA6BC8AB2E10B58FF4439B7497E6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We address a central problem of neuroanatomy, namely, the automatic segmentation of neuronal structures depicted in stacks of electron microscopy (EM) images. This is necessary to efficiently map 3D brain structure and connectivity. To segment biological neuron membranes, we use a special type of deep artificial neural network as a pixel classifier. The label of each pixel (membrane or nonmembrane) is predicted from raw pixel values in a square window centered on it. The input layer maps each window pixel to a neuron. It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction. The output layer produces a calibrated probability for each class. The classifier is trained by plain gradient descent on a 512 × 512 × 30 stack with known ground truth, and tested on a stack of the same size (ground truth unknown to the authors) by the organizers of the ISBI 2012 EM Segmentation Challenge. Even without problem-specific postprocessing, our approach outperforms competing techniques by a large margin in all three considered metrics, i.e. rand error, warping error and pixel error. For pixel error, our approach is the only one outperforming a second human observer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>How is the brain structured? The recent field of connectomics <ref type="bibr" target="#b1">[2]</ref> is developing high-throughput techniques for mapping connections in nervous systems, one of the most important and ambitious goals of neuroanatomy. The main tool for studying connections at the neuron level is serial-section Transmitted Electron Microscopy (ssTEM), resolving individual neurons and their shapes. After preparation, a sample of neural tissue is typically sectioned into 50-nanometer slices; each slice is then recorded as a 2D grayscale image with a pixel size of about 4 × 4 nanometers (see Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>The visual complexity of the resulting stacks makes them hard to handle. Reliable automated segmentation of neuronal structures in ssTEM stacks so far has been infeasible. A solution of this problem, however, is essential for any automated pipeline reconstructing and mapping neural connections in 3D. Recent advances in automated sample preparation and imaging make this increas- ingly urgent, as they enable acquisition of huge datasets <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>, whose manual analysis is simply unfeasible.</p><p>Our solution is based on a Deep Neural Network (DNN) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> used as a pixel classifier. The network computes the probability of a pixel being a membrane, using as input the image intensities in a square window centered on the pixel itself. An image is then segmented by classifying all of its pixels. The DNN is trained on a different stack with similar characteristics, in which membranes were manually annotated.</p><p>DNN are inspired by convolutional neural networks introduced in 1980 <ref type="bibr" target="#b15">[16]</ref>, improved in the 1990s <ref type="bibr" target="#b24">[25]</ref>, refined and simplified in the 2000s <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b32">33]</ref>, and brought to their full potential by making them both large and deep <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. Lately, DNN proved their efficiency on data sets extending from handwritten digits (MNIST) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>, handwritten characters <ref type="bibr" target="#b10">[11]</ref> to 3D toys (NORB) <ref type="bibr" target="#b12">[13]</ref> and faces <ref type="bibr" target="#b34">[35]</ref>. Training huge nets requires months or even years on CPUs, where high data transfer latency prevented multi-threading code from saving the situation. Our fast GPU implementation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref> overcomes this problem, speeding up single-threaded CPU code by up to two orders of magnitude.</p><p>Many other types of learning classifiers have been applied to segmentation of TEM images, where different structures are not easily characterized by intensity differences, and structure boundaries are not correlated with high image gradients, due to noise and many confounding micro-structures. In most binary segmentation problems, classifiers are used to compute one or both of the following probabilities: (a) probability of a pixel belonging to each class; (b) probability of a boundary dividing two adjacent pixels. Segmentation through graph cuts <ref type="bibr" target="#b6">[7]</ref> uses (a) as the unary term, and (b) as the binary term. Some use an additional term to account for the expected geometry of neuron membranes <ref type="bibr" target="#b22">[23]</ref>.</p><p>We compute pixel probabilities only (point (a) above), and directly obtain a segmentation by mild smoothing and thresholding, without using graph cuts. Our main contribution lies therefore in the classifier itself. Others have used off-the-shelf random forest classifiers to compute unary terms of neuron membranes <ref type="bibr" target="#b21">[22]</ref>, or SVMs to compute both unary and binary terms for segmenting mitochondria <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27]</ref>. The former approach uses haar-like features and texture histograms computed on a small region around the pixel of interest, whereas the latter uses sophisticated rotational <ref type="bibr" target="#b16">[17]</ref> and ray <ref type="bibr" target="#b33">[34]</ref> features computed on superpixels <ref type="bibr" target="#b2">[3]</ref>. Feature selection mirrors the researcher's expectation of which characteristics of the image are relevant for classification, and has a large impact on classification accuracy. In our approach, we bypass such problems, using raw pixel values as inputs. Due to their convolutional structure, the first layers of the network automatically learn to compute meaningful features during training.</p><p>The main contribution of the paper is a practical state-of-the-art segmentation method for neuron membranes in ssTEM data, described in Section 2. It outperforms existing methods as validated in Section 3. The contribution is particularly meaningful because our approach does not rely on problem-specific postprocessing: fruitful application to different biomedical segmentation problems is therefore likely. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>For each pixel we consider two possible classes, membrane and non-membrane. The DNN classifier (Section 2.1) computes the probability of a pixel p being of the former class, using as input the raw intensity values of a square window centered on p with an edge of w pixels-w being an odd number to enforce symmetry. When a pixel is close to the image border, its window will include pixels outside the image boundaries; such pixels are synthesized by mirroring the pixels in the actual image across the boundary (see Figure <ref type="figure" target="#fig_1">2</ref>).</p><p>The classifier is first trained using the provided training images (Section 2.2). After training, to segment a test image, the classifier is applied to all of its pixels, thus generating a map of membrane probabilities-i.e., a new real-valued image the size of the input image. Binary membrane segmentation is obtained by mild postprocessing techniques discussed in Section 2.3, followed by thresholding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">DNN architecture</head><p>A DNN <ref type="bibr" target="#b12">[13]</ref> consists of a succession of convolutional, max-pooling and fully connected layers. It is a general, hierarchical feature extractor that maps raw pixel intensities of the input image into a feature vector to be classified by several fully connected layers. All adjustable parameters are jointly optimized through minimization of the misclassification error over the training set.</p><p>Each convolutional layer performs a 2D convolution of its input maps with a square filter. The activations of the output maps are obtained by summing the convolutional responses which are passed through a nonlinear activation function.</p><p>The biggest architectural difference between the our DNN and earlier CNN <ref type="bibr" target="#b24">[25]</ref> are max-pooling layers <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b30">31]</ref> instead of sub-sampling layers. Their outputs are given by the maximum activation over non-overlapping square regions. Max-pooling are fixed, non-trainable layers which select the most promising features. The DNN also have many more maps per layer, and thus many more connections and weights.</p><p>After 1 to 4 stages of convolutional and max-pooling layers several fully connected layers further combine the outputs into a 1D feature vector. The output layer is always a fully connected layer with one neuron per class (two in our case). Using a softmax activation function for the last layer guarantees that each neuron's output activation can be interpreted as the probability of a particular input image belonging to that class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training</head><p>To train the classifier, we use all available slices of the training stack, i.e., 30 images with a 512×512 resolution. For each slice, we use all membrane pixels as positive examples (on average, about 50000), and the same amount of pixels randomly sampled (without repetitions) among all nonmembrane pixels. This amounts to 3 million training examples in total, in which both classes are equally represented.</p><p>As is often the case in TEM images-but not in other modalities such as phase-contrast microscopy-the appearance of structures is not affected by their orientation. We take advantage of this property, and synthetically augment the training set at the beginning of each epoch by randomly mirroring each training instance, and/or rotating it by ±90 • .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Postprocessing of network outputs</head><p>Because each class is equally represented in the training set but not in the testing data, the network outputs cannot be directly interpreted as probability values; instead, they tend to severely overestimate the membrane probability. To fix this issue, a polynomial function post-processor is applied to the network outputs.</p><p>To compute its coefficients, a network N is trained on 20 slices of the training volume T train and tested on the remaining 10 slices of the same volume (T test , for which ground truth is available). We compare all outputs obtained on T test (a total of 2.6 million instances) to ground truth, to compute the transformation relating the network output value and the actual probability of being a membrane; for example, we measure that, among all pixels of T test which were classified by N as having a 50% probability of being membrane, only about 18% have in fact such a ground truth label; the reason being the different prevalence of membrane instances in T train (i.e. 50%) and in T test (roughly 20%). The resulting function is well approximated by a monotone cubic polynomial, whose coefficients are computed by least-squares fitting. The same function is then used to calibrate the outputs of all trained networks.</p><p>After calibration (a grayscale transformation in image processing terms), network outputs are spatially smoothed by a 2-pixel-radius median filter. This results in regularized of membrane boundaries after thresholding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Foveation and nonuniform sampling</head><p>We experimented with two related techniques for improving the network performance by manipulating its input data, namely foveation and nonuniform sampling (see Figure <ref type="figure" target="#fig_2">3</ref>).</p><p>Foveation is inspired by the structure of human photoreceptor topography <ref type="bibr" target="#b13">[14]</ref>, and has recently been shown to be very effective for improving nonlocal-means denoising algorithms <ref type="bibr" target="#b14">[15]</ref>. It imposes a spatially-variant blur on the input window pixels, such that full detail is kept in the central section (fovea), while the peripheral parts are defocused by means of a convolution with a disk kernel, to remove fine details. The network, whose task is to classify the center pixel of the window, is then forced to disregard such peripheral fine details, which are most likely irrelevant, while still retaining the general structure of the window (context). Nonuniform sampling is motivated by the observation that (in this and other applications) larger window sizes w generally result in significant performance improvements. However, a large w results in much bigger networks, which take longer to train and, at least in theory, require larger amounts of training data to retain their generalization ability. With nonuniform sampling, image pixels are directly mapped to neurons only in the central part of the window; elsewhere, their source pixels are sampled with decreasing resolution as the distance from the window center increases. As a result, the image in the window is deformed in a fisheye-like fashion, and covers a larger area of the input image with fewer neurons.</p><p>Simultaneously applying both techniques is a way of exploiting data at multiple resolutions-fine at the center, coarse in the periphery of the window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Averaging outputs of multiple networks</head><p>We observed that large networks with different architectures often exhibit significant output differences for many image parts, despite being trained on the same data. This suggests that these powerful and flexible classifiers exhibit relatively large variance but low bias. It is therefore reasonable to attempt to reduce such variance by averaging the calibrated outputs of several networks with different architectures.</p><p>This was experimentally verified. The submissions obtained by averaging the outputs of multiple large networks scored significantly better in all metrics than the single networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental results</head><p>All experiments are performed on a computer with a Core i7 950 3.06GHz processor, 24GB of RAM, and four GTX 580 graphics cards. A GPU implementation <ref type="bibr" target="#b11">[12]</ref> accelerates the forward propagation and back propagation routines by a factor of 50.</p><p>We validate our approach on the publicly-available dataset <ref type="bibr" target="#b8">[9]</ref> provided by the organizers of the ISBI 2012 EM Segmentation Challenge <ref type="bibr" target="#b0">[1]</ref>, which represents two portions of the ventral nerve cord of a Drosophila larva. The dataset is composed by two 512 × 512 × 30 stacks, one used for training, one for testing. Each stack covers a 2 × 2 × 1.5 µm volume, with a resolution of 4 × 4 × 50 nm/pixel. For the training stack, a manually annotated ground truth segmentation is provided. For the testing stack, the organizers obtained (but did not distribute) two manual segmentations by different expert neuroanatomists. One is used as ground truth, the other to evaluate the performance of a second human observer and provide a meaningful comparison for the algorithms' performance.</p><p>A segmentation of the testing stack is evaluated through an automated online system, which computes three error metrics in relation to the hidden ground truth:</p><p>Rand error: defined as 1 -F rand , where F rand represents the F 1 score of the Rand index <ref type="bibr" target="#b28">[29]</ref>, which measures the accuracy with which pixels are associated to their respective neurons.</p><p>Warping error: a segmentation metric designed to account for topological disagreements <ref type="bibr" target="#b18">[19]</ref>; it accounts for the number of neuron splits and mergers required to obtain the candidate segmentation from ground truth.</p><p>Pixel error: defined as 1 -F pixel , where F pixel represents the F 1 score of pixel similarity.</p><p>The automated system accepts a stack of grayscale images, representing membrane probability values for each pixel; the stack is thresholded using 9 different threshold values, obtaining 9 binary stacks. For each of the stacks, the system computes the error measures above, and returns the minimum error.</p><p>Pixel error is clearly not a suitable indicator of segmentation quality in this context, and is reported mostly for reference. Rand and Warping error metrics have various strengths and weaknesses, without clear consensus in favor of any. The former tends to provide a more consistent measure but penalizes even slightly misplaced borders, which would not be problematic in most practical applications. The latter has a more intuitive interpretation, but completely disregards non-topological errors.</p><p>We train four networks N1, N2, N3 and N4, with slightly different architectures, and window sizes w = 65 (for N1, N2, N3) and w = 95 (for N4); all networks use foveation and nonuniform sampling, except N3, which uses neither. As the input window size increases, the network depth also increases because we keep the convolutional filter sizes small. The architecture of N4 is the deepest, and is reported in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Training time for one epoch varies from approximately 170 minutes for N1 (w = 65) to 340 minutes for N4 (w = 95). All nets are trained for 30 epochs, which leads to a total training time of several days. However, once networks are trained, application to new images is relatively fast: classifying the 8 million pixels comprising the whole testing stack takes 10 to 30 minutes on four GPUs. Such implementation is currently being further optimized (with foreseen speedups of one order of magnitude at least) in view of application to huge, terapixel-class datasets <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>. The outputs of four such networks are shown in Figure <ref type="figure" target="#fig_3">4</ref>, along with their performance after filtering.</p><p>By averaging the outputs of all networks, results improve significantly. The final result for one slice of the test stack is shown in Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>Our results are compared to competing methods in Table <ref type="table" target="#tab_1">2</ref>.</p><p>Since our pure pixel classifier method aims at minimizing pixel error, Rand and warping errors are just minimized as a side-effect, but never explicitly accounted for during segmentation. In contrast, some competing segmentation approaches adopt different post-processing techniques directly opti-  mizing the rand error. Nevertheless, their results are inferior. But such post-processing techniqueswhich unlike our general classifier are specific to this particular problem-could be successfully applied to finetune our outputs, further improving results. Preliminary results in this direction are encouraging: the problem-specific postprocessing techniques in <ref type="bibr" target="#b19">[20]</ref> and <ref type="bibr" target="#b23">[24]</ref>, operating on our segmentation, reduce the Rand error to measure to 36•10 -3 and 32•10 -3 , respectively. Further research along these lines is planned for the near future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and conclusions</head><p>The main strength of our approach to neuronal membrane segmentation in EM images lies in a deep and wide neural network trained by online back-propagation to become a very powerful pixel classifier with superhuman pixel-error rate, made possible by an optimized GPU implementation more than 50 times faster than equivalent code on standard microprocessors.</p><p>Our approach outperforms all other approaches in the competition, despite not even being tailored to this particular segmentation task. Instead, the DNN acts as a generic image classifier, using raw pixel intensities as inputs, without ad-hoc post-processing. This opens interesting perspectives on applying similar techniques to other biomedical image segmentation tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Left: the training stack (one slice shown). Right: corresponding ground truth; black lines denote neuron membranes. Note complexity of image appearance.</figDesc><graphic coords="2,108.00,81.86,396.03,105.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of our approach (see text).</figDesc><graphic coords="3,147.60,81.86,316.83,94.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Input windows with w = 65, from the training set. First row shows original window (Plain); other rows show effects of foveation (Fov), nonuniform sampling (Nu), and both (Fov+Nu). Samples on the left and right correspond to instances of class Membrane and Non-membrane, respectively. The leftmost image illustrates how a checkerboard pattern is affected by such transformations.</figDesc><graphic coords="4,108.00,487.67,396.03,146.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Above, from left to right: part of a source image from the test set; corresponding calibrated outputs of networks N1, N2, N3 and N4; average of such outputs; average after filtering. Below, the performance of each network, as well as the significantly better performance due to averaging their outputs. All results are computed after median filtering (see text).</figDesc><graphic coords="6,108.00,81.86,396.03,194.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Left: slice 16 of the test stack. Right: corresponding output.</figDesc><graphic coords="7,108.00,81.86,396.00,198.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc><ref type="bibr" target="#b10">11</ref>-layer architecture for network N4, w = 95.</figDesc><table><row><cell>Layer</cell><cell>Type</cell><cell>Maps and neurons</cell><cell>Kernel size</cell></row><row><cell>0</cell><cell>input</cell><cell>1 map of 95x95 neurons</cell><cell></cell></row><row><cell>1</cell><cell>convolutional</cell><cell>48 maps of 92x92 neurons</cell><cell>4x4</cell></row><row><cell>2</cell><cell>max pooling</cell><cell>48 maps of 46x46 neurons</cell><cell>2x2</cell></row><row><cell>3</cell><cell>convolutional</cell><cell>48 maps of 42x42 neurons</cell><cell>5x5</cell></row><row><cell>4</cell><cell>max pooling</cell><cell>48 maps of 21x21 neurons</cell><cell>2x2</cell></row><row><cell>5</cell><cell>convolutional</cell><cell>48 maps of 18x18 neurons</cell><cell>4x4</cell></row><row><cell>6</cell><cell>max pooling</cell><cell>48 maps of 9x9 neurons</cell><cell>2x2</cell></row><row><cell>7</cell><cell>convolutional</cell><cell>48 maps of 6x6 neurons</cell><cell>4x4</cell></row><row><cell>8</cell><cell>max pooling</cell><cell>48 maps of 3x3 neurons</cell><cell>2x2</cell></row><row><cell>9</cell><cell>fully connected</cell><cell>200 neurons</cell><cell>1x1</cell></row><row><cell>10</cell><cell>fully connected</cell><cell>2 neurons</cell><cell>1x1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of our approach and competing algorithms. For comparison, the first two rows report the performance of the second human observer and of a simple thresholding approach.</figDesc><table><row><cell>Second Human Observer</cell><cell>27</cell><cell>344</cell><cell>67</cell></row><row><cell>Simple Thresholding</cell><cell>445</cell><cell>15522</cell><cell>222</cell></row><row><cell>Our approach</cell><cell>48</cell><cell>434</cell><cell>60</cell></row><row><cell>Laptev et al. [24] (1)</cell><cell>65</cell><cell>556</cell><cell>83</cell></row><row><cell>Laptev et al. [24] (2)</cell><cell>70</cell><cell>525</cell><cell>79</cell></row><row><cell>Sumbul et al.</cell><cell>76</cell><cell>646</cell><cell>65</cell></row><row><cell>Liu et al. [26] (1)</cell><cell>84</cell><cell>1602</cell><cell>134</cell></row><row><cell>Kaynig et al. [23]</cell><cell>84</cell><cell>1124</cell><cell>157</cell></row><row><cell>Liu et al. [26] (2)</cell><cell>89</cell><cell>1134</cell><cell>78</cell></row><row><cell>Kamentsky et al. [20]</cell><cell>90</cell><cell>1512</cell><cell>100</cell></row><row><cell>Burget et al. [8]</cell><cell>139</cell><cell>2641</cell><cell>102</cell></row><row><cell>Tan et al. [36]</cell><cell>153</cell><cell>685</cell><cell>88</cell></row><row><cell>Bas et al. [4]</cell><cell>162</cell><cell>1613</cell><cell>109</cell></row><row><cell>Iftikhar et al. [18]</cell><cell>230</cell><cell>16156</cell><cell>150</cell></row></table><note><p><p><p>Group</p>Rand error</p>[•10 -3 ] Warping error [•10 -6 ] Pixel error [•10 -3 ]</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially supported by the Supervised Deep / Recurrent Nets SNF grant, Project Code 140399.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Segmentation of neuronal structures in EM stacks challenge -ISBI</title>
		<ptr target="http://tinyurl.com/d" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://openconnectomeproject.org" />
		<title level="m">The Open Connectome Project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Slic superpixels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
		<idno>149300 EPFL</idno>
		<imprint>
			<date type="published" when="2010-06">June), 2010</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Contextual grouping in a concept: a multistage decision strategy for EM segmentation</title>
		<author>
			<persName><forename type="first">Erhan</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><forename type="middle">G</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical Neural Networks for Image Interpretation</title>
		<author>
			<persName><forename type="first">Sven</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2766</biblScope>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Network anatomy and in vivo physiology of visual cortical neurons</title>
		<author>
			<persName><forename type="first">D</forename><surname>Davi</surname></persName>
		</author>
		<author>
			<persName><surname>Bock</surname></persName>
		</author>
		<author>
			<persName><forename type="middle">A</forename><surname>Wei-Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">L</forename><surname>Kerlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Andermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><forename type="middle">W</forename><surname>Hood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Wetzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">R</forename><surname>Yurgenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyon</forename><forename type="middle">S</forename><surname>Soucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Clay</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">471</biblScope>
			<biblScope unit="issue">7337</biblScope>
			<biblScope unit="page" from="177" to="182" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Trainable Segmentation Based on Local-level and Segmentlevel Feature Extraction</title>
		<author>
			<persName><forename type="first">Radim</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaclav</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Masek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An integrated micro-and macroarchitectural analysis of the drosophila brain by computer-assisted serial section electron microscopy</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Preibisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anchi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Pulokas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Tomancak</surname></persName>
		</author>
		<author>
			<persName><surname>Volker Hartenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1000502</biblScope>
			<date type="published" when="2010">10 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep, big, simple neural nets for handwritten digit recognition</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Claudiu Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3207" to="3220" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convolutional neural network committees for handwritten character classification</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Claudiu Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1250" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Flexible, high performance convolutional neural networks for image classification</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Claudiu Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1237" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-column deep neural networks for image classification</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Claudiu Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human photoreceptor topography</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Curcio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Sloan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hendrickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of comparative neurology</title>
		<imprint>
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="497" to="523" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Foveated self-similarity in nonlocal image filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Boracchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">8291</biblScope>
			<biblScope unit="page">829110</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neocognitron: A self-organizing neural network for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName><forename type="first">Kunihiko</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning rotational features for filament detection</title>
		<author>
			<persName><forename type="first">G</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fleurety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="1582" to="1589" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Detection of Neuronal Structures using a Patch-based Multi-features and Support Vector Machines Learning Algorithm</title>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Iftikhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afzal</forename><surname>Godil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Boundary Learning by Optimization with Topological Constraints</title>
		<author>
			<persName><forename type="first">Viren</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Bollmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">R</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Helmstaedter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">L</forename><surname>Briggman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winfried</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">B</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Mendenhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wickliffe</forename><forename type="middle">C</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><forename type="middle">J</forename><surname>Hayworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Schalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Tapia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Sebastian</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2488" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Segmentation of EM images of neuronal structures using CellProfiler</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Kamentsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Bobby</forename><surname>Kasthuri</surname></persName>
		</author>
		<ptr target="http://openconnectomeproject.org/Kasthuri11/" />
		<title level="m">Mouse Visual Cortex Dataset in the Open Connectome Project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Geometrical consistent 3D tracing of neuronal processes in ssTEM data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kaynig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention-MICCAI</title>
		<imprint>
			<biblScope unit="page" from="209" to="216" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neuron geometry extraction by perceptual grouping in sstem images</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kaynig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2902" to="2909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Segmentation of Neuronal Structures in EM stacks</title>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarvesh</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998-11">November 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neuron Segmentation in EM Images using Series of Classifiers and Watershed Tree</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mojtaba</forename><surname>Seyedhosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Jurrus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Supervoxel-Based Segmentation of Mitochondria in EM Image Stacks With Learned Shape Features</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Knott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A fully automated approach to segmentation of irregularly shaped cellular structures in EM images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention-MICCAI</title>
		<imprint>
			<biblScope unit="page" from="463" to="471" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">336</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hierarchical models of object recognition in cortex</title>
		<author>
			<persName><forename type="first">Maximiliam</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1019" to="1025" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluation of pooling operations in convolutional architectures for object recognition</title>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adreas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Object recognition with features inspired by visual cortex</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Serre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Computer Vision and Pattern Recognition Conference</title>
		<meeting>of Computer Vision and Pattern Recognition Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName><forename type="first">Patrice</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="958" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast ray features for learning irregular shapes</title>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="397" to="404" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Performance and scalability of GPU-based convolutional neural networks</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Strigl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Kofler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Podlipnig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th Euromicro Conference on Parallel, Distributed, and Network-Based Processing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Membrane extraction using two-step classification and post-processing</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changming</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISBI 2012 EM Segmentation Challenge</title>
		<meeting>of ISBI 2012 EM Segmentation Challenge</meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
