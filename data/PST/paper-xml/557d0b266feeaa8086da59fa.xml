<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Edge-Labeling Using Dictionary-Based Relaxation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Edwin</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic and Electrical Engineering</orgName>
								<orgName type="institution">SERC Rutherford Laboratory</orgName>
								<address>
									<addrLine>OX1 1 OQX</addrLine>
									<settlement>Chilton, Didcot, Oxfordshire</settlement>
									<country key="GB">England</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<postCode>GU2</postCode>
									<settlement>Guildford</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MEMBER, IEEE</roleName><forename type="first">Josef</forename><surname>Kittler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic and Electrical Engineering</orgName>
								<orgName type="institution">SERC Rutherford Laboratory</orgName>
								<address>
									<addrLine>OX1 1 OQX</addrLine>
									<settlement>Chilton, Didcot, Oxfordshire</settlement>
									<country key="GB">England</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sxh</forename><forename type="middle">J</forename><surname>En</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic and Electrical Engineer-ing</orgName>
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<postCode>GU2 SXH</postCode>
									<settlement>Guildford</settlement>
									<country key="GB">England</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Kittler</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic and Electrical Engineer-ing</orgName>
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<postCode>GU2 SXH</postCode>
									<settlement>Guildford</settlement>
									<country key="GB">England</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Edge-Labeling Using Dictionary-Based Relaxation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EB5140FB1BA82975D821C5418B7C89CB</idno>
					<note type="submission">received May 17, 1988; revised August 16, 1989. Recommended for acceptance by C. Brown.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Contextual classification</term>
					<term>edge-labeling</term>
					<term>probabilistic relaxation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an improved application of probabilistic relaxation to edge-labeling. The improvement derives from the use of a representation of the edge-process that is internally consistent and which utilizes a more complex description of edge-structure. The particular novelty of the application lies in the use of a dictionary to represent permitted labelings of the entire context-conveying neighborhood of each pixel. This approach is to be contrasted with the use of approximate factorizations which have been employed in previous applications to decompose the neighborhood into object-pairs. We give details of the dictionary approach and the related representation of the edge-process. A comparison with other edge-postprocessing strategies is provided. This leads us to conclude that the dictionary-based approach is a powerful edge-postprocessing tool. It relaxes the demands on the level of filtering that has to be applied to cope with image noise with the benefit of reduced blurring of fine image features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION ROBABILISTIC relaxation is a well known technique</head><p>P for labeling image entities. It relies on iteratively updating the distribution of available probability over a label set for each of the image entities; the crucial computational ingredient is a support function which combines evidence from the context-conveying neighborhood and incorporates prior knowledge of the structure of the labeling task in-hand. One of the earliest applications of probabilistic relaxation to labeling problems of realistic complexity was concerned with edge-enhancement. The application was not widely adopted as a practical edgedetection strategy for reasons of limited performance such as nonuniform convergence and the inability to enhance a realistic variety of edges. It was subsequently shown that these limitations resulted from internal inconsistencies in the specification of the relaxation scheme [ 131, the heuristic nature of the updating process <ref type="bibr" target="#b4">[ 5 ]</ref> , and a limited capacity to accurately represent edge-processes. Recent work has aimed at resolving the problems of consistency and improving representational capacity <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr">[ 121, [ 141.</ref> The rejection of probabilistic relaxation as a means of edge-labeling may therefore be regarded as premature. The objective of this paper is to demonstrate that the early limitations of probabilistic relaxation have been overcome and that it can be used to label edges with a comparable, if not improved, performance to the most advanced existing edge-detection algorithms. In particular we will show the advantages to be gained from using a richer representation of the edge-process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . EdgeLabeling</head><p>Edge-labeling is acknowledged as an important early stage in computer vision. The correspondence between edge tokens in different images is used as the basis of several approaches to stereoscopic reconstruction of depth and also to deriving information about rigid body motion; edge-based descriptions are also used for model matching. In each of these applications, the robustness of the edge-finding process to noise is of vital importance. Robust edge-detection has therefore been a goal of computer vision for almost three decades. The task is a complex one. A complete physical description of the detection process would involve models of the image sensing device, scene illumination effects and of the object-geometry of edge-features. For example, boundary discontinuities between objects in uniformly illuminated scenes are characterized by step-profiles in the image luminance function. When sampled by a realistic sensing device, the stepprofile will be blurred due to finite resolving power of the optical components and be subject to thermal noise contamination from the electronic components. Further complications are introduced when illumination gradients are present and when the location of nonstep edge types is attempted.</p><p>Most authors have confined their attention to the detection of restricted types of edge-structure. For instance, <ref type="bibr">Canny [16]</ref>, [ 171 and Spacek [9] have concentrated on the optimal characterization of step-profiles in the presence of noise using first derivatives of the image luminance function. The important conceptual stages in the edge-labeling task are as follows.</p><p>The image is first filtered to smooth the effects of noise and, in some applications, produce a multiscale representation of image data. The filtered image luminance function is then differentiated with a view to finding significant edge-features. This procedure amplifies any residual noise-component present in the luminance function. Both Canny and Spacek derive optimal filters for the detection of step edges in the presence of noise. Spacek's filter satisfies the optimality criteria of maximum signalto-noise ratio, maximum localization of the gradient-maxima associated with idealized edges and minimum peak density. The computation of directional derivatives is 0162-8828/90/0200-0165$01 .OO @ 1990 IEEE achieved by first applying a circularly symmetric realization of the optimal filter and subsequently differentiating in the required orientation using operators of the smallest possible mask size. Canny, who originally formulated the above optimality criteria, resorts for computational reasons to the use of a suboptimal Gaussian filter. Although the directional derivatives are computed in a single stage using directional masks, the edge-filtering process is operationally identical to Spacek's method. In addition to smoothing the effects of noise, both filters have a tendency to remove genuine high-frequency edge-features such as comers.</p><p>Having obtained the gradient vectors of the image luminance function, it is necessary to locate local maxima of the gradient magnitude. Both authors use nonmaximum suppression techniques for this purpose. Canny performs a simple interpolation of the gradient information in a 3 X 3 window to determine the direction and magnitude of the local gradient-maxima. Spacek performs a leastsquares second-order polynomial fit to twelve neighboring gradient magnitudes. The coefficients of the polynomial are used to determine the maximum value of the derivative of the image luminance function in the direction of the gradient. By virtue of the fitting procedure, Spacek's method gives subpixel acuity in the detection of the gradient-maxima.</p><p>Edge-pixels are labeled on the basis of the information provided by the localized gradient-maxima of the luminance function. In Spacek's detector this can be achieved using a simple binary thresholding procedure. Canny uses multithreshold hysteresis linking which draws on information concerning edge-connectivity . Edge-pixels are initially labeled if their response exceeds a highthreshold value. Pixels lying above a weaker response threshold are then admitted provided they belong to edgesegments which are connected to the initially labeled pixels. Finally, unconnected high-response pixels are deleted.</p><p>Canny and Spacek use first derivatives of the filtered image luminance function as the basis of their edge-detection methods. Other authors characterize the raw edgeinformation in different ways. On the basis of psychophysical observations, Marr and Hildreth [19] argue for the use of zero crossings of the Laplacian of Gaussian operator. The properties of zero crossings ensure that the detected edges are connected. Since the differential operator is second-order its noise amplification effects are severe unless it draws on a large support mask; this limits its capacity to faithfully detect high-curvature edge-features. Rather than using differential operators Nalwa [ 181 directly interprets the information in the image luminance function by fitting profiles in restricted windows. The form of these profiles is motivated by considerations of the image sampling procedure. Haralick [20] on the other hand has proposed an edge-detection scheme which draws on a facet model of the image luminance function.</p><p>The approaches listed above are concerned with the way that raw edge-information in the image luminance function is characterized. In this paper we are interested in the later stages of edge-detection, i.e., the postprocessing of the raw or filtered edge-information. The task is concerned with locating and labeling consistent edge-structures given confused or noisy response information. In practice it invariably draws on various sources of contextual information such as the gradient vectors available in a neighborhood of the image or the connectivity of candidate edge-structures. For instance Canny performs nonmaxima suppression by interpolating gradient vectors from an image neighborhood and draws on connectivity information in the hysteresis linking stage. Spacek, on the other hand, imposes analytic continuity on the gradient magnitudes by fitting a second-order polynomial surface to achieve nonmaximum suppression. Although these schemes are certainly effective solutions to the problem, they do not necessarily make best use of the available contextual information. It is in this respect that the contextual labeling schemes can be profitably applied to the edge-detection problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relaxation Processes</head><p>A host of contextual labeling strategies are described in the literature. The bulk of these is encompassed by the term relaxation. The common aim is to improve the consistency of object classification. This is achieved by utilizing observational information in the form of measurements pertaining to objects and prior knowledge of the constraints which apply in a particular labeling application. The relaxation processes draw on this information in a number of distinct ways. For instance, discrete relaxation is concerned with the updating of object-labels so as to achieve global consistency. Probabilistic relaxation, on the other hand, is concerned with updating label probabilities using the evidence provided by neighboring objects. Both types of relaxation process have received considerable attention in the literature and have a variety of realizations.</p><p>The original discrete relaxation algorithm was developed by <ref type="bibr">Waltz [21]</ref>. This work is significant for two reasons. First, it showed how globally consistent label configurations could be obtained using a constraint filtering algorithm. The second aspect is more pertinent to the work reported here; it showed how knowledge relating to a particular labeling application could be represented by a dictionary of symbolic constraints applying to groups of objects. Unfortunately, the constraint filtering algorithm had a number of shortcomings. It proved difficult to regulate for general labeling problems and by virtue of the purely symbolic representation of the labeling task, failed to admit the wealth of available observational information.</p><p>It was the need to overcome these shortcomings that led Rosenfeld, Hummel, and Zucker [l] to the probabilistic relaxation method. However, a host of difficulties have subsequently been identified and are pursued in the literature. In particular Hummel and Zucker <ref type="bibr" target="#b4">[5]</ref>  An interesting application of Markov modeling to edgepostprocessing has been reported by Haralick <ref type="bibr" target="#b24">[25]</ref>. The method draws on a facet model characterization of edgeresponse with the label process drawing on a Markov chain concept. The Markov chain allows label probabilities to be computed recursively by distinguishing between the causal past and future of continuous edge-structures. By virtue of the chain indexing of continuous edges the label process can be expressed using painvise relationships between adjacent edge-labels; a separate decision is required to assign the edge-direction.</p><p>Although all of these extensions of the relaxation concept admit observational information, they have not drawn on Waltz's dictionary idea <ref type="bibr" target="#b20">[21]</ref> to model the label process. We have addressed this issue in [6] by detailing a probabilistic relaxation method which draws directly on the dictionary concept to combine evidence for label assignments. The dictionary method has a vastly improved capacity to represent highly structured labeling applications. Our aim in this paper is to apply the dictionarybased probabilistic relaxation method to the postprocessing of edge-information and to demonstrate its performance advantages. Regardless of any merits, the Markov methods described above are not directly comparable to the dictionary-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Edge-Labeling by Probabilistic Relaxation</head><p>Previous applications of probabilistic relaxation labeling to edge-detection and curve enhancement have invariably exploited prior knowledge of the permitted label assignments to pairs of pixels [4], <ref type="bibr" target="#b7">[8]</ref>, [lo]. The use of such limited prior knowledge effectively corresponds to factorization of the entire context-conveying neighborhood [3], [12], [14] with the inevitable consequence of loss of edge-modeling capacity. In this paper we will make use of the permissible labelings for the entire context-conveying neighborhood. These labelings are represented by a dictionary. When used in conjunction with probabilistic relaxation, the dictionary approach has the following advantages.</p><p>It avoids the necessity to approximate the world model by marginal probabilities for subunits (e.g., pixel pairs) with a corresponding loss of representation and in some case admitting nonphysical labelings. The method therefore allows a much richer representation of the structure of the world model. Factorization schemes are associated with limiting assumptions which restrict the capacity of the world model to adequately cope with realistic labeling problems.</p><p>It represents a considerable improvement in computational efficiency. The complexity of the support function associated with factorization schemes is an exponential function of the size of the label set and the number of objects in each representational unit. The complexity of the dictionary-based support function, on the other hand, is determined by the number of permissible labelings. For most highly structured labeling applications, the length of the dictionary is very much smaller than the number of combinatorially occurring configurations.</p><p>It must therefore be stressed that the novelty of the application described in this paper lies in the use of the dictionary concept to represent edge-structure. The edge-labeling problem is highly amenable to this approach since the permitted labelings of context-conveying neighborhoods are determined by connectivity on the pixel lattice and are therefore easily compiled in a dictionary. This property allows a more sophisticated model of the edgeprocess to be used. It should also be noted that the support functions used in the previous applications have displayed internal inconsistency; for instance, after an initial subjective improvement, the image labeling deteriorates displaying effects such as edge-thickening. The support functions used in our formulation are internally consistent and we have demonstrated that the relaxation process converges uniformly upon a labeling which is objectively consistent and is in subjective agreement with the image contents [3].</p><p>The use of dictionary-based probabilistic relaxation contrasts with the postprocessing approaches used by Canny and Spacek in the following ways.</p><p>Initial probabilities for edge-and non-edge-pixel classes are used to represent gradient information. The gradients can either be derived from the raw image luminance function or from the output of a filter. Following Spacek, the gradient information is computed using differencing operators based on the smallest possible support masks; this choice clearly separates the effects of filtering and differentiation. The label probabilities model the effects of noise in the non-edge-class; this is a novel feature of the method since it does not require a detailed description of the appearance of edge-profiles in the image luminance function. The method is not limited in its capacity to cope with high levels of noise by the small size of the support masks used for differentiation; it can equally well be applied to the output of noise suppressing filters of large support mask. It should be noted that the optimal filters used by Canny and Spacek are solely concerned with the detection of step-profiles in the presence of noise.</p><p>Prior knowledge of the labelings permitted by edgeconnectivity is represented in a dictionary. The salient properties of the label process for edge-labeling are encapsulated by a dictionary for the 3 X 3 neighborhood. There is little representational advantage to be gained from the use of dictionaries for larger neighborhoods. In the work of Spacek there is no attempt to draw on this type of symbolic constraint to improve the connectivity of detected edges. Canny draws on an implicit dictionary concept by measuring an index of connectivity during hysteresis linking.</p><p>The evidence combining procedure accumulates support for the edge-and non-edge-labels from the items in the dictionary. The procedure is applied recursively until the label probabilities converge on a hard labeling which has a unique interpretation. In doing this support is incorporated from an increasingly large neighborhood; the final label probabilities eventually reflect support from a neighborhood which is of much greater size than that used by the evidence combining formula. In performing a polynomial fit to gradient magnitudes Spacek effectively draws on evidence from an image neighborhood. Canny on the other hand works with a symbolic representation of the labeling task which is derived from the gradient magnitudes for single pixels using a set of thresholds.</p><p>According to the approach described above, raw gradient information is regarded as evidence that should be combined with our expectations based on prior knowledge. By exploiting the rich context of prior knowledge to its full extent the need for noise suppressing filtering is minimized. This reduces the band limitation of features in the image luminance function. Although we have concentrated on the postprocessing of information derived from first-difference operators, the approach could also be applied to alternative characterizations of the raw edgeinformation (e.g., Nalwa [ 181, Haralick [20]) provided that probabilistic models of the measurement process are available.</p><p>The outline of this paper is as follows. In Section 11, we review the formulation of probabilistic relaxation necessary for the edge-labeling application. Section 111 contains details of the computational realization of the relaxation approach. In Section IV, we present an evaluation of the performance of dictionary-based probabilistic relaxation for edge-labeling and provide a comparison to other approaches.</p><p>11. DICTIONARY-BASED PROBABILISTIC RELAXATION An important task in scene interpretation is the global labeling of objects in an unambiguous and consistent way. The algorithms which prove most successful in this respect invariably draw on information concerning objectcontext and utilize prior knowledge of the structure of the labeling problem in-hand. Probabilistic relaxation is a technique that embodies these ingredients. First formu-lated in a seminal paper by Rosenfeld, Hummel, and Zucker [ 11, the technique has received sustained interest over the past decade.</p><p>The problem addressed in probabilistic relaxation is that of finding the class identity 0, of each object in a network U,, j = 1 , N according to a set of class labels Q . According to the philosophy of probabilistic relaxation, each object simultaneously admits every label in the set with probabilities that reflect the evidence. Central to the approach suggested by Rosenfeld, Hummel, and Zucker is the iterative updating of the label probabilities for each object using an evidence combining formula. In order to facilitate the development of the relaxation formalism we shall use the notation we, to denote a particular realization of the class identity of object U,. At the nth iteration of the relaxation process, the label probability for this assignment is P c " ) ( 0, = we, ). The updating of the label probability draws on contextual information through a support function for the object-label assignment, i.e., e'"'( 0, = we, ). The original evidence combining formula proposed by Rosenfeld, Hummel, and Zucker, is</p><formula xml:id="formula_0">( 1 )</formula><p>The explicit specification of the support function was a prerequisite of the original RHZ scheme. As such it tended to be based on inconsistent assumptions concerning the way in which contextual support is quantified. In [3], [12], and [14] we have addressed the problem of combining evidence in probabilistic relaxation in a framework which does not commence with a specification of the support function. Instead, we commence by specifying a set of probabilistic relationships which have distinct and precise meaning. Since the specification dictates the representation of world-knowledge, the relaxation mechanism is internally consistent. The probabilistic representation has the following constituents</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P C o ) ( 0 ,</head><p>= w ) = P(Oj = w Ix, ) are derived from the raw measurements for objects xj, j = 1 , N . By recursively combining evidence we improve the estimate of the label probabilities by incorporating contextual information. We regard the updating of label probabilities as an implicit filtering of the raw observations. Since at each update the current probabilities reflect contextual evidence from increasingly large neighborhoods, the repeated updating would eventually achieve the desired objective of drawing global contextual information from the complete network. This is the essence and philosophy behind probabilistic relaxation algorithms.</p><p>The joint prior P(Oj = we,, Of = we,, Vf E I,* ) is a probabilistic representation of the world-model of label structure for the objects in the context-conveying neighborhood of object j , i.e., the objects with index-set I:. The single object priors P ( Of = os,) are obtained from the joint priors by applying the axiomatic properties of joint probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The initial label probabilities</head><p>With this framework, the support function becomes <ref type="bibr" target="#b2">[3]</ref>, r121, r141</p><formula xml:id="formula_1">p ( e j = e/ = vi E 17). ( 2 )</formula><p>The summation over object-label assignments to the neighborhood of directly interacting objects, i.e., CwgIEQ, implies that the evidence combining formula is of exponential complexity. However, in the following section we shall demonstrate that in practice the actual complexity, far from being exponential, may compare favorably to factorization approaches which implement support calculation in polynomial time [l], 141, [61, 181, [lo].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Support Derived from Dictionary Look-Up</head><p>In order to render the evidence combining formula given in (2) useful for realistic labeling problems, it is necessary to derive support functions of at most polynomial complexity. One approach to reducing the computational complexity of the support function is to factorize the joint prior into marginal probabilities for smaller subunits of the context-conveying neighborhood. The need to maintain the internal consistency of the relaxation scheme dictates the size of subunits. For instance the four pixel neighborhood must be factorized in terms of pairs of objects while the eight pixel neighborhood is factorized into groups of four pixels; the complexity of the resulting support functions are of order m2 and m4, respectively <ref type="bibr" target="#b4">[5]</ref>,</p><p>Alternatively, and central to the approach adopted in this paper, the exponential rise in computational expense with the size of representational units can be offset by the following observation: although the joint prior is potentially of exponential complexity, in many realistic applications the number of permissible configurations of labels in the contextual neighborhood is relatively small. This restriction in complexity results from the fact that many labeling problems are in fact highly structured; this will be demonstrated for the case of edge-labeling. As a consequence it becomes feasible to make an exhaustive compilation of the permissible configurations and to list them in a dictionary. This idea was central to the discrete relaxation method of Waltz <ref type="bibr" target="#b20">[21]</ref>.</p><p>As we shall demonstrate in Section IV, for the edgelabeling application the compilation of the dictionary is very straightforward; it consists of all labelings of a 3 X 3 neighborhood permitted by eight connectivity on a pixel lattice. The highly structured nature of the application becomes clear when it is noted that the dictionary contains only 181 of the 59 combinatorial possibilities. The implementation of the dictionary-based method is very simple for another reason; every object neighborhood has an identical dictionary. Waltz demonstrated that the dictionary was capable of encapsulating the label process for more complex applications. For interpreting line drawings of blocks-world scenes the dictionary is a compila-t 141. tion of the constraints applying at line junctions. These junctions are of varying types and topology. The dictionary therefore contains items of different length and has sections for different junction topologies.</p><p>Although the power of the dictionary representation of constraints was evident from the work of Waltz, it has not been adopted in work on probabilistic relaxation. In a recent paper we have addressed this issue by detailing an evidence combining approach to probabilistic relaxation which utilizes the dictionary concept <ref type="bibr" target="#b2">[3]</ref>. The method represents an improvement on existing techniques since it draws on the labeling of the entire context-conveying neighborhood of each object. Our aim here is to review the formalism necessary to apply the method to the edgelabeling application.</p><p>If the number of permissible labelings Z , for each of the object neighborhoods I, is small, then they can be realistically listed in a dictionary 9,. The dictionary for each object neighborhood is subdivided into sections DJ (we, )   which have length Z, (we, ) and which are indexed according to the value center-object label we,. Let U;, denote the label on the object a[, 1 # j , required by the kth entry in the section BJ (we, ) of the dictionary. Accordingly, the kth section entry in the dictionary is a set of labels defined over the context-conveying neighborhood of object a/, which we denote by</p><p>Having defined the dictionary concept it remains to show how the associated joint priors for the permissible labelings may be modeled. In the work reported here we apportion the total available probability mass among the physical dictionary items. For the edge-labeling application we adopt a uniform distribution of probability mass. This need not necessarily be the case; in some applications it may be desirable to encourage some configurations at the expense of others. Accordingly, the probability measure associated with any physically impossible configuration { O r = we,, VZ E I, } @ 9, (we, ) is zero, i.e., Af(wO,) = {e, = we,, = ai,, VZ EZ,* &gt; .</p><p>This dictionary model of the label process results in a critical simplification of the support function in (2). The implied multiple sum over label assignments to the neighborhood of directly interacting objects can be replaced by a sum over labelings in the subsection of the dictionary (we, ) and the support function becomes</p><p>This support function allows us to use knowledge concerning the label assignments to the full context-convey-ing neighborhood; in the next section we will demonstrate how it can be used to express a more sophisticated model of edge-processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">EDGE-LABELING USING DICTIONARY-BASED</head><p>SUPPORT The observation that the behavior of the physical edges is governed by connectivity on a pixel lattice suggests that their behavior can be successfully encapsulated in a dictionary. Provided it is possible to characterize edge-information using a set of initial label probabilities, then dictionary-based probabilistic relaxation may provide a useful framework for combining evidence to label edgepixels. Evidence is recursively combined by drawing on the dictionary of permissible labelings in the context-conveying neighborhood until a hard labeling is obtained. The way in which the evidence combining approach draws on the available contextual information can be contrasted with Canny's hysteresis linking scheme or Spacek's polynomial fitting of gradient magnitudes. Neither approach simultaneously combines evidence and exploits knowledge concerning edge-structure. Although hysteresis linking does effectively draw on a dictionary to determine connectivity, it does not combine evidence. Edgepixels are labeled on the basis of their connectivity and the value of their gradient magnitude. Spacek's procedure draws on a polynomial fit to the gradient magnitudes in a local region of the image. The gradient-maxima determined in this way have increased connectivity by virtue of the analytic nature of the fitting procedure. However, the method does not draw on any kind of dictionary concept; the final hard-labeling of edge-pixels is performed using a thresholding operation which makes no use of prior knowledge of edge-structure.</p><p>In order to apply the support function given in (5) to edge-postprocessing we must provide the following computational ingredients.</p><p>A set of class labels to describe the edge-process. Initial label probabilities derived from the image luminance function.</p><p>An appropriately structured dictionary of edge-labeling possibilities.</p><p>A priori probabilities for the dictionary items and single label probabilities.</p><p>In Section 111-A we describe the meaning of the labels used to represent the edge-process, Section 111-B contains a discussion of the procedure used to calculate initial label probabilities, and Section 111-C gives details of the dictionary and the inference of a priori probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Class Labels for the Edge-Process</head><p>The choice of class labels used to represent edges involves a compromise between exploiting the full structural richness of permissible neighborhood labelings and the computational complexity of the resulting evidence combining formula. For the implementation described here we have chosen to use a five label set. This consists of the four labels which represent edge-propagation par-allel and antiparallel to the two pixel lattice axes and a non-edge-label. The notation used to denote this label set is f? = { +, t , +, 1, 4 ] where the arrows are perpendicular to the intensity gradients associated with the edges and 4 is the non-edge-label. As an example, -+ denotes a pixel belonging to an edge which is associated with a boundary that is parallel to the horizontal axis of the pixel lattice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Initial A Posteriori Probabilities</head><p>The role of the initial a posteriori probabilities is to model the affinity of raw measurements derived from a gray-scale image to the class labels used to represent the edge-process. This section describes the model adopted and its calculational realization in terms of the derivatives of the image luminance function.</p><p>If the initial gray-level image is composed of regions of uniform intensity bounded by step edges, then the corresponding directional intensity gradients will be characterized by delta functions of differing amplitude. In reality, the regions in the gray-level image will neither be of uniform intensity nor bounded by step edges. In particular the individual pixel gray-levels may be subject to random noise and the boundaries of regions may extend over several pixels. As a result, the intensity gradient will not be simply characterized by delta functions, but will consist of many complex features including isolated noise pixels, ramps, and ridges; any model that attempted to describe such a variety of edges would contain many parameters. In order to avoid bias in favor of any particular type of edge-profile, we have concentrated on modeling the noise processes. The model assumptions concerning the edgeprocess are independent of the gray-scale profile and are expressed only in terms of the admissible edge-configurations which are described in Section 111-C.</p><p>A conventional model of the noise generation process has been adopted here, that is, that the noise occurring in the pixel gray-levels is assumed to be additive and is generated by a Gaussian probability distribution function with zero mean and standard deviation U . The intensity gradients in the pixel lattice directions are derived from the mask shown in Fig. <ref type="figure" target="#fig_0">1</ref> using the following first differences:</p><p>In vector form the above transformation of gray-scale values can be expressed as c = ATg where c = ( c , , c ~) ~, g = ( go, gl, g , ) T and <ref type="bibr" target="#b6">(7)</ref> If the pixel go belongs to the non-edge-class, then each of the pixels go, g , , and g2 must belong to the same image region; this implies that the pixel gray-levels are subject to identical distribution functions which have the same mean and standard deviation. Consequently, c1 and c2 will be of zero mean. Under the assumption that the noise component in the pixel gray-level value acts as an independent random v = C C ai,j * a i -l , j -l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">= 2 j = 2</head><p>In both the uncorrelated and correlated cases, the vector of first differences c is obtained by the linear transformation of the gray-scale values c = ATg. As a consequence c is normal with distribution function where the transformed variance-covariance matrix e = A T U . After substitution for the transformation matrix the general expression for the class conditional density for the first differences is</p><formula xml:id="formula_3">1 P(% c2po = 4) = 2 ~4 4 ( s -U ) ( S -t ) -( t + U -s -u)'o2 ( 16) (s -U ) . : + (s -t ) c z + ( t + U -s -v ) c l c 2 { 4 ( s -u ) (s -t ) -( t + u -s -v12} o2</formula><p>variable, the joint conditional density of g is normal with variance-covariance matrix <ref type="bibr" target="#b7">(8)</ref> However, as we indicated in the Introduction, the characterization of edge-information frequently involves a filtering stage. In this case the gray-scale values will be correlated and in consequence the variance-covariance matrix will no longer be diagonal. Suppose that the raw image has been processed using the N X N filter al,l * -* F = (;;,; :: : : I ) . In Section IV we report how the dictionary-based relaxation method can be used in conjunction with the output of a noise suppressing filter. For the purpose of experimentation, we use Spacek's <ref type="bibr" target="#b8">[9]</ref> optimal filter. As a concrete example, when this filter is computed on a 5 X 5 support mask, the numerical values of the correlations s, t , U , and v result in the following density function 0 . 3 6 ( ~:</p><formula xml:id="formula_4">+ c:) -0.067~1~2 exp [ -<label>a2</label></formula><p>It is interesting to note that as the mask size of the Spacek filter increases, the cross product of the directional derivatives has a diminishing effect and in the limit of large mask size the density has circular rather than elliptical symmetry.</p><p>Having derived the general conditional distribution function for the first differences and presented some specific instances, it remains to be shown how the initial label probabilities can be computed. The a posteriori probability of the non-edge-label is obtained from the conditional distribution function by applying the Bayes (19) Since the form of the mixture density function is not known, it is only possible to place a bound on the a posteriori probabilities; this is done by making the assump- tion that the density function corresponding to zero intensity gradient is a maximum, i.e., p ( c l = 0, c2 = 0 ) 2 p ( cI # 0, c2 # 0). This assumption is quite realistic as the mixing proportions of edge-pixels will be very small in comparison to non-edge-pixels (i.e., the majority of pixels in an image will be non-edge-pixels). Moreover, in the vicinity of the origin, the mixture density will be dominated entirely by the conditional probability density which peaks at zero. The assumption, combined with the Bayes formula, leads to the following inequality:</p><formula xml:id="formula_5">p(cl = 0, c2 = oleo = 4) p(cl z 0, c2 + oleo = 4 ) p ( e , = +I = 0, c2 = 0 ) P ( e o = # 0, c2 z 0) 1 ' ( 2 0 )</formula><p>If the a posteriori probability of the non-edge-label is taken to be unity when the total edge-response is zero, then where</p><formula xml:id="formula_6">A = ( C I I + (c2I.</formula><p>( 2 3 )</p><p>To summarize, the above procedure for estimating the initial label probabilities has the following properties.</p><p>It uses the smallest mask size to estimate the derivatives of the image luminance function. This has the consequence of preserving features of high-spatial-frequency such as corners. The method used to calculate derivatives uses a simple 2*1 difference operator.</p><p>It does not make any assumptions Concerning the luminance profile of the edge-types that might be present in an image. The method does not assume that edges present step-profiles.</p><p>It models the effects of noise through the joint conditional density function for the first differences. The method can process raw unfiltered edge-information.</p><p>The model described above should be contrasted with those adopted by Berthod and <ref type="bibr">Faugeras [4]</ref> and by Zucker et al. <ref type="bibr" target="#b7">[8]</ref> in their applications of probabilistic relaxation to edge-labeling. According to both of these approaches, the initial label probabilities are assigned on the basis of the responses to a set of directional difference masks; no attempt is made to justify the way in which the raw mea-</p><formula xml:id="formula_7">(s -U ) c : + (s -t &gt; c : + ( t + U -s -21)c,c2 - ~( 6 , = 4 \ c l # 0 , c2 + 0 ) 1 exp { 4 ( s -U ) (s -t ) -( t + U -s -u ) 2 ) c J ~ i (s -U ) . : + (s -t,c: + ( t + U -s -V ) C l C 2 Presidual = 1 -exp - i { 4 ( s -U ) (s -2) -( t + U -s -U ) * } fJ2</formula><p>Finally, the a posteriori probabilities for the four edgelabels are obtained by apportioning Presidual according to the relative signs and magnitudes of c1 and c2:</p><formula xml:id="formula_8">-C1 A q e o = + 1 c1, c 2 ) = -Pres,dual if cI I o = o otherwise c.2 P ( 0, = t 1 c1, c2) = 7 presidual if c2 I o = o</formula><p>otherwise However, we acknowledge that the problem is complex and that the model we adopt does have limitations. For instance, when the thermal noise contamination is low and the image noise is dominated by quantization errors, a better model would involve a uniform rather than Gaussian density. However, based on the experimental studies reported in Section IV-C, these limitations do not appear to impair performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Dictionay and Associated Probabilities</head><p>The role of the dictionary is to encapsulate knowledge concerning the permissible labelings of the context-conveying neighborhood. Since we wish to exploit the greatest amount of evidence available for each pixel, we will use the eight pixel neighborhood shown in Fig. <ref type="figure" target="#fig_2">2</ref>  culate support. We are therefore concerned with generating the dictionary of possible labelings of a 3*3 pixel window.</p><p>The dictionary must contain all physically reasonable labelings. It must not be biased toward particular types of edge-structure such as continuous straight lines or corners. To this end we have adopted a model of the edgelabel process based on connectivity within the 3 *3 pixel window. Briefly the properties of this model are as follows.</p><p>Edges are one pixel wide. Permissible edges propagate continuously in one direction or undergo changes in the direction of n / 2 .</p><p>Examples of labelings that result from this model are shown in Fig. <ref type="figure" target="#fig_3">3</ref>. The full dictionary has 181 items and the cardinalities of the sections are as follows:</p><formula xml:id="formula_9">Z(+) = Z ( t ) = Z(+) = Z(1) = 17 Z ( 4 ) = 113.<label>(24)</label></formula><p>A further model assumption is necessary to infer the a priori probabilities for the dictionary items. In order not to bias the relaxation method in favor of particular edgestructures we have assumed that each dictionary item is equally likely, i.e., ( 2 5 ) 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P ( A k ( w ) ) = 5</head><p>where Ak ( U ) is the kth item of the section 33 ( U ) of the dictionary. This method gives equal likelihood to all permissible edge-structures and does not, for instance, encourage straight edges at the expense of corners.</p><p>The a priori probabilities for single pixel label assignments were then inferred using the axiomatic property of joint probability, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Z ( W )</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P ( &amp; = w ) = k = 1 P ( A k ( w ) ) . ( 2 6 )</head><p>This procedure for calculating the a priori probabilities differs from the approaches adopted by Berthod and Faugeras and by Zucker et al. in the following respects.</p><p>It uses knowledge of labeling structure for the whole context-conveying neighborhood; the previous work only made use of a priori probabilities for pixel pairs. We therefore exploit more information concerning the structure of the edge-labeling application. In the work of Zucker [8], the probabilities took the form of heuristic compatibility coefficients in the range -1 .O-1 .O; these coefficients were chosen to encourage continuous edges and suppress corners. A similar goal oriented approach was adopted by Berthod and Faugeras [4] who derived a set of probabilities with the objective of encouraging continuous straight edges. Our method does not exhibit these biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. APPLICATION OF THE EDGE-MODEL</head><p>This section describes experimentation undertaken to investigate the performance of the dictionary-based probabilistic relaxation algorithm for the edge-labeling process described in Section 111. These experiments were intended to evaluate the robustness of the dictionary-based algorithm and to compare its performance with other approaches to edge-labeling .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Comparison to Other Methods</head><p>The following edge-labeling algorithms have been studied in order to assess the performance of the dictionary-based approach described in the previous section.</p><p>Hilditch edge-thinning as an example of an incremental labeling algorithm applied to the thresholded edgemagnitudes [ 111. The Hilditch algorithm also uses lists of neighborhood labelings and the comparison is made to show the advantages of using an evidence combining approach. This procedure does attempt to recognize label structure but it does not attempt to combine evidence.</p><p>We have performed a detailed comparison with the edge-detector proposed by Spacek, since this represents one of the most theoretically consistent and practically successful approaches described in the literature. There are two aspects to the comparison to Spacek's work. First, we have compared the results of relaxation labeling to the thresholding of fitted gradient magnitudes; the comparison uses identical differencing techniques in order to assess which method is most robust to noise. Second, we have compared the two labeling strategies for images convolved with filtering masks of different size in order to determine which method most successfully reconstructs edges for a given mask size.</p><p>Although we have chosen Spacek's algorithm as the basic metric of comparison, we also present some experimental comparison to the work of Canny. In this respect we are concerned with comparing the nonmaximum suppression and hysteresis linking stages to dictionarybased probabilistic relaxation. The comparison is not extensive. We will suffice to show that Canny's postprocessing is only robust to noise if applied to a filtered representation of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Imugery</head><p>Both synthetic and natural images have been used to compare the dictionary-based edge-labeling algorithm with the approaches described above. The synthetic images were of two kinds:</p><p>An image of a circle circumscribed by a square which was corrupted by varying amounts of additive Gaussian noise. This image was used to evaluate the ability of the edge-labeling algorithms to detect edges of varying orientation and to find the comers of the square which represent points of high curvature.</p><p>In addition to being subject to thermal noise contamination, realistic edges are sampled by imaging devices of finite resolution and are subject to illumination gradients. As a consequence, the sampled edges of physical objects in natural scenes will not present step-profiles in the image luminance function. To assess the effectiveness of relaxation labeling to correctly identify the position of more realistic edge-types we have generated sigmoid edge-profiles of varying width. This has been achieved by applying low-pass filters of varying mask size to a ramp structure of a few pixels width. Thermal noise has subsequently been added to the profiles.</p><p>In addition to these synthetic images, the edge-labeling algorithms have been applied to natural images. In particular, we have studied images of cluttered scenes where realistic edges do not necessarily have a step-profile and noise may be present due to the image sampling procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results</head><p>Fig. <ref type="figure">4</ref> shows the results of successive iterations of the dictionary-based labeling algorithm applied to the circleinside-square image in which the signal-to-noise ratio (SNR) is 2 5 : 6 ; the intensities of the pixels are proportional to the probability of the non-edge-label. After eight iterations of the evidence-combining formula, the process has essentially converged and there are very few pixels -Fig. <ref type="figure">4</ref>. Successive iterations of dictionary-based relaxation for which the probability is neither zero nor unity. It can be seen there are no inconsistent labelings present in the scene and all edges are one pixel thick. It is also worth noting that all four comers of the square are well reconstructed.</p><p>In order to evaluate the relative performance of the edge-labeling algorithms described in Section IV-A, a series of circle-inside-square images with signal-to-noise ratios of 9 , 7 , %, %, and were used. Fig. <ref type="figure" target="#fig_4">5</ref> shows a comparison of results obtained using dictionary-driven relaxation, Hilditch edge-thinning, and Spacek's algorithm without filtering applied to these images. At the lowest level of noise all four algorithms perform well. When the signal-to-noise ratio falls below $, Hilditch edge-thinning fails. When the signal-to-noise ratio is less than 9, Spacek's edge-labeling algorithm is no longer able to label genuine edge-pixels without also labeling a large number of noise pixels. The dictionary-based relaxation approach gives good results for values of the signal-tonoise ratio down to p. Even when the signal-to-noise ratio is below this value, the dictionary-based approach labels a reasonable fraction of genuine edge-pixels without labeling an unacceptably large number of non-edge-pixels. Another encouraging feature of the edge-segments reconstructed by the dictionary-based approach is their strong connectivity.</p><p>The dictionary-based approach can also be used to label the output from filters which suppress the noise and produce multiresolution representations of image data; Spacek's circularly symmetric operator is such a filter. When used to suppress noise, these filters have the property of smoothing the high-frequency-spatial component in an image. Under certain circumstances this may be an undesirable property since genuine edge-features such as comers or fine details are removed. Since dictionary-based relaxation models the noise generation process and can reliably reconstruct edge-segments at higher levels of noise than other labeling algorithms, it may be used to label edges using a smaller mask size than, for instance, Spacek's polynomial method. In order to demonstrate this effect a circle-inside-square image with signal-to-noise ratio of 25 : 15 has been convolved with circularly symmetric Spacek filters of mask size ( w ) 3, 5, 7, 9, and 11 pixels. The dictionary-based labeling of the filtered image successfully reconstructs edge-segments for a mask size of 5 pixels, while Spacek's polynomial method only succeeds if the mask size exceeds 9 pixels; these results are demonstrated in Fig. <ref type="figure" target="#fig_5">6</ref>. When the mask size used exceeds 9 pixels the relaxation approach begins to label apparently spurious edges in the proximity of the boundaries of the figures in the synthetic image. This problem appears to be the consequence of the dilation of the intensity gradient by the large filter mask and may be rectified by subsampling the filtered image.</p><p>Fig. <ref type="figure" target="#fig_6">7</ref> is a comparison of the dictionary-based approach and Canny's postprocessing applied to a synthetic circleinside-square image of signal-to-noise ratio of 25 : 8. Fig. <ref type="figure" target="#fig_6">7</ref>(a) shows the best result that could be obtained when Canny's method was applied to the raw image; no filtering has been employed. The result is poor in comparison with that shown in Fig. <ref type="figure" target="#fig_6">7</ref>(b) which was obtained using the dictionary-based approach. A much better result is obtained when Canny's postprocessing is applied the output of a Gaussian filter. Fig. <ref type="figure" target="#fig_6">7</ref>(c) shows the best labeling that could be obtained after filtering with a support mask of 5</p><p>x 5 had been performed. Filtering based on a smaller support mask fails to adequately label the physical edges of the figures in the image. The erosion of corners is very evident in Fig. <ref type="figure" target="#fig_6">7(c</ref>). Finally, Fig. <ref type="figure" target="#fig_6">7(d)</ref> shows the result of applying dictionary-based relaxation to the output of a Gaussian filter; this is the most satisfactory of the four labelings.</p><p>From this experimentation with Canny's postprocessing, it is clear that the method only performs well when applied to a filtered representation of the image. It cannot cope with raw noise. Although the postprocessing has been applied to the output of a Gaussian filter, it could equally well have been applied to the output of Spacek's optimal filter. The results described above indicate that dictionarybased relaxation labeling can be successfully applied to images containing step edges which have been corrupted by additive noise. However, the model used to calculate the initial a posteriori probabilities does not depend on the profile of the edge. In order to investigate the behavior of the relaxation approach when the gray-scale profile departs radically from that of a step edge, we have studied the behavior of the labeling algorithms when applied to synthetic profiles.</p><p>We have generated a sigmoid profile of width 2 pixels. This edge-profile was corrupted with additive Gaussian noise with standard deviation varying from zero gray-levels at the top of the image to 32 gray-levels at the bottom of the image, i.e., the signal-to-noise ratio has a minimum value of 4. The corrupted image was then processed using filters of mask size two and four pixels. The resulting image simulates the combined effects of sensor noise and finite sampling width. Without any filtering of the gray-scale intensities the relaxation approach is able to reconstruct the edge provided that the signal-to-noise ratio is not less than 6.4; after filtering with mask size 4 pixels, the relaxation approach successfully reconstructs the entire edge at all levels of noise. These results are encouraging since they indicate that the relaxation approach is both robust to noise and the width of the profile. These results are demonstrated in Fig. <ref type="figure">8</ref>.   We have performed extensive comparative experiments on images of natural scenes. Figs. 9, 10, and 11 show examples of the comparative performance of dictionarybased relaxation and the postprocessing algorithms of Spacek and Canny. The image used for the comparison in Fig. <ref type="figure">9</ref> was chosen because of its noisy and textured nature. Both Spacek and Canny prove susceptible to the noise component and cannot cleanly segment out the meaningful edge features. Dictionary-based relaxation, on the other hand, is capable of locating the important edgeinformation without labeling an unacceptable amount of extraneous edge-structure. Fig. <ref type="figure" target="#fig_0">10</ref> shows a comparison of the three techniques for a less noisy and uncluttered scene. All three techniques perform well, however, the edges located by dictionary-based relaxation display better connectivity properties. Finally, Fig. <ref type="figure" target="#fig_0">11</ref> shows the comparison on a fairly complex scene. In the foreground there are isolated edges corresponding to shape boundaries, while the background is dense with occluding edges. All three approaches appear to label successfully a large number of genuine edges. However, the relaxation labeling algorithm reconstructs edges which have a much stronger tendency to be connected and finds fewer edge-features which appear to be artifacts of texture or noise. In order to demonstrate that dictionary-based relaxation can succeed in labeling a natural variety of edge-types in the presence of noise, we have corrupted the image used for the experimentation shown in Fig. <ref type="figure" target="#fig_0">11</ref> with additive Gaussian noise of standard deviation 15 gray-levels. Fig. <ref type="figure" target="#fig_10">12(a)</ref> shows the result of applying dictionary-based relaxation to the corrupted image, Fig. <ref type="figure" target="#fig_10">12(b</ref>) shows the result of applying Spacek's labeling algorithm to the unfiltered image, and Fig. <ref type="figure" target="#fig_10">12(c</ref>) shows the result of applying Spacek's labeling algorithm when the image has been filtered with a mask of size 5 pixels. The labeling produced by Spacek's algorithm without a filter operation is clearly inferior to dictionary-based relaxation; it is only when a fil-ter mask of 5 pixels is applied that the two results achieve comparability.</p><p>In practical applications of edge-labeling an important consideration is automatic adaptation to varying noise conditions. As indicated above, in the dictionary-based approach the response to differing levels of noise is controlled by the parameter U used in the calculation of Presidual while in Spacek's strategy it is controlled by the mask size used in the filtering operation. One strategy for adaptively calculating U is to adopt an estimation procedure similar to that suggested in <ref type="bibr">[15]</ref>. In the studies reported here, the value of U that gave the best subjective performance was greater than the additive noise compo- We have demonstrated that probabilistic relaxation can be successfully applied to the problem of edge-labeling. The success of the application derives from two features of the way in which the relaxation scheme is formulated. Firstly. we commence with a specification of the proba-bilistic framework that is used to represent the world model: this ensures internal consistency. Secondly, we represent prior knowledge of the structure of the application using a dictionary of labeling possibilities for the entire context-conveying neighborhood for each object; this is to be contrasted with the use of factorizations of the neighborhood which involve limiting approximations and reduce the representational capacity of the scheme. The resulting algorithm combines evidence for the presence of edges by drawing on prior knowledge of the permitted label structures. The consequence of the improved formulation is a cornputationally efficient algorithm which is comparable in performance to edge-detection strategies which are acknowledged as being successful. In particular, the dictionary-based approach is capable of enhancing edge-struc-tures in the presence of considerable noise without the need to apply filters which involve a large support mask. This has the advantage that high-frequency edge-features such as comers are not sacrificed at the expense of noise suppression.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>U;Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Gray-level values used to calculate partial derivatives</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>c = ( to2 su2 5 ::l j ( 9 )</head><label>59</label><figDesc>The variance-covariance matrix for the filtered gray-scale values is as follows (10) u(T2 ua2 sa2 where the covariance elements resulting from the correlations introduced by the filtering operation are In the case of raw unfiltered observations when s = I and r = U = v = 0, then the density function reduces to (17)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Eight pixel context-conveying neighborhood.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Examples from the dictionary of neighborhood labelings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (a) Dictionary-based relaxation applied to a synthetic image with different levels of additive Gaussian noise; i) SNR = 2.512, ii) SNR = 25/4, iii) SNR = 2 5 / 6 , iv) SNR = 2518, v) SNR = 25/10. (b) Hilditch edge-thinning applied to a synthetic image with different levels of additive Gaussian noise; i) SNR = 2 5 / 2 , ii) SNR = 2514, iii) SNR = 25/6. (c) Spacek's labeling procedure applied to a synthetic image with different levels of additive Gaussian noise; i) SNR = 2512, ii) SNR = 25/4, iii) SNR = 2 5 1 6 , iv) SNR = 2 5 1 8 , v) SNR = 25/10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6 . (a) Dictionary-based relaxation applied to a synthetic image which has been convolved with circularly symmetric filters of different mask size; i) w = 1, ii) w = 3, iii) w = 5 , iv) w = 7, v) w = 9, vi) w = 11. (b) Spacek's edge-operator with filters of different mask size applied to a synthetic image; i) w = 1, ii) w = 3, iii) w = 5 , iv) w = 7, v) w = 9, vi) w = 11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparison of dictionary-based relaxation and Canny's algorithm for an SNR = 25 : 8 image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig.8. Dictionary-based relaxation applied to synthetic edge-profile subject to varying amounts of additive Gaussian noise and smoothed using low-pass filters of different width; i) w = 1, ii) 1%' = 2, iii) w = 4. The signal-to-noise ratio varies from 128/0 at the top of the image to 128/32 at the bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>. (a) Original image of a natural scene. (b) Dictionary-based relaxation applied to an image of a natural scene. (c) Spacek's second-order surface model applied to an image of a natural scene. (d) Canny's postprocessing applied to an image of a natural scene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>1 I (;(I Original image 01 d natural hcene. ( b ) D i c t i o n a r y h a w J relax- ;ition applied to a n image 01 ii niituril \ccnc' ( c ) Spacek's s e c o n d -o r d e r \iil-f,icr niodcl applied 10 an imagc ol U natural s c e n e ( d ) Canny's post-proce\sing applied to an image ot ;I natural v x n s I nent in the images; this is reconcilable with the fact that no attempt has been made at accounting for quantization errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. (a) Dictionary-based relaxation applied to an image of a natural scene corrupted by additive Gaussian noise of standard deviation 15 graylevels. (b) Spacek's labeling algorithm applied to an image of a natural scene corrupted by additive Gaussian noise of standard deviation 15 graylevels. (c) Spacek's labeling algorithm with filter mask size 5 pixels applied to a natural scene corrupted by additive Gaussian noise of standard deviation 15 gray-levels.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Josef Kittler (M'74) has been working in the fields of pattern recognition, image analysis, and computer vision since 1970. He is the author or coauthor of more than 100 publications which include 5 books (one coauthored and four edited) and more than 40 papers in refereed international journals.Dr. Kittler is a member of the editorial boards of IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, Pattern Recognition Journal, Image and Vision Computing, Pattern Recognition Letters, and the International Journal of Pattern Recognition and Artijcial Intelligence.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scene labeling by relaxation operations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Sysr., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="420" to="433" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review of relaxation labeling algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Illingworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="206" to="216" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining evidence in probabilistic relaxation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Pattern Recognition ArtiJcial Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving consistency and reducing ambiguity in stochastic labeling: An optimization approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berthod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="412" to="424" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the foundations of relaxation labeling processes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Contextual decision rule for region analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="145" to="155" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A list-driven contextual decision rule</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Scandinavian Cont ImageAnalysis</title>
		<meeting>5th Scandinavian Cont ImageAnalysis</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An application of relaxation labeling to line and curve enhancement</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="394" to="403" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Edge-detection and motion detection</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Spacek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="43" to="56" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Determining compatibility coefficients for curve enhancement relaxation processes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="548" to="555" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linear skeletons form square cupboards</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hilditch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Machine Intell.</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="403" to="420" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compatibility and support functions in probabilistic relaxation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th ICPR</title>
		<meeting>8th ICPR<address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On compatibility and support functions in probabilistic relaxation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Foglein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graphics, Image Processing</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relaxation labeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Patrern Recognition Theory and Practice</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Devijver</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An automatic thresholding algorithm and its performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Illingworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Foglein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Paler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th ICPR</title>
		<meeting>7th ICPR</meeting>
		<imprint>
			<publisher>Montreal</publisher>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Finding edges and lines in images</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">M.I.T. Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">720</biblScope>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A computational approach to edge-detection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern. Anal. Machine Inrell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="679" to="700" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On detecting edges</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nalwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern. Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="701" to="714" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Theory of edge-detection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Roy. Soc. London</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="212" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A facet model for image data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graphics, Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="267" to="287" />
			<date type="published" when="1981">1981. 1989. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Understanding line drawings of scenes with shadows</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Waltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Psychology of Computer Vision</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Winston</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions and Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern. Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bayes smoothing algorithms for segmentation of binary images modeled by Markov random fields</title>
		<author>
			<persName><forename type="first">H</forename><surname>Derin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Elliot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cristi</surname></persName>
		</author>
		<author>
			<persName><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern. Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="707" to="720" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image segmentation using simple Markov random fields</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elliot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Compur. Vision, Graphics, Image Processing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S J</forename><surname>Lee</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th ICPR</title>
		<meeting>9th ICPR<address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1982. 1989</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="203" to="207" />
		</imprint>
	</monogr>
	<note>tion</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Stat. Soc., series B</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">D. degree in high energy physics from the University of Durham, UK, in 1977 and 1981, respectively. In 1981 he joined the Rutherford Appleton Laboratory to work on an experiment to measure charmed particle lifetimes using high resolution imaging techniques at the Stanford Linear Accelerator Center. Since 1985, he has been doing research in the areas of pattern recognition and computer vision, his current interests being in the methodology and the application of relaxation processes to image interpretation problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Edwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hancock received the B.Sc. degree in physics and the Ph</title>
		<imprint/>
	</monogr>
	<note>He is also an Associate Lecturer in the Department of Electrical Engineering at the University of Surrey. He has published over 25 papers in refereed journals and conferences</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
