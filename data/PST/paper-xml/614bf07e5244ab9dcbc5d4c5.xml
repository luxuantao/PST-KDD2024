<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Simple Approach to Jointly Rank Passages and Select Relevant Sentences in the OBQA Context</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>He He, Mohit Iyyer</roleName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wen- 393</forename><surname>Tau Yih</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Zettle</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Clark</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuexiang</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daoyuan</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yaliang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ying</forename><forename type="middle">2020</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><surname>Joint</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
						</author>
						<title level="a" type="main">A Simple Approach to Jointly Rank Passages and Select Relevant Sentences in the OBQA Context</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the open book question answering (OBQA) task, selecting the relevant passages and sentences from distracting information is crucial to reason the answer to a question. HotpotQA dataset is designed to teach and evaluate systems to do both passage ranking and sentence selection. Many existing frameworks use separate models to select relevant passages and sentences respectively. Such systems not only have high complexity in terms of the parameters of models but also fail to take the advantage of training these two tasks together since one task can be beneficial for the other one. In this work, we present a simple yet effective framework to address these limitations by jointly ranking passages and selecting sentences. Furthermore, we propose consistency and similarity constraints to promote the correlation and interaction between passage ranking and sentence selection.The experiments demonstrate that our framework can achieve competitive results with previous systems and outperform the baseline by 28% in terms of exact matching of relevant sentences on the HotpotQA dataset.</p><p>043 pipeline: identify the most relevant passage by one 044 model and then match each question with a single 045 sentence in the corresponding passage by another 046 model. Such systems are heavy in terms of the 047 size of the models which requires long training and 048 inference time. Green AI has recently been advo-049 cated to against the trend of building large models 050 which are both environmentally unfriendly and ex-051 pensive, raising barriers to participation in NLP 052 research (Schwartz et al., 2020). Apparently, sys-053 tems using multiple models to solve HotpotQA task 054 do not belong to the family of Green AI. Further-055 more, the benefits of learning from passage ranking 056 1 181</p><p>and selecting relevant sentences are not well utilized by these systems. Intuitively, if a passage is ranked high, then some sentences in the passage should be selected as relevant. On the other hand, if a passage is ranked low, then all sentences in the passage should be classified as irrelevant.</p><p>To build a Green AI system and take advantage of multi-task learning, we introduce a Two-in-One model, a simple model trained on passage ranking and sentence selection jointly. More specifically, our model generates passage representations and sentence representations simultaneously, which are then fed to a passage ranker and sentence classifier respectively. Then we promote the interaction between passage ranking and sentence classification using consistency and similarity constraints. The consistency constraint is to enforce that the relevant passage includes relevant sentences, while the similarity constraint ensures the model to generate the representation of relevant passages more closer to the representations for relevant sentences than irrelevant ones. The experiments conducted on the HotpotQA datasets demonstrate that our simple model achieves competitive results with previous systems and outperforms the baselines by 28%. 2 Related Work HotpotQA Systems A straightforward way to solve the HotpotQA challenge is to build a hierarchical system (Nie et al., 2019), meaning a system first ranks relevant passages and then identifies relevant sentences from the selected passages. Such a hierarchical system involves multiple models thus requires long inference time. More importantly, such a system only leverages the impact of passage ranking on sentence selection but ignores the influence of the sentence selection on the passage ranking. Our framework achieves these two tasks by one model and facilitates the interaction by two constraints. Groeneveld et al. (2020) proposes a pipeline based on three BERT models (Devlin et al., 2019) to solve the HotpotQA challenge. The system first selects relevant sentences and then detects the answer span, finally, identifies the relevant sentences according to the answer span. Though the pipeline is strong, the way it solves the problem is opposite to human beings. We, humans, identify the relevant sentences, and then give the answer span. Many existing works demonstrate the effectiveness of graph neural networks(GNN) on HotpotQA challenge (Fang et al., 2020; Tu et al., 2019). Since GNN is out of the scope of this work, 107 we do not compare it with these frameworks. 108 Joint Model for QA Joint learning has been 109 studied in Question Answering Tasks. Deng et al. 110 (2020) proposes a joint model to tackle commu-111 nity question answering such that the model can 112 simultaneously select the set of correct answers 113 from candidates and generate an abstractive sum-114 mary for each selected answer. Sun et al. (2019) 115 proposes a generative collaborative network to an-116 swer questions and generate questions. The main 117 difference between our work and previous ones 118 are in two sense (1) our proposed model uses the 119 shared encoder to tackle two classification tasks 120 (2) besides the loss function to optimize individual 121 tasks, we also propose two constraints that utilize 122 the relation between these two tasks. 123 3 HotpotQA Dataset 124 HotpotQA dataset (Yang et al., 2018) is designed 125 for multi-hop reasoning question answering tasks, 126 i.e. to reason over multiple documents and an-127 swer questions (see Figure 1). Particularly, Hot-128 potQA challenge requires reasoning over two pas-129 sages. Furthermore, to guide the system to perform 130 meaningful and explainable reasoning, the dataset 131 also provides supporting facts (SP) that reach the 132 answer to the question. HotpotQA provide two 133 challenging settings: in Fullwiki setting, a system 134 needs to rank passage from the entire wiki corpus; 135 in Distractor setting, 10 distracting passages (in-136 cluding relevant ones) are given for each question. 137 In this work, we mainly focus on the latter setting. 138 From the training set, we find that 70.4% questions 139 have exactly two supporting facts (SP), and 60.0% 140 of SP are the first sentence of passages. 141 4 Method 142 We aim to jointly conduct two tasks, passage rank-143 ing and supporting facts selection for HotpotQA. 144 Given a question Q, the goal is to simultaneously 145 rank the set of candidates A = {a 1 , ..., a i } and iden-3 183 and irrelevant sentence respectively. Equation 3 220 enforces that all the relevant sentences should have 221 higher similarity with the passage than all the ir-222 relevant sentences by a margin m; otherwise, the 223 model would be penalized. In practice, we set the 224 margin m at 1 and find optimum results. We train 225 our model in an end-to-end fashion by combining 226 L joint , L con and L dis . 227 5 Experiment 228 In this section, we first describe the training setup, 229 and then introduce two baselines. We evaluate the 230 two baselines and our proposed joint model on the 231 HotpotQA dataset. Yang et al. (2018) provides 232 two metrics for supporting facts evaluation, exact 233 matching (EM) and F1 score. We also present the 234 precision and recall of SP, and the exact match-235 ing of passages for detailed comparison. Mean-236 while, we compare our model with the QUARK 237 system (Groeneveld et al., 2020). Lastly, we con-238 duct an ablation study to show the effectiveness of 239 the proposed similarity loss and consistent loss.</p><p>240 5.1 Experiment Setup 241 We use Huggingface (Wolf et al., 2020) and Py-242 torch (Paszke et al., 2019) libraries to implement 243 each model. We use 4 TX1080 and V100 NVIDIA 244 to train models in 5 epochs with a learning rate of 245 1e-5, batch size of 32. We set the maximum input 246 length in training to be 512. 247 5.2 Baseline 248 To have comparable size of the model, two base-249 lines have similar structure as our Two-in-One 250 model. Our model has two classification heads, 251 whereas each of the baselines has one classification 252 head. One baseline is to select relevant sentences, 253 and the other one is to rank passages. 254 Sentence Selection Baseline The first base-255 line is to select relevant sentence, and particu-256 larly, we use a RoBERTa-large with an additional 257 MLP trained on question and a single sentence: 258 s Q /s S /s , where Q is a question and S is a 259 sentence. Although this model can not predict the 260 relevant passage directly, based on the assumption 261 that relevant passages include relevant sentences, 262 we pick up two relevant passages based on the 263 top2 sentence scores. When the top1 and the top2 264 sentences are from the same passage, we continue 265 searching based on the ranking sentence scores 266 We show the effectiveness of our proposed frame-380 work by evaluating the model performance on the 381 HotpotQA datasets, concluding that jointly mod-382 eling passage ranking and sentence selection is 383 beneficial for the task of OBQA. Compared to the 384 existing QA systems, our model, with fewer param-385 eters and more green than previous models, can 386 achieve competitive results. We also propose mul-387 tiple future directions to improve our model such 388 as exploring the relationship among passages, sup-389 porting sentences, and answers in modeling and 390</p><p>generalizing our method on more datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open book question answering (OBQA) requires a system to find the relevant documents to reason the answer to a question. It has wide and practical Natural Language Processing (NLP) applications such as search engines <ref type="bibr" target="#b3">(Kwiatkowski et al., 2019)</ref> and dialogue systems <ref type="bibr" target="#b8">(Reddy et al., 2019;</ref><ref type="bibr">Choi et al., 2018)</ref>. Among several OBQA datasets <ref type="bibr">(Dhingra et al., 2017;</ref><ref type="bibr" target="#b5">Mihaylov et al., 2018;</ref><ref type="bibr" target="#b2">Khot et al., 2020)</ref>, HotpotQA <ref type="bibr" target="#b14">(Yang et al., 2018)</ref> is more challenging because it requires a system not only to find the relevant passages from large corpus but also find the relevant sentences in the passage which eventually reach to the answer. Such a task also increases the interpretability of the systems.</p><p>To address this challenge, most of the previous work <ref type="bibr" target="#b6">(Nie et al., 2019;</ref><ref type="bibr" target="#b0">Fang et al., 2020;</ref><ref type="bibr" target="#b11">Tu</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>158</head><p>In details, given a question and a passage, we firstly 159 create an input to feed through RoBERTa <ref type="bibr">(Liu et al</ref> </p><formula xml:id="formula_0">L pass = (ŷ − y) 2 , L sent = K i=1 ( xi − x i ) 2 , L joint = L pass + L sent , (<label>1</label></formula><formula xml:id="formula_1">)</formula><formula xml:id="formula_2">177</formula><p>where ŷ is the predicted passage score, y is the 178 ground truth score of the passage, xi and x i are the predicted sentence score and ground truth score of S i , respectively, and K is the total number of sentences in the passage. We simply sum up the passage loss and sentence loss to jointly update model parameters.</p><p>During the inference time, passages are ranked based on the logits given by the passage ranker.</p><p>For the sentence classification, we take 0<ref type="foot" target="#foot_2">2</ref> as the threshold to classify the relevance of each sentence:</p><p>if the score given by the sentence classifier is larger than 0, then it is relevant; otherwise, irrelevant.</p><p>Next, we introduce two constraints to facilitate the interaction between these two tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Consistency Constraint</head><p>Intuitively, if a passage is relevant to the question, then there are some sentences from the passages that are relevant; on the other hand, if a passage is not relevant to the answer, then there should not be relevant sentences inside the passage. Thus, we propose a consistency constraint over the passage ranker and sentence classifier to minimize the gap between the passage score and the maximum sentence score. The loss function is as follows:</p><formula xml:id="formula_3">L con = (ŷ − max(x)) 2 ,<label>(2)</label></formula><p>where x = [x 1 . . . xn ] denotes a stack of predicted sentence scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Similarity Constraint</head><p>As we have shown at the beginning of this section, token s is used to get the passage score, and each token /s is used to get the sentence score.</p><p>Intuitively, the similarity between token s of a relevant passage is more close to token /s of a relevant sentence than to /s of any irrelevant sentence. To enforce this constraint, we use triplet as follows: </p><formula xml:id="formula_4">L sim = 1 N • M N i=1 M j=1 (max{d(v p , v r i ) − d(v p , v n j ) + m, 0}),<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Result</head><p>As we see from  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation</head><p>To evaluate the impacts of the consistency constraint and the similarity constraint, we conduct experiments with and without constraints. From  <ref type="bibr" target="#b1">(Groeneveld et al., 2020)</ref>, is the result of a framework with 3 BERT models, SAE <ref type="bibr" target="#b11">(Tu et al., 2019)</ref> uses two large language models and an GNN model, and HGN <ref type="bibr" target="#b0">(Fang et al., 2020)</ref> uses a large language model, a GNN model and other reasoning layers. predict the start and end position of the answer span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>337</head><p>A restricted inference procedure can be enforced</p><p>338 that the answer span should be predicted from the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we present a simple model, Two-in-One, to rank passage and classify sentence together.</p><p>By jointly training with passage ranking and sentence selection, the model is capable of capturing 5 185</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example from the HotpotQA dataset, where the question should be answered by combining supporting facts(SP) from two passages. In the SP, the first string refers to the title of passage, and the second integer means the index of the sentence.</figDesc><graphic url="image-1.png" coords="1,306.14,212.58,218.28,280.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. On top of the encoder, there are two MLP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>where d(•, •) is the Euclidian similarity, N is the number of relevant sentences, M is the number of irrelevant sentences, v p , v r , v n is the vector representation of the relevant passage, relevant sentence, until the second document comes up. Then the supporting facts are those sentences from the relevant documents with a score larger than 0. Passage Selection Baseline In the second baseline, again, we use RoBERTa-large but with the goal of passage selection. The input to the model is a question and a passage: s Q /s P /s . Since such a model can not predict sentence relevancy score, based on the statistic of HotpotQA that majority of training set has two supporting facts and the most of them are the first sentences in a paragraph (see Section 3), we select supporting facts by the first sentence of the top1 and top2 passages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>for the passage ranking by comparing Two-in-One with Passage Selection Baseline on the EM of passage. Besides, we also compare Two-in-One with QUARK<ref type="bibr" target="#b1">(Groeneveld et al., 2020)</ref>, a framework involving three BERT models, (roughly three times larger than ours). Two-in-One achieves comparable results in terms of F1 and EM of SP regardless of much less parameters in our system. Notice that we do not have the other three values because they are not presented in their original paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>339</head><label></label><figDesc>selected sentence given by the previous model. One 340 benefit is to reduce the difficulty for the answer 341 selection model since less sentences will be seen by 342 the model and the second benefit is to increase the 343 interpretability of the model. On the other hand, if the sentence selection model makes mistakes, then such errors will carry to the answer span model which yields the wrong answer eventually. Passage and Sentence Representation We use the contextual vector of a special token in front of each sentence to represent the sentence; we can also try to use the average pooling of every token in the sentence to get the representation of a sentence. Similar for the passage representation. Evaluate on More Dataset To show that the generalization of the proposed model, it can also evaluate on more datasets, such as NaturalQuestion (NQ) dataset (Kwiatkowski et al., 2019). Although the NQ dataset does not have annotated support sentences, the sentence which contains the answer can be taken as the support sentence to train the sentence selection model. It is worth mentioning that in the HotpotQA dataset, there are multiple support sentences while the NQ only has one, thus, if the Two-in-One model is trained on a single dataset, then one model might not generalize well to other dataset. A simple solution might be to train the Two-in-One model on multi-datasets. Zero-shot Testing It is also interesting to see if Two-in-One model can generalize better to unseen domains than simple baselines without any finetuning. To verify this, we can compare the Twoin-One model and baselines models trained on the HotpotQA dataset to other datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>., is the i th sentence from a passage. We take s</figDesc><table><row><cell>160</cell><cell></cell><cell></cell><cell></cell></row><row><cell>161</cell><cell cols="4">2019) by concatenating the question and the pas-</cell></row><row><cell>162</cell><cell cols="4">sage as follows, s Q /s S 1 /s S 2 ... /s S k /s where s and /s are special tokens in RoBERTa,</cell></row><row><cell>164</cell><cell></cell><cell></cell><cell></cell></row><row><cell>165</cell><cell cols="4">as the contextual representation for passage ranking</cell></row><row><cell>166</cell><cell cols="4">and the /s in front of each sentence for sentence</cell></row><row><cell>167</cell><cell cols="4">selection. The passage ranker and the sentence clas-</cell></row><row><cell>168</cell><cell cols="4">sifier have identical structure (two-layer Multiple-</cell></row><row><cell>169</cell><cell cols="4">Layer Perceptron(MLP)) but different weights.</cell></row><row><cell></cell><cell cols="4">Combine Selection: select the relevant sentences if</cell></row><row><cell></cell><cell></cell><cell cols="2">the passage is in top K</cell></row><row><cell></cell><cell>passage ranker</cell><cell></cell><cell>sentence classifier</cell></row><row><cell></cell><cell>&lt;s&gt;</cell><cell>&lt;/s&gt;</cell><cell>&lt;/s&gt;</cell><cell>&lt;/s&gt;</cell></row><row><cell></cell><cell></cell><cell></cell><cell>RoBERTa</cell></row><row><cell></cell><cell cols="3">&lt;s&gt;Q&lt;/s&gt;S1&lt;/s&gt;S2...&lt;/s&gt;Sk&lt;/s&gt;</cell></row><row><cell></cell><cell>Query</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Passages</cell></row><row><cell></cell><cell cols="4">Figure 2: The architecture of Two-in-One model for passage ranking and relevant sentence selection. For HotpotQA dataset, K is two.</cell></row><row><cell>170</cell><cell cols="4">The model is jointly trained by passage loss and</cell></row><row><cell>171</cell><cell cols="4">sentence loss. In detail, during the training time,</cell></row><row><cell>172</cell><cell cols="4">we assign the relevant passages and sentences with</cell></row><row><cell>173</cell><cell cols="4">ground truth score 1 while irrelevant passages and</cell></row><row><cell>174</cell><cell cols="4">sentences with ground truth score -1. Then, Mean</cell></row><row><cell>175</cell><cell cols="4">Square Error(MSE) loss is applied to calculate the</cell></row><row><cell>176</cell><cell cols="3">passage and sentence loss as follows,</cell></row></table><note>163S i</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table /><note>, Two-in-One framework outperforms two baselines with large-margin improvement in all metrics, especially we see a significant improvement on the EM of SP. Our framework outperforms the Sentence Selection Baseline by 20% and 4.5% improvement on the precision and recall of SP, respectively, which demonstrates that jointly learning is beneficial for sentence classification. Also, jointly learning benefits</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>, we see that both consistency constraint</cell></row><row><cell>and similarity constraint improve F1 and EM of</cell></row><row><cell>SP and the similarity constraint also improves the</cell></row><row><cell>EM of passages. We found that without any con-</cell></row><row><cell>straint, though the model can rank the passages</cell></row><row><cell>well, it suffers from distinguishing between close</cell></row><row><cell>sentences. The similarity constraint addresses this</cell></row><row><cell>issue in some sense by maximizing the distance</cell></row><row><cell>between relevant and irrelevant sentences.</cell></row><row><cell>To better understand the impact of consistency</cell></row><row><cell>constraint, we analyze the consistency between the</cell></row><row><cell>passage score and the sentence score. The predic-</cell></row><row><cell>4 184</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>The Results for two baselines and Two-in-One model with similarity constraint on dev set of HotpotQA distracting dataset. SP stands for supporting facts and EM for Exact Match. * refers to estimation. The bottom systems have much larger model size than our method, where QUARK</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>The results for Two-in-One model with or without consistency and similarity constraints.</figDesc><table><row><cell></cell><cell>Model</cell><cell cols="3">SP F1 SP EM Passage EM</cell></row><row><cell></cell><cell>Two-in-One</cell><cell>85.52</cell><cell>58.67</cell><cell>90.93</cell></row><row><cell></cell><cell>Two-in-One + con</cell><cell>85.55</cell><cell>58.98</cell><cell>90.29</cell></row><row><cell></cell><cell cols="2">Two-in-One + sim Two-in-One + con + sim 85.63 85.82</cell><cell>59.17 58.74</cell><cell>91.11 90.78</cell></row><row><cell>319</cell><cell></cell><cell></cell><cell></cell></row><row><cell>320</cell><cell cols="4">sentences in that passage. We observe that by</cell></row><row><cell>321</cell><cell cols="4">adding the consistency constraint, the gap between</cell></row><row><cell>322</cell><cell cols="4">the passage score and the sentence score is much</cell></row><row><cell>323</cell><cell cols="4">smaller than without the consistency constraint, i.e.</cell></row><row><cell>324</cell><cell cols="4">0.03 v.s. 0.11. It demonstrates that the constraint is</cell></row><row><cell>325</cell><cell cols="3">beneficial for consistent prediction.</cell></row><row><cell>326</cell><cell>6 Future Work</cell><cell></cell><cell></cell></row><row><cell>327</cell><cell cols="4">While in this work, we show the initial and promis-</cell></row><row><cell>328</cell><cell cols="4">ing results of the Two-in-One model on one single</cell></row><row><cell>329</cell><cell cols="4">dataset, there are a couple of directions we can</cell></row><row><cell>330</cell><cell cols="4">explore in the future such as those discussed below.</cell></row><row><cell>331 332</cell><cell cols="4">Model Architecture It is easy to extend the Two-in-One model to Three-in-One model such that</cell></row><row><cell>333</cell><cell cols="4">besides the passage ranking and sentence selection</cell></row><row><cell>334</cell><cell cols="4">modules, a third module can predict the answer</cell></row><row><cell>335</cell><cell cols="4">span. Like the simple extractive QA model based</cell></row><row><cell>336</cell><cell cols="4">on RoBERTa, where a linear layer or an MLP can</cell></row></table><note>tion of a model is consistent if the passage score 316 agrees with the sentence scores and the agreement 317 can be measured by the gap between the passage 318 score and the maximum sentence score among all</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The value of K depends on the task, and for HotpotQA, K is</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">The reason for threshold "0" is that it is the middle value of 1 and -1, which are labels for relevant and irrelevant sentences in the training time.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 182 model <ref type="bibr" target="#b12">(Vaswani et al., 2017)</ref> to encode questions</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>pirical Methods in Natural Language Processing, pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics. 7 187</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hierarchical 431 graph network for multi-hop question answering</title>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohit</forename><surname>Pillai</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.710</idno>
	</analytic>
	<monogr>
		<title level="m">432 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8823" to="8838" />
		</imprint>
	</monogr>
	<note>Shuo-430 hang Wang, and Jingjing Liu</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple yet strong pipeline for HotpotQA</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName><surname>Sabharwal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.711</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8839" to="8845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">QASC: A dataset for question answering via sentence composition</title>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Guerquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07">2020. February 7-12, 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="8082" to="8090" />
		</imprint>
	</monogr>
	<note>The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Natural questions: A benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Transactions of the Association for Computational Linguistics</publisher>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv preprint</title>
		<imprint>
			<date type="published" when="1907">2019. 1907.11692</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1260</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2381" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Revealing the importance of semantic retrieval for machine reading at scale</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1258</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2553" to="2566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep 6 186 learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Köpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08">2019. 2019. 2019. December 8-14, 2019</date>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">CoQA: A conversational question answering challenge</title>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00266</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Green ai</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="54" to="63" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Joint learning of question answering and question generation</title>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="971" to="982" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<idno>abs/1911.00484</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
				<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04">2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Em</title>
				<meeting>the 2018 Conference on Em</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
