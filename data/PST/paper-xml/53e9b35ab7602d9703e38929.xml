<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributed Similarity Search in High Dimensions Using Locality Sensitive Hashing *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Michel</surname></persName>
							<email>sebastian.michel@epfl.ch</email>
						</author>
						<author>
							<persName><forename type="first">Karl</forename><surname>Aberer</surname></persName>
							<email>karl.aberer@epfl.ch</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Parisa Haghani EPFL</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributed Similarity Search in High Dimensions Using Locality Sensitive Hashing *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CE362CF8F43618F9B1340E8D2FAA52E5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-Search process</term>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing-Indexing methods</term>
					<term>H.4.m [Information Systems]: Miscellaneous Distributed High Dimensional Search knn search, range query, high dimensionality, p2p</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we consider distributed K-Nearest Neighbor (KNN) search and range query processing in high dimensional data. Our approach is based on Locality Sensitive Hashing (LSH) which has proven very efficient in answering KNN queries in centralized settings. We consider mappings from the multi-dimensional LSH bucket space to the linearly ordered set of peers that jointly maintain the indexed data and derive requirements to achieve high quality search results and limit the number of network accesses. We put forward two such mappings that come with these salient properties: being locality preserving so that buckets likely to hold similar data are stored on the same or neighboring peers and having a predictable output distribution to ensure fair load balancing. We show how to leverage the linearly aligned data for efficient KNN search and how to efficiently process range queries which is, to the best of our knowledge, not possible in existing LSH schemes. We show by comprehensive performance evaluations using real world data that our approach brings major performance and accuracy gains compared to state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The rapid growth of online information, triggered by the popularity of the Internet and the huge amounts of usergenerated content from Web 2.0 applications, calls for efficient management of this data to improve usability and enable efficient and accurate access to the data. User-generated data today range from simple text snippets to (semi-) structured documents and multimedia content. To enable rich representation and avoid loss of information, the number of features extracted to represent the data is very often high. Furthermore, as the data sources are naturally distributed in large-scale networks, traditional centralized indexing techniques become impractical. To address the demanding needs caused by this rapidly growing, large-scale, and naturally distributed information ecology, we propose in the following an efficient, distributed, and scalable index for high-dimensional data enabling efficient and accurate similarity search.</p><p>Peer-to-Peer (P2P) overlay networks are well-known to facilitate the sharing of large amounts of data in a decentralized and self-organizing way. These networks offer enormous benefits for distributed applications in terms of efficiency, scalability, and resilience to node failures. Distributed Hash Tables (DHTs) <ref type="bibr" target="#b32">[30,</ref><ref type="bibr" target="#b30">28]</ref>, for example, allow efficient key lookups in logarithmic number of routing hops but are typically limited to exact or range queries. Similarity search in high dimensional data has been a popular research topic in the last years <ref type="bibr">[9,</ref><ref type="bibr" target="#b19">17,</ref><ref type="bibr" target="#b34">32,</ref><ref type="bibr" target="#b10">8,</ref><ref type="bibr" target="#b16">14]</ref>. Distributed processing of such queries is even more complicated, but is unavoidable due to the inherently distributed way data is generated in the Web. Existing approaches to the similarity search problem in high dimensional data either focus on centralized settings, as cited above, rely on preprocessing data centrally, assume data ownership by peers in a hierarchical P2P setting or fail at providing both high quality search results and a fair load balance in the network <ref type="bibr" target="#b18">[16,</ref><ref type="bibr" target="#b31">29,</ref><ref type="bibr" target="#b17">15]</ref>.</p><p>In this paper we consider similarity search over high dimensional data in structured overlay networks. Inspired by the idea of Locality Sensitive Hashing (LSH) technique <ref type="bibr" target="#b19">[17,</ref><ref type="bibr" target="#b16">14]</ref> which probabilistically assigns similar data to the same bucket in a hash table, we first investigate the difficulties of directly applying this method to a distributed environment and then devise two locality preserving mappings which satisfy the identified requirements of bucket placement on peers of a P2P network. The first requirement, placing buckets which are likely to hold similar data on the same peer or its neighboring peers, aims at minimizing the number of network hops necessary to retrieve the search results, causing a decrease in both network traffic and the overall response time. The second requirement considers load balancing and is satisfied by harnessing estimates of the distribution of resulting data (bucket) mapping. The basic ideas for our approach appeared in a preliminary short paper at a workshop <ref type="bibr" target="#b21">[19]</ref>. This current work substantially extends the prior work in the following ways: we capture the notion of buckets likely to hold similar data, enabling more elaboration on suitability of different mapping scheme. We propose another novel mapping schemes which satisfies our identified requirements. We also address range queries which are difficult to process in LSH-based indexing techniques and show how our proposed mappings can be used to derive estimates of the range of necessary peers to be visited. In addition, we extended our experimental evaluation by considering more datasets and comparing against state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Problem Statement and System Overview</head><p>In similarity search objects are characterized by a collection of relevant features and are represented as points in a high dimensional space. In some applications the objects are considered in a metric space where only a distance function is defined among them and the features of the objects are unknown. However, with the advances in metric space embedding (cf. <ref type="bibr" target="#b2">[1]</ref>) a vector space assumption is valid and realistic. Given a collection of such points and a distance function between them, similarity search can be performed in the following two forms:</p><p>• K-Nearest Neighbor (KNN) query: Given a query point q the goal is to find the K closest (in terms of the distance function) points to it.</p><p>• range query: Given a query point q and a range r the goal is to find all points within a distance r of q.</p><p>In many applications returning the approximate KNN of a point, instead of the exact ones, suffices. The approximate version is even more desirable when the data dimensionality is high, as similarity search is very expensive in such domains. Here, the goal is to find K objects whose distances are within a small factor (1+ ) of the true K nearest neighbors' distances. The quality of similarity search is measured by the number of returned results, as well as the distances to the query for the K points returned compared to the corresponding distances of the true K nearest objects for KNN queries.</p><p>We consider similarity search in structured peer-to-peer networks, where N peers P1, ..., PN are connected by a DHT that is organized in a cyclic ID space, such as in Chord <ref type="bibr" target="#b32">[30]</ref>. Every node is responsible for all keys with identifiers between the ID of its predecessor node and its own ID. Our underlying similarity search method is probabilistic and relies on building several indices of data to achieve highly accurate query results. We assume each of these data indices is maintained by a subset of size n of all peers where n is an order of magnitude smaller than N . Each of these subsets form a local DHT among themselves. For each replica of the data we deterministically select a subset of peers to hold the corresponding index, i.e., not all peers hold a share of the index from the beginning. These initially selected peers are gateway peers to the corresponding local DHTs. The number of peers/nodes inside each local DHT might grow/shrink over time depending on the load of the system. The locations (IDs) of the gateway peers is global knowledge based on a deterministic sampling process with fixed seed value. However, not the peers are known but only their IDs in the underlying network. We explain this process in more detail in Section 4. If a gateway peer is not accessible, the peer currently holding the gateway peer ID is asked to join the local DHT using one of the other gateway peers. These dynamics are handled by the underlying network and are beyond the scope of this paper.</p><p>Our goal is to map the high dimensional data to the peers in a way that assures fair load balancing in the local DHTs and at the same time enables efficient and accurate KNN and range query processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contribution and Outline</head><p>With this work we make the following contributions:</p><p>• We discuss the difficulties of distributing existing LSH schemes and derive requirements to distribute them in a way that assures fair load balance and efficient and accurate similarity search processing.</p><p>• We present two novel mapping schemes which satisfy the mentioned requirements.</p><p>• We present a top-K algorithm to efficiently process distributed KNN queries.</p><p>• We show, relying on our mapping schemes, how otherwisedifficult-to-process range queries can be efficiently processed in our setting by presenting a novel samplingbased method which utilizes our estimated range of peers necessary to contact.</p><p>• We experimentally evaluate the efficiency and effectiveness of our approach using two real-world data sets.</p><p>The rest of this paper is organized as follows. Section 2 discusses related work. Section 3 presents the requirements of distributing LSH indices to the linear peer domain and puts forward two mappings which satisfy those requirements. Section 4 concentrates on the creation of the local DHTs. Section 5 presents the KNN query processing algorithms. Section 6 addresses the challenges in processing range queries and presents an approach based on range sampling to overcome these constraints. Section 7 presents the experimental evaluation of our approach. Section 8 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Similarity search in high dimensional spaces has been the focus of many works in the database community in the recent years. The problem has been intensively researched on in the centralized setting, for which the approaches can be divided into two main categories. Space partitioning methods form the first category consisting of all tree-based approaches such as R-tree <ref type="bibr" target="#b20">[18]</ref> and K-D trees <ref type="bibr" target="#b9">[7]</ref>, which perform very well when data dimensionality is not high but degrade to linear search for high enough dimensions <ref type="bibr">[9]</ref>. The Pyramid <ref type="bibr" target="#b10">[8]</ref> and iDistance <ref type="bibr" target="#b34">[32]</ref> techniques map the high dimensional data to one dimension and partition/cluster that space to answer queries by translating them to the one dimensional space. The second category consists of hash-based approaches which trade accuracy for efficiency, by returning approximate closest neighbors of a query point. LSH <ref type="bibr" target="#b19">[17]</ref> is an approximate method, which uses several locality preserving hash functions to hash the data, such that with high probability close points are hashed to the same bucket. While this method is very efficient in terms of time, tuning such hash functions depends on the distance of the query point to its closest neighbor. Several follow-ups of this method exist which try to solve the problems associated with it <ref type="bibr" target="#b8">[6,</ref><ref type="bibr" target="#b16">14,</ref><ref type="bibr" target="#b25">23,</ref><ref type="bibr" target="#b27">25,</ref><ref type="bibr" target="#b3">2]</ref>. Very recently <ref type="bibr" target="#b5">[4]</ref> proposed a method based on distance hashing which has the advantage of not depending on any specific distance measure, but involves some off-line tuning of parameters. Approximate range search in high dimensions has also been the focus of some works such as <ref type="bibr" target="#b4">[3,</ref><ref type="bibr" target="#b14">12]</ref> which return points in (1 + )r of the query point, instead of retrieving points which have exactly distance smaller or equal to r to the query point. In this work we do not consider approximate ranges queries.</p><p>With the emergence of the P2P paradigm <ref type="bibr" target="#b32">[30,</ref><ref type="bibr" target="#b30">28]</ref>, there has been a tendency to leverage the power of distributed computing by sharing the cost incurred by such methods over a set of machines. A number of P2P approaches, such as <ref type="bibr" target="#b15">[13,</ref><ref type="bibr" target="#b12">10,</ref><ref type="bibr" target="#b13">11]</ref> have been proposed for similarity search, but they are either dedicated to one dimensional data or do not consider very high dimensional data. MCAN <ref type="bibr" target="#b18">[16]</ref> uses a pivot-based technique to map the high dimensional metric data to an N-dimensional vector space, and then uses CAN <ref type="bibr" target="#b30">[28]</ref> as its underlying structured P2P system. The pivots are chosen based on the data, which is preprocessed in a centralized fashion and then distributed over the peers. SWAM <ref type="bibr" target="#b7">[5]</ref> is a family of Small World Access Methods, which aims at building a network topology that groups together peers with similar content. In this structure peers can hold a single data item each, which is not well-suited for large data sets. SkipIndex <ref type="bibr" target="#b35">[33]</ref> and VBI-tree <ref type="bibr" target="#b23">[21]</ref> both rely on tree-based approaches which do not scale well when data dimensions are high. In pSearch <ref type="bibr" target="#b33">[31]</ref>, the well known information retrieval techniques Vector Space Model (VSM) and Latent Semantic Indexing(LSI) are used to generate a semantic space. This Cartesian space is then directly mapped to a multidimensional CAN which basically has the same dimensionality of the Cartesian space (as high as 300 dimensions). Since the dimensionality of the underlying peer-to-peer network depends on the dimensionality of the data (or the number of reduced dimensions) different overlays are needed for various data sets with different dimensionality. This dependency and centralized computation of LSI make this approach less practical in real applications. In <ref type="bibr" target="#b31">[29]</ref> the authors follow pSearch by employing VSM and LSI, but map the resulting high dimensional Cartesian space to a one dimensional Chord. Unlike pSearch this method is independent of corpus size and dimensionality. This is the closest work in state of the art to us, since it considers high dimensional data over a structured peer-to-peer system. We compare our approach to this work and explain it in more depth in Section 2.1. Recently, SimPeer <ref type="bibr" target="#b17">[15]</ref> was proposed, which uses the principle of iDistance <ref type="bibr" target="#b22">[20]</ref> to provide range search capabilities in a hierarchical unstructured P2P network for high dimensional data. In this work also, the peers are assumed to hold and maintain their own data. On the contrary, we consider efficient similarity search over structured P2P networks, which guarantees logarithmic lookup time in terms of network size, and leverage on LSH-based approaches to provide approximate results to KNN search efficiently, even in very high dimensional data. Our approach also enables efficient range search which is difficult in LSH-based approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Approach by Sahin et al.</head><p>Here we briefly describe the approach of <ref type="bibr" target="#b31">[29]</ref>. A globally known list R = r1, r2, ..., rv of reference data points is considered. These are either randomly chosen from the data set or are the cluster representatives of a clustered sample set. In order to index a data point v, it is compared against all reference points and a sorted list of references in increasing distance to v is constructed. The first j references, which are the reference points closest to v are used to make the Chord key for it: the binary representations of the ID's of these j references are concatenated, with the highest relevant refer-ence as the high order bits. If there are any remaining bits in the Chord bit representation, they are filled with zeros. The intuition behind this approach is that points which are close to each other, share common top references and will therefore be stored at the same peer. In order to increase the probability of this event, multiple Chord keys are made for each data point, choosing j different reference points, or different permutations of them. At query time, the query point is similarly mapped to the Chord ring and the corresponding peers are scanned with the K closest points returned and merged at the peer issuing the query. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of indexing a data point. This approach of mapping data points to the Chord ring focuses on placing close points on the same peer and does not exploit nearby peers. For example a data point q close to v might have (r6, r4) as its two first closest references, corresponding to the Chord key 1001100000, resulting in placing it on a far peer from where v is placed (i.e. 1101000000). In our approach we aim at placing close points on the same peer or neighboring peers to exploit the linear order of peers in Chord style DHTs and avoid high number of DHT lookups.</p><p>Sorted reference list (v) = {r 6 ,r 4 ,r 0 ,r 5 ,r 2 ,r 1 ,r 3 ,r 7 } R = {r 0 ,r 1 ,r 2 ,r 3 ,r 4 ,r 5 ,r 6 ,r 7 }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference points to create Chord keys</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corresponding</head><p>Chord keys ), j is 2 and each data point is replicated three times.</p><formula xml:id="formula_0">(1 st ,2 nd ) (1 st ,3 rd ) (2 nd ,<label>3 rd ) (r6,r4) (r6,r0) (r4,r0</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Revisiting LSH</head><p>The basic idea behind the LSH-based approaches is the application of locality sensitive hashing functions. A family of hash functions H = {h : S → U } is called (r1, r2, p1, p2)sensitive if the following conditions are satisfied for any two points q, v ∈ S:</p><formula xml:id="formula_1">• if dist(q, v) ≤ r1 then P rH (h(q) = h(v)) ≥ p1 • if dist(q, v) &gt; r2 then P rH (h(q) = h(v)) ≤ p2</formula><p>where S specifies the domain of points and dist is the distance measure defined in this domain.</p><p>If r1 &lt; r2 and p1 &gt; p2, the salient property of these functions results in more similar objects being mapped to the same hash value than distant ones. The actual indexing is done using LSH functions and by building several hash tables to increase the probability of collision (i.e. being mapped to the same hash value) for close points. At query time, the KNN search is performed by hashing the query point to one bucket per hash table, scanning that bucket and then ranking all discovered objects by their distance to the query point. The closest K points are returned as the final result.</p><p>In the last few years, the development of locality sensitive hash functions has been well addressed in the literature. In this work, we consider the family of LSH functions based on p-stable distributions <ref type="bibr" target="#b16">[14]</ref>. This family of LSH functions are most suitable when the distance measure between the points is the lp norm. Given a point v = v1, . . . , v2 in the ddimensional vector space, its lp norm is defined as: ||v||p = (|v1| p + ... + |v d | p ) 1/p . Stable Distribution: A distribution D over IR is called pstable, if there exists p ≥ 0 such that for any n real numbers r1 . . . rn and i.i.d. variables X1 . . . Xn with distribution D, the random variable i riXi has the same distribution as the variable ( i |ri| p ) 1/p X, where X is a random variable with distribution D. p-stable distributions exist for p ∈ (0, 2]. The Cauchy and Normal distributions are respectively 1-stable and 2-stable.</p><p>In the case of p-stable LSH, for each d-dimensional data point v the hashing scheme considers k independent hash functions of the following form :</p><formula xml:id="formula_2">ha,B(v) = a • v + B W (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>where a is a d -dimensional vector whose elements are chosen independently from a p-stable distribution, W ∈ IR, and B is drawn uniformly from [0, W ]. Each hash function maps a d-dimensional data point to an integer. With k such hash functions, the final result is an integer vector of dimension k of the the following form:</p><formula xml:id="formula_4">g(v) = (ha 1 ,B 1 (v), ..., ha k ,B k (v))<label>(2)</label></formula><p>In this work we assume the distance function is the widely used l2 norm (Euclidean distance) and use the Normal distribution as our p-stable distribution.</p><p>In LSH-based schemes, in order to achieve high search accuracy, multiple hash tables need to be constructed. Experimental results <ref type="bibr" target="#b19">[17]</ref> show that the number of hash tables needed can reach up to over a hundred. In centralized settings this causes space efficiency issues. While this constraint is less visible in a P2P setting, a high number of hash tables results in another serious issue arising specifically in this environment. In order to visit all hash tables (which is needed to answer the KNN query with good accuracy) a large number of peers may need to be contacted. Solutions to this shortcoming in centralized settings <ref type="bibr" target="#b25">[23,</ref><ref type="bibr" target="#b27">25]</ref> suggest investigating more than one bucket in each hash table, instead of building many different hash tables. The main idea is that we can guess which buckets other than the bucket which the query hashes to, are more likely to hold data that is similar to the query point. In our envisioned P2P scenario, jumping from one bucket to another can potentially cause jumping from one peer to another, which induces O(log n) network hops in a network of n peers. In the following section, we discuss and introduce mapping schemes which allow us to significantly reduce the number of incurred network hops during query time by grouping those buckets which are likely to hold similar data on the same peer, while effectively balancing the load in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MAPPING LSH TO THE PEER IDENTI-FIER SPACE</head><p>Given the output of the p-stable LSH, which is a vector of integers, we consider a mapping to the peer identifier space, denoted as ξ :</p><formula xml:id="formula_5">Z k → IN.</formula><p>Different instances of the mapping function ξ come with different characteristics w.r.t. to load balancing and the ability to efficiently search the index. In terms of network bandwidth consumption and number of network hops, clearly, a mapping of all data to just one peer is optimal. Obviously, this mapping suffers from a huge load imbalance. The other extreme is to assign each hash bucket to a peer using a pseudo-uniform hash function that provides perfect load balancing but steals any control on grouping similar buckets on the same peer, therefore causing an excessive number of DHT lookups. More formally, ξ should satisfy the following two conditions:</p><p>• Condition 1: assign buckets likely to hold similar data to the same peer.</p><p>• Condition 2: have a predictable output distribution which fosters fair load balancing.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> shows an illustration of the overall mapping from the d-dimensional space, to the k-dimensional LSH buckets, to finally the peer identifier space using ξ.  We first try to capture the semantics of similar buckets: buckets likely to hold close data. The first condition of the LSH definition states that close points are more likely to be mapped to the same hash value. However, it is not clear which hash buckets are more probable to hold similar data. This has been discussed also in <ref type="bibr" target="#b25">[23,</ref><ref type="bibr" target="#b27">25]</ref> in a query-dependent way. However we need a more general view, as mapping buckets to peers should be independent of queries. We show that using hash functions of the form of Equation 1 close points have a higher probability of being mapped to close integers, that is, integers with small l1 distance. This is more general than the LSH definition, i.e. being hashed to the same value. Since bucket labels are concatenations of such integers, we argue that the l1 distance can capture the distance between buckets, buckets likely to hold close data have small l1 distance to each other. We prove the following theorems following the above argument.</p><p>Theorem 1 For any three points v1, v2, q ∈ S where ||q-v1||2 = c1 and ||q-v2||2 = c2 and c1 &lt; c2 the following inequality holds: <ref type="figure">c,</ref><ref type="figure">δ</ref>). We want to show that for any fixed δ, s(c, δ) is monotonically decreasing in terms of c. We first derive t(c, δ). Our argument is similar to that of <ref type="bibr" target="#b16">[14]</ref>. Since elements of the random vector a are chosen from a standard Normal distribution, a.qa.v is distributed according to cX where X is a random variable drawn from a Normal distribution. Therefore the probability distribution of |a.q -a.v| is 1 c f ( x c ) where f (x) denotes the probability density function of the absolute value of the standard Normal distribution (i.e., the mean is zero and the variance is one) :</p><formula xml:id="formula_6">pr(|h(q) -h(v1)| ≤ δ) ≥ pr(|h(q) -h(v2)| ≤ δ) Proof. Let s(c, δ) := pr(|h(q) -h(v)| ≤ δ) and t(c, δ) := pr(|h(q) -h(v)| = δ) where ||q -v||2 = c. Then s(c, δ) can be written as s(c, δ) = t(c, 0) + • • • + t(</formula><formula xml:id="formula_7">f (x) = 0 if x &lt; 0 2 √ 2π e -x 2 /2 if x ≥ 0</formula><p>For δ = 0, in order to have |h(q) -h(v1)| = δ, |a.qa.v| has to be in [0, W ). Depending on the exact value of |a.q -a.v| different range of values for B can leave |h(q)h(v1)| = 0 or change it to |h(q) -h(v1)| = 1. For example if |a.q -a.v|=0, all values of B ∈ [0, W ) keep the desired values |h(q) -h(v1)| = 0. The size of this range of values for B decreases linearly as |a.q -a.v| increases inside [0, W ), until it reaches 0 for |h(q) -h(v1)| = W . Since B is drawn uniformly at random from [0, W ], the following can be derived:</p><formula xml:id="formula_8">t(c, 0) = W 0 1 c f ( u c )(1 - u W )du</formula><p>The case for δ &gt; 0 is similar. However this time, a bigger range of values ([(δ -1)W, (δ + 1)W )) for |a.q -a.v| can satisfy |h(q) -h(v1)| = δ . The argument regarding B is similar to above. Therefore the following can be seen:</p><formula xml:id="formula_9">t(c, δ) = (δ)W (δ-1)W 1 c f ( u c )( u W -(δ -1))du + (δ+1)W (δ)W 1 c f ( u c )((δ + 1) - u W )du<label>(3)</label></formula><p>Summing up all values of t(c, d) for d ≤ δ, we arrive at the following for s(c, δ):</p><formula xml:id="formula_10">s(c, δ) = (δ+1)W 0 1 c f ( u c )du + (δ+1)W (δ)W 1 c f ( u c )(δ - u W )du</formula><p>With a change of variable v = u c we can eliminate all occurrences of c inside the integrals and take the derivative of s(c, δ) in terms of c. Given that uf (u)du = -f (u), this will lead us to:</p><formula xml:id="formula_11">∂s(c, δ) ∂c = 1 W (f ( (δ + 1)W c ) -f ( (δ)W c ))</formula><p>which is smaller than 0 for all values of c &gt; 0, as f (x) is monotonically decreasing. Therefore for any fixed δ, s(c, δ) is monotonically decreasing in terms of c. 2</p><p>Theorem 2 For any two points q, v ∈ S, pr(|h(q)h(v)| = δ) is monotonically decreasing in terms of δ.</p><formula xml:id="formula_12">Proof. Let ||q -v||2 = c. From Theorem 1, pr(|h(q) - h(v)| = δ) is equal to Eq. 3.</formula><p>It is easy to see that if we take the derivative from this equation in terms of δ we arrive at the following:</p><formula xml:id="formula_13">∂t(c, δ) ∂δ = - (δ)W c (δ-1)W c f (u)du + (δ+1)W c (δ)W c f (u)du</formula><p>which is smaller than zero, as the range of the two integrals is equal, the term under both is the same and is monotonically decreasing and non negative for the values under comparison.</p><p>2</p><p>The above two theorems indicates that l1 can capture the distance between buckets in terms of probability of holding close data: Given bucket labels b1,b2 and b3 which are integer vectors of dimension k, if ||b1 -b2)||1 &lt; ||b1 -b3||1, then b1 and b2 have a higher probability to hold similar data than b1 and b3.</p><p>Having a better understanding of the semantics of similar buckets, we now discuss two mappings which satisfy the two conditions mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Linear Mapping based on Sum</head><p>We propose ξsum(b) = k i=1 bi as an appropriate placement function which can be used to map the k-dimensional vector of integer b, as the output of p-stable LSH, to the one dimensional peer identifier space. The intuition is that the sum treats all bucket label parts bi equally and that minor differences in the bi values are smoothed out by the sum leading to close ξsum() values for "close" bucket labels. In the following, we show how relying on p-stable LSH and its characteristics, it satisfies both conditions above.</p><p>We first investigate condition 1. As discussed in the previous section, buckets which are likely to hold similar data have small l1 distance to each other. Given ξsum as our mapping function we have:</p><formula xml:id="formula_14">|ξsum(b1) -ξsum(b2)|=|(b11 - b21) + • • • + (b 1k -b 2k )| ≤ ||b1 -b2||1.</formula><p>Which means if buckets with labels b1 and b2 are likely to hold similar data, ξsum(b1) and ξsum(b2) will also be close. Given the assignment of data to peers in Chord-style overlays, this results in assigning the two buckets to the same or neighboring peers in the Chord ring with high probability.</p><p>As for the second condition, assume d -dimensional points, a and v1. If elements of a are chosen from a Normal distribution with mean 0 and standard deviation 1, denoted as N(0,1), a • v1 is distributed according to the Normal distribution N (0, ||v1||2). For not too large W , ha,B(v1) is distributed according to the Normal distribution</p><formula xml:id="formula_15">N ( W 2W , ||v 1 || 2 W</formula><p>) where h is function of the form Eq. 1. Therefore g(v1) will be a k -dimensional vector, whose elements follow the above distribution. We can now benefit from a nice property of the Normal distributions under summation: ξsum(g(v1)) is distributed according to the Normal distribution</p><formula xml:id="formula_16">N ( k 2 , √ k||v1||2 W )</formula><p>The global picture consisting of all data points v1, . . . , v M first projected using p-stable LSH and then mapped to Z by ξsum, following the Normal distribution</p><formula xml:id="formula_17">N ( k 2 , k i ||v i || 2 2 √ M W )</formula><p>We can therefore predict the distribution of the output of ξsum, having an estimate of the mean of data points' l2 norm. We assume that we know the mean norm of available data, but as we will later see, this assumption is only relevant for the start-up of the system where gateway peers are inserted into the hash tables. Calculating statistics, like in our case the mean, over data distributed in large-scale systems has been well addressed in the literature (cf., e.g., <ref type="bibr" target="#b24">[22]</ref>). In Section 4 we show how this can be used to balance the load in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Linear Mapping based on Cauchy LSH</head><p>As another instance of ξ we propose the LSH function based on Cauchy distribution (1-stable) which offers a probabilistic placement of similar buckets on the same peer. More formally, for a bucket label b,</p><formula xml:id="formula_18">ξ lsh a ,B (b) = a • b + B W2</formula><p>where elements of a are chosen independently from a standard Cauchy distribution with probability distribution function</p><formula xml:id="formula_19">cr(x; x0, γ) = 1 πγ 1 1 + ( x-x 0 γ ) 2</formula><p>where the location parameter x0 = 0, scale parameter γ = 1, W2 ∈ IR, and B is chosen uniformly from [0, W2]. Note that b denotes a bucket label and is a k dimensional vector of integers which is itself the output of an LSH function applied on a d-dimensional data point. Given that this LSH function is most suitable for the l1 norm and that l1 captures the dissimilarity among buckets, ξ lsh a ,B probabilistically satisfies condition 1.</p><p>The output distribution of this function is similarly predictable. Assume a bucket label b1. Given the characteristics of p-stable distributions, a • b1 follows the distribution ||b1||1X where X is a Cauchy distribution. For not too large W2, h a ,B (b1) is distributed with the probability distribution function</p><formula xml:id="formula_20">cr(x; W2 2W2 , ||b1||1<label>W2</label></formula><formula xml:id="formula_21">)</formula><p>a Cauchy distribution with location parameter 1 2 and scale parameter ||b 1 || 1 W 2 . Now, considering all bucket labels, b1, . . . , b P mapped to Z by ξ lsh a ,B , the output follows the Cauchy distribution with location parameter 1 2 and scale parameter ||b i || 1 P W 2 . In this case, to be able to predict the distribution of the output, we need the mean of l1 norms of all possible bucket labels. Since the initial hash functions ha,B are known to all peers, this again boils down to the problem of distributed statistics calculation <ref type="bibr" target="#b24">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">LOCAL DHT CREATION</head><p>To map a particular domain of integer values to a (subset of) peers, it is important to know the size and distribution of the domain. As discussed in Sections 3.1 and 3.2 the values generated by ξsum and ξ lsh follow known distributions. We briefly describe how this information can be utilized to create local DHTs which as described in Section 1.1 maintain the data index, for a more detailed description see <ref type="bibr" target="#b21">[19]</ref>.</p><p>Consider a linear bucket space of M buckets in which we want to distribute the values generated by the ξsum mapping. The case for ξ lsh follows similarly. Let µsum, σsum be the mean and the standard deviation of the values generated by ξsum (cf. Section 3). We choose the first bucket (at position 1) to be responsible for µsum -2 * σsum and the last bucket (at position M ) to be responsible for µsum +2 * σsum. We restrict ourselves to the span of two standard deviation to avoid overly broad domains and map the remaining data to the considered range via a simple modulo operation:</p><formula xml:id="formula_22">ψ(value) := ( value -(µsum -2 * σsum) 4 * σsum * M ) mod M (4)</formula><p>As mentioned in Section 1.1 we want to maintain each particular LSH hash table (which is an index of the whole data points) by a subset of peers that is usually some orders of magnitude smaller than the global set of peers. To limit the responsibility of maintaining one hash table to a subset of peers, we dynamically form separate local DHTs for each hash table as follows: At system startup, we place γ peers at predefined positions (known by all peers) based on the normal distribution N (µsum, σsum) by sampling γ values from N (µsum, σsum) and mapping them to buckets in the range of {1, .., M } using ψ.</p><p>For a particular number of initial peers and the sampled values, we consider ρ(value, l) := (ψ(value) + hash(l)) mod |G| as the mapping of a (value, l)-pair to the global set of peers G, where l is a hash table id. ρ consists of two components, the previously described ψ function and hash(l) as an offset for global load balancing. The peers responsible for these ρ values are invited to join (create) the particular DHTs. The case for ξ lsh is similar, just we use the location and scale parameters of the predicted Cauchy distribution in Equation 4 since mean or standard deviation are not defined for Cauchy distributions. Also at start up, peers are sampled from the predicted Cauchy distribution.</p><p>The number of peers dynamically grows inside each local DHT by overloaded peers issuing requests on the global DHT to find peers to join the local DHT on a particular position (bucket). In case of access load problems, the gateway peers can call for a global increment of the number of gateway peers, i.e., increase the number of possible gateway peers that will subsequently be hit by requests and hence invited to join the local DHTs maintaining the LSH hash tables. We can benefit from the rich related work on load balancing techniques over DHT, such as the work by Pitoura et al <ref type="bibr" target="#b28">[26]</ref>, that replicates "hot" ranges inside a Chord style DHT and then lets peers randomly choose among the replicated arcs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Handling Churn</head><p>We will now discuss possible ways to handle churn, in particular, peers leaving the system without prior notice, but leave any detailed analysis and in particular the impact of the low level (DHT based) churn handling mechanisms to the overall performance as future work.</p><p>To handle churn it is common practise to introduce a certain degree of replication to the system. One such replication based mechanisms has been already introduced above when presenting the concept of multiple gateway peers per local DHT which solves the following problem: If a peer lookup on one of the predefined positions leads to a peer that is not currently in the local DHT as a gateway peer, that peer issues a lookup on one of the other entry points and joins the particular hash table it belongs to. We can furthermore add two more ways of replication: (i) replication of complete local DHTs and/or (ii) replication within particular local DHTs. While approach (i) is straight forward to implement it is extremely coarse and more suitable for handling access load problems (hot peers) rather than handling churn in an efficient way. Approach (ii) seems to be more suitable for handling churn: neighboring peers within each local DHT could maintain also the index of their immediate neighbors and in case of a peer failure transmit the replicas to the new peer joining the free spot. Both approaches certainly cause higher load on the system not only in terms of storage but in particular in terms of message exchanges to keep the replicas in sync. We will investigate the impact of replicated local DHTs in our future work and for this paper concentrate on the actual indexing mechanisms. Note that in addition to the replication mechanisms presented above, the underlying global DHT might use replication of routing indices as well, which is treated by us as a black box.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">KNN QUERY PROCESSING</head><p>Given l LSH hash tables, a query point q = (q1, ..., q d ) is first mapped to buckets g1(q) . . . g l (q) using the p-stable LSH method. The query initiator then uses one randomly selected gateway peer per local DHT as an entry to that local DHT. Subsequently, the responsible peer P for main-taining the share of the global index that contains gi(q) is determined by mapping gi(q) to the peer identifier space using ξ(gi(q)), as defined above. The query is passed on to P that executes the KNN query locally using a full scan and passes the query on. We restrict the local query execution to a simple full-scan query processing since we do not want to intermingle local performance with global performance. The local query execution strategy is orthogonal to our work. For the query forwarding (i.e., routing), we consider two possible options: (i) incremental forwarding to neighboring peers or (ii) forwarding based on the multi probe technique <ref type="bibr" target="#b25">[23]</ref>. The results return by all l hash tables are aggregated at the query initiator and the K closest points to q are returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Linear Forwarding</head><p>We will now define a stopping condition for the linear forwarding method. Let τ denote the distance of the K th object w.r.t. the query object q, obtained by a local full scan KNN search. Peer P will pass the query and the current rank-K distance τ to its neighboring peers P pred and Psucc, causing each one single network hop. Upon receiving the query, P pred and Psucc will issue a local full scan KNN search and compare their best result to τ (cf. Algorithm 1). If the distance d best of the best document is bigger than τ , the peer will not return any results and will stop forwarding the query to its neighbor (depending on the direction, successor or predecessor). The stopping condition can be relaxed by introducing a parameter α and stop forwarding if d best &gt; τ /α. α allows for either a more aggressive querying (α &gt; 1) of neighboring peers or for an early stopping (α &lt; 1). </p><formula xml:id="formula_23">Input: query q, threshold τ , Pinit, direction result[] = localIndex.executeLocalKnn(q); if result[0].distance&gt;τ /α</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multi-Probe Based Forwarding</head><p>The multi-probe LSH method <ref type="bibr" target="#b25">[23]</ref> slightly varies the integers in g(q) and produces bucket ID's which are likely to hold close elements to q. For each of these modifications, the method then probes the resulting bucket for new answerers. We adapt this technique as an alternative to the successor/predecessor based forwarding as follows: after the full scan, the peer generates a list of buckets to probe next, considering the maximum number of extra buckets. It is very likely that some of these buckets have already been visited, thus they are removed from the list. For a generated bucket g(q) with ξsum(g(q)) / ∈]P.pred().id, P.id], the peer issues a lookup in the local DHT and forwards the query and bucket list to the peer responsible for ξ(g(q)). The peer that receives the query, issues a full scan, removes visited buckets from the list and forwards the query (cf. Algorithm 2).</p><p>Input The multi probe algorithm relies on the parameter that specifies the maximum number of probes, whereas the linear forwarding algorithm has a clear defined stopping condition. The relaxation parameter α is optional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RANGE QUERY</head><p>While LSH provides a nice solution to KNN query processing in high dimensional data, unlike other methods, it is difficult to extend it to range queries. This is because specific LSH functions are designed to map points with certain distance from each other to the same hash value. The parameter r1 in the definition of LSH functions indicates this distance (cf., Section 2.2). Therefore different indices should be made for different parameters r1 to satisfy range search for different values of the range radius. However it is impractical to construct a different index for each possible range.</p><p>With mapping similar buckets to the same peer or to neighboring peers, we can support also range queries. Several buckets, which are likely to hold similar data to the query are investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Range Query Processing</head><p>Range query processing over the linearly mapped data is different to the KNN queries as the overall objective is to return all items within a particular range, i.e., the stopping condition of the linear forwarding algorithm needs to be adapted. The startup phase of the query processing is the same as described in Section 5 for the KNN query algorithms: for a given query we determine the peer responsible for the bucket to which this point is mapped.</p><p>Once the starting peer is known and receives the query, it will first execute the query locally using a full scan and return all matching items to the query initiating peer, i.e., send all items within range &lt; r. Subsequently, it will forward the query to its neighboring peers. The forwarding stops at a peer that does not have a single matching item.</p><p>While this processing seems to be intuitive it has the following serious drawback caused by an observation illustrated in Figure <ref type="figure">3</ref>. The range of the query is indicated by the long arrow, the spot in the middle represents the query point. Now, the three circles indicate the responsibility of peers for the data items. Obviously, the data in the inner circle can be processed since it is maintained by the initial peer hosting also the query point. Then, however, due to the often naturally clustered data, the following up peer does not maintain any items in the desired range hence causing the algorithm to stop when having covered the range to the second inner circle, thus missing relevant items.</p><p>To overcome this problem of "empty" ranges inside the query range, we opt for sampling the range, i.e., starting separate range queries at predefined position.</p><p>The idea is to sample s points in the range peer l , ..., peeru Unfortunately, the data distribution inside this range is not known a priori. Furthermore, it depends on the query point and on the range itself, which makes it not tractable to pre-compute. This in particular means that even though the actual data distribution inside the hash tables is known (to the peers maintaining it) it cannot be used to predict the query dependent range of peers to visit.</p><p>In absence of any knowledge of data distributions, we employ a simple sampling method that divides the range in equally sized sub-ranges. For each sub-range, the query is forwarded to one responsible peer. Subsequently, each peer starts the range query processing and as described above, each processing thread stops when (i) an already queried peer is met or (ii) a peer does not have any single item within the specified range. We will now describe the process of range estimations.</p><p>Figure <ref type="figure">3</ref>: Illustration of the problem we face when processing range queries over the linearly mapped data. The "empty" ranges cause the algorithm to stop before the full range has been explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Range Prediction</head><p>We will now try to derive query dependent lower and upper bounds for the values generated by ξ. As we will later see, these estimates can be used to enable efficient parallelized in-hash-table query processing.</p><p>Recall from Section 2.2 that the output of the considered LSH hash function is a k-dimensional vector of integer values where each value corresponds to one of the k hash functions of the form of Equation <ref type="formula" target="#formula_2">1</ref>.</p><p>Assume a query point q = (q1, ..., q d ) and a range r. Let furthermore be a (+) = argmaxj{aij} and a (-) = argminj{aij} the positions of the largest and smallest values of elements of one of the k vectors ai. The idea is to select samples from the d dimensional space that are in distance r of q and produce a bucket label with maximum l1 difference from g a,b (q) from Equation <ref type="formula" target="#formula_4">2</ref>. These samples will be mapped into the linear space using h a,b and ξ.</p><p>To construct these samples, we repeat the following for all k vectors of a i . We add to the query vector at the maximal and minimal value positions of vector a i the query range r. More formally, we generate the upper range point as q i (+) := q+j a (+) i * r and the lower range point as q i (-) := q-j a (-)</p><formula xml:id="formula_24">i * r</formula><p>where ji is the i th unit vector. Using these generated samples of points in distance r we apply the standard techniques using LSH hashing and mapping through ξ to determine the upper and lower bound ξ values upper(q, r) := argmaxi{ξ(g(q (+) ))} lower(q, r) := argmini{ξ(g(q (-) ))} Assume peeru and peer l to be the two peers responsible for the above two values. According to condition 1 of an appropriate ξ function, peers which fall between these two peers in the Chord style ring, are most likely to hold data in range r of the query point q. Since the output distribution of ξ is known the above values can be used to estimate the number of peers which should be contacted to answer a query with range r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>We have implemented a simulation of the proposed system and algorithms using Java 1.6. The simulation runs on a 2x2.33 GHz Quad-Core Intel Xeon CPU with 8GB RAM. The data is stored in an Oracle 11g database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Sets and Overlay setup</head><p>Flickr: We used a crawl of Flickr consisting of 1, 000, 000 images represented by their MPEG7 visual descriptors. The total number of dimensions per image is 282 and contains descriptors such as Edge Histogram Type and Homogeneous Texture Type. For the global DHT we considered a population of 1, 000, 000 peers and each replica of the data set is maintained by a local DHT of 1000 peers.</p><p>Corel: For the second data set we experimented on 60, 000 photo images from the Corel data set as previously used in, e.g. <ref type="bibr" target="#b26">[24]</ref> <ref type="foot" target="#foot_0">1</ref> . Each image has 89 dimensions in this data set. In this case we assumed a global DHT of 100, 000 peers and 100 peers per local DHT.</p><p>For both datasets, we use the Euclidean distance to measure the distances between points, treating all dimensions equally and without preprocessing the data. As query points we chose 100 points randomly from each of the datasets. All performance measures are averaged over 100 queries. K = 20 in all KNN experiments. Table <ref type="table" target="#tab_2">1</ref> summarizes the data set and overlay setup parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods under Comparison</head><p>To evaluate our data placement methods, we distribute the data among peers once with ξsum and once with ξ lsh . We experimented with different values of LSH parameters: k, W and W2 and here report the best performances achieved. In the results, unless otherwise stated, the default values are k = 20, W = 5 and W2 = 3 for the Flickr data set and k = 20, W = 50 and W2 = 1.25 for the Corel data set. For each of these mapping functions we consider the following query processing methods:</p><p>Simple: This is the baseline query processing algorithm. At query time, the whole local index of the peer which is responsible for the mapped LSH bucket using ξ is scanned without further forwarding. This is used both for KNN and range queries.</p><p>MProbe: At KNN query time we use the multi-probing based algorithm as described in Section 5.2, fixing the number of probes to 100.</p><p>Linear: At query time the linear forwarding algorithm, Section 5.1, is used with appropriate stopping conditions for KNN or range search.</p><p>Sample: This is the sampling-based method described in Section 6.1 which is dedicated to range query processing.</p><p>Sahin: To compare with state of the art, we have implemented the method described in Section 2.1 by Sahin et. el <ref type="bibr" target="#b31">[29]</ref>. In order to fairly compare against this method, we follow the same index creation of Section 4 where replicas of the data are maintained by smaller rings. We have experimented with different number of reference vector sizes and different number of references for publishing indices. We report here the best performance results which achieve a fair load balance as well. The reference vector size is set to 32 and reference points are selected uniformly at random from the whole data set. To achieve a fair load balance, we employed multi-level reference sets as described in the initial work, however increasing the number of references used for publishing the indices proved to be more effective. Therefore only one level of references is used and the number of references used for publishing indices is set to 4. The initial work of <ref type="bibr" target="#b31">[29]</ref> employs the Simple query processing method as explained 2.1. In addition to that we also experimented processing queries with our Linear method. The MProbe method is not applicable here, as it depends on the LSH buckets. Processing range queries are not discussed in <ref type="bibr" target="#b31">[29]</ref>; we also experimented only the KNN queries with this method.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures of Interest</head><p>Gini Coefficient: As for a measure of load imbalances we consider the Gini coefficient of the load distribution, that is defined as G = 1 -2 1 0 L(x)dx where L(x) is the Lorenz curve of the underlying distribution. Pitoura et al <ref type="bibr" target="#b29">[27]</ref> show that the Gini coefficient is the most appropriate statistical metric for measuring load distribution fairness. The Gini coefficient, apart from the other three measures, is query in- dependent and measured once for each benchmark to report on the storage load distribution.</p><p>Number of Network Hops: We count the number of network hops during the query execution. Network hops are one of the most critical parameters in making distributed algorithms applicable in large-scale wide-area networks. Each DHT lookup causes logn/2 or logN/2 network hops (i.e., local or global DHT). Hence, we count the number of local and global lookups and translate this to the overall number of network hops. The cost for local query execution is considered to be negligible in our scenario, as the network cost is clearly the dominating factor: One single network hop in a wide-area costs in average around 100ms, which overrules the I/O cost, induced by a standard hard disk, with approximately 8ms for disk seek time plus rotation latency and 100M B/s transfer rate for sequential accesses, in case of local disk access.</p><p>Relative Recall: For the effectiveness metric, we report on the relative recall, i.e., the number of relevant data points among returned data points. The relevance is defined by the full-scan run over the entire data set to determine the K nearest points to a query point for KNN queries. For range queries, all data points in range r of the query point are relevant. It should be noted that since we are ranking all candidate objects and returning only the top K in KNN queries and only the points within distance r of the query point in range queries, precision is equal to relative recall and we do report it separately.</p><p>Error Ratio: Given that LSH is an approximate algorithm, we also measured the Error Ratio which measures the quality of approximate nearest neighbor search as defined in <ref type="bibr" target="#b19">[17]</ref>.</p><formula xml:id="formula_25">1 K K i=1 d LSH i d true i</formula><p>where dLSH i is the distance of query point to its i-th nearest neighbor found by LSH and dtrue i is its distance to its true i-th nearest neighbor. Since this measure does not add new insight over relative recall and due to space constraints we do not report it here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Experimental Results</head><p>We first investigate the effect of employing ξsum and ξ lsh on the load distribution and compare this against the Sahin data placement. As seen in Table <ref type="table" target="#tab_3">2</ref> for both Flickr and Corel data sets, the Gini coefficients of all different load distributions fall in the range of [0.4, 0.6] which is a strong indicator of a fair load distribution <ref type="bibr" target="#b28">[26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">KNN query Results</head><p>We now show the results obtained for the KNN search. Figures <ref type="figure" target="#fig_4">4</ref> and<ref type="figure" target="#fig_5">5</ref> show the obtained recall when queries are processed by the Simple method. We have varied the number of hash tables (or respectively replicas for Sahin) from 2 to 40 for the Flickr data set and from 2 to 10 for the Corel data set. For the Corel dataset ξsum achieves better recall compared to Sahin and ξ lsh . ξsum and ξ lsh obtain better recalls for number of replicas more than 24 for the Flickr data set which has higher dimensionality . We observe that the obtained recall for all three placement methods with the Simple query processing algorithm is quite low even when increasing the number of hash tables (replicas). It should be noted that while employing the Simple method for processing queries, the number of incurred network hops for answering each query is equal to number of hash tables (replicas) times logN/2, where N is the number of peers in the global DHT. In this case, only one peer is visited in each local DHT maintaining a hash table (replica) of the data set.</p><p>Figures <ref type="figure">6</ref> and<ref type="figure" target="#fig_6">7</ref> show recall versus number of network hops for three placement methods, this time using Linear and MProbe processing algorithms respectively for the Flickr and Corel data sets. We see a big increase in recall compared to when processing queries using Simple for both data sets and all three placement methods. We have varied the number of hash tables (replicas) exactly like the previous experiment, from 2 to 40 for Flickr, and from 2 to 10 for Corel. We show on the x-axis the number of network hops incurred which corresponds to the number of hash tables (replicase) and number of times the query is forwarded in each local DHT maintaining a hash table (replica). As can be seen for both data sets, the combination of ξsum and ξ lsh with the Linear processing algorithm achieves the best recall while incurring not many network hops. This confirms that ξsum and ξ lsh preserve the locality, i.e., they group buckets with similar content to the same or neighboring peers. ξsum and ξ lsh achieve similar recall in both data sets, while Sahin's quality of result degrade drastically when processing the Flickr data set. This observation again shows better scalability of our algorithm with respect to data dimensionality, which is due to LSH characteristics. MProbe achieves better recall compared to Simple, but does not perform as well as Linear : number of incurred network hops is more, as each forward in a local DHT maintaining a hash table results in logn/2 hops, where n is the number of peers maintaining that ring.</p><p>We have also summarized these results in Tables <ref type="table" target="#tab_5">3</ref> and<ref type="table" target="#tab_7">4</ref> to better compare these methods with respect to network load (number of times the data is replicated in the network). For example let us consider the 13 th and 15 th rows of Table <ref type="table" target="#tab_5">3</ref>.</p><p>With Linear the ξ lsh data placement achieves more than twice better recall at the expense of only 0.01 more number of network hops while having the same network load as Sahin. The best achieved recall is shown in bold in both tables.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Range query Results</head><p>We now report the results obtained for range searches. For each data set the radius of the range query is chosen such that the number of possible results are reasonable, i.e. for Flickr this ranges from 27 to 562, while for Corel it ranges from 17 to 194. Figure <ref type="figure" target="#fig_7">8</ref> shows a general view of the effect of varying the range on recall. As discussed also in Section   6.1 recall in the Simple method can fall when the radius of range increases. An example of this effect is shown in Figure <ref type="figure" target="#fig_7">8</ref>. However, our Sampling method proves to be effective at maintaining high recall as the radius changes. Tables <ref type="table" target="#tab_9">5</ref> and<ref type="table" target="#tab_12">7</ref> show the results for ξsum, while Tables <ref type="table" target="#tab_11">6</ref> and<ref type="table">8</ref> report on ξ lsh for the two data sets. Clearly, Sample performs very well at achieving good recall for different choices of the range in both data sets. Our Linear method obtains smaller recall compared to Sample, however the number of network hobs incurred by this method is considerably less than Sample. The best achieved recalls are shown in bold.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>We have presented a robust and scalable solution to the distributed similarity search problem over high dimensional data. Having investigated the characteristics of the existing centralized LSH based methods, we have devised an algorithm to distribute the p-stable LSH method considering the requirements that arise in distributed settings. Our proposed locality preserving mapping, brings together two con-  tradictory conditions of efficient and high quality similarity search in distributed se1ttings: Enabling probabilistic placement of similar data on the same peer or neighboring peers, while achieving a fair load balancing. We have shown how to create the index, leveraging our proposed mapping and its characteristics. We have theoretically proved the locality preserving properties of our mapping and devised efficient algorithms for both K-nearest neighbor and range queries.</p><p>To our knowledge this is the first work enabling similarity range queries over LSH indices. Our experimental evaulation shows major performance gains compared to state-ofthe-art. We believe that our approach is thus well-positioned to become a fundamental building block towards applying LSH based methods in real world, distributed applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of mapping a data point v to the Chord peer space by Sahin. The number of references is 7, the Chord range is (0, 2 10 ), j is 2 and each data point is replicated three times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the two level mapping from the d-dimensional space to the peer identifier space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Recall versus number of DHT lookups for different data placement methods employing Simple query processing for the Flickr data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Recall versus number of DHT lookups for different data placement methods employing Simple query processing for the Corel data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Recall versus number of DHT lookups for the Corel data set representing Linear with the three different placement methods and MProbe with ξsum and ξ lsh .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The effect of varying the range on recall. The results are shown for #hash tables=20 and ξsum as the placement function for the Corel data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Top-K Style Query Execution based on the locality sensitive mapping to the linear peer space by passing the query on to succeeding or preceding peers.</figDesc><table><row><cell>then</cell></row><row><cell>done;</cell></row><row><cell>else</cell></row><row><cell>resultSet = ∅;</cell></row><row><cell>for (index=0; index&lt;K; index++) do</cell></row><row><cell>if results[index].distance&lt;τ /α then</cell></row><row><cell>resultSet.add(results[index]);</cell></row><row><cell>else</cell></row><row><cell>τ = resultSet.rankKDistance();</cell></row><row><cell>sendResults(resultSet, Pinit);</cell></row><row><cell>forwardQuery(this.predecessor() or/and</cell></row><row><cell>this.successor(), τ , q, Pinit, pred or/and</cell></row><row><cell>succ);</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>Algorithm 1:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Data Sets and Overlay setup</figDesc><table><row><cell></cell><cell>Flickr</cell><cell>Corel</cell></row><row><cell>#data points</cell><cell>1,000,000</cell><cell>60,000</cell></row><row><cell>#dimensions</cell><cell>282</cell><cell>89</cell></row><row><cell>#peers in Global DHT (N)</cell><cell>1,000,000</cell><cell>100,000</cell></row><row><cell>#peers per Local DHT (n)</cell><cell>1000</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Gini Coefficient when distributing 2 replicas of the data sets Recall versus number of DHT lookups for the Flickr data set representing Linear with the three different placement methods and MProbe with ξsum and ξ lsh .</figDesc><table><row><cell></cell><cell></cell><cell>Data set</cell><cell>Sahin</cell><cell>ξsum</cell><cell>ξ lsh</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Flickr</cell><cell>0.42</cell><cell>0.52</cell><cell>0.41</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Corel</cell><cell>0.40</cell><cell>0.46</cell><cell>0.57</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">recall versus number of network hops</cell><cell></cell></row><row><cell></cell><cell>80 90 100</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Linear-ξ lsh Linear-ξ sum MProbe-ξ lsh MProbe-ξ sum Linear-Sahin</cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>recall(%)</cell><cell>40 50 60</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>200</cell><cell>400</cell><cell>600</cell><cell>800</cell><cell>1000</cell><cell>1200</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2"># network hops</cell><cell></cell><cell></cell></row><row><cell cols="2">Figure 6:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Measuring recall and number of network hops for different number of hash tables, for different placement and processing methods the Flickr data set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Measuring recall and number of network hops for different number of hash tables, for different placement and processing methods the Corel data set.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">recall/range</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>100</cell><cell cols="2">Simple</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>90</cell><cell cols="2">Linear Sample</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>recall</cell><cell>60</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>40</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2000</cell><cell>2050</cell><cell>2100</cell><cell>2150</cell><cell>2200</cell><cell>2250</cell><cell>2300</cell><cell>2350</cell><cell>2400</cell><cell>2450</cell><cell>2500</cell><cell>2550</cell><cell>2600</cell><cell>2650</cell><cell>2700</cell><cell>2750</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">range (r)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Measuring recall and number of network hops for different range radius' and number of hash tables, for different processing methods under comparison with ξsum as the placement function for the Corel data set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Measuring recall and number of network hops for different range radius' and number of hash tables, for different processing methods under comparison with ξ lsh as the placement function for the Corel data set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Measuring recall and number of network hops for different range radius' and number of hash tables, for different processing methods under comparison with ξsum as the placement function for the Flickr data set.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>available under: http://kdd.ics.uci.edu/databases/CorelFeatures/CorelFeatures</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The work presented in this paper was partially supported by the National Competence Center in Research on Mobile Information and Communication Systems (NCCR-MICS), a center supported by the Swiss National Science Foundation under grant number 5005-67322 and by the European project NEPOMUK No FP6-027705.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Relative Recall in % (#Network Hops</title>
		<imprint/>
	</monogr>
	<note>range l Simple Linear Sample 200 2 79.38% (20) 80.67% (26) 81.32% (53</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Advances in metric embedding theory</title>
		<author>
			<persName><forename type="first">Ittai</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yair</forename><surname>Bartal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ofer</forename><surname>Neiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions</title>
		<author>
			<persName><forename type="first">Alexandr</forename><surname>Andoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Approximate range searching</title>
		<author>
			<persName><forename type="first">Sunil</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Mount</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Geom</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Panagiotis Relative Recall in % (#Network Hops</title>
		<author>
			<persName><forename type="first">Michalis</forename><surname>Vassilis Athitsos</surname></persName>
		</author>
		<author>
			<persName><surname>Potamias</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>range l Simple Linear Sample 200 2 78.90% (20) 81.44% (27) 81.49% (51</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Measuring recall and number of network hops for different range radius&apos; and number of hash tables, for different processing methods under comparison with ξ lsh as the placement function for the Flickr data set. Papapetrou, and George Kollios. Nearest neighbor retrieval using distance-based hashing</title>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Swam: a family of access methods for similarity-search in peer-to-peer data networks</title>
		<author>
			<persName><forename type="first">Farnoush</forename><surname>Banaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Kashani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Lsh forest: self-tuning indexes for similarity search</title>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Bawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyson</forename><surname>Condie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Ganesan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">K-d trees for semidynamic point sets</title>
		<author>
			<persName><forename type="first">Jon</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bentley</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Computational Geometry</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The pyramid-technique: towards breaking the curse of dimensionality</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Berchtold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Böhm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">S</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Goldstein</surname></persName>
		</author>
		<title level="m">Raghu Ramakrishnan, and Uri Shaft. When is &quot;nearest neighbor&quot; meaningful? In ICDT</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mercury: supporting scalable multi-attribute range queries</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ashwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukesh</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><surname>Seshan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient evaluation of nearest-neighbor queries in content-addressable networks</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Buchmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klemens</forename><surname>Böhm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Integrated Publication and Information Systems to Virtual Information and Knowledge Environments</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Approximate range searching in higher dimension</title>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Chazelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avner</forename><surname>Magen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Geom</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="29" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">P-ring: an efficient and robust p2p range index structure</title>
		<author>
			<persName><forename type="first">Adina</forename><surname>Crainiceanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakash</forename><surname>Linga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayavel</forename><surname>Shanmugasundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In SIGMOD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Locality-sensitive hashing scheme based on p-stable distributions</title>
		<author>
			<persName><forename type="first">Mayur</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahab</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Computational Geometry</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Yannis Kotidis, and Michalis Vazirgiannis. Peer-to-peer similarity search in metric</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Doulkeridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akrivi</forename><surname>Vlachou</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A content-addressable network for similarity search in metric spaces</title>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Falchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Gennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Zezula</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Similarity search in high dimensions via hashing</title>
		<author>
			<persName><forename type="first">Aristides</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="518" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">R-trees: A dynamic index structure for spatial searching</title>
		<author>
			<persName><forename type="first">Antonin</forename><surname>Guttman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD Conference</title>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">LSH at largedistributed knn search in high dimensions</title>
		<author>
			<persName><forename type="first">Parisa</forename><surname>Haghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Cudré-Mauroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Aberer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WebDB</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">idistance: An adaptive b + -tree based indexing method for nearest neighbor search</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin</forename><surname>Beng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kian-Lee</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang 0003</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Vbi-tree: A peer-to-peer framework for supporting multi-dimensional indexing schemes</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin</forename><surname>Beng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quang Hieu</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aoying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gossip-based aggregation in large dynamic networks</title>
		<author>
			<persName><forename type="first">Márk</forename><surname>Jelasity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Montresor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Özalp</forename><surname>Babaoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-probe lsh: Efficient indexing for high-dimensional similarity search</title>
		<author>
			<persName><forename type="first">Qin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Josephson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moses</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Supporting ranked boolean similarity queries in mars</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kriengkrai</forename><surname>Porkaew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharad</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Entropy based nearest neighbor search in high dimensions</title>
		<author>
			<persName><forename type="first">Rina</forename><surname>Panigrahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Replication, load balancing and efficient range query processing in dhts</title>
		<author>
			<persName><forename type="first">Theoni</forename><surname>Pitoura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Ntarmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Triantafillou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Load distribution fairness in p2p data management systems</title>
		<author>
			<persName><forename type="first">Theoni</forename><surname>Pitoura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Triantafillou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A scalable content-addressable network</title>
		<author>
			<persName><forename type="first">Sylvia</forename><surname>Ratnasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Content-based similarity search over peer-to-peer systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ozgur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fatih</forename><surname>Sahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyakant</forename><surname>Emekçi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><forename type="middle">El</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><surname>Abbadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Chord: A scalable peer-to-peer lookup service for internet applications</title>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Frans</forename><surname>Kaashoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Peer-to-peer information retrieval using self-organizing semantic overlay networks</title>
		<author>
			<persName><forename type="first">Chunqiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhya</forename><surname>Dwarkadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Indexing the distance: An efficient method to knn processing</title>
		<author>
			<persName><forename type="first">Cui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beng</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Chin</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kian-Lee</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Skipindex: Towards a scalable peer-to-peer index service for high dimensional data</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randolph</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Princeton University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
