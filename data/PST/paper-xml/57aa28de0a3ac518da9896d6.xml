<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structural Deep Network Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daixin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tsinghua National Laboratory for Information Science and Technology Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
							<email>cuip@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Tsinghua National Laboratory for Information Science and Technology Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
							<email>wwzhu@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Tsinghua National Laboratory for Information Science and Technology Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structural Deep Network Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BC55DEB4233B9FDF4D754E270456B779</idno>
					<idno type="DOI">10.1145/2939672.2939753</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Network Embedding</term>
					<term>Deep Learning</term>
					<term>Network Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Network embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Nowadays, networks are ubiquitous and many real-world applications need to mine the information within these networks. For example, recommendation system in Twitter aims to mine the preferred tweets for users from the social network. Online advertise-Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD <ref type="bibr">'16, August 13-17, 2016</ref>, San Francisco, CA, USA c 2016 ACM. ISBN 978-1-4503-4232-2/16/08. . . $15.00 DOI: http://dx.doi.org/10.1145/2939672.2939753 ment targeting often needs to cluster the users into communities in the social network. Therefore, mining the information in the network is very important. One of the fundamental problems is how to learn useful network representations <ref type="bibr" target="#b5">[5]</ref>. An effective way is to embed networks into a low-dimensional space, i.e. learn vector representations for each vertex, with the goal of reconstructing the network in the learned embedding space. As a result, mining information in networks, such as information retrieval <ref type="bibr" target="#b34">[34]</ref>, classification <ref type="bibr" target="#b15">[15]</ref>, and clustering <ref type="bibr" target="#b20">[20]</ref>, can be directly conducted in the low-dimensional space.</p><p>Learning network representations faces the following great challenges: (1) High non-linearity: As <ref type="bibr" target="#b19">[19]</ref> stated, the underlying structure of the network is highly non-linear. Therefore, how to design a model to capture the highly non-linear structure is rather difficult. <ref type="bibr" target="#b2">(2)</ref> Structure-preserving: To support applications analyzing networks, network embedding is required to preserve the network structure. However, the underlying structure of the network is very complex <ref type="bibr" target="#b24">[24]</ref>. The similarity of vertexes is dependent on both the local and global network structure. Therefore, how to simultaneously preserve the local and global structure is a tough problem. (3) Sparsity: Many real-world networks are often so sparse that only utilizing the very limited observed links is not enough to reach a satisfactory performance <ref type="bibr" target="#b21">[21]</ref>.</p><p>In the past decades, many network embedding methods have been proposed, which adopted shallow models, such as IsoMAP <ref type="bibr" target="#b29">[29]</ref>, Laplacian Eigenmaps (LE) <ref type="bibr" target="#b1">[1]</ref> and Line <ref type="bibr" target="#b26">[26]</ref>. However, due to the limited representation ability of shallow models <ref type="bibr" target="#b2">[2]</ref>, it is difficult for them to capture the highly nonlinear network structure <ref type="bibr" target="#b30">[30]</ref>. Although some methods adopt kernel techniques <ref type="bibr" target="#b32">[32]</ref>, as <ref type="bibr" target="#b36">[36]</ref> stated, kernel methods are also shallow models and cannot capture the highly non-linear structure well.</p><p>In order to capture the highly non-linear structure well, in this paper we propose a new deep model to learn vertex representations for networks. This is motivated by the recent success of deep learning, which has been demonstrated to have a powerful representation ability to learn complex structures of the data <ref type="bibr" target="#b2">[2]</ref> and has achieved substantial success in dealing with images <ref type="bibr" target="#b15">[15]</ref>, text <ref type="bibr" target="#b25">[25]</ref> and audio <ref type="bibr" target="#b10">[10]</ref> data. In particular, in our proposed model we design a multilayer architecture which consists of multiple non-linear functions. The composition of multiple layers of non-linear functions can map the data into a highly non-linear latent space, thereby being able to capture the highly non-linear network structure.</p><p>In order to address the structure-preserving and sparsity problems in the deep model, we further propose to exploit the first-order and second-order proximity <ref type="bibr" target="#b26">[26]</ref> jointly into the learning process. The first-order proximity is the local pairwise similarity only between the vertexes linked by edges, which characterizes the local network structure. However, due to the sparsity of the network, many legitimate links are missing. As a result, the first-order proximity is not sufficient to represent the network structure. Therefore, we further propose the second-order proximity, which indicates the similarity of the vertexes' neighborhood structures, to capture the global network structure. With the first-order and second-order proximity, we can well characterize the local and global network structure, respectively. To preserve both the local and global network structure in the deep model, we propose a semi-supervised architecture, in which the unsupervised component reconstructs the second-order proximity to preserve the global network structure while the supervised component exploits the first-order proximity as the supervised information to preserve the local network structure. As a result, the learned representations can well preserve both the local and global network structure. In addition, as shown in Figure <ref type="figure" target="#fig_0">1</ref>, the number of pairs of vertexes which have secondorder proximity is much huger than those have first-order proximity. Therefore, the import of second-order proximity is able to provide much more information in term of characterizing the network structure. As a result, our method is robust to sparse networks. Empirically, we conduct the experiments on five real-world networked datasets and four real-world applications. The results show that compared with baselines, the representations generated by our method can reconstruct the original networks significantly better and achieve substantial gains on various tasks and various networks, including very sparse networks. It demonstrates that our representations learned in the highly non-linear space can preserve the network structure well and are robust to sparse networks.</p><p>In summary, the contributions of this paper are listed as follows:</p><p>• We propose a Structural Deep Network Embedding method, namely SDNE, to perform network embedding. The method is able to map the data to a highly non-linear latent space to preserve the network structure and is robust to sparse networks. To the best of our knowledge, we are among the first to use deep learning to learn network representations.</p><p>• We propose a new deep model with a semi-supervised architecture, which simultaneously optimizes the first-order and second-order proximity. As a result, the learned representations preserve the local and global network structure and are robust to sparse networks.</p><p>• The proposed method is extensively evaluated on five real datasets and four application scenarios. The results demonstrate the superior usefulness of the method in multi-label classification, reconstruction, link prediction and visualization. Specifically, our method can achieve more significant improvements (20%) over baselines when labelled data is scarce. In some cases we only need 60% less training samples but still achieve better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deep Neural Network</head><p>Representation learning has long been an important problem of machine learning and many works aim at learning representations for samples <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b35">35]</ref>. Recent advances in deep neural networks have witnessed that they have powerful representations abilities <ref type="bibr" target="#b12">[12]</ref> and can generate very useful representations for many types of data. For example, <ref type="bibr" target="#b15">[15]</ref> proposed a seven-layer convolutional neural network to generate image representations for classification. <ref type="bibr" target="#b33">[33]</ref> proposed a multimodal deep model to learn image-text unified representations to achieve cross-modality retrieval task.</p><p>However, to the best of our knowledge, there have been few deep learning works handling networks, especially learning network representations. In <ref type="bibr" target="#b9">[9]</ref>, Restricted Boltzmann Machines were adopted to do collaborative filtering. <ref type="bibr" target="#b30">[30]</ref> adopted deep autoencoder to do graph clustering. <ref type="bibr" target="#b5">[5]</ref> proposed a heterogeneous deep model to do heterogeneous data embedding. We differ from these works in two aspects. Firstly, the goals are different. Our work focuses on learning low-dimensional structure-preserved network representations which can be utilized among tasks. Secondly, we consider both the first-order and second-order proximity between vertexes to preserve the local and global network structure. But they only focus on one-order information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Network Embedding</head><p>Our work solves the problem of network embedding, which aims to learn representations for networks. Some earlier works like Local Linear Embedding (LLE) <ref type="bibr" target="#b22">[22]</ref>, IsoMAP <ref type="bibr" target="#b29">[29]</ref> first constructed the affinity graph based on the feature vectors and then solved the leading eigenvectors as the network representations. More recently, <ref type="bibr" target="#b26">[26]</ref> designed two loss functions attempting to capture the local and global network structure respectively. Furthermore, <ref type="bibr" target="#b4">[4]</ref> extended the work to utilize high-order information. Despite the success of these network embedding approaches, they all adopt shallow models. As we have explained earlier, it is difficult for shallow models to effectively capture the highly non-linear structure in the underlying network. In addition, although some of them attempt to use first-order and high-order proximity to preserve the local and global network structure, they learn the representations for them separately and simply concatenate the representations. Obviously, it is sub-optimal than simultaneously modeling them in a unified architecture to capture both the local and global network structure.</p><p>DeepWalk <ref type="bibr" target="#b21">[21]</ref> combined random walk and skip-gram to learn network representations. Although empirically effective, it lacks a clear objective function to articulate how to preserve the network structure. It is prone to preserving only the second-order proximity. However, our method designs an explicit objective function, which aims at simultaneously preserving the local and global structure by preserving both the first-order and second-order proximity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">STRUCTURAL DEEP NETWORK EMBED-DING</head><p>In this section, we first define the problem. Then we introduce the proposed semi-supervised deep model of SDNE. At last we present some discussions and analysis on the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>We first give the definition of a Graph. DEFINITION 1. (Graph) A graph is denoted as G = (V, E), where V = {v1, ..., vn} represents n vertexes and E = {ei,j} n i,j=1 represents the edges. Each edge ei,j is associated with a weight si,j ≥ 0 1 . For vi and vj not linked by an edge, si,j = 0. Otherwise, for unweighted graph si,j = 1 and for weighted graph, si,j &gt; 0.</p><p>Network embedding aims to map the graph data into a lowdimensional latent space, where each vertex is represented as a low-dimensional vector and the network computing can be directly realized. As we have explained, both local and global structure are essential to be preserved. Then we first define the first-order proximity, which characterizes the local network structure.</p><p>DEFINITION 2. (First-Order Proximity) The first-order proximity describes the pairwise proximity between vertexes. For any pair of vertexes, if si,j &gt; 0, there exists positive first-order proximity between vi and vj. Otherwise, the first-order proximity between vi and vj is 0.</p><p>Naturally, it is necessary for network embedding to preserve the first-order proximity because it implies that two vertexes in realworld networks are always similar if they are linked by an observed edge. For example, if a paper cites another paper, they should contain some common topic. However, real-world datasets are often so sparse that the observed links only account for a small portion. There exist many vertexes which are similar with each other but not linked by any edges. Therefore, only capturing the first-order proximity is not sufficient. We introduce the second-order proximity to capture the global network structure. DEFINITION 3. (Second-Order Proximity) The second-order proximity between a pair of vertexes describes the proximity of the pair's neighborhood structure. Let Nu = {su,1, ..., s u,|V | } denote the first-order proximity between vu and other vertexes. Then, secondorder proximity is determined by the similarity of Nu and Nv.</p><p>Intuitively, the second-order proximity assumes that if two vertexes share many common neighbors, they tend to be similar. Such an assumption has been proved reasonable in many fields <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b14">14]</ref>. For example, in linguistics words will be similar if they are always surrounded by similar contexts <ref type="bibr" target="#b6">[6]</ref>. People will be friends if they have many common friends <ref type="bibr" target="#b14">[14]</ref>. The second-order proximity has been demonstrated to be a good metric to define the similarity of a pair of vertexes, even if they are not linked by an edge <ref type="bibr" target="#b17">[17]</ref>, and thus can highly enrich the relationship of vertexes. Therefore, by introducing the second-order proximity, it is able to characterize the global network structure and alleviate the sparsity problem.</p><p>With the first-order and second-order proximity, we investigate the problem of how to integrate them simultaneously to preserve both the local and global structure when we perform network embedding. Such a problem is defined as follows: DEFINITION 4. (Network Embedding) Given a graph denoted as G = (V, E), network embedding aims to learn a mapping func-</p><formula xml:id="formula_0">tion f : vi -→ y i ∈ R d , where d |V |.</formula><p>The objective of the function is to make the similarity between y i and y j explicitly preserve the first-order and second-order proximity of vi and vj.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Framework</head><p>In this paper, we propose a semi-supervised deep model to perform network embedding, whose framework is shown in Figure <ref type="figure" target="#fig_1">2</ref>. In detail, to capture the highly non-linear network structure, we propose a deep architecture, which is composed of multiple nonlinear mapping functions to map the input data to a highly nonlinear latent space to capture the network structure. Furthermore, in 1 For signed network, negative links exist. But in this paper we only consider non-negative links. order to address the structure-preserving and sparsity problems, we propose a semi-supervised model to exploit both the second-order and first-order proximity. For each vertex, we are able to obtain its neighborhood. Accordingly, we design the unsupervised component to preserve the second-order proximity, by reconstructing the neighborhood structure of each vertex. Meanwhile, for a small portion of pairs of nodes, we can obtain their pairwise similarities, i.e. the first-order proximities. Therefore, we design the supervised component to exploit the first-order proximity as the supervised information to refine the representations in the latent space. By jointly optimizing them in the proposed semi-supervised deep model, SDNE can preserve the highly-nonlinear local-global network structure well and is robust to sparse networks. In the following section, we will introduce how to realize the semi-supervised deep model in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Loss Functions</head><p>Before introducing the loss functions, we define some of the terms and notations in Table <ref type="table">1</ref> which will be used later. Note thatâ bove the parameters represents the parameters of the decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Terms and Notations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symbol</head><p>Definition n number of vertexes K number of layers S = {s1, ..., sn} the adjacency matrix for the network</p><formula xml:id="formula_1">X = {xi} n i=1 , X = {xi} n i=1</formula><p>the input data and reconstructed data</p><formula xml:id="formula_2">Y (k) = {y (k) i } n i=1 the k-th layer hidden representations W (k) , Ŵ (k) the k-th layer weight matrix b (k) , b(k) the k-th layer biases θ = {W (k) , Ŵ (k) , b (k) , b(k) }</formula><p>the overall parameters Now we introduce the loss functions for the semi-supervised model. We first describe how the unsupervised component exploits the second-order proximity to preserve the global network structure.</p><p>The second-order proximity refers to how similar the neighborhood structure of a pair of vertexes is. Thus, to model the secondorder proximity, it is required to model the neighborhood of each vertex. Given a network G = (V, E), we can obtain its adjacency matrix S, which contains n instances s1, ..., sn. For each instance si = {si,j} n j=1 , si,j &gt; 0 if and only if there exists a link between vi and vj. Therefore, si describes the neighborhood structure of the vertex vi and S provides the information of the neighborhood structure of each vertex. With S, we extend the traditional deep autoencoder <ref type="bibr" target="#b23">[23]</ref> to preserve the second-order proximity.</p><p>For the consideration of being self-contained, we briefly review the key idea of deep autoencoder. It is an unsupervised model which is composed of two parts, i.e. the encoder and decoder. The encoder consists of multiple non-linear functions that map the input data to the representation space. The decoder also consists of multiple non-linear functions mapping the representations in representation space to reconstruction space. Then given the input xi, the hidden representations for each layer are shown as follows 2 :</p><formula xml:id="formula_3">y (1) i = σ(W (1) xi + b (1) ) y (k) i = σ(W (k) y (k-1) i + b (k) ), k = 2, ..., K<label>(1)</label></formula><p>After obtaining y (K) i , we can obtain the output xi by reversing the calculation process of encoder. The goal of the autoencoder is to minimize the reconstruction error of the output and the input. The loss function is shown as follows:</p><formula xml:id="formula_4">L = n i=1 xi -xi 2 2 (2)</formula><p>As <ref type="bibr" target="#b23">[23]</ref> proved, although minimizing the reconstruction loss does not explicitly preserve the similarity between samples, the reconstruction criterion can smoothly capture the data manifolds and thus preserve the similarity between samples. Then considering our case that if we use the adjacency matrix S as the input to the autoencoder, i.e. xi = si, since each instance si characterizes the neighborhood structure of the vertex vi, the reconstruction process will make the vertexes which have similar neighborhood structures have similar latent representations.</p><p>Nevertheless, such a reconstruction process cannot be directly applied to our problem because of some specific characteristics of networks. In the networks, we can observe some links but simultaneously many legitimate links are not observed, which means that the links between vertexes do indicate their similarity but no links do not necessarily indicate their dissimilarity. Moreover, due to the sparsity of networks, the number of non-zero elements in S is far less than that of zero elements. Then if we directly use S as the input to the traditional autoencoder, it is more prone to reconstruct the zero elements in S. However, this is not what we want. To address this problem, we impose more penalty to the reconstruction error of the non-zero elements than that of zero elements. The revised objective function is shown as follows:</p><formula xml:id="formula_5">L 2nd = n i=1 (x i -xi) b i 2 2 = ( X -X) B 2 F (3)</formula><p>where means the Hadamard product, b i = {bi,j} n j=1 . If si,j = 0, bi,j = 1, else bi,j = β &gt; 1. Now by using the revised deep autoencoder with the adjacency matrix S as input, the vertexes which have similar neighborhood structure will be mapped near in the representations space, guaranteed by the reconstruction criterion. In other words, the unsupervised component of our model can preserve the global network structure by reconstructing the secondorder proximity between vertexes.</p><p>It is not only necessary to preserve the global network structure, but also essential to capture the local structure. We use the firstorder proximity to denote the local network structure. The firstorder proximity can be regarded as the supervised information to constrain the similarity of the latent representations of a pair of vertexes. Therefore, we design the supervised component to exploit 2 In this work, we use the sigmoid function σ(x) = 1 1+exp(-x) as the non-linear activation function the first-order proximity. The loss function for this goal is defined as follows 3 :</p><formula xml:id="formula_6">L1st = n i,j=1 si,j y (K) i -y (K) j 2 2 = n i,j=1 si,j yi -yj 2 2 (4)</formula><p>The objective function of Eq. 4 borrows the idea of Laplacian Eigenmaps <ref type="bibr" target="#b1">[1]</ref>, which incurs a penalty when similar vertexes are mapped far away in the embedding space. Some works about social networks <ref type="bibr" target="#b13">[13]</ref> also use the similar idea. We differentiate them in the aspect that we incorporate the idea in the deep model to make the vertexes linked by an edge be mapped near in the embedding space. As a result, the model preserves the first-order proximity.</p><p>To preserve the first-order and second-order proximity simultaneously, we propose a semi-supervised model, which combines Eq. 4 and Eq. 3 and joint minimizes the following objective function:</p><formula xml:id="formula_7">Lmix = L 2nd + αL1st + νLreg = ( X -X) B 2 F + α n i,j=1 si,j yi -yj 2 2 + νLreg (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where Lreg is an L2-norm regularizer term to prevent overfitting, which is defined as follows:</p><formula xml:id="formula_9">Lreg = 1 2 K k=1 ( W (k) 2 F + Ŵ (k) 2 F )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Optimization</head><p>To optimize the aforementioned model, the goal is to minimize Lmix as a function of θ. In detail, the key step is to calculate the partial derivative of ∂Lmix/∂ Ŵ (k) and ∂Lmix/∂W (k) . The detailed mathematical form of the partial derivative is shown as follows:</p><formula xml:id="formula_10">∂L mix ∂ Ŵ (k) = ∂L 2nd ∂ Ŵ (k) + ν ∂Lreg ∂ Ŵ (k) ∂L mix ∂W (k) = ∂L 2nd ∂W (k) + α ∂L 1st ∂W (k) + ν ∂Lreg ∂W (k) , k = 1, ..., K<label>(6)</label></formula><p>We first look at ∂L 2nd /∂ Ŵ (K) . It can be rephrased as follows:</p><formula xml:id="formula_11">∂L 2nd ∂ Ŵ (K) = ∂L 2nd ∂ X • ∂ X ∂ Ŵ (K)<label>(7)</label></formula><p>For the first term, according to Eq. 3 we have:</p><formula xml:id="formula_12">∂L 2nd ∂ X = 2( X -X) B<label>(8)</label></formula><p>The calculation of the second term ∂ X/∂ Ŵ is easy since X = σ( Ŷ (K-1) Ŵ (K) + b(K) ). Then ∂L 2nd /∂ Ŵ (K) is accessible. Based on back-propagation, we can iteratively obtain ∂L 2nd /∂ Ŵ (k) , k = 1, ...K -1 and ∂L 2nd /∂W (k) , k = 1, ...K. Now the calculation of the partial derivative of L 2nd is finished.</p><p>Then we continue to calculate the partial derivative of ∂L1st/∂W (k) . The loss function of L1st can be rephrased as follows:</p><formula xml:id="formula_13">L1st = n i,j=1 si,j yi -yj 2 2 = 2tr(Y T LY )<label>(9)</label></formula><p>3 For simplicity of notations, we denote network representations</p><formula xml:id="formula_14">Y (K) = {y (K) i } n i=1 as Y = {yi} n i=1 .</formula><p>where L = D -S, D ∈ R n×n is a diagonal matrix, Di,i = j si,j.</p><p>Then we first focus on the calculation of ∂L1st/∂W (K) :</p><formula xml:id="formula_15">∂L1st ∂W (K) = ∂L1st ∂Y • ∂Y ∂W (K) (10) Since Y = σ(Y (K-1) W (K) + b (K)</formula><p>), the calculation of the second term ∂Y /∂W (K) is easy. For the first term of ∂L1st/∂Y , we have:</p><formula xml:id="formula_16">∂L1st ∂Y = 2(L + L T ) • Y<label>(11)</label></formula><p>Similarly, by using back-propagation we can finish the calculation of partial derivative of L1st.</p><p>Now we have obtained the partial derivatives of the parameters. With an initialization of the parameters, the proposed deep model can be optimized by using stochastic gradient descent. Note that due to the high nonlinearity of the model, it suffers from many local optimal in the parameter space. Therefore, in order to find a good region of parameter space, we use Deep Belief Network to pretrain the parameters at first <ref type="bibr" target="#b11">[11]</ref>, which has been demonstrated as an essential initialization of parameters for deep learning in literature <ref type="bibr">[7]</ref>. The full algorithm is presented in Alg. 1. Based on X and θ, apply Eq. 1 to obtain X and Y = Y K . 5:</p><p>Lmix(X; θ) = ( X -X) B 2 F +2αtr(Y )+νLreg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Based on Eq. 6, use ∂Lmix/∂θ to back-propagate through the entire network to get updated parameters θ. 7: until converge 8: Obtain the network representations Y = Y (K)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis and Discussions</head><p>In this section, we present some analysis and discussions of the proposed semi-supervised deep model of SDNE.</p><p>New vertexes: A practical issue for network embedding is how to learn representations for newly arrived vertexes. For a new vertex v k , if its connections to the existing vertexes is known, we can obtain its adjacency vector x = {s 1,k , ..., s n,k }, where s i,k indicates the similarity between the existing vi and the new vertex v k . Then we can simply feed the x into our deep model and use the trained parameters θ to get the representations for v k . The complexity for such a process is O(1). If there exist no connections between vi and the existing vertexes in the network, our method and state-of-the-art network embedding methods cannot handle. To handle such case, we can resort to other side information, such as the content features of the new vertexes, which we leave as the future work.</p><p>Training Complexity: It is not difficult to see that the training complexity of our model is O(ncdI), where n is the number of vertexes, d is the maximum dimension of the hidden layer, c is the average degree of the network and I is the number of iterations. Parameter d is usually related to the dimension of embedding vectors but not related to the number of vertexes. I is also independent with n. For c, it usually can be regarded as a constant in real-world applications. For example, in the social network, the maximum number of friends for a people is always bounded <ref type="bibr" target="#b30">[30]</ref>. In top-k similarity graph, c = k. Therefore, cdI is independent with n and thus the overall training complexity is linear to the number of vertexes in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>In this section, we evaluate our proposed method on several realworld datasets and applications. The experimental results demonstrate significant improvements over baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>In order to comprehensively evaluate the effectiveness of the representations, we use five networked datasets, including three social networks, one citation network and one language network, for three real-world applications, i.e. multi-label classification, link prediction and visualization. Considering the characteristics of these datasets, for each application we use one or more datasets to evaluate the performances. The detailed descriptions are listed as follows.</p><p>• BLOGCATALOG <ref type="bibr" target="#b27">[27]</ref>, FLICKR <ref type="bibr" target="#b27">[27]</ref> and YOUTUBE <ref type="bibr" target="#b28">[28]</ref>: They are social network of online users. Each user is labelled by at least one category. There are overall 39 different categories for BLOGCATALOG, 195 categories for FLICKR and 47 categories for categories. These categories can be used as the ground-truth of each vertex. Therefore, they can be evaluated on the multi-label classification task.</p><p>• ARXIV GR-QC <ref type="bibr" target="#b16">[16]</ref>: It is a paper collaboration network which covers papers in the field of General Relativity and Quantum Cosmology from arXiv. In this network, the vertex represents an author and the edge indicates that the authors have coauthored a scientific paper in arXiv. The dataset is used for the link-prediction task since we have no category information of each vertex.</p><p>• 20-NEWSGROUP<ref type="foot" target="#foot_0">4</ref> : This dataset is a collection of approximate 20000 newsgroup documents and each document is labelled by one of the 20 different groups. We use the tfidf vectors of each word to represent the document and the cosine similarity as the similarity between two documents. We can construct the network according to such similarities. We select the documents labelled as comp.graphics, rec.sport.baseball and talk.politics.gums to perform the visualization task.</p><p>To summarize, we conduct experiments on both weighted and unweighted, sparse and dense, small and large networks. Therefore, the datasets can comprehensively reflect the characteristics of the network embedding methods. The detailed statistics of the datasets can be summarized in Table <ref type="table" target="#tab_0">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Algorithms</head><p>We use the following five methods as the baselines. The first four are network embedding methods. Common Neighbor directly predicts the links over the networks, which has been demonstrated to be an effective method to perform link prediction <ref type="bibr" target="#b17">[17]</ref>.</p><p>• DeepWalk <ref type="bibr" target="#b21">[21]</ref>: It adopts random walk and skip-gram model to generate network representations.</p><p>• LINE <ref type="bibr" target="#b26">[26]</ref>: It defines loss functions to preserve the first-order or second-order proximity separately. After optimizing the loss functions, it concatenates these representations.</p><p>• GraRep <ref type="bibr" target="#b4">[4]</ref>: It extends to high-order proximity and uses the SVD to train the model. It also directly concatenates the representations of first-order and high-order.</p><p>• Laplacian Eigenmaps (LE) <ref type="bibr" target="#b1">[1]</ref>: It generates network representations by factorizing the Laplacian matrix of the adjacency matrix. It only exploits the first-order proximity to preserve the network structure.</p><p>• Common Neighbor <ref type="bibr" target="#b17">[17]</ref>: It only uses the number of common neighbors to measure the similarity between vertexes. It is used as the baseline only in the task of link prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics</head><p>In our experiment, we perform the task of reconstruction, link prediction, multi-label classification and visualization. For reconstruction and link prediction, we use precision@k and Mean Average Precision (MAP) to evaluate the performance. Their definitions are listed as follows:</p><p>• precision@k is a metric which gives equal weight to the returned instance. It is defined as follows:</p><formula xml:id="formula_17">precision@k(i) = | {j | i, j ∈ V, index(j) ≤ k, ∆ i (j) = 1} | k</formula><p>where V is the vertex set, index(j) is the ranked index of the j-th vertex and ∆i(j) = 1 indicates that vi and vj have a link.</p><p>• Mean Average Precision (MAP) is a metric with good discrimination and stability. Compared with precision@k, it is more concerned with the performance of the returned items ranked ahead. It is calculated as follows:</p><formula xml:id="formula_18">AP (i) = j precision@j(i) • ∆i(j) | {∆i(j) = 1} | M AP = i∈Q AP (i) | Q | ,</formula><p>where Q is the query set.</p><p>For the multi-label classification task, we adopt micro-F 1 and macro-F 1 as many other works do <ref type="bibr" target="#b27">[27]</ref>. In detail, for a label A, we denote TP(A), FP(A) and FN(A) as the number of true positives, false positives and false negatives in the instances which are predicted as A, respectively. Suppose C is the overall label set. Micro-F 1 and Macro-F 1 are defined as follows:</p><p>• Macro-F 1 is a metric which gives equal weight to each class.</p><p>It is defined as follows:</p><formula xml:id="formula_19">M acro -F 1 = A∈C F 1(A) | C |</formula><p>where F 1(A) is the F 1-measure for the label A.</p><p>• Micro-F 1 is a metric which gives equal weight to each instance. It is defined as follows:</p><formula xml:id="formula_20">P r = A∈C T P (A) A∈C (T P (A)+F P (A)) , R = A∈C T P (A) A∈C (T P (A)+F N (A)) M icro -F 1 = 2 * P r * R P r+R</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameter Settings</head><p>We propose a multi-layer deep structure in this paper and the number of layers varies with different datasets. The dimension of each layer is listed in Table <ref type="table" target="#tab_1">3</ref>. The neural networks have three layers for BLOGCATALOG, ARXIV GR-QC and 20-NEWSGROUP and four layers for FLICKR and YOUTUBE. If we use deeper model, the performance almost remains unchanged or even becomes worse. For our method, the hyper-parameters of α, β and ν are tuned by using grid search on the validation set. The parameters for baselines are tuned to be optimal. For LINE, the mini-batch size of the stochastic gradient descent is set to 1. The learning rate of the starting value is 0.025. The number of negative samples is set as 5 and the total number of samples is 10 billion. In addition, according to <ref type="bibr" target="#b26">[26]</ref>, LINE yields better results when concatenating both 1-step and 2-step representations to form the final embedding vectors and do L2 normalization to the final embedding vectors. We follow their way to get the results of the LINE. For DeepWalk, we set window size as 10, walk length as 40, walks per vertex as 40. For GraRep, we set maximum matrix transition step as 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experiment Results</head><p>In this section, we first evaluate the reconstruction performance. Then we report the results of the generalization of the network representations generated by different embedding methods on three classic data mining and machine learning applications, i.e. multilabel classification, link prediction and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Network Reconstruction</head><p>Before proceeding to evaluate the generalization of the proposed method on real-world applications, we first provide a basic evaluation on different network embedding methods with respect to their capability of network reconstruction. The reason for this experiment is that a good network embedding method should ensure that the the learned embeddings can preserve the original network structure. We use a language network ARXIV GR-QC and a social network BLOGCATALOG as representatives. Given a network, we use different network embedding methods to learn the network representations and then predict the links of the original networks. As the existing links in the original network are known and can serve as the ground-truth, we can evaluate the reconstruction performance, i.e. the training set error, of different methods. The precision@k and MAP are used as the evaluation metrics. The result on the precision@k is presented in Figure <ref type="figure" target="#fig_4">3</ref>. The result on MAP is shown in Table <ref type="table" target="#tab_2">4</ref>.</p><p>From the results, we have the following observations and analysis:   The results show that our method achieves better reconstruction performance than that of baselines.</p><p>• Table <ref type="table" target="#tab_2">4</ref> shows that our method achieves significant improvements in MAP over the baselines in both datasets. Figure <ref type="figure" target="#fig_4">3</ref> shows that the precision@k of our method is consistently the highest when k increases. It demonstrates that our method is able to preserve the network structure well.</p><p>• Specifically, for the network of ARXIV GR-QC, the precision@k of our method can reach 100% and maintain around 100% until the k increases to 10000. This indicates that our method can almost perfectly reconstruct the original network in this dataset, especially considering that the total number of links in this dataset is 28980.</p><p>• Although SDNE and LINE both exploit the first-order and second-order proximity to preserve the network structure, S-DNE achieves better performance. The reasons may be twofold. Firstly, LINE adopts shallow structure, which is difficult to capture the highly non-linear structure in the underlying network. Secondly, LINE directly concatenates the representations for the first-order and second-order proximity, which is sub-optimal than jointly optimizing them in S-DNE.</p><p>• The result that both SDNE and LINE perform better than LE, which only exploits the first-order proximity to preserve the network structure, demonstrates that the import of secondorder proximity can help preserve the network structure better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Multi-label Classification</head><p>Classification is a so important task among many applications that the related algorithm and theories have been investigated by many works <ref type="bibr" target="#b18">[18]</ref>. Therefore, we evaluate the effectiveness of different network representations through a multilabel classification task in this experiment. The representations for the vertexes are generated from the network embedding methods and are used as features to classify each vertex into a set of labels. Specifically, we adopt the LIBLINEAR package <ref type="bibr" target="#b8">[8]</ref> to train the classifiers. When training the classifier, we randomly sample a portion of the labeled nodes as the training data and the rest as the test. For BLOGCAT-ALOG, we randomly sample 10% to 90% of the vertexes as the training samples and use the left vertexes to test the performance.</p><p>For FLICKR and for YOUTUBE, we randomly sample 1% to 10% of the vertexes as the training samples and use the left vertexes to test the performance. In addition, we remove the vertexes which are not labelled by any categories in YOUTUBE. We repeat such a process 5 times and report the averaged Micro-F1 and Macro-F1. The results are shown in Figure <ref type="figure" target="#fig_5">4</ref> and Figure <ref type="figure" target="#fig_6">5</ref>, respectively. From the results, we have the following observations and analysis 5 :</p><p>• In Figure <ref type="figure" target="#fig_5">4</ref> and Figure <ref type="figure" target="#fig_6">5</ref>, the curve of our method is consistently above the curves of baselines. It demonstrates that the learned network representations of our method can better generalize to the classification task than baselines.</p><p>• In Figure <ref type="figure" target="#fig_5">4</ref> (BLOGCATALOG), the improvement margin of our method over the baselines is more obvious when the training percentage decreases from 60% to 10%. It demonstrates that our method can achieve a more significant improvement than baselines when the labelled data is limited. Such an advantage is especially important for real-world applications because the labelled data is usually scarce.</p><p>• In most cases, the performance of DeepWalk is the worst among the network embedding methods. The reasons are twofold. First of all, DeepWalk does not have an explicit objective function to capture the network structure. Secondly, DeepWalk uses a random walk to enrich the neighbors of vertexes, which introduces a lot of noises due to the randomness, especially for vertexes which have high degrees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">Link Prediction</head><p>In this section, we concentrate on the link prediction task and conduct two experiments. The first evaluates the overall performance and the second evaluates that how different sparsity of the networks affects the performance of different methods.</p><p>We use the dataset ARXIV GR-QC in this section. To conduct the link prediction task in a network, we randomly hide a portion of the existing links and use the left network to train the network embedding model. After the training, we can obtain the representations for each vertex and then use the obtained representations 5 Some results such as the observation that our method outperforms LINE have been listed and explained in Section 4.5.1. Therefore, we only list some particular observations of this experiment. Table <ref type="table">5</ref>: precision@k on ARXIV GR-QC for link prediction Algorithm P @2 P @10 P @100 P @200 P @300 P @500 P @800 P @1000 P @10000 SDNE to predict the unobserved link. Unlike the reconstruction task, this task predicts the future links instead of reconstructing the existing links. Therefore, this task can show the performance of predictability of different network embedding methods. In addition, we add Common Neighbor in this task because it has been proved as an effective method to do link prediction <ref type="bibr" target="#b17">[17]</ref>.</p><p>For the first experiment, we randomly hide 15 precentage of existing links (about 4000 links) and use the precision@k as the evaluation metric of predicting the hidden links. We gradually increase the k from 2 to 10000 and report the result in Table <ref type="table">5</ref>. The best performance is highlighted in bold. Some of the observations and analysis on Table <ref type="table">5</ref> are listed as follows:</p><p>• The result shows that when k increases, the performance of our method is consistently better than other network embedding methods. It demonstrates that the representations learned by our method have much better predicting power for new link formation.</p><p>• When k = 1000, the precision of our method is still higher than 0.9, but that of other methods quickly drops below 0.8. It demonstrates that our method can keep a high precision for links ranking ahead. Such an advantage is very important for some real-world applications such as recommendation and information retrieval, because users care more about the results ranked ahead in such applications.</p><p>In the second experiment, we change the sparsity of the networks by randomly removing a portion of links in the original network and then follow the aforementioned procedure to report the results of different network embedding methods. The result is shown in Figure <ref type="figure" target="#fig_7">6</ref>.</p><p>The result shows that the margin between LE and SDNE or between LE and LINE becomes larger when the network is sparser. It demonstrates that the import of second-order proximity is able to make the learned representations more robust to sparse networks. Moreover, when we remove 80% of the links, our method still performs significantly better than baselines. It also demonstrates the power of SDNE in dealing with sparse networks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.4">Visualization</head><p>Another important application for network embedding is to generate visualizations of a network on a two-dimensional space. Therefore, we visualize the learned representations of the 20-NEWSGROUP network. We use the low-dimensional network representations learned by different network embedding methods as the input to the visualization tool t-SNE <ref type="bibr" target="#b31">[31]</ref>. As a result, each newsgroup document is mapped as a two-dimensional vector. Then we can visualize each vector as a point on a two dimensional space. For documents which are labelled as different categories, we use different colors on the corresponded points. Therefore, a good visualization result is that the points of the same color are near from each other. The visualization figure is shown in Figure <ref type="figure">7</ref>. Besides the visualization figure, similar to <ref type="bibr" target="#b4">[4]</ref> we use the Kullback-Leibler divergence as a quantitative evaluation metric. The lower the KL divergence, the better the performance. The result is shown in Table <ref type="table" target="#tab_4">6</ref>.</p><p>From Figure <ref type="figure">7</ref>, we can see that the results of LE and DeepWalk are not satisfactory because the points belonging to different categories are mixed with each other. For LINE, the clusters of different categories are formed. However, in the center part the documents  of different categories are still mixed with each other. For GraRep, the result looks better because points of the same color form segmented groups. However, the boundaries of each group are not very clear. Obviously, the visualization of SDNE performs best in both the aspects of group separation and boundary aspects. The results shown in Table <ref type="table" target="#tab_4">6</ref> also quantitatively demonstrate the superiority of our method in the visualization task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Parameter Sensitivity</head><p>We investigate the parameter sensitivity in this section. Specifically, we evaluate how different numbers of the embedding dimensions and different values of hyper-parameter α and β can affect the results. We report precision@k on the dataset of ARXIV-GRQC.</p><p>Choose an appropriate number of embedding dimensions: We first show how the dimension of the embedding vectors affects the performance in Figure <ref type="figure">8</ref>(a). We can see that initially the performance raises when the number of dimension increases. This is intuitive as more bits can encode more useful information in the increasing bits. However, when the number of dimensions continuously increases, the performance starts to drop slowly. The reason is that too large number of dimensions may introduce noises which will deteriorate the performance. Overall, it is always important to determine the number of dimensions for the latent embedding space, but our method is not very sensitive to this parameter.</p><p>Find a good balanced point between first-order and secondorder proximity: Then we show how the value of α affects the performance in Figure <ref type="figure">8</ref>(b). The parameter of α balances the weight of the first-order proximity and second-order proximity between vertexes. When α = 0, the performance is totally determined by the second-order proximity. And the larger the α, the more the model concentrates on the first-order proximity. From Figure <ref type="figure">8</ref>(b), we can see that the performance of α = 0.1 and α = 0.2 are better than that of α = 0. It demonstrates that both first-order and secondorder proximity are essential for network embedding methods to characterize the network structure.</p><p>Concentrate more on the reconstruction error for the nonzero elements: At last, we show how the value of β affects the performance. The β controls the reconstruction weight of the nonzero elements in the training graph. The larger the β, the model will more prone to reconstruct the non-zero elements. The result is shown in Figure <ref type="figure">8</ref>(c). We can see that when β = 1, the result is not good. Because in this case, the model will equally reconstruct the non-zero and zero elements in the training network. As we have explained before, no link between two nodes does not indicate dissimilarity of these two nodes, but the existence of a link between two nodes does indicate similarity of these two nodes. Therefore, the reconstruction of zero elements will introduce noises and thus deteriorate the performance. However, when β is too large, the performance decreases too. The reason is that, in this case, the model almost ignores the zero-elements when perform reconstruction and is prone to maintain similarity between any pair of nodes. However, many zero elements still indicate the dissimilarity between vertexes. Therefore, the performance drops. This experiment suggests that we should concentrate more on the reconstruction error of none-zero elements in the training networks but cannot totally omit the reconstruction error of zero elements when we perform network embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>In this paper, we propose a Structural Deep Network Embed-ding, namely SDNE, to perform network embedding. Specifically, to capture the highly non-linear network structure, we design a semi-supervised deep model, which has multiple layers of nonlinear functions. To further address the structure-preserving and sparsity problem, we jointly exploit the first-order proximity and second-order proximity to characterize the local and global network structure. By jointly optimizing them in the semi-supervised deep model, the learned representations are local-global structurepreserved and are robust to sparse networks. Empirically, we evaluate the generated network representations in a variety of network datasets and applications. The results demonstrate substantial gains of our method compared with state-of-the-art.</p><p>Our future work will focus on how to learn representations for a new vertex which has no linkage to existing vertexes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The number of pairs of vertexes which have firstorder and second-order proximity in different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The framework of the semi-supervised deep model of SDNE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Training Algorithm for the semi-supervised deep model of SDNE Input: the network G = (V, E) with adjacency matrix S, the parameters α and ν Output: Network representations Y and updated Parameters: θ 1: Pretrain the model through deep belief network to obtain the initialized parameters θ = {θ (1) , ..., θ (K) } 2: X = S 3: repeat 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: precision@k on (a) ARXIV GR-QC and (b) BLOG-CATALOG.The results show that our method achieves better reconstruction performance than that of baselines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Micro-F1 and Macro-F1 on BLOGCATALOG. The results show that our method achieves better classification performance than that of baselines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Micro-F1 and Macro-F1 on (a) FLICKR and (b) YOUTUBE. The results show that our method achieves the best classification performance among baselines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance of network embedding on networks of different sparsity. It shows that SDNE is more robust to the sparse network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Visualization of 20-NEWSGROUP. Each point indicates one document. Color of a point indicates the category of the document. The blue indicates the topic of rec.sport.baseball, the red indicates the topic of comp.graphics and the green indicates the topic of talk.politics.guns</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the dataset</figDesc><table><row><cell>Dataset</cell><cell>#(V)</cell><cell>#(E)</cell></row><row><cell>BLOGCATALOG</cell><cell>10312</cell><cell>667966</cell></row><row><cell>FLICKR</cell><cell>80513</cell><cell>11799764</cell></row><row><cell>YOUTUBE</cell><cell>1138499</cell><cell>5980886</cell></row><row><cell>ARXIV GR-QC</cell><cell>5242</cell><cell>28980</cell></row><row><cell>20-NEWSGROUP</cell><cell>1720</cell><cell>Full-connected</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Neural Network Structures</cell></row><row><cell>Dataset</cell><cell>#nodes in each layer</cell></row><row><cell>BLOGCATALOG</cell><cell>10300-1000-100</cell></row><row><cell>FLICKR</cell><cell>80513-5000-1000-100</cell></row><row><cell>YOUTUBE</cell><cell>22693-5000-1000-100</cell></row><row><cell>ARXIV GR-QC</cell><cell>5242-500-100</cell></row><row><cell>20-NEWSGROUP</cell><cell>1720-200-100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>MAP on ARXIV-GRQC and BLOGCATALOG on reconstruction task</figDesc><table><row><cell>Method</cell><cell>SDNE</cell><cell cols="4">ARXIV-GRQC GraRep LINE DeepWalk LE</cell><cell cols="5">BLOGCATALOG SDNE GraRep LINE DeepWalk LE</cell></row><row><cell>MAP</cell><cell>0.836**</cell><cell>0.05</cell><cell>0.69</cell><cell>0.58</cell><cell cols="2">0.23 0.63**</cell><cell>0.42</cell><cell>0.58</cell><cell>0.28</cell><cell>0.12</cell></row><row><cell></cell><cell></cell><cell cols="6">Significantly outperforms GraRep at the: ** 0.01 level.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 :</head><label>6</label><figDesc>KL-divergence for the 20-NEWSGROUP dataset</figDesc><table><row><cell>Algorithm</cell><cell cols="5">SDNE GraRep LINE DeepWalk LE</cell></row><row><cell cols="2">KL divergence 0.68**</cell><cell>0.73</cell><cell>0.87</cell><cell>2.6</cell><cell>2.95</cell></row><row><cell cols="5">Significantly outperforms GraRep at the: ** 0.01 level.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>http://qwone.com/ jason/20Newsgroups/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGMENTS</head><p>This work was supported by National Program on Key Basic Research Project, No. 2015CB352300; National Natural Science Foundation of China, No. 61370022, No. 61531006, No. 61472444 and No. 61210008. Thanks for the research fund of Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning deep architectures for ai</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Heterogeneous network embedding via deep architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Context and contextual word meaning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Dash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SKASE Journal of Theoretical Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="21" to="31" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A non-iid framework for collaborative filtering with restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">K</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML-13</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1148" to="1156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>-R. Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A matrix factorization technique with trust propagation for recommendation in social networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM conference on Recommender systems</title>
		<meeting>the fourth ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structure of growing social networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Girvan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">46132</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph evolution: Densification and shrinking diameters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American society for information science and technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cauchy graph embedding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="553" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="849" to="856" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semantic hashing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="969" to="978" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Structure preserving embedding</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="937" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1631</biblScope>
			<biblScope unit="page">1642</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>International World Wide Web Conferences Steering Committee</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Relational learning via latent social dimensions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scalable learning of collective behavior based on sparse social dimensions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1107" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph kernels</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1201" to="1242" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep multimodal hashing with orthogonal regularization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence</title>
		<meeting>the 24th International Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2291" to="2297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spectral hashing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1753" to="1760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-view intact space learning. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2531" to="2544" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Two-layer multiple kernel learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="909" to="917" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
