<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Robustness of Graph Neural Networks with Heterophily-Inspired Designs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiong</forename><surname>Zhu</surname></persName>
							<email>jiongzhu@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junchen</forename><surname>Jin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">T</forename><surname>Schaub</surname></persName>
							<email>schaub@cs.rwth-aachen.de</email>
							<affiliation key="aff2">
								<orgName type="institution">RWTH Aachen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
							<email>dkoutra@umich.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Robustness of Graph Neural Networks with Heterophily-Inspired Designs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent studies have exposed that many graph neural networks (GNNs) are sensitive to adversarial attacks, and can suffer from performance loss if the graph structure is intentionally perturbed. A different line of research has shown that many GNN architectures implicitly assume that the underlying graph displays homophily, i.e., connected nodes are more likely to have similar features and class labels, and perform poorly if this assumption is not fulfilled. In this work, we formalize the relation between these two seemingly different issues. We theoretically show that in the standard scenario in which node features exhibit homophily, impactful structural attacks always lead to increased levels of heterophily. Then, inspired by GNN architectures that target heterophily, we present two designs-(i) separate aggregators for ego-and neighbor-embeddings, and (ii) a reduced scope of aggregation-that can significantly improve the robustness of GNNs. Our extensive empirical evaluations show that GNNs featuring merely these two designs can achieve significantly improved robustness compared to the best-performing unvaccinated model with 24.99% gain in average performance under targeted attacks, while having smaller computational overhead than existing defense mechanisms. Furthermore, these designs can be readily combined with explicit defense mechanisms to yield state-of-the-art robustness with up to 18.33% increase in performance under attacks compared to the best-performing vaccinated model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph neural networks (GNNs) aim to translate the enormous empirical success of deep learning to data defined on non-Euclidean domains such as manifolds or graphs <ref type="bibr" target="#b3">[4]</ref>, and have become important tools to solve a variety of learning problems for graph structured and geometrically embedded data. However, as shown in recent works <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b4">5]</ref>, graph neural networks-much like their "standard" deep learning counterparts-can suffer from high sensitivity to adversarial perturbations: intentionally introduced minor changes in the graph structure can lead to significant changes in the performance of GNNs. This finding, first articulated by Zügner et al. <ref type="bibr" target="#b40">[41]</ref> and Dai et al. <ref type="bibr" target="#b4">[5]</ref>, has triggered a large number of studies that investigated different types of attack scenarios <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>A seemingly unrelated aspect that has been scrutinized in the literature recently is that many GNNs rely on homophily, i.e., the tendency of similar nodes (with respect to features or class labels) to create connections <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b39">40]</ref>. Datasets displaying such tendencies are thus typically called homophilous. For simplicity, we overload this term to also denote GNNs grounded in this idea, such as the graph convolutional network (GCN) <ref type="bibr" target="#b12">[13]</ref>, which aggregates information through averaging over neighboring nodes. While homophilous network data and architectures are dominant in the study of networks, homophily is not a universal organizational principle, and there are networks (such as romantic relationship networks, or predator-prey networks in ecology) which are mostly heterophilous. It has been shown that simply applying a homophilous GNN to a heterophilous dataset can lead to significant performance loss compared to the homophilous regime due to assumption mismatch <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b35">36]</ref>. Thus, to learn from such heterophilous network data, modified 'heterophilous' GNN architectures are necessary, as neighboring node features now may be anti-correlated with neighboring class labels.</p><p>While previous studies were concerned with naturally occurring heterophilous interactions, such heterophilous interactions may also be artificially introduced as adversarial noise: as homophilous network architectures exploit homophilous correlation, they can be sensitive to deviations that render the data more heterophilous. A natural question is then if this observation can be related to previously proposed attacking strategies on GNNs. In this work, we therefore investigate the relation between heterophily and robustness of graph neural networks against adversarial structural perturbations on graphs, focusing on the task of semi-supervised node classification.</p><p>More specifically, our main contributions are:</p><p>• We formally show that existing structural attacks work by exploiting the limitations of GNNs in handling graphs with heterophily. More precisely, we prove that effective structural attacks on homophilous graphs always lead to increased heterophily in the neighborhood of the target nodes. • We identify architectural designs-inspired from handling heterophily-that improve robustness of GNNs against adversarially-induced heterophilous connections with theoretical justifications: (i) ego-and neighbor-embedding separation, and (ii) utilization of smaller aggregation scope. • We analyze the effectiveness of the identified designs through extensive experiments with both real-world homophilous and heterophilous datasets, and compare GNN models with these designs to state-of-the-art robustified models. Our results show that GNNs featuring merely the identified designs achieve significantly improved robustness compared to models without these designs, while having the same order of computational complexity. In addition, combining these designs with existing vaccination mechanisms yields state-of-the-art robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Notation and Preliminaries</head><p>Let G = (V, E, X) be an undirected, unweighted graph with node set V, edge set E (without selfloops) and node attributes X. The (1-hop) neighborhood N (v) = {u : (u, v) ∈ E} of a node v ∈ V is the set of all nodes that are directly adjacent to v; the k-hop neighborhood of v ∈ V is defined as the set of all nodes from which v can be reached by a shortest path of length k. We represent the graph G algebraically by an adjacency matrix A ∈ {0, 1} |V|×|V| and node feature matrix X ∈ R |V|×F . We use A s = A + I to denote the adjacency matrix with self-loops added, and denote the corresponding row-stochastic matrices as Ā = D −1 A and Ās = D −1 s A s , respectively, where D is a diagonal matrix with D ii = j A ij (D s is defined analogously). We further assume there exists a class label vector y, which contains a unique class label y v for each node v. Given a training data set T V = {(v 1 , y 1 ), (v 2 , y 2 ), ...} of labeled nodes, the goal of semi-supervised node classification is now to learn a mapping : V → Y from the nodes to the set Y of class labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph neural networks (GNNs)</head><p>The majority of current graph neural networks operate according to a message passing paradigm. A typical formalization of this approach is to assign a representation vector r v to each node v ∈ V that is iteratively updated by K stackable layers of learnable transformations that alternate between aggregating representations over neighboring nodes N (v) and updating the current representation r (k)   v via a (nonlinear) encoder ENC. For prevailing GNN models like GCN <ref type="bibr" target="#b12">[13]</ref> and GAT <ref type="bibr" target="#b32">[33]</ref>, each layer can be formalized as</p><formula xml:id="formula_0">r (k) v = ENC AGGR r (k−1) u : u ∈ N (v) ∪ {v}</formula><p>, where AGGR is the mean function weighted by node degrees (GCN) or an attention mechanism (GAT), and ENC is any learnable (nonlinear) mapping.</p><p>Adversarial attacks on graph Given a clean graph G = (V, E, X) and a GNN f that processes graph G, the goal of an adversarial attacker is to perturb the structure of G and create a graph G = (V, E , X) with a modified set of edges E such that the performance of the GNN f is maximally degraded. The knowledge available to the attacker can vary under different scenarios <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref>. Here, we follow the gray-box assumption formalized by Zügner et al. <ref type="bibr" target="#b40">[41]</ref>, where the attacker can access the training set T V , but does not know the trained GNN f . To create attacks, the attacker considers a surrogate GNN and chooses perturbations that maximize the attack loss L atk , assuming that effective attacks to the surrogate model are transferable to the attacked GNN <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>. For node classification, the attack loss L atk quantifies the mismatch of the predictions z v ∈ [0, 1] |Y| made by the GNN f compared to the true labels y. As an example, for a targeted attack of node v with class label y v ∈ Y, the loss L atk could be the cross-entropy loss (CE-type) used for training the network <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b34">35]</ref>:</p><formula xml:id="formula_1">L CE atk = H (z v , y v ) = − log z v,yv</formula><p>, or the negative classification margin (CMtype) <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b34">35]</ref>:</p><formula xml:id="formula_2">L CM atk = −∆ c = −(z v,yv − max y =yv z v,y</formula><p>). The perturbations of attackers are usually subject to additional constraints, such as the amount of perturbations and unnoticeability <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taxonomy of attacks</head><p>We follow the taxonomy of attacks introduced in prior work <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref>. For node classification, the attacker may aim to change the classification of a specific node v ∈ V (targeted attack), or to decrease the overall classification accuracy (untargeted attack). Attacks can also happen at different stages relative to the training process: we refer to the attacks introduced before the training process as poison (pre-training) attacks, and attacks introduced after the training process (and before potential retraining on the perturbed data) as evasion (post-training) attacks. While our theoretical analysis ( §3) mostly considers targeted evasion attacks, we consider other types of attacks in our empirical evaluation ( §5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Characterizing homophily and heterophily in graphs</head><p>We characterize the types of connections in a graph which contribute to its overall level of homophily and heterophily as follows:</p><p>Definition 1 (Homo/Heterophilous path and edge) A k-hop homophilous path from node w to u is a length-k path between endpoint nodes with the same class label y w = y u . Otherwise, the path is called heterophilous. A homophilous or heterophilous edge is a special case with k = 1.</p><p>Following <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b19">20]</ref>, we define homophily ratio h to quantify the level of homophily in a network: Definition 2 (Homophily ratio) The homophily ratio is the fraction of homophilous edges among all the edges in a graph:</p><formula xml:id="formula_3">h = |{(u, v) ∈ E|y u = y v }|/|E|.</formula><p>The homophily ratio h can help distinguish the tendency of connections in a network as either homophilous or heterophilous. As discussed in <ref type="bibr" target="#b19">[20]</ref>, when the edges in a graph are wired randomly, independent to the node labels, the expectation for h will be h r = 1  |Y| on graphs with balanced classes. By comparing h with h r , we define the tendency of connections as follows:</p><p>Definition 3 (Homophilous tendency) A graph G with class labels Y displays a homophilous tendency if its homophily ratio satisfies h &gt; 1 |Y| . Otherwise it displays a heterophilous tendency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relation between Graph Heterophily &amp; Model Robustness</head><p>In this section, we formalize the connection between the ability of GNN models to learn under heterophily and their robustness against adversarial structural attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Structural Attacks are Mostly Heterophilous Attacks</head><p>Our first result shows that, for homophilous data, effective structural attacks on GNNs (as measured by loss L atk ) always result in a reduced level of homophily: new heterophilous connections are added, or existing homophilous connections are removed. It also states that direct perturbations on 1-hop neighbors of the target nodes are more effective than indirect perturbations (so-called influencer attacks <ref type="bibr" target="#b40">[41]</ref>) on multi-hop neighbors. For simplicity, we establish the theorem below for targeted evasion (post-training) attacks in a stylized learning setup; however, our findings generalize to more general attack types and datasets as we show in our experiments ( §5).</p><p>Theorem 1 Let G = (V, E, X) be a d-regular, self-loop-free graph with adjacency matrix A and node features xv = p • onehot(yv) + 1−p |Y| • 1 for each node v, where 1 is an all-1 vector, and p is a parameter that regulates the signal strength of the one-hot class label compared to uniform noise. Also assume that a fraction h of each node's neighbors belong to the same class, while a fraction 1−h |Y|−1 belongs uniformly to any other class. Consider a 2-layer linearized GNN f (2)   s (A, X) = Ā2</p><p>s XW trained on a training set T V with at least one node from each class y ∈ Y. If h &gt; 1 |Y| , the following statements hold for a unit perturbation of the adjacency matrix that targets an arbitrary node v: 1. the attack losses L atk (both CE-and CM-type, §2) increase only when removing a homophilous edge or path, or adding a heterophilous edge or path to node v; 2. direct perturbations on edges (or 1-hop paths) of the target node v lead to greater increase in L atk than indirect perturbations on multi-hop paths to target node v.</p><p>We give the proof in App. C.1. Intuitively, the relative inability of existing GNNs to exploit heterophilous data <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b39">40]</ref> can be exploited by an attacker by inserting heterophilous connections in graphs expected to be homophilous. However, when the graph displays a heterophilous tendency, attacks increasing the homophily level are effective, in particular if degree d is high; if degree d is low, decreasing the homophily level can still be effective. We discuss this case in detail in App. C.1. Empirical Observations Table <ref type="table" target="#tab_0">1</ref> shows the change in homophily ratio for four datasets before and after NETTACK <ref type="bibr" target="#b40">[41]</ref> (see §5.1 for detailed setup). For all graphs displaying a homophily tendency (h &gt; 1 |Y| ), the average homophily ratio in 1-hop neighborhoods of the target nodes, h t , reduces significantly after NETTACK. These results confirm Thm. 1 and relevant observations in prior works <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b10">11]</ref>. For the heterophilous dataset Snap Patents, we explain the increase in h t in App. C.1.</p><p>We further observe that the heterophilous connections introduced by attackers, especially for targeted attacks, affect mostly the level of homophily within the neighborhood of the target nodes, h t . In comparison, most naturally-heterophilous graphs exhibit heterophilous connections globally. This difference between adversarially-introduced local heterophily and naturally-occurring global heterophily leads to differences in the designs of effective architectures for both scenarios ( §3.2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Boosting Robustness with Heterophily-inspired Designs</head><p>Based on the findings in the previous section, a natural follow-up question is whether GNNs with better performance under heterophily are more robust against structural attacks. Inspired by recent works on improving GNNs for heterophilous settings <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b35">36]</ref>, we present two designs-separate aggregators for ego-and neighbor-embeddings ( §3.2.1), and a reduced scope of aggregation ( §3.2.2)-that boost the robustness of GNNs by enabling them to better deal with adversarially-introduced heterophilous connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Design 1: Using Separate Aggregators for Ego-and Neighbor-embeddings</head><p>In the first design, we separate the GNN aggregators for ego-embedding r v and neighbor-embeddings {r u : u ∈ N (v)}. Formally, the representation learned for node v in the k-th layer is:</p><formula xml:id="formula_4">r (k) v = ENC AGGR1(r (k−1) v ), AGGR2({r (k−1) u : u ∈ N (v)}) ,<label>(1)</label></formula><p>where AGGR1 and AGGR2 are separate aggregators, such as averaging functions (GCN), attention mechanisms (GAT), or pooling mechanisms <ref type="bibr" target="#b8">[9]</ref>, and ENC is any learnable (nonlinear) mapping. This design has been utilized in existing GNN models including GraphSAGE <ref type="bibr" target="#b8">[9]</ref> and H 2 GCN <ref type="bibr" target="#b39">[40]</ref>, and has been shown to boost the representation power of GNNs under natural heterophily <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intuition</head><p>The key change in comparison to the GCN-style formulation in §2 is to allow the egoembedding r v to be aggregated and weighted separately from the neighbor-embeddings {r u : u ∈ N (v)}. Intuitively, ego-embeddings are independent of the graph structure and thus unaffected by adversarial perturbations; hence, a separate aggregator provides access to information unperturbed from attacks, and helps mitigate the effects caused by attacks in the final node representation.</p><p>Theory We formalize the above intuition by analyzing how separate aggregators for ego-and neighbor-embeddings enable GNN layers to reduce the attack loss, even if only a very simple implementation of this principle is considered. Specifically, we show that even if AGGR1 and AGGR2 in Eq. ( <ref type="formula" target="#formula_4">1</ref>) are simple averaging functions as in Thm. 1, and ENC is a linear combination of the two aggregated representations, merely increasing the weights α for the ego-embedding in the linear combination ENC can lead to reduced attack loss L atk under structural perturbations:</p><p>Theorem 2 Under the setup of Thm. 1, consider two alternative layers from which a two-layer linearized GNN is built: (1) a layer defined as f s (A, X) = Ās XW; and (2) a layer formulated as f (A, X; α) = (1 − α) Ā + αI XW, which mixes the ego-and neighbor-embedding linearly under a predefined weight α ∈ [0, 1]. Then, for h &gt; 1 |Y| , α &gt; 1 1+d , and a unit perturbation increasing L atk as discussed in Thm. 1, outputs of layer f lead to a strictly smaller increase in L atk than f s .</p><p>We provide the proof in App. C.2; note that for α = 1 1+d , the two layers are the same: f (A, X; α) = f s (A, X). Theorem 2 essentially shows that an increase to the weights of ego-embedding improves the robustness of the GNN f for a homophily ratio h &gt; 1  |Y| . Though aggregators and encoders are stylized in the theorem, the empirical analysis in §5 confirms that GNNs with more advanced aggregators and encoders also benefit from separate aggregators for ego-embeddings: methods with this design outperform methods without it by at least 14.45% and 8.89% on homophilous and heterophilous graphs, respectively, while performing comparably on clean datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Design 2: Utilization of Smaller Scope of Aggregation</head><p>The second design reduces the scope of aggregation in GNNs. We find that shallow GNN architectures with few layers K, which aggregate information from the immediate neighbors N (v) of each node v ∈ V (e.g., Eq. ( <ref type="formula" target="#formula_4">1</ref>)), provide better robustness against structural perturbations than deeper GNNs. Note that this is in contrast to the GNN designs addressing naturally-occurring heterophily which aim to aggregate information from higher-order neighborhoods <ref type="bibr" target="#b39">[40]</ref>.</p><p>Intuition To deal with naturally-occurring heterophily that is exhibited globally in the graph, a useful strategy is to exploit the heterophilous patterns by considering higher-order neighborhoods <ref type="bibr" target="#b39">[40]</ref> or GNN formulations leveraging class compatibility matrices <ref type="bibr" target="#b38">[39]</ref>. On the contrary, adversariallyintroduced heterophily is localized to the neighborhood of the target node, while there are globally few heterophilous connections in the graph (cf. Table <ref type="table" target="#tab_0">1</ref>). Capturing this local heterophilous deviation in an otherwise homophilous graph is difficult, even for GNN designs capable of modeling heterophily. Furthermore, directly perturbing the 1-hop neighborhood of the target node also leads to changes in its 2-hop neighborhood and beyond: for example, on a graph with homophily ratio h close to 1, adding a heterophilous connection from node v with class label y v to node u with class label y u = y v introduces other neighbors of node u to the 2-hop neighborhood of node v, which reduces the level of homophily in the 2-hop neighborhood of node v. Thus, these perturbations propagate to higher-order neighborhoods of the target node, and further increase the attack loss L atk , as we formalize next.</p><p>Theory As we show next, GNNs with smaller scope of aggregation accumulate fewer perturbations in the neighborhood of the target node during the aggregation step, and have smaller attack loss L atk than GNNs with larger scope of aggregation:</p><formula xml:id="formula_5">Theorem 3 Under the setup of Thm. 1, consider the 2-layer GNN f (2) s (A, X) = Ā2 s XW and the single-layer GNN f s (A, X) = Ās XW. For h &gt; 1</formula><p>|Y| and a unit perturbation increasing L atk as in Thm. 1, outputs of the single-layer GNN f s lead to a strictly smaller increase in L atk than f (2)  s .</p><p>The proof is given in App. C.3. Going beyond the specific GNN architecture considered in the proof, our empirical analysis in §5.2 shows the effectiveness of this design for more general settings. Specifically, we evaluate its effectiveness by comparing the robustness of multiple GNN methods using 1 or 2 layers, and observe increased accuracy against attacks by up to 23.89% for all methods, including GCN <ref type="bibr" target="#b12">[13]</ref>, which does not utilize our first design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Adversarial Attacks and Defense Strategies for Graphs Since NETTACK <ref type="bibr" target="#b40">[41]</ref> and RL-S2V <ref type="bibr" target="#b4">[5]</ref> first demonstrated the vulnerabilities of GNNs against adversarial perturbations, a variety of attack strategies under different scenarios have been proposed, including adversarial attacks on the graph structure <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b16">17]</ref>, node features <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b21">22]</ref>, or combinations of these perturbations <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>On the defense side, various techniques for improving the robustness of GNNs against adversarial attacks have been proposed, including: adversarial training <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b2">3]</ref>; low-rank approximation of graph adjacency <ref type="bibr" target="#b6">[7]</ref> to mitigate the perturbations introduced by Nettack <ref type="bibr" target="#b40">[41]</ref>; Pro-GNN <ref type="bibr" target="#b11">[12]</ref>, which aims to learn the unperturbed graph structure in training by assuming that the unperturbed graph is low-rank, sparse, and shows homophily with respect to the node features; GCN-Jaccard <ref type="bibr" target="#b33">[34]</ref> and GNNGuard <ref type="bibr" target="#b36">[37]</ref>, which also assume homophily of features (or structural embeddings), and train GNN models on a pruned graph in which only strong homophilous links are kept; RGCN <ref type="bibr" target="#b37">[38]</ref>, which uses Gaussian distributions for node embeddings and adopt a variance-based attention mechanism to mitigate perturbations. Other recent works have looked into certification of nodes that are guaranteed to be immune to certain types of structural and feature perturbations <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b43">44]</ref>. Interested readers are referred to the recent surveys <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref> for a comprehensive review of the literature.</p><p>GNNs &amp; Heterophily Despite the success of GNNs on homophilous networks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b9">10]</ref>, recent works <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b38">39]</ref> showed that heterophilous datasets can lead to significant performance loss for popular GNN architectures (e.g., GCN <ref type="bibr" target="#b12">[13]</ref>, GAT <ref type="bibr" target="#b32">[33]</ref>). This issue is also known in classical semi-supervised learning <ref type="bibr" target="#b23">[24]</ref>. To address this issue in semi-supervised node classification, several GNN designs for handling heterophilous connections have been proposed <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b1">2]</ref>. Yan et al. <ref type="bibr" target="#b35">[36]</ref> recently discussed the connection between graph heterophily and oversmoothing for GNNs, and proposed designs to address both issues simultaneously. However, the formal connection between heterophily and robustness to adversarial attacks in graphs has received little attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Empirical Evaluation</head><p>In our empirical analysis, we seek to answer the following questions: (Q1) How robust to adversarial attacks are models vaccinated with our theoretically-identified designs? (Q2) How do models with our designs compare to state-of-the-art vaccinated GNN models?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Attack Setup We consider both targeted and untargeted attacks (cf. §2), generated by NET-TACK <ref type="bibr" target="#b40">[41]</ref> and Metattack <ref type="bibr" target="#b41">[42]</ref>, respectively. As we focus on robustness against structural perturbations, we keep the node features unchanged. We randomly generate 3 sets of perturbations per attack method and dataset. Per attack method, we consider poison (pre-training) and evasion (post-training) attacks, leading to four attack cases in total. We provide more details in App. D.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GNN Models</head><p>To demonstrate the effectiveness of our identified designs compared to existing vaccination mechanisms, we evaluate four groups of models against adversarial attacks: (1) Models vaccinated with heterophily-inspired designs only: GraphSAGE <ref type="bibr" target="#b8">[9]</ref>, H 2 GCN <ref type="bibr" target="#b39">[40]</ref> and CPGNN <ref type="bibr" target="#b38">[39]</ref>;</p><p>(2) State-of-the-art architectures designed with robustness in mind: ProGNN <ref type="bibr" target="#b11">[12]</ref>, GNNGuard <ref type="bibr" target="#b36">[37]</ref> and GCN-SVD <ref type="bibr" target="#b6">[7]</ref>;</p><p>(3) Models vaccinated with both heterophily-inspired designs and explicit robustness-enhancing mechanisms based on low-rank approximation: H 2 GCN-SVD and GraphSAGE-SVD; (4) Models without any vaccination, including some of the most popular methods: GCN <ref type="bibr" target="#b12">[13]</ref>, GAT <ref type="bibr" target="#b32">[33]</ref>, and the graph-agnostic multilayer perceptron (MLP) that relies only on node features. We discuss the implementations and parameters used in App. D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets &amp; Evaluation Setup</head><p>In addition to the two widely-adopted datasets with strong homophily, Cora <ref type="bibr" target="#b22">[23]</ref> and Citeseer <ref type="bibr" target="#b26">[27]</ref>, we consider two heterophilous (or weakly homophilous) graphs introduced in <ref type="bibr" target="#b19">[20]</ref>: FB100 <ref type="bibr" target="#b30">[31]</ref> and Snap Patents <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. We report the data statistics in Table <ref type="table" target="#tab_1">2</ref> and give more details in App. D.4. For computational tractability, we sample a subset of the Snap Patents data using a snowball sampling approach <ref type="bibr" target="#b7">[8]</ref>, where we keep 20% of the neighbors for each traversed node (see App. D.4 for details). For evaluation, we follow the setup in <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b11">12]</ref>: per dataset, we split the nodes into training (10%), validation (10%) and test (80%) splits, and determine the model parameters using the training and validation splits. We report the average performance and standard deviation on the 3 sets of perturbations that we generated. For targeted attacks with NETTACK, we report the classification accuracy on the target nodes; for untargeted attacks with Metattack, we report it over the test splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Robustness of Models with the Theoretically-identified Designs: Empirical Validation</head><p>In this section, focusing on targeted attacks, we compare models with the designs identified in §3.2 to models without any vaccination, consistent with our assumptions for theoretical analysis in §3.  <ref type="table" target="#tab_1">2</ref> shows that all methods with Design 1 significantly outperform methods without the design under poison attacks by at least 14.45% and 8.89% on homophilous and heterophilous datasets, respectively. On the clean data, all methods perform similarly with differences in accuracy less than 3.5% in most cases. These results confirm the findings of Thm. 2 for real-world datasets.</p><p>Design 2: Utilization of Smaller Scope of Aggregation We study the performance of three GNN methods, GCN, H 2 GCN and GraphSAGE, when varying their number of layers as 1 or 2 (the default). The bottom part of Table <ref type="table" target="#tab_1">2</ref> shows that by adopting a smaller scope of aggregation, H 2 GCN and GraphSAGE achieve 3.89% to 23.89% performance gain under poison attacks across the four datasets. We also observe increased robustness for 1-layer GCN over 2-layer GCN in all homophilous datasets, even though GCN does not utilize Design 1. These observations validate Thm. 3, which states that robustness against targeted structural attacks can be improved by reducing the scope of GNN aggregation on real-world datasets. Note, however, that there are trade-offs between increased robustness and reduced performance without attacks, as we discuss in §6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Benchmark Study of GNN Models</head><p>In addition to the ablation studies, we also conduct a comprehensive benchmark study to evaluate the effectiveness of our identified designs in comparison to existing vaccination mechanisms. We consider all four categories of GNN models mentioned in §5.1, and evaluate their robustness against both targeted and untargeted attacks through NETTACK and Metattack, respectively. We report the hyperparameters used for each method in App. D.3; note that we fix the number of layers for all methods to 2 for a fair comparison, as reducing the number of layers improves robustness for a variety of models (per Design 2 and observations in §5.2).  <ref type="table" target="#tab_2">3</ref> (left) shows that GraphSAGE-SVD and H 2 GCN-SVD, which combine our identified designs with the existing vaccination approach of low-rank approximation adopted in GCN- Without adopting existing vaccination mechanisms, H 2 GCN, GraphSAGE and CPGNN, which only utilize the identified designs, also show significantly improved robustness compared to unvaccinated methods: models based on heterophily-inspired designs outperform the best-performing unvaccinated method (GAT) on all datasets by up to 24.99% in average performance, despite having comparable performance on clean datasets. On datasets such as Citeseer and FB100, they also achieve comparable performance to state-of-the-art vaccinated baselines like ProGNN and GCN-SVD. We note that GNNGuard, a competitive baseline under homophily, has significantly worse robustness under heterophily; this demonstrates the limitations of similaritybased vaccination approaches, which, by implicitly assuming homophily in their design, may hinder the robustness on heterophilous graphs. 2 Evasion attacks. Under evasion attacks (Table <ref type="table">E</ref>.1), we observe similar trends as in poison attacks: while GNNGuard and ProGNN are not designed to defend against evasion attacks, GraphSAGE-SVD and H 2 GCN-SVD are up to 20.55% more accurate than the GCN-SVD baseline, and methods featuring the identified designs alone achieve up to 24.44% gain in average performance against the best unvaccinated baseline. In summary, these observations show that the heterophily-inspired designs are orthogonal to existing vaccination mechanisms for improving the robustness of GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness and Performance</head><p>Untargeted attacks by Metattack: 1 Poison attacks. We also test the robustness of each method against untargeted attacks by Metattack. Table <ref type="table" target="#tab_2">3</ref> (right) shows the performance under poison attacks.</p><p>Though our theoretical analysis in §3 focuses mostly on the effectiveness of heterophily-inspired designs under targeted attacks, we also observe similar improvements in robustness brought by adopting these designs against untargeted attacks in the poison setup: models featuring the identified designs show significantly improved robustness compared to unvaccinated models by up to 16.05% across all datasets, while having comparable average performance on the clean datasets. Moreover, models combining these designs with low-rank approximation show more than 10% improvement in average accuracy compared to GCN-SVD, which uses only low-rank approximation, and ProGNN. We note that GNNGuard also shows more competitive robustness under untargeted attacks by utilizing similarity-based defense, as existing works have shown that low-rank based approach does not adapt well to untargeted attacks <ref type="bibr" target="#b11">[12]</ref>. Nevertheless, methods combining both designs and low-rank still outperform GNNGuard on two datasets, and have the best average ranking among all methods. 2 Evasion attacks. We present the performance under evasion attacks and on clean datasets in Table <ref type="table">E</ref>.2 in the Appendix. Unlike the poison attacks, the evasion setup of Metattack only leads to a slight decrease of less than 2% in average accuracy for most models compared to their performance on clean datasets, and do not show advantages of increased robustness for vaccinated models (with the identified designs or other vaccination machanisms) against unvaccinated models.</p><p>Complexity and Runtime Another benefit of adopting heterophily-inspired designs for boosting robustness of GNNs is their smaller computational overhead compared to existing vaccination mechanisms, especially vaccinations based on low-rank approximation. As our identified designs can be applied as simple architectural changes on top of an existing GNN, they usually maintain the same order of computational complexity as the base model. For example, adding the two designs to GCN <ref type="bibr" target="#b12">[13]</ref> results in an architecture similar to GraphSAGE <ref type="bibr" target="#b8">[9]</ref>; both have the same order of computational complexity as O(|V| + |E|) by leveraging the sparse connectivity of most real-world graphs. Low-rank approximation-based vaccination, on the other hand, approximates the adjacency matrix of a graph by an SVD, resulting in an adjusted low-rank adjacency matrix Ã based on which the GNN runs. However, not only is computing an SVD potentially costly (O(|V| 3 ) in general), but in most cases it also results in a dense Ã (in contrast to the sparse original adjacency matrix), thus increasing the complexity of each iteration of the GNN.</p><p>Table <ref type="table" target="#tab_4">4</ref> shows the empirical runtime of 200 training iterations of each model, where we observe that models vaccinated with heterophily-inspired designs have the least runtime among all vaccinated models. Even only considering methods based on the same implementation, H 2 GCN and GraphSAGE are still 3-4 times faster than the corresponding H 2 GCN-SVD and GraphSAGE-SVD methods. We report the detailed setup of this experiment in App. D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We formalized the connection between heterophily and adversarial attacks and showed theoretically and empirically that effective structural attacks on homophilous graphs gravitate towards increasing heterophily. Using these insights, we showed that heterophily-inspired designs can lead to competitive robustness improvement, with a small computational overhead and essentially no influence on clean performance. Finally, we compared these designs with state-of-the-art vaccination mechanisms under different attack scenarios for various datasets, and illustrated that they are complementary and that their combination can lead to more robust GNN models.</p><p>Limitations While the identified designs help boost robustness against structural perturbations, similar to state-of-the-art models like GNNGuard <ref type="bibr" target="#b36">[37]</ref> and ProGNN <ref type="bibr" target="#b11">[12]</ref>, they may remain vulnerable to other types of attacks such as feature perturbations. Moreover, while vaccinated models have in most cases comparable performance on clean datasets to the unvaccinated models, as our benchmark study ( §5.3) shows, unvaccinated models in average still perform better on clean datasets without perturbations. We attribute this to an inevitable trade-off between performance and robustness, which is also observed in computer vision applications <ref type="bibr" target="#b31">[32]</ref>.</p><p>Future Directions We note that MLP, which is graph-agnostic and thus immune to structural perturbations, outperforms all GNN models against NETTACK on Citeseer and Snap Patents (Table <ref type="table" target="#tab_2">3</ref>). This shows that designing effective vaccination strategies that work for a broad set of attack scenarios is challenging and still far from fully-understood. Further, in contrast to <ref type="bibr" target="#b40">[41]</ref>, we find that most models show better robustness against evasion attacks than against poison attacks. This calls for further work to examine the differences between robustness against poison and evasion attacks.</p><p>Societal Impact Robust methods are key for drawing reliable conclusions from graph-structured data, in particular if the obtained results are to be used for decision-making. We comment on the potential societal impact of our work in App. A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Societal Impacts</head><p>A large number of popular GNN models are inherently based on homophily. Our work shows that such models may be less robust to adversarial perturbations, and thus when employed for decisionmaking these models may lead to undesirable, erroneous or biased results. For example, an inherently homophilous GNN model may lead to the so-called "filter bubble" phenomenon in a recommendation system in which existing beliefs or preferences are reinforced. Similarly, as homophily-based GNNs typically average over node neighborhoods, this may result in less visibility of minority groups in the network, thus reinforcing disparities. Heterophilous network designs may improve some of these aspects, and also benefit from some additional robustness as shown in this work.</p><p>However, it should be noted that heterophilous GNNs on their own cannot fully solve the aforementioned issues. In particular, while heterophilous designs can improve robustness, they are not (in general) constructed to ensure other important aspects such as fairness. Better understanding of GNNs and tailored auditing tools are necessary in order to deploy these learning algorithms in the context of decision-making affecting humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Nomenclature</head><p>We summarize the main symbols used in this work and their definitions below: s (A, X) = Ā2 s XW on clean data and analytically derive the optimal weight matrix W * in a stylized learning setup; then, we construct a targeted evasion attack and calculate the attack loss for a unit structural perturbation; last, we summarize and validate the statements in the theorem.</p><p>Stylized learning on clean data Given the 2-layer linearized GNN f (2)   s (A, X) = Ā2 Without loss of generality, we reorder T V accordingly such that the one-hot encoding of labels for nodes in the training set [Y] T V ,: is in increasing order of the class label y v :</p><formula xml:id="formula_6">[Y] T V ,: =                         1 0 0 • • • 0 . . . . . . . . . . . . . . . 1 0 0 • • • 0 0 1 0 • • • 0 . . . . . . . . . . . . . . . 0 1 0 • • • 0 . . . . . . . . . . . . . . . 0 0 0 • • • 1 . . . . . . . . . . . . . . . 0 0 0 • • • 1                         |T V |×|Y|<label>(2)</label></formula><p>Now we look at the term</p><formula xml:id="formula_7">[ Ā2 s X] T V ,: in [z] T V ,: = [ Ā2 s X] T V ,:</formula><p>W, which are the feature vectors aggregated by the two GNN layers for nodes v in the training set T V . As stated in the theorem, we assume that the graph is d-regular (i.e., all nodes have degree d), proportion h of their neighbors belong to the same class, while proportion 1−h |Y|−1 of them belong to any other class uniformly, and for each node v ∈ V the node features are given as</p><formula xml:id="formula_8">x v = p • onehot(y v ) + 1−p |Y| • 1 for each node v ∈ V.</formula><p>Then, after the first layer, we have:</p><formula xml:id="formula_9">[ Ās X] T V ,: = 1 d + 1                            (hd + 1)p 1−h |Y|−1 dp 1−h |Y|−1 dp • • • 1−h |Y|−1 dp . . . . . . . . . . . . . . . (hd + 1)p 1−h |Y|−1 dp 1−h |Y|−1 dp • • • 1−h |Y|−1 dp 1−h |Y|−1 dp (hd + 1)p 1−h |Y|−1 dp • • • 1−h |Y|−1 dp . . . . . . . . . . . . . . . 1−h |Y|−1 dp (hd + 1)p 1−h |Y|−1 dp • • • 1−h |Y|−1 dp . . . . . . . . . . . . . . . 1−h |Y|−1 dp 1−h |Y|−1 dp 1−h |Y|−1 dp • • • (hd + 1)p . . . . . . . . . . . . . . . 1−h |Y|−1 dp 1−h |Y|−1 dp 1−h |Y|−1 dp • • • (hd + 1)p                            |T V |×|Y| + 1 − p |Y| (3)</formula><p>and after the second layer</p><formula xml:id="formula_10">[ Ā2 s X] T V ,: = 1 (d + 1) 2 |Y|(|Y| − 1)                          S 1 T 1 T 1 • • • T 1 . . . . . . . . . . . . . . . S 1 T 1 T 1 • • • T 1 T 1 S 1 T 1 • • • T 1 . . . . . . . . . . . . . . . T 1 S 1 T 1 • • • T 1 . . . . . . . . . . . . . . . T 1 T 1 T 1 • • • S 1 . . . . . . . . . . . . . . . T 1 T 1 T 1 • • • S 1                          |T V |×|Y| + 1 |Y| ,<label>(4)</label></formula><p>where S 1 = ((h|Y| − 1)d + |Y| − 1) 2 p, and</p><formula xml:id="formula_11">T 1 = ((h|Y|−1)d+|Y|−1) 2 p |Y|−1</formula><p>.</p><p>For [Y] T V ,: and [ Ā2 s X] T V ,: which we derived in Eq. ( <ref type="formula" target="#formula_6">2</ref>) and (4), we can find the optimal weight matrix</p><formula xml:id="formula_12">W * such that [ Ā2 s X] T V ,: W * = [Y] T V ,:</formula><p>, making the cross-entropy loss L([z] T V ,: , [Y] T V ,: ) = 0. To find W * , we can proceed as follows. First, sample one node from each class to form a smaller set T S ⊂ T V . Therefore, we have:</p><formula xml:id="formula_13">[Y] T S ,: =     1 0 0 • • • 0 0 1 0 • • • 0 . . . . . . . . . . . . . . . 0 0 0 • • • 1     |Y|×|Y| = I |Y|×|Y| and [ Ā2 s X] T S ,: = 1 (d + 1) 2 |Y|(|Y| − 1)     S 1 T 1 T 1 • • • T 1 T 1 S 1 T 1 • • • T 1 . . . . . . . . . . . . . . . T 1 T 1 T 1 • • • S 1     |Y|×|Y| + 1 |Y| .</formula><p>Note that [ Ā2 s X] T S ,: is a specific circulant matrix, and therefore its inverse exists. Using the Sherman-Morrison formula, we can find its inverse as:</p><formula xml:id="formula_14">[ Ā2 s X]T S ,: −1 = (d + 1) 2 (|Y| − 1) 2 p(−dh|Y| + d − (|Y| − 1)) 2 |Y| •     |Y| − 1 −1 • • • −1 −1 |Y| − 1 • • • −1 . . . . . . . . . . . . −1 −1 • • • |Y| − 1 + 1 |Y|     . Now, let W * = [ Ā2 s X] T S ,: −1 , then we have [z] T S ,: = [ Ā2 s X] T S ,: W * = [Y] T S ,: = I |Y|×|Y| . It is also easy to verify that [z] T V ,: = [ Ā2 s X] T V ,: W * = [Y] T V ,: . Since W * satisfies L([z] T V ,: , [Y] T V ,: ) = 0, we know W * = [ Ā2 s X] T S ,:</formula><p>−1 is the optimal weight matrix that we can learn under T V .</p><p>Attack loss under evasion attacks Now consider an arbitrary target node v ∈ V with class label y v ∈ Y, and a unit structural perturbation that would affect the predictions z v of node v made by GNN f</p><p>s . Without loss of generality, we assume node v has y v = 1. As f (2) s contains 2 GNN layers with each layer aggregating feature vectors within neighborhood N (v) of each node v, the perturbation must take place in the direct (1-hop) neighborhood N (v) or 2-hop neighborhood N 2 (v) to affect the predictions z v . For the unit perturbation, the attacker can add or remove a homophilous edge or path to node v, which we denote as δ 1 (δ 1 = 1 for addition and δ 1 = −1 for removal); alternatively, the attacker can add or remove a heterophilous edge or path to node v, which we denote as δ 2 = ±1 analogously. We denote the perturbed graph adjacency matrix as Ā s , and</p><formula xml:id="formula_16">z v = [ Ā 2 s X] v,: W * 1 Unit perturbation in direct neighborhood N (v).</formula><p>We first consider a unit perturbation in the direct (1-hop) neighborhood N (v) of node v. For simplicity of derivation, we assume that the perturbation does not change the row-stochastic normalization of Ās , and only affects the aggregated feature vectors of the target node v.</p><p>In the case of δ 1 = ±1 and δ 2 = 0, we have</p><formula xml:id="formula_17">[ Ā s X] v,: − [ Ās X] v,: = 1 d + 1 δ 1 1−p |Y| + p δ 1 1−p |Y| • • • δ 1 1−p |Y| and [ Ā 2 s X] v,: − [ Ā2 s X] v,: = 1 (d + 1) 2 |Y| S 2 T2 |Y|−1 • • • T2 |Y|−1 , where S 2 = δ 1 (dp(h|Y| − 1) + d + 2(|Y| − 1)p + 2) and T 2 = δ 1 (p(−|Y|(dh + 2) + d + 2) + (d + 2)(|Y| − 1)). By Multiplying [ Ā 2</formula><p>s X] v,: by W * , we can get the predictions z v after perturbations as</p><formula xml:id="formula_18">z v = [ Ā 2 s X] v,: W * = 1 (d + 1) 2 (d(h|Y| − 1) + |Y| − 1) 2 [ 1 + S 3 T 3 • • • T 3 ]<label>(5)</label></formula><p>with</p><formula xml:id="formula_19">S 3 = δ 1 (d 3 (h + |Y| − 2)(h|Y| − 1) + 2d 2 (h + |Y| − 2)(h|Y| + |Y| − 2) + d(|Y| − 1)((h + 4)|Y| + 3h − 8) + 2(|Y| − 1) 2 )</formula><p>and</p><formula xml:id="formula_20">T 3 = dδ 1 (h − 1)(d|Y|((d + 2)h + 2) − d(d + 4) + 3(|Y| − 1)).</formula><p>On the perturbed graph, the CM-type attack loss is calculated as</p><formula xml:id="formula_21">L CM atk (z v ) = −(z v,yv − max y =yv z v,y ) = −(1 + S 3 − T 3 ) (d + 1) 2 (d(h|Y| − 1) + |Y| − 1) 2 .</formula><p>Since on clean data, L CM atk (z v ) = −1, the change in attack loss before and after attack is</p><formula xml:id="formula_22">∆L CM atk = L CM atk (z v ) − L CM atk (z v ) = T 3 − S 3 (d + 1) 2 (d(h|Y| − 1) + |Y| − 1) 2 = − δ 1 (|Y| − 1)(dh|Y| − d + 2|Y| − 2) (d(h|Y| − 1) + |Y| − 1) 2 . (<label>6</label></formula><formula xml:id="formula_23">)</formula><p>Solving following system of inequalities for δ 1 ,</p><formula xml:id="formula_24">       ∆L CM atk &gt; 0 h ∈ [0, 1] |Y| ≥ 2 d, |Y| ∈ Z + (7)</formula><p>we get the valid range of δ 1 as</p><formula xml:id="formula_25">     δ 1 &lt; 0, when 0 ≤ h &lt; 1 |Y| and 0 &lt; d &lt; 2−2|Y| h|Y|−1 δ 1 &gt; 0, when 0 ≤ h &lt; 1 |Y| and d &gt; 2−2|Y| h|Y|−1 δ 1 &lt; 0, when 1 |Y| ≤ h ≤ 1 . (<label>8</label></formula><formula xml:id="formula_26">)</formula><p>We can similarly solve the valid range of δ 1 for increasing the CE-type attack loss, which is the same as the range for CM-type attack loss as Eq. (8).</p><p>In the case of δ 1 = 0 and δ 2 = ±1, we have</p><formula xml:id="formula_27">[ Ā s X] v,: − [ Ās X] v,: = 1 d + 1 δ 2 1−p |Y| + q δ 2 1−p |Y| + p • • • δ 2 1−p |Y| + p and [ Ā 2 s X] v,: − [ Ā2 s X] v,: = 1 (d + 1) 2 |Y| S4 |Y|−1 T 4 • • • T 4 , where S 4 = δ 2 (p(−|Y|(dh+2)+d+2)+(d+2)(|Y|−1)) and T 4 = δ 2 (dp(h|Y|−1)+d+2(|Y|− 1)p + 2). By multiplying [ Ā 2</formula><p>s X] v,: with W * , we can get the predictions z v after the perturbations. Following a similar derivation to that in the previous case, we can compute the change in the CM-type attack loss before and after attack as</p><formula xml:id="formula_28">∆L CM atk = δ 2 (|Y| − 1)(dh|Y| − d + 2|Y| − 2) (d(h|Y| − 1) + |Y| − 1) 2 . (<label>9</label></formula><formula xml:id="formula_29">)</formula><p>Solving the same system of inequalities as Eq. ( <ref type="formula">7</ref>) for δ 2 , we obtain the valid range of δ 2 as</p><formula xml:id="formula_30">     δ 2 &gt; 0, when 0 ≤ h &lt; 1 |Y| and 0 &lt; d &lt; 2−2|Y| h|Y|−1 δ 2 &lt; 0, when 0 ≤ h &lt; 1 |Y| and d &gt; 2−2|Y| h|Y|−1 δ 2 &gt; 0, when 1 |Y| ≤ h ≤ 1 . (<label>10</label></formula><formula xml:id="formula_31">)</formula><p>We can similarly solve the valid range of δ 2 for increasing the CE-type attack loss, which is the same as the range for CM-type attack loss as Eq. (10).</p><p>2 Unit perturbation in 2-hop neighborhood N 2 (v). We now consider a unit perturbation in the 2-hop neighborhood N (v) of node v. In this case we will have [ Ā s X] v,: = [ Ās X] v,: . In the case of δ 1 = ±1 and δ 2 = 0, we have</p><formula xml:id="formula_32">[ Ā 2 s X] v,: − [ Ā2 s X] v,: = 1 (d + 1) 2 |Y| S 5 T5 |Y|−1 • • • T5 |Y|−1 , where S 5 = (((h|Y| − 1)d + |Y| − 1)p + d + 1)δ 1 and T 5 = ((−h|Y|p + |Y| + p − 1)d − |Y|p + |Y| + p − 1)δ 1 . By multiplying [ Ā 2 s X] v,:</formula><p>with W * , we can get the predictions z v after perturbations. Following a similar derivation as before, we can get the change in the CM-type attack loss before and after attack as</p><formula xml:id="formula_33">∆L CM atk = − δ 1 (|Y| − 1) (h|Y| − 1)d + |Y| − 1 . (<label>11</label></formula><formula xml:id="formula_34">)</formula><p>Solving the same system of inequalities as Eq. (7) for δ 1 , we get the valid range of δ 1 as</p><formula xml:id="formula_35">     δ 1 &lt; 0, when 0 ≤ h &lt; 1 |Y| and 0 &lt; d &lt; 1−|Y| h|Y|−1 δ 1 &gt; 0, when 0 ≤ h &lt; 1 |Y| and d &gt; 1−|Y| h|Y|−1 δ 1 &lt; 0, when 1 |Y| ≤ h ≤ 1 . (<label>12</label></formula><formula xml:id="formula_36">)</formula><p>We can similarly solve the valid range of δ 1 for increasing the CE-type attack loss, which is the same as the range for CM-type attack loss as Eq. <ref type="bibr" target="#b11">(12)</ref>.</p><p>For the case δ 1 = 0 and δ 2 = ±1, we have</p><formula xml:id="formula_37">[ Ā 2 s X] v,: − [ Ā2 s X] v,: = 1 (d + 1) 2 |Y| S6 |Y|−1 T 6 • • • T 6 where S 6 = δ 2 (d(−h|Y|p + |Y| + p − 1) − |Y|p + |Y| + p − 1) and T 6 = δ 2 (p(d(h|Y| − 1) + |Y| − 1) + d + 1). Multiplying [ Ā 2 s X] v,:</formula><p>with W * , we can get the predictions z v after perturbations. As before we can compute the change in the CM-type attack loss before and after attack as</p><formula xml:id="formula_38">∆L CM atk = δ 2 (|Y| − 1) d(h|Y| − 1) + |Y| − 1<label>(13)</label></formula><p>Finally, solving the same system of inequalities as Eq. (7) for δ 2 , we get the valid range of δ 2 as</p><formula xml:id="formula_39">     δ 2 &gt; 0, when 0 ≤ h &lt; 1 |Y| and 0 &lt; d &lt; 1−|Y| h|Y|−1 δ 2 &lt; 0, when 0 ≤ h &lt; 1 |Y| and d &gt; 1−|Y| h|Y|−1 δ 2 &gt; 0, when 1 |Y| ≤ h ≤ 1<label>(14)</label></formula><p>We can similarly solve the valid range of δ 2 for increasing the CE-type attack loss, which is the same as the range for CM-type attack loss as Eq. ( <ref type="formula" target="#formula_39">14</ref>).</p><p>Summary and validation of theorem statements Based on our derivations, we summarize and validate our statements in the theorem next.</p><p>1 The attack losses L atk (both CE-and CM-type, §2) increase only by removing a homophilous edge or path, or adding a heterophilous edge or path to node v. From Eq. ( <ref type="formula" target="#formula_25">8</ref>), ( <ref type="formula" target="#formula_30">10</ref>), ( <ref type="formula" target="#formula_35">12</ref>), ( <ref type="formula" target="#formula_39">14</ref>), we observe that for both direct attacks in 1-hop neighborhood N (v) and indirect attacks in 2-hop neighborhood N 2 (v), when h ≥ 1 |Y| , the attack loss increases only if δ 1 &lt; 0, which represents removal of a homophilous edge or path to node v, or if δ 2 &gt; 0, which represents addition of a heterophilous edge or path to node v.</p><p>2 Direct perturbations on edges (or 1-hop paths) of the target node v lead to greater increase in L atk than indirect perturbations on multi-hop paths to target node v.</p><p>From Eq. (6) and Eq. ( <ref type="formula" target="#formula_28">9</ref>), the change in the CM-type attack loss ∆L CM atk (z v ) for direct perturbations on 1-hop neighborhood N (v) of the target node v considering both δ 1 and δ 2 can be written as</p><formula xml:id="formula_40">∆L CM,direct atk = − δ 1 (|Y| − 1)(dh|Y| − d + 2|Y| − 2) (d(h|Y| − 1) + |Y| − 1) 2 + δ 2 (|Y| − 1)(dh|Y| − d + 2|Y| − 2) (d(h|Y| − 1) + |Y| − 1) 2<label>(15)</label></formula><p>From Eq. (11) and Eq. ( <ref type="formula" target="#formula_38">13</ref>), the change in the CM-type attack loss ∆L CM atk (z v ) for indirect perturbations on 2-hop neighborhood N 2 (v) of the target node v considering both δ 1 and δ 2 is</p><formula xml:id="formula_41">∆L CM,indirect atk = − δ 1 (|Y| − 1) (h|Y| − 1)d + |Y| − 1 + δ 2 (|Y| − 1) d(h|Y| − 1) + |Y| − 1<label>(16)</label></formula><p>Note that when h &gt; 1 |Y| , we have dh|Y|</p><formula xml:id="formula_42">− d + 2|Y| − 2 d(h|Y| − 1) + |Y| − 1 = 1 + |Y| − 1 d(h|Y| − 1) + |Y| − 1 &gt; 1<label>(17)</label></formula><p>Therefore we will always have ∆L CM,direct atk &gt; ∆L CM,indirect atk for an effective unit perturbation that increases attack loss L CM atk (i.e., δ 1 = −1 and δ 2 = 0, or δ 1 = 0 and δ 2 = 1) when h &gt; 1 |Y| .</p><p>More discussion on empirical observations In Table <ref type="table" target="#tab_0">1</ref>, for the heterophilous Snap Patents dataset, we observe an increase in the average homophily ratio in the 1-hop neighborhoods of the target nodes h t after NETTACK Ṫhis phenomenon can also be explained from the results derived in Proof 1: from Eq. ( <ref type="formula" target="#formula_25">8</ref>), ( <ref type="formula" target="#formula_30">10</ref>), ( <ref type="formula" target="#formula_35">12</ref>), ( <ref type="formula" target="#formula_39">14</ref>), we can see that while effective structural attacks always result in a reduced level of homophily for graphs displaying homophilous tendency (i.e., h &gt; 1 |Y| ), the effective attacks for graphs displaying heterophilous tendency (i.e., h &lt; 1 |Y| ) are dependent on the node degrees d. For high-degree nodes, the effective structural attacks will instead always result in an increased level of homophily (or reduced level of heterophily); for low-degree nodes, the effective attacks still result in a reduced level of homophily. These theoretical takeaways help explain the increase in h t after attacks in Snap Patents: as this dataset displays a heterophilous tendency with h &lt; 1  |Y| , the attacks can result in increased level of homophily for target high-degree nodes in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Detailed Analysis of Theorem 2</head><p>Proof 2 (for Theorem 2) In this proof, we mainly focus on analyzing the increase in L atk for the GNN layer defined as f (A, X; α) = (1 − α) Ā + αI XW. We follow a similar process as in Proof 1, since the layer defined as f s (A, X) = Ās XW is a special case of the previous formulation when α = 1 1+d .</p><p>Layer f (A, X; α) = (1 − α) Ā + αI XW We first derive the optimal weight matrix W * in a stylized learning setup as in Proof 1. Following a similar process, for this GNN layer we have , and</p><formula xml:id="formula_43">(1 − α) Ā + αI X T S ,: = 1 − p |Y| +     S 7 T 7 T 7 • • • T 7 T 7 S 7 T 7</formula><formula xml:id="formula_44">[Y] T S ,: =     1 0 0 • • • 0 0 1 0 • • • 0 . . . . . . . . . . . . . . . 0 0 0 • • • 1     |Y|×|Y| = I |Y|×|Y|</formula><p>Using the Sherman-Morrison formula, we find its inverse:</p><p>(1 − α) Ā + αI X T S ,:</p><formula xml:id="formula_45">−1 = |Y| − 1 p(a(h − 1)|Y| − h|Y| + 1)|Y| •     1 − |Y| 1 1 • • • 1 1 1 − |Y| 1 • • • 1 . . . . . . . . . . . . . . . 1 1 1 • • • 1 − |Y|     + 1 |Y| Assuming W * = (1 − α) Ā + αI X T S ,:<label>−1</label></formula><p>, we obtain</p><formula xml:id="formula_46">[z] T S ,: = (1 − α) Ā + αI X T S ,: W * = [Y] T S ,: = I |Y|×|Y| . Since W * satisfies L([z] T V ,: , [Y] T V ,:</formula><p>) = 0, we know W * is the optimal weight matrix that we can learn under T V .</p><p>Now consider an arbitrary target node v ∈ V with class label y v ∈ Y, and a unit structural perturbation that affects the predictions z v of node v made by the GNN layer f (A, X; α) = (1 − α) Ā + αI XW. Without loss of generality, we assume node v has y v = 1. Note that we will only discuss the case of direct structural perturbation to the 1-hop neighborhood N (v) of target node v, as indirect perturbations do not affect the predictions z v for node v produced by a single GNN layer. Denote ∆ Ā = Ā − Ā as the change in the adjacency matrix Ā before and after the attack. Similar to Proof 1, for simplicity of derivation, we assume that the perturbation does not change the row-stochastic normalization of Ā, and we use δ 1 to denote addition (δ 1 = 1) or removal (δ 1 = −1) of a homophilous edge to node v, and use δ 2 to denote addition or removal of a heterophilous edge to node v.</p><p>In the case of δ 1 = ±1 and δ 2 = 0, we have</p><formula xml:id="formula_47">(1 − α)∆ Ā + αI X v,: = (1 − α)δ 1 d|Y| [ ((|Y| − 1)p + 1) (1 − p) • • • (1 − p) ]</formula><p>and the change in the CM-type attack loss L CM atk before and after the perturbation can be derived as</p><formula xml:id="formula_48">∆L CM atk = ((1 − α)|Y| + α − 1)δ 1 d(α(h − 1) − h)|Y| + d .<label>(18)</label></formula><p>In the case of δ 1 = 0 and δ 2 = ±1, we have</p><formula xml:id="formula_49">(1 − α)∆ Ā + αI X v,: = (1 − α)δ 2 d|Y| [ (1 − p) (|Y| − 1)p + 1 • • • (|Y| − 1)p + 1 ]</formula><p>and the change in the CM-type attack loss L CM atk before and after the perturbation can be derived as</p><formula xml:id="formula_50">∆L CM atk = (α − 1)(|Y| − 1)δ 2 d(α(h − 1) − h)|Y| + d . (<label>19</label></formula><formula xml:id="formula_51">)</formula><p>From Eq. (18) and Eq. <ref type="bibr" target="#b18">(19)</ref>, the change in the CM-type attack loss ∆L CM atk for GNN layer f (A, X; α) considering both δ 1 and δ 2 can be written as</p><formula xml:id="formula_52">∆L CM,f atk = ((1 − α)|Y| + α − 1)δ 1 d(α(h − 1) − h)|Y| + d + (α − 1)(|Y| − 1)δ 2 d(α(h − 1) − h)|Y| + d . (<label>20</label></formula><formula xml:id="formula_53">)</formula><p>Layer f s (A, X) = Ās XW This formulation is a special case of the previously discussed f (A, X; α) formulation when α = 1 1+d . In the case of δ 1 = ±1 and δ 2 = 0, from Eq. (18), we have the change in the CM-type attack loss L CM atk before and after the perturbation as</p><formula xml:id="formula_54">∆L CM atk = − (|Y| − 1)δ 1 d(h|Y| − 1) + |Y| − 1 . (<label>21</label></formula><formula xml:id="formula_55">)</formula><p>In the case of δ 1 = 0 and δ 2 = ±1, from Eq. ( <ref type="formula" target="#formula_50">19</ref>), we have the change in the CM-type attack loss L CM atk before and after the perturbation as</p><formula xml:id="formula_56">∆L CM atk = (|Y| − 1)δ 2 d(h|Y| − 1) + |Y| − 1 . (<label>22</label></formula><formula xml:id="formula_57">)</formula><p>From Eq. (21) and Eq. ( <ref type="formula" target="#formula_56">22</ref>), the change in the CM-type attack loss ∆L CM atk for GNN layer f s (A, X) considering both δ 1 and δ 2 can be written as</p><formula xml:id="formula_58">∆L CM,fs atk = − (|Y| − 1)δ 1 d(h|Y| − 1) + |Y| − 1 + (|Y| − 1)δ 2 d(h|Y| − 1) + |Y| − 1<label>(23)</label></formula><p>Comparison of increase in attack loss ∆L CM atk Solving the following system of inequalities for variable α</p><formula xml:id="formula_59">             ∆L CM,fs atk &gt; ∆L CM,f atk &gt; 0 α, h ∈ [0, 1] |Y| ≥ 2 d, |Y| ∈ Z + δ 1 , δ 2 ∈ {−1, 0, 1}<label>(24)</label></formula><p>we get the valid range of α as</p><formula xml:id="formula_60">     1 d+1 &lt; α &lt; 1, when 0 ≤ h &lt; 1 |Y| and 0 &lt; d &lt; 1−|Y| h|Y|−1 and δ 1 &lt; δ 2 0 ≤ α &lt; 1 d+1 , when 0 ≤ h &lt; 1 |Y| and d &gt; 1−|Y| h|Y|−1 and δ 1 &gt; δ 2 1 d+1 &lt; α &lt; 1, when 1 |Y| ≤ h ≤ 1 and δ 1 &lt; δ 2 . (<label>25</label></formula><formula xml:id="formula_61">)</formula><p>From the solution in Eq. (25), we observe that when h &gt; 1 |Y| , a unit perturbation increasing L atk as discussed in Theorem 1 (i.e. δ 1 = −1 and δ 2 = 0, or δ 1 = 0 and δ 2 = 1) will satisfy the condition δ 1 &lt; δ 2 , and thus lead to a strictly smaller increase ∆L CM,f atk in the attack loss for layer f (A, X; α) than the increase ∆L CM,fs atk for layer f s (A, X) if α &gt; 1 d+1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Detailed Analysis of Theorem 3</head><p>Proof 3 (for Theorem 3) We discuss separately the cases where the unit perturbation occurs in the direct (1-hop) neighborhood N (v), and in the 2-hop neighborhood N 2 (v) of the target node v, as unit perturbation that occurs beyond the 2-hop neighborhood N 2 (v) of the target node v will not be an effective attack to the target node v for both GNN formulations.</p><p>Unit perturbation in direct neighborhood N (v) The amount of increase in CM-type attack loss ∆L CM atk for the 2-layer GNN f</p><formula xml:id="formula_62">(2) s (A, X) = Ā2 s XW is given in Eq. (15) in Proof 1 as ∆L CM,f<label>(2)</label></formula><formula xml:id="formula_63">s atk = − δ 1 (|Y| − 1)(dh|Y| − d + 2|Y| − 2) (d(h|Y| − 1) + |Y| − 1) 2 + δ 2 (|Y| − 1)(dh|Y| − d + 2|Y| − 2) (d(h|Y| − 1) + |Y| − 1) 2<label>(26)</label></formula><p>This term is denoted as ∆L CM,direct atk in Eq. <ref type="bibr" target="#b14">(15)</ref>.</p><p>The amount of increase in CM-type attack loss ∆L CM atk for the single-layer GNN f s (A, X) = Ās XW is given in Eq. (23) in Proof 2 as</p><formula xml:id="formula_64">∆L CM,fs atk = − (|Y| − 1)δ 1 d(h|Y| − 1) + |Y| − 1 + (|Y| − 1)δ 2 d(h|Y| − 1) + |Y| − 1<label>(27)</label></formula><p>Table <ref type="table">D</ref>.1 shows that the differences in accuracy between the two variants are in most cases less than 2%, while in many cases variant (II) shows better accuracy compared to variant (I), especially in experiments against Metattack. Thus, we use variant (II) as the default implementation for the empirical evaluations in §5.</p><p>For GCN-SVD, the ambiguity comes from the order of applying the preprocessing and low-rank approximation for the adjacency matrix A, which is not discussed in the original paper <ref type="bibr" target="#b6">[7]</ref>.</p><p>• Variant (I): Since the original authors' implementation is not publicly available, we consider the implementation provided in DeepRobust <ref type="bibr" target="#b18">[19]</ref> as variant (I): it first calculates the rank-k approximation Ã of A, and then generates the preprocessed adjacency matrix Âs</p><formula xml:id="formula_65">= D−1/2 s ( Ã + I) D−1/2 s = D−1/2 s Ãs D−1/2 s</formula><p>, which is then processed by a GCN <ref type="bibr" target="#b12">[13]</ref>. However, as the identity matrix I is added into Ã after the low-rank approximation, the diagonal elements of the resulting Âs matrix (i.e., the weights for the self-loop edges in the graph) can become significantly larger than the off-diagonal elements, especially when the rank k is low. As a result, this order of applying the preprocessing and low-rank approximation inadvertently adopts Design 1 which we identified; we have shown in Theorem 2 that even merely increasing the weights α for the ego-embedding in the linear combination ENC in Eq. ( <ref type="formula" target="#formula_4">1</ref>) can lead to reduced attack loss L atk under structural perturbations.</p><p>• Variant (II): In variant (II), we consider the opposite order where we first add the identity matrix I (self-loops) into the original adjacency matrix A, then we perform the low-rank approximation, and finally we symmetrically normalize the low-rank matrix Ãs to generate the preprocessed Âs used by a GCN model. This order allows the diagonal elements to be more on par in magnitude with the off-diagonal elements. As an example, on Citeseer, when using variant (I) with rank k = 5, the average magnitude of the diagonal elements of the resulting Âs can be 22.3 times the average magnitude of the off-diagonal elements; when using variant (II) instead, the average magnitude of the diagonal elements is only 9.0 times that of the off-diagonal elements.</p><p>In Table <ref type="table">D</ref>.1, we report the performance of the two variants of GCN-SVD under the experimental settings considered in §5 with rank k ∈ {5, 10, 15, 50}: Variant (I), with our first design implicitly built-in, has in most cases significantly higher performance than variant (II), especially on homophilous datasets and when rank k is low. These results further demonstrate the effectiveness of Design 1 that we identified. To enable a clear perspective of the performance and robustness improvement brought by Design 1, in our empirical analysis in §5, on top of the low-rank approximation vaccination we adopt variant (II) as the default implementation.</p><p>Attack Implementations We incorporate the following implementations of attacks from DeepRobust <ref type="bibr" target="#b18">[19]</ref> to our empirical framework. More Details on the Attack Setup For NETTACK, we randomly select 60 nodes from the graph as the target nodes for each set of perturbations, instead of the GCN-based target selection approach as in <ref type="bibr" target="#b40">[41]</ref>: the approach in <ref type="bibr" target="#b40">[41]</ref> only selects nodes that are correctly classified by GCN <ref type="bibr" target="#b12">[13]</ref> on clean data, thus introducing unfair advantages towards GCN, especially on heterophilous datasets where GCN can exhibit significantly inferior accuracy to models like GraphSAGE <ref type="bibr" target="#b39">[40]</ref>. We use an attack budget equal to its node degree and allow direct attacks on target nodes. For Metattack, we budget the attack as 20% of the number of edges in each dataset, and we use the Meta-Self variant as it shows the most destructiveness <ref type="bibr" target="#b41">[42]</ref>.</p><p>Hardware Specifications For fair runtime measurements, we measure the runtime of each model on an Amazon EC2 instance with instance type as p3.2xlarge, which features an 8-core CPU, 61 GB Memory, and a Tesla V100 GPU with 16 GB GPU Memory. For the remaining experiments, we use a workstation with a 12-core AMD Ryzen 9 3900X CPU, 64GB RAM, and a Quadro P6000 GPU with 24 GB GPU Memory. • Heterophilous Datasets: FB100 <ref type="bibr" target="#b30">[31]</ref> is a set of 100 Facebook university friendship network snapshots from 2005 <ref type="bibr" target="#b19">[20]</ref>, from which we use one network. Each node is labeled with the reported gender, and the features encode education and accommodation. Data are sent to the original authors <ref type="bibr" target="#b19">[20]</ref> in an anonymized form. Though the dataset contains limited demographic (categorical) information volunteered by users on their individual Facebook pages, we manually inspect the dataset and confirm that the anonymized dataset is not recoverable and thus not identifiable. Also, no offensive content is found within the data. Snap Patents <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> is a utility patent citation network. Node labels reflect the time the patent was granted, and the features are derived from the patent's metadata. The dataset is maintained by the National Bureau of Economic Research, and is freely available for download <ref type="foot" target="#foot_1">3</ref> . Neither personally identifiable information nor offensive content is identified when we manually inspect the dataset. • Homophilous Datasets: Cora <ref type="bibr" target="#b22">[23]</ref> and Citeseer <ref type="bibr" target="#b26">[27]</ref> datasets are scientific publication citation networks, whose labels categorize the research field, and features indicate the absence or presence of the corresponding word from the dictionary. No personally identifiable information or offensive content is identified when we manually inspect both datasets.</p><p>Downsampling For better computational tractability, we sample a subset of the Snap Patents data using a snowball sampling approach <ref type="bibr" target="#b7">[8]</ref>, where a random 20% of the neighbors for each traversed node are kept. We provide the pseudocode for the downsampling process in Algorithm 1.</p><p>Algorithm </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>s</head><label></label><figDesc>XW and the training set T V , the goal of the training process is to optimize the weight matrix W to minimize the cross-entropy loss function L([z] T V ,: , [Y] T V ,: ), where predictions [z] T V ,: = [ Ā2 s X] T V ,: W correspond to the predicted class label distributions for each node v in the training set T V , and [Y] T V ,: is the one-hot encoding of class labels provided in the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>• H 2 GCN• H 2 - 1 -innter_steps: 2 •</head><label>2212</label><figDesc>GCN no-ego Initialization Parameters: -network_setup: M64-R-T1-G-V-T2-G-V-C2-D0.5-MO Training Parameters: -early_stopping: Yes -train_iters: 200 patience: 100 lr: 0.01 • GraphSAGE-1 Initialization Parameters: -adj_nhood: ['1'] -network_setup: I-T1-G-V-C1-MO-R -adj_norm_type: rw Training Parameters: -early_stopping: Yes -train_iters: 200 patience: 100 lr: 0.01 • GraphSAGE Initialization Parameters: -adj_nhood: ['1'] -network_setup: I-T1-G-V-C1-M64-R-T2-G-V-C2-MO-R -adj_norm_type: rw Training Parameters: -early_stopping: Yes -train_iters: 200 patience: 100 lr: 0.01 • CPGNN-1 Initialization Parameters: -network_setup: GGM64-VS-R-G-GMO-VS-E-BP1 Training Parameters: -early_stopping: Yes -train_iters: 400 patience: 100 lr: nhid: 64 dropout: 0.5 -base_model: GCN for variant (I); GCN-fixed for variant (II) (default). epochs: 400 lr: 0.01 -lr_adj: 0.01 -weight_decay: 5e-4 alpha: 5e-4 beta: 1.5 gamma: 1 -lambda_: 0 phi: 0 -outer_steps: GCN-SVD Initialization Parameters: nhid: 64 k: best k chosen from {5, 10, 15, 50} for each dataset dropout: 0.5 -svd_solver: eye-svd (for variant (II) only) Training Parameters: -train_iters: 200 -weight_decay: 5e-4 lr:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Change in homophily ratio h before and after NETTACK on perturbed graphs, and change in the average homophily ratio within the 1-hop neighborhood of the target nodes, h t .</figDesc><table><row><cell>Dataset</cell><cell>#Classes |Y|</cell><cell>Graph h Before After</cell><cell>Target Node h t Before After</cell></row><row><cell>Cora</cell><cell>7</cell><cell>0.8041 0.8035</cell><cell>0.8286 0.4092</cell></row><row><cell>Citeseer</cell><cell>6</cell><cell>0.7364 0.7357</cell><cell>0.6616 0.3286</cell></row><row><cell>FB100</cell><cell>2</cell><cell>0.5306 0.5304</cell><cell>0.5391 0.4103</cell></row><row><cell>Snap</cell><cell>5</cell><cell>0.1340 0.1340</cell><cell>0.1292 0.1648</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of datasets (top) and ablation study for designs: mean accuracy ± stdev over multiple sets of experiments against poison attacks by NETTACK. For each design, the best method is highlighted in blue per dataset.</figDesc><table><row><cell>We provide a more compre-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>hensive benchmark study</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>involving more models at-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>tacked by both NETTACK</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>and Metattack in  §5.3. We</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>report detailed hyperparam-</cell><cell></cell><cell></cell><cell cols="2">Homophilous graphs</cell><cell cols="2">Heterophilous graphs</cell></row><row><cell>eters used for each method in App. D.3.</cell><cell></cell><cell>#Nodes |V| #Edges |E|</cell><cell>Cora 2,485 5,069</cell><cell>Citeseer 2,110 3,668</cell><cell>FB100 2,032 78,733</cell><cell>Snap 4,562 12,103</cell></row><row><cell></cell><cell></cell><cell>#Classes |Y|</cell><cell>7</cell><cell>6</cell><cell>2</cell><cell>5</cell></row><row><cell>Design 1: Separate Ag-gregators for Ego-and Neighbor-embeddings We compare methods with separate aggregators for ego-and neighbor-</cell><cell>DESIGN 1</cell><cell>#Features F Homophily h H2GCN GraphSAGE GCN GAT H2GCNno-ego</cell><cell>1,433 0.804 38.89±5.50 36.67±2.72 1.67±0.00 13.89±0.79 22.22±0.79</cell><cell>3,703 0.736 27.22±1.57 31.67±10.89 4.44±2.83 8.89±3.42 10.00±2.36</cell><cell>1,193 0.531 27.78±3.42 33.89±3.42 0.56±0.79 0.56±0.79 0.00±0.00</cell><cell>269 0.134 12.78±2.83 16.67±7.07 2.22±2.08 3.89±4.37 3.89±5.50</cell></row><row><cell>embeddings, H 2 GCN and GraphSAGE, with two methods that lack this design: GCN and GAT. We also consider a variant of</cell><cell>DESIGN 2</cell><cell>H2GCN-1 GraphSAGE-1 GCN-1 H2GCN GraphSAGE GCN</cell><cell>46.11±4.16 43.33±6.24 5.00±2.72 38.89±5.50 36.67±2.72 1.67±0.00</cell><cell>51.11±9.26 40.00±9.53 12.78±2.08 27.22±1.57 31.67±10.89 4.44±2.83</cell><cell>31.67±6.24 45.56±6.14 0.56±0.79 27.78±3.42 33.89±3.42 0.56±0.79</cell><cell>17.22±2.83 22.78±2.08 1.67±1.36 12.78±2.83 16.67±7.07 2.22±2.08</cell></row><row><cell>H</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>2 GCN, H 2 GCN no-ego , in which we drop the aggregator for ego-embedding. The first part of Table</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc></figDesc><table /><note>shows the performance of each method under poison (pretraining) attacks, and Fig.1visualizes the performance per method on clean datasets and against poison attacks by NETTACK. For conciseness, we report detailed results under evasion (post-training) attacks and on clean (unperturbed) data in TableE.1 for NETTACK and Table E.2 for Metattack. Targeted attacks by NETTACK: 1 Poison attacks. Under targeted poison attacks by NETTACK, Table</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Benchmark study: mean accuracy ± stdev against poison attacks. Accuracy is reported on target nodes for NETTACK, and on full test splits for Metattack. Best GNN model is highlighted in blue per dataset, and in gray per model group. MLP is immune to structural attacks and not considered as a GNN model. Detailed results are listed in Tables E.1 and E.2 and the setup in §5.1. (details in App. D.2), outperform the best-performing state-of-the-art methods across all datasets by up to 13.34% in homophilous settings and 18.33% in heterophilous settings.</figDesc><table><row><cell>Hetero.</cell><cell>Vaccin.</cell><cell cols="2">Homophilous graphs Cora Citeseer h=0.804 h=0.736</cell><cell cols="2">Heterophilous graphs FB100 Snap h=0.531 h=0.134</cell><cell></cell><cell>Homophilous graphs Cora Citeseer h=0.804 h=0.736</cell><cell>Heterophilous graphs FB100 Snap h=0.531 h=0.134</cell></row><row><cell>H2GCN-SVD</cell><cell></cell><cell>70.00±2.72</cell><cell>65.00±3.60</cell><cell cols="2">59.44±3.42 26.11±1.57</cell><cell></cell><cell>67.87±0.47 70.42±0.46</cell><cell>56.72±0.08 25.60±0.14</cell></row><row><cell>GraphSAGE-SVD</cell><cell></cell><cell>71.67±2.36</cell><cell>67.78±3.42</cell><cell cols="2">60.00±1.36 26.67±6.80</cell><cell></cell><cell>68.86±1.32 69.10±0.52</cell><cell>55.76±0.33 26.58±0.30</cell></row><row><cell>H2GCN GraphSAGE CPGNN GNNGuard ProGNN</cell><cell>NETTACK</cell><cell cols="2">38.89±5.50 36.67±2.72 31.67±10.89 27.22±1.57 41.11±9.06 24.44±4.37 58.33±1.36 59.44±3.14 48.89±7.97 32.78±7.49</cell><cell cols="2">27.78±3.42 12.78±2.83 33.89±3.42 16.67±7.07 41.67±3.60 20.00±0.00 0.56±0.79 9.44±1.57 33.89±4.78 17.78±9.26</cell><cell>Metattack</cell><cell>57.75±6.61 54.34±0.82 54.68±2.56 59.74±1.74 45.51±4.57 54.96±0.87 74.20±0.55 68.13±0.74 45.10±6.20 46.58±1.02</cell><cell>54.84±0.76 25.34±0.59 54.72±0.83 24.14±0.76 60.97±2.86 24.81±1.37 60.89±0.48 23.78±0.67 53.40±1.19 24.80±1.09</cell></row><row><cell>GCN-SVD</cell><cell></cell><cell>53.33±4.91</cell><cell>28.89±2.08</cell><cell cols="2">41.67±2.36 25.00±5.44</cell><cell></cell><cell>47.82±7.59 51.20±1.78</cell><cell>55.00±2.06 25.25±0.91</cell></row><row><cell>GAT</cell><cell></cell><cell>13.89±0.79</cell><cell>8.89±3.42</cell><cell>0.56±0.79</cell><cell>3.89±4.37</cell><cell></cell><cell>41.70±3.60 48.40±2.17</cell><cell>50.37±0.66 25.00±0.73</cell></row><row><cell>GCN</cell><cell></cell><cell>1.67±0.00</cell><cell>4.44±2.83</cell><cell>0.56±0.79</cell><cell>2.22±2.08</cell><cell></cell><cell>37.46±3.35 45.81±2.99</cell><cell>51.82±1.41 25.03±0.68</cell></row><row><cell>MLP*</cell><cell></cell><cell>64.44±3.42</cell><cell>70.56±3.42</cell><cell cols="2">57.78±2.83 30.00±2.72</cell><cell></cell><cell>64.55±1.58 67.67±0.11</cell><cell>56.56±0.58 26.25±1.05</cell></row><row><cell cols="8">3RLVRQ$FFXUDF\ SVD [7] &amp;OHDQ$FFXUDF\ &amp;LWHVHHUh = 0.736 *11*XDUG 3UR*11 +2*&amp;169' *UDSK6$*(69'</cell><cell>*&amp;169' +2*&amp;1</cell><cell>&amp;OHDQ$FFXUDF\ )%h = 0.531 *$7 *&amp;1 *UDSK6$*( &amp;3*11 0/3</cell></row></table><note>Figure 1: (Best viewed in color.) Classification accuracy on clean data and against poison attacks for target nodes attacked by NETTACK. Error bars show standard deviation across different sets of experiments. Detailed results are listed in Table E.1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Runtime (in seconds) of 200 training iterations on Cora. See App. D for detailed setup, including the implementation used for each method.GCN GAT GNNGuard ProGNN GCN-SVD H 2 GCN GraphSAGE CPGNN H 2 GCN-SVD GraphSAGE-SVD</figDesc><table><row><cell>2.17</cell><cell>2.98</cell><cell>39.63</cell><cell>220.30</cell><cell>134.81</cell><cell>16.54</cell><cell>17.24</cell><cell>36.37</cell><cell>62.33</cell><cell>55.45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table B .</head><label>B</label><figDesc>We give the proof in three parts: first, we analyze the training process of the GNN f</figDesc><table><row><cell>s A s low-rank approximation of the adjacency matrix A learnable weight matrix for GNN models F -dimensional feature vector for node v direct (1-hop) neighbors of node v in G without self-loops (i.e., excluding v) set of class labels class label for node v ∈ V |V|-dimensional vector of class labels (for all the nodes) T V = {(v 1 , y 1 ), (v 2 , y 2 ), ...} training data for semi-supervised node classification Ã W x v N (v) Y y v y G = (V, E , X) graph G with modified edgeset E f a certain GNN model that processes G K the number of layers of GNN f r (k) v node representations learned by GNN f at round / layer k AGGR function that aggregates node feature representations within a neighborhood ENC learnable (nonlinear) mapping that generates latent representation z v label prediction by GNN f for node v ∈ V, z v ∈ [0, 1] |Y| L atk attack loss that quantifies the mismatch between z and the true labels y L CE atk attack loss defined with cross-entropy loss L CE atk = H (z v , y v ) = − log z v,yv L CM atk attack loss defined with negative classification margin L CM atk = −∆ c = −(z v,yv − max y =yv z v,y ) d the degree of each node in a regular graph p parameter regulating the signal strength of one-hot class label vs. uniform noise α a predefined weight scalar in Theorem 2, α ∈ [0, 1] h edge homophily ratio, h = |{(u, v) ∈ E|y (2)</cell></row></table><note>1: Major symbols and definitions.SymbolsDefinitionsG = (V, E, X) graph G with nodeset V, edgeset E, and |V| × F node feature matrix X X |V| × F node feature matrix of G, X ∈ R |V|×F A |V| × |V| adjacency matrix of G, A ∈ {0,1} |V|×|V| A s adjacency matrix with self-loops added, A s = A + I D diagonal matrix of degrees, with D ii = j A ij Ā row-stochastic matrix for A, Ā = D −1 A Ās row-stochastic matrix for A s , Ās = D −1 u = y v }|/|E| h r expectation for h on graphs with balanced classes, h r = 1 |Y| h t average homophily ratio within the 1-hop neighborhood of the targeted nodes C Proofs and Discussions of Theorems C.1 Detailed Analysis of Theorem 1 Proof 1 (for Theorem 1)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>1: Downsampling Algorithm For Snap Patents Input: Graph to sample G Number of nodes to sample N Sampling ratio p Output: Downsampled graph G 1 initialization /* Initialize a queue bfsquene for Breadth First Search, and a list nodessampled for storing sampled nodes */ * Start BFS with a random node from the largest connected component in G; Random(array, n) returns n elements from an array with equal probability without replacement */ 4 node starting ← RANDOM(LARGESTCONNECTEDCOMPONENT(G), 1) 5 push node starting into bfs quene 6 while LENGTH(nodes sampled ) &lt; N do</figDesc><table><row><cell>10</cell><cell>for neighbor ∈ neighbors drawn do</cell></row><row><cell>11</cell><cell>if neighbor / ∈ nodes sampled then</cell></row><row><cell>12</cell><cell>append neighbor to nodes sampled</cell></row><row><cell>13</cell><cell>push neighbor into bfs quene</cell></row><row><cell>14</cell><cell>end</cell></row><row><cell>15</cell><cell>end</cell></row><row><cell cols="2">16 end</cell></row><row><cell cols="2">17 G ← subgraph induced by nodes sampled</cell></row><row><cell cols="2">18 return G</cell></row></table><note>2 bfs quene ← QUEUE() 3 nodes sampled ← LIST() /7 node ← bfs quene .pop() 8 neighbors ← one hop neighbors of node 9 neighbors drawn ← RANDOM(neighbors, p× LENGTH(neighbors))</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Preprint. Under review.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">https://www.nber.org/research/data/us-patents</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>This material is based upon work supported by the National Science Foundation under CAREER Grant No. IIS 1845491, Army Young Investigator Award No. W911NF1810397, an Adobe Digital Experience research faculty award, an Amazon faculty award, a Google faculty award, and AWS Cloud Credits for Research. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Quadro P6000 GPU used for this research. MTS received funding from the Ministry of Culture and Science (MKW) of the German State of North Rhine-Westphalia ("NRW Rückkehrprogramm") and the Excellence Strategy of the Federal Government and the Länder. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or other funding parties.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>which is the same as the ∆L CM,indirect atk term in Eq. <ref type="bibr" target="#b15">(16)</ref>.</p><p>For the ∆L CM,direct atk term in Eq. <ref type="bibr" target="#b14">(15)</ref> and the ∆L CM,indirect atk term in Eq. ( <ref type="formula">16</ref>), we have shown in Proof 1 that we always have ∆L CM,direct atk &gt; ∆L CM,indirect atk for an effective unit perturbation that increases attack loss L CM atk (i.e., δ 1 = −1 and δ 2 = 0, or δ 1 = 0 and δ 2 = 1) when h &gt; 1 |Y| ; replcaing the ∆L CM,direct atk term in Eq. <ref type="bibr" target="#b14">(15)</ref> to the equivalent term ∆L CM,f (2)   s atk in Eq. <ref type="bibr" target="#b25">(26)</ref>, and the ∆L CM,indirect atk term in Eq. <ref type="bibr" target="#b15">(16)</ref> to the equivalent term ∆L CM,fs atk in Eq. <ref type="bibr" target="#b26">(27)</ref> proves the statement of the theorem for a unit structural perturbation in direct neighborhood N (v) of the target node v.</p><p>Unit perturbation in 2-hop neighborhood N 2 (v) As the predictions z v of target node v made by the single-layer GNN f s (A, X) is not affected by perturbation in 2-hop neighborhood N 2 (v), we have the increase in CM-type attack loss as ∆L CM,fs atk = 0 in this case. Therefore, it is straightforward to see that any effective unit perturbation that increases attack loss L CM,f (2)   s atk always have ∆L CM,f (2)   s atk &gt; ∆L CM,fs atk = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Combining Heterophily-Inspired Designs with Low-Rank Approximation</head><p>In this section, we provide more details on how we incorporate the low-rank approximation vaccination into the formulations of H 2 GCN <ref type="bibr" target="#b39">[40]</ref> and GraphSAGE <ref type="bibr" target="#b8">[9]</ref> in order to form the hybrid methods, H 2 GCN-SVD and GraphSAGE-SVD.</p><p>H 2 GCN-SVD From <ref type="bibr" target="#b39">[40]</ref>, each layer in the neighborhood aggregation stage of H 2 GCN can be algebraically formulated as</p><p>where Â = D −1/2 AD −1/2 is the symmetrically normalized adjacency matrix without self-loops;</p><p>is the symmetrically normalized 2-hop graph adjacency matrix</p><p>are the node representations after the k-th layer, and CONCAT is the column-wise concatenation function. For H 2 GCN-SVD, we replace Â and Â2 in Eq. ( <ref type="formula">28</ref>) respectively with the low-rank approximations of Ã and Ã2 , which are both postprocessed to be symmetrically normalized.</p><p>GraphSAGE-SVD From <ref type="bibr" target="#b8">[9]</ref>, each layer in GraphSAGE can be algebraically formulated as</p><p>where Ā is the row-stochastic graph adjacency matrix without self-loops; R (k) are the node representations after the k-th layer; CONCAT is the column-wise concatenation function; W (k) is the learnable weight matrix for the k-th layer, and σ is the non-linear activation function (ReLU). For GraphSAGE-SVD, we replace Ā in Eq. ( <ref type="formula">29</ref>) with the low-rank approximation of the adjacency matrix Ã, postprocessed by row-stochastic normalization. Note that we do not enable the neighborhood sampling function for the GraphSAGE and GraphSAGE-SVD models tested in this work, as noted in Appendix D.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Hyperparameters</head><p>• H 2 GCN-SVD Initialization Parameters:</p><p>-adj_svd_rank: best k chosen from {5, 50} for each dataset Training Parameters:</p><p>-early_stopping: Yes -train_iters: 200 patience: 100</p><p>• GraphSAGE-SVD Initialization Parameters:  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MixHop: Higher-Order Graph Convolution Architectures via Sparsified Neighborhood Mixing</title>
		<author>
			<persName><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Ver Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Deyu</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00797</idno>
		<title level="m">Beyond Low-frequency Information in Graph Convolutional Networks</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Certifiable Robustness to Graph Perturbations</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
				<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adversarial attack on graph structured data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1115" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Yushun</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaize</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Jalaian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.12840</idno>
		<title level="m">Graph Neural Networks with Adaptive Frequency Response Filter</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">All you need is low (rank) defending against adversarial attacks on graphs</title>
		<author>
			<persName><forename type="first">Negin</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saba</forename><forename type="middle">A</forename><surname>Al-Sayouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Darvishzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
				<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Snowball Sampling</title>
		<author>
			<persName><forename type="first">Leo</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
		<idno type="DOI">10.1214/aoms/1177705148</idno>
		<ptr target="https://doi.org/10.1214/aoms/1177705148" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="148" to="170" />
			<date type="published" when="1961">1961. 1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Residual Correlation in Graph Neural Network Regression</title>
		<author>
			<persName><forename type="first">Junteng</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><surname>Austion R Benson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="588" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00653</idno>
		<title level="m">Adversarial attacks and defenses on graphs: A review and empirical study</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Graph structure learning for robust graph neural networks</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Diffusion Improves Graph Learning</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Weißenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graphs over Time: Densification Laws, Shrinking Diameters and Possible Explanations</title>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<idno type="DOI">10.1145/1081870.1081893</idno>
		<ptr target="https://doi.org/10.1145/1081870.1081893" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Krevl</surname></persName>
		</author>
		<ptr target="http://snap.stanford.edu/data" />
		<title level="m">SNAP Datasets: Stanford Large Network Dataset Collection</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial attack on community detection by hiding individuals</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
				<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="917" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Sean</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14187</idno>
		<title level="m">Beyond Low-Pass Filters: Adaptive Feature Propagation on Graphs</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno>arXiv:cs.LG/2005.06149</idno>
		<title level="m">DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Derek</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hohne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.01404</idno>
		<title level="m">New Benchmarks for Learning on Non-Homophilous Graphs</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14612</idno>
		<title level="m">Non-local graph neural networks</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards More Practical Adversarial Attacks on Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuangrui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automating the construction of internet portals with machine learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="127" to="163" />
			<date type="published" when="2000-01">2000. 01 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Graph-based semi-supervised learning for relational networks</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 SIAM International Conference on Data Mining. SIAM</title>
				<meeting>the 2017 SIAM International Conference on Data Mining. SIAM</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="435" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Geom-GCN: Geometric Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Hongbin</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingzhe</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Chen-Chuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><surname>Yang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=S1e2agrFvS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">GMNN: Graph Markov Neural Networks</title>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5241" to="5250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Galligher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="93" to="93" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph Agreement Models for Semi-Supervised Learning</title>
		<author>
			<persName><forename type="first">Otilia</forename><surname>Stretcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnamurthy</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanouil</forename><surname>Platanios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8713" to="8723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.10528</idno>
		<title level="m">Adversarial attack and defense on graph data: A survey</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Indirect adversarial attacks via poisoning neighbors for graph convolutional networks</title>
		<author>
			<persName><forename type="first">Tsubasa</forename><surname>Takahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Big Data (Big Data)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1395" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Social structure of Facebook networks</title>
		<author>
			<persName><forename type="first">Amanda</forename><forename type="middle">L</forename><surname>Traud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Mucha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mason</forename><forename type="middle">A</forename><surname>Porter</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physa.2011.12.021</idno>
		<ptr target="https://doi.org/10.1016/j.physa.2011.12.021" />
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="page" from="4165" to="4180" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12152</idno>
		<title level="m">Robustness may be at odds with accuracy</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJXMpikCZ" />
		<title level="m">Graph Attention Networks. International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adversarial Examples for Graph Data: Deep Insights into Attack and Defense</title>
		<author>
			<persName><forename type="first">Huijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Tyshetskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Docherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liming</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/669</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/669" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</title>
				<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4816" to="4823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Topology attack and defense for graph neural networks: An optimization perspective</title>
		<author>
			<persName><forename type="first">Kaidi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongge</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsui-Wei</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyi</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04214</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06462</idno>
		<title level="m">Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">GNNGuard: Defending Graph Neural Networks against Adversarial Attacks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust graph convolutional networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Dingyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1399" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Jiong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anup</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tung</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nedim</forename><surname>Lipka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nesreen</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.13566</idno>
		<title level="m">Graph Neural Networks with Heterophily</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs</title>
		<author>
			<persName><forename type="first">Jiong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adversarial Attacks on Graph Neural Networks via Meta Learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Certifiable robustness and robust training for graph convolutional networks</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="246" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Certifiable robustness of graph convolutional networks under structure perturbations</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1656" to="1665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Python Fire 1 and signac 2 . We incorporated the following implementations of GNN models in our framework. For GNNGuard and GCN-SVD, there are some implementation ambiguities</title>
		<ptr target="https://github.com/GemsLab/H2GCN" />
		<imprint/>
	</monogr>
	<note>D Detailed Experimental Setups and Hyperparameters D.1 More Details on the Experimental Setup Benchmark Implementations Our empirical framework is built on DeepRobust [19. which we discuss in the next paragraph. H 2 GCN [40</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Notes on the GNNGuard and GCN-SVD Implementations We note that there are ambiguities in the implementations of GNNGuard [37] and GCN-SVD [7], which can lead to different variants with different performance and robustness, as we show in Table D.1. For GNNGuard, the ambiguity comes from different interpretations of Eq. (4) in the original paper [37]: we consider the authors&apos; original implementation as variant (I), and the model described in the original paper as variant (II), which we implement by building on the authors&apos; implementation. Table D.1: Performance comparison between variants of GNNGuard and GCN-SVD: mean accuracy ± stdev over multiple sets of experiments</title>
		<ptr target="https://github.com/DSE-MSU/DeepRobust/blob/master/examples/graph/test_gcn_svd.pyGAT[33]https://github.com/DSE-MSU/DeepRobust/blob/master/deeprobust/graph/defense/gat.pyGCN[13]https://github.com/DSE-MSU/DeepRobust/blob/master/deeprobust/graph/defense/gcn.py" />
		<imprint/>
	</monogr>
	<note>Homophilous graphs Heterophilous graphs Homophilous graphs Heterophilous graphs</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m">Cora Citeseer FB100 Snap Cora Citeseer FB100 Snap</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Clean Datasets Clean Datasets GNNGuard ( I ) 75</title>
		<idno>56±5.15 70.00±6.24 68.89±2.08 31.67±0.00 79.58±0.97 71.68±1.10 65.31±1.48 26.37±0.70</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gnnguard</surname></persName>
		</author>
		<idno>II) 77.22±6.29 67.78±4.78 67.22±2.08 28.33±3.60 80.15±0.55 72.61±0.28 65.66±0.60 26.51±0.98</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 5 66</title>
		<idno>67±8.16 63.89±5.50 51.67±6.24 29.44±0.79 69.43±0.99 68.31±0.34 52.95±0.13 27.66±0.05</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 5 52.78±5.50 35.00±1.36 50.56±4.37 25.00±5.93 55.05±1.77 41.47±0.72 52.40±0.18 25.84±0.07</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 10 66</title>
		<idno>11±6.71 65.00±3.60 52.78±4.16 30.56±2.08 71.08±0.46 69.19±1.13 54.47±0.32 27.57±0.18</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 10 66.11±4.78 45.00±3.60 51.11±2.08 22.22±4.78 64.79±1.56 52.17±0.39 51.19±0.41 25.45±0.21</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 15 72</title>
		<idno>78±6.98 63.89±7.74 57.78±2.83 28.89±2.08 72.74±0.29 66.51±1.53 57.67±0.36 27.61±0.55</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 15 69.44±2.08 46.67±6.24 52.78±5.15 21.67±1.36 65.61±0.19 60.55±0.73 53.24±0.45 26.63±0.25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 50 78</title>
		<idno>89±6.29 66.67±3.60 65.56±2.83 31.11±0.79 77.98±0.43 68.25±0.86 63.41±0.45 27.81±0.39</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 50 NETTACK 75.56±4.16 59.44±0.79 55.00±1.36 27.78±6.71</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Poison Attacks Poison Attacks GNNGuard ( I )</title>
		<idno>57.22±2.08 60.00±3.60 0.56±0.79 11.11±0.79 73.68±0.99 67.89±0.92 60.82±0.45 23.98±0.71</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gnnguard</surname></persName>
		</author>
		<idno>II) 58.33±1.36 59.44±3.14</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 5 64</title>
		<idno>44±9.06 60.00±4.71 41.67±6.24 27.78±6.29 64.65±2.57 66.35±1.48 53.14±0.43 25.64±0.47</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 5 44.44±2.83 33.33±2.72 41.67±2.36 25.00±6.80 42.19±5.33 40.17±1.57 51.87±0.38 24.82±0.43</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>I ) k = 10 67.78±5.50 57.78±1.57 35.56±1.57 31.67±5.93 65.54±1.28 65.46±0.92 55.68±0.15 25.93±0.75</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 10 48.89±3.14 31.67±2.36 34.44±0.79 26.11±6.85 49.92±5.88 47.16±3.93 53.16±0.45 25.30±0.28</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 15 64</title>
		<idno>44±3.93 52.78±4.78 23.89±6.29 29.44±3.93 65.46±2.33 61.04±1.04 58.06±0.05 25.83±0.69</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 15 51.11±3.42 33.89±3.93 30.56±2.83 26.11±6.14 50.30±3.80 47.87±1.31 54.20±0.36 25.25±0.91</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 50 61</title>
		<idno>67±4.71 48.33±7.07 16.67±4.08 30.56±7.97 60.06±5.43 49.31±4.52 62.07±0.69 26.05±0.63</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 50 NETTACK 53.33±4.91 28.89±2.08 23.33±2.72 25.00±5.44</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">( I ) k = 5 64</title>
		<idno>44±8.20 59.44±3.93 41.11±7.97 31.67±3.60 68.18±1.13 67.54±0.97 52.91±0.28 27.40±0.29</idno>
		<editor>Evasion Attacks Evasion Attacks GNNGuard ( I ) --------GNNGuard (II) --------GCN-SVD</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 5 46.67±4.08 32.22±4.37 45.56±3.93 26.11±6.14 52.01±2.45 30.69±1.01 52.32±0.10 25.87±0.27</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>I ) k = 10 65.56±7.49 57.22±3.42 36.11±1.57 31.11±0.79 68.36±1.33 67.85±0.72 54.51±0.68 27.30±0.30</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 10 57.22±6.14 37.78±3.93 36.67±3.60 30.56±8.85 58.70±3.00 45.62±2.52 52.58±0.20 24.60±0.26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 15 67</title>
		<idno>22±6.14 54.44±6.14 24.44±5.50 30.00±1.36 69.32±1.21 65.26±0.97 57.79±0.38 28.06±0.23</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 15 65.56±6.14 38.33±5.93 23.89±6.98 27.22±7.97 64.02±1.30 54.09±2.25 53.81±0.35 25.29±0.41</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">GCN-SVD ( I ) k = 50 65</title>
		<idno>00±6.24 50.56±6.43</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gcn-Svd</surname></persName>
		</author>
		<idno>II) k = 50 NETTACK 60.00±6.24 47.78±4.37 25.00±4.71 30.56±9.56</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
