<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Iteration-wise Generalized Shrinkage-Thresholding Operators for Blind Deconvolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">School of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">Department of Computing</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongwei</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Zhang</surname></persName>
							<email>csdzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Iteration-wise Generalized Shrinkage-Thresholding Operators for Blind Deconvolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FDE628CCA7193D0636F98024757E8E25</idno>
					<idno type="DOI">10.1109/TIP.2016.2531905</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2531905, IEEE Transactions on Image Processing This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2531905, IEEE Transactions on Image Processing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>blind deconvolution</term>
					<term>kernel estimation</term>
					<term>image deblurring</term>
					<term>hyper-Laplacian</term>
					<term>discriminative learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Salient edge selection and time-varying regularization are two crucial techniques to guarantee the success of maximum a posterior (MAP)-based blind deconvolution. However, the existing approaches usually rely on carefully designed regularizers and handcrafted parameter tuning to obtain satisfactory estimation of the blur kernel. Many regularizers exhibit the structure-preserving smoothing capability, but fail to enhance salient edges. In this paper, under the MAP framework, we propose the iteration-wise p-norm regularizers together with data-driven strategy to address these issues. First, we extend the generalized shrinkage-thresholding (GST) operator for p- norm minimization with negative p value, which can sharpen salient edges while suppressing trivial details. Then, the iterationwise GST parameters are specified to allow dynamical salient edge selection and time-varying regularization. Finally, instead of handcrafted tuning, a principled discriminative learning approach is proposed to learn the iteration-wise GST operators from the training dataset. Furthermore, the multi-scale scheme is developed to improve the efficiency of the algorithm. Experimental results show that, negative p value is more effective in estimating the coarse shape of blur kernel at the early stage, and the learned GST operators can be well generalized to other dataset and real world blurry images. Compared with the stateof-the-art methods, our method achieves better deblurring results in terms of both quantitative metrics and visual quality, and it is much faster than the state-of-the-art patch-based blind deconvolution method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Blind image deconvolution aims to recover the latent sharp image x and blur kernel k from the blurry observation</p><formula xml:id="formula_0">y = k ⊗ x + n,<label>(1)</label></formula><p>where ⊗ denotes 2D convolution and n is additive Gaussian white noise. Blind image deconvolution generally involves two stages, i.e., blur kernel estimation and non-blind deconvolution, where the former is crucial to the success of the algorithm. There are two classes of popular blur kernel estimation strategies: variational Bayes (VB)-based and maximum a posterior (MAP)-based ones. Levin et al. <ref type="bibr" target="#b0">[1]</ref> showed that naive MAP prefers trivial delta kernel solution while the VB-based approaches are more robust in estimating the blur kernel. This observation has motivated several VBbased methods for image deconvolution <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. However, the approximation of integration is required, making VB-based methods computationally inefficient.</p><p>Recently, with the introduction of salient edge selection and time-varying regularization, interest in improved MAP has been revived for efficient blind deconvolution with many representative methods <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>. MAP jointly estimates the pair (k, x) by maximizing a posterior probability,</p><formula xml:id="formula_1">max x,k Pr(x, k|y) ∝ max x,k Pr(y|x, k) Pr(x) Pr(k),<label>(2)</label></formula><p>where Pr(x, k|y) denotes a posterior on (x, k), Pr(x) and Pr(k) are the priors of the latent sharp image and the blur kernel, and Pr(y|x, k) denotes the likelihood of the observation y. The MAP model can be equivalently rewritten as,</p><formula xml:id="formula_2">min k,x λ 2σ 2 n k ⊗ x -y 2 + φ (x) + µϕ (k) ,<label>(3)</label></formula><p>where σ n is the standard deviation (std.) of the additive Gaussian white noise, and φ (x) and ϕ (k) are the regularizers on x and k, respectively. Widpf and Zhang <ref type="bibr" target="#b5">[6]</ref> recasted VB as MAP with spatially-adaptive sparse prior to explain the connections between the existing VB <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> and MAP approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>Our work is motivated by the two key techniques, i.e., salient edge selection <ref type="bibr" target="#b11">[12]</ref> and time-varying regularization, which have been widely adopted in MAP-based blind deconvolution. However, we re-analyze these techniques by raising three questions:</p><p>1) Salient edge selection is widely used to explicitly or implicitly recover salient edges to facilitate kernel estimation <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. In <ref type="bibr" target="#b11">[12]</ref>, shock and bilateral filters are employed in each iteration to enhance strong edges while suppressing harmful small-scale textures. Actually, bilateral filter is a smoothing operator and shock filter is a sharpening operator, while the regularizers like 0 -norm <ref type="bibr" target="#b15">[16]</ref> result in a structure-preserving smoothing operator. Thus, our first question is: is it possible to extend the existing regularizers, e.g., p -norm <ref type="bibr" target="#b17">[18]</ref>, to achieve both smoothing and sharpening capability? The GST operator is the solution to the p-norm minimization problem x = arg minx 1 2 (x -y) 2 + λ|x| p , and in the left plot the horizontal and vertical axes are denoted by y and x, respectively. In the initial stage, the GST operator with negative p value can impose a larger threshold for suppressing small-scale textures and magnifying the salient edges. Then, by gradually increasing the p values along with iteration, we can include more gradient details for refining the kernel estimation.</p><p>2) Time-varying regularization is also widely adopted in blind deconvolution. To better estimate the blur kernel k, the salient edges should be dynamically recovered to guide the algorithm gradually converge to the desired solution. For example, in <ref type="bibr" target="#b11">[12]</ref> parameters of the shock and bilateral filters are tuned to select the strongest edges at first, and subsequently the estimated kernel is refined by the gradually added details. In <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>, the regularization parameter λ is set small in the first a few iterations to preserve strong edges, and then gradually increases along with iteration to produce accurate blur kernel. So, our second question is: is there a family of priors (each iteration has its own parameters) for blind deconvolution? 3) Most existing approaches involve carefully designed regularizers and handcrafted parameter tuning to guide the algorithms to converge to the desired solution. It is interesting to ask the question: can we learn the iteration-wise regularization parameters using the data-driven strategy?</p><p>In this paper, we address above problems based on the MAP framework with iteration-wise regularizers. For the second problem, we adopt a family of hyper-Laplacian distribution Pr(d) ∝ e -d p p /λ on gradient d = ∇x, where each iteration has its own parameters (p i , λ i ). The resulting p -norm minimization problem can be readily solved using the generalized shrinkage-thresholding (GST) operator <ref type="bibr" target="#b17">[18]</ref>. Thus, iterationwise GST operators are exploited in our MAP framework. For the first problem, we extend the GST operator for p -norm minimization with negative p value. GST is computationally efficient and can well imitate the shock and bilateral filters in enhancing salient edges while smoothing small-scale textures. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, GST with p = -1 magnifies the strongest edges so that the coarse shape of blur kernel can be rapidly estimated. With the increase of p value, e.g., p = 0 and p = 0.2, GST gradually adds more gradient details to refine the estimated blur kernel.</p><p>For the third problem, we propose a discriminative learning method to learn the iteration-wise regularization parameters, i.e. GST operators, from the training dataset. Furthermore, multi-scale scheme is employed to improve the efficiency and effectiveness by learning regularization parameters over scales (S -1, ..., s, ..., 0) and inner itera-tions (1, ..., t, ..., T ). As illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, in the training stage a discriminative learning framework is used to greedily learn the iteration-wise regularization parameters by minimizing the weighted mean square error (MSE) between the estimated gradient images / blur kernels and the ground truth ones, i.e. we greedily learn (λ (s,t) , p (s,t) ) after learning {(λ (S-1,1) , p (S-1,1) ), ..., (λ (s,t-1) , p (s,t-1) )}. In the deblurring stage, kernel estimation is performed over scales (S -1, ..., s, ..., 0). One-step solutions by the augmented Lagrangian method (ALM) are adopted to update the blur kernel k and the latent image gradient d so that the parameters (λ (s,t) , p (s,t) ) can be optimally determined via the gradient descent method. When the inner iteration t reaches the maximum value T , the estimated blur kernel k (s,T ) and latent gradient d (s,T ) would be upsampled to be used as the initialization of the finer scale s -1, i.e., k (s-1,1) and d (s-1,1) . Experimental results show that the learned iterationwise GST operators can be directly applied to other dataset and real world blurry images. The proposed method can achieve visually more plausible results than the existing gradient prior based methods, including both MAP <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15]</ref> and VB <ref type="bibr" target="#b1">[2]</ref>, and also outperforms the state-of-the-art patch based method <ref type="bibr" target="#b20">[21]</ref> in terms of both deblurring quality and efficiency. This paper is a substantial extension of our pioneer work <ref type="bibr" target="#b21">[22]</ref>. Compared with <ref type="bibr" target="#b21">[22]</ref>, the coarse-to-fine framework is adopted to improve the kernel estimation performance, more experiments are conducted to evaluate the proposed method, and more analyses and discussions are presented. We summarize our contributions from three aspects: 1) We generalize the GST operator for p -norm minimization with negative p values, which can magnify the salient edges while suppressing trivial textures, making it very promising in coarse estimation of the blur kernel. 2) By specifying iteration-wise GST operators, a novel MAP-based blind deconvolution method is developed to naturally select proper salient edges for robust blur kernel estimation, which makes the estimated blur kernel free from the trivial delta kernel solution and gradually converge to the desired solution. 3) To avoid heavy parameters tuning, we propose a principled discriminative learning approach to learn iterationwise GST operators from a training dataset, and the </p><formula xml:id="formula_3">    ( , ) ( , ) ( , 1) ( , 1) ( , ) ( , )<label>( 1</label></formula><formula xml:id="formula_4">i i i i i i L       θ d d d k k k</formula><p>Learning GST operators for scale s .. . .. .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Blurry images Clear images</head><p>Ground truth of blur kernels For iteration t in scale s, minimizing the loss function defined on to learn the optimal GST operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>… …</head><p>Scale s in {S -1, … , s, … , 0} learned parameters can be directly applied to other datasets and real blurry images. The remainder of this paper is organized as follows. Section II reviews related work. Section III presents the proposed iteration-wise framework for blur kernel estimation together with the specially designed one-step ALM solutions. Section IV learns the optimal GST operators using the proposed principled discriminative learning framework. Section V gives the experimental results, and Section VI ends this paper with some conclusions and discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>For better blur kernel estimation, it is critical to impose regularization to guide the MAP based algorithms to be away from the trivial delta kernel solution. In this section, we briefly review the existing regularizers on the latent image x and the blur kernel k.</p><p>A. Regularization on latent image 1) p -norm regularizers: In <ref type="bibr" target="#b22">[23]</ref>, it has been shown that the gradients of natural images can be well modeled with hyper-Laplacian distribution, where the p -norm (0.5 &lt; p &lt; 0.8) was suggested as the regularizer in non-blind image restoration. In blind deconvolution, one natural choice is the total variation (TV) regularizer with p = 1 <ref type="bibr" target="#b7">[8]</ref>. However, the small p value usually produces sparser gradients and better kernel estimation. Wipf and Zhang <ref type="bibr" target="#b5">[6]</ref> suggested p -norm with p 1 and Xu et al. adopted the l 0 -norm regularizer <ref type="bibr" target="#b15">[16]</ref>.</p><p>It is interesting to note that, even though Levin et al. <ref type="bibr" target="#b0">[1]</ref> theoretically analyzed that TV based blind deconvolution (TVBD) <ref type="bibr" target="#b7">[8]</ref> and its variants would converge to the trivial delta kernel <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19]</ref>, several TVBD algorithms <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> actually succeed in estimating blur kernel and latent image. To explain the incongruence between the success of TV in <ref type="bibr" target="#b7">[8]</ref> and the failure of TV in <ref type="bibr" target="#b0">[1]</ref>, Perrone and Favaro <ref type="bibr" target="#b8">[9]</ref> revealed that Chan and Wong <ref type="bibr" target="#b7">[8]</ref> actually adopted a projected alternating minimization algorithm for TVBD, and the success of the algorithm can be explained by the delayed normalization of blur kernel.</p><p>Using the half-quadratic strategy, the updating of the latent image x in Eq. ( <ref type="formula" target="#formula_2">3</ref>) can be split to the following two subproblems min</p><formula xml:id="formula_5">x λ 2σ 2 n k ⊗ x -y 2 + δ 2 ∇x -w 2 , (<label>4</label></formula><formula xml:id="formula_6">)</formula><formula xml:id="formula_7">min w δ 2 ∇x -w 2 + w p p ,<label>(5)</label></formula><p>where the gradient operator ∇ = {∇ h , ∇ v } includes the horizontal and vertical directions. The w subproblem in (5) can be efficiently solved using the look-up table method <ref type="bibr" target="#b22">[23]</ref> or the GST operator <ref type="bibr" target="#b17">[18]</ref>. Specifically, when p = 0 the w subproblem can be solved by hard-thresholding <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>To improve the performance of blur kernel estimation, one usual strategy is to gradually increase the regularization parameters λ along the iterations. However, to the best of our knowledge, no studies were given on the iteration-wise tuning of the p values. Moreover, although discriminative learning has achieved state-of-the-art performance in non-blind restoration <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref>, most existing blind deconvolution methods solely rely on handcrafted tuning of the regularization parameters.</p><p>2) Other forms of regularizers: Other gradient-based regularizers have also been developed to enhance strong edges for better kernel estimation. In <ref type="bibr" target="#b14">[15]</ref>, Krishnan et al. extended the standard 1 -norm gradient prior to a normalized version ∇x 1 / ∇x 2 to avoid the trivial delta kernel solution, and in <ref type="bibr" target="#b27">[28]</ref>, Paragios et al. proposed a discrete MRF prior to produce highly sparse gradients. Different from gradient priors that only model connections among adjacent pixels, patch-based priors that can better model large-scale structures provide a better way to extract salient edges for kernel estimation <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>. Moreover, by exploiting the patch sparsity of sharp image on an over-complete dictionary, sparse representation based approaches have also been developed for blind deconvolution <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Regularization on blur kernel</head><p>The basic regularizer on blur kernel is the non-negative constraint k i ≥ 0, ∀i and the normalization constraint i k i = 1, which naturally come from the property of camera shake blur. Furthermore, the camera shake trajectory is a 1D connected path, so it is reasonable to enforce the sparsity on kernel. Although a variety of blind deconvolution methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33]</ref> do not explicitly impose the sparsity regularizer, in their implementations, hard-thresholding operation is performed to assign any k i ≤ ε to zero, where ε is some small positive number, implicitly enhancing its sparsity. Meanwhile, other gradient sparsity regularizers, e.g., TV <ref type="bibr" target="#b7">[8]</ref> and hyper-Laplacian <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b33">34]</ref>, have also been suggested to avoid the trivial delta kernel solution <ref type="bibr" target="#b9">[10]</ref>.</p><p>Moreover, based on the observation that blurring reduces the frequencies of sharp image, spectral priors of blur kernel can be extracted from the blurry observation <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref>. Along this line, several works <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> indicate that the texture-only blurry images can also be successfully handled, but still rely on the salient structures to better acquire spectral information of kernel <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>In this work, we adopt the sparsity on kernel together with the non-negative and normalization constraints, and focus on the development of iteration-wise regularizers on latent image x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. KERNEL ESTIMATION WITH ITERATION-WISE MAP</head><p>In this section, we first formulate our iteration-wise MAPbased model in the gradient space. We then extend the GST operator for p -norm minimization to the case with p &lt; 0, which is used to sharpen salient edges while smoothing trivial textures. Finally, one-step augmented Lagrangian method (ALM) is proposed to update the latent sharp image gradient d and blur kernel k alternatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><p>As suggested in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b32">33]</ref>, we formulate the proposed MAP-based blind deconvolution model in the gradient space,</p><formula xml:id="formula_8">min d,k λ 2σ 2 n k ⊗ d -∇y 2 + φ (d) + µϕ (k) ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_9">d = ∇x with d h = ∇ h x and d v = ∇ v x.</formula><p>Gradient images have been widely adopted in the existing blind deconvolution methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>. As explained in <ref type="bibr" target="#b11">[12]</ref>, the use of gradient images can make the blur kernel estimation better conditioned. And empirical studies have validated the superiority of gradient images against intensity images <ref type="bibr" target="#b1">[2]</ref>.</p><p>As to the image priors, we impose the hyper-Laplacian prior on gradients d,</p><formula xml:id="formula_10">Pr(d) ∝ e -d p p /λ .<label>(7)</label></formula><p>Instead of uisng fixed parameters in existing methods, in this work the parameters {λ, p} are iteration-wisely set. Moreover, since the image d is the gradient of some image x, the constraint d = ∇x should be satisfied, which has been often omitted in existing blind deconvolution models. In this work, the constraint d = ∇x is explicitly expressed as <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>,</p><formula xml:id="formula_11">∇ h d v = ∇ v d h .<label>(8)</label></formula><p>As to the priors on kernel k, we simply enforce its sparsity via hyper-Laplacian prior,</p><formula xml:id="formula_12">Pr(k) ∝ e -µ k 0.5 0.5 ,<label>(9)</label></formula><p>together with the non-negative constraint and the normalization constraint</p><formula xml:id="formula_13">i k i = 1, k i ≥ 0, ∀i.<label>(10)</label></formula><p>One may choose the iteration-wise regularization parameters for k. But our experiments show that simultaneously learning of the parameters for d and k cannot obtain better results than only learning parameters for d. Taking both efficiency and simplicity into account, we fix p = 0.5 for k in our model. The coarse-to-fine multi-scale strategy is adopted in most blind deconvolution methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">43]</ref> to make the kernel estimation more robust and efficient. In this work, we also employ the multi-scale framework, where blur kernel estimation is performed over scales (S -1, ..., s, ..., 0) and inner iterations (1, ..., t, ..., T ). The blurry input y is downsampled to S scales, i.e., y (0) , ..., y (s) , ..., y (S-1) . On the coarsest scale, i.e., blurry input y (S-1) , the blur kernel is first estimated, and then upsampled as the initialization of scale S -2. The coarse-to-fine kernel estimation procedure is recursively performed until the finest scale y (0) = y. The overall multi-scale kernel estimation process is summarized in Algorithm 1.</p><p>Given scale s and iteration t, by incorporating the constraints in Eqns. ( <ref type="formula" target="#formula_11">8</ref>) and <ref type="bibr" target="#b9">(10)</ref> and the priors in Eqns. ( <ref type="formula" target="#formula_10">7</ref>) and ( <ref type="formula" target="#formula_12">9</ref>) into Eq. ( <ref type="formula" target="#formula_8">6</ref>), the iteration-wise MAP-based blind deconvolution model is formulated as: where λ (s,t) and p (s,t) are iteration-wise GST parameters that can be learned from a training dataset. Since all the scales share the same kernel estimation procedure, in the following context, given scale s and iteration t, we simplify (s, t) as (t) to more clearly present the alternative updating of the blur kernel k and the latent image gradient d.</p><formula xml:id="formula_14">min d,k λ (s,t) 2σ 2 n k ⊗ d -∇y (s) 2 + d p (s,t) p (s,t) +µ k 0.5 0.5 s.t. ∇ h d v = ∇ v d h , i k i = 1, k i ≥ 0, ∀i,<label>(11</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. GST and its extension to p &lt; 0</head><p>The model in Eq. ( <ref type="formula" target="#formula_14">11</ref>) is a non-convex p -norm minimization problem. By far, many optimization methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref> have been developed for p -norm (0 ≤ p ≤ 1) optimization . Among these methods, the generalized iterated shrinkage algorithm (GISA) <ref type="bibr" target="#b17">[18]</ref> is very promising due to its computational efficiency and convergence to better solution. The key of GISA is to introduce a generalized shrinkage-thresholding (GST) operator to solve the following basic p -norm minimization subproblem,</p><formula xml:id="formula_15">x = arg min x 1 2 (y -x) 2 + λ|x| p . (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>The GST operator <ref type="bibr" target="#b17">[18]</ref> is defined as</p><formula xml:id="formula_17">x = 0, if |y| ≤ τ GST p (λ) , sgn (y) S GST p (|y|; λ) , if |y| &gt; τ GST p (λ) ,<label>(13)</label></formula><p>where the threshold τ GST p (λ) is given by</p><formula xml:id="formula_18">τ GST p (λ) = (2λ(1 -p)) 1 2-p + λp(2λ(1 -p)) p-1 2-p ,<label>(14)</label></formula><p>and the unique minimum S GST p (|y|; λ) can be found by solving the following equation</p><formula xml:id="formula_19">S GST p (|y|; λ) -y + λp S GST p (|y|; λ) p-1 = 0.<label>(15)</label></formula><p>Zuo et al. <ref type="bibr" target="#b17">[18]</ref> suggested an iterative algorithm to compute S GST p (|y|; λ) by repeatedly performing the following shrinkage step</p><formula xml:id="formula_20">|x| = |y| -λp(|x|) p-1 .<label>(16)</label></formula><p>When 0 ≤ p ≤ 1, the GST operator can always obtain the optimal solution to the subproblem in Eq. ( <ref type="formula" target="#formula_15">12</ref>). From Eqns. ( <ref type="formula" target="#formula_18">14</ref>) and ( <ref type="formula" target="#formula_20">16</ref>), one can easily see that GST with 0 ≤ p &lt; 1 actually is a smoothing operator. However, as illustrated in <ref type="bibr" target="#b11">[12]</ref>, rough kernel estimation is benefited by both the smoothing of harmful small-scale textures and the sharpening of salient edges. To this end, Cho et al. <ref type="bibr" target="#b11">[12]</ref> adopted the bilateral filter for image smoothing and the shock filter for edge sharpening. And one natural problem is to ask whether we can extend GST to possess the ability of thresholding and expansion. Interestingly, one can easily verify that by setting p as a negative value, the solution S GST p (|y|; λ) by GST in Eq. ( <ref type="formula" target="#formula_20">16</ref>) becomes a thresholdingexpansion operator. Therefore, the extended GST operator with p &lt; 0 can employ the thresholding rule to suppress detailed textures and utilize the expansion rule to enhance strong edges, which in spirit is similar with the bilateral and shock filters adopted in <ref type="bibr" target="#b11">[12]</ref>.</p><p>The tradeoff between smoothness and sharpness is critical for blind deconvolution. In the early stage of kernel estimation, the sharpness plays an important role. Thus we use the GST operator with p &lt; 0, which can magnify the salient edges to enhance the sharpness while simultaneously introducing a larger threshold for suppressing ringing artifacts and small-scale textures. Along with iteration we increase p to appropriate positive values for optimal tradeoff between smoothness and sharpness. Moreover, instead of handcrafted tuning, we adopt a discriminative learning framework to learn the iteration-wise GST operators from a training dataset, which will be explained in detail in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Alternating minimization</head><p>We adopt the alternating minimization method to solve the MAP-based blind deconvolution model in Eq. ( <ref type="formula" target="#formula_14">11</ref>). (i) Fixing k, a one-step hybrid ALM method is adopted to update d by considering the equality constraint in Eq. ( <ref type="formula" target="#formula_11">8</ref>); (ii) Fixing d, a one-step ALM method is employed to update k. In the following, we describe the algorithms for updating d and k in details.</p><p>1) Updating d via one-step hybrid ALM: By fixing the blur kernel as the current estimation k (t-1) , the problem on d is formulated as</p><formula xml:id="formula_21">min d λ (t) 2σ 2 n k (t-1) ⊗d-∇y 2 + d p (t) p (t) s.t. ∇ T c d = 0,<label>(17)</label></formula><p>where</p><formula xml:id="formula_22">∇ c =[∇ v , -∇ h ].</formula><p>With the half-quadratic strategy, we introduce an auxiliary variable w, decomposing the d problem into the following two subproblems,</p><formula xml:id="formula_23">w (t) =argmin w β (t)<label>2</label></formula><p>w-d (t-1) 2 + w</p><formula xml:id="formula_24">p (t) p (t) , d (t) =argmin d λ (t) 2σ 2 n k (t-1) ⊗d-∇y 2 + β (t) 2 w (t) -d 2 s.t. ∇ T c d = 0, (<label>18</label></formula><formula xml:id="formula_25">)</formula><p>where β is the penalty parameter. The w-subproblem and d-subproblem usually need to be updated alternatively with several iterations, but this will make the relationship between d (t) with (λ (t) , p (t) ) hard to analyze and non-differential. Therefore, we set the number of inner-iteration to be 1, resulting in the one-step hybrid ALM method. In Eq. ( <ref type="formula" target="#formula_24">18</ref>), the solution to w is obtained by the extended GST operator with p &lt; 0. With the GST operator, the solution is,</p><formula xml:id="formula_26">w (t) i =    0, if d (t) i ≤ τ (t) i , sgn d (t) i d (t) i -1 β (t) p (t) d (t) i p (t) -1 , else,<label>(19)</label></formula><p>where the threshold τ (t) i is defined as</p><formula xml:id="formula_27">τ (t) i = 2 β (t) 1-p (t) 1 2-p (t) + 1 β (t) p (t) 2 β (t) 1-p (t) p (t) -1 2-p (t)</formula><p>.</p><p>The d-subproblem is a quadratic programming problem with equality constraint, which can be solved by the Lagrangian dual method <ref type="bibr" target="#b41">[42]</ref>. The Lagrangian function is where ν is the Lagrangian vector. The closed-form solution can be obtained by</p><formula xml:id="formula_29">L(d, ν) = λ (t) 2σ 2 n k (t-1) ⊗d-∇y 2 + β (t) 2 w (t) -d 2 + ν T ∇ T c d,<label>(21</label></formula><formula xml:id="formula_30">d (t) = Ω -1 η + β (t) w (t) ,<label>(22)</label></formula><p>where</p><formula xml:id="formula_31">Ω = A T k A k + β (t) I, η = λ (t) σ 2 n A T k ∇y -∇ c ν (t)</formula><p>, and the Lagrangian vector is updated as:</p><formula xml:id="formula_32">ν (t) = ∇ T c Ω -1 ∇ c -1 ∇ T c Ω -1 A T k ∇y+β (t) w (t+1) . (<label>23</label></formula><formula xml:id="formula_33">)</formula><p>The main computational burden is the matrix inversion and multiplication on the convolution matrix A k corresponding to the blur kernel k. Assuming the periodic boundary condition of blurry image, the convolution matrix A k is a block circulant with circulant blocks (BCCB) matrix that can be diagonalized via Fourier transform, and the matrix inversion and multiplication in Eqns. ( <ref type="formula" target="#formula_30">22</ref>) and ( <ref type="formula" target="#formula_32">23</ref>) can be efficiently computed by using fast Fourier transform (FFT).</p><p>2) Updating k via one-step ALM: By fixing the gradient image as the updated estimation d (t) , the problem on k can be formulated as:</p><formula xml:id="formula_34">min k λ (t) 2σ 2 n k⊗d (t) -∇y 2 +µ k 0.5 0.5 s.t. i k i =1, k i ≥0, ∀i,<label>(24)</label></formula><p>By introducing two auxiliary variables h = k and g = k, we use the standard ALM to reformulate Eq. ( <ref type="formula" target="#formula_34">24</ref>) as:</p><formula xml:id="formula_35">min k,h,g λ (t) 2σ 2 n k⊗d (t) -∇y 2 +B(h)+ δ (t) 1 2 1 T k-1 2 +µ (t) g 0.5 0.5 s.t. k = h, k = g,<label>(25)</label></formula><p>where 1 is a vector whose entries are all 1, and B(h) is a boundary constraint defined as follows:</p><formula xml:id="formula_36">B (h i ) = +∞, if h i &lt; 0, 0, else.<label>(26)</label></formula><p>With the standard ALM, the problem on k in Eq. ( <ref type="formula" target="#formula_35">25</ref>) can be solved by iteratively solving the following three subproblems,</p><formula xml:id="formula_37">h (t) = min h δ (t) 2 2 k (t-1) -h 2 +B (h) , g (t) = min g δ (t) 1 2 k (t-1) -g 2 +µ (t) g 0.5 0.5 , k (t) = min k λ (t) 2σ 2 n k ⊗ d (t) -∇y 2 + δ (t) 3 2 1 T k-1 2 + δ (t) 2 2 k-h (t) 2 + δ (t) 1 2 k-g (t) 2 .<label>(27)</label></formula><p>Also, the updating of h (t) , g (t) , k (t) can be performed for several times. In this work, to make the relationship between k (t) and λ (t) explicit, we update h (t) , g (t) , k (t) only one step, resulting in our one-step ALM method.</p><p>As to the h-subproblem, it can be easily solved by an entrywise projection operator,</p><formula xml:id="formula_38">h (t) i = k (t-1) i , if k (t-1) i &gt; 0, 0, else.<label>(28)</label></formula><p>The g-subproblem is a p -norm minimization, which can be simply solved by the GST operator <ref type="bibr" target="#b17">[18]</ref>. Finally, the ksubproblem is a quadratic optimization problem whose closedform solution is</p><formula xml:id="formula_39">k (t) = Φ -1 ζ,<label>(29)</label></formula><p>where</p><formula xml:id="formula_40">ζ = λ (t) σ 2 n A d ∇y + δ (t) 1 g (t) + δ (t) 2 h (t) + δ (t) 3 1 and Φ= λ (t) σ 2 n A T d A d +δ (t) 1 I+δ (t)</formula><p>2 I+δ (t) 3 11 T . 11 T is a matrix with all entries being 1, which fortunately is also a BCCB matrix, and the corresponding matrix inversion and product can be efficiently computed by FFT.</p><p>Algorithm 2 summarizes the main steps of our alternating minimization algorithm at scale s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Multi-scale image deconvolution</head><p>Input: Blurry image y, scale number S Output: Blur kernel k and latent image x 1: Initializing d (S-1) and k (S-1) 2: for s = S -1 to 0 do Inputing y (s) , d (s) , k (s) and {θ (s,1) , ..., θ (s,t) , ..., θ (s,T ) } to Algorithm 2 that returns d (s) and k (s)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>if s &gt; 0 then 6: Upsamping d (s) and k (s) to d (s-1) and k (s-1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>end if 8: end for 9: k = k (0) 10: Given k, recovering x by non-blind deconvolution Algorithm 2 Kernel estimation on scale s Input: Blurry image y, d (0) , k (0) and {θ (1) , ..., θ (t) , ..., θ (T ) } Output: Blur kernel k and latent gradient d 1: for t = 1 to T do 2:</p><p>// Lines 3-4 solve d-step Eq. ( <ref type="formula" target="#formula_24">18</ref>)</p><p>3:</p><formula xml:id="formula_41">w (t) = GST d (t-1) , p (t) , 1/β (t)</formula><p>4:</p><formula xml:id="formula_42">d (t) = Ω -1 η + β (t) w (t)</formula><p>5:</p><p>// Lines 6-8 solve k-step Eq. ( <ref type="formula" target="#formula_37">27</ref>)</p><p>6:</p><formula xml:id="formula_43">h (t) = arg min h δ (t) 2 2 k (t-1) -h 2 +B (h) 7:</formula><p>g (t) = GST k (t-1) , 0.5, µ (t) /δ (t) 1</p><p>8:</p><formula xml:id="formula_44">k (t) = Φ -1 ζ 9:</formula><p>Updating β (t+1) , δ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DISCRIMINATIVE LEARNING OF ITERATION-WISE GST OPERATORS</head><p>Given the scale number S and the inner iteration number T in each scale, the number of GST parameters to be set in the proposed iteration-wise MAP framework is 2 × S × T , i.e. {{(λ (S-1,t) , p (S-1,t) )} T t=1 , ..., {(λ (s,t) , p (s,t) )} T t=1 , ..., {(λ (0,t) , p (0,t) )} T t=1 }. For such a large amount of parameters, hand-crafted tuning is impractical. Therefore, in this section we propose a discriminative learning framework <ref type="bibr" target="#b47">[48]</ref> to learn the iteration-wise GST operators from a training dataset.</p><p>Denote the training dataset by D = {(d</p><formula xml:id="formula_46">(gt) i , k<label>(gt) i</label></formula><p>,∇y i )} N i=1 , which includes N blurry images together with the groundtruth clear images and blur kernels, i.e., the gradient d , and the gradient of the blurry image ∇y i . Since the multi-scale framework is adopted in kernel estimation, given scale s, the training dataset D is sampled to the corresponding size, i.e., D (s) = {(d</p><formula xml:id="formula_47">(s,gt) i , k (s,gt) i ,∇y (s) i )} N i=1 with D (0) = D.</formula><p>Given scale s and iteration t, to estimate θ (s,t) = λ (s,t) , p (s,t) , the loss function is defined as the weighted MSE on D (s) ,</p><formula xml:id="formula_48">L (s,t) (θ) = N i=1 L (s,t) i (θ) = N i=1 α (t) L (s,t) d i (θ) + L (s,t) k i (θ) = N i=1 α (s,t) 2 d (s,t) i -d (s,gt) i 2 / d (s,gt) i + 1 2 k (s,t) i -k (s,gt) i 2 / k (s,gt) i , (<label>30</label></formula><formula xml:id="formula_49">)</formula><p>where |•| counts the entries of the vector for the normalization of image and kernel sizes, and α denotes the trade-off parameter. Note that our aim is to estimate the desired blur kernel. Thus the second term in Eq. ( <ref type="formula" target="#formula_48">30</ref>) should be emphasized, especially at the early stage. Therefore, we let the α value increase along with the scale numbers and iteration numbers.</p><p>In the first a few iterations the GST operators are learned with small α for rapid kernel estimation, and then the GST operator is learned with larger α value for refining the estimated kernel while yielding better estimation on the latent clear image. The overall learning procedure over scales is summarized in Algorithm 3 with more details introduced as follows. Similar to the kernel estimation in Section III, given scale s and iteration t, we simplify (s, t) as (t) to more clearly present the learning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Learning algorithm</head><p>We greedily learn the GST parameters for each iteration using the gradient descent method, and the partial derivative of loss function L (t) i (θ) w.r.t. θ (t) needs to be computed first. The updating rules of blur kernel k and the latent gradient image d in Section III are specially designed as one-step ALM solutions, which make the loss function differentiable. From Eqns. ( <ref type="formula" target="#formula_26">19</ref>), ( <ref type="formula" target="#formula_30">22</ref>), <ref type="bibr" target="#b28">(29)</ref>, and (30), we have the following observations:</p><formula xml:id="formula_50">• L (t) i (θ) is a function of d (t) i and k (t) i ; • d (t) i is a function of w (t) i and λ (t) ; • w (t) i is a function of p (t) ; • k (t)</formula><p>i is a function of λ (t) . With these observations, the partial derivative of loss function L (t) i (θ) w.r.t. θ can be written as,</p><formula xml:id="formula_51">∂L (t) i ∂θ = α (t) ∂L (t) d i ∂p , α (t) ∂L (t) d i ∂λ + ∂L (t) k i ∂λ . (<label>31</label></formula><formula xml:id="formula_52">)</formula><p>The partial derivative of (t) i w.r.t. p only includes the partial derivative of L d (t) i w.r.t. p, which based on Eq. ( <ref type="formula" target="#formula_30">22</ref>) can be obtained by</p><formula xml:id="formula_53">∂L (t) d i ∂p = ∂L (t) d i ∂d (t) i ∂d (t) i ∂w (t) i ∂w (t) i ∂p = β (t) / d gt i d (t) i -d gt i T Ω -1 ∂w (t) i ∂p . (<label>32</label></formula><formula xml:id="formula_54">)</formula><p>The partial derivative of w (t) i w.r.t. p can be obtained based on Eq. ( <ref type="formula" target="#formula_26">19</ref>)</p><formula xml:id="formula_55">∂w (t) i ∂p =    0, if d (t) i ≤ τ (t) i , - sgn d (t) i β (t) d (t) i p-1 +p d (t) i p-1 ln d (t) i ,else,<label>(33)</label></formula><p>where the threshold τ</p><formula xml:id="formula_56">(t)</formula><p>i in Eq. ( <ref type="formula" target="#formula_28">20</ref>) is approximated by setting p as p (t-1) .</p><p>As to the partial derivative of L </p><formula xml:id="formula_57">∂L (t) d i ∂λ = ∂L (t) d i ∂di (t) ∂d (t) i ∂λ =1/ σ 2 n d gt i d (t) i -d gt i T Ω -1 A T k ∇y i -A T k A k . (<label>34</label></formula><formula xml:id="formula_58">)</formula><p>and then based on Eq. ( <ref type="formula" target="#formula_39">29</ref>), the partial derivative of L (t) ki w.r.t. λ can be obtained by</p><formula xml:id="formula_59">∂L (t) k i ∂λ = ∂L (t) k i ∂k (t) i ∂k (t) i ∂λ = 1/ σ 2 n k gt i k (t) i -k gt i T Φ -1 A T d ∇y i -A T d A d . (<label>35</label></formula><formula xml:id="formula_60">)</formula><p>Once the partial derivative of L (t) (θ) w.r.t. θ is obtained, the optimal θ (t) can be obtained by any gradient descent method, and we adopt the gradient-based L-BFGS method <ref type="bibr" target="#b48">[49]</ref>. On scale s, the procedures of learning iteration-wise GST operators are summarized in Algorithm 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Learning GST operators over scales</head><p>Input: Training set D, scale number S Output:</p><p>{θ (S-1,t) } T t=1 , ..., {θ (s,t) } T t=1 , ..., {θ (0,t)} T t=1 1: Denoting θ as α, µ, β, δ1, δ2, δ3 and initializing θ (S,T ) 2: for s = S -1 to 0 do Initializing θ (s,1) as θ (s+1,T )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Inputing D (s) and θ (s,1) to Algorithm 4 to learn the optimal parameters of scale s, i.e. {θ (s,t) } T t=1 6: end for Algorithm 4 Learning GST operators on scale s Input: Training set D and α (1) , µ (1) , β (1) , δ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output:</head><p>θ (1) , ..., θ (t) , ..., θ (T ) 1: for t = 1 to T do  Using gradient based L-BFGS method to search optimal θ (t)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Updating α (t+1) , µ (t+1) and penalty parameters β (t+1) ,δ </p><formula xml:id="formula_61">(t+1) 1 , δ<label>(t+1) 2 , δ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation</head><p>In our implementation, some extra constraints are taken to improve the robustness and stability of the learned iterationwise GST operators. In <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>, the regularization parameter λ begins with some small value and gradually increases along with the iteration numbers. As to the p value, p = 0 is first adopted to estimate the blur kernel, and then p = 0.5 is adopted for the final restoration <ref type="bibr" target="#b15">[16]</ref>. As a summary, both λ and p values should be non-decreasing along with the iteration numbers. Thus, in our greedy learning procedure, for each scale s, the non-decreasing constraints on both λ and p are imposed, i.e., λ (s,t+1) ≥ λ (s,t) and p (s,t+1) ≥ p (s,t) , and over the scales, it is reasonable to consider the constraints λ (s-1,1) ≥ λ (s,T ) and p (s-1,1) ≥ p (s,T ) . As to the search range, λ is constrained in [0.5, 5], and p is constrained in</p><formula xml:id="formula_62">[-1, 0.2].</formula><p>Moreover, we set the scale number S = 5, the number of inner iterations in each scale T = 20, and the dowmsampling rate as 2. Thus, there are 200 GST parameters to be learned in the proposed iteration-wise MAP framework. Other parameters, including regularization weight µ and penalty parameters β, δ 1 , δ 2 , δ 3 , should also be non-decreasing along with the scales and iterations. Specifically, the regularization weight µ on blur kernel k is initialized as 1 × 10 -6 , and updated by µ (t+1) = min 1.1 × µ (t) , 1 × 10 -3 . The penalty parameter β is initialized as 1×10 -4 , and updated by β (t+1) = min 1.5 × β (t) , 1 × 10 -2 . The three δs are initialized as 1×10 -3 , and updated by δ (t+1) = min 1.1 × δ (t) , 1 × 10 -1 . Moreover, we use the noise estimation method <ref type="bibr" target="#b49">[50]</ref> to estimate the std. of the additive Gaussian white noise, and it is assumed in the range</p><formula xml:id="formula_63">[1 × 10 -3 , 1 × 10 -2 ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discussion</head><p>Our learning method is conceptually similar to the cascade of shrinkage field (CSF) <ref type="bibr" target="#b24">[25]</ref>, which also adopts the discriminative learning approach to learn the iteration-wise image priors on filter responses. After greedy learning of the parameters iteration-by-iteration, a joint learning over iterations is performed to globally fine-tune the iteration-wise parameters. However, the CSF is designed for non-blind deconvolution, while our model is designed for blind deconvolution where the robust blur kernel estimation can be achieved by the learned GST operators. Moreover, we adopt the multi-scale scheme to learn the iteration-wise GST operators over scales and iterations, while CSF only learns the parameters at the finest scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>For quantitative evaluation, two benchmark datasets of blurry images are used to test the performance of the proposed method, where Levin et al.'s dataset <ref type="bibr" target="#b0">[1]</ref> is adopted to illustrate the learnability of iteration-wise GST operators, and Sun et al.'s dataset <ref type="bibr" target="#b20">[21]</ref> is employed to validate the generalization of the proposed method to other blurry images. To evaluate the restoration quality, we use three quantitative metrics, i.e., PSNR, SSIM <ref type="bibr" target="#b50">[51]</ref>, and error ratio <ref type="bibr" target="#b0">[1]</ref> which is defined as,</p><formula xml:id="formula_64">Error Ratio = x gt -xk / x gt -xk gt ,<label>(36)</label></formula><p>where xk and xk gt are the recovered images using the estimated blur kernel k and the groundtruth blur kernel k gt , respectively. To evaluate the computational efficiency, we report the CPU running time. Our method is compared with several competing methods, including three edge-based MAP approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref> and one VB approach <ref type="bibr" target="#b1">[2]</ref>. All the experiments were ran on a computer with 3.30GHz Intel(R) Xeon(R) CPU. We further evaluate the proposed method on real world blurry images, and compare it with two state-of-the-art edgebased uniform deblurring approaches <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21]</ref>. The reason to choose these methods is that they are the top two competing methods based on the quantitative metrics on the two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training the iteration-wise priors</head><p>Levin et al.'s dataset <ref type="bibr" target="#b0">[1]</ref> contains 4 clear images and 8 blur kernels, and is used to determine model parameters and to demonstrate the feasibility of the proposed discriminative learning method. In the learning procedure, the trade-off parameter α (s,t) is introduced to balance the contributions of the blur kernel k and the image gradient d terms in Eq. <ref type="bibr" target="#b29">(30)</ref>, where a small α is first adopted to avoid the trivial delta kernel solution and subsequently α is increased to guide the algorithm to converge to the groundtruth blur kernel and clear image. Thus, α (s,t) is initialized with a sufficiently small number, i.e., α (S-1,1) = 1 × 10 -3 , and gradually increases along with the training iterations, i.e., α (s,t+1) = min(ρα (s,t) , 1).</p><p>We analyze the effect of the increasing rate ρ. Fig. <ref type="figure" target="#fig_5">3</ref> shows the learned GST parameters obtained using three ρ values, i.e., 1.0, 1.1, 1.2. For any ρ, both λ and p begin with small values and then gradually increase along with scales and iterations, validating the consistency of the trend for dynamic selection of GST operators for kernel estimation. The larger ρ = 1.2 makes α increase more rapidly, making the learned GST parameters also increase rapidly. Specially, when ρ = 1.0, the α is fixed to its initial value 1 × 10 -3 , and the contribution of the image gradient d term keeps constant. Table I lists the mean PSNR, SSIM and Error Ratio values using the learned GST operators with different ρ values. In terms of all the three quantitative metrics, our learning method with ρ = 1.1 leads to the best results, and thus ρ = 1.1 is adopted in the following experiments. To validate the effectiveness of iteration-wise priors, we also consider two variants of our method by fixing the p value as 1057-7149 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. -1 (i.e. Ours(-1)) and 0.2 (i.e. Ours(0.2)), while the other parameters remain the same with our method (i.e., Ours).</p><p>From Table <ref type="table" target="#tab_5">II</ref>, the proposed method with iteration-wise p values outperforms Ours(0.2) and Ours(-1) in terms of all the three performance metrics. Fig. <ref type="figure">5</ref> shows the deblurring results using these three methods. One can see that the proposed method with iteration-wise p values can obtain more accurate estimation of blur kernel and visually more pleasing result of the deblurring image, validating the superiority of iterationwise priors against the fixed ones. We further evaluate the stability of the learned parameters from two aspects. In these experiments, except the iterationwise λ and p values we keep the other parameters unchanged. First, we fit these curves with the modified logistic function to avoid the storage of the learned paramters. As shown in Fig. <ref type="figure" target="#fig_5">3</ref> and Table <ref type="table" target="#tab_5">II</ref>, the fitted curves can well approximate the learned parameters, and the results based on the fitted curves are moderately inferior to those based on the learned curves. Considering that our method has 200 parameter values to store, we still report the results of our method based on the learned optimal parameters in the following experiments. Second, we use another synthetically blurred dataset to re-train the iteration-wise priors. The dataset contains 10 clear images with diverse contents and 8 blur kernels randomly selected from the dataset <ref type="bibr" target="#b51">[52]</ref>. Then the learned priors were applied to Levin et al.'s dataset. Table <ref type="table" target="#tab_5">II</ref> shows that the re-trained priors can also produce satisfying results. Since the images and blur kernels are quite different from Levin et al.'s dataset, it is reasonable that the results by the newly trained parameters are marginally inferior to our method based on the original parameter curves. Therefore, we conclude that the learned parameters are stable with the training dataset, and one can obtain similar performance by using the learned parameters on other training datasets.</p><p>Finally, we compare the proposed method with five competing approaches, including four MAP approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref> and one VB approach <ref type="bibr" target="#b1">[2]</ref>. The three quantitative metrics and running time of all the methods are listed in Table <ref type="table" target="#tab_5">II</ref>. In terms of all three quantitative metrics, the proposed method performs much better than the gradient-based methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15]</ref> and is even a little better than Sun et al.'s patchbased method <ref type="bibr" target="#b20">[21]</ref>. Fig. <ref type="figure">6</ref> shows the curves of the accumulated error ratios, and the proposed method succeeds in recovering 100% cases with the error ratio below 3, which is deemed as the threshold for visually plausible perception. Moreover, we provide the mean PSNR and SSIM values w.r.t. each individual blur kernel, as shown in Fig. <ref type="figure">7</ref>, from which one can see that the proposed method can achieve the best deblurring quality in general. Fig. <ref type="figure" target="#fig_11">4</ref> shows the visual deblurring results of one blurry image. The blur kernel estimated by our method is more accurate than the other methods, leading to more visually plausible latent image. As to the computational efficiency, the proposed method is slower than the methods of Cho &amp; Lee <ref type="bibr" target="#b11">[12]</ref> and Xu &amp; Jia <ref type="bibr" target="#b15">[16]</ref>, partially due to their optimized implementations in C/C++, but is more than 15 times faster than Sun et al. <ref type="bibr" target="#b20">[21]</ref>.    stage, for fair comparison the same method <ref type="bibr" target="#b52">[53]</ref> is used to perform the final deblurring for each of the competing methods.</p><p>Table <ref type="table" target="#tab_6">III</ref> lists the three quantitative metrics and running time of all the methods on Sun et al.'s dataset, and the proposed method achieves better results than all the competing methods. It is interesting to note that, our method is nearly 40 times faster than Sun et al. <ref type="bibr" target="#b20">[21]</ref>, partially because the test image sizes from Sun et al.'s dataset is generally much larger than those from Levin et al.'s dataset. Moreover, the proposed method with iteration-wise p values is also superior to Ours(0.2) and Ours(-1) on Sun et al.'s dataset, which demonstrates that the superiority of iteration-wise priors can be well generalized to other blurry images. In Fig. <ref type="figure" target="#fig_0">11</ref>, the deblurring result with iteration-wise p values obviously suffers less artifacts at windwill.</p><p>As shown in Fig. <ref type="figure">8</ref>, when the error ratio is more than 2.6, the proposed method achieves the best success rate. As illustrated in Fig. <ref type="figure" target="#fig_13">9</ref>, in terms of both PSNR and SSIM, our method can obtain better deblurring quality for 5 out of 8 kernels. Fig. <ref type="figure" target="#fig_0">10</ref> shows the visual effect comparison of the competing methods, where our method performs better in recovering detailed textures. In Fig. <ref type="figure" target="#fig_1">12</ref>, although all the methods can not accurately estimate the blur kernel, our deblurring result is more visually plausible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation on real blurry images</head><p>In this subsection we evaluate the performance of the proposed method on real blurry photographs, and compare it with the the top two competing methods based on Tables II and III, i.e., Xu &amp; Jia <ref type="bibr" target="#b15">[16]</ref> and Sun et al. <ref type="bibr" target="#b20">[21]</ref>. Fig. <ref type="figure" target="#fig_10">13</ref> shows the deblurring results on three real blurry images. For the image roma, our method and Sun et al.'s method can achieve satisfactory deblurring results, while the result by Xu &amp; Jia has visible color distortions in the red close-up. The second image is taken in low light condition. The results by Xu &amp; Jia and Sun et al. suffer severe distortions and noise in the red and green close-ups, while the result by our method is more clear and visually plausible. Moreover, the third image vehicle is severely blurred, and our method achieves much better result. For example, the license number can be roughly read as "N15 5826" from the deblurring result by our method, but it is difficult to be recognized from the results by both Xu &amp; Jia <ref type="bibr" target="#b15">[16]</ref> and Sun et al. <ref type="bibr" target="#b20">[21]</ref>. For the green and yellow close-ups, although all the results are not good, the result by our method is visually more pleasant, while the distortions like ringing effects are much more severe for Xu &amp; Jia and Sun et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS</head><p>In this paper, by generalizing the GST operator to the case with p &lt; 0, we proposed an iteration-wise MAP framework for blind deconvolution. Then a discriminative learning method was developed to learn iteration-wise GST operators from a blurry image set. The learned GST operators begin with p &lt; 0 to avoid trivial delta kernel solution, and gradually increase with iterations for accurate blur kernel estimation. The proposed method can be directly applied to other dataset and real world blurry images. Experimental results showed that the proposed method performs better than the competing methods in terms of both quantitative metrics and visual effect, and is much faster than the state-of-the-art patch-based method <ref type="bibr" target="#b20">[21]</ref>.</p><p>The proposed iteration-wise learning method was designed on the image gradients, and thus has limitations to model patch-level structures. In our future work, we will investigate the appropriate framework learn iteration-wise priors for image patches or filter responses. Moreover, to improve kernel estimation performance, joint learning over iterations can also be used to fine-tune the greedily learned parameters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the GST operators with different p values, intermediate edge images and estimated blur kernels. The GST operator is the solution to the p-norm minimization problem x = arg minx 12 (x -y) 2 + λ|x| p , and in the left plot the horizontal and vertical axes are denoted by y and x, respectively. In the initial stage, the GST operator with negative p value can impose a larger threshold for suppressing small-scale textures and magnifying the salient edges. Then, by gradually increasing the p values along with iteration, we can include more gradient details for refining the kernel estimation.</figDesc><graphic coords="2,238.90,64.53,74.45,74.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The proposed iteration-wise learning framework employs the coarse-to-fine strategy. In the learning stage, given the scale s, the iteration-wise GST operators can be greedily learned from the downsampled training dataset D (s) , and in the deblurring stage, the learned iteration-wise GST operators are used for blur kernel estimation.</figDesc><graphic coords="3,136.87,273.37,61.98,62.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 10: end for 11 :</head><label>311</label><figDesc>k = k (t) and d = d(t)   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(gt) i of the clear image, the blur kernel k (gt) i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 :</head><label>3</label><figDesc>Downsampling training set D to D(s)   4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>for i = 1 to N do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>LogisticFigure 3 :</head><label>3</label><figDesc>Figure 3: The learned iteration-wise p and λ values for each scale and iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of deblurring results on Levin et al.'s dataset.</figDesc><graphic coords="10,140.00,183.92,81.22,81.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 5 : 7 :Figure 8 :</head><label>578</label><figDesc>Figure 5: Example of deblurring results of the three variants of our method on Levin et al's dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Mean PSNR and SSIM of each kernel on Sun et al.'s dataset. methods from left to right are Krishnan et al. [15], Cho &amp; Lee [12], Levin et al. [2], Xu &amp; Jia [16], Sun et al. [21], and Ours, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>d Learning Stage Deblurring Stage Training set D</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">( , ) s t</cell><cell> </cell><cell>( , ) s t 2</cell><cell>( , ) s t i</cell><cell>( , ) s gt</cell><cell>2</cell><cell>( , ) s gt</cell><cell>1 2</cell><cell>( , ) s t</cell><cell>( , ) s gt</cell><cell>2</cell><cell>( , ) s gt</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>if</cell><cell>t T </cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Updating</cell><cell cols="2"></cell><cell cols="2">s t</cell><cell>,</cell><cell>p</cell><cell>s t</cell><cell>to</cell><cell>s t  </cell><cell>,</cell><cell>p</cell><cell>s t</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t t  </cell><cell cols="2">1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">else</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Upsamping 1 s s  </cell><cell cols="2">k</cell><cell cols="2">s T</cell><cell cols="2">and</cell><cell>d</cell><cell>s T</cell><cell>as</cell><cell>k</cell><cell>s</cell><cell></cell><cell>,1)</cell><cell>and</cell><cell>d</cell><cell>( 1,1) s </cell><cell>NO</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">endif</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scale 0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>&amp;</cell><cell>YES</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Iteration T</cell></row><row><cell>Input</cell><cell>k</cell><cell>(0)</cell><cell>and</cell><cell>y</cell><cell cols="2">k</cell><cell cols="2">( , ) s t</cell><cell cols="4">and</cell><cell></cell><cell cols="2">( , ) s t</cell><cell>Iteration t in scale s</cell><cell>Output and k</cell><cell>x</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2531905, IEEE Transactions on Image Processing</figDesc><table /><note><p><p>)</p>1057-7149 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2531905, IEEE Transactions on Image Processing</figDesc><table><row><cell>6</cell></row></table><note><p><p>)</p>1057-7149 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table I :</head><label>I</label><figDesc>The results on Levin et al.'s dataset<ref type="bibr" target="#b0">[1]</ref> by our learning methods with different ρ values</figDesc><table><row><cell></cell><cell>PSNR</cell><cell>SSIM</cell><cell>Error Ratio</cell></row><row><cell>ρ = 1.2</cell><cell>30.88</cell><cell>0.9198</cell><cell>1.2303</cell></row><row><cell>ρ = 1.1</cell><cell>30.91</cell><cell>0.9238</cell><cell>1.2210</cell></row><row><cell>ρ = 1.0</cell><cell>30.24</cell><cell>0.9076</cell><cell>1.2635</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table II :</head><label>II</label><figDesc>Comparisons of mean PSNR, mean SSIM, mean error ratio and mean running time (seconds) on Levin et al.'s dataset<ref type="bibr" target="#b0">[1]</ref>.</figDesc><table><row><cell></cell><cell>PSNR</cell><cell>SSIM</cell><cell>Error Ratio</cell><cell>Time</cell></row><row><cell>Known k</cell><cell>32.31</cell><cell>0.9385</cell><cell>1.0000</cell><cell>-</cell></row><row><cell>Krishnan et al. [15]</cell><cell>28.26</cell><cell>0.8547</cell><cell>2.3746</cell><cell>8.9400</cell></row><row><cell>Cho &amp; Lee [12]</cell><cell>28.83</cell><cell>0.8801</cell><cell>1.5402</cell><cell>1.3951</cell></row><row><cell>Levin et al. [2]</cell><cell>28.79</cell><cell>0.8922</cell><cell>1.5592</cell><cell>78.263</cell></row><row><cell>Xu &amp; Jia [16]</cell><cell>29.45</cell><cell>0.9000</cell><cell>1.4071</cell><cell>1.1840</cell></row><row><cell>Sun et al. [21]</cell><cell>30.85</cell><cell>0.9191</cell><cell>1.2244</cell><cell>191.03</cell></row><row><cell>Ours(-1)</cell><cell>28.63</cell><cell>0.8899</cell><cell>1.6235</cell><cell>10.403</cell></row><row><cell>Ours(0.2)</cell><cell>29.08</cell><cell>0.9057</cell><cell>1.4181</cell><cell>10.830</cell></row><row><cell>Ours(Logistic)</cell><cell>30.89</cell><cell>0.9214</cell><cell>1.2228</cell><cell>10.549</cell></row><row><cell>Ours(Re-train)</cell><cell>30.80</cell><cell>0.9188</cell><cell>1.2257</cell><cell>10.981</cell></row><row><cell>Ours</cell><cell>30.91</cell><cell>0.9238</cell><cell>1.2210</cell><cell>10.998</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table III :</head><label>III</label><figDesc>Comparisons of mean PSNR, mean SSIM, mean error ratio and mean running time (seconds) on Sun et al.'s dataset<ref type="bibr" target="#b20">[21]</ref>.</figDesc><table><row><cell></cell><cell>PSNR</cell><cell>SSIM</cell><cell>Error Ratio</cell><cell>Time</cell></row><row><cell>Known k</cell><cell>32.35</cell><cell>0.9536</cell><cell>1.0000</cell><cell>-</cell></row><row><cell>Krishnan et al. [15]</cell><cell>22.76</cell><cell>0.8136</cell><cell>6.8351</cell><cell>159.29</cell></row><row><cell>Cho &amp; Lee [12]</cell><cell>26.13</cell><cell>0.8624</cell><cell>5.0731</cell><cell>10.518</cell></row><row><cell>Levin et al. [2]</cell><cell>24.64</cell><cell>0.8606</cell><cell>4.5798</cell><cell>518.59</cell></row><row><cell>Xu &amp; Jia [16]</cell><cell>28.11</cell><cell>0.9016</cell><cell>3.2843</cell><cell>6.2940</cell></row><row><cell>Sun et al. [21]</cell><cell>29.32</cell><cell>0.9200</cell><cell>2.4036</cell><cell>3911.1</cell></row><row><cell>Ours(-1)</cell><cell>28.03</cell><cell>0.9032</cell><cell>3.2083</cell><cell>99.193</cell></row><row><cell>Ours(0.2)</cell><cell>28.58</cell><cell>0.9152</cell><cell>2.9802</cell><cell>98.231</cell></row><row><cell>Ours</cell><cell>29.35</cell><cell>0.9231</cell><cell>2.3901</cell><cell>98.071</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank the associate editor and the anonymous reviewers for their constructive suggestions.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported by NSFC grant (61271093), the program of ministry of education for new century excellent talents (NCET-12-0150), and the Hong Kong RGC General Research Fund (PolyU 5313/12E).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation on Sun et al.'s dataset</head><p>Sun et al.'s dataset <ref type="bibr" target="#b20">[21]</ref> includes 80 clear images and 8 blur kernels, which is used to test the generalization capability of the learned GST operators. In the blur kernel estimation stage, the proposed method directly adopts the iteration-wise GST operators learned on Levin et al.'s dataset to the blurry images from Sun et al.'s dataset <ref type="bibr" target="#b20">[21]</ref>. In the non-blind deconvolution  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding and evaluating blind deconvolution algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient marginal likelihood optimization in blind deconvolution</title>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Variational bayesian blind deconvolution using a total variation prior</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Babacan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="26" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="787" to="794" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian blind deconvolution with general sparse image priors</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Babacan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Analysis of bayesian blind deconvolution</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Blind deconvolution via lower-bounded logarithmic image priors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Perrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Diethelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Total variation blind deconvolution</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="375" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Total variation blind deconvolution -the devil is in the details</title>
		<author>
			<persName><forename type="first">D</forename><surname>Perrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint map estimation for blind deconvolution: when does it work</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Rameshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Velmurugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Indian Conference on Computer Vision, Graphics and Image Processing</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deblurring low-light images with light streaks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast motion deblurring</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Two-phase kernel estimation for robust motion deblurring</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Psf estimation using sharp edge prediction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Blind deconvolution using a normalized sparsity measure</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unnatural l0 sparse representation for natural image deblurring</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Structure extraction from texture via relative total variation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A generalized iterated shrinkage algorithm for non-convex sparse coding</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">High-quality motion deblurring from a single image</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Motion deblurringalgorithms and systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Rajagopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Edge-based blur kernel estimation using patch priors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on computational photography (ICCP)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discriminative learning of iteration-wise priors for blind deconvolution</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast image deconvolution using hyper-laplacian priors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Filter forests for learning data-dependent convolutional kernels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fanello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Keskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Pattaccini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Paek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Shrinkage fields for effective image restoration</title>
		<author>
			<persName><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A machine learning approach for non-blind image deconvolution</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Discriminative non-blind deblurring</title>
		<author>
			<persName><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mrf-based blind image deconvolution</title>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Blind deblurring using internal patch recurrence</title>
		<author>
			<persName><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Blur kernel estimation using normalized color-line priors</title>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sparse representation based blind image deblurring</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Blind image deblurring based on sparse prior of dictionary pair</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deblurring face images with exemplars</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Blind deconvolution using alternating maximum a posteriori estimation with heavytailed priors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kotera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Šroubek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Analysis of Images and Patterns</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Direct method for restoration of motion-blurred images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yitzhaky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lantzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kopeika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA A</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1512" to="1519" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Psf estimation via gradient domain correlation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="386" to="392" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Blind image deblurring using spectral properties of convolution operators</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="5047" to="5056" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Blur-kernel estimation from spectral irregularities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hybrid image deblurring by fusing edge and power spectrum information</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Blind deconvolution with non-local sparsity reweighting</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1311.4029</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An iterative shrinkage approach to totalvariation image restoration</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Michailovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1281" to="1299" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fast total-variation based image restoration based on derivative augmented lagrangian method</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Inverse kernels for fast spatial deconvolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Iteratively reweighted algorithms for compressive sensing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on Acoustics, speech and signal processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A content-aware image prior</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An unconstrained lq minimization with 0 ≤ q ≤ 1 for sparse solution of underdetermined linear systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="101" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Thresholding-based iterative selection procedures for model selection and shrinkage</title>
		<author>
			<persName><forename type="first">Y</forename><surname>She</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="384" to="415" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Discriminatively trained and-or graph models for object shape detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="959" to="972" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">minfunc: unconstrained differentiable multivariate optimization in matlab</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="http://www.cs.ubc.ca/∼schmidtm/Software/minFunc.html" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scale invariance and noise in natural images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Recording and playback of camera shake: Benchmarking blind deconvolution with a real-world database</title>
		<author>
			<persName><forename type="first">R</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">he was a Visiting Professor in Microsoft Research Asia. He is currently a Professor in the School of Computer Science and Technology, Harbin Institute of Technology. His current research interests include discriminative learning, image modeling, low level vision, and biometrics. Dr. Zuo has published more than 50 papers in top tier academic journals and conferences including IJCV</title>
		<author>
			<persName><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, ICCV, ECCV, and NIPS</title>
		<meeting><address><addrLine>T-NNLS, T-IFS</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004-11">2007. July 2004 to December 2004. November 2005 to August 2006. July 2007 to February 2008. August 2009 to February 2010</date>
		</imprint>
		<respStmt>
			<orgName>Harbin Institute of Technology, Harbin, China ; The Hong Kong Polytechnic University</orgName>
		</respStmt>
	</monogr>
	<note>he was a Research Assistant at the Department of Computing. Dr. Zuo is a Senior Member of IEEE, an Associate Editor of the IET Biometrics, and the Guest Editors of Neurocomputing and Pattern Recognition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
