<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems</title>
				<funder ref="#_z3PNbmY">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_tUnpRun">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_YbRZgfH">
					<orgName type="full">Fonds de la Recherche Scientifique -FNRS</orgName>
				</funder>
				<funder ref="#_H2QSfmk">
					<orgName type="full">Fonds Wetenschappelijk Onderzoek -Vlaanderen</orgName>
				</funder>
				<funder ref="#_V7yyK4X">
					<orgName type="full">Research Council KU Leuven</orgName>
				</funder>
				<funder ref="#_JwCKkzZ">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
				<funder>
					<orgName type="full">Optimal Primal-Dual Algorithms (APDO)</orgName>
				</funder>
				<funder ref="#_uXvAdAa #_6b2e5hA #_yYbP849 #_FhDSJxd #_6zdmhMX">
					<orgName type="full">Research Foundation Flanders (FWO)</orgName>
				</funder>
				<funder ref="#_43RphbU">
					<orgName type="full">Swiss National Science Foundation</orgName>
					<orgName type="abbreviated">SNSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-02-20">20 Feb 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Pethick ?puya Latafat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Panagiotis</forename><surname>Patrinos</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Fercoq</surname></persName>
						</author>
						<author>
							<persName><forename type="first">;</forename><surname>Volkan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cevher</forename><surname>?bstract</surname></persName>
						</author>
						<title level="a" type="main">Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-02-20">20 Feb 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2302.09831v1[math.OC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces a new extragradient-type algorithm for a class of nonconvex-nonconcave minimax problems. It is well-known that finding a local solution for general minimax problems is computationally intractable. This observation has recently motivated the study of structures sufficient for convergence of first order methods in the more general setting of variational inequalities when the so-called weak Minty variational inequality (MVI) holds. This problem class captures non-trivial structures as we demonstrate with examples, for which a large family of existing algorithms provably converge to limit cycles. Our results require a less restrictive parameter range in the weak MVI compared to what is previously known, thus extending the applicability of our scheme. The proposed algorithm is applicable to constrained and regularized problems, and involves an adaptive stepsize allowing for potentially larger stepsizes. Our scheme also converges globally even in settings where the underlying operator exhibits limit cycles.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many machine learning applications, from generative adversarial networks (GANs) to robust reinforcement learning, result in nonconvex-nonconcave constrained minimax problems, which pose notorious difficulties to the scalable first order methods. Indeed, there is no shortage of results illustrating divergent or cycling behavior when going beyond minimization problems <ref type="bibr" target="#b3">(Bena?m &amp; Hirsch, 1999;</ref><ref type="bibr" target="#b16">Hommes &amp; Ochea, 2012;</ref><ref type="bibr" target="#b27">Mertikopoulos et al., 2018b;</ref><ref type="bibr" target="#b17">Hsieh et al., 2021)</ref>.</p><p>Traditionally, minimax problems have been studied for more than half a century under the umbrella of the variational inequalities (VIs). The extragradient-type algorithms from the VI literature was recently brought to the awareness of the machine learning community <ref type="bibr">(Mertikopoulos et al., 2018a;</ref><ref type="bibr" target="#b12">Gidel et al., 2018;</ref><ref type="bibr" target="#b5">B?hm et al., 2020)</ref>, and have provided a principled way of stabilizing training and avoiding Poincar? recursions. However, these results mostly concern the convex-concave setting.</p><p>In nonconvex-nonconcave minimax problems, or more generally nonmonotone variational inequalities (VIs), even finding a local solution is in general intractable. This has been made precise through exponential lower bound of the classical optimization type <ref type="bibr" target="#b15">(Hirsch &amp; Vavasis, 1987)</ref> and computational complexity results <ref type="bibr" target="#b30">(Papadimitriou, 1994;</ref><ref type="bibr">Daskalakis et al., 2021b)</ref>. This is in sharp contrast to minimization problems, where only finding a global solution is intractable. The recent result of <ref type="bibr" target="#b17">(Hsieh et al., 2021)</ref> provides some intuition behind this difference by showing that the asymptotic limits of most schemes, including extragradient, can converge to attracting limit cycles.</p><p>To make progress in lieu of these negative results, <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref> proposes a simple generalization of extragradient, called (EG+), that can converge to a stationary point even for a class of nonmonotone problems provided that the weak Minty variational inequality (MVI) holds. This problem class is parametrized by a constant ?, which controls the degree of nonconvexity. However, given the range of ? in <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>, the new class is still too small to include even the simplest counterexample of <ref type="bibr" target="#b17">Hsieh et al. (2021)</ref> for the general Robbins-Monro schemes.   <ref type="bibr">(Hsieh et al., 2021, Example 5</ref>.2) provides an example where the weak MVI constant ? does not satisfy algorithmic requirements of (EG+) and (EG+) does not converge to a stationary point but rather the attracting limit cycle (left). In contrast, adaptively choosing the extrapolation stepsize large enough with our new method, called (CurvatureEG+), is sufficient for avoiding the limit cycles (right). The repellant limit cycle is indicated in black and the stream plot shows the vectorfield Fz. The blue and red curves indicate multiple trajectories of the algorithms starting from initializations indicated in black. See Appendix C.4 for properties of Forsaken.</p><p>Contributions Building on the analysis in <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>, we propose a new adaptive scheme, called (CurvatureEG+), that converges even in the difficult counter example of <ref type="bibr" target="#b17">Hsieh et al. (2021)</ref> as illustrated in Fig. <ref type="figure" target="#fig_1">1</ref>. Our main contributions are summarized below.</p><p>1. We propose an adaptive extragradient-type algorithm that converges for a larger range of ?, the parameter in the weak MVI assumption (cf. Assumption I(iii)) than previously known.</p><p>2. More importantly, we show that convergence is ensured if 2? `?k ? 0, where ? k is the extrapolation stepsize. This is crucial since by selecting ? k through a backtracking procedure larger stepsizes are allowed, which in turn implies convergence for more negative values of ?, thus capturing a larger class of problems. In addition, we show that the linesearch eventually passes without triggering any backtrack if initialized based on the Jacobian of F (cf. Section 4).</p><p>3. We present a non-adaptive variant of our algorithm (CEG+), and show that for particular parameter choices (EG+) of <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>, and when ? " 0 the celebrated forwardbackward-forward (FBF) algorithm of <ref type="bibr" target="#b41">Tseng (2000)</ref> are recovered, thus unifying and generalizing both methods. We improve upon <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref> by not only relaxing the problem class but also the stepsize range. We show that our results are tight by providing a matching lower bound, thus providing a complete picture of (EG+) under weak MVI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>The community has resorted to various approaches to make progress for nonconvex-nonconcave minimax problems. One line of work focuses on deriving local convergence results <ref type="bibr" target="#b25">(Mazumdar et al., 2019;</ref><ref type="bibr" target="#b11">Fiez &amp; Ratliff, 2020;</ref><ref type="bibr" target="#b14">Heusel et al., 2017)</ref>. For global results, the two primary approaches have been to either assume a global oracle for the inner problem <ref type="bibr" target="#b19">(Jin et al., 2019;</ref><ref type="bibr" target="#b8">Davis &amp; Drusvyatskiy, 2018)</ref> or assume particular problem structure such as the Polyak-?ojasiewicz condition <ref type="bibr" target="#b29">(Nouiehed et al., 2019;</ref><ref type="bibr" target="#b42">Yang et al., 2020)</ref> or concavity for the inner problem <ref type="bibr" target="#b33">(Rafique et al., 2019)</ref>.</p><p>We follow the same tradition of assuming structure, but from the general perspective of operator theory. The idea of studying minimax and related problems through the lens of variational inequality has a long history <ref type="bibr" target="#b28">(Minty, 1962;</ref><ref type="bibr" target="#b35">Rockafellar, 1976;</ref><ref type="bibr" target="#b32">Polyak, 1987;</ref><ref type="bibr" target="#b4">Bertsekas, 1997)</ref>, with recent renewed interest due to its relevance for minimax formulations <ref type="bibr">(Mertikopoulos et al., 2018a;</ref><ref type="bibr" target="#b12">Gidel et al., 2018;</ref><ref type="bibr" target="#b0">Azizian et al., 2020)</ref>.</p><p>One relaxation of the monotone case for which we have positive results is that of Minty variational inequalities (MVI) <ref type="bibr">(Mertikopoulos et al., 2018a;</ref><ref type="bibr" target="#b39">Song et al., 2021;</ref><ref type="bibr" target="#b43">Zhou et al., 2017;</ref><ref type="bibr" target="#b24">Liu et al., 2021)</ref>, which includes all quasiconvex-concave and starconvex-concave problems. <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref> introduced the relaxed condition of weak MVI. In the unconstrained setting they showed non-asymptotic convergence results under a restricted problem constant ?. Similarly to us, <ref type="bibr">Lee &amp; Kim (2021a)</ref> extends the regime but under the stronger condition of cohypomonotonicity.</p><p>They do so by studying a more evolved variant of extragradient building on anchoring techniques. We instead directly improve upon (EG+) and generalize it to new settings.</p><p>In the stochastic setting, usually the stepsize for the extrapolation step is diminishing. This is the case in <ref type="bibr" target="#b5">B?hm et al. (2020)</ref> where they consider a forward-backward-forward type scheme. However, they remain in the monotone setting, where the limit cycles are non-attracting, as exemplified by a bilinear game. <ref type="bibr" target="#b17">Hsieh et al. (2021)</ref> recently showed that a large family of algorithms, which includes the extragradient method with diminishing stepsize, can converge to attracting limit cycles. Going beyond this restriction, prior to <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>, <ref type="bibr" target="#b18">Hsieh et al. (2020)</ref> interestingly considers two separate and diminishing stepsizes under the stronger assumption of MVI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem formulation and preliminaries</head><p>In this paper we are interested in finding zeros of an operator (or set-valued mapping) T : n ? n that is written as the sum of a Lipschitz continuous (but possibly nonmonotone) operator F and a maximally monotone operator A. That is, we wish to find z P n such that the general inclusion 0 P T z Az `Fz (2.1) holds. The set of all such points is denoted by zer T tz P R n | 0 P T zu. Throughout the paper problem (2.1) is studied under the following assumptions (definitions can be found in Appendix A).</p><p>Assumption I. In problem (2.1), (i) Operator A : n ? n is a maximally monotone operator.</p><p>(ii) Operator F : n ? n is L-Lipschitz continuous.</p><p>(iii) Weak Minty variational inequality (MVI) holds, i.e., there exists a nonempty set S ? ? zer T such that for all z ? P S ? and some ? P p?1 2L , 8q</p><p>xv, z ?z? y ? ?}v} 2 , for all pz, vq P gph T .</p><p>(2.2) Generally, we do not require the weak Minty assumption to hold at every z ? P zer T . In fact, as shown in Theorem 3.1 nonemptiness of S ? is sufficient for ensuring that the limit points belong to zer T . Interestingly, despite nonmonotonicity of F, global (as opposed to subsequential) convergence can be established when S ? " zer T , an assumption that is still weaker than cohypomonotonicity.</p><p>VIs provide a convenient abstraction for a range of problems. We mention some central examples below but otherwise defer to the overview in <ref type="bibr" target="#b10">Facchinei &amp; Pang (2007)</ref>. Subsequently, we provide examples where the weak MVI holds.</p><p>Example 1: (minimax optimization). A comprehensive way to capture a wide range of applications in machine learning is to consider structured minimax problems of the form minimize</p><formula xml:id="formula_0">xP nx maximize yP ny</formula><p>Lpx, yq ?px, yq `gpxq ?hpyq, (2.3) where ? is not necessarily convex in x or concave in y. Functions g and h are proper extended real-valued lower semicontinuous and convex, with easy to compute proximal maps. Common examples for g and h involve regularizers such as 1 , 2 norms, or indicator functions of sets allowing us to capture constrained minimax problems. The first order optimality condition associated with this problem may be written in the form of the structured inclusion (2.1) by letting Fz " p? x ?px, yq, ??y ?px, yqq, Az " pBgpxq, Bhpyqq.</p><p>As it will become clear in the next section (cf. Algorithm 1), the main computations involved in the proposed scheme are evaluations of F and resolvent J A " pid `Aq ?1. Recall that the resolvent of a maximally monotone operator is firmly nonexpansive with full domain <ref type="bibr">(cf. (Bauschke &amp; Combettes, 2017, Sect. 23)</ref>). If A " B f is the subdifferential operator of a convex function f , then its resolvent is the proximal mapping. For instance when A is as in Example 1, then its resolvent is given by J A px, yq " pprox g pxq, prox h pyqq.</p><p>Example 2: (N-player games). More generally, we can consider a continuous game of N players in normal form. Denote the decision variables z :" pz i ; z ?iq :" pz 1 , ..., z N q and let the loss incurred by the i th player be L i pz i ; z ?iq " ? i pzq `gi pz i q where ? i is the payoff function and g i typically enforce constraints on z i . Then we seek a Nash equilibrium, which is any decision which is unilaterally stable, i.e., L i pz ? i ; z ? ?iq ? L i pz i ; z ? ?iq @z i and i P rNs t1, . . . , Nu.</p><p>(2.4)</p><p>The corresponding first order optimality conditions may be written as Az " pBg 1 pz 1 q, . . . , Bg N pz N qq and Fz " p? z 1 ? 1 pzq, . . . , ? z N ? N pzqq.</p><p>A solution to (2.1) thus returns a candidate for which the first order condition of the above problems is satisfied. In the monotone case these two solution concepts coincide, while in the more general case of weak MVI, we provide examples where this still holds. In particular, we introduce in Section 5 a nonconvex-nonconcave minimax game which additionally exhibits limit cycles for Fz. As a consequence most schemes including gradient descent ascent, extragradient and optimistic gradient descent ascent do not converge to a stationary point globally <ref type="bibr" target="#b17">(Hsieh et al., 2021)</ref>. However, the global Nash equilibrium satisfies Assumption I(iii) with ? ? ?1{2L, which we show is sufficient for global convergence of (CEG+).</p><p>The weak MVI condition is satisfied in certain reinforcement learning settings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Generalizing Extragradient+</head><p>Our starting point is the Extragradient+ (EG+) algorithm of <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref> which is identical to extragradient (Korpelevich, 1976) except for the second stepsize being smaller. They only treat the inclusion (2.1) when A " 0, and in our notation require ? P p?1{8L, 0s. Specifically,</p><formula xml:id="formula_1">zk " z k ??k Fz k , z k`1 " z k ?? k ? k F zk (EG+)</formula><p>where they choose ? k " 1 {L and ?k " 1 {2 <ref type="bibr">(Diakonikolas et al., 2021, Thm. 3.2)</ref>.</p><p>We generalize (EG+) in Algorithm 1 to take the operator A into account-consequently we capture constraint and regularized problems as well. In addition, the scheme is adaptive in ?k . We will show that the weaker requirement of ? P p?1{2L, 8q suffices even for the more general inclusion (2.1).</p><p>The main convergence results of Algorithm 1 are established in the next theorem. The proof is largely inspired by recent developments in operator splitting techniques in the framework of monotone inclusions <ref type="bibr" target="#b21">(Latafat &amp; Patrinos, 2017;</ref><ref type="bibr" target="#b13">Giselsson, 2021)</ref>. The key idea lies in interpreting each iteration of the algorithm as a projection onto a certain hyperplane, an interpretation that dates back to <ref type="bibr" target="#b37">Solodov &amp; Tseng (1996)</ref>; <ref type="bibr" target="#b38">Solodov &amp; Svaiter (1999)</ref>.</p><p>Theorem 3.1. Suppose that Assumption I holds, and let ? k P p0, 2q, ? k P `t?2?u `, 1 {L ? where txu ` maxt0, xu, ? k P p ??k{2, ?s, lim inf k?8 ? k p2 ??k q ? 0, and lim inf k?8 p? k `?k{2q ? 0. Consider the sequences pz k q kP , pz k q kP generated by Algorithm 1. Then for all z ? P S ? ,</p><formula xml:id="formula_2">min k"0,1,...,m 1 ? 2 k }Hz k ?Hz k } 2 ? 1 ?pm`1q }z 0 ?z? } 2 , (3.1)</formula><p>where ? " lim inf k?8 ? k p2 ??k qp? k `?k{2q 2 . Moreover, the following holds (i) pz k q kP is bounded and its limit points belong to zer T ;</p><p>(ii) if in addition lim sup k?8 ? k ? 1 {L and S ? " zer T , then pz k q kP , pz k q kP both converge to some z ? P zer T .</p><p>Note that whenever lim sup k?8 ? k ? 1 L , Lemma A.3(ii) may be used to derive a similar inequality in terms of }z k ?zk } by lower bounding }Hz k ?Hz k } in (3.1). We also remark that tighter rates may be obtained in the regime ? ? 0, however, this will not be pursued in this work.</p><p>Algorithm 1 (AdaptiveEG+) Deterministic algorithm for problem (2.1)</p><formula xml:id="formula_3">Initialize z 0 " z init P n , ? k P p0, 2q, ? k P `t?2?u `, 1 {L ? , ? k P p ??k{2, ?s, Repeat for k " 0, 1, . . . until convergence 1.1: Let zk " `id `?k A ??1 `zk ??k Fz k 1.2: Compute stepsize ? k " ? k ? k `xz k ?zk , Hz k ?Hz k y }Hz k ?Hz k } 2 ,</formula><p>where H " id ??k F. 1.3: Update the vector z k`1 " z k `?k ? k pHz k ?Hz k q Return z k`1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Non-adaptive stepsize variant</head><p>Although we do not incur additional costs for evaluating the adaptive stepsize ? k in step 1.2, it proves instructive to present a variant with constant stepsize. As a result we compare the range of our stepsizes against <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref> showing an improvement by a factor of 3 {2. Moreover, in the monotone case (? " 0), with a certain choice of stepsizes the algorithm reduces to the celebrated forward-backward-forward (FBF) algorithm of <ref type="bibr" target="#b41">Tseng (2000)</ref>. We remark that the relation of FBF to projection-type algorithms was noted in <ref type="bibr" target="#b41">Tseng (2000)</ref>, <ref type="bibr">(Giselsson, 2021, Sect. 6.2.1)</ref>.</p><p>To this end, in this subsection consider the following non-adaptive variant of Algorithm 1 that generalizes (EG+). Letting ?k P p0, 1 `2? k{? k q:</p><formula xml:id="formula_4">zk " `id `?k A ??1 `zk ??k Fz k ?, z k`1 " z k `? k pHz k ?Hz k q. (CEG+)</formula><p>The convergence of this algorithm is an immediate byproduct of Theorem 3.1. To see this, note that the z k`1 update in step 1.3 may be written as</p><formula xml:id="formula_5">z k`1 " z k `2? k ? k pHz k ?Hz k q, for ? k P p0, 1q.</formula><p>Therefore, convergence is still ensured for any ?k ? 2? k as the difference may be absorbed by the relaxation parameter ? k . Note that by 1 {2-cocoercivity of H (cf. Lemma A.3(i))</p><formula xml:id="formula_6">?k ? 2? k ? k `1 ? 2? k ? k `2xHz k ?Hz k , zk ?zk y }Hz k ?Hz k } 2 " 2? k , (3.2)</formula><p>establishing the validity of the prescribed stepsize range. The convergence of the non-adaptive variant is summarized in the next corollary that for simplicity is stated with constant parameters (dropping subscripts k).</p><p>Corollary 3.2 (Constant stepsize). Suppose that Assumption I holds, and let ? P `t?2?u `, 1 {L ? , ? P p ??{2, ?s, and ? P p0, 1 `2? {?q. Consider the sequences pz k q kP , pz k q kP generated according to the update rule (CEG+). Then,</p><formula xml:id="formula_7">min k"0,1,...,m }Hz k ?Hz k } 2 ? }z 0 ?z? } 2 ?pm `1q , (3.3)</formula><p>where ? " ?p1 `2? ? ??q. Moreover, the claims of Theorems 3.1(i) and 3.1(ii) hold true.</p><p>The setting of <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref> in (EG+) involves the stepsizes ? k " 1 {L, ? k " 1 {2. Note that when restricting to A " 0, the iterates (CEG+) simplify to this form owing to the fact that Hz k ?Hz k " zk ??F zk ?Hz k " ??F zk . In comparison, in our setting if ? " ? " ?1{8L (the smallest ? permitted in <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>) is selected, then based on our analysis in Corollary 3.2 we may select ? k " 1 {L, and ?k P p0, 3 {4q, thus the upper bound for the second stepsize is 3 {2 times that of <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>.</p><p>Remark 3.3 (relation to FBF). In Corollary 3.2 the range of stepsizes ?, ? may alternatively be set as ? P `t?2?u `, 1 {L ?, ? P p0, 1`2 ? {?s. This is due to the fact that if ? ? 1 {L (strictly), then H is strictly 1 {2-cocoercive. Therefore, in (3.2), 1`2 ? ? ? 2? k holds, and thus the stepsize ? " 1`2 ? ? is permitted. Although this may appear to be of little practical significance, by setting ? P p0, 1 {Lq, ? " ? " 0, and ? " 1 in (CEG+), we obtain z k`1 " zk `?Fz k ??F zk , which is the forward-backward-forward (FBF) algorithm of <ref type="bibr" target="#b41">Tseng (2000)</ref>, <ref type="bibr">(Bauschke &amp; Combettes, 2017, Thm. 26.17)</ref>). The dashed line indicates where ? " ?1{8L. This is the condition under which <ref type="bibr">(Diakonikolas et al., 2021, Thm. 3.2)</ref> shows the first convergence result p?q. Corollary 3.2 improves their result by matching the lower bound for any ?, in particular for ? " 3 {4 p q. The adaptive scheme in Theorem 3.1 matches the smallest possible ? for any (EG+) scheme with fixed stepsize p q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Lower bounds</head><p>We show that the result in Corollary 3.2 is tight by providing a matching lower bound when A " 0. We do so by fixing ?k and showing a stepsize dependent lower bound. In particular, note that if ?k " 1 {2 as in <ref type="bibr">Diakonikolas et al. (2021, Thm. 3</ref>.2), then Theorem 3.4 implies a lower bound of ? ? ?1{4L for the (EG+) scheme. The lower bound is contextualized in Fig. <ref type="figure" target="#fig_2">2</ref> by relating it to our convergence results and existing results in the literature.</p><p>Theorem 3.4. Consider a sequence pz k q kPN generated according to (EG+) fixing ? k " ? " 1 {L and ?k " ? P p0, 1q. Let ??L ? 1?? 2 . Then, there exists an F : n ? n , n ? 1, satisfying Assumption I(ii) and Assumption I(iii) for which the sequence will not converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Adaptively taking larger stepsizes using local curvature</head><p>As made apparent in the analysis in Section 3 (cf. Appendix B.1) the bound on the smallest weak MVI constant ? in Assumption I(iii) may be replaced with the requirement that ? ? ??k{2 for all k P . Therefore, larger stepsizes ? k would guarantee global convergence for an even larger class of problems. Since a global Lipschitz constant is inherently pessimistic the natural question then becomes how to locally choose a maximal stepsize without diverging.</p><p>The proposed scheme involves a backtracking linesearch that uses the local curvature for its initial guess. The reason being that this will immediately pass, close enough to the solution z ? , by argument of continuity. More precisely, we will set the initial guess to something slightly smaller than }JFpz k q} ?1, where JFpzq denotes the Jacobian of F at z and } ?} is the spectral norm. Note that, despite the use of second order information, the scheme remains efficient since }JFpzq} only requires one eigenvalue computation performed through Jacobian-vector product <ref type="bibr" target="#b31">(Pearlmutter, 1994)</ref>.</p><p>Given an initial point z 0 " z init and ? P p0, 1q, the final scheme which we denote (CurvatureEG+) proceeds for k " 0, 1, . . . as follows:</p><p>1. Obtain ? k and zk according to Algorithm 2 with ? init " ?}JFpz k q} ?1 2. Compute z k`1 according to steps 1.2 and 1.3 of Algorithm 1 (CurvatureEG+)</p><p>The above intuitive reasoning is made precise in the next lemma where it is shown that backtracking linesearch will terminate in finite time and that ? init will be immediately accepted asymptotically.</p><p>Algorithm 2 Lipschitz constant backtracking Initialize z k P n , ? P p0, 1q, ? P p0, 1q 2.1: Set initial guess ? " ? init , and let G ? pz k q `id `?A ??1 `zk ??Fz k while ?}FpG ? pz k qq ?Fz k } ? ?}G ? pz k q ?zk } do ? ? ?? Return ? k " ? and zk " G ? pz k q Lemma 4.1 (Lipschitz constant backtracking). Suppose that F : n ? n is a L-Lipschitz continuous operator. Consider the linesearch procedure in Algorithm 2. Then, (i) The linesearch terminates in finite time with ? ? mint? init , ?? {Lu;</p><p>(ii) Suppose that pz k q kP converges to z ? P zer T . If F is continuously differentiable, and ? init P p0, ?}JFpz k q} ?1q with ? P p0, 1q, then eventually the backtrack will never be invoked (? init would be accepted).</p><p>The convergence results for (CurvatureEG+) are deduced based of the above lemma and Theorem 3.1 and are provided in Corollary B.1 in Appendix B.2. We illustrate the behavior of (CurvatureEG+) in Fig. <ref type="figure" target="#fig_1">1</ref> and in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Constructing toy examples</head><p>When Assumption I(iii) holds for negative ?, limit cycles of the underlying operator Fz can emerge.</p><p>We illustrate this with simple polynomial examples for which all the properties of interest can be computed in closed form.</p><p>Definition 1 (PolarGame). A PolarGame denotes a two-player game whose associated operator F has limit cycles at }z} 2 " c i for all i P rks where c i ? 0.</p><p>This turns out to be particularly easy to construct in polar coordinates as the name suggests (see Appendix C.1). Apart from introducing arbitrary number of limit cycles it also gives us control over ?. This is illustrated in the following instantiations capturing three important cases.</p><p>Example 3: (PolarGame). Consider Fz " p?px, yq ?y, ?py, xq `xq where }z} 8 ? 11 {10 and ?px, yq " 1 16 axp?1 `x2 `y2 qp?9 `16x 2 `16y 2 q. We have the following three cases: (i) a " 1 then ? P p?1 L , ?1 2L q (ii) a " 3 4 then ? P p?1 2L , ?1 3L q (iii) a " 1 3 then ? P p?1 8L , ?1 10L q where L denotes the Lipschitz constant of F restricted to the constraint set. For all cases F exhibits limit cycles at }z} " 1 and }z} " 3 {4. Proof is deferred to Appendix C.2.</p><p>Example 4: (minimax). In the particular case of constrained minimax problem we introduce the following polynomial game: minimize</p><formula xml:id="formula_8">|x|? 4 {3 maximize |y|? 4 {3 ?px, yq :" xy `?pxq ??pyq,<label>(GlobalForsaken)</label></formula><p>where ?pzq " 2z 6 21 ?z4 3 `z2 3 . We provide proof of the following properties in Appendix C.3:</p><p>(i) There exists a repellant limit cycle and an attracting limit cycle of F.</p><p>(ii) z ? " p0, 0q is a global Nash equilibrium for which Assumption I(iii) holds inside the constraint with ? ? ?1{2L, where L denotes the Lipschitz constant of F restricted to the constraint set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>The algorithms considered in the experiments include the adaptive Algorithm 1, (CurvatureEG+), and constant stepsize methods that can be seen as instances of (CEG+) for various choices of ? k and ?k . When ? k " 1 {L and ?k " 1 we recover a constrained variant of extragradient, which we denote CEG. When ?k " 1 {2 we denote the scheme CEG+, which is the direct generalization to the constraint setting of the (EG+) scheme studied in <ref type="bibr">Diakonikolas et al. (2021, Thm. 3.2)</ref>. Note that this choice of ?k restricts the problem class for which we otherwise can have guaranteed convergence according to Corollary 3.2. When ?k is chosen adaptively according to Algorithm 1 we refer to it as AdaptiveEG+. Finally, when ? k is additionally chosen adaptively we use the name (CurvatureEG+).</p><p>In the stochastic setting, when ? k " 1 {k and ? k " 1, effectively both stepsizes diminish, and we recover a constrained variant of the popular stochastic extragradient scheme (see e.g. Hsieh et al.   <ref type="formula">2021</ref>), who shows that the sequence generated by SEG can converge to limit cycles of the underlying operator F. On the other hand, we observe that SEG+ escapes the attracting limit cycle. In (b) we also provide a more challenging example motivated by our lower bound.</p><p>(2021, Algorithm 3)), which we refer to as SEG. We also consider a heuristic variant where ? k " 1 {L and only ? k is decreasing, which we refer to as SEG+.</p><p>We test the algorithms on the constructed examples and confirm their convergence guarantees. Specifically, we apply the algorithms to the minimax problem in Example 4, the PolarGames in Example 3, and a worst case construction, Example 5, from the proof of the lower bound (cf. Appendix B.3). For Example 5 we choose the problem parameters such that ? " ?1{3L according to (B.13), and additionally add an 8 -ball constraint to keep the iterates bounded. To simulate the stochastic setting we add Gaussian noise to calls of F. Results for the deterministic setting and stochastic setting can be found in Fig. <ref type="figure" target="#fig_3">3</ref> and Fig. <ref type="figure" target="#fig_4">4</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper introduced an EG-type algorithm for a class of nonconvex-nonconcave minimax problems that satisfy the weak Minty variational inequality (MVI). The range of parameter in the weak MVI was extended compared to EG+ of <ref type="bibr" target="#b9">Diakonikolas et al. (2021)</ref>, and tightness of our results were demonstrated through construction of a counter example. In addition, EG+ <ref type="bibr" target="#b9">(Diakonikolas et al., 2021)</ref>, as well as the forward-backward-forward algorithm <ref type="bibr" target="#b41">(Tseng, 2000)</ref> were all shown to be special cases of our scheme. Furthermore, (CurvatureEG+) was proposed that performs a backtracking linesearch on the extrapolation stepsize ? k allowing for larger stepsizes and relaxes the condition ? ? 1 2L to ? ? ??k{2 which is often a much weaker condition. More importantly, it is shown that asymptotically the linesearch always passes with ? k " ?}JFpz k q} ?1 for any ? P p0, 1q, thus ratifying the name (CurvatureEG+). Future direction include exploring applications of the proposed algorithm in particular in the setting of GANs. It is also interesting to develope a variance reduced variant of the algorithm for finite sum minimax problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Preliminary definitions</head><p>Notationally we will use txu ` maxt0, xu throughout. We additionally recall some standard definitions and results and refer to Bauschke &amp; Combettes (2017); <ref type="bibr" target="#b36">Rockafellar (1970)</ref>) for further details.</p><p>An operator or set-valued mapping A : n ? d maps each point x P n to a subset Ax of d . We will use the notation Apxq and Ax interchangably. We denote the domain of A by dom A tx P  <ref type="formula">2020</ref>)). An Operator A : n ? n is said to be ?-monotone for some ? P , if for all px, yq, px 1 , y 1 q P gph A ?}x ?x1 } 2 ? xx ?x1 , y ?y1 y, and it is said to be ?-comonotone if for all px, yq, px 1 , y 1 q P gph A ?}y ?y1 } 2 ? xx ?x1 , y ?y1 y.</p><p>The operator A is said to be maximally (co)monotone if its graph is not strictly contained in the graph of another (co)monotone operator.</p><p>We say that A is monotone if it is 0-monotone. When ? ? 0, ?-comonotonicity is also referred to as |?|-cohypomonotonicity. Definition A.2 (Lipschitz continuity and cocoercivity). Let D ? n be a nonempty subset of n . A single-valued operator A : D ? n is said to be L-Lipschitz continuous if for any x, x 1 P D }Ax ?Ax 1 } ? L}x ?x1 }, and ?-cocoercive if ?}Ax ?Ax 1 } 2 ? xx ?x1 , Ax ?Ax 1 y.</p><p>Moreover, A is said to be nonexpansive if it is 1-Lipschitz continuous, and firmly nonexpansive if it is 1-cocoercive.</p><p>The resolvent operator J A is firmly nonexpansive (with dom J A " n ) if and only if A is (maximally) monotone.</p><p>The following lemma plays an important role in our convergence analysis.</p><p>Lemma A.3. Let A : n ? n denote a single valued operator. Then,</p><formula xml:id="formula_9">(i) A is 1-Lipschitz if and only if T " id ?A is 1 {2-cocoercive.</formula><p>(ii) If A is L-Lipschitz, then T " id ??A, ? P p0, 1 {Lq, is p1 ??Lq-monotone, and in particular }T u ?T v} ? p1 ??Lq}u ?v} for all u, v P n .</p><p>Proof. The first claim follows directly from <ref type="bibr">(Bauschke &amp; Combettes, 2017, Prop.4.11</ref>). That T is strongly monotone is a consequence of the Cauchy Schwarz inequality and Lipschitz continuity of A:</p><p>xT v ?T u, v ?uy " }v ?u} 2 ??xAv ?Au, v ?uy ? p1 ??Lq}v ?u} 2 . In turn, the last claim follows from the Cauchy-Schwarz inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proofs and further results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Proofs of Section 3</head><p>Proof of Theorem 3.1. Let H " id ??k F. By Step 1.1 Hz k P zk `?k Az k . Therefore,</p><formula xml:id="formula_10">1 ? k pHz k ?Hz k q P Az k `F zk (B.1)</formula><p>In what follows we will show that Algorithm 1 is equivalent to taking a forward-backward step followed by a correction step. Consider the updates zk pid `?k Aq</p><formula xml:id="formula_11">?1`z k ??k Fz k ?, (B.2) z k`1 " p1 ??k qz k `?k ? D k pz k q, where D k ! w | xHz k ?Hz k , zk ?wy ? ? k ? k }Hz k ?Hz k } 2</formula><p>) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note that</head><formula xml:id="formula_12">xHz k ?Hz k , zk ?zk y `?k ? k }Hz k ?Hz k } 2 ? p 1 2 `?k ? k q}Hz k ?Hz k } 2 (B.</formula><p>3) where in the inequality Lemma A.3(i) was used. Hence, by (B.3) the stepsize ? k is positive and bounded away from zero. Moreover, if z k P D k , then from (B.3) we may conclude that }Hz k ?Hz k } ? 0 which implies that the generated sequence remains constant and zk P zer T (cf. (B.1)).</p><p>The projection onto D k for any v R D k is given by</p><formula xml:id="formula_13">? D k pvq " v `xz k ?v, Hz k ?Hz k y ??k ? k }Hz k ?Hz k } 2 }Hz k ?Hz k } 2 pHz k ?Hz k q</formula><p>Moreover, (B.1) together with Assumption I(iii) at zk yields</p><formula xml:id="formula_14">1 ? k xHz k ?Hz k , zk ?z? y ? ? ? 2 k }Hz k ?Hz k } 2 ? ? k ? 2 k }Hz k ?Hz k } 2 , (B.4) thus ensuring z ? P S ? ? D k . The projection onto D k is then given by ? D k pz k q " z k `?k pHz k ?Hz k q,</formula><p>where ? k is as in step 1.2.</p><p>Finally, since the projection ? D k is firmly nonexpansive, it follows from <ref type="bibr">(Bauschke &amp; Combettes, 2017, Cor. 4.41</ref>) that the mapping p1 ??k qid `?k ? D k is ? k{2-averaged. Consequently, we may conclude that pz k q kP is Fej?r monotone relative to S ? (Bauschke &amp; <ref type="bibr">Combettes, 2017, Prop. 4.35(iii)</ref>).</p><p>That is for all</p><formula xml:id="formula_15">z ? P S ? }z k`1 ?z? } 2 ? }z k ?z? } 2 ??k p2 ??k q? 2 k }Hz k ?Hz k } 2 . (B.3) ? }z k ?z? } 2 ??k ? 2 k }Hz k ?Hz k } 2 , (B.5)</formula><p>where ? k ? k p2?? k qp ? k 2 `?k q 2 . The convergence rate in (3.1) is obtained by telescoping (B.5). Since lim inf k?8 ? k ? 0, p 1 ? 2 k }Hz k ?Hz k } 2 q kP converges to zero. Moreover, p}z k ?z? } 2 q kP converges and the sequence pz k q kP is bounded. Since ? k is bounded, and F and the resolvents pid `?k Aq ?1 are Lipschitz continuous <ref type="bibr">(cf. (Bauschke &amp; Combettes, 2017, Cor. 23.9</ref>)), so is their composition. Hence, pz k q kP is also bounded. Let pz k q kPK be a subsequence converging to some z P n . Combined with the fact that p 1 ? 2 k }Hz k ?Hz k } 2 q kP converges to zero, we may conclude from (B.1) along with <ref type="bibr">(Bauschke &amp; Combettes, 2017, Prop. 20.38)</ref> and Lipschitz continuity of F that z P zer T . Finally, if in addition ? " lim sup k?8 ? k ? 1{L, then p1 ??Lq}z k ?zk } ? }Hz k ?Hz k } (invoke Lemma A.3(ii)). Therefore, p}z k ?zk }q kP converges to zero, which in turn implies that a subsequence pz k q kPK 1 converges to a point z 1 iff so does the subsequence pz k q kPK 1 . Hence, pz k q kPK also converges to z P zer T . Consequently, if Assumption I(iii) holds at all of the zeros of T , i.e., if S ? " zer T , then the second claim follows by invoking (Bauschke &amp; Combettes, 2017, Thm. 5.5).</p><p>Proof of Corollary 3.2 (Constant stepsize). The proof of convergence was already given prior to the statement of the corollary. It remains to derive (3.3). By Assumption I(iii) and owing to 1 {2cocoercivity of H (cf. Lemma A.3(i))</p><formula xml:id="formula_16">xz k ?z? , Hz k ?Hz k y " xz k ?z? , Hz k ?Hz k y `xz k ?z k , Hz k ?Hz k y (B.4) ? ?p 1 2 `?k ? k q}Hz k ?Hz k } 2 . (B.6)</formula><p>Therefore, provided that ? ? 0 we have</p><formula xml:id="formula_17">}z k`1 ?z? } 2 " }z k ?z? } 2 `? 2 }Hz k ?Hz k } 2 `2 ?xz k ?z? , Hz k ?Hz k y (B.6) ? }z k ?z? } 2 ??p2p 1 2 `? ? q ??q}Hz k ?Hz k } 2 .</formula><p>Telescoping the above inequality yields the claimed inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Convergence results and proofs of Section 4</head><p>The convergence results for (CurvatureEG+) are provided in the next corollary where ? in Assumption I(iii) is allowed to take potentially larger values provided that ? ? ??k{2. Note that owing to the lower bound on ? k (cf. Lemma 4.1(i)), the weak MVI assumption in the corollary is always satisfied if ? P p?? ? {2L, 8q, however, in practice ? k may take larger values. Corollary B.1. Suppose that Assumptions I(i) and I(ii) hold, and consider the sequences pz k q kP , pz k q kP generated by (CurvatureEG+). Suppose that Assumption I(iii) holds for some ? P satisfying ? k `2? ? 0, and let ? k P p ??k{2, ?s, ? k P p0, 2q, lim inf k?8 ? k p2 ??k q ? 0, and lim inf k?8 p? k `?k{2q ? 0. Then, (i) The sequence p}z k ?zk } 2 q kP vanishes;</p><p>(ii) pz k q kP , pz k q kP are bounded, and have the same limit points belonging to zer T ;</p><p>(iii) if in addition S ? " zer T , then pz k q kP , pz k q kP both converge to some z ? P zer T .</p><p>Moreover, if z k , zk ? z ? P zer T (as is the case in B.1(iii)), and F is continuously differentiable, then eventually the backtrack will never be invoked.</p><p>Proof. Observe that in the proof of Theorem 3.1 1-Lipschitz continuity of ? k F is only used at the generated points zk and z k (see (B.3)), and is thus ensured by the linesearch Algorithm 2. Therefore, it is easy to see that ? k is positive and bounded away from zero provided that ? ? ??k{2 , see (B.3). Moreover, since ? k }F zk ?Fz k } ? ?}z k ?zk }, arguing as in Lemma A.3(ii) we obtain }Hz k ?Hz k } ? p1 ??q}z k ?zk }. Hence, it follows from (B.5) that</p><formula xml:id="formula_18">}z k`1 ?z? } 2 ? }z k ?z? } 2 ??k p1??q ? 2 k }z k ?zk } 2 ,</formula><p>By telescoping the inequality and noting that ? k is bounded, we obtain ? kP }z k ?zk } 2 ? 8, implying B.1(i). Noting this and arguing as in the last part of the proof of Theorem 3.1 establishes B.1(ii), B.1(iii). The last claim is the direct consequence of Lemma 4.1(ii).</p><p>Proof of Lemma 4.1 (Lipschitz constant backtracking). 4.1(i): Since F is L-Lipschitz continuous the linesearch would terminate in finite steps. Either ? init satisfies the condition, or else the backtrack procedure is invoked, which in turn implies the previous candidate ?{? should have violated the condition leading the the claimed lower bound.</p><p>4.1(ii): Since the resolvent pid`?Aq ?1 and F are Lipschitz continous, so is their composition. Hence, G ? pz k q ? G ? pz ? q. Furthermore, by definition z ? ??Fz ? P G ? pz ? q `?ApG ? pz ? qq. Consequently, using monotonicity of A at G ? pz ? q and z ? , and that ?Fz ? P Az ? yields 0 ? xz ? ??Fz ? ?G? pz ? q Fz ? , G ? pz ? q ?z? y " ?}z ? ?G? pz ? q} 2 . Thus G ? pz ? q " z ? . Using the fact that both pG ? pz k qq kP and pz k q kP converges to z ? P zer T :</p><formula xml:id="formula_19">lim k?8 }FpG ? pz k qq ?Fz k } }G ? pz k q ?zk } ? lim sup z,z 1 ?z ? }Fz 1 ?Fz} }z 1 ?z} " lip Fpz ? q " }JFpz ? q},</formula><p>where <ref type="bibr" target="#b34">(Rockafellar &amp; Wets, 2009</ref>, Thm. 9.7) was used. The claim follows from continuity of JF and the fact that pz k q kP converges to z ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Proofs of Section 3.2</head><p>To prove the lower bound we introduce the following unconstrained bilinear minimax problem with an unstable critical point. where z " px, yq. In this particular case, both L and ? turn out to be constants. By simple calculation we have, }JFpzq} "</p><formula xml:id="formula_20">a a 2 `b2 , ? " b a 2 `b2 (B.9)</formula><p>where } ?} is the spectral norm. Since the norm of the Jacobian is constant it equates the global Lipschitz constant, L " }JFpzq}.</p><p>By linearity of F, one step of (EG+) is conveniently also a linear operator. Specifically, z k`<ref type="foot" target="#foot_0">1</ref> " T z k with T :"</p><formula xml:id="formula_21">?p1??qa 2 `b??? ? a 2 `b2 `?b`b ?2 `b2</formula><p>?a? ??a ) is a linear system, we simultaneously learn that picking c any larger would imply non-convergence through max i |? i | ? 1 (given z 0 ? 0). We can trivially embed problem (B.10) into a higher dimension to generalize the result. Noting that c " ??L completes the proof.</p><p>We provide Mathematica code to verify each step of the above proof. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Toy examples</head><p>In the following appendix, L denotes the Lipschitz constant of F restricted to the constraint set and ? is the parameter of the weak MVI (Assumption I(iii)) when restricted to the constraint set. This restriction of the definitions is warranted, since z k remains within the constraint set in all simulations, while zk is guaranteed to stay within by definition of Step 1.1 in Algorithm 1 (and likewise for all other considered method treating problem (2.1)).</p><p>All computer-assisted calculations can be found in the supplementary code. 1</p><p>C.1 Constructing a PolarGame (Definition 1)</p><p>Recall Definition 1 which considers a vectorfield F : R n ? R n with limit cycles at r P tc 1 , ..., c k u where c i ? 0 for all i P rks. Such a vectorfield can be constructed for n " 2 by departing from the ?? Figure <ref type="figure" target="#fig_5">5</ref>: We can construct the desired properties in polar coordinates pr, ?q and subsequently transform it into a vectorfield in cartesian coordinates px, yq. This is illustrated by a PolarGame with attracting limit cycles at radius }z} " 1 and repellant limit cycle at }z} " 3 {4 for the associated operator Fz as indicated in red and blue respectively. prptq `ci q ?prptq ?ci q B? Bt " ?b ?rptq,</p><formula xml:id="formula_22">(C.1)</formula><p>with a, b ? 0. Transforming this dynamics into cartesian coordinates yields the desired vectorfield, F, while subsequently integrating with respect to x and y yields the two potentials associated with the two players. Note that the roots t?c i u k i"1 for the polynomial defining 9 r are not strictly necessary for showing existence of limit cycles, but leads to a simpler form for Fz. We illustrate the construction in Fig. <ref type="figure" target="#fig_5">5</ref>. Proposition 1. Let Fz " p 9</p><p>x, 9 yq be the evolution in cartesian coordinates of the associated vectorfield in polar coordinates defined by (C.1). Then the only stationary point of F is at the origin p0, 0q and there exists a limit cycle at r " c i for all i P rks.</p><p>Proof. Let r " a x 2 `y2 . It is easy to see from (C.1) that the only stationary point is at r " 0. By construction, 9 r is a polynomial with roots c i for all i P rks, so any trajectory starting on the circle defined by r " c i remains in that set. However, 9</p><p>? is strictly nonzero. As a consequence Fz is nonzero, so r " c i must define a limit cycle, which proofs the claim. Figure <ref type="figure">7</ref>: In (a) we observe that all algorithms converge, despite F having an attracting limit cycle in Example 4. However, note that in the stochastic setting, where diminishing stepsize is required, SEG does not converge to the critical point (see Fig. <ref type="figure" target="#fig_4">4a</ref>). In (b) we demonstrate that when ? " ?1{3L, picking ?k ? 1 {3 for (CEG+) is necessary for convergence in general. See Section 6 for the experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Proof for properties of Example 3</head><p>The operator F : R 2 ? R 2 defined in Example 3 is obtained by constructing the associated dynamics in polar coordinates, Br Bt " ?a ?rptq ?prptq `1q ?prptq ?1q ?prptq `3{4q ?prptq ?3{4q B? Bt " ?rptq.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(C.2)</head><p>This can easily be verified by a change of variables. From Proposition 1 it then follows, that there must exist a limit cycle at }z} " 1 and }z} " 3 {4. To verify the conditions on ? we compute the closed form solution to ? and L in Mathematica:</p><p>(i) For a " 1 we have ? " ?50176 It can easily be verified that the stated conditions for ? in Example 3 are met for the values above. This completes the proof.</p><p>We provide Mathematica code verifying the construction of F and the closed form solutions to L and ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Proof for properties of Example 4</head><p>Under the definitions of ? and L in Appendix C, we claim that the origin p0, 0q in (GlobalForsaken) is a global Nash equilibrium and satisfies Assumption I(iii) with ? ? ?1{2L.</p><p>To verify that p0, 0q is indeed a global Nash equilibrium we need to check that the solution cannot be unilaterally improved. In other words, the solution should coincide with px ? , y ? q where</p><p>x ? " arg min We can easily verify this with Minimize in Mathematica, since the functions are polynomial for which a closed form solutions to the global optimization problem will be returned.</p><p>To find ? for z ? " p0, 0q we solve the global minimization problem, minimize z xFz, z ?z? y }Fz} 2 , (C.4)</p><p>for which a closed form solution can be found with Mathematica, which when numerically evaluated is approximately ?0.119732.</p><p>We need to compute L to ensure ? ? ?1{2L. In our case of convex constraints, C, we have that L " sup zPC }JFpzq} where } ?} denotes the spectral norm <ref type="bibr">(Rockafellar &amp; Wets, 2009, Thm. 9</ref>.2 and 9.7). Under our constraint }z} 8 ? 4 {3, this can similarly be computed in closed form, yielding L " b 1 2 p9409</p><p>? 59721901`74125591q {2835. So ?1 2L ? ?0.165432 which satisfy the condition ? ? ?1 2L . This completes the proof. Proposition 2. Let F be the associated operator of ? in (GlobalForsaken) defined as Fz " p? x ?px, yq, ??y ?px, yqq. Define the radius as r " }z}. Then, Fz has a stable critical point at the origin p0, 0q, at least one attracting limit cycle in the region defined by a 3 {2 ? r ? 2 and at least one repellant limit cycle within r ? a 3 {2.</p><p>Proof. We follow a similar argument as in <ref type="bibr">Hsieh et al. (2021, D.2)</ref>. We can compute the associated operator F, ?9 x 9 y ?" ?4x 5 and we observe that 9 r ? 0 for any ?. Likewise for r " 2, we have that 9 r " ?4 21 p22 cosp4?q`25q which implies 9 r ? 0. Since there is no stationary point in the region S " ! pr, ?q :</p><formula xml:id="formula_23">a 3 {2 ? r ? 2</formula><p>) it then follows from the Poincar?-Bendixson theorem <ref type="bibr">(Teschl, 2012, Thm. 7.16</ref>) that there must exist at least one attracting limit cycle in S. Further, it is easy to see that p0, 0q is a critical point and that it is stable by inspection of the Jacobian JFpzq. Since S is trapping, it follows from Poincar?-Hopf index theorem, that there must exist a repellant limit cycles in the region defined by r ? a 3 {2. This completes the proof.</p><p>C.4 Proof of properties for <ref type="bibr">(Hsieh et al., 2021, Example 5.2)</ref> This section considers <ref type="bibr">(Hsieh et al., 2021, Example 5.</ref>2) on the constraint domain D " tz P n | }z} 8 ? 3 {2u. We show that the unique critical point z ? does not satisfies the weak MVI for ? ? ?1{2L even when restricted to the constraint set z P D. We restate the example with the additional constraint for convenience. where ?pzq " 1 4 z 2 ?1 2 z 4 `1 6 z 6 .</p><p>By using Mathematica, we can obtain a closed form solution of the Lipschitz constant L of F restricted to the constraint set, which we find to be L " for z P D. Mathematica finds the candidate z 1 " p?1.01236, ?0.104749q for which ?pz 1 q " ?0.477761. So ? must be at least this small, i.e. ? ? ?0.477761. Since ?1{2L ? ?0.04, this implies that ? ? ?1{2L. See Forsaken.nb for Mathematica-assisted computations. This rules out convergence guarantees for both (CEG+) and AdaptiveEG+ (Algorithm 1), which is supported by the simulation in Figure <ref type="figure" target="#fig_12">8</ref>. However, as observed, (CurvatureEG+) converges in the simulations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>?Laboratory for Information and Inference Systems (LIONS), EPFL (thomas.pethick@epfl.ch) : Department of Electrical Engineering (ESAT-STADIUS), KU Leuven ; Laboratoire Traitement et Communication d'Information, T?l?com Paris, Institut Polytechnique de Paris</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Forsaken(Hsieh et al., 2021, Example 5.2) provides an example where the weak MVI constant ? does not satisfy algorithmic requirements of (EG+) and (EG+) does not converge to a stationary point but rather the attracting limit cycle (left). In contrast, adaptively choosing the extrapolation stepsize large enough with our new method, called (CurvatureEG+), is sufficient for avoiding the limit cycles (right). The repellant limit cycle is indicated in black and the stream plot shows the vectorfield Fz. The blue and red curves indicate multiple trajectories of the algorithms starting from initializations indicated in black. See Appendix C.4 for properties of Forsaken.</figDesc><graphic url="image-1.png" coords="2,157.44,81.86,138.60,141.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The grey region indicates where convergence provably cannot be guaranteed by Theorem 3.4.The dashed line indicates where ? " ?1{8L. This is the condition under which(Diakonikolas et al., 2021,  Thm. 3.2)  shows the first convergence result p?q. Corollary 3.2 improves their result by matching the lower bound for any ?, in particular for ? " 3 {4 p q. The adaptive scheme in Theorem 3.1 matches the smallest possible ? for any (EG+) scheme with fixed stepsize p q.</figDesc><graphic url="image-3.png" coords="6,226.80,81.86,158.40,87.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Deterministic setting. In (a) we have an instance of Example 3 with ? ? ?1{2L for which Theorem 3.4 provides lower bound for extrapolation stepsize ? k " 1 {L. However, adaptively choosing ? k larger can converge as illustrated with (CurvatureEG+). In addition, (b) confirms with Example 5, that (CEG+) for ?k " 1 {2 and CEG may indeed not converge even when ? " ?1{3L. In contrast, both AdaptiveEG+ and (CurvatureEG+) converges to the stationary point. Note that picking ?k ? 1 {3 would lead to convergence of (CEG+) by Corollary 3.2. See Fig. 6 and Fig. 7 for supplementary experiments.</figDesc><graphic url="image-4.png" coords="8,145.56,102.78,150.48,147.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Stochastic setting. In (a) we test the stochastic algorithms on our nonconvex-nonconcave constrained minimax example. The cycling behavior of SEG is inline with Hsieh et al. (2021), who shows that the sequence generated by SEG can converge to limit cycles of the underlying operator F. On the other hand, we observe that SEG+ escapes the attracting limit cycle. In (b) we also provide a more challenging example motivated by our lower bound.</figDesc><graphic url="image-7.png" coords="8,145.56,367.66,150.48,96.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Example 5 :</head><label>5</label><figDesc>Consider the following minimax problem: minimize xPR maximize yPR f px, yq :" axy `b 2 px 2 ?y2 q, (B.7) where b ? 0 and a ? 0. Proof of Theorem 3.4. The associated operator of Example 5 can easily be computed, Fz " pay `bx, by ?axq, (B.8)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Example 3 for different values of a (and thereby different values of ?).Note that even extragradient may escape the limit cycles even though ? ? 0. This is not in conflict with the negative results of<ref type="bibr" target="#b17">Hsieh et al. (2021)</ref> since the stepsize is not diminishing. However, in the general case even extragradient with fixed stepsize will not converge as shown by the lower bound in Theorem 3.4.</figDesc><graphic url="image-13.png" coords="16,242.64,267.00,126.72,131.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Example 5 (? " 1 {3L)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>x</head><label></label><figDesc>?px, 0q y ? " arg max y ?p0, yq. (C.3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>of variables into polar coordinates pr, ?q we get that r " ax 2 `y2 evolves as,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>?px, yq :" xpy ?0.45q `?pxq ??pyq, (Forsaken)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>?. Mathematica can solve approximately for the critical point, yielding z ? " p0.0780267, 0.411934q. To find ? we want to globally minimize ?pzq :" xFz,z?z ? y }Fz} 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: Demonstration of algorithms on(Hsieh et al., 2021, Example 5.2). Only (CurvatureEG+) converges to the critical point, while the remaining methods, CEG, (CEG+) with ?k " 1 {2, and AdaptiveEG+ converges to an attracting limit cycle. See Section 6 for further specification of the algorithms.</figDesc><graphic url="image-17.png" coords="19,226.80,81.86,158.40,163.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>n | Ax ? Hu, its graph by gph A tpx, yq P n ? d | y P Axu, and the set of its zeros by zer A tx P n | 0 P Axu. The inverse of A is defined through its graph: gph A ?1 tpy, xq | px, yq P gph Au. The resolvent of A is defined by J A pid `Aq ?1, where id denotes the identity operator.</figDesc><table><row><cell>Definition A.1 ((co)monotonicity Bauschke et al. (</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>We know that a linear dynamical system is globally asymptotically stable if and only if the spectral radius of the linear mapping is strictly less than 1.Let ? 1 , ? 2 be the eigenvalues of T . Then the spectral radius is the largest absolute value of the eigenvalues. For T this becomes, So we can ask what c in ? " ?c L needs to be for the sequence pz k q kPN to converge. Solving for c in this equality with max i |? i | ? 1, we obtain,</figDesc><table><row><cell></cell><cell></cell><cell cols="2">a ???</cell><cell cols="3">a 2 `b2 ?2b</cell><cell>?2</cell><cell>2 `b2 ?2b `b2 p1??qa 2 `b??? ? a 2 `b2 `?b`b ?2 ?2 ? ?. (B.10)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>`b2</cell><cell></cell><cell></cell><cell>`b2</cell></row><row><cell></cell><cell>d</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>max iPt1,2u</cell><cell>|? i | "</cell><cell cols="6">2 p2p ? ?1q ? `1qa 2 ?2 ?p ? `1qb `?a 2 `b2 ?b?`b a 2 `b2</cell><cell>.</cell><cell>(B.11)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">c ?</cell><cell cols="3">1 ?? 2</cell><cell>,</cell><cell>(B.12)</cell></row><row><cell cols="2">provided that we pick</cell><cell>?</cell><cell cols="3">1 ?c2 c</cell><cell cols="2">"</cell><cell>?a b</cell><cell>.</cell><cell>(B.13)</cell></row><row><cell cols="8">Equation (B.13) provides a specification for Example 5. As long as (B.12) is satisfied, (EG+) is</cell></row><row><cell cols="8">guaranteed to converge for ? k " 1 {L. On the other hand, since (B.10</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The supplementary code can be found at https://github.com/LIONS-EPFL/weak-minty-code/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">Acknowledgments and disclosure of funding</head><p>We would like to especially thank <rs type="person">Yu-Guan Hsieh</rs> for providing valuable feedback and discussion. This project has received funding from the <rs type="funder">European Research Council (ERC)</rs> under the European Union's <rs type="programName">Horizon 2020 research and innovation programme</rs> (grant agreement n?725594 -time-data). This work was supported by the <rs type="funder">Swiss National Science Foundation (SNSF)</rs> under grant number <rs type="grantNumber">200021_205011</rs>. The work of the second and third author was supported by the <rs type="funder">Research Foundation Flanders (FWO)</rs> postdoctoral grant <rs type="grantNumber">12Y7622N</rs> and research projects <rs type="grantNumber">G081222N</rs>, <rs type="grantNumber">G0A0920N</rs>, <rs type="grantNumber">G086518N</rs>, and <rs type="grantNumber">G086318N</rs>; <rs type="funder">Research Council KU Leuven</rs> <rs type="grantNumber">C1</rs> project No. <rs type="grantNumber">C14/18/068</rs>; <rs type="funder">Fonds de la Recherche Scientifique -FNRS</rs> and the <rs type="funder">Fonds Wetenschappelijk Onderzoek -Vlaanderen</rs> under <rs type="projectName">EOS</rs> project <rs type="projectName">no 30468160 (SeLMA)</rs>; <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs> under the <rs type="grantName">Marie Sk?odowska-Curie</rs> grant agreement No. <rs type="grantNumber">953348</rs>. The work of <rs type="person">Olivier Fercoq</rs> was supported by the <rs type="funder">Agence National de la Recherche</rs> grant <rs type="grantNumber">ANR-20-CE40-0027</rs>, <rs type="funder">Optimal Primal-Dual Algorithms (APDO)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JwCKkzZ">
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
				<org type="funding" xml:id="_43RphbU">
					<idno type="grant-number">200021_205011</idno>
				</org>
				<org type="funding" xml:id="_uXvAdAa">
					<idno type="grant-number">12Y7622N</idno>
				</org>
				<org type="funding" xml:id="_6b2e5hA">
					<idno type="grant-number">G081222N</idno>
				</org>
				<org type="funding" xml:id="_yYbP849">
					<idno type="grant-number">G0A0920N</idno>
				</org>
				<org type="funding" xml:id="_FhDSJxd">
					<idno type="grant-number">G086518N</idno>
				</org>
				<org type="funding" xml:id="_6zdmhMX">
					<idno type="grant-number">G086318N</idno>
				</org>
				<org type="funding" xml:id="_V7yyK4X">
					<idno type="grant-number">C1</idno>
				</org>
				<org type="funding" xml:id="_YbRZgfH">
					<idno type="grant-number">C14/18/068</idno>
				</org>
				<org type="funded-project" xml:id="_H2QSfmk">
					<orgName type="project" subtype="full">EOS</orgName>
				</org>
				<org type="funded-project" xml:id="_z3PNbmY">
					<idno type="grant-number">953348</idno>
					<orgName type="grant-name">Marie Sk?odowska-Curie</orgName>
					<orgName type="project" subtype="full">no 30468160 (SeLMA)</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
				<org type="funding" xml:id="_tUnpRun">
					<idno type="grant-number">ANR-20-CE40-0027</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A tight and unified analysis of gradient-based methods for a whole spectrum of differentiable games</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Wa?ss Azizian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><surname>Gidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2863" to="2873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convex analysis and monotone operator theory in Hilbert spaces</title>
		<author>
			<persName><forename type="first">H</forename><surname>Heinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">L</forename><surname>Bauschke</surname></persName>
		</author>
		<author>
			<persName><surname>Combettes</surname></persName>
		</author>
		<idno>978-3-319-48310-8</idno>
	</analytic>
	<monogr>
		<title level="m">CMS Books in Mathematics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalized monotone operators and their averaged resolvents</title>
		<author>
			<persName><forename type="first">Walaa</forename><forename type="middle">M</forename><surname>Heinz H Bauschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfu</forename><surname>Moursi</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Programming</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mixed equilibria and dynamical systems arising from fictitious play in perturbed games</title>
		<author>
			<persName><forename type="first">Michel</forename><surname>Bena?m</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morris</forename><forename type="middle">W</forename><surname>Hirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="36" to="72" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nonlinear programming</title>
		<author>
			<persName><forename type="first">Dimitri</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Operational Research Society</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="334" to="334" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Axel</forename><surname>B?hm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sedlmayer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09033</idno>
		<title level="m">Ern? Robert Csetnek, and Radu Ioan Bo?. Two steps at a timetaking gan training in stride with tseng&apos;s method</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Independent policy gradient methods for competitive reinforcement learning</title>
		<author>
			<persName><forename type="first">Constantinos</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><forename type="middle">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Golowich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04233</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The complexity of constrained min-max optimization</title>
		<author>
			<persName><forename type="first">Constantinos</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stratis</forename><surname>Skoulakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manolis</forename><surname>Zampetakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing</title>
		<meeting>the 53rd Annual ACM SIGACT Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1466" to="1478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Stochastic subgradient method converges at the rate $O(k {-1/4})$ on weakly convex functions</title>
		<author>
			<persName><forename type="first">Damek</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Drusvyatskiy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02988</idno>
		<imprint>
			<date type="published" when="2018-02">February 2018</date>
		</imprint>
	</monogr>
	<note>cs, math</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient methods for structured nonconvex-nonconcave min-max optimization</title>
		<author>
			<persName><forename type="first">Jelena</forename><surname>Diakonikolas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantinos</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2746" to="2754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Finite-dimensional variational inequalities and complementarity problems</title>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong-Shi</forename><surname>Pang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Gradient descent-ascent provably converges to strict local minmax equilibria with a finite timescale separation</title>
		<author>
			<persName><forename type="first">Tanner</forename><surname>Fiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Ratliff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.14820</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Gauthier Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ga?tan</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vignoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><surname>Lacoste-Julien</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10551</idno>
		<title level="m">A variational inequality perspective on generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nonlinear forward-backward splitting with projection correction</title>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Giselsson</surname></persName>
		</author>
		<idno type="DOI">10.1137/20M1345062</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2199" to="2226" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exponential lower bounds for finding Brouwer fixed points</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vavasis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Symposium on Foundations of Computer Science</title>
		<meeting>the 28th Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="401" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multiple equilibria and limit cycles in evolutionary games with logit dynamics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marius</forename><forename type="middle">I</forename><surname>Hommes</surname></persName>
		</author>
		<author>
			<persName><surname>Ochea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="434" to="441" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The limits of min-max optimization algorithms: Convergence to spurious non-critical sets</title>
		<author>
			<persName><forename type="first">Ya-Ping</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panayotis</forename><surname>Mertikopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volkan</forename><surname>Cevher</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4337" to="4348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling</title>
		<author>
			<persName><forename type="first">Yu-Guan</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Iutzeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?r?me</forename><surname>Malick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panayotis</forename><surname>Mertikopoulos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10162</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">What is local optimality in nonconvexnonconcave minimax optimization?</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praneeth</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00618</idno>
		<imprint>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
	<note>cs, math, stat</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The extragradient method for finding saddle points and other problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Galina</surname></persName>
		</author>
		<author>
			<persName><surname>Korpelevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matecon</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="747" to="756" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Asymmetric forward-backward-adjoint splitting for solving monotone inclusions involving three operators</title>
		<author>
			<persName><forename type="first">Puya</forename><surname>Latafat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panagiotis</forename><surname>Patrinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="93" />
			<date type="published" when="2017-09">Sep 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Fast extra gradient methods for smooth structured nonconvexnonconcave minimax problems</title>
		<author>
			<persName><forename type="first">Sucheol</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghwan</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02326</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Semi-anchored multi-step gradient descent ascent method for structured nonconvex-nonconcave composite minimax problems</title>
		<author>
			<persName><forename type="first">Sucheol</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghwan</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.15042</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">First-order convergence theory for weakly-convex-weakly-concave min-max problems</title>
		<author>
			<persName><forename type="first">Mingrui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Rafique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">169</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">On finding local Nash equilibria (and only local Nash equilibria) in zero-sum games</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">V</forename><surname>Mazumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Shankar</forename><surname>Sastry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00838</idno>
		<imprint>
			<date type="published" when="2019-01">January 2019</date>
		</imprint>
	</monogr>
	<note>cs, math, stat</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile</title>
		<author>
			<persName><forename type="first">Panayotis</forename><surname>Mertikopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Lecouat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houssam</forename><surname>Zenati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan-Sheng</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Piliouras</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02629</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cycles in adversarial regularized learning</title>
		<author>
			<persName><forename type="first">Panayotis</forename><surname>Mertikopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Piliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2018">2018b</date>
			<biblScope unit="page" from="2703" to="2717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Monotone (nonlinear) operators in hilbert space</title>
		<author>
			<persName><forename type="first">J</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><surname>Minty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Duke Mathematical Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="346" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Solving a class of non-convex min-max games using iterative first order methods</title>
		<author>
			<persName><forename type="first">Maziar</forename><surname>Maher Nouiehed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjian</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meisam</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Razaviyayn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08297</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the complexity of the parity argument and other inefficient proofs of existence</title>
		<author>
			<persName><forename type="first">Christos</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and system Sciences</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="498" to="532" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast exact multiplication by the hessian</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName><surname>Polyak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note>Introduction to optimization. Optimization Software New York</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Rafique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingrui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02060</idno>
		<title level="m">Non-convex min-max optimization: Provable algorithms and applications in machine learning</title>
		<imprint>
			<date type="published" when="2019-01">January 2019</date>
		</imprint>
	</monogr>
	<note>cs, math</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Variational analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-B</forename><surname>Wets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">317</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Monotone operators and the proximal point algorithm</title>
		<author>
			<persName><forename type="first">Rockafellar</forename><surname>Tyrrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on control and optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="877" to="898" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Tyrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rockafellar</forename></persName>
		</author>
		<title level="m">Convex analysis</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Modified projection-type methods for monotone variational inequalities</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Solodov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1814" to="1830" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A hybrid projection-proximal point algorithm</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mikhail</surname></persName>
		</author>
		<author>
			<persName><surname>Solodov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benar</surname></persName>
		</author>
		<author>
			<persName><surname>Svaiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of convex analysis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="70" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Optimistic dual extrapolation for coherent non-monotone variational inequalities</title>
		<author>
			<persName><forename type="first">Chaobing</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04410</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Ordinary differential equations and dynamical systems</title>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Teschl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>American Mathematical Soc</publisher>
			<biblScope unit="volume">140</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A modified forward-backward splitting method for maximal monotone mappings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="431" to="446" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Global convergence and variance-reduced optimization for a class of nonconvex-nonconcave minimax problems</title>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Negar</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niao</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09621</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stochastic mirror descent in variationally coherent optimization problems</title>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panayotis</forename><surname>Mertikopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Bambos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">W</forename><surname>Glynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
