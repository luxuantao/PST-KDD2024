<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Subgradient Methods for Saddle-Point Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-03-05">5 March 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
						</author>
						<author>
							<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial and Enterprise Systems Engineering</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Subgradient Methods for Saddle-Point Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-03-05">5 March 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">C74E99B4663898A2F844C91FBD109DD8</idno>
					<idno type="DOI">10.1007/s10957-009-9522-7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study subgradient methods for computing the saddle points of a convex-concave function. Our motivation comes from networking applications where dual and primal-dual subgradient methods have attracted much attention in the design of decentralized network protocols. We first present a subgradient algorithm for generating approximate saddle points and provide per-iteration convergence rate estimates on the constructed solutions. We then focus on Lagrangian duality, where we consider a convex primal optimization problem and its Lagrangian dual problem, and generate approximate primal-dual optimal solutions as approximate saddle points of the Lagrangian function. We present a variation of our subgradient method under the Slater constraint qualification and provide stronger estimates on the convergence rate of the generated primal sequences. In particular, we provide bounds on the amount of feasibility violation and on the primal objective function values at the approximate solutions. Our algorithm is particularly well-suited for problems where the subgradient of the dual function cannot be evaluated easily (equivalently, the minimum of the Lagrangian function at a dual solution cannot be computed efficiently), thus impeding the use of dual subgradient methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keywords</head><p>Saddle-point subgradient methods • Averaging • Approximate primal solutions • Primal-dual subgradient methods • Convergence rate Communicated by P.M. Pardalos.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We consider a convex-concave function L : X × M → R, where X and M are closed convex sets in R n and R m . We are interested in computing a saddle point (x * , μ * ) of L(x, μ) over the set X × M, where a saddle point is defined as a vector pair (x * , μ * ) that satisfies L(x * , μ) ≤ L(x * , μ * ) ≤ L(x, μ * ), for all x ∈ X, μ ∈ M.</p><p>Saddle point problems arise in a number of areas such as constrained optimization duality, zero-sum games, and general equilibrium theory. It has been long recognized that subgradient methods provide efficient decentralized computational means for solving non-smooth saddle point and optimization problems in many disciplines. Most remarkably in networking applications, dual subgradient methods have been used with great success in designing decentralized network control protocols (see Low and Lapsley <ref type="bibr" target="#b0">[1]</ref>, Srikant <ref type="bibr" target="#b1">[2]</ref>, and Chiang et al. <ref type="bibr" target="#b2">[3]</ref>). This approach relies on the assumption that the subgradient of the dual function can be evaluated efficiently using local information, which is possible when the underlying optimization problem has special structure (i.e., the objective function is separable). For solving general optimization problems, recent research in networking focused on primal-dual subgradient methods, which are aimed at computing saddle points of the corresponding Lagrangian function. The objective is to generate approximate solutions with performance guarantees in relatively small number of iterations.</p><p>In this paper, we propose a subgradient algorithm for generating approximate saddle-point solutions for a convex-concave function. Our algorithm builds on the seminal Arrow-Hurwicz-Uzawa algorithm <ref type="bibr" target="#b3">[4]</ref> and the averaging scheme suggested by Bruck <ref type="bibr" target="#b4">[5]</ref> (see also <ref type="bibr">Nemirovski and Yudin [6]</ref>). In contrast to existing work with focus on the convergence of the iterates to a saddle point, we present an algorithm that generates approximate saddle points and provide explicit rate estimates per-iteration. In particular, we establish upper and lower bounds on the function value of the generated solutions. For the case of Lagrangian saddle point problems, we provide a variation on our main algorithm and establish stronger convergence and convergence rate results under the Slater constraint qualification.</p><p>Subgradient methods for solving saddle point problems have been the focus of much research since the seminal work of Arrow, Hurwicz, and Uzawa <ref type="bibr" target="#b3">[4]</ref>. Arrow, Hurwicz, and Uzawa proposed continuous-time versions of these methods for general convex-concave functions. They provide global stability results under strict convexity assumptions in a series of papers in the collection <ref type="bibr" target="#b3">[4]</ref>. Uzawa in <ref type="bibr" target="#b6">[7]</ref> focused on a discrete-time version of the subgradient method with a constant stepsize rule and showed that the iterates converge to any given neighborhood of a saddle point provided that the stepsize is sufficiently small. 1 Methods of Arrow-Hurwicz-Uzawa type for finding saddle-points of a general convex-concave function have also been studied by Gol'shtein <ref type="bibr" target="#b7">[8]</ref> and Maistroskii <ref type="bibr" target="#b8">[9]</ref>, who provided convergence results using diminishing stepsize rule and under some stability assumptions on saddle points, which are weaker than strict convexity assumptions. Zabotin <ref type="bibr" target="#b9">[10]</ref> has extended the preceding work by establishing convergence without assuming saddle-point stability. Korpelevich <ref type="bibr" target="#b10">[11]</ref> considered an "extragradient method" for computing saddle points, which can be viewed as a gradient method with perturbations. Perturbations have also been used more recently by Kallio and Ruszczyński <ref type="bibr" target="#b11">[12]</ref> to construct a class of subgradient methods for computing saddle points with an adaptive stepsize rule that uses the "primal-dual gap" information. These methods have been further developed by Kallio and Rosa <ref type="bibr" target="#b12">[13]</ref> and used in computing the saddle points of the standard Lagrangian function. Nemirovski and Yudin <ref type="bibr" target="#b5">[6]</ref> considered a different approach where they combined the subgradient method with a simple averaging scheme in the context of Lagrangian saddle point problems and provided convergence results with adaptive stepsize rules.</p><p>In this paper, our main interest is in computing approximate saddle points of the Lagrangian function of a convex constrained optimization problem. To set the stage, we first study the computation of approximate saddle points (as opposed to asymptotically exact solutions) using subgradient methods with a constant stepsize. We consider constant stepsize rule because of its simplicity and practical relevance, and because our interest is in generating approximate solutions in finite number of iterations. Our first main result can be summarized as follows. Let L be a convex-concave function with saddle point (x * , μ * ). Let {x k , μ k } be the iterates generated by our subgradient algorithm. Then, under the assumption that the generated iterates are bounded, the function value L( xk , μk ) at the time-averaged iterates xk and μk converges to L(x * , μ * ) at rate 1/k within error level αL 2 (see Proposition 3.1), explicitly given as a function of the stepsize α and the subgradient bound L. We view providing rate estimates within this error level natural since this level is resulting from a tight bound of αL 2 /2 on the performance of a subgradient method with a constant stepsize (see the comment after Lemma 3.2).</p><p>Our second set of results focus on Lagrangian saddle point problems and offer a variant of our main algorithm with stronger error estimates for the averaged primal solution under the Slater constraint qualification. These results are obtained without assuming the boundedness of the iterates owing to the fact that we can exploit the special structure of the optimal solution set of the Lagrangian dual problem under the Slater condition. The error estimates are in terms of the amount of constraint violation and the primal objective function value for the generated solutions. These estimates highlight the explicit tradeoffs between the accuracy of the solutions and computational complexity of the algorithm as a function of the stepsize. This method can be applied in wide range of problems where the dual subgradient methods cannot be used because of the difficulties associated with efficiently computing the subgradients of the dual function.</p><p>In addition to the papers cited above, our work is related to recent work on subgradient methods based on non-Euclidean projections. Beck and Teboulle <ref type="bibr" target="#b13">[14]</ref> for example, consider a non-differentiable convex optimization problem with simple constraints and study the Mirror Descent Algorithm (MDA), first proposed by Nemirovski and Yudin <ref type="bibr" target="#b5">[6]</ref>. They show that MDA achieves a rate estimate of 1/ √ k for the objective function value of the generated iterates. In related work, Nemirovski <ref type="bibr" target="#b14">[15]</ref> proposes a prox-type method with averaging for computing saddle points of continuously differentiable convex-concave functions with Lipschitz continuous gradient and provides a rate estimate of 1/k for the saddle function value. Auslender and Teboulle <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> propose subgradient methods based on non-Euclidean projections for solving variational inequalities and non-differentiable convex optimization problems. Under the assumption that the constraint set is compact, they provide a rate estimate of 1/ √ k. The paper is organized as follows. In Sect. 2, we introduce the notation and the basic notions that we use throughout the paper and present a formulation of the saddle point problem. In Sect. 3, we present our subgradient method and provide relations for the iterates of the method. We construct approximate solutions by considering running averages of the generated iterates and provide error estimates for these solutions. In Sect. 4, we consider application of our subgradient method to Lagrangian duality. In Sect. 5, we propose a variation on the original algorithm under the Slater condition and present error estimates for the averaged primal solutions. In Sect. 6, we summarize our results and provide some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section, we formulate the saddle-point problem of interest and present some preliminary results that we use in the subsequent development. We start by introducing the notation and basic terminology that we use throughout the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation and Terminology</head><p>We consider the n-dimensional vector space R n and the m-dimensional vector space R m . We denote the m-dimensional nonnegative orthant by R m + . We view a vector as a column vector, and we write x i to denote the i-th component of a vector x. We denote by x y the inner product of two vectors x and y. We use y to denote the standard Euclidean norm, y = y y. Occasionally, we also use the standard 1norm and ∞-norm denoted respectively by y 1 and y ∞ , i.e., y 1 = i |y i | and y ∞ = max i |y i |. We write dist( ȳ, Y ) to denote the standard Euclidean distance of a vector ȳ from a set Y , i.e., dist( ȳ, Y ) = inf y∈Y ȳy .</p><p>For a vector u ∈ R m , we write u + to denote the projection of u on the nonnegative orthant in R m , i.e., u + is the componentwise maximum of the vector u and the zero vector,</p><formula xml:id="formula_0">u + = (max{0, u 1 }, . . . , max{0, u m }) , for u = (u 1 , . . . , u m ) .</formula><p>For a convex function F : R n → [-∞, ∞], we denote the domain of F by dom(F ), where</p><formula xml:id="formula_1">dom(F ) = {x ∈ R n | F (x) &lt; ∞}.</formula><p>We use the notion of a subgradient of a convex function F (x) at a given vector x ∈ dom(F ). A subgradient s F ( x) of a convex function F (x) at any x ∈ dom(F ) provides a linear underestimate of the function F . In particular, s F ( x) ∈ R n is a subgradient of a convex function F : R n → R at a given vector x ∈ dom(F ) when the following relation holds:</p><formula xml:id="formula_2">F ( x) + s F ( x) (x -x) ≤ F (x), for all x ∈ dom(F ). (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>The set of all subgradients of F at x is denoted by ∂F ( x).</p><p>Similarly, for a concave function q : R m → [-∞, ∞], we denote the domain of q by dom(q), where</p><formula xml:id="formula_4">dom(q) = {μ ∈ R m | q(μ) &gt; -∞}.</formula><p>Concave function q(μ). A subgradient of a concave function is defined through a subgradient of a convex function -q(μ). In particular, s q ( μ) ∈ R m is a subgradient of a concave function q(μ) at a given vector μ ∈ dom(q) when the following relation holds:</p><formula xml:id="formula_5">q( μ) + s q ( μ) (μ -μ) ≥ q(μ), for all μ ∈ dom(q).<label>(2)</label></formula><p>Similarly, the set of all subgradients of q at μ is denoted by ∂q( μ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Saddle-Point Problem</head><p>We consider the following saddle-point problem:</p><formula xml:id="formula_6">min x∈X max μ∈M L(x, μ), (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>where X is a closed convex set in R n , M is a closed convex set in R m , and L is a convex-concave function defined over X × M. In particular, L(•, μ) : X → R is convex for every μ ∈ M, and L(x, •) : M → R is concave for every x ∈ X. For any given ( x, μ) ∈ X × M, the subdifferential set of L( x, μ) with respect to x is denoted by ∂ x L( x, μ), while the subdifferential set of L( x, μ) with respect to μ is denoted by ∂ μ L( x, μ). We assume that these subdifferential sets are nonempty for all ( x, μ) ∈ X × M. We use L x ( x, μ) and L μ ( x, μ) to denote a subgradient of L with respect to x and a subgradient of L with respect to μ at any</p><formula xml:id="formula_8">( x, μ) ∈ X × M. A solution to problem (3) is a vector pair (x * , μ * ) ∈ X × M such that L(x * , μ) ≤ L(x * , μ * ) ≤ L(x, μ * ), for all x ∈ X and μ ∈ M. (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>Such a vector pair (x * , μ * ) is also referred to as the saddle point of the function L(x, μ) over the set X × M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Subgradient Algorithm for Approximate Saddle Points</head><p>To generate approximate solutions to problem (3), we consider a subgradient method motivated by the Arrow-Hurwicz-Uzawa algorithm <ref type="bibr" target="#b3">[4]</ref>. In particular, the method has the following form:</p><formula xml:id="formula_10">x k+1 = P X [x k -αL x (x k , μ k )] , for k = 0, 1, . . . ,<label>(5)</label></formula><formula xml:id="formula_11">μ k+1 = P M [μ k + αL μ (x k , μ k )], for k = 0, 1, . . . ,<label>(6)</label></formula><p>where P X and P M denote the projection on sets X and M respectively. The vectors x 0 ∈ X and μ 0 ∈ M are initial iterates, and the scalar α &gt; 0 is a constant stepsize. The vectors L x (x k , μ k ) and L μ (x k , μ k ) denote subgradients of L at (x k , μ k ) with respect to x and μ, correspondingly.</p><p>Our focus on a constant stepsize is motivated by the fact that we are interested in quantifying the progress of the algorithm in finite number of iterations. An adaptive diminishing stepsize α k that varies with each iteration may be used if the interest is in establishing the convergence properties of the iterates to a saddle point as the number of iterations k goes to infinity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Relations</head><p>In this section, we establish some basic relations that hold for the sequences {x k } and {μ k } obtained by the algorithm in ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>). These properties are important in our construction of approximate primal solutions, and in particular, in our analysis of error estimates of these solutions.</p><p>We start with a lemma providing relations that hold under minimal assumptions. The relations given in part (b) of this lemma have been known and used extensively to analyze dual subgradient approaches (for example, see Shor <ref type="bibr" target="#b17">[18]</ref>, Polyak <ref type="bibr" target="#b18">[19]</ref>, Demyanov and Vasilev <ref type="bibr" target="#b19">[20]</ref>, Correa and Lemaréchal <ref type="bibr" target="#b20">[21]</ref>, Nedić and Bertsekas <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, Nedić and Ozdaglar <ref type="bibr" target="#b23">[24]</ref>). The proofs are included here for completeness. Lemma 3.1 (Basic Iterate Relations) Let the sequences {x k } and {μ k } be generated by the subgradient algorithm (5)- <ref type="bibr" target="#b5">(6)</ref>. We then have:</p><p>(a) For any x ∈ X and for all k ≥ 0,</p><formula xml:id="formula_12">x k+1 -x 2 ≤ x k -x 2 -2α(L(x k , μ k ) -L(x, μ k )) + α 2 L x (x k , μ k ) 2 .</formula><p>(b) For any μ ∈ M and for all k ≥ 0,</p><formula xml:id="formula_13">μ k+1 -μ 2 ≤ μ k -μ 2 + 2α(L(x k , μ k ) -L(x k , μ)) + α 2 L μ (x k , μ k ) 2 .</formula><p>Proof (a) By using the nonexpansive property of the projection operation and relation (5), we obtain that, for any x ∈ X and all k ≥ 0,</p><formula xml:id="formula_14">x k+1 -x 2 = P X [x k -αL x (x k , μ k )] -x 2 ≤ x k -αL x (x k , μ k ) -x 2 = x k -x 2 -2αL x (x k , μ k )(x k -x) + α 2 L x (x k , μ k ) 2 .</formula><p>Since the function L(x, μ) is convex in x for each μ ∈ M, and since</p><formula xml:id="formula_15">L x (x k , μ k ) is a subgradient of L(x, μ k ) with respect to x at x = x k [cf.</formula><p>the definition of a subgradient in (1)], we obtain that, for any x,</p><formula xml:id="formula_16">L x (x k , μ k )(x -x k ) ≤ L(x, μ k ) -L(x k , μ k ), or equivalently, -L x (x k , μ k )(x k -x) ≤ -(L(x k , μ k ) -L(x, μ k )) .</formula><p>Hence, for any x ∈ X and all k ≥ 0,</p><formula xml:id="formula_17">x k+1 -x 2 ≤ x k -x 2 -2α(L(x k , μ k ) -L(x, μ k )) + α 2 L x (x k , μ k ) 2 .</formula><p>(b) Similarly, by using the nonexpansive property of the projection operation and relation <ref type="bibr" target="#b5">(6)</ref> we obtain that, for any μ ∈ M,</p><formula xml:id="formula_18">μ k+1 -μ 2 = P M [μ k + αL μ (x k , μ k )] -μ 2 ≤ μ k + αL μ (x k , μ k ) -μ 2 .</formula><p>Therefore,</p><formula xml:id="formula_19">μ k+1 -μ 2 ≤ μ k -μ 2 +2α(μ k -μ) L μ (x k , μ k )+α 2 L μ (x k , μ k ) 2 , for all k. Since L μ (x k , μ k ) is a subgradient of the concave function L(x k , μ) at μ = μ k [cf. (<label>2</label></formula><p>)], we have that, for all μ,</p><formula xml:id="formula_20">(μ k -μ) L μ (x k , μ k ) = L(x k , μ k ) -L(x k , μ).</formula><p>Hence, for any μ ∈ M and all k ≥ 0,</p><formula xml:id="formula_21">μ k+1 -μ 2 ≤ μ k -μ 2 + 2α(L(x k , μ k ) -L(x k , μ)) + α 2 L μ (x k , μ k ) 2 .</formula><p>We establish some additional properties of the iterates x k and μ k under the assumption that the subgradients used by the method are bounded. This is formally stated in the following assumption. Assumption 3.1 (Subgradient Boundedness) The subgradients L x (x k , μ k ) and L μ (x k , μ k ) used in the method defined by ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) are uniformly bounded, i.e., there is a constant L &gt; 0 such that</p><formula xml:id="formula_22">L x (x k , μ k ) ≤ L, L μ (x k , μ k ) ≤ L, for all k ≥ 0.</formula><p>This assumption is satisfied for example when the sets X and M are compact, and the function L is a convex-concave function over R n × R m . Also, the assumption is satisfied when the function L is affine in (x, μ).</p><p>Under the preceding assumption, we provide a relation for the iterates x k and μ k and an arbitrary vectors x ∈ X and μ ∈ M. This relation plays a crucial role in our subsequent analysis. Lemma 3.2 Let the sequences {x k } and {μ k } be generated by the subgradient algorithm (5)- <ref type="bibr" target="#b5">(6)</ref>. Let the subgradient boundedness assumption hold (cf. Assumption 3.1), and let xk and μk be the iterate averages given by</p><formula xml:id="formula_23">xk = 1 k k-1 i=0 x i , μk = 1 k k-1 i=0 μ i .</formula><p>We then have, for all k ≥ 1,</p><formula xml:id="formula_24">1 k k-1 i=0 L(x i , μ i ) -L(x, μk ) ≤ x 0 -x 2 2αk + αL 2 2 , for any x ∈ X,<label>(7)</label></formula><formula xml:id="formula_25">- μ 0 -μ 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) -L( xk , μ), for any μ ∈ M. (<label>8</label></formula><formula xml:id="formula_26">)</formula><p>Proof We first show the relation in <ref type="bibr" target="#b6">(7)</ref>. By using Lemma 3.1(a) and the boundedness of the subgradients L x (x i , μ i ) [cf. Assumption 3.1], we have that, for any x ∈ X and i ≥ 0,</p><formula xml:id="formula_27">x i+1 -x 2 ≤ x i -x 2 -2α(L(x i , μ i ) -L(x, μ i )) + α 2 L 2 .</formula><p>Therefore,</p><formula xml:id="formula_28">L(x i , μ i ) -L(x, μ i ) ≤ 1 2α x i -x 2 -x i+1 -x 2 + αL 2 2 .</formula><p>By adding these relations over i = 0, . . . , k -1, we obtain, for any x ∈ X and k ≥ 1,</p><formula xml:id="formula_29">k-1 i=0 (L(x i , μ i ) -L(x, μ i )) ≤ 1 2α x 0 -x 2 -x k -x 2 + kαL 2 2 , implying that 1 k k-1 i=0 L(x i , μ i ) - 1 k k-1 i=0 L(x, μ i ) ≤ x 0 -x 2 2αk + αL 2 2 .</formula><p>Since the function L(x, μ) is concave in μ for any fixed x ∈ X, there holds</p><formula xml:id="formula_30">L(x, μk ) ≥ 1 k k-1 i=0 L(x, μ i ), with x ∈ X and μk = 1 k k-1 i=0 μ i .</formula><p>Combining the preceding two relations, we obtain that, for any x ∈ X and k ≥ 1,</p><formula xml:id="formula_31">1 k k-1 i=0 L(x i , μ i ) -L(x, μk ) ≤ x 0 -x 2 2αk + αL 2 2 ,</formula><p>thus establishing the relation <ref type="bibr" target="#b6">(7)</ref>. Similarly, by using Lemma 3.1(b) and the boundedness of the subgradients L μ (x i , μ i ), we have that, for any μ ∈ M and i ≥ 0,</p><formula xml:id="formula_32">μ i+1 -μ 2 ≤ μ i -μ 2 + 2α(L(x i , μ i ) -L(x i , μ)) + α 2 L 2 .</formula><p>Hence,</p><formula xml:id="formula_33">1 2α μ i+1 -μ 2 -μ i -μ 2 - αL 2 2 ≤ L(x i , μ i ) -L(x i , μ).</formula><p>By adding these relations over i = 0, . . . , k -1, we obtain that, for all μ ∈ M and k ≥ 1,</p><formula xml:id="formula_34">1 2α μ k -μ 2 -μ 0 -μ 2 - kαL 2 2 ≤ k-1 i=0 (L(x i , μ i ) -L(x i , μ)) , implying that - μ 0 -μ 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) - 1 k k-1 i=0 L(x i , μ).</formula><p>Because the function L(x, μ) is convex in x for any fixed μ ∈ M, we have</p><formula xml:id="formula_35">1 k k-1 i=0 L(x i , μ) ≥ L( xk , μ), with μ ∈ M and xk = 1 k k-1 i=0 x i .</formula><p>Combining the preceding two relations, we obtain that, for all μ ∈ M and k ≥ 1,</p><formula xml:id="formula_36">- μ 0 -μ 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) -L( xk , μ),</formula><p>thus showing the relation <ref type="bibr" target="#b7">(8)</ref>.</p><p>The error level αL 2 /2 appearing in ( <ref type="formula" target="#formula_24">7</ref>) and ( <ref type="formula" target="#formula_25">8</ref>) is actually a tight error bound on the performance of the subgradient algorithm with a constant stepsize α. This can be seen by considering the minimization problem min x∈R n f (x) with f (x) = L max |x i |, and by applying the subgradient method with a stepsize α and initial vector x 0 = αL 2 e i , where e i is the vector in R n with ith entry equal to 1 and all other entries equal to 0. 2  The relations in the previous lemma will be key in providing approximate saddle points with per-iteration performance bounds in the following section. In particular, using this lemma, we establish a relation between the averaged values 2 In this case, one can show that x 1 = -x 0 , x 2 = x 0 , implying that the iterates x k are trapped in a cycle alternating between x 0 and -x 0 . Since the optimal value is f * = 0 and f (x k ) = αL 2  2 , it follows that the error bound αL 2  2 is tight for this problem.</p><formula xml:id="formula_37">1 k k-1 i=0 L(x i , μ i )</formula><p>and the saddle point value L(x * , μ * ). We also show a relation between the function value L( xk , μk ) at the iterate averages xk and μk , and the saddle point value L(x * , μ * ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approximate Saddle Points</head><p>In this section, we focus on constructing approximate saddle points using the information generated by the subgradient method given in ( <ref type="formula" target="#formula_10">5</ref>)- <ref type="bibr" target="#b5">(6)</ref>. We use a simple averaging scheme to generate approximate solutions. In particular, we consider the running averages xk and μk generated by</p><formula xml:id="formula_38">xk = 1 k k-1 i=0 x i , μk = 1 k k-1 i=0 μ i , for k ≥ 1.</formula><p>These averages provide approximate solutions for the saddle-point problem, as indicated by the following result.</p><p>Proposition 3.1 Let the subgradient boundedness assumption hold (cf. Assumption 3.1). Let {x k } and {μ k } be the sequences generated by method (5)-( <ref type="formula" target="#formula_11">6</ref>), and let (x * , μ * ) ∈ X × M be a saddle point of L(x, μ). We then have:</p><formula xml:id="formula_39">(a) For all k ≥ 1, - μ 0 -μ * 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) -L(x * , μ * ) ≤ x 0 -x * 2 2αk + αL 2 2 .</formula><p>(b) The averages xk and μk satisfy the following relation for all k ≥ 1:</p><formula xml:id="formula_40">- μ 0 -μ * 2 + x 0 -xk 2 2αk -αL 2 ≤ L( xk , μk ) -L(x * , μ * ) ≤ x 0 -x * 2 + μ 0 -μk 2 2αk + αL 2 ,</formula><p>where L is the subgradient bound of Assumption 3.1.</p><p>Proof (a) Our proof is based on Lemma 3.2. In particular, by letting x = x * and μ = μ * in ( <ref type="formula" target="#formula_24">7</ref>) and ( <ref type="formula" target="#formula_25">8</ref>), respectively, we obtain that, for any k ≥ 1,</p><formula xml:id="formula_41">1 k k-1 i=0 L(x i , μ i ) -L(x * , μk ) ≤ x 0 -x * 2 2αk + αL 2 2 , - μ 0 -μ * 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) -L( xk , μ * ).</formula><p>By the convexity of the sets X and M, we have xk ∈ X and μk ∈ M for all k ≥ 1. Therefore, by the saddle-point relation [cf. ( <ref type="formula" target="#formula_8">4</ref>)], we have</p><formula xml:id="formula_42">L(x * , μk ) ≤ L(x * , μ * ) ≤ L( xk , μ * ).</formula><p>Combining the preceding three relations, we obtain that, for all k ≥ 1,</p><formula xml:id="formula_43">- μ 0 -μ * 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) -L(x * , μ * ) ≤ x 0 -x * 2 2αk + αL 2 2 . (<label>9</label></formula><formula xml:id="formula_44">)</formula><p>(b) Since xk ∈ X and μk ∈ M for all k ≥ 1, we use Lemma 3.2 with x = xk and μ = μk to obtain, for all k ≥ 1,</p><formula xml:id="formula_45">1 k k-1 i=0 L(x i , μ i ) -L( xk , μk ) ≤ x 0 -xk 2 2αk + αL 2 2 , - μ 0 -μk 2 2αk - αL 2 2 ≤ 1 k k-1 i=0 L(x i , μ i ) -L( xk , μk ).</formula><p>By multiplying with -1 the preceding relations and combining them, we see that</p><formula xml:id="formula_46">- x 0 -xk 2 2αk - αL 2 2 ≤ L( xk , μk ) - 1 k k-1 i=0 L(x i , μ i ) ≤ μ 0 -μk 2 2αk + αL 2 2 . (<label>10</label></formula><formula xml:id="formula_47">)</formula><p>The result follows by summing the relations ( <ref type="formula" target="#formula_43">9</ref>) and <ref type="bibr" target="#b9">(10)</ref>. Under the assumption that the iterates generated by the subgradient algorithm ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) are bounded (which holds when the sets X and M are compact), this result shows that the function values of the averaged iterates L( xk , μk ) converge to the saddlepoint value L(x * , μ * ) within error level αL 2 with rate 1/k. The error level is due to our use of a constant stepsize and can be controlled by choosing a smaller stepsize value. The estimate of the preceding proposition provides explicit tradeoffs between accuracy and computational complexity in choosing the stepsize value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Lagrangian Duality</head><p>In this section, we consider a major application of the subgradient method developed so far, which is to the Lagrangian function of an optimization problem. In particular, we consider a constrained optimization problem, which we refer to as primal problem, and the corresponding Lagrangian dual problem. Motivated by the standard characterization of the primal-dual optimal solutions as the saddle points of the Lagrangian function, we use the subgradient method of ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) to construct approximate primal and dual optimal solutions with per-iteration performance bounds. We start by introducing primal and dual problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Primal and Dual Problems</head><p>We consider the following constrained optimization problem:</p><formula xml:id="formula_48">min f (x), s.t. g(x) ≤ 0, x ∈ X, (<label>11</label></formula><formula xml:id="formula_49">)</formula><p>where f : R n → R is a convex function, g = (g 1 , . . . , g m ) , each g j : R n → R is a convex function, and X ⊂ R n is a nonempty closed convex set. We refer to this problem as the primal problem. We denote the primal optimal value by f * . The dual problem of ( <ref type="formula" target="#formula_48">11</ref>) is defined through Lagrangian relaxation of the inequality constraints g(x) ≤ 0 and is given by max q(μ),</p><formula xml:id="formula_50">s.t. μ ≥ 0, μ ∈ R m .</formula><p>The dual objective function q : R m + → R is defined by</p><formula xml:id="formula_51">q(μ) = inf x∈X L(x, μ),<label>(12)</label></formula><p>where L(x, μ) : X × R m + → R is the Lagrangian function defined by</p><formula xml:id="formula_52">L(x, μ) = f (x) + μ g(x). (<label>13</label></formula><formula xml:id="formula_53">)</formula><p>We denote the dual optimal value by q * and the dual optimal set by M * . It is well-known that for any μ ≥ 0, the dual function value q(μ) is a lower bound on the primal optimal value f * , i.e., weak duality holds. Moreover, under standard Constraint Qualifications (such as the Slater condition which will be discussed in the following section), the optimal values of the primal and the dual problems are equal, i.e., there is zero duality gap, and there exists a dual optimal solution, i.e., the set M * is nonempty (see for example Bertsekas <ref type="bibr" target="#b24">[25]</ref> or Bertsekas, Nedić, and Ozdaglar <ref type="bibr" target="#b25">[26]</ref>). Therefore, in view of the favorable structure of the dual problem, it is a common approach to solve the dual problem using subgradient methods, hence providing approximate dual optimal solutions and bounds on the primal optimal value in finite number of iterations. More recent literature also considered exploiting the subgradient information generated in the dual space directly to produce approximate primal solutions (see Sherali and Choi <ref type="bibr" target="#b26">[27]</ref>, Larsson, Patriksson, and Strömberg <ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>, Nesterov <ref type="bibr" target="#b30">[31]</ref>, and Nedić and Ozdaglar <ref type="bibr" target="#b23">[24]</ref>).</p><p>The use of subgradient methods for solving the dual problem relies on the assumption that the subgradients of the dual function can be evaluated efficiently at each iteration. Due to the structure of the dual function q, the subgradients of q at a vector μ are related to the vectors x μ attaining the minimum in <ref type="bibr" target="#b11">(12)</ref>. Specifically, we have the following relation for the subdifferential set ∂q(μ) of the dual function q at a given μ ≥ 0 (see Bertsekas, Nedić, and Ozdaglar <ref type="bibr" target="#b25">[26]</ref>, Proposition 4.5.1):</p><formula xml:id="formula_54">conv({g(x μ ) | x μ ∈ X μ }) ⊆ ∂q(μ), X μ = {x μ ∈ X | q(μ) = f (x μ ) + μ g(x μ )}.</formula><p>Hence, effective use of dual subgradient methods requires efficient computation of the minimizer x μ in (12) at each iteration (which is possible when the Lagrangian function has a favorable structure). In many applications however, the Lagrangian function lacks any special structure that allows efficient computation of the minimizer x μ , and therefore efficient computation of a subgradient of the dual function.</p><p>In the rest of the paper, we focus on this case. In particular, we want to investigate auxiliary procedures for generating directions that may be good approximations of the subgradients. Our development is motivated by the following standard result that characterizes the primal-dual optimal solutions as the saddle points of the Lagrangian function (see Bertsekas <ref type="bibr" target="#b24">[25]</ref>, Prop. 5.1.6). Theorem 4.1 (Saddle-Point Theorem) The pair (x * , μ * ) with x * ∈ X and μ * ≥ 0 is a primal-dual optimal solution pair if and only if x * ∈ X, μ * ≥ 0, and the following relation holds:</p><formula xml:id="formula_55">L(x * , μ) ≤ L(x * , μ * ) ≤ L(x, μ * ), for all x ∈ X, μ ≥ 0, i.e., (x * , μ * )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>is a saddle point of the Lagrangian function L(x, μ).</head><p>Based on this characterization, we will use the subgradient method of the previous section for finding the saddle points of the Lagrangian function. The averaging scheme will allow us to construct approximate primal and dual optimal solutions with per-iteration error bounds. We then provide stronger error estimates under the Slater constraint qualification. The key feature that allows us to obtain stronger bounds is the boundedness of the dual optimal solution set under Slater condition. This feature is elaborated further in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Boundedness of the Optimal Dual Set</head><p>In this section, we show that any set of the form {μ ≥ 0 | q(μ) ≥ c} for a fixed c (which includes the dual optimal set as a special case for c = q * ) is bounded under the standard Slater constraint qualification, formally given in the following assumption. Assumption 4.1 (Slater Condition) There exists a vector x ∈ R n such that g j ( x) &lt; 0, for all j = 1, . . . , m.</p><p>We refer to a vector x satisfying the Slater condition as a Slater vector.</p><p>In addition to guaranteeing zero duality gap and the existence of a dual optimal solution, Slater condition also implies that the dual optimal set is bounded (see for example Hiriart-Urruty and Lemaréchal <ref type="bibr" target="#b31">[32]</ref>). This property of the dual optimal set under the Slater condition, has been observed and used as early as in Uzawa's analysis of Arrow-Hurwicz gradient method in <ref type="bibr" target="#b6">[7]</ref>. Nevertheless this fact has not been utilized in most analysis of subgradient methods in the literature <ref type="foot" target="#foot_0">3</ref> .</p><p>The following proposition extends the result on the optimal dual set boundedness under the Slater condition. In particular, it shows that the Slater condition guarantees the boundedness of the (level) sets {μ ≥ 0 | q(μ) ≥ c} (see Hiriart-Urruty and Lemaréchal <ref type="bibr" target="#b31">[32]</ref> and Nedić and Ozdaglar <ref type="bibr" target="#b23">[24]</ref>). Lemma 4.1 Let μ ≥ 0 be a vector and consider the set</p><formula xml:id="formula_56">Q μ = {μ ≥ 0 | q(μ) ≥ q( μ)}.</formula><p>Let the Slater condition hold (cf. Assumption 4.1). Then, the set Q μ is bounded and, in particular, we have</p><formula xml:id="formula_57">μ 1 ≤ 1 γ (f ( x) -q( μ)) , for all μ ∈ Q μ,</formula><p>where γ = min 1≤j ≤m {-g j ( x)} and x is a Slater vector.</p><p>An immediate implication of this result is that, for any dual optimal solution μ * , we have</p><formula xml:id="formula_58">μ * 1 ≤ 1 γ f ( x) -q * . (<label>14</label></formula><formula xml:id="formula_59">)</formula><p>This fact will be used in constructing a slight variation of the subgradient method of ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Primal-Dual Subgradient Method</head><p>In this section, we apply the subgradient method of ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) to the Lagrangian function of <ref type="bibr" target="#b12">(13)</ref>. Since the Lagrangian function L(x, μ) is defined over X × R m + , an application of the method involves choosing the set M to be the nonnegative orthant R m + . In this case the dual iterates μ k generated by the algorithm need not be bounded. Note that the subgradients with respect to x and μ of the Lagrangian function L(x, μ) at the vector (x k , μ k ) are given by</p><formula xml:id="formula_60">L x (x k , μ k ) = s f (x k ) + m j =1 μ j k s g j (x k ), L μ (x k , μ k ) = g(x k ), (<label>15</label></formula><formula xml:id="formula_61">)</formula><p>where μ j k is the j th component of the vector μ k , while s f (x k ) and s g j (x k ) are respectively subgradients of f and g j at x k . If the dual iterates μ k are not bounded, then the subgradients (L x (x k , μ k ), L μ (x k , μ k )) need not be bounded. This violates the Subgradient Boundedness assumption (cf. Assumption 3.1). In the existing literature on saddle-point subgradient methods, such boundedness assumptions have been often assumed without any explicit guarantees on the boundedness of the dual iterates (see Gol'shtein <ref type="bibr" target="#b7">[8]</ref>).</p><p>One of the contributions of this paper is the following variation of the subgradient method of ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) using the Slater condition, which allows us to dispense with the boundedness assumption on the dual iterates μ k generated by the algorithm. In particular, we consider a primal-dual subgradient method in which the iterates are generated by the following:</p><formula xml:id="formula_62">x k+1 = P X [x k -αL x (x k , μ k )] , for k = 0, 1, . . . , (<label>16</label></formula><p>)</p><formula xml:id="formula_63">μ k+1 = P D [μ k + αL μ (x k , μ k )], for k = 0, 1, . . . ,<label>(17)</label></formula><p>where the set D is a compact convex set that contains the set of dual optimal solutions (to be discussed shortly) and P X and P D denote the projection on the sets X and D respectively. The vectors x 0 ∈ X and μ 0 ≥ 0 are initial iterates, and the scalar α &gt; 0 is a constant stepsize. Here L x (x k , μ) denotes a subgradient with respect to x of the Lagrangian function L(x, μ) at the vector x k . Similarly, L μ (x, μ k ) denotes a subgradient with respect to μ of the Lagrangian function L(x, μ) at the vector μ k [cf. <ref type="bibr" target="#b14">(15)</ref>].</p><p>Under the Slater condition, the dual optimal set M * is nonempty and bounded, and a bound on the norms of the dual optimal solutions is given by</p><formula xml:id="formula_64">μ * 1 ≤ 1 γ (f ( x) -q * ), for all μ * ∈ M * ,</formula><p>with γ = min 1≤j ≤m {-g j ( x)} and x a Slater vector [cf. <ref type="bibr" target="#b13">(14)</ref>]. Thus, having the dual value q = q( μ) for some μ ≥ 0, since q * ≥ q, we obtain</p><formula xml:id="formula_65">μ * 1 ≤ 1 γ (f ( x) -q), for all μ * ∈ M * . (<label>18</label></formula><formula xml:id="formula_66">)</formula><p>This motivates the following choice for the set D:</p><formula xml:id="formula_67">D = μ ≥ 0 μ ≤ f ( x) - q γ + r ,<label>(19)</label></formula><p>with a scalar r &gt; 0. Clearly, the set D is compact and convex, and it contains the set of dual optimal solutions in view of relation <ref type="bibr" target="#b17">(18)</ref> and the fact y ≤ y 1 for any vector y. Under this choice of set D, the dual sequence {μ k } is bounded. This allows us to make the following assumption.</p><p>Assumption 5.1 (Bounded Subgradients) Let the sequences {x k } and {μ k } be generated by the subgradient algorithm ( <ref type="formula" target="#formula_62">16</ref>)- <ref type="bibr" target="#b16">(17)</ref>. The subgradients L x (x k , μ k ) and L μ (x k , μ k ) are uniformly bounded for all k, i.e., there exists some L &gt; 0 such that max</p><formula xml:id="formula_68">k≥0 max L x (x k , μ k ) , L μ (x k , μ k ) ≤ L.</formula><p>This assumption is satisfied for example when f and all g j 's are affine functions, or when the set X is compact. In the latter case, since the functions f and g j 's are convex over R n , they are also continuous over R n , and therefore the sets x∈X ∂f (x) and x∈X ∂g j (x) are bounded (see Bertsekas, Nedić, and Ozdaglar <ref type="bibr" target="#b25">[26]</ref>, Proposition 4.2.3). Moreover, max x∈X g(x) is finite, thus we can provide a uniform upper bound on the norm of the subgradient sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Approximate Primal Solutions under the Slater Condition</head><p>In this section, we focus on constructing primal solutions by using the iterates generated by the primal-dual subgradient algorithm ( <ref type="formula" target="#formula_10">5</ref>)- <ref type="bibr" target="#b5">(6)</ref>. Our goal is to generate approximate primal solutions and provide performance guarantees in terms of bounds on the amount of feasibility violation and primal cost values at each iteration. We generate primal solutions by averaging the vectors from the sequence {x k }. In particular, we define xk as the average of the vectors x 0 , . . . , x k-1 , i.e.,</p><formula xml:id="formula_69">xk = 1 k k-1 i=0 x i , for all k ≥ 1.<label>(20)</label></formula><p>The average vectors xk lie in the set X because X is convex and x i ∈ X for all i. However, these vectors need not satisfy the primal inequality constraints g j (x) ≤ 0, j = 0, . . . , m, and therefore, they can be primal infeasible.</p><p>In the next proposition, we provide per-iterate error estimates on the feasibility violation and primal cost values of the average vectors xk . Proposition 5.1 Let the Slater condition and the bounded subgradient assumption hold (cf. Assumptions 4.1 and 5.1). Let the sequences {x k } and {μ k } be generated by the subgradient algorithm (16)- <ref type="bibr" target="#b16">(17)</ref>. Let { xk } be the sequence of the primal averages as defined in <ref type="bibr" target="#b19">(20)</ref> and let x * be a primal optimal solution. Then, for all k ≥ 1, we have:</p><p>(a) An upper bound on the amount of constraint violation of the vector xk is given by</p><formula xml:id="formula_70">g( xk ) + ≤ 2 kαr f ( x) - q γ + r 2 + x 0 -x * 2 2kαr + αL 2 2r .</formula><p>(b) An upper bound on the primal cost of the vector xk is given by</p><formula xml:id="formula_71">f ( xk ) ≤ f * + μ 0 2 2kα + x 0 -x * 2 2kα + αL 2 .</formula><p>(c) A lower bound on the primal cost of the vector xk is given by</p><formula xml:id="formula_72">f ( xk ) ≥ f * - f ( x) - q γ g( xk ) + .</formula><p>Here, the scalars r &gt; 0 and q with q ≤ q * are those from the definition of the set D in <ref type="bibr" target="#b18">(19)</ref>, γ = min 1≤j ≤m {-g j ( x)}, x is the Slater vector of Assumption 4.1, and L is the subgradient norm bound of Assumption 5.1.</p><p>Proof (a) Using the definition of the iterate μ k+1 in <ref type="bibr" target="#b16">(17)</ref> and the nonexpansive property of projection on a closed convex set, we obtain for all μ ∈ D and all i ≥ 0,</p><formula xml:id="formula_73">μ i+1 -μ 2 = P D [μ i + αL μ (x i , μ i )] -μ 2 ≤ μ i + αL μ (x i , μ i ) -μ 2 ≤ μ i -μ 2 + 2α(μ i -μ) L μ (x i , μ i ) + α 2 L μ (x i , μ i ) 2 ≤ μ i -μ 2 + 2α(μ i -μ) L μ (x i , μ i ) + α 2 L 2 ,</formula><p>where the last inequality follows from the boundedness of the subgradients [cf. Assumption 5.1]. Therefore, for any μ ∈ D,</p><formula xml:id="formula_74">(μ -μ i ) L μ (x i , μ i ) ≤ μ i -μ 2 -μ i+1 -μ 2 2α + αL 2 2</formula><p>, for all i ≥ 0. ( <ref type="formula">21</ref>)</p><p>Since L μ (x i , μ i ) is a subgradient of the function L(x i , μ) at μ = μ i , using the subgradient inequality [cf. ( <ref type="formula" target="#formula_5">2</ref>)], we obtain that, for any dual optimal solution μ * ,</p><formula xml:id="formula_75">(μ i -μ * ) L μ (x i , μ i ) ≤ L(x i , μ i ) -L(x i , μ * ), for all i ≥ 0.</formula><p>Since (x * , μ * ) is a primal-dual optimal solution pair and x i ∈ X, it follows from Theorem 4.1 that</p><formula xml:id="formula_76">L(x i , μ * ) ≥ L(x * , μ * ) = f * .</formula><p>Combining the preceding two relations, we obtain</p><formula xml:id="formula_77">(μ i -μ * ) L μ (x i , μ i ) ≤ L(x i , μ i ) -f * .</formula><p>We then have, for all μ ∈ D and all i ≥ 0,</p><formula xml:id="formula_78">(μ -μ * ) L μ (x i , μ i ) = (μ -μ * -μ i + μ i ) L μ (x i , μ i ) = (μ -μ i ) L μ (x i , μ i ) + (μ i -μ * )L μ (x i , μ i ) ≤ (μ -μ i ) L μ (x i , μ i ) + L(x i , μ i ) -f * .</formula><p>From the preceding relation and ( <ref type="formula">21</ref>), we obtain that, for any μ ∈ D,</p><formula xml:id="formula_79">(μ -μ * ) L μ (x i , μ i ) ≤ μ i -μ 2 -μ i+1 -μ 2 2α + αL 2 2 + L(x i , μ i ) -f * , for all i ≥ 0.</formula><p>Summing over i = 0, . . . , k -1 for k ≥ 1, we obtain, for any μ ∈ D and k ≥ 1,</p><formula xml:id="formula_80">k-1 i=0 (μ -μ * ) L μ (x i , μ i ) ≤ μ 0 -μ 2 -μ k -μ 2 2α + αkL 2 2 + k-1 i=0 L(x i , μ i ) -kf * ≤ μ 0 -μ 2 2α + αkL 2 2 + k-1 i=0 L(x i , μ i ) -kf * .</formula><p>Therefore, for any k ≥ 1,</p><formula xml:id="formula_81">max μ∈D k-1 i=0 (μ -μ * ) L μ (x i , μ i ) ≤ 1 2α max μ∈D μ 0 -μ 2 + αkL 2 2 + k-1 i=0 L(x i , μ i ) -kf * . (<label>22</label></formula><formula xml:id="formula_82">)</formula><p>We now provide a lower estimate on the left-hand side of the preceding relation. Let k ≥ 1 be arbitrary and, for simplicity, we suppress the explicit dependence on k by letting</p><formula xml:id="formula_83">s = k-1 i=0 L μ (x i , μ i ). (<label>23</label></formula><formula xml:id="formula_84">)</formula><p>In view of the fact L μ (x i , μ i ) = g(x i ), it follows that</p><formula xml:id="formula_85">s = k-1 i=0 g(x i ). (<label>24</label></formula><formula xml:id="formula_86">)</formula><p>By convexity of the functions g j , it further follows that s ≥ kg( xk ). Hence, if s + = 0, then the bound in part (a) of this proposition trivially holds. Therefore, assume that s + = 0 and define a vector μ as follows:</p><formula xml:id="formula_87">μ = μ * + r s + s + .</formula><p>Note that μ ≥ 0 since μ * ≥ 0, s + ≥ 0 and r &gt; 0. By Lemma 4.1, the dual optimal solution set is bounded and, in particular, μ * ≤ f ( x)-q * γ . Furthermore, since q ≤ q, it follows that μ * ≤ f ( x)- q γ for any dual solution μ * . Therefore, by the definition of the vector μ, we have</p><formula xml:id="formula_88">μ ≤ μ * + r ≤ f ( x) - q γ + r, (<label>25</label></formula><formula xml:id="formula_89">)</formula><p>implying that μ ∈ D. Using the definition of the vector s in <ref type="bibr" target="#b22">(23)</ref> and relation <ref type="bibr" target="#b21">(22)</ref>, we obtain</p><formula xml:id="formula_90">( μ -μ * ) s = k-1 i=0 ( μ -μ * ) L μ (x i , μ i ) ≤ max μ∈D k-1 i=0 (μ -μ * ) L μ (x i , μ i ) ≤ 1 2α max μ∈D μ 0 -μ 2 + αkL 2 2 + k-1 i=0 L(x i , μ i ) -kf * . (<label>26</label></formula><formula xml:id="formula_91">)</formula><p>Since μμ * = r s + s + , we have ( μμ * ) s = r s + . By using the expression for s given in <ref type="bibr" target="#b23">(24)</ref>, we obtain</p><formula xml:id="formula_92">( μ -μ * ) s = r k-1 i=0 g(x i ) + .</formula><p>Substituting the preceding equality in <ref type="bibr" target="#b25">(26)</ref> and dividing both sides by r, we obtain</p><formula xml:id="formula_93">k-1 i=0 g(x i ) + ≤ 1 2αr max μ∈D μ 0 -μ 2 + αkL 2 2r + 1 r k-1 i=0 L(x i , μ i ) -kf * . (<label>27</label></formula><formula xml:id="formula_94">)</formula><p>Dividing both sides of this relation by k, and using the convexity of the functions g j in g = (g 1 , . . . , g m ) together with the definition of the average primal vector xk yields</p><formula xml:id="formula_95">g( xk ) + ≤ 1 k k-1 i=0 g(x i ) + ≤ 1 2kαr max μ∈D μ 0 -μ 2 + αL 2 2r + 1 r 1 k k-1 i=0 L(x i , μ i ) -f * . (28) Since μ 0 ∈ D, it follows that max μ∈D μ 0 -μ 2 ≤ max μ∈D ( μ 0 + μ ) 2 ≤ 4 max μ∈D μ 2 .</formula><p>By using the definition of the set D [cf. ( <ref type="formula" target="#formula_67">19</ref>)], we have</p><formula xml:id="formula_96">max μ∈D μ ≤ f ( x) - q γ + r.</formula><p>Using Proposition 3.1(a) with the substitution L(x * , μ * ) = f * and M = D, we can also provide an upper bound on the last term in ( <ref type="formula" target="#formula_93">27</ref>):</p><formula xml:id="formula_97">1 k k-1 i=0 L(x i , μ i ) -f * ≤ x 0 -x * 2 2αk + αL 2 2 . (<label>29</label></formula><formula xml:id="formula_98">)</formula><p>Substituting the preceding three estimates in the relation of ( <ref type="formula">28</ref>) we obtain the desired upper bound on the amount of constraint violation of the average vector xk , i.e.,</p><formula xml:id="formula_99">g( xk ) + ≤ 2 kαr f ( x) - q γ + r 2 + x 0 -x * 2 2kαr + αL 2 r .</formula><p>(b) By the convexity of the cost function f , we have</p><formula xml:id="formula_100">f ( xk ) ≤ 1 k k-1 i=0 f (x i ) = 1 k k-1 i=0 L(x i , μ i ) - 1 k k-1 i=0 μ i g(x i ).</formula><p>Thus, it follows by <ref type="bibr" target="#b28">(29)</ref> that</p><formula xml:id="formula_101">f ( xk ) -f * ≤ 1 k k-1 i=0 L(x i , μ i ) -f * - 1 k k-1 i=0 μ i g(x i ) ≤ x 0 -x * 2 2αk + αL 2 2 - 1 k k-1 i=0 μ i g(x i ). (<label>30</label></formula><formula xml:id="formula_102">)</formula><p>We next provide a lower bound on -</p><formula xml:id="formula_103">1 k k-1 i=0 μ i g(x i</formula><p>). Note that 0 ∈ D, so that from Lemma 3.1(b) with μ = 0, we have</p><formula xml:id="formula_104">μ k+1 2 ≤ μ k 2 + 2αμ k g(x k ) + α 2 L 2 .</formula><p>Thus,</p><formula xml:id="formula_105">-2αμ k g(x k ) ≤ μ k 2 -μ k+1 2 + α 2 L 2 , implying that -μ k g(x k ) ≤ 1 2α μ k 2 -μ k+1 2 + αL 2 2 .</formula><p>By summing these relations, we obtain</p><formula xml:id="formula_106">- k-1 i=0 μ i g(x i ) ≤ 1 2α μ 0 2 -μ k 2 + kαL 2 2 .</formula><p>Hence,</p><formula xml:id="formula_107">- 1 k k-1 i=0 μ i g(x i ) ≤ μ 0 2 2αk + αL 2 2 .</formula><p>The estimate follows by substituting the preceding relation in <ref type="bibr" target="#b29">(30)</ref>. (c) For any dual optimal solution μ * , we have</p><formula xml:id="formula_108">f ( xk ) = f ( xk ) + (μ * ) g( xk ) -(μ * ) g( xk ) = L( xk , μ * ) -(μ * ) g( xk ).</formula><p>By the saddle-point theorem [cf. Theorem 4.1], it follows that</p><formula xml:id="formula_109">L( xk , μ * ) ≥ L(x * , μ * ) = f * . Hence, f ( xk ) ≥ f * -(μ * ) g( xk ).<label>(31)</label></formula><p>Furthermore, since μ * ≥ 0 and g( xk</p><formula xml:id="formula_110">) ≤ g + ( xk ), it follows that -(μ * ) g( xk ) ≥ -(μ * ) g + ( xk ) ≥ -μ * g + ( xk ) .</formula><p>Since μ * ≤ f ( x)-q * γ and q * ≥ q, it follows that μ * ≤ f ( x)- q γ , which when substituted in (31) yields the desired estimate.</p><p>We note here that the primal-dual method of ( <ref type="formula" target="#formula_10">5</ref>)-( <ref type="formula" target="#formula_11">6</ref>) with the set D as given in <ref type="bibr" target="#b18">(19)</ref> couples the computation of multipliers through the projection operation. In some applications, it might be desirable to accommodate distributed computation models whereby the multiplier components μ j are processed in a distributed manner among a set of processors or agents. To accommodate such computations, one may modify the subgradient method of ( <ref type="formula" target="#formula_62">16</ref>)-( <ref type="formula" target="#formula_63">17</ref>) by replacing the set D of (19) with the following set:</p><formula xml:id="formula_111">D ∞ = μ ≥ 0 μ ∞ ≤ f ( x) - q γ + r .</formula><p>It can be seen that the results of Proposition 5.1 also hold for this choice of the projection set. In particular, this can be seen by following the same line of argument as in the proof of Proposition 5.1 [by using the fact y ∞ ≤ y in (25)].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Optimal Choice for the Set D</head><p>The bound provided in part (a) of Proposition 5.1 is a function of the parameter r, which is used in the definition of the set D [cf. <ref type="bibr" target="#b18">(19)</ref>]. We next consider selecting the parameter r such that the right-hand side of the bound in part (a) of Proposition 5.1 is minimized at each iteration k. Given some k ≥ 1, we choose r as the optimal solution of the problem</p><formula xml:id="formula_112">min r&gt;0 2 kαr f ( x) - q γ + r 2 + x 0 -x * 2 2kαr + αL 2 2r .</formula><p>It can be seen that the optimal solution of the preceding problem, denoted by r * (k), is given by</p><formula xml:id="formula_113">r * (k) = f ( x) - q γ 2 + x 0 -x * 2 4 + kα 2 L 2 4 , for k ≥ 1.<label>(32)</label></formula><p>Consider now an algorithm where the dual iterates are obtained by μ i+1 = P D k [μ i + αL μ (x i , μ i )], for each i ≥ 0, with μ 0 ∈ D 0 and the set D k given by</p><formula xml:id="formula_114">D k = μ ≥ 0 μ ≤ f ( x) - q γ + r * (k) ,</formula><p>where r * (k) is given by <ref type="bibr" target="#b31">(32)</ref>. Hence, at each iteration i, the algorithm projects onto the set D k , which contains the set of dual optimal solutions M * . Substituting r * (k) in the bound of Proposition 5.1(a), we can see that</p><formula xml:id="formula_115">g( xk ) + ≤ 4 kα ⎛ ⎝ f ( x) - q γ + f ( x) - q γ 2 + x 0 -x * 2 4 + kα 2 L 2 4 ⎞ ⎠ ≤ 4 kα 2(f ( x) -q) γ + x 0 -x * 2 + αL √ k 2 = 8 kα f ( x) - q γ + 2 x 0 -x * kα + 2L √ k .</formula><p>The preceding discussion combined with Proposition 5.1(a) immediately yields the following result. (33) where x is the Slater vector of Assumption 4.1, γ = min 1≤j ≤m {-g j ( x)}, and L is the bound on the subgradient norm of Assumption 5.1. Let the primal-dual sequence {x i , μ i } be generated by the following modified subgradient method: Let x 0 ∈ X and μ 0 ∈ D k . For each i ≥ 0, the iterates x i and μ i are obtained by</p><formula xml:id="formula_116">x i+1 = P X [x i -αL x (x i , μ i )] , μ i+1 = P D k [μ i + αL μ (x i , μ i )],</formula><p>i.e., at each iteration, the dual solutions are projected onto the set D k . Then, an upper bound on the amount of feasibility violation of the vector xk is given by</p><formula xml:id="formula_117">g( xk ) + ≤ 8 kα f ( x) - q γ + 2 x 0 -x * kα + 2L √ k . (<label>34</label></formula><formula xml:id="formula_118">)</formula><p>This result shows that for a given k, the error estimate provided in (34) can be achieved if we use a primal-dual subgradient method where each dual iterate is projected on the set D k defined in (33). Given a pre-specified accuracy for the amount of feasibility violation, this bound can be used to select the stepsize value and the set D k for the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We presented a subgradient method for generating approximate saddle points for a convex-concave function L(x, μ) defined over X × M. This algorithm takes steps along directions defined by the subgradients of the function L(x, μ) with respect to x and μ, and uses an averaging scheme to produce approximate saddle points. We showed that under the assumption that the iterates generated by the algorithm are bounded (which will hold when the sets X and M are compact), the function values L( xk , μk ), at the iterate averages xk and μk , converge to the function value at a saddle point with rate 1/k and with an error level which is a function of the stepsize value.</p><p>We then focused on Lagrangian duality, where we consider a convex primal optimization problem and its Lagrangian dual. We proposed using our subgradient algorithm for generating saddle points of the Lagrangian function of the primal problem, which provide approximate primal-dual optimal solutions. Under Slater condition, we studied a variation of our algorithm which allowed us to generate convergence rate estimates without imposing boundedness assumptions on the generated iterates.</p><p>An important application of our work is in resource allocation problems for networked-systems. In this context, Lagrangian duality and subgradient methods for solving the dual problem have been used with great success in developing decentralized network algorithms (see Low and Lapsley <ref type="bibr" target="#b0">[1]</ref>, Srikant <ref type="bibr" target="#b1">[2]</ref>, and Chiang et al. <ref type="bibr" target="#b2">[3]</ref>). This approach relies on the assumption that the subgradient of the dual function can be evaluated efficiently. This implicitly assumes that the Lagrangian function is decomposable, which will hold when the primal problem has a separable structure. Our results in this paper can be used to generalize this approach to more general non-separable resource allocation problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The result in part (a) of the preceding proposition provides bounds on the averaged function values1 k k-1 i=0 L(x i , μ i ) interms of the distances of the initial iterates μ 0 and x 0 from the vectors x * and μ * that constitute a saddle point of L. In particular, the averaged function values 1 k k-1 i=0 L(x i , μ i ) converge to the saddle point value L(x * , μ * ) within error level αL 2 /2 with rate 1/k. The result in part (b) gives bounds on the function value L( xk , μk ) of the averaged iterates xk and μk in terms of the distances of the averaged iterates from the initial iterates and saddle point vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 5 . 2</head><label>52</label><figDesc>Let the Slater condition and the bounded subgradient assumption hold [cf. Assumptions 4.1 and 5.1]. Fix a positive integer k ≥ 1, and define the set D k as</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>See also our recent work<ref type="bibr" target="#b23">[24]</ref> for the analysis of dual subgradient methods under Slater assumption.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b0">1</ref> <p>Note that, though not explicitly stated in <ref type="bibr" target="#b6">[7]</ref>, Uzawa's proof holds under the assumption that the function L(x, μ) is strictly convex in x.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimization flow control, I: Basic algorithm and convergence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Lapsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mathematics of Internet Congestion Control</title>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Birkhauser</publisher>
			<pubPlace>Basel</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Layering as optimization decomposition: a mathematical theory of network architectures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Doyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="255" to="312" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Arrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hurwicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Uzawa</surname></persName>
		</author>
		<title level="m">Studies in Linear and Non-Linear Programming</title>
		<meeting><address><addrLine>Stanford</addrLine></address></meeting>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the weak convergence of an ergodic iteration for the solution of variational inequalities for monotone operators in Hilbert space</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bruck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="159" to="164" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cezare convergence of gradient method approximation of saddle points for convex-concave functions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Judin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dokl. Akad. Nauk SSSR</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="page" from="1056" to="1059" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Iterative methods in concave programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>Uzawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in Linear and Nonlinear Programming</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Arrow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Hurwicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Uzawa</surname></persName>
		</editor>
		<meeting><address><addrLine>Stanford</addrLine></address></meeting>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="1958">1958</date>
			<biblScope unit="page" from="154" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A generalized gradient method for finding saddle points</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Gol'shtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matekon</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="36" to="52" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient methods for finding saddle points</title>
		<author>
			<persName><forename type="first">D</forename><surname>Maistroskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matekon</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3" to="22" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A subgradient method for finding a saddle point of a convex-concave function</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Zabotin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Issled. Prikl. Mat</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="6" to="12" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The extragradient method for finding saddle points and other problems</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Korpelevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matekon</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="35" to="49" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Perturbation methods for saddle point computation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kallio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruszczyński</surname></persName>
		</author>
		<idno>No. WP-94- 38</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>International Institute for Applied Systems Analysis</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large-scale convex optimization via saddle-point computation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kallio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Rosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="93" to="101" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mirror descent and nonlinear projected subgradient methods for convex optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Prox-method with rate of convergence O(1/t) for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Nemirovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="251" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interior gradient and proximal methods for convex and conic optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auslender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="697" to="725" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Projected subgradient methods with non-Euclidean distances for nondifferentiable convex minimization and variational inequalities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auslender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10107-007-0147-z</idno>
	</analytic>
	<monogr>
		<title level="j">Math. Program., Ser. B</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Translated from Russian by</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Z</forename><surname>Shor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Minimization methods for Nondifferentiable Functions</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Kiwiel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ruszczynski</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Introduction to Optimisation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Software</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">F</forename><surname>Demyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Vasilyev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Nondifferentiable Optimization. Optimization Software</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Convergence of some algorithms for convex minimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lemaréchal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="261" to="271" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Convergence rate of incremental subgradient algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Optimization: Algorithms and Applications</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Uryasev</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Pardalos</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer Academic, Dordrecht</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Incremental subgradient methods for nondifferentiable optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="138" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Approximate primal solutions and rate analysis for dual subgradient methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1757" to="1780" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear Programming</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convex Analysis and Optimization</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recovery of primal solutions when using subgradient optimization methods to solve Lagrangian duals of linear programs</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sherali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="105" to="113" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ergodic results and bounds on the optimal value in subgradient optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strömberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Operations Research Proceedings</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Kelinschmidt</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ergodic convergence in subgradient optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strömberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Soft</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="93" to="120" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ergodic primal convergence in dual subgradient schemes for convex programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strömberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="283" to="312" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Primal-dual subgradient methods for convex problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<idno>No. 67</idno>
	</analytic>
	<monogr>
		<title level="j">Center for Operations Research and Econometrics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Catholic University of Louvain (UCL</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">CORE) Report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lemaréchal</surname></persName>
		</author>
		<title level="m">Convex Analysis and Minimization Algorithms</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
