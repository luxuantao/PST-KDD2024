<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Web Image Mining Towards Universal Age Estimator</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Engineering Drive</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<postCode>117576</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Engineering Drive</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<address>
									<postCode>117576</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Engineering Drive</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<address>
									<postCode>117576</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">Universal Age Estimator</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Web Image Mining Towards Universal Age Estimator</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F3AB8A71CCC9225771FA46E681A2F5B3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.4.9 [Computing Methodologies]: Image Processing and Computer Vision-Applications Algorithm</term>
					<term>Performance</term>
					<term>Experimentations Internet Vision</term>
					<term>Age Estimation</term>
					<term>Multi-instance Regression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present an automatic web image mining system towards building a universal human age estimator based on facial information, which is applicable to all ethnic groups and various image qualities. First, a large (∼391k) yet noisy human aging image dataset is crawled from the photo sharing website Flickr and Google image search engine based on a set of human age related text queries. Then, within each image, several human face detectors of different implementations are used for robust face detection, and all the detected faces with multiple responses are considered as the multiple instances of a bag (image). An outlier removal step with Principal Component Analysis further refines the image set to about 220k faces, and then a robust multi-instance regressor learning algorithm is proposed to learn the kernel-regression based human age estimator under the scenarios with possibly noisy bags. The proposed system has the following characteristics: 1) no manual human age labeling process is required, and the age information is automatically obtained from the age related queries, 2) the derived human age estimator is universal owing to the diversity and richness of Internet images and thus has good generalization capability, and 3) the age estimator learning process is robust to the noises existing in both Internet images and corresponding age labels. This automatically derived human age estimator is extensively evaluated on three popular benchmark human aging databases, and without taking any images from these benchmark databases as training samples, comparable age estimation accuracies with the state-of-the-art results are achieved.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Image based human age estimation has wide potential applications, e.g., demographic data collection for supermarkets or other public areas, age-specific human computer interfaces, age-oriented commercial advertisement, and human identification based on old ID-photos. For these applications, generally a large set of human face images with ground-truth age labels are required for learning an effective human age estimator. The previous research for human age estimation can be roughly divided into two categories according to whether the age estimation task is considered as a regression problem or a multi-class classification problem. Many efforts have been devoted to the human age estimation problem in the past few years. Kwon et al. <ref type="bibr" target="#b12">[12]</ref> proposed a human age classification method based on cranio-facial development theory and skin wrinkle analysis, where the human faces are classified into three groups, namely, babies, young and senior adults. Hayashi et al. <ref type="bibr" target="#b9">[9]</ref> proposed to use the wrinkle and geometry relationships between different parts of a face to classify the age information into groups at the five year intervals. Lanitis et al. <ref type="bibr" target="#b13">[13]</ref> adopted Active Appearance Models (AAM) <ref type="bibr" target="#b4">[4]</ref> to extract the combined shape and texture information for human age estimation. Geng et al. <ref type="bibr">[7]</ref> proposed to model the statistical properties of aging patterns, and each aging pattern characterizes the aging process for one person. Yan et al. proposed a method called Ranking with Uncertain Labels for age estimation by introducing a semidefinite programming (SDP) formulation for regression problems with uncertain nonnegative labels <ref type="bibr" target="#b21">[21]</ref>. Yan et al. later introduced a patch kernel method based on Gaussian Mixture Models (GMM) for age regression, where the best result on FG-NET database to date was reported <ref type="bibr" target="#b22">[22]</ref>. Guo et al. <ref type="bibr" target="#b8">[8]</ref> introduced an age manifold learning scheme for extracting face aging features and designed a locally adjusted robust regressor for the prediction of human ages. Recently, Fu and Huang <ref type="bibr" target="#b6">[6]</ref> developed a discriminant subspace learning method for age estimation by exploring the sequential patterns from the face images with aging features.</p><p>These approaches have achieved satisfactory human age estimation accuracies on certain benchmark human aging datasets, e.g., FG-NET <ref type="bibr" target="#b1">[1]</ref> and UIUC <ref type="bibr" target="#b6">[6]</ref> databases, there however exist two difficulties which essentially hamper the research and applications in this area:</p><p>1. Most previous algorithmic evaluations were performed on relatively small dataset(s), mainly due to the difficulties in collecting a large dataset with precise human age groundtruths. Moreover, each human aging database usually only covers one human ethnic group, and for certain ages, e.g., senior ages, the samples are rare. All these essentially limit the generalization capability of the learnt human age regressor to general face images from real applications.</p><p>2. All previous research on image based human age estimation is founded on the assumption that the face images have been cropped out and reasonably aligned. For practical applications, rough face detection has been considered as a wellsolved problem, the precise face cropping is however still far from satisfying, which consequently results in the so-called face misalignment issue. A practical solution to bridge the gap between the possibly misaligned faces and the requirement of precise face cropping for age estimation is critical to guarantee the algorithmic robustness and effectiveness in real applications.</p><p>As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, the main purpose of this research is to drive the human age estimation research more towards real scenarios. Instead of being limited to well-cropped faces and single human ethnic group, the system should be able to take general face images for training universal human age estimator, which is applicable for all ages, all ethnic groups and various image qualities. Meanwhile, the ultimate goal of this research is to design a fully automatic and real-time system which takes general face images as inputs. Our proposed solution for such targets is motivated by the following observations:</p><p>1. Though it is practically difficult or even impossible to collect a large face image set with precise age ground-truths, the Internet provides very rich resources on face images with possible age information encoded within the surrounding texts. The popular image search engines such as Google image search and photo sharing websites such as Flickr can provide a huge number of images for even a single age-related query (e.g., 15 years old), where usually thousands of correct samples from different human ethnic groups are available. There were some such attempts for web image mining, for example, Yanai and Barnard <ref type="bibr" target="#b23">[23]</ref> proposed a web image mining method for discriminative visual concept selection. The main contributions of this work are three-fold: 1) we present a web image mining scheme to harness the Internet images for collecting a large and diverse face database with nearly-correct age labels, and then use it for learning universal human age estimator; 2) we propose a novel learning algorithm to robustly derive a human age estimator based on images with multiple face instances and possibly noisy labels; and 3) we develop a fully automatic system for automatic training image collection, age regressor learning, and final age estimation, which does not rely on any kind of human interactions and is thus of great potentials in real scenarios. A system overview is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref> and the three major components of the proposed research are summarized as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Internet Aging Image Collecting</head><p>The Internet aging image collection is performed by automatically crawling images from the image search engines or photo sharing websites based on a set of age related text enquiries, e.g., "15-years-old", "age-15" and "15th-birthday" for the age of 15 years. In this step, generally more than 10k of images can be downloaded for each age, but a large portion of these images do not contain any face instance or contain only face instances with other different ages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Noisy Image and Label Filtering</head><p>In this work, we propose to adopt a pipeline approach to retain good face instances for model training as well as to filter out those noisy images or face instances as many as possible. First, we propose to conduct parallel face detection based on multiple face detectors for improving the probability to obtain well-aligned face instances for each image, and then the face instances overlapping with those at least one face instance from distinct detectors are retained as good samples for model training. Then, Principal Component Analysis <ref type="bibr" target="#b10">[10]</ref> is applied for each age and those face instances with large reconstruction errors are filtered out. This pre-screened dataset is then input into the proposed robust multi-instance regression algorithm to learn a universal human age estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Robust Multi-instance Regression</head><p>In this step, we are given a set of training face images with multiple face instances within each image, and the task is to learn a human age regressor. This problem can be considered as a specific multi-instance learning problem, but those previous multi-instance learning algorithms cannot be directly applied for this problem since there may exist noisy image labels for the training data. In this work, we present a robust multi-instance learning algorithm to tackle this problem with the awareness of label outliers.</p><p>Note that multi-instance learning is a widely studied research topic in the past few years. Keeler et al. <ref type="bibr" target="#b11">[11]</ref> first proposed the multi-instance learning concept when dealing with the hand-printed numerals detection problem, motivated by the observation that there might exist more than one numerals in a single image. After that, many researchers proposed various related schemes such as DD <ref type="bibr" target="#b14">[14]</ref>, EM-DD <ref type="bibr" target="#b24">[24]</ref> and citation-kNN <ref type="bibr" target="#b20">[20]</ref> to tackle this problem. Also the multi-instance learning concept was incorporated into both boosting and support vector machine algorithms, yielding the so  called MIL-boosting <ref type="bibr" target="#b19">[19]</ref> and MIL-SVM <ref type="bibr" target="#b2">[2]</ref> algorithms. There also exist several algorithms proposed for the multiple instance multiple label learning problem <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b25">25]</ref>. Besides these classification problems, recently Ray et al. <ref type="bibr" target="#b15">[15]</ref> proposed a multi-instance regression framework to deal with the regression problem, which is the most related work with our research in this work. This algorithm does not consider the noisy label issue, and therefore the algorithmic robustness cannot be guaranteed. The rest of this paper is organized as follows. Section 2 introduces the Internet aging image collecting and noise pre-screening process. The robust multi-instance regression algorithm is elaborated in Section 3 and the experimental results are demonstrated in Section 4. Section 5 concludes this paper along with discussion of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">INTERNET AGING IMAGE DATABASE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Internet Aging Image Collecting</head><p>A universal age estimator heavily relies on a large training image set with the age ground-truths. Generally the human facial images are very easy to obtain from different sources, their precise age labels are however not easy to obtain, especially when a universal age estimator is expected for all ethnic groups. Generally there are two ways to obtain such age labels. In the first way, the real age labels are known, provided right by the humans in the images or recorded when capturing the images. The FG-NET <ref type="bibr" target="#b1">[1]</ref> and UIUC <ref type="bibr" target="#b6">[6]</ref> aging databases belong to this category. For the second way, the age labels are obtained based on the human estimations and the database used in <ref type="bibr" target="#b9">[9]</ref> belongs to this category.</p><p>Recent years have witnessed an explosion of social media content shared online, e.g., Flickr. For these community-contributed media repositories, the users may upload personal media data with informative titles and annotate with descriptive tags. For those human face related images, the human age information is often naturally involved within the media titles and tags, e.g., the titles like Mother's 50th Birthday and the tags like 15-years. Also for those popular image search engines, e.g., Google image search, a large amount of images are available based on age related queries. Although it is often the case that the titles/tags and queries might be irrelevant to those retrieved images, there do exist a considerable portion of images with correct information on ages. Motivated by this observation, we propose to crawl aging images from the Internet (we use Flickr and Google image search in this work) based on a set of age related text queries. In this work, we construct the query list using the age related templates such as xx-years-old, agexx and xxth-birthday, and finally about 10k to 20k images could be downloaded for each age from 1 year old to 80 years old. Note that we do not explicitly use the ages over 80 since generally it is not so distinguishable for ages above 80 as indicated in <ref type="bibr" target="#b22">[22]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Parallel Face Detection for Robustness</head><p>We have the following observations on the crawled aging images: 1) many images do not contain faces, 2) even in those images which contain faces, the involved faces may not be in frontal view, and 3) there may exist occlusions for the faces. Thus accurate and robust face detection is compulsory in prior to the further age estimator learning process. On one hand, the images without faces shall be removed, and on the other hand, the faces shall be detected in a robust way. There are many face detectors with reasonably good performances, but generally no detector can guarantee to be perfect. However, the parallel detection results from several face detectors can provide multiple and complimentary detection results for each image, which actually simulate the multi-instance learning scenario. We thus adopt this scheme to use multiple state-of-the-art face detectors for detecting all possible faces for each image. The detectors we used belong to different variations of Adaboost <ref type="bibr" target="#b18">[18]</ref> based detectors. The diagram of this parallel face detection scheme is illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Within-age-category Noise Filtering</head><p>After the parallel face detection step, most images without faces are removed, but there may still exist noises for those detected faces, e.g., false alarms, faces with large spatial misalignments, and faces with incorrect age labels. These noises can be further reduced by using certain statistical approaches. In our work, we adopt two ways to remove potentially false face detections. Firstly, we match the detection results from the parallel face detectors, namely, only those detected faces which have significant overlapping with other faces from different detectors are retained (e.g., with more than 90% overlapping areas). The step removes most of the false alarm faces. Secondly, we perform Principal Component Analysis (PCA) <ref type="bibr" target="#b10">[10]</ref> within each age category and then remove those faces with large reconstruction errors based on the retained components, i.e., these "faces" are greatly different from the majority of the detected faces within an age category. This step is capable of filtering out some of the "poor" faces such as occluded, rotated or significantly deformed ones, since these noisy faces usually exhibit quite different appearances compared with those normal near-frontal faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ROBUST UNIVERSAL AGE ESTIMATOR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Robust Multi-instance Age Estimator</head><p>After the noise filtering step, the left aging dataset, which may still contain noisy images and labels, has the following characteristics:</p><p>1. There might exist multiple face instances within a single image, which come from the parallel face detection or from multiple true human faces within an image.</p><p>2. For each individual image, there is no guarantee that there exist at least one face instance right with the given age label.</p><p>The second property makes the problem to learn an age estimator essentially different from those well-known multi-instance learning problems, where a common assumption is that there exist within each bag at least one positive instance with the bag label. Therefore we need develop new regressor learning framework for multiinstance regression with noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Robust Multi-instance Regression Formulation</head><p>Before introducing the detailed formulation, we first show the main terminologies. Instead of explicitly enforcing that each image, referred to as bag within the context for multi-instance learning, has at least one face instance with the given age, we impose a soft constraint, that is, we allow some bags contribute no face instances with the given ages. Denote each bag as</p><formula xml:id="formula_0">Bi, i = 1, • • • , M,</formula><p>where M is the total number of bags (images). Also we unpack the bags and provide index for the face instance in the instance level, and the label of the jth instance is denoted as yj (without regarding whether it is correct or not) while its feature vector representation is denoted as xj ∈ R d , where d is the feature dimension and we shall introduce the details of the features in the latter part of this paper. For each bag, the number of involved instances is denoted as |Bi| = #{xj |xj ∈ Bi}. The total number of instances is denoted as N , namely i |Bi| = N .</p><p>The target of this work is to learn a human age regressor,</p><formula xml:id="formula_1">f (x, a) : x ∈ R d → y ∈ R,<label>(1)</label></formula><p>where x is the input feature vector of the face instance and a is the parameter vector to estimate. In the following we present the detailed formulation for multi-instance regressor learning with possibly noisy labels. First, we define pj as the parameter to measure the possibility of a face instance xj to inherit its parent bag's label, and as pj ∈ [0, 1], we rewrite it as</p><formula xml:id="formula_2">pj = e -c 2 j (2)</formula><p>with cj being a real value. Here we denote</p><formula xml:id="formula_3">c = [c1, c2, • • • , cN ] T .</formula><p>Then the entire possibility to have at least one face instance with the label of the ith bag is,</p><formula xml:id="formula_4">PB i = 1 - x j ∈B i (1 -pj).</formula><p>(</p><p>A direct observation of this formula is that if one instance takes the probability of 1, the entire probability of a bag shall be 1.</p><p>The problem of multi-instance regressor learning with noisy la-bels is then defined as the optimization,</p><formula xml:id="formula_6">min Q(c, a) = N j=1 pj(yj -f (xj , a)) 2 + α j =j w jj (f (xj, a) -f (x j , a)) 2 -β M i=1 log PB i ,<label>(4)</label></formula><p>which can be further expand as</p><formula xml:id="formula_7">Q(c, a) = N j=1 e -c 2 j (yj -f (xj, a)) 2 + α j =j w jj (f (xj, a) -f (x j , a)) 2 -β M i=1</formula><p>log(1 -</p><formula xml:id="formula_8">x j ∈B i (1 -e -c 2 j )).<label>(5)</label></formula><p>The matrix W = [w jj ] is define as</p><formula xml:id="formula_9">w jj = 1, if xj ∈ N k 1 (i), 0, else,<label>(6)</label></formula><p>where N k 1 (i) is the k1 nearest neighbor set of the face instance xj measured by Euclidean distance in the feature vector space, and in this work k1 is set as 7.</p><p>Note that: 1) the first term in the objective function measures the data fitting capability, namely, the error between the labels and the estimations from the derived age estimator; 2) the second term measures the smoothness of the regression function, i.e., those samples with similar feature representations should also be similar for the predicted labels; 3) the third term denotes the negative log likelihood of the probability for the ith bag to have at least one face instance with the label of the bag, which penalizes the cases without face instances selected; and 4) α and β are two parameters for controlling the tradeoff among these three parts. Also for the second smoothness term, we do not multiply the indicator variables cj and c j , since this regularity is applicable for all face instances, not constrained to those face instances with the largest cj 's. It means that finally the so-called negative face instances within a bag are also used for the deduction of the regressor, which well enhances the robustness of the regressor learning process.</p><p>The function f (x, a) is the final age regression mapping function. In this work, we use kernel regression method for estimating y for a face instance represented as x, and the Gaussian kernel is used in this work, namely,</p><formula xml:id="formula_10">k(x1, x2) = exp{-x1 -x2 2 /σ 2 1 }</formula><p>, where σ1 is a tunable parameter for measuring feature similarity. First, we select a set of M reference face instances from the entire face instance set, denoted as X = [x1, • • • , xM ], the age estimation model from x to its age label y is then formulated as</p><formula xml:id="formula_11">y = f (x, a) = M m=1 amk(x, xm) M m=1 k(x, xm) , (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>where a = [a1, • • • , a M ] T is the parameter vector. Note that the reference point number M and the parameter σ1 are set empirically in all our experiments in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Optimization Procedure</head><p>There exist two set of variables in problem formulation, namely, a and c, and the objective function is not convex. Therefore no global optimum is available, and we adopt the alternative optimization scheme to minimize this objective function, namely, we alternate the optimization with respect to a and c respectively by fixing the other parameter set in each iteration step. For fixed c, since the third term depends only on c, the whole objective function becomes a quadratic function. Here, we denote y</p><formula xml:id="formula_13">= [y1, y2, • • • , yN ] T , F = [fnj ] ∈ R N×M with fnj = k(xn,x j ) M m=1 k(xn,xm )</formula><p>, and L = D -W with D as a diagonal matrix defined as Djj = j w jj . W is defined in Eqn. <ref type="bibr" target="#b6">(6)</ref>. Then the objective function can be reformulated in the matrix form as <ref type="bibr" target="#b8">(8)</ref> where Σc denotes the diagonal matrix whose diagonal elements are from c, namely, Σc(j, j) = e -c 2 j and Σc(j, j ) = 0, j = j . To minimize this objective function, we calculate the derivative of this function and set it to be zero, and then we have</p><formula xml:id="formula_14">min Q(c, a) = (y -F a) T Σc(y -F a) + 2α(F a) T L(F a) -β M i log PB i ,</formula><formula xml:id="formula_15">F T (Σc + 2αL)F a = F T Σcy.<label>(9)</label></formula><p>Therefor the optimal a could be obtained as:</p><formula xml:id="formula_16">a = (F T (Σc + 2αL)F ) † F T Σcy,<label>(10)</label></formula><p>where † denotes the pseudo inverse of a matrix. For a fixed a, the objective function with respect to c is nonlinear and we use gradient descent method for the optimization. The partial derivative is calculated as</p><formula xml:id="formula_17">∂Q ∂cj = -2cj e -c 2 j (f (xj , a) -yj ) 2 + 2β 1 -P B(j) P B(j) cj e -c 2 j 1 -e -c 2 j ,<label>(11)</label></formula><p>where B(j) denotes the the parent bag of the instance xj. The above two steps iterate until converged, namely stop when the consecutive changes of a and c are smaller than a predefined threshold, set as 10 -4 in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Convergence Analysis</head><p>The optimization problem in Eqn. ( <ref type="formula">8</ref>) is non-convex due to the non-convexity of the objective function, and hence we cannot guarantee that the solution shall be globally optimal. Here, instead we prove that the iterative procedure converges to a local optimum. For the optimization with respect to a, its closed-form solution guarantees the non-increase of the objective function. And for the optimization with respect to c, the gradient descent method also guarantees the non-increase of the objective function. We therefore have</p><formula xml:id="formula_18">Q(ct, at) ≥ Q(ct, at+1) ≥ Q(ct+1, at+1),<label>(12)</label></formula><p>where at means the derived solution from the tth iteration for a and also for ct. Therefore, the objective function is non-increasing. Also, the objective function value is non-negative, which means that the objective function has a lower-bound of 0. Then we can conclude that the objective function shall converge to a local optimum according to "Gauchy's criterion for convergence" <ref type="bibr" target="#b17">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Post-processing with Feature Refinement</head><p>The original feature vector for the face instance does not necessarily provide good discriminating power for distinguishing the age information, and a supervised dimensionality reduction process may offer better discriminating power. We do not plan to put the dimensionality reduction within the aforementioned robust multiinstance regression formulation, since it shall bring heavy computation cost due to the much larger size of the projection matrix, denoted as P ∈ R d×m where m is the final desired feature dimension, compared with the parameter vectors a and c.</p><p>In this subsection, we follow the work in <ref type="bibr" target="#b22">[22]</ref> to adopt a supervised learning process for enhancing the discriminating power of the feature vector after we have obtained the values for c. More specifically, we first select the top-k2 (k2 is set as 100 in this work) face instances with the largest pj's for each age. To simplify the representation, we still denote these selected face instances with high probabilities as xj 's and their age labels as yj's. The criteria for guiding the pursue of the project matrix is that in the derived low-dimensional feature space, the face instances with similar age labels should also be similar in feature space. Let the label similarity matrix W s = [w s jj ] defined as</p><formula xml:id="formula_19">w s jj = e -||y j -y j || 2 /σ 2 2 , (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>the σ2 is set to be 1 in this work and then the projection matrix is achieved by the following optimization, min</p><formula xml:id="formula_21">P T P =I j =j ||P T xj -P T x j || 2 w s jj . (<label>14</label></formula><formula xml:id="formula_22">)</formula><p>Denote X s as the feature matrix for the selected face instance, then the optimal P consists of the eigenvectors corresponding to the topm largest eigenvalues of the matrix X s L s X sT , where L s is the Laplacian matrix of the matrix W s . We then project all the training, testing, and reference face instances of the regressor into this low dimensional space by P .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Face Instance Representation via Patches</head><p>For those automatically crawled and cropped face instances, spatial misalignments may exist, and thus a robust feature representation is critical for final age estimation performance. The feature vector x to represent the face instance is derived based on the work <ref type="bibr" target="#b22">[22]</ref>, namely, each face instance is finally represented as a so-called supervector.</p><p>First, the DCT2 features are extracted from the small patches (in this work we use 8 × 8 pixels patches) to form the feature vector z ∈ R d , and then based on all the patches extracted in an overlapping manner, we build a universal background model with Gaussian Mixture Models (GMM) as follows,</p><formula xml:id="formula_23">p(z; Θ) = K k=1 w k N (z; µ k , Σ k ),<label>(15)</label></formula><p>where Θ = {w1, µ 1 , Σ1, • • • }, w k , µ k and Σ k are the weight, mean and covariance matrix of the kth Gaussian component, respectively, and K is the total number of Gaussian components. The density is a weighted linear combination of K uni-modal Gaussian densities, namely,</p><formula xml:id="formula_24">N (z; µ k , Σ k ) = 1 (2π) d 2 |Σ k | 1 2 e -1 2 (z-µ k ) T Σ -1 k (z-µ k ) . (<label>16</label></formula><formula xml:id="formula_25">)</formula><p>We obtain a maximum likelihood parameter set for the GMM by using the Expectation-Maximization (EM) approach as in <ref type="bibr" target="#b5">[5]</ref>.</p><p>For each face instance, we derive the instance-specific GMM by adapting the mean vectors of the global GMM and retaining the mixture weights and covariance matrices. Assuming that the extracted patch set from the face instance is denoted as {zi} H i=1 , and then an MAP adaption process is as follows,</p><formula xml:id="formula_26">p(k|zj ) = w k N (zj; µ k , Σ k ) K k =1 w k N (zj ; µ k , Σ k ) , (<label>17</label></formula><formula xml:id="formula_27">)</formula><formula xml:id="formula_28">n k = H i=1 p(k|zj ),<label>(18)</label></formula><formula xml:id="formula_29">µ k = 1 n k H i=1 p(k|zj )zj,<label>(19)</label></formula><formula xml:id="formula_30">μk = α k µ k + (1 -α k )µ k , (<label>20</label></formula><formula xml:id="formula_31">)</formula><p>where α k = n k /(n k + r) and r is a parameter on priors. The above MAP adaptation process is based on conjugate priors for the means, and is useful because it interpolates, smoothly, between the hyper-parameters µ k and the maximum likelihood parameters µ k . If a Gaussian component has a high probabilistic count, n k , then α k approaches 1 and the adapted parameters emphasize the new sufficient statistics; otherwise, the adapted parameters are determined by the global model. Suppose we have two face instances with the exacted patch set as Za and Z b , then, from the GMM MAP adaptation process in <ref type="bibr" target="#b17">(17)</ref><ref type="bibr" target="#b18">(18)</ref><ref type="bibr" target="#b19">(19)</ref><ref type="bibr" target="#b20">(20)</ref>, we can obtain two adapted GMMs for them, denoted as ga and g b . Consequently, each face instance is represented by a specific GMM distribution model, and a natural similarity measure between them is the Kullback-Leibler divergence,</p><formula xml:id="formula_32">D(ga||g b ) = ga(z)log ga(z) g b (z) dz. (<label>21</label></formula><formula xml:id="formula_33">)</formula><p>The Kullback-Leibler divergence itself does not satisfy the conditions for a metric, but there exists an upper bound from the logsum inequality,</p><formula xml:id="formula_34">D(ga||g b ) ≤ K k=1 w k D(N (z; μa k , Σ k )||N (z; μb k , Σ k )),</formula><p>where μa k denotes the adapted mean of the kth component from face instance a, and likewise for μb k . Based on the assumption that the covariance matrices are unchanged during the MAP adaptation process, the right side of the above inequality is equal to</p><formula xml:id="formula_35">d(Za, Z b ) = 1 2 K k=1 w k ( μa k -μb k ) T Σ -1 k ( μa k -μb k ).<label>(22)</label></formula><p>It is easy to prove that d(Za, Z b ) is a metric function, and can be considered as the Euclidean distance between two supervectors in another high-dimensional feature space,</p><formula xml:id="formula_36">φ(Za) = [ w1 2 Σ -1 2 1 μa 1 ; • • • ; wK 2 Σ -1 2 K μa K ],<label>(23)</label></formula><p>and then</p><formula xml:id="formula_37">d(Za, Z b ) = φ(Za) -φ(Z b ) 2 .</formula><p>Then we can represent each face instance using x = φ(Z) given that Z is the extract patch set. If the patch DCT2 feature is of d dimensional, and the number of components used is K, then the representation length would be of dK, which is normally very large. In this work, we perform PCA to reduce this original dimension into d = 2000 dimension, for the sake of computational tractability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Database Construction</head><p>We crawled 391, 176 images (also known as face bags) from Flickr.com and Google image search engine based on a set of age related queries for each year from 1 to 80, and detected 586, 595 face instances by using the parallel face detection scheme. After the pre-screening of the initial face instances, we have totally 77, 021 images (bags) with 219, 892 face instances left, i.e., about 2/3 of the face instances (false alarms, misaligned or poor quality faces) are removed. Note that the derived face dataset is significantly larger than the state-of-the-art aging dataset, e.g., FG-NET <ref type="bibr" target="#b1">[1]</ref> (1002 face images), and MORPH-1 (1690 face images) and MORPH-2 <ref type="bibr" target="#b16">[16]</ref> (55, 608 face images).</p><p>Fig. <ref type="figure" target="#fig_5">4</ref> shows several typical samples before the pre-screening step and Fig. <ref type="figure" target="#fig_6">6</ref> displays the sample face instances automatically cropped from the face image dataset before and after pre-screening. Several conclusions can be drawn from these observations:</p><p>1. In most raw images, multiple face instances are cropped due to the multiple detector process, which essentially leads to a multi-instance problem for learning the universal age estimator.</p><p>2. We could observe that for some images, the bag age label is incorrect. In this case, the original multiple instance learning algorithm is easy to fail. Therefore a robust multi-instance learning algorithm, which can handle noisy labels, is necessary for pursuing a universal age estimator.</p><p>3. There are also many poor quality faces and false alarm detections output from the face detectors. Poor quality faces include those non-frontal faces and occluded faces. Most of these inappropriate detections may be pre-screened out by the multiple detector strategy. This results in a very clean dataset containing face instances only.</p><p>4. A small portion of the filtered instances are true faces. These true faces are also removed as they are detected by only one face detector.</p><p>5. There exist a significant number of non-face images related to the age keywords, e.g., pet, old building, wine, birthday cake, and tomb, which are easily filtered out by the face detectors.  An illustration of the age statistics for the dataset before and after pre-screening is shown in Fig. <ref type="figure" target="#fig_4">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Algorithmic Evaluations</head><p>In this subsection, we systematically evaluate the algorithmic convergence, robustness and age estimation accuracy of our proposed robust multi-instance regressor learning algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Experiment Setup</head><p>Our proposed algorithm is trained on the constructed Internet aging database (cropped faces after the pre-screening step). The aforementioned image patch based features are used to represent each face instance. For all the experiments, the cropped and prescreened faces are first re-scaled to the size of 80 × 80 pixels, then the histogram equalization is performed on the re-scaled faces. Then the DCT2 features are extracted based on 8×8 image patches and the universal background model is trained with 512 Gaussian components. The adaptation rate r is set to be 1.0 in this work. By performing PCA on the derived supervector, 2000 dimension of features are preserved and after the post-processing step, we further project the feature vector into a 500 dimensional space. Note that the first dimensionality reduction is for computational efficiency while the second is for improving discriminative power. In the evaluations, we mainly focus on whether the robust multi-instance learning can improve the algorithmic performance. We may implement many different regressors for such an evaluation, and in this work, we use the Gaussian kernel based kernel regression method for designing the age regressor. The comparison experiments are conducted between our proposed robust multi-instance regression method with noisy labels (RMIR) and the direct Gaussian kernel regression (GKR) without considering label noises. For both methods, the number of reference centers (M ) and the kernel parameter σ1 are set to be empirically optimal. For RMIR, α and β are fixed empirically in all the experiments. The convergency process of the objective function for our proposed robust multi-instance regression method is visualized in Fig. <ref type="figure" target="#fig_8">7</ref>.</p><p>The training process is performed on the constructed Internet aging database. As can been seen, normally the optimization process shall converge after about 20 iterations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Within-database Experiments</head><p>The within-database experiments cannot directly be conducted on our constructed Internet aging database, since the precise age labels are not provided. We therefore perform these evaluations on those state-of-the-art aging datasets: FG-NET <ref type="bibr" target="#b1">[1]</ref> and MORPH-1 <ref type="bibr" target="#b16">[16]</ref>, where the ground-truth age labels are available. For these datasets, we randomly partition each of them into the training set and testing set as: for FG-NET, 600 images are randomly selected as the training set and the rest 402 images are taken as the testing set. For the MORPH-1 dataset, the training and testing partition is 800 : 890. Since these datasets have only one face instance for each image, the following scheme is used to simulate the noisy multiple instance case: in the training set, for each image, we randomly add another instance to construct a two-instance-bag. Note that the selected instances might not belong to the same bag label. Then for all the training bags, we randomly add certain level of label noises, namely, from 0% to 40%. We then perform both our proposed robust multi-instance regression algorithm and the GKR on all the instances from the training bags.</p><p>The comparison results in terms of the mean absolute error (MAE) on the testing set are shown in Fig. <ref type="figure">8</ref>. The definition for the MAE is given as:</p><formula xml:id="formula_38">MAE = Nt j=1 | yj -gj|/Nt, (<label>24</label></formula><formula xml:id="formula_39">)</formula><p>where yj and gj are the estimation and ground-truth age label respectively, and Nt is the number of testing samples. As can be seen, our proposed method scales well with the increase of age label noise level, however the regressor GKR fails in the presence of label noises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Cross-database Experiments</head><p>In this subsection, we evaluate the algorithmic performance under the cross-database scenarios, namely the age estimator is trained on one database and then tested on another database. The algorithms are trained on our collected Internet aging dataset and then the obtained regressors are tested on those benchmark datasets, including FG-NET (1002 images), MORPH-1 (1690 images), MORPH-2 (55, 608 images). Note that MORPH-1 and MORPH-2 contains face images from most ethnic groups. The age statistics and the regression accuracies in terms of the mean absolute error (MAE) on these testing datasets are summarized in Table <ref type="table">1</ref>, where the baseline results from GKR are also reported for comparison. As can been seen, the MAEs from our proposed method is satisfying (9.49, 7.42, and 8.60 for these three datasets respectively) and our proposed robust multi-instance learning based regressor outperforms the baseline GKR based regressor significantly. The poor performance of GKR is mainly caused by the presence of the noisy labels in the training dataset.</p><p>To further validate the generalization capability of the regressor  learnt from our proposed robust multi-instance regressor learning method on the large-scale Internet aging database, we also evaluate the cross-database age estimation accuracies between the FG-NET and MORPH-1 datasets, namely, we use the FG-NET dataset for training and the MORPH-1 dataset for testing, and vice versa. The results reported in Table <ref type="table">1</ref> show that these small-size datasets lack the generalization capability, while our Internet aging database performs much better. Note that the best result ever reported using FG-NET as the training set and MORPH-1 as testing set is 8.07 in <ref type="bibr">[7]</ref>, which is also worse than our reported result (i.e., 7.42) by learning the universal age estimator from the Internet aging database.</p><p>The results shown in Table <ref type="table">1</ref> exhibit certain error distributions. For almost all cases (except when FG-NET dataset is used for training), the mid-age range presents lower errors but small/large age ranges have larger errors. This is due to the age distribution of the training data, i.e., for MORPH-1 and MORPH-2 dataset, there are more samples in the mid-age range. For our IAD dataset, more valid samples (with large pj) are also in the mid-age range after RMIR training. For FG-NET dataset, more samples are in the small age range, which results in smaller testing errors in the small age range.</p><p>To illustrate the effectiveness of our proposed robust multi-instance learning method in a visualizable way, we show the top ranked 10 faces (based on the probability of pj = e -c 2 j derived from our RMIR algorithm) and the bottom ranked 10 faces from the training results on the Internet aging database for comparison in Fig. <ref type="figure">9</ref>. We can observe that the majority of the bottom ranked faces are face instances with incorrect age labels or of poor image qualities and the top ranked faces are more consistent with the given age labels, which validates effectiveness of our formulation in removing image outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS AND FUTURE WORK</head><p>In this paper, we aimed to utilize the prosperous Internet media resources for automatically constructing a universal human age es-  timator. The main contributions of this work are as follows. First, a large size (∼391k) human aging image database was crawled via a set of popular age related queries. Then, after parallel detection and noise removal, a clean database with about 220k face instances is obtained. Finally, a robust multiple instance regressor learning method was developed for handling both noisy images and labels, which led to a strong universal age estimator, applicable to all ethnic groups and various image qualities. An interesting direction for future study is to develop incremental learning algorithm for learning multi-instance regressor with noisy labels, which is practically valuable for web-scale data mining purpose.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of the purpose of this study, i.e., to utilize web image resources for learning a universal age estimator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The system overview for learning universal age estimator based on automatic web image mining.</figDesc><graphic coords="3,329.50,214.08,83.92,55.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An exemplary result from parallel face detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Age label statistics of the downloaded images before (left light color bars) and after (right dark color bars) prescreening.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Some sample images from the raw face database with detected face regions. Each column denotes a type of detection results, including (from left to right): (a) All the face instances (single or multiple) within the image inherit the bag age label; (b) Part of the face instances inherit the bag age label and other detected face instances correspond to other ages (noisy instances); (c) The bag age label is incorrect (the age labels for the images are 20, 10, 50, 60, 20, 20 from top to bottom); (d) Poor quality face instances due to rotation, illumination variation, occlusion or photo fadedness; (e) Images contain false detections; (f) Age-relevant images which however contain no face instances. Note that different colors of the detection rectangles indicate the results from different detectors.</figDesc><graphic coords="7,58.20,64.08,80.30,411.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Sample face instances from the raw aging image database. Note that the images with masks are removed by the prescreening step, and some true faces are also removed as they are detected by only one face detector.</figDesc><graphic coords="8,53.76,53.81,502.56,251.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The convergence process of our proposed robust multi-instance regression learning algorithm on the constructed Internet aging database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Comparison of the mean absolute errors (MAEs) (on the testing set) using different methods on the FG-NET (left) and MORPH-1 (right) dataset. The lower bound means the mean absolute error obtained by training a GKR regressor with the incorrect face instances excluded .</figDesc><graphic coords="9,316.83,234.95,221.76,199.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Table 1 :</head><label>1</label><figDesc>Age distribution statistics, mean absolute errors (MAEs) (year) of our Robust Multi-Instance Regression algorithm (RMIR) and GKR regressor on the three testing datasets. Note that "IAD-Train" means we use the Internet aging database as the training set and similarly "FG-NET-Train" means the FG-NET database is used as the training set.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGMENTS</head><p>We thank Mr. Yantao Zheng and Dr. Jinhui Tang for the help in collecting online image data. This research is done for CSIDM Project No. CSIDM-200803 partially funded by a grant from the National Research Foundation (NRF) administered by the Media Development Authority (MDA) of Singapore. This work is also supported by NRF/IDM Program, under research Grant NRF2008IDM-IDM004-029.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://sting.cycollege.ac.cy/alanitis/fgnetaging.html" />
		<title level="m">The fg-net aging database</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Support vector machines for multiple-instance learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiple-instance learning via embedded instance selection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2006">1931 ĺC1947. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Human age estimation with regression on discriminative aging manifold</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="578" to="584" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic age estimation based on facial aging patterns</title>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith-Miles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2234" to="2240" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image-based human age estimation by manifold learning and locally adjusted robust regression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1178" to="1188" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A method for estimating and modeling age and gender using facial image processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Koshimizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Virtual Systems and Multimedia</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Joliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Integrated segmentation and recognition of hand-printed numerals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Keeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Leow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="557" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Age classification from facial images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lobo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing different classifiers for automatic age estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lanitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Draganova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Christodoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics, Part B</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="621" to="628" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A framework for multiple-instance learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-P Ĺęrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="570" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiple instance regression</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Morph: A longitudinal image database of normal adult age-progression</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tesafaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2006-03">March 2006</date>
			<biblScope unit="page" from="341" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Rudin</surname></persName>
		</author>
		<title level="m">Principles of Mathematical Analysis</title>
		<imprint>
			<publisher>McGray-Hill</publisher>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
	<note>3nd Edition</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiple instance boosting for object detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Solving the multiple-instance problem: a lazy learning approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1119" to="1125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regression from uncertain labels and its applications to soft-biometrics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="698" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regression from patch-kernel</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Finding visual concept by web image mining</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yanai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Em-dd: An improved multiple-instance learning technique</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning with application to scene classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
