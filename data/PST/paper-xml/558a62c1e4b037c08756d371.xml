<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">COSMOS-A Representation Scheme for 3D Free-Form Objects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Chitra</forename><surname>Dorai</surname></persName>
							<email>dorai@watson.ibm.com</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Anil</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
							<email>jain@cps.msu.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 704</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">COSMOS-A Representation Scheme for 3D Free-Form Objects</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F473CC6A236F39D96311903EAB039722</idno>
					<note type="submission">received 15 Sept. 1995; revised 27 Mar. 1997. Recommended for acceptance by K. Bowyer.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Free-form objects</term>
					<term>sculpted surfaces</term>
					<term>arbitrarily curved objects</term>
					<term>3D object representation</term>
					<term>shape index</term>
					<term>spherical map</term>
					<term>shape spectrum</term>
					<term>view matching</term>
					<term>object recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We address the problem of representing and recognizing 3D free-form objects when 1) the object viewpoint is arbitrary, 2) the objects may vary in shape and complexity, and 3) no restrictive assumptions are made about the types of surfaces on the object. We assume that a range image of a scene is available, containing a view of a rigid 3D object without occlusion. We propose a new and general surface representation scheme for recognizing objects with free-form (sculpted) surfaces. In this scheme, an object is described concisely in terms of maximal surface patches of constant shape index. The maximal patches that represent the object are mapped onto the unit sphere via their orientations, and aggregated via shape spectral functions. Properties such as surface area, curvedness, and connectivity, which are required to capture local and global information, are also built into the representation. The scheme yields a meaningful and rich description useful for object recognition. A novel concept, the shape spectrum of an object is also introduced within the framework of COSMOS for object view grouping and matching. We demonstrate the generality and the effectiveness of our scheme using real range images of complex objects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>E are interested in the problem of representing and recognizing general 3D free-form objects. The success of several existing 3D object recognition systems can be attributed to the restrictive nature of the types and number of geometrical objects that can be handled by the system. Fig. <ref type="figure" target="#fig_0">1</ref> portrays various classes of objects and the representation schemes that can be adopted to describe them. An obstacle to the widespread acceptance of 3D object recognition systems is that most current systems cannot accommodate sculpted surfaces <ref type="bibr">[1]</ref>. They are limited to domains where the objects are prespecified to be mostly polyhedral, quadric, and superquadric. Our interest is, therefore, to specifically address the challenge of representing and recognizing arbitrarily curved objects, without limiting our domain of interest to a fixed set of geometrical shapes. In this paper, we propose a representation scheme that answers the following important question: How do we represent arbitrarily curved objects compactly, without restricting the object shape and structure, so that their recognition by a computer is made easier? Our work is also motivated by the increasing requirements in several real-world industrial applications, such as automated inspection and recognition, to handle manufactured free-form surfaces and naturally occurring sculpted objects that cannot be modeled using volumetric primitives and that may not have easily detectable landmark features such as edges and vertices. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Free-Form Surfaces</head><p>A free-form surface S is defined to be a smooth surface, such that the surface normal is well defined and continuous almost everywhere, except at vertices, edges, and cusps <ref type="bibr" target="#b1">[2]</ref>. Since there is no other restriction on S, it is not constrained to be polyhedral, piecewise-quadric, or superquadric. Discontinuities in the surface normal or curvature may be present anywhere on a free-form object, and, similarly, discontinuities in the surface depth may be present anywhere in a projection of the object. The curves that connect these points of discontinuity may meet or diverge smoothly. Some representative objects with free-form surfaces are human faces, cars, boats, airplanes, sculptures, etc. Observe that we do not include statistically defined shapes, such as textures and foams, arborizations such as trees or bushes, crumpled surfaces (fractals), regular and quasiregular tessellations of space and surface patches, and subjects of integral geometry in our study. We also exclude selfintersecting and nonorientable surfaces <ref type="bibr" target="#b2">[3]</ref>, such as Möbius strips and Klein bottles, from consideration. In this paper, we use the terms "objects with free-form surfaces," "sculpted objects," and "free-form objects" interchangeably. Fig. <ref type="figure" target="#fig_1">2</ref> shows a set of free-form surfaces which is representative of the objects that we want a vision system to recognize automatically. The range images of objects shown in Fig. <ref type="figure" target="#fig_1">2</ref> were obtained using a laser range scanner (Technical Arts White scanner) that produces depth data in an X-Y grid. The figure shows surface depth as pseudo intensity, displaying the relative orientation of the surfaces; points oriented almost vertically are shown in darker shades. Observe that the surface data obtained from a single-view range sensor typically take the form of a graph surface, and, hence, the surface parameterization takes a very simple form:</p><formula xml:id="formula_0">r x u v u v f u v T , ,<label>, , a f a f</label></formula><p>= , where T denotes the transpose. However, we note that our proposed representation and recognition schemes work on any collection of (x, y, z) points on which the fundamental notions of metric, tangent space, curvature, and natural coordinate frames can be suitably defined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Overview of our Representation Scheme</head><p>The goals of the COSMOS <ref type="bibr" target="#b3">[4]</ref> representation scheme are the following:</p><p>• It should be a general representation scheme that can be used to describe sculpted objects, as well as objects composed of simple analytical surface primitives. • The scheme should be as compact and expressive as possible for accurate recognition of objects from a single range image.</p><p>Our approach makes use of shape index to represent complex objects for their recognition. The shape index was originally proposed by Koenderink and van Doorn for graphical visualization of surfaces <ref type="bibr" target="#b4">[5]</ref>, and we employ a modified definition to identify the shape category to which each surface point on an object belongs. An object is concisely characterized by a set of maximally sized surface patches of constant shape index and their orientationdependent mapping onto the unit sphere. The patches that get assigned to the same point on the sphere are aggregated according to the shape categories of the surface components. The points on the unit sphere are further characterized by a set of support functions describing the shape, average curvedness, and area of the mapped patches. The average curvedness of a surface patch specifies whether it is highly or gently curved; the surface area quantifies its extent in three-dimensional space; the orientation (mean surface normal) of the patch describes how it is directed in 3D space. The relative spatial arrangement of the various patches as encoded by their connectivity is also built into the representation. We refer to our representation scheme as COSMOS (Curvedness-Orientation-Shape Map On Sphere).</p><p>The main strength of our scheme is the integration of local and global shape information that can be computed easily from sensed data, and is reflective of the underlying surface geometry. It is also a general scheme capable of representing arbitrarily curved 3D objects and objects with holes, as it does not rely on analytical surface primitives to approximate regions. A novel concept, the shape spectrum of an object, is also introduced within the framework of COSMOS for object view grouping and matching. The shape spectral features allow free-form object views to be grouped meaningfully in terms of the shape categories of the visible surfaces and their surface areas. A set of effective matching primitives can also be derived from this scheme for object recognition. The current paper focuses primarily on the representation aspects of COSMOS, since there are many alternative matching strategies and algorithms that can be developed using this representation.</p><p>This paper is organized as follows. In Section 3, we motivate our representation scheme, present a detailed analysis of the scheme in terms of its definition, formal properties, and highlight its capabilities. Since the emphasis of this paper is on deriving an effective representation of a sculpted object, the topic of multiobject segmentation in the scene is outside the scope of this paper, and, hence, will not be discussed further. However, we briefly note that our recognition system, based on the COSMOS scheme, can handle multiple unoccluded objects in the scene. Section 4 describes techniques for deriving the COSMOS representation of an object view from its range data. Section 5 discusses examples of shape spectra of object views derived from their range images. We present experimental results with real range images of several different objects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>Design of an appropriate representation scheme for 3D objects is a crucial factor that influences the ease with which they are recognized. Besl and Jain <ref type="bibr" target="#b5">[6]</ref>, Suetens et al. <ref type="bibr" target="#b7">[7]</ref>, and Arman and Aggarwal <ref type="bibr" target="#b8">[8]</ref> present comprehensive surveys of 3D object representation schemes and recognition strategies. Flynn and Jain <ref type="bibr" target="#b9">[9]</ref> summarize a number of challenging and important representational and matching themes in 3D object recognition research. 3D object recognition research has dealt mainly with geometric entities in two and three dimensions, using representations, such as points or groups of points, straight line segments and polylines, planar faces and edges, silhouettes of 2D views, planar and quadric surface patches, generalized cylinders, constructive surface geometry (simple volumetric primitives), and superquadrics. Although not geometry-based, a recent technique called parametric eigenspace has been proposed to project a large set of 2D appearances of an object into the "eigenspace" (parameterized by pose and illumination) using principal component analysis. Other representation schemes include geons and aspect graphs.</p><p>Most of these object representation schemes have adopted some form of surface or volumetric parametric models to characterize the shapes of 3D objects. However, objects with free-form surfaces, in general, may not have simple volumetric shapes that can be expressed with, for example, a superquadric primitive, even though it can be specified by eight (including bending and tapering) shape parameters. On the other hand, as the surface-based representations are mostly based on a small set of analytical surface primitives, such as polyhedral and quadric surfaces, they either exclude sculpted objects from their domains or approximate free-form surfaces with a very large number of simple surface primitives. Global representations, such as the extended Gaussian image (EGI) <ref type="bibr" target="#b10">[10]</ref> and other orientation-based descriptors <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b14">[14]</ref> describe 3D objects in terms of their surface normal distributions on the unit sphere, with appropriate support functions. They handle convex polyhedra efficiently, but arbitrarily curved objects have to be either approximated by planar patches or divided into regions based on the Gaussian curvature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Representation Schemes for Free-Form Surface</head><p>Some recent approaches have specifically sought to address the issue of representing sculpted surfaces. Table <ref type="table">1</ref> presents an overview of these approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Parametric Representations</head><p>Parametric representations are mainly employed in CAD systems to design and analyze free-form surfaces. The IGES standard used in CAD representations for free-form surfaces is NURBS (Non-Uniform Rational B-spline Surfaces) <ref type="bibr" target="#b1">[2]</ref>. Use of NURBS has not yet become prevalent in the computer vision community, since it is very difficult to match image data to an object model's NURBS-based representation. Most vision researchers have, therefore, proposed both global and local structural descriptions based on local curvatures or normals to represent free-form surfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Global Representations</head><p>While algebraic surfaces <ref type="bibr" target="#b15">[15]</ref> are more flexible than quadrics or superquadrics in representing complex curved objects' primitives, issues such as bounding constraints and convergence of surface fitting need to be investigated thoroughly as surface approximations using implicit polynomials <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b26">[26]</ref> are less stable generally, and can be more computation-intensive than approximations using parametric forms. Ultimately, even these representations are limited in scope. With the HOT curve representation scheme <ref type="bibr" target="#b24">[24]</ref>, the recognition accuracy can be poor if the inflection points are not accurately localized. The SAI global representation <ref type="bibr" target="#b27">[27]</ref>, <ref type="bibr" target="#b19">[19]</ref> can be used only for objects that are topologically equivalent to the sphere. In addition, for each object, the appropriate mesh resolution needs to be determined. Figure/ground segmentation is a critical issue when viewpoint-dependent features, such as 2D silhouettes, are extracted along with internal edges from intensity images to model curved objects <ref type="bibr" target="#b22">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 1 CURRENT REPRESENTATION SCHEMES FOR COMPLEX CURVED OBJECTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation scheme Type of descriptor</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Object domain Sensing modality</head><p>Algebraic polynomials <ref type="bibr" target="#b15">[15]</ref>, <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b17">[17]</ref> Global Objects described by quartic curves and surfaces Range Splash and super segments <ref type="bibr" target="#b18">[18]</ref> Local Arbitrarily curved objects Range Simplex angle image <ref type="bibr" target="#b19">[19]</ref> Global Objects topologically equivalent to the sphere Range Registration using point sets <ref type="bibr" target="#b20">[20]</ref> Global Arbitrarily curved objects Range Registration using image contours <ref type="bibr" target="#b20">[20]</ref> Global Free-form surfaces 2D X-ray projections 2D silhouettes with internal edges <ref type="bibr" target="#b22">[22]</ref> Global Arbitrarily curved objects Intensity</p><p>Triangles and crease angle histograms <ref type="bibr" target="#b23">[23]</ref> Global Free-form objects Range HOT (High Order Tangent) curves <ref type="bibr" target="#b24">[24]</ref> Global Arbitrarily curved objects Video sequences</p><p>Convex, concave and planar surfaces <ref type="bibr" target="#b25">[25]</ref> Local Arbitrarily curved objects Range</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Local Structure-Based Representations</head><p>Local structural descriptions of general surfaces using splash and super segments <ref type="bibr" target="#b18">[18]</ref> do not provide a higher level description of the object. The features derived can be sensitive to noise in the sensed data and also to occlusions, thus affecting the reliability of the matching. The stability of crease angle histograms proposed for matching representations based on triangles <ref type="bibr" target="#b23">[23]</ref> depends on good triangulation of surfaces and also on smoothing algorithms that would retain the important features of the surface with a minimal number of triangles. Instead of matching object features to scene features, Jain and Hoffman <ref type="bibr" target="#b25">[25]</ref> handcraft an evidence rule base that stores salient surface features along with the evidence of their occurrences in each of the objects in the database, and use the rulebase to recognize objects in the scene. The surfaces are restricted to planar, convex, and concave in this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Registration</head><p>Registration-based approaches to free-form object matching <ref type="bibr" target="#b20">[20]</ref>, <ref type="bibr" target="#b21">[21]</ref> avoid surface segmentation and surface fitting for recognition. The main disadvantage is that, just as in any iterative minimization technique, registration of surfaces is sensitive to the initial value of the transformation. It is also not guaranteed to find the best transformation if the scene contains occluded objects, or if the point densities in the model and scene representations are different, and if there are numerous spurious points from different objects. The emphasis is more toward recovering the spatial pose accurately, rather than discriminating between or recognizing multiple objects. In summary, current representation schemes work best for a limited class of 3D objects. The generality of the shapes of free-form objects is a major difficulty that is not easily overcome with analytical representations. This has motivated us to find other means of capturing the object shape in a general manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COSMOS-A NEW REPRESENTATION SCHEME</head><p>The novelty of our scheme lies in its description of an object as a smooth composition or arrangement of regions of arbitrary shapes that can be detected regardless of the complexity of the object. We also use a spherical mapping of the detected surface patches of constant shape for their aggregation, along with support functions describing the curvatures, areas, and connectivity of the patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Definitions</head><p>Each of the local and global attributes used in the COSMOS scheme captures a specific geometric aspect of the object, and is defined using differential geometry-based concepts, such as shape index, curvedness, and surface normals. A general parametric form of a surface S with respect to a known coordinate system is given by</p><formula xml:id="formula_1">S x x x u v y u v z u v u v = OE = L N M M O Q P P OE Õ R S | T | U V | W | r r 4 4<label>3 2 : , , , , , a f a</label></formula><formula xml:id="formula_2">f a f a f W . (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>Differential geometry is used for describing local behavior of surfaces in a small neighborhood. We assume without any loss of generality that the surface S can be adequately modeled as being at least piecewise smooth, i.e., it contains smooth surface patches separated by discontinuities in depth and orientation, where the extent of smoothness depends on the attributes that need to be discussed at a point p on S. Most free-form surfaces are smooth. For example, to represent orientation and curvature, the functions used to represent S must at least be of class C 2 (twice differentiable).</p><p>Then the first and second fundamental forms <ref type="bibr" target="#b2">[3]</ref> of a surface are well defined on these patches, and are used to define geometric quantities that are of interest to us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Shape Index</head><p>A quantitative measure of the shape of a surface at a point p, called the shape index S I , is defined as</p><formula xml:id="formula_4">S p p p p p I b g b g b g b g b g = - + - - 1 2 1 1 1 2 1 2 p k k k k tan (<label>2</label></formula><formula xml:id="formula_5">)</formula><p>where N 1 and N 2 are the principal curvatures of the surface, with N 1 N 2 . Note that in Koenderink and van Doorn's definition <ref type="bibr" target="#b4">[5]</ref>, the range of the shape index is [1, 1], whereas, with our definition, all shapes can be mapped on the interval S I = [0, 1], conveniently allowing aggregation of surface patches based on their shapes (see Section 3.4).</p><p>The shape index values have to be nonnegative in our formulation, because we use them in the definition of the shape spectral functions of surface patches. These spectral functions are used in the aggregation of attributes of the surface patches in terms of their shape index values. With mirror shapes, such as the spherical cap and the cup, whose S I values are +1 and 1, with Koenderink and van Doorn's definition, shape index values interact during attribute aggregation, and local information about each shape category is not maintained distinctly. Hence, it is necessary to redefine the shape index to take only nonnegative values. Every distinct surface shape corresponds to a unique value of S I , except the planar shape. Points on a planar surface have an indeterminate shape index, since N 1 = N 2 = 0. For computational purposes in our implementation, a symbolic label (or sometimes, a shape index value of 2.0) is used to indicate surface planarity. Nine well-known shape categories and their locations on the shape index scale are shown in Fig. <ref type="figure" target="#fig_3">3</ref>. The representative shapes from each category are graphically illustrated in Fig. <ref type="figure" target="#fig_4">4</ref>. The shape index captures the intuitive notion of "local" shape of a surface. Surface classification into eight basic shape types based on the signs of Gaussian and mean curvatures that was employed by Besl <ref type="bibr" target="#b28">[28]</ref> for segmentation can be carried out within our framework by quantizing the continuous S I scale into eight categories. Furthermore, since the Gaussian curvature is intrinsic to a surface, both Gaussian and mean curvatures are necessary for characterizing the notion of extrinsic shape, whereas a single shape index suffices for the same task. The shape index provides a continuous gradation between salient shapes, such as convex, saddle, and concave, and, thus, has the larger vocabulary needed to describe subtle shape variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Curvedness</head><p>The shape of a rigid object is not only independent of its position and orientation in space, but also independent of its scale. In order to capture the scale differences between objects (e.g., a soccer ball and a cricket ball) in our representation scheme, we use the curvedness or the amount of curvatures in a region. The curvedness <ref type="bibr" target="#b29">[29]</ref> of a surface at a point p is defined as</p><formula xml:id="formula_6">R p p p b g b g b g d i = + k k 1 2 2 2 2. (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>It is a measure of how highly or gently curved a surface is, and its dimension is that of the reciprocal of length. A unit sphere has unit curvedness and so does a unit saddle sur-</p><formula xml:id="formula_8">face (|N 2 | = |N 1 | = 1). A unit cylinder has R = 1 2 (N 1 = 1</formula><p>and N 2 = 0). The curvedness becomes zero only for planar patches, unlike the Gaussian curvature which vanishes on parabolic surfaces (cylindrical ridges and ruts) also, even though these surfaces appear definitely curved to humans. The new parameters (S I , R) can be viewed as polar coordinates in the (N 1 , N 2 )-plane, with planar points mapped to the origin. The direction indicates the surface shape, whereas the distance from the origin captures the size. what we gain is the decoupling of the shape attribute of a surface from its scale. Besl <ref type="bibr" target="#b30">[30]</ref> also discusses four different sets of functions based on the surface curvatures, and these include a polar transformation of the N 1 and N 2 plane akin to (S I , R). In his formulation, the functions (U, \) are used, where U measures the total "bending energy" of the surface along both the curvature directions, and \ is the angle in the principal curvature plane. Koenderink and van Doorn <ref type="bibr" target="#b4">[5]</ref> provide good reasons for using the shape index for surface classification, instead of schemes based on N 1 and N 2 themselves. These include the decoupling of size and shape so that a single number suffices to capture the latter, and obviation of the need for (arbitrary) assignment of a principal direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Constant-Shape Maximal Patch (CSMP)</head><p>The fundamental component of the COSMOS representation of an object is the description of an object in terms of surface patches that are of different shapes. A CSMP on a 3D freeform object O is a maximally sized surface patch P ¯ O, such that p, q ° P, 1) S I (p) = S I (q), and</p><p>2) a path from p to q consisting of points r ° P, such that S I (r) = S I (p) = S I (q).</p><p>The second condition imposes connectedness of the points in the CSMP P. For example, a spherical surface has a single CSMP of spherical cap (convex) shape, whereas a truncated cylinder bounded by hemispherical caps at its ends has three CSMPs, one with cylindrical ridge shape and the other two of spherical cap shape.</p><p>An n-faced convex polyhedron would contain n CSMPs of planar shape, separated by edges of surface normal discontinuities (shape index is indeterminate for these edges). In theory, edges and vertices would form their own patches (CSMPs) in COSMOS. An edge has infinite curvature in one direction (between the faces it separates) and finite curvature in the other direction (along the edge). As a special case, in a polyhedron an edge can be viewed as the limit of a cylinder whose radius approaches zero (implying that the curvedness has approached infinity, while the shape index has stayed constant). Thus, each edge forms a CSMP of its own (recall that planar faces have indeterminate shape  index, which is representationally distinct from the shape index of a cylinder), and would separate each face. Vertices would not aggregate into either edges or faces, since they have a different shape index-they can usually be viewed as the limiting case of a cup or cap with curvedness approaching infinity. Therefore, a polyhedron theoretically gets segmented into its individual faces in COSMOS. Some of the issues that need to be addressed in practice are discussed in Section 4.2.</p><p>In a digital implementation of the representation scheme, with the surface depth data of an object obtained using a range scanner that produces data on an X-Y grid, a CSMP would be computed as a region containing surface points (pixels) whose shape indices are the same and which are eight-connected with each other. With other types of surface data, the connectedness can be suitably defined in order to determine the CSMPs on the object. The shape index of a CSMP is the same as that of the surface points contained within it. Note that when the shape index varies at each surface point on the object, each CSMP contains a single point instead of a set of points. Fig. <ref type="figure" target="#fig_5">5</ref> shows the constantshape maximal patches detected in a range image of a view of a vase, obtained using the segmentation technique described in Section 4.1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Shape Spectral Function</head><p>We define the shape spectral function as</p><formula xml:id="formula_9">S S : 2 + O AE ,</formula><p>where 2 O is a set of surface patches and + is the space of complex-valued functions such that</p><formula xml:id="formula_10">S P e P S jtS P I ( ) = OE ( ) , 2 O (4)</formula><p>where S P I ( ) is the shape index of the patch P, and t is a parameter that allows us to study shape properties of objects in a suitable transform domain (see Section 3.4), just as time-varying waveforms can be studied conveniently in the Fourier transform domain. It is used in the definitions of support functions (Section 3.2) for the aggregation of geometric attributes of surface patches when multiple patches of identical shapes are found on different parts of an object (a realistic situation in the cases of nonconvex and symmetrical objects) and need to be summarized without any loss of information. It thus provides a way to qualitatively characterize "which shape categories are present, and how much of each shape category is present in an object." This characterization is developed in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5">Other Descriptors</head><p>COSMOS also characterizes how objects and their surface patches are oriented with respect to one another in a threedimensional space in terms of their average surface normals. The extent of the object in 3D space is also represented quantitatively by the surface area. Along with these local descriptors, our representation scheme encodes the relative arrangement of surface patches on the object by their adjacencies. Note that maintaining connectivity information is tantamount to characterizing the global structure of an object in a local manner. These descriptors are quite expressive and do not depend on the presence of any analytical primitives, and are, therefore, useful with arbitrarily curved objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Definition of the COSMOS of a 3D Free-Form Object</head><p>The COSMOS representation of an object segmented into a set of homogeneous patches (CSMPs) comprises two sets of functions: the Gauss patch map and surface connectivity list ÃG 0 , VÓ, and the support functions ÃG 1 , G 2 Ó. The first set captures the orientation and connectivity information of the object, and the latter captures salient local surface information of the CSMPs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Gauss Patch Map and Surface Connectivity List</head><formula xml:id="formula_11">, (<label>5</label></formula><formula xml:id="formula_12">)</formula><p>where $ n p b g is the normal at p ° P, dO is the differential area element in P, and P ° 2 O . The integral dO p P OE zz denotes the total surface area of the CSMP P. r G 0 (P) is the average surface normal over P. For example, in a computer implementation with discretely sampled object surface data, this will be computed as</p><formula xml:id="formula_13">$ $ , , n p P p n p P p p N i i N b g l q b g m r for = for = 1 1 Â R S | T | L .</formula><p>When we refer to the "unit sphere," we also include an extra point, the center of the sphere, to which we map zero normals. Thus, G 0 maps each CSMP, P, on O to a point on the unit sphere whose normal corresponds to the orientation (mean surface normal) of the patch P. Viewed inversely, the Gauss patch map associates each point s ° 5 2 on the unit sphere with a (possibly empty) set of patches at s,</p><formula xml:id="formula_14">G s P G P s 0 1 0 -( ) = OE ( ) = 2 O r o t .<label>(6)</label></formula><p>As a notational convenience, we generalize this and define the inverse Gauss patch map of a region of the unit sphere S ¯ 5 2 as</p><formula xml:id="formula_15">G S P s S G P s 0 1 0 - = OE $ OE ( ) = 2 O , r o t .<label>(7)</label></formula><p>Fig. <ref type="figure" target="#fig_8">6</ref> shows a telephone handset, the CSMPs on the object, and their spherical mapping, as given by G 0 .</p><p>The surface connectivity list V : 2 O P O AE 2 is defined as</p><formula xml:id="formula_16">V P Q Q P p P q Q p q ( ) = OE π " &gt; ( ) $ OE OE -&lt; 2 O , , d d 0 b g o t ,<label>(8)</label></formula><p>where 2</p><p>P O is the power set of 2 O , and Ep qE is the Euclidean distance between the points p and q. That is, V associates each patch P ° 2 O with the set of patches V(P) = {Q} 2O</p><p>that are adjacent to P, and thus represents connectivity information about the segmented object.</p><p>It can be seen that the traditional region adjacency graph data structure can be easily abstracted from the set of CSMPs, 2 O , and the surface connectivity list V of an object, where each CSMP P on the object serves as a node in the graph, and V(P) provides information about the edges (or the connectivity) that link the nodes in the region adjacency graph.</p><p>The orientation of the patches determined by G 0 associates the CSMPs with points on the unit sphere. The mapping G 0 for any given convex object is one-to-one, since surface normals are unique on the convex object, and no two CSMPs on the object will have the same surface orientation. However, in the case of a nonconvex object, it is possible to have identical surface normals at multiple points on the object's surface (see Fig. <ref type="figure" target="#fig_8">6</ref>). Therefore, several CSMPs may map to the same point on the unit sphere, leading to multiple folds on the sphere. The surface connectivity list V maintains the connectivity information of the patches by keeping a list of adjacent patches for each patch on the object, and thus identifies each fold with unique information that is, in many cases, useful for a coarse approximation of the object's surface, even when full recoverability is not assured.</p><p>Furthermore, observe that, for symmetrically closed smooth objects containing a single CSMP, the Gauss patch map of the object is a single point on the unit sphere, its center. In a practical implementation, this mapping may turn out to be unstable, depending on how the object is discretely sampled, and also on the amount of noise that may be present in computing the surface normal. However, as will be shown in Section 4, we have adopted an object model which is a collection of views of an object, and, hence, only 2D views (appearances) of objects are dealt with in our system. Since 2D object views need not provide complete information on the object (e.g., the back of the object may not be visible in some views), we are not likely to encounter situations where all the surface normals sum to zero, and, thus, the problem of possible instability of the Gauss patch map of objects subject to sampling is avoided in our implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Support Functions on the Sphere</head><p>While the domain of the first set of functions was 2 O , i.e., G 0 and V are defined over the object itself, the second set of functions are defined over the unit sphere 5 2 . In essence, these functions summarize, at each point in 5 2 , the local information about all the patches that have been mapped by G 0 to the point.</p><p>Let s ° 5 2 be a point on the unit sphere, and dS(s) be a small neighborhood of s on 5 2 . Several CSMPs from differ- ent parts of the object O may have been mapped to s by G 0 , i.e., the Gauss patch map may have several folds over s. Then G s </p><formula xml:id="formula_17">P Q G dS P = OE - 0 1 U ,<label>(10)</label></formula><p>corresponding to a single fold over s. We then define the patched Gaussian object density D(s|P) on the single fold corresponding to P as</p><formula xml:id="formula_18">D s P dO dS dS P b g = AE lim 0 . (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>Note that D(s|P) becomes equal to the inverse of Gaussian curvature of a point on the object when the patch P consists of a single point. When the patch is of finite nonzero area, D(s|P) can be written as the product of the surface area of the patch and a Dirac delta function whose spike is at s (see Section 3.3 for a definition of the Dirac Delta function), as explained later.</p><p>We define the two support functions, G 1 : 5 2 + and G 2 : 5 2 +, where + is the space of complex-valued functions, such that </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G s t D s P S P S P G s</head><formula xml:id="formula_20">1 0 1 , a f c h = ( ) OE ( ) - Â<label>(12)</label></formula><p>and</p><formula xml:id="formula_21">G s t R P D s P S P m S P G s 2 0 1 , a f c h = ( ) ( ) OE ( ) - Â ,<label>(13)</label></formula><p>where S S (P) is the shape spectral function of a CSMP P, and R m (P) is the mean curvedness over P given by Using the sifting property of the Dirac delta function, we define, for CSMPs of nonzero area, G 1 at a point s 0 on the unit sphere to be equal to the area of the mapped patch multiplied by the Dirac delta function and also by its shape spectral function. Then, the integral of G 1 (s 0 , 0) in a region around s 0 on 5 2 provides the total surface area of the CSMPs that are mapped into the region. For ease of discussion, from now on, when we refer to G 1 defined for patches of finite surface area, we will simply state that G 1 contains information about the surface area of the mapped patches.</p><p>Similarly, G 2 (s, 0), when integrated over a region around a point on the unit sphere and normalized by the area of the mapped patches, provides the mean curvedness of the patches mapped into the region. When a point on the unit sphere is the image of multiple CSMPs on the object, G 2 (s, t), after integration and normalization, provides a weighted summary of the mean curvedness of these patches categorized in terms of the shape index. Note that in the definitions of both G 1 and G 2 , at a point on the unit sphere, the area and the mean curvedness of each patch P are multiplied by the shape spectral function, e jtS p I b g . The shape spec- tral function aids in maintaining the surface area and curvedness of each patch individually without aggregating them if their shapes are different, although many patches may have been mapped to the same point. When multiple patches of identical shape index map onto the same point on the unit sphere, then their areas and curvedness add up appropriately, resulting in a summary of area and curvedness of each class of shape present in the object, as explained in Section 3.4. This can be used effectively for indexing during the matching stage of an object recognition system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Examples</head><p>The above definitions can be illustrated using a few examples: For a convex polyhedron, each face of the polyhedron becomes a CSMP (the faces are planar everywhere, and the edges bound these surface patches of constant planar shape). The orientations of the CSMPs are given by the surface normals of the planar faces. Each CSMP gets mapped individually to a point (as the object is convex) on the unit sphere. The support function G 1 , defined at the points on the unit sphere where the planar faces are mapped, specifies the area of the planar faces. Note that, for planar shapes, the curvedness R is zero. In the case of general convex objects, where several CSMPs of different shapes and areas exist, each CSMP P gets mapped to a unique point s on the unit sphere with G 1 (s, t) = (Area(P))e jtS p I b g . In the cases of nonconvex objects, where multiple CSMPs P i , i = 1, 2, are mapped to the same point s 0 on the unit sphere, G 1 (s 0 , t) = ((Area(P 1 ))e A suitable transform of the support functions defined using the shape spectral functions results in high level feature summaries that characterize the local geometric attributes of an object. This will be established in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Definition of Shape Spectrum</head><p>We define the shape spectrum H : [0, 1] [0, ] as follows:</p><formula xml:id="formula_22">H h S p h dO I O ( ) = - zz d b g c h , (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>where h is the shape index variable, dO is a small region containing a point p on object O, S p I b g is the shape index at p, and G() is the Dirac delta function. The latter is defined by</p><formula xml:id="formula_24">d x k f x dx f k a k b a b - ( ) ( ) = ( ) £ £ R S T z if otherwise 0</formula><p>for all functions f(x).</p><p><ref type="foot" target="#foot_0">1</ref> As a consequence of its definition, G(x k) is zero everywhere except at x = k, where it has an infinite value (a "spike"). Clearly, the delta function has a 'sifting' or 'sampling' property, in the sense that it picks up the value of f(x) at the point where its spike appears. Our objective in defining the shape spectrum is to determine "how much" of the object's surface area has a particular shape index value h, and, therefore, (15) utilizes the Dirac delta to accumulate the area of O for each shape index value h.</p><p>In practice, we need a discretized definition of the shape spectrum, since we work with pixels when we deal with range images of the object; we call this the shape histogram. Let us partition the shape index scale [0, 1] into n "bins," such that the kth bin is the half open interval [(k 1)/n, k/n) (the shape index value 1 is included in the nth bin by definition). The value of the shape histogram in bin k is the number of pixels whose shape index falls in that bin:</p><formula xml:id="formula_25">H h k n S p k i N I i = F H I K = = Â c 1 b g d i , (<label>16</label></formula><formula xml:id="formula_26">)</formula><p>where p i is a pixel, N is the total number of object pixels in the range image, and F is the characteristic function of the kth bin:</p><formula xml:id="formula_27">c k k n k n x x ( ) = £ &lt; R S T - 1 0 1 otherwise.</formula><p>While <ref type="bibr" target="#b15">(15)</ref> is the precise definition required for our theory, ( <ref type="formula" target="#formula_25">16</ref>) is not as important, in the sense that we are free to employ other discretizations that may display algorithmically better properties. For example, instead of "binning" the shape index scale into n fixed-width bins, we can often employ a more flexible binning scheme which has narrower bins (i.e., "higher resolution") near values of the shape index where a large number of pixels accumulate. Similarly, when we work with patches (the CSMPs used to segment an object), explicit bin boundaries are stored in each patch and inverted to approximate the shape spectrum. All these practical methods are qualitatively equivalent to the concept of "how much of the object has a given shape value," formally embodied in <ref type="bibr" target="#b15">(15)</ref>. For computational purposes, such as comparing spectra of two different object views <ref type="bibr" target="#b32">[32]</ref>, we use a normalized (with respect to the object area) shape histogram where each bin contains percentage surface area of the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relationship Between Shape Spectrum and G 1</head><p>As has been signaled by the term "spectrum" itself, there is a fundamental connection between the support function G 1 (s, t) and the shape spectrum H(h): The shape spectrum is the Fourier transform of the integral of G 1 over the entire unit sphere. Indeed, this is what originally motivated our definition of the support function G 1 ; G 1 spreads the information over the unit sphere, which makes it much easier to work with CSMPs, whereas H spreads the information over the shape index scale, which makes it much easier to work with object view correlations.</p><p>To formally prove the relationship between G 1 and H, we begin with the integral of G 1 over the entire unit sphere 5 </p><formula xml:id="formula_28">( ) = = L N M O Q P zz Â zz AE OE ( ) ( ) - , lim a f $ . (<label>17</label></formula><formula xml:id="formula_29">)</formula><p>To simplify the right-hand side, we make the following observations. Whereas, in a normal integral, we would replace (dO/dS)dS by dO, the term dO dS dS</p><formula xml:id="formula_30">P d i is included,</formula><p>because we wished to consider point sets P on each fold in G s 0 1 -( ) separately. This need to consider each fold of O separately is also the reason for the presence of the summation:</p><p>Of the right-hand side of the definition of G 1 (s, t), <ref type="bibr" target="#b12">(12)</ref> aggregates all the CSMPs that get mapped to a point s on the unit sphere. We now note that the integral is over the entire unit sphere 5 2 , and, therefore, each fold (and CSMP P) on O will be duly considered in turn, and will be considered exactly once. Therefore, in changing domain of the integral to dO, we may safely drop the restriction dO P , as well as the summation sign, and just traverse the entire object O. where we have used the facts that the Fourier transform of e j t a is 2SG(D h) for any constant D, and G(x) = G(x). The factor of 2S is of no particular significance as it can be made to disappear with an alternative definition of the Fourier transform (see, e.g., the treatment in <ref type="bibr" target="#b31">[31]</ref>).</p><p>In passing, we observe that the above treatment of "shape" as an analogue of "frequency" explains our need to relocate the shape index scale to the interval [0, 1] from Koenderink and van Doorn's original <ref type="bibr">[1, +1]</ref>. When all the "frequencies" are nonnegative numbers, terms with different frequencies in the expressions for G 1 , H, etc., do not interact with each other. On the other hand, transform theory makes it clear that two spikes, one at 1 and another at +1, do interact to define a single signal, the sinusoid. We need to keep the shape content in an object at S I = 0.5 (rut shape) distinct from (i.e., unaggregated with) the shape content at S I = +0.5 (ridge shape), and, hence, the redefinition of the shape index.</p><p>Observe that a similar formulation can be used to define "how much" of the object's curvedness has a particular shape index value h, and this can be seen to provide a qualitative measure of the scale of each surface shape present in the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Properties of the COSMOS Representation</head><p>In this section, we briefly highlight some of the important properties of the COSMOS representation. Some important issues in the design and evaluation of a representation scheme, as set forth by Requicha <ref type="bibr" target="#b33">[33]</ref>, are as follows:</p><p>1) object domain (objects that can be modeled with the scheme), 2) validity of the representation (i.e., whether it avoids nonsensical representations), 3) uniqueness and completeness (whether the mapping from objects to representations is one-to-one), and 4) conciseness of the representation.</p><p>The properties of the COSMOS scheme which relate to these issues are discussed below.</p><p>Although the decomposition of an object in terms of the surface patches has been studied earlier, the COSMOS scheme is new because of its use of the continuous-scale shape index for segmenting and matching free-form objects. The continuous scale increases the expressiveness of our scheme and makes it suitable for representing complex objects. Previous approaches, which use the signs of the Gaussian and mean curvatures <ref type="bibr" target="#b28">[28]</ref>, <ref type="bibr" target="#b13">[13]</ref>, can describe a surface in terms of only eight categories (based on user-specified thresholds), whereas the shape index scale can be adaptively divided into as many classes as needed to extract CSMPs on an object depending on the complexity of its shape. In addition, the COSMOS representation combines both local and global aspects in describing an object via support functions defined on the unit sphere and CSMP connectivity, which can be used for effective recognition of free-form objects. The COSMOS scheme will not generate nonsensical representations when they are computed from images of real objects. It may be possible, of course, to artificially synthesize nonsensical representations as with any sufficiently expressive set of primitives, but this is not a concern since our objective is recognition, not reconstruction, from a database of real objects.</p><p>The COSMOS representation of an object is independent of the position of the origin of the object's coordinate system. It is independent of the position of the origin because the orientations of the maximal patches get projected onto the unit sphere in parallel transformation. The scale information is captured in terms of the curvedness of the CSMP. A rotation of the coordinate systems is reflected by the rotation of the orientations of the CSMPs mapped to the unit sphere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Compactness</head><p>The COSMOS representation compactly captures the geometry of an object in terms of a set of easily detectable maximal patches. Objects of simple shapes, such as polyhedra, cylinders, and spheres, have very compact representations. For example, for a full sphere, we have a single CSMP (S I = 1), and it is mapped to the center of the unit sphere (] = 0, K = 0) which is then associated with the appropriate area and curvedness support functions. The adjacency set V is empty, as there is only a single CSMP. It is also compact for many classes of objects that contain only a few distinguishable surface patches of constant shape index, i.e, whose surface shapes do not change rapidly over large regions of the object. If an object is complex and composed of different shapes with rapid protrusions and indentations, then its shape complexity is reflected in an increased number of CSMPs on the object.</p><p>The COSMOS representation is compact in terms of the CSMPs, and their Gauss patch map, when compared with the EGI <ref type="bibr" target="#b10">[10]</ref> and other orientation-based descriptors, such as SFBR <ref type="bibr" target="#b11">[11]</ref>, CEGI <ref type="bibr" target="#b12">[12]</ref>, GGI <ref type="bibr" target="#b13">[13]</ref>, MEGI <ref type="bibr" target="#b14">[14]</ref>, and OBR <ref type="bibr" target="#b34">[34]</ref>, where 3D objects are described in terms of their pointwise surface normal distributions on the unit sphere. Table <ref type="table" target="#tab_1">2</ref> discusses the features of various orientation-based descriptors and contrasts them with the COSMOS scheme. These orientation-based descriptors represent only convex polyhedra efficiently, and most of them are limited by the classes of objects that can be handled. Both GGI and COSMOS include the surface adjacency information as part of the object representation in order to handle nonconvex surfaces. While GGI stores the local support of every fold of the Gaussian image of a surface separately for the express purpose of object recoverability, COSMOS aggregates the support functions using the shape spectral functions to result in high-level feature summaries that can be effectively used for recognition. Further, the surface patches are derived based on constant Gaussian curvature alone with the GGI scheme. The global orientation-based descriptors are verbose from the point of view of recognition, and their main emphasis is on abstracting an object description that can aid in the recoverability, which is in contrast with our objective of building a recognition system. The matching can fail when parts of objects are occluded, as only spherical maps of the objects are available to establish object similarities. However, COSMOS provides CSMPs and associated local and global support features that can be potentially used for recognition, even when objects are partially occluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Convex Objects</head><p>The spherical mapping in the COSMOS scheme is isomorphic to the EGI scheme in the case of convex polyhedra. For a convex polyhedron O, each planar face (f i ) of the polyhedron becomes a maximal patch of constant shape, f i ° O ½ P i ° O. G 0 maps each CSMP P i to the unit sphere, based on the direction of its surface normal (orientation). The adjacencies of the planar faces are stored in V. Since the curvedness of a planar surface is zero, G 2 = 0 for all the CSMPs P i and G 1 provides the area of each of the planar faces. Thus, COSMOS, for a convex polyhedron, is a mapping of the normals of each of the planar faces of the polyhedron onto the unit sphere, along with their associated areas and connectivity (denoted by A and V) as shown in Fig. <ref type="figure" target="#fig_13">7</ref>. The EGI representation for the polyhedron is also shown in the figure. COSMOS . Thus, both convex polyhedra and smooth convex closed objects whose shape index varies continuously are recoverable (up to a translation) from their COSMOS representations as the surface recoverability theorems of EGI apply in these cases. Though it may happen that the COSMOS representation of a convex object containing many CSMPs that have nonzero area is unique up to a translation, recoverability is not guaranteed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.3">Nonconvex Objects</head><p>With a nonconvex object containing many CSMPs that have nonzero surface area, its COSMOS representation can possibly be used to reconstruct the object coarsely in terms of the patches up to a translation. However, we hasten to add that recoverability is not always guaranteed. Recollect that our representation of an object not only has the local descriptions of the CSMPs on the object, but also maintains their adjacencies explicitly. Since the connectivity information between the patches is captured, even when more than one patch maps onto an identical point on the unit sphere, there is a sufficient amount of information preserved to obtain the inverse map of the unit sphere unambiguously. The  surface adjacency information helps in discriminating between different patches with identical orientation. However, note that, since we use the average surface normals in our representation, information about the orientation of each surface point is lost, and this can easily complicate the recoverability of the object. Our representation does not model the holes that may be present in an object, and, hence, recoverability of such an object from its COSMOS representation is not possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DERIVING COSMOS FROM RANGE DATA</head><p>While the COSMOS representations of objects derived from their complete 3D surface data are viewpoint-independent, the representation derived from a given range image of an object is view-dependent due to 1) the orientations of the CSMPs, and 2) the curved nature of the object.</p><p>A complete COSMOS representation of the object can therefore be composed using all the CSMPs computed from several of its views, and object recognition can then proceed by matching the input data against this view-independent model. However, for the remainder of this paper, we construct the COSMOS representation of each of the object views and this set of representations constitutes a multiview description of the object. We have adopted a "collection of views" description of an object, because the input to a recognition system is typically a 2D appearance of an object. Since identification has to proceed from a single view of an object, our approach is to maintain a set of views in our object database, and to match only observed surface patches with those of the model views. The range data of the views of the object are obtained either using a range sensor or using the CAD models or surface triangulations, if available. The number of views chosen to represent an object is model-driven, based on the complexity of the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Construction of the COSMOS of a View of an Object</head><p>We first present a scheme to derive the COSMOS representation from the range data from a single view of an object. For the discussion below, we assume that the range image of a view of an object is obtained using a Technical Arts white scanner <ref type="bibr" target="#b35">[35]</ref>, and consists of pixels arranged on a Cartesian X-Y grid. The following processing steps are applicable to data obtained using other kinds of range scanners with suitable definitions of surface curvatures, pixel connectedness, etc. The steps are shown in Fig. <ref type="figure" target="#fig_14">8</ref>. The range image obtained using the laser range scanner available in our laboratory provides surface depth data of the object visible to the camera. The accuracy of the depth measurement is of the order of 0.001 inches. Since the camera used in the scanner does not use square pixels, and since the camera is mounted at an angle to the object to be scanned (it is not placed directly overhead), some views of the object appear compressed in length while some of the views appear stretched. This is also aggravated by the fact that the image sampling along the X direction is not the same as in the Y direction. Currently, no preprocessing is done on our data to correct for this distortion, as our intent is to demonstrate that our recognition system can perform well in spite of the distortions that may be present in the data. We treat these distortions as different forms of noise in the sensed surface data.</p><p>We first compute the surface curvatures at each pixel (object point) in the image by estimating them using a bicubic approximation of the local neighborhood. In our implementation, we use a neighborhood of 5 5 pixels to locally approximate the underlying surface. Then we apply the iterative curvature smoothing algorithm based on the curvature consistency criterion <ref type="bibr" target="#b36">[36]</ref> to improve the reliability of the estimated curvatures. We process all the data by running the curvature smoothing algorithm for 15 iterations, and, as can be seen from the segmentation results shown in Section 4.2, this smoothing is sometimes excessive for some object views.</p><p>Once the curvatures are reliably estimated at each pixel, the shape index values are computed. The next challenging task is to obtain as few maximally connected patches of constant shape index as possible, while retaining sufficient information about the different shapes that may be present. Since the range data are of finite resolution, and since curvature estimates can be noisy, we need to take into account the possibility of noise in the shape index values of surface points belonging to the same shape. Connected points whose shape indices are similar have to be merged to obtain a CSMP.</p><p>An obvious approach to finding maximal patches of constant shape index in the range image is to partition the shape scale a priori (independent of the actual distribution of shape index values in the image) into a finite number of bins of either fixed or varying width. However, with such a method, the bin boundaries are artificial and may not correspond to a more "natural" segmentation of the image. The shape index boundaries should depend on the contents of the image. More generally, the problem is to group image pixels into CSMPs with the following objectives: 1) minimize the total number of CSMPs in the image (to avoid fragmentation into hundreds of small patches); and 2) minimize some measure of the spread of shape index values of the pixels within a CSMP.</p><p>Since these two objectives obviously conflict, global information is required to achieve objective 1, subject to some constraints. A brief description of our segmentation algorithm is given below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constrained Region Growing</head><p>Our segmentation algorithm constructs maximal patches by repeatedly merging smaller patches, starting with very small (pixel-sized) patches. Since, in each step, it merges the two (adjacent) patches that would result in the least merged shape diameter (the difference between the minimum and maximum shape index values within the patch) of all the feasible (connected) pairs of patches, the spread of shape indices of the pixels within a patch is minimized. In addition, since the algorithm is applied until the maximum merged shape diameter would exceed the constrained value for every remaining pair of patches, it minimizes the total number of patches. Using the shape index in this way improves the segmentation over methods that use only fixed-width and fixed-threshold quantized bins.</p><p>To illustrate the effectiveness and the generality of our scheme, we show the maximal patches for different objects in  the CSMPs is shown in part c. The surface attributes stored by the coefficients in the support functions on the unit sphere for the vase are given (without the shape spectral functions) in Table <ref type="table" target="#tab_2">3</ref>. The support functions are defined at points on the unit sphere as indicated in the table. At all other points on the unit sphere, they are undefined. A shape diameter of 0.25 yielded good CSMPs in most images. An increased shape diameter resulted in bigger patches in the cases of the cobra-head and the cup. This parameter can be adaptively adjusted depending on the size of the smallest CSMP that is detected in a given image.</p><p>If the design criterion is that the smallest CSMP found in an object view should contain at least 10 percent of the visible surface area in the view, then the shape diameter can be adjusted depending on the object present in the view. We note that the perceptual accuracy of the segmentation is not the only criterion to evaluate object segmentation in our case; one can have visually unsatisfactory segmentation (e.g., over-segmentation) which is, however, adequate for object recognition. Our recognition system <ref type="bibr" target="#b37">[37]</ref> based on COSMOS has been designed to handle imperfect segmentation results by merging connected CSMPs if necessary, while establishing the model-scene patch correspondences during recognition.</p><p>A few remarks about the segmentation and the role of edges on the objects (surface depth and surface normal discontinuities) are in order. In range images of objects, edges are never knife-sharp nor are corners needle-like. With free-form objects, in particular, the edges present on the objects are typically smooth, without sudden jumps in depth or normals (e.g., contrast a human face with a polyhedron). Since our current segmentation algorithm does not explicitly detect edges prior to region growing, our experimental results indicate that the detected CSMPs blend into neighboring CSMPs without a sharp intervening boundary. Future work on improving the segmentation results should integrate edge detection schemes with the region growing algorithm to obtain stable region boundaries and also prevent CSMPs from leaking across the discontinuities to their surrounding regions. Another promising direction is experimenting with statistical properties, such as the standard deviation of a patch's S I , as a basis for determining the CSMPs, instead of the shape diameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SHAPE SPECTRUM FROM RANGE DATA</head><p>As described in Section 3.3, the shape spectrum of an object characterizes its shape content by summarizing the area on the surface of an object at each shape index value. The shape spectrum of an object view is obtained from its range data by constructing a histogram H(h) of the shape index values-we used 0.005 as the bin width-and accumulating all the object pixels that fall into each bin. Note that the shape spectrum could also have been constructed using the surface area and shape index values of the CSMPs generated by segmentation. However, we preferred to directly use the original shape index values computed for each pixel in the image (instead of using the mean and variance information stored in the CSMPs), and, thus, avoided being affected by any segmentation imperfections. Under ideal conditions (noiseless curvatures, zero CSMP shape diameter), these two ways of constructing the spectrum would yield identical results, but, in practice, the former is desirable. Since the shape index for planar points on an object surface is indeterminate, we have assigned a symbolic label to the planar points for our consideration. For plotting and computational purposes, this label is arbitrarily assigned a value of 2.0, and, therefore, the range of shape index values for computing the shape spectrum of a view takes a value in the range [0, 1] and also 2.0.</p><p>The nonplanar shape spectral plot of the vase (Vase2-1), shown in Fig. <ref type="figure" target="#fig_0">10a</ref>, indicates that the main shape category present in this object is dome, along with a few smaller peaks in the ridge and saddle-ridge categories. From Fig. <ref type="figure" target="#fig_0">10b</ref>, it can be seen that the dominant shape category in Big-Y-1 object is ridge (0.6875 S I 0.8125). A few concavities in the object are characterized by the nonzero bins below the 0.5 shape index level.</p><p>It can be observed that, based on the shape spectral information alone, it is difficult to discriminate between objects that are only polyhedral. However, the concept of shape spectrum can be effectively used for categorizing objects into purely polyhedral and nonpolyhedral; polyhedral object views exhibit a peak (maximum surface area) only at the planar shape index (which has been chosen to be 2.0 in our experiments). Since there is a huge body of techniques available for polyhedral object recognition, we will not further discuss this topic. Note that occlusion of an object in a view, either by other objects or due to selfocclusion, results in some of the surface patches being visible only partially in the image, and this affects the shape spectrum by influencing the surface area count (percent) stored at various shape categories. We have devised a novel object view representation based on shape spectrum features that can tolerate the presence of occlusion in an object to a certain extent, and have proposed a general and powerful technique for organizing multiple views of freeform objects into compact and homogeneous clusters and for matching of views in a model database <ref type="bibr" target="#b32">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">COSMOS-BASED FREE-FORM OBJECT RECOGNITION</head><p>A feature representation consisting of the moments computed from the shape spectrum of an object view has been adopted for designing a matching stage that quickly eliminates unlikely object view matches from a model database of views. Once a small subset of likely candidate views has been isolated from the database, based on the views' spectral features, we employ a detailed matching scheme that exploits the various components of the COSMOS representation to derive a matching score and to establish the scenemodel view surface patch correspondences. This matching scheme is inspired by traditional graph matching algorithms and exploits the natural structural information that is being made explicit in the COSMOS representation. A complete recognition system has been implemented and experimentally validated with a database of over 6,000 object views generated from CAD models and surface triangulations and 100 range images of several different complex objects acquired using the range scanner. The details of this multilevel matching strategy and the recognition experiments will be presented in a forthcoming publication (see also <ref type="bibr" target="#b38">[38]</ref>), and will not be discussed further here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">SUMMARY</head><p>We have presented a novel representation scheme called COSMOS for 3D objects. It is a shape-based description of objects suitable for representing free-form surfaces without requiring complex 3D analytical modeling of objects. It is compact for all classes of objects, except those in which the shape index changes rapidly over the object surface. Some classes of objects are also recoverable from their COSMOS representations. We also introduced a powerful matching primitive, the shape spectrum of an object, for fast matching of an input object view with views stored in a model database, and for eliminating unlikely views during recognition. It characterizes the shape content of an object by summarizing the area on the surface of the object at each shape index value. Although we have assumed unoccluded views of the objects, we expect that small amounts of occlusions will be tolerated in our representation scheme as long as the salient surfaces that provide the characteristic shape information about the objects are visible. We demonstrated how the COSMOS representation can be derived from range data of an object view and illustrated the representation using range images of several complex objects. The COSMOS representation scheme can be used as the basis for various matching algorithms and for model database organization; a simple prototype has been developed with good results, and ongoing work deals with strengthening and further exploiting the COSMOS scheme.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Representation and object shape complexity.</figDesc><graphic coords="1,305.84,332.42,272.31,112.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Range images of 3D free-form objects.</figDesc><graphic coords="2,107.72,55.96,390.72,190.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Since (S I , R) are the polar coordinates in the principal curvatures plane, N 1 and N 2 can be recovered from S I and R in the usual manner. No loss of information occurs when one goes from the (N 1 , N 2 ) representation to the (S I , R) space;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Nine well-known shape types and their locations on the S I scale.</figDesc><graphic coords="5,129.32,57.20,361.08,62.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Nine representative shapes on the S I scale.</figDesc><graphic coords="5,95.84,150.64,426.48,165.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Maximal patches of constant shape index (colors indicate different shape index values): (a) Range image of a vase; (b) CSMPs detected on the vase.</figDesc><graphic coords="6,45.20,348.52,124.68,124.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Given an object O segmented into a set of patches 2 O ac- cording to the CSMP criterion, we define the Gauss patch map as a function G</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>is the set of patches from O mapped at s and G dS 0 1 is the inverse Gauss patch map of dS, i.e, the set of all patches of O that map to points within dS. For any patch P ° G s 0 1 -( ), let us denote the restriction of G dS continuous region of O (since all the patches in G dS P 0 1 are neighbors of P, they are joined into one large patch whose image is entirely within dS), dO Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Example of a 3D free-form object and its spherical mapping r G 0 .</figDesc><graphic coords="7,44.00,59.40,264.00,179.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>The support functions ÃG 1 , G 2 Ó defined on the unit sphere capture the local geometric attributes of the mapped CSMPs. G 1 (s, t) integrated over a region on 5 2 maintains a summary of the surface areas of all the mapped CSMPs in each shape category. As a special case, the integral of G 1 (s, 0) over a region on 5 2 provides the surface area of the CSMPs that are mapped into the region. The term D(s|P) in G 1 becomes equal to the inverse of the Gaussian curvature of a point on the object when the CSMP P is a point, and it is equal to the product of the area and the Dirac delta function when the CSMP is of finite, nonzero area, for the following reason. Recollect that the Gaussian curvature K at a surface point p on O is defined by is the area on the unit sphere to which a region dO ® O has been mapped. The inverse of the Gaussian curthe shape index changes everywhere on O, then each single point p ° O becomes a CSMP P on the object. Then G 1 , defined at the point to which P is mapped on the unit sphere is equal to 1 K p e jtS p I b g c h b g . In the case of objects where the shape index is distinct and constant over different regions, the CSMPs are well-defined, and their surface areas are nonzero. Then lim dS dO dS AE0 for a CSMP P becomes equal to the surface area of P multiplied by the Dirac delta function, because dO is nonzero for P, and dS tends to zero; it is equivalent to the area dO of P multiplied by a Dirac delta function G(t) (see Section 3.3 for its definition).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>I</head><label></label><figDesc>b g + (Area(P 2 ))e jtS p I b g + ). If the shape indices of the CSMPs are the same, then their areas are aggregated. Similarly, the support function G 2 results in a summary of the mean curvedness of the CSMPs in each shape category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>For the same reason, we can change the variable and integrate over points p ° O instead of considering point sets P°G s transform of g 1 , with h as the transform variable,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>The COSMOS mapping also reduces to EGI in the case of a continuous smooth convex closed object, in which S p I b g, p ° O is different at every point p on the object. Let O be an object that is convex 2 and whose S p I b gdiffers at every point p ° O; then, a point p i on the object becomes a CSMP P i , as 2. For a convex object, S I _ 0.5. the shape index is not constant over any neighborhood around p i . The orientation of P i is then the same as the normal N p i at p i . Each p i on the surface gets mapped to a point on the unit sphere by the function G 0 , explained earlier, in this case, the coefficient in the support function G 1 is the inverse of the Gaussian curvature 1/K(p i ). G 2 provides the curvedness of the point, R(p i ) e jtS p I i b g . The support function stored on 5 2 EGI is included among the support functions stored at the points on 5 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. COSMOS and EGI of a convex polyhedron. (The support functions are shown only for normals N1 and N4 for clarity.)</figDesc><graphic coords="11,51.08,447.76,251.88,262.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Construction of COSMOS from range data of an object.</figDesc><graphic coords="12,356.00,53.44,159.12,277.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 9 .</head><label>9</label><figDesc>In this figure, part a shows the range image of an object, and part b shows the image of the various CSMPs (shown in different colors) on the object. The Gauss map of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Representation of 3D free-form objects: (a) range image; (b) constant-shape maximal patches; (c) the Gauss patch map.</figDesc><graphic coords="13,173.00,60.04,285.72,465.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 COSMOS</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="3">AND ORIENTATION-BASED REPRESENTATIONS</cell></row><row><cell>Represent</cell><cell>Mapping</cell><cell>Support functions on the</cell><cell>Applicable</cell><cell>Salient features</cell></row><row><cell>ation</cell><cell></cell><cell>unit sphere</cell><cell>object domain</cell><cell></cell></row><row><cell>scheme</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EGI [10]</cell><cell>Spherical map-</cell><cell>Gaussian curvature at a surface</cell><cell>Convex closed</cell><cell>Convex objects can be recovered; translation</cell></row><row><cell></cell><cell>ping of surface</cell><cell>point</cell><cell>objects</cell><cell>cannot be recovered uniquely.</cell></row><row><cell></cell><cell>normals at all</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>points</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SFBR [11]</cell><cell>Spherical map-</cell><cell>Distance of the tangent plane at</cell><cell>Convex closed</cell><cell>Closed surfaces can be uniquely recovered;</cell></row><row><cell></cell><cell>ping of surface</cell><cell>a point from a predefined origin</cell><cell>objects</cell><cell>the representation depends on the choice of</cell></row><row><cell></cell><cell>normals at all</cell><cell></cell><cell></cell><cell>origin and is scale variant.</cell></row><row><cell></cell><cell>points</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CEGI [12]</cell><cell>Spherical map-</cell><cell>Complex number storing the</cell><cell>Convex closed</cell><cell>Translation of a convex object can be</cell></row><row><cell></cell><cell>ping of surface</cell><cell>Gaussian curvature and the</cell><cell>objects</cell><cell>recovered uniquely.</cell></row><row><cell></cell><cell>normals of all</cell><cell>distance of a point from a speci-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>points</cell><cell>fied origin in the direction of the</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>normal</cell><cell></cell><cell></cell></row><row><cell>GGI [13]</cell><cell>Spherical map-</cell><cell>Minimum and maximum princi-</cell><cell>Convex and</cell><cell>Any oriented smooth surface can be repre-</cell></row><row><cell></cell><cell>ping of surface</cell><cell>pal curvatures; adjacency rela-</cell><cell>nonconvex</cell><cell>sented uniquely and recovered upto a</cell></row><row><cell></cell><cell>normals of con-</cell><cell>tions between the surface points</cell><cell>objects</cell><cell>translation.</cell></row><row><cell></cell><cell>stant Gaussian</cell><cell>and their ordering</cell><cell></cell><cell></cell></row><row><cell></cell><cell>curvature</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>patches</cell><cell></cell><cell></cell><cell></cell></row><row><cell>OBR [34]</cell><cell>The Gauss map</cell><cell>Distance function; first and sec-</cell><cell>Convex and</cell><cell>Convex and star shaped objects can be re-</cell></row><row><cell></cell><cell>(surface nor-</cell><cell>ond curvature functions; radial</cell><cell>star shaped</cell><cell>covered from their representations.</cell></row><row><cell></cell><cell>mals) and the</cell><cell>distance function</cell><cell>objects</cell><cell></cell></row><row><cell></cell><cell>dilation map</cell><cell></cell><cell></cell><cell></cell></row><row><cell>COSMOS</cell><cell>Spherical map-</cell><cell>Gaussian curvature; mean</cell><cell>Convex and</cell><cell>Shape-based analysis of objects; connectivity</cell></row><row><cell>[4]</cell><cell>ping of orienta-</cell><cell>curvedness</cell><cell>nonconvex</cell><cell>information is maintained as a list; convex</cell></row><row><cell></cell><cell>tions of CSMPs</cell><cell></cell><cell>objects</cell><cell>polyhedra and convex objects whose shape</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>index varies continuously can be recovered.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 THE</head><label>3</label><figDesc>COSMOS REPRESENTATION: SUPPORT FUNCTIONS FOR VASE2-1 ON THE UNIT SPHERE</figDesc><table><row><cell>Point on the unit sphere (], K)</cell><cell>CSMP</cell><cell>Mean shape index</cell><cell>Surface area</cell><cell>Mean Curvedness</cell></row><row><cell>(3.106989, 0.677436)</cell><cell>P1 (red)</cell><cell>0.854807</cell><cell>5725</cell><cell>0.593455</cell></row><row><cell>(3.079618, 0.482079)</cell><cell>P2 (green)</cell><cell>0.720356</cell><cell>112</cell><cell>0.366058</cell></row><row><cell>(0.065550, 0.607387)</cell><cell>P3 (blue)</cell><cell>0.473433</cell><cell>289</cell><cell>0.454395</cell></row><row><cell>(2.893622, 0.616532)</cell><cell>P4 (yellow)</cell><cell>0.656924</cell><cell>793</cell><cell>0.737030</cell></row><row><cell>(3.091251, 0.926560)</cell><cell>P5 (magenta)</cell><cell>0.576004</cell><cell>343</cell><cell>0.571970</cell></row><row><cell>(0.230828, 0.580261)</cell><cell>P6 (cyan)</cell><cell>0.821453</cell><cell>520</cell><cell>0.932052</cell></row><row><cell>(3.129172, 0.983077)</cell><cell>P7 (white)</cell><cell>0.747665</cell><cell>326</cell><cell>1.105722</cell></row><row><cell>(3.115084, 0.647045)</cell><cell>P8 (light green)</cell><cell>0.678569</cell><cell>1088</cell><cell>0.474518</cell></row><row><cell>(0.053756, 0.681923)</cell><cell>P9 (pine green)</cell><cell>0.666768</cell><cell>17</cell><cell>0.394001</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Strictly speaking, for a suitably chosen set of all "test functions" on the domain of x<ref type="bibr" target="#b31">[31]</ref>, which places no restriction on us in practice.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their thoughtful suggestions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Amsterdam</title>
		<editor>
			<persName><forename type="middle">A K</forename><surname>Object Recognition Systems</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><surname>Flynn</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier Science Publishers B.V</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Machine Vision for Three-Dimensional Scenes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<editor>H. Freeman</editor>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="25" to="71" />
		</imprint>
	</monogr>
	<note>The Free-Form Surface Matching Problem</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Millman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Parker</surname></persName>
		</author>
		<title level="m">Elements of Differential Geometry</title>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">COSMOS-A Representation Scheme for Free-Form Surfaces</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dorai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Int&apos;l Conf. Computer Vision</title>
		<meeting>Fifth Int&apos;l Conf. Computer Vision<address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Surface Shape and Curvature Scales</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Doorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="557" to="565" />
			<date type="published" when="1992-10">Oct. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Three-Dimensional Object Recognition</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="75" to="145" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Shape spectra of (a) Vase2-1 shown in Fig. 2, and (b) Big-Y-1 shown in Fig</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational Strategies for Object Recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="5" to="61" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Model-Based Object Recognition in Dense Range Images-A Review</title>
		<author>
			<persName><forename type="first">F</forename><surname>Arman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="43" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Three-Dimensional Object Recognition</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Pattern Recognition and Image Processing</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Young</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="497" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extended Gaussian Image</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Representing Oriented Piecewise C 2 Surfaces</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Nalwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="131" to="153" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Complex EGI: A New Representation for 3-D Pose Determination</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="707" to="721" />
			<date type="published" when="1993-07">July 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Orientation-Based Differential Geometric Representations for Computer Vision Applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Taubes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="258" />
			<date type="published" when="1994-03">Mar. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">3-D Object Recognition Using MEGI Model from Range Data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iwata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th Int&apos;l Conf. Pattern Recognition</title>
		<meeting>12th Int&apos;l Conf. Pattern Recognition<address><addrLine>Jerusalem, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-10">Oct. 1994</date>
			<biblScope unit="page" from="843" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Estimation of Planar Curves, Surfaces, and Nonplanar Space Curves Defined by Implicit Equations with Applications to Edge and Range Image Segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="115" />
			<date type="published" when="1991-11">Nov. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Describing Complicated Objects by Implicit Polynomials</title>
		<author>
			<persName><forename type="first">D</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Subrahmonia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="53" />
			<date type="published" when="1994-01">Jan. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Representations and Algorithms for 3D Curved Object Recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vijayakumar</surname></persName>
		</author>
		<editor>A.K. Jain and P.J. Flynn</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Elsevier Science Publishers B.V</publisher>
			<biblScope unit="page" from="17" to="56" />
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>Three-Dimensional Object Recognition Systems</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Structural Indexing: Efficient 3-D Object Recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="145" />
			<date type="published" when="1992-02">Feb. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Spherical Representation for the Recognition of Curved Objects</title>
		<author>
			<persName><forename type="first">H</forename><surname>Delingette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>Fourth IEEE Int&apos;l Conf. Computer Vision<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Method for Registration of 3-D Shapes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="1992-02">Feb. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recovering the Position and Orientation of Free-Form Objects from Image Contours Using 3D Distance Maps</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lavalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="378" to="390" />
			<date type="published" when="1995-04">Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Determining Pose of 3D Objects with Curved Surfaces</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Stockman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="56" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Triangles as a Primary Representation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<editor>Vision, M. Hebert, J. Ponce, T. Boult, and A. Gross</editor>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="191" to="206" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>Object Representation in Computer</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">HOT Curves for Modelling and Recognition of Smooth Curved 3D Objects</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-06">June 1994</date>
			<biblScope unit="page" from="876" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evidence-Based Recognition of 3-D Objects</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="783" to="802" />
			<date type="published" when="1988-11">Nov. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Practical Reliable Bayesian Recognition of 2D and 3D Objects Using Implicit Polynomials and Algebraic Invariants</title>
		<author>
			<persName><forename type="first">J</forename><surname>Subrahmonia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="505" to="519" />
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Shape Representation and Image Segmentation Using Deformable Surfaces</title>
		<author>
			<persName><forename type="first">H</forename><surname>Delingette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="132" to="144" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<title level="m">Springer Series in Perception Engineering</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>Surfaces in Range Image Understanding</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Solid</forename><surname>Shape</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Analysis and Interpretation of Range Images</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<editor>R.C. Jain and A.K. Jain</editor>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="141" to="205" />
		</imprint>
	</monogr>
	<note>Geometric Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A Guide to Distribution Theory and Fourier Transforms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Strichartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, Fla</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">View Organization and Matching of Free-Form Objects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dorai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Symp. Computer Vision, Coral Gables</title>
		<meeting>IEEE Int&apos;l Symp. Computer Vision, Coral Gables<address><addrLine>Fla</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-11">Nov. 1995</date>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Representations for Rigid Solids: Theory, Methods, and Systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A G</forename><surname>Requicha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980-12">Dec. 1980</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="437" to="464" />
		</imprint>
	</monogr>
	<note>Computing Surveys</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Orientation-Based Representations of 3-D Shape</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Woodham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-06">June 1994</date>
			<biblScope unit="page" from="182" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">CAD-Based Computer Vision: Modeling and Recognition Strategies</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Michigan State Univ., Dept. of Computer Science, East Lansing</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Feature Extraction for 3-D Model Building and Object Recognition</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Ferrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soucy</surname></persName>
		</author>
		<editor>A.K. Jain and P.J. Flynn</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Elsevier Science Publishers B.V</publisher>
			<biblScope unit="page" from="57" to="88" />
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>Three-Dimensional Object Recognition Systems</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Recognition of 3D Free-Form Objects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dorai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Int&apos;l Conf. Pattern Recognition</title>
		<meeting>13th Int&apos;l Conf. Pattern Recognition<address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-08">Aug. 1996</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="697" to="701" />
		</imprint>
	</monogr>
	<note>Vision</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">COSMOS: A Framework for Representation and Recognition of 3D Free-Form Objects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dorai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Computer Science</title>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
		<respStmt>
			<orgName>Michigan State Univ., East Lansing</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
