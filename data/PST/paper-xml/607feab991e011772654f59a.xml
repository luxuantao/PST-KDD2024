<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Surface Form Competition: Why the Highest Probability Answer Isn&apos;t Always Right</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-04-16">16 Apr 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Peter</forename><surname>West</surname></persName>
							<email>pawest@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Allen Institute for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Surface Form Competition: Why the Highest Probability Answer Isn&apos;t Always Right</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-04-16">16 Apr 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2104.08315v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models have shown promising results in zero-shot settings <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr" target="#b26">Radford et al., 2019)</ref>. For example, they can perform multiple choice tasks simply by conditioning on a question and selecting the answer with the highest probability.</p><p>However, ranking by string probability can be problematic due to surface form competition-wherein different surface forms compete for probability mass, even if they represent the same underlying concept, e.g. "computer" and "PC." Since probability mass is finite, this lowers the probability of the correct answer, due to competition from other strings that are valid answers (but not one of the multiple choice options).</p><p>We introduce Domain Conditional Pointwise Mutual Information, an alternative scoring function that directly compensates for surface form competition by simply reweighing each option according to a term that is proportional to its a priori likelihood within the context of the specific zero-shot task. It achieves consistent gains in zero-shot performance over both calibrated <ref type="bibr" target="#b44">(Zhao et al., 2021)</ref> and uncalibrated scoring functions on all GPT-2 and GPT-3 models on a variety of multiple choice datasets. 1 *A joint investigation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite the impressive results large pretrained language models have achieved in zero-shot settings <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr" target="#b26">Radford et al., 2019)</ref>, we argue that current work underestimates the zero-shot capabilities of these models on classification tasks. This is in large part due to surface form competition-a property of generative models that causes probability to be rationed between different valid Figure <ref type="figure">1</ref>: While humans select from given options, language models implicitly assign probability to every possible string. This creates surface form competition between different strings that represent the same concept. Example from CommonsenseQA <ref type="bibr" target="#b36">(Talmor et al., 2019)</ref>. strings, even ones that differ trivially, e.g., by capitalization alone. We show such competition can be largely removed by scoring choices according to Domain Conditional Pointwise Mutual Information (PMI DC ), which reweights scores by how much more likely a hypothesis (answer) becomes given a premise (question) within the specific task domain.</p><p>More specifically, consider the example question (shown in Figure <ref type="figure">1</ref>): "A human wants to submerge himself in water, what should he use?" with multiple choice options "Coffee cup", "Whirlpool bath", "Cup", and "Puddle." From the given options, "Whirlpool bath" is the only one that makes sense. Yet, other answers are valid and easier for a language model to generate, e.g., "Bathtub" and "A bathtub." Since all surface forms compete for finite probability mass, allocating significant probability mass to "Bathtub" decreases the amount of probability mass assigned to "Whirlpool bath." While the total probability of generating some correct answer may be high (i.e., across all valid surface forms), only one of these is a listed option. This is particularly problematic here, because "Whirlpool bath" will be much lower probability than "Bathtub," due to its rarity. More generally, methods that do not account for surface form competition will favor answers with fewer lexical paraphrases of this type, without any consideration of the task or question under consideration. PMI DC factors out the probability of a specific surface form, instead looking at how much more probable a hypothesis becomes when conditioned on a premise. We use a domain premise string to estimate the unconditional probability of a hypothesis in a given domain. For CommonsenseQA, for example, we compute the probability of each answer option immediately following the string "? the answer is:", and then divide the conditional by this estimate to calculate PMI DC . This scaling factor renormalizes according to the surface form competition that is inherent to the domain or task, e.g. completions of the domain premise that are just inherently unlikely will be upweighted more. After reweighting we can much more directly measure what the question tells us about the answer and vice versa (the mutual information, see §3 for a full derivation and discussion). Hypotheses no longer need to compete: both "Whirlpool bath" and "Bathtub " will be considered similarly connected to the question after the domain premise reweighting, and so both will attain a high score.</p><p>PMI DC is the only method that consistently outperforms raw, normalized, and calibrated probability scoring methods on more than a dozen multiple choice datasets and it does so for every model in the GPT-2 and GPT-3 families ( §4). To better explain these gains, we show it is possible to use the distinct structure of the COPA dataset <ref type="bibr" target="#b28">(Roemmele et al., 2011)</ref> to remove surface form competition entirely, which we call scoring-by-premise, and show that all methods perform well in this ideal-ized setting ( §5). Finally, we analyze three exceptions where PMI DC does worse than other methods and discuss how inherent differences in dataset construction and task specification cause different methods to work better or worse ( §6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Zero-shot vs. Few-Shot Zero-shot inference has long been of interest in NLP, Computer Vision, and ML in general <ref type="bibr" target="#b34">(Socher et al., 2013;</ref><ref type="bibr" target="#b9">Guadarrama et al., 2013;</ref><ref type="bibr" target="#b29">Romera-Paredes and Torr, 2015)</ref>. However, <ref type="bibr" target="#b26">Radford et al. (2019)</ref> popularized the notion that language models have many zero-shot capabilities that simply need to be discovered by prompting the model. For instance placing "TL;DR" (internet slang for Too Long; Didn't Read) at the end of an article causes the model to generate a summary. Efficiently discovering the right prompt is difficult and has become an active area of research <ref type="bibr" target="#b27">(Reynolds and McDonell, 2021;</ref><ref type="bibr" target="#b33">Shin et al., 2020;</ref><ref type="bibr" target="#b12">Jiang et al., 2020)</ref>. <ref type="bibr" target="#b1">Brown et al. (2020)</ref> demonstrated that few-shot learning without fine-tuning is possible with very large language models. Very recent work has shown it is possible to get smaller models to exhibit few-shot learning behavior, but again using finetuning <ref type="bibr">(Schick and Schütze, 2020b,a;</ref><ref type="bibr" target="#b33">Shin et al., 2020;</ref><ref type="bibr" target="#b44">Zhao et al., 2021)</ref>. Improving zero-shot inference of large models has been a less active area, as most zero-shot behavior is assumed to be directly tied to model quality. It is unclear how to train a better model for a particular task without any task-specific data.</p><p>Surface Form Competition When applying generative models to multiple choice problems simply choosing the highest probability answer becomes problematic due to valid surface forms competing for probability. Indeed, recent work in question answering has demonstrated the importance of considering all multiple choice options together <ref type="bibr" target="#b13">(Khashabi et al., 2020)</ref>, rather than independently assigning each answer a score and simply choosing the highest. This is a difficult strategy to adapt to left-to-right generative language models, which implicitly choose between all possible strings. The use of unsupervised language models pretrained on relatively expansive corpora exacerbates surface form competition because such language models generate a much wider distribution than a given question answering dataset contains.</p><p>"What is the most populous nation in North America?" Posed with this question, a language model such as GPT-3 can generate a correct response such as "USA", "United States", or "United States of America" with high probability. While correct strings like this all contribute to the probability of a correct generation, they may have vastly different probabilities: a common string "United States" will be much more likely than rarer forms like "U.S. of A.". In generative scenarios, as long as most of the probability mass goes to valid strings the generation is likely to be valid. This is not the case for multiple choice problems. Posed with two possible answers, "USA" and "Canada", GPT-3 may still choose the correct answer by probability. However, if we substitute out "USA" for "U.S. of A.", it becomes very likely that GPT-3 will assign higher probability to "Canada", a less likely answer conceptually, but a much more likely surface form. Beyond this, incorrect generic answers such as "I don't know" can take up much of the probability space, relegating the desired answers to the tail of the distribution where calibration with softmax is less trustworthy <ref type="bibr" target="#b10">(Holtzman et al., 2020)</ref>.</p><p>PMI Work in dialogue has used PMI to promote diversity <ref type="bibr" target="#b45">(Zhou et al., 2019;</ref><ref type="bibr" target="#b42">Yao et al., 2017;</ref><ref type="bibr" target="#b22">Li et al., 2016;</ref><ref type="bibr" target="#b22">Mou et al., 2016;</ref><ref type="bibr" target="#b37">Tang et al., 2019)</ref>.</p><p>Recently, Brown et al. (2020) used a scoring function resembling PMI DC for zero-shot question answering, though they only use the string "A:" as a prompt for the unconditional probability estimate, whereas we use a task-specific domain premise (see §3 for details). Furthermore, <ref type="bibr" target="#b1">Brown et al. (2020)</ref> only report this scoring method on three datasets (ARC, OpenBookQA, and RACE, included here) out of the more than 20 tested and do not compare scores with their standard method, averaging loglikelihoods (AVG in this work). In contrast, we complete a comprehensive comparison on GPT-3 and GPT-2, as well as shedding light on the underlying issue of surface form competition in §5.</p><p>Contextual Calibration Recently, <ref type="bibr" target="#b44">Zhao et al. (2021)</ref> describe a new method for calibrating the probabilities of an LM so that straightforward probability-based scoring works better. Though geared towards few-shot learning, the authors devise a clever means of using "dummy" answers for zero-shot learning. <ref type="bibr" target="#b44">Zhao et al. (2021)</ref> calibrate for three forms of bias: (1) majority label bias, (2) recency bias, and (3) common token bias. Of these, only (3) applies to the zero-shot case, as "majority label" and "recency" refer to the given few-shot examples' labels and ordering. PMI DC directly compensates for common token bias by dividing by the domain conditional probability of each answer without the need for new model parameters, and performs superior to contextual calibration (CC) in the majority of cases.</p><p>Prompt Sensitivity Recent work highlights the sensitivity of LMs with respect to the inputs, and proposes to consider various paraphrases of the prompt to overcome this sensitivity <ref type="bibr" target="#b5">(Davison et al., 2019;</ref><ref type="bibr" target="#b12">Jiang et al., 2020)</ref>, as well as noting that certain trigger tokens <ref type="bibr" target="#b33">(Shin et al., 2020)</ref> can strongly effect the output of such models. In this work we focus on fixing issues regarding the surface form of possible outputs.</p><p>Interpreting Language Models Language models tend to model selectional preferences and thematic fit <ref type="bibr" target="#b24">(Pantel et al., 2007;</ref><ref type="bibr" target="#b7">Erk et al., 2010)</ref> which are different from semantic plausibility because the former is more concerned with typicality <ref type="bibr" target="#b40">(Wang et al., 2018)</ref>. Probability, possibility and plausibility give distinct and relevant notions ( <ref type="bibr" target="#b38">Van der Helm, 2006)</ref>, but reporting bias <ref type="bibr" target="#b8">(Gordon and Van Durme, 2013)</ref> means that language models only model what people are likely to write (on websites, that were reachable under the given scrape, etc.). PMI DC aims to adjust for these challenges to better measure the underlying agreement between language models and human judgements, but of course is still subject to the limits of the language models it is used with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Zero-shot Scoring Strategies</head><p>This paper does not define any new modeling or finetuning methods. Rather, we propose the broad use of PMI DC scoring for any given model and prompt. PMI DC compensates for the fact that different correct answers compete for probability, even though only one will be listed as the correct multiple choice option. We begin by describing the two most common methods currently in use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Standard Methods</head><p>The first baseline approach is simply selecting the highest-probability option, e.g. baselines in <ref type="bibr" target="#b44">Zhao et al. (2021)</ref> and <ref type="bibr" target="#b12">Jiang et al. (2020)</ref>, which we here refer to as LM. Given a prompt x (e.g. "The man broke his toe because") and set of possible answers Figure <ref type="figure">2</ref>: An example from COPA <ref type="bibr" target="#b28">(Roemmele et al., 2011)</ref> with the template we use as well as the scoring functions we test. LM returns the highest probability option, while AVG length-normalizes log-likelihoods and chooses the highest option. PMI DC is a measurement of the mutual information between hypothesis and premise, intuitively how much x explains y i and vice versa. CC computes an affine transform of LM (adding extra parameters W and b), adjusting to a given answer set which must be finite and fixed for a given task; PMI DC does not require knowledge about possible answers and is readily applied to tasks where answers vary from question to question. y 1 , y 2 , • • • , y n (e.g. "he got a hole in his sock.", "he dropped a hammer on his foot"), LM is defined as:</p><formula xml:id="formula_0">arg max i P (y i |x).<label>(1)</label></formula><p>However, using length normalized log-likelihoods <ref type="bibr" target="#b1">(Brown et al., 2020)</ref> has become standard due to its superior performance, and is commonly used for generation tasks <ref type="bibr" target="#b19">(Mao et al., 2019;</ref><ref type="bibr" target="#b23">Oluwatobi and Mueller, 2020)</ref>. For causal language models, e.g., GPT-2 and GPT-3, Equation 1 can be decomposed as:</p><formula xml:id="formula_1">P (y i |x) = j=1 P (y j i |x, y 1 i , • • • , y j−1 i )</formula><p>where y j i is the jth token of y i and i is the number of tokens in y i . The AVG strategy is defined as:</p><formula xml:id="formula_2">arg max i i j=1 log P (y j i |x, y 1•••j−1 ) i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Domain Conditional PMI</head><p>Direct probability is not an adequate zero-shot scoring function due to surface form competition. A natural solution is to factor out the probability of specific surface forms, which is what Pointwise Mutual Information (PMI) does:</p><formula xml:id="formula_3">PMI(x, y) = log P (y|x) P (y) = log P (x|y) P (x) . (2)</formula><p>In effect, this is how much more likely the hypothesis ("he dropped a hammer on his foot") becomes given the premise ("The man broke his toe because"). In a multiple-choice setting-where the premise x does not change across hypotheses-this is proportional to P (x|y), i.e., the probability of the premise given the hypothesis. We experiment with this scoring-by-premise in Section 5. While Equation 2 estimates how related premise x is to hypothesis y in general, we found that estimates of P (y) vary wildly. We believe this is because many possible answers are extremely rare in a general setting and therefore their unconditional probability is not well calibrated for the purposes of a given task.</p><p>We are specifically trying to measure P (y) in a given domain, e.g., for the "because" relation in our running example, shown in Figures <ref type="figure">2 &amp; 3</ref>. To quantify this, we propose Domain Conditional PMI:</p><formula xml:id="formula_4">PMI DC (x, y, domain) = P (y|x, domain) P (y|domain) (3) = P (y|x, domain) P (y|x domain )<label>(4)</label></formula><p>or how much x tells us about y within a given domain.</p><p>Typically, P (y|x, domain) = P (y|x) because the premise x implies the domain in the datasets considered here and for most modern datasets, e.g., "The man broke his toe because" sets the model up to predict a dependent clause that is the cause of some event, without further representation of the domain. In order to estimate P (y|domain)-the probability of seeing hypothesis y in this domain-we use a short domainrelevant template x domain , which we call a "domain premise", often this is just the ending of the conditional premise x. For example, to help predict a causal relation like in Figure <ref type="figure">2</ref> we use x domain = "because" and thus divide by P (y|because). For details about templates see Appendix ??.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Non-standard Baselines</head><p>Unconditional We also compare to the unconditional (in-domain) estimate as a scoring function:</p><formula xml:id="formula_5">arg max i P (y i |x domain ).</formula><p>(5)</p><p>We refer to this as UNC. It ignores the premise completely, only using a domain premise x domain (e.g., using P (y|because) as the score). Yet, it is sometimes competitive, for instance on BoolQ <ref type="bibr" target="#b2">(Clark et al., 2019)</ref>. UNC is a sanity check on whether zero-shot inference is actually using the information in the question to good effect. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Multiple Choice Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>We use GPT-2 via the HuggingFace Transformers library <ref type="bibr" target="#b41">(Wolf et al., 2020)</ref> and GPT-3 via OpenAI's beta API. <ref type="foot" target="#foot_1">2</ref> We do not finetune any models, nor do we alter their output. Our code is public, complete with data loading scripts for each dataset to support maximum reproducibility. <ref type="foot" target="#foot_2">3</ref> See the appendix ( §??) for example instances from each dataset in our templated format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets</head><p>We report results on 16 splits of 13 datasets, and briefly describe each dataset here.</p><p>Continuation These datasets require the model to select a continuation to previous text, making them a natural way to test language models. Choice of Plausible Alternatives (COPA) <ref type="bibr" target="#b28">(Roemmele et al., 2011)</ref> asks for various "because" and "so" relationships, as shown in Figure <ref type="figure">2</ref>. StoryCloze (SC) <ref type="bibr" target="#b21">(Mostafazadeh et al., 2017)</ref> gives the model a choice between two alternative endings to 5 sentence stories. Finally, HellaSwag (HS) uses GPT-2 to generate, BERT to filter, and crowd workers to verify possible continuations to a passage.  <ref type="figure">C</ref>) are standardized tests described as "natural, grade-school science questions," with the "Easy" split found to be solvable by either a retrieval or word co-occurrence system, and the rest of the questions put in the "Challenge" split. Open Book Question Answering (OBQA) <ref type="bibr" target="#b20">(Mihaylov et al., 2018)</ref> is similar to both of these, but was derived using and intended to be tested with a knowledge source (or "book") available; we do not make use of the given knowledge source, following <ref type="bibr" target="#b1">Brown et al. (2020)</ref>. Finally, Common-senseQA (CQA) <ref type="bibr" target="#b36">(Talmor et al., 2019)</ref> leverages CONCEPTNET <ref type="bibr" target="#b35">(Speer et al., 2017)</ref> to encourage crowd workers to write questions with challenging distractors.</p><p>Open Set vs. Closed Set Datasets The above datasets are all "open set" in that multiple choice answers may be any string. Below we describe "closed set" datasets with a pre-specified set of answers. These are more difficult for the zeroshot case, as this closed set of answers is often somewhat domain specific, but we do not adapt the model to this closed set of answers in any capacity, unlike Contextual Calibration <ref type="bibr" target="#b44">(Zhao et al., 2021)</ref>. tions based on a multi-sentence passage, with a "yes" or "no" answer.</p><formula xml:id="formula_6">Boolean</formula><p>Entailment Entailment datasets focus on the question of whether a hypothesis sentence B is entailed by a premise sentence A. Recognizing Textual Entailment (RTE) <ref type="bibr" target="#b4">(Dagan et al., 2005)</ref> requires predicting an "entailment" or "contradiction" label while Commitment Bank <ref type="bibr" target="#b6">(De Marneffe et al., 2019)</ref> allows for (a small fraction of) questions to be marked "neutral".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Classification</head><p>We consider three more complex classification datasets: SST-2 &amp; -5 <ref type="bibr" target="#b34">(Socher et al., 2013)</ref> for various granularities of sentiment classification, AG's News <ref type="bibr" target="#b43">(Zhang et al., 2015)</ref> (AGN) for topic classification, and TREC <ref type="bibr" target="#b18">(Li and Roth, 2002)</ref> for question classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We report results for GPT-3 and GPT-2 in Tables <ref type="table" target="#tab_6">1  and 2</ref>. The trend favoring PMI DC is clear in these tables, but a more digestible summary is shown in Table <ref type="table" target="#tab_4">3</ref> which aggregates the percentage of splits over which a given method achieves the best score or ties for first-place. In this summarized view it is clear that PMI DC consistently outperforms other scoring methods when aggregated over a variety of datasets. Indeed, the smallest margin (in number of datasets won or tied) between PMI DC and the best competing method is on GPT-3 13B with AVG, but that margin is 50 percentage points. This does not imply that PMI DC is always better or that it will be better by a large margin, though it often is. It does suggest that PMI DC is a significantly better bet on a new dataset, as it more consistently matches or outperforms every other method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Removing Surface Form Competition</head><p>What if we used the probability of the premise given the hypothesis P (x|y i ) instead? While we are still measuring the probability of a surface form (e.g. "the man broke his toe"), it is the same surface form across different options ("he had a hole in his sock", "he dropped a hammer on his foot"), eliminating the surface form competition between options. y i and y i can now both attain high scores if they are both correct answers and cause x to be likely. We call this scoring-by-premise.</p><p>Due to the nature pretrained causal language models like GPT-2 and GPT-3, it is not usually possible to measure the premise given the hypothesis. This is because the phrasing of the connection between the premise and hypothesis often only works one way, e.g. it is strange to see an answer before a question. We exploit the structure of the COPA dataset <ref type="bibr" target="#b28">(Roemmele et al., 2011)</ref> to create a "COPA Flipped" dataset via a simple alternative template, shown in Figure <ref type="figure">3</ref>. COPA consists of cause and effect pairs (CAUSE so EFFECT, and EFFECT because CAUSE). In the original dataset, whatever comes second (either CAUSE or EFFECT) has multiple options that a model must choose between. These can be reversed by flipping the order of CAUSE and EFFECT, then substituting the natural inverse relation ("because"− →"so" and "so"− →"because" ). Table <ref type="table">4</ref> shows scores on COPA and COPA Flipped side-by-side. The clearest trend is that in COPA Flipped everything except UNC (Unc in the table) produces the exact same result. This is because flipping the hypothesis and premise means that it's the context that changes and not the continuation. LM, AVG, and PMI DC only differ from each other over different continuations, not over different contexts for the same continuation.</p><p>The second important observation is that in COPA Flipped all of these methods generally do about as well as PMI DC on the unflipped version. Indeed, on average they do a little bit better! This is because surface form competition has been eradicated: as the continuation being scored is always the same, it does not matter if other continuations would have been equally good. In COPA Flipped, it only matters how well the context explains the continuation, as measured via ease of prediction. This is not subject to surface form competition because there is only one hypothesis to explain, it is not competing with any other hypotheses for probability mass. Not all datasets are so easily flippable, so manually flipping individual questions is not a generally applicable strategy. Luckily, PMI DC is symmetric across flipping:</p><formula xml:id="formula_7">arg max i P (y i |x, domain) P (y i |domain) = arg max i P (x|y i , domain) P (x|domain) = arg max i P (x|y i , domain)</formula><p>In theory, PMI DC 's selected answer should be the same between on COPA and COPA Flipped, though we expect small differences due to "so" and "because" not being perfect inverses. Actually, the flipped score meets or exceeds PMI DC on the unflipped data on most models in this setting. One possible reason for this is that on COPA Flipped there is no division to calculate PMI DC ; since lan-Figure <ref type="figure">3</ref>: Experiment from §5, where the premise and hypothesis are flipped and the hypothesis that leads to the highest probability premise is chosen as the answer i.e. scoring-by-premise. In this case, LM, AVG, and PMI DC all yield the same solution, since they only differ between different hypotheses, not between different premises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COPA</head><p>COPA  <ref type="table">4</ref>: To demonstrate the presence of surface form competition, we show that methods that don't directly adjust for competing surface forms (i.e. LM and AVG) have the exact same score as PMI DC when scoring the premise. Indeed, using this method LM can do just as well as PMI DC applied to the non-flipped version of COPA because surface form competition is not present in this case. For details see §5.</p><p>guage model probabilities are approximations, division may induce multiplicative error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis</head><p>Failure Cases There are three datasets on which PMI DC does not consistently perform better than other scoring methods: HellaSwag, ARC Easy, and BoolQ. Interestingly (and without any foreknowledge on our part) each one is dominated by a different scoring method. HellaSwag is most amenable to AVG. After examining a number of data points and the scores of each algorithm, we observe that HellaSwag is more focused on the internal coherence of the hypotheses themselves (given basic topic information from the premise), rather than external coherence, e.g., a hypothesis being a valid or specific answer to a posed question. This is appears to be largely because it was generated by GPT-2 <ref type="bibr" target="#b26">(Radford et al., 2019)</ref> and filtered with BERT, which results in relatively on-topic but somewhat odd hypotheses that humans can distinguish from natural data.</p><p>ARC Easy yields highest scores to LM, i.e. just selecting the highest probability option. Upon manual observation, the strongest pattern we were able to find was the presence of stock answers, e.g., the fact that clouds are generated when "ocean water evaporates and then condenses in the air." Indeed, <ref type="bibr" target="#b3">Clark et al. (2018)</ref> note that ARC Easy are the questions that were solved either by a retrieval or word co-occurrence baseline, while examples that were answered incorrectly by both were put into the ARC Hard split. This appears to adequately explain our observations. Finally, BoolQ, a binary reading comprehension dataset, in which all answers are either "yes" or "no" is best solved by an unconditional baseline. This is largely because the dataset presents truly complex questions, that require more reasoning than GPT-2 or 3 are capable of doing out-of-thebox. The unconditional baseline simply manages to infer the majority label without data, but none of the methods reported actually do better than the majority baseline. The one exception is PMI DC with the largest GPT-3 model, but that is a less than 2 percentage point improvement.</p><p>Why does length normalization work? Past work offers little explanation for why AVG should be a successful strategy for choosing the correct answer, other than the vague intuitive notion that estimates are strongly length biased and require some kind of length compensation. Length bias may be caused by the final softmax layer of current language models assigning too much probability mass to irrelevant options at each time-step, a</p><p>property noted in open-ended generation, characterlevel language modeling, and machine translation <ref type="bibr" target="#b10">(Holtzman et al., 2020;</ref><ref type="bibr" target="#b0">Al-Rfou et al., 2019;</ref><ref type="bibr" target="#b25">Peters et al., 2019)</ref>. If this is the issue, it would mean that longer sequences are even less probable than they should be, biasing the model towards shorter answers.</p><p>Another possible argument is that length normalization may account for unconditional probability in a similar way to PMI DC . Length normalization is measured over Byte Pair Encoding (BPE) tokens <ref type="bibr" target="#b32">(Sennrich et al., 2016)</ref> and BPE tends to produce a vocabulary such that most tokens are equally frequent <ref type="bibr" target="#b39">(Wang et al., 2020)</ref>. Furthermore, recent evidence suggests that language is approximately uniformly information dense <ref type="bibr" target="#b15">(Levy, 2018;</ref><ref type="bibr" target="#b16">Levy and Jaeger, 2007;</ref><ref type="bibr" target="#b11">Jaeger, 2006)</ref>. As such, length in BPE tokens may correspond roughly to a unigram estimate of log-probability, supposing that BPE tokens have approximately uniform unigram log-probability. The adjustment made by AVG is still somewhat different than PMI DC , (division of log terms rather than subtraction) but could have a similar effect. On inspected examples AVG and PMI DC often agreed on answer ranking more than other pairs of methods. We leave exploration of this phenomenon to future work.</p><p>7 Discussion §5 shows that surface form competition is the cause of certain inadequacies with the standard probability-based scoring methods. PMI DC alleviates this, but so does scoring-by-premise in which the probability of the premise given the hypothesis is used as the score. The takeaway here is that generative models assigning probability to a given option isn't the same as selection. PMI DC is not a panacea for zero-shot inference. Rather, it is a technique that aligns the prediction being made by the model with the actual task humans would like to get done, which is closer to "choose the hypothesis that explains the premise" than "generate the exact surface form of the hypothesis".</p><p>Generative models are density estimation functions that assign probability to every possible string, which is a very different task than the human act of selecting an answer. We expect surface form competition anywhere that generative models are used for selection where there is sufficient uncertainty. There are also many more complex tasks we would like to apply generative models to, such as giving a model a prompt and having it write an essay, but they largely still elude us. Perhaps some of the difficulty comes from using these models in a way that doesn't align with the specific nature of the task.</p><p>Consider long-form generation, where currently the best we can do is sample from a large language model. This strategy is clearly problematic because language models marginalize over the contextual probability of every author they've encountered (weighted by the frequency with which they've encountered them) and then draw from this wide and extremely noisy distribution, a kind of "authorship competition".</p><p>No explicit modeling of concepts was needed to counteract surface form competition, instead using a variation of PMI for a scoring function was enough. We tentatively posit that similarly general methods (in contrast to explicit structure) may help in many other areas, especially as training becomes infeasible for most individual labs due to the cost and engineering effort required to build extremely large language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We conduct a large-scale comparison of standard and recent scoring functions for zero-shot inference across all GPT-2 and GPT-3 models. We show that Domain Conditional PMI consistently outperforms previous scoring functions on a wide variety of multiple choice datasets. We also argue that compensating for surface form competition is the cause of this boost, by demonstrating that other methods work just as well as Domain Conditional PMI when surface form competition is eliminated. We analyze failure cases of our proposed method and show that they are tied to dataset construction and task definition. Finally, we report a set of qualitative analyses to explain why Domain Conditional PMI outperforms existing zero-shot scoring methods. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="1,314.00,199.99,205.35,297.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-2.png" coords="4,92.66,66.65,426.69,176.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-3.png" coords="8,92.66,66.65,426.68,177.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>PMIDC CC Unc LM Avg PMIDC Unc LM Avg PMIDC Unc LM Avg PMIDC CC COPA 0.548 0.684 0.684 0.744 -0.564 0.758 0.736 0.770 0.566 0.792 0.778 0.842 0.560 0.852 0.828 0.892 -SC 0.509 0.660 0.683 0.731 -0.514 0.702 0.733 0.768 0.520 0.741 0.778 0.799 0.519 0.793 0.831 0.840 -HS 0.311 0.345 0.414 0.342 -0.347 0.408 0.535 0.400 0.388 0.488 0.662 0.458 0.435 0.576 0.772 0.535 -Comparison of scoring algorithms when using GPT-3 for zero-shot inference on multiple choice questions.</figDesc><table><row><cell>Multiple Choice Accuracy on GPT-3</cell></row><row><cell>Params. Unc LM Avg R-M 2.7B 0.224 0.378 0.424 0.426 -0.212 0.433 0.459 0.485 0.229 0.496 0.506 0.513 0.225 0.557 0.564 0.557 -6.7B 13B 175B R-H 0.214 0.303 0.327 0.360 -0.220 0.348 0.368 0.398 0.229 0.382 0.392 0.421 0.222 0.424 0.433 0.437 -ARC-E 0.316 0.504 0.447 0.447 -0.335 0.582 0.523 0.515 0.338 0.662 0.597 0.577 0.362 0.735 0.670 0.633 -ARC-C 0.211 0.216 0.255 0.305 -0.218 0.268 0.298 0.330 0.223 0.321 0.343 0.385 0.226 0.402 0.432 0.455 -OBQA 0.100 0.172 0.272 0.428 -0.114 0.224 0.354 0.480 0.104 0.282 0.412 0.504 0.106 0.332 0.438 0.580 -CQA 0.159 0.332 0.360 0.447 -0.174 0.400 0.429 0.503 0.164 0.488 0.479 0.585 0.163 0.610 0.574 0.667 -</cell></row><row><cell>BQ RTE CB SST-2 0.499 0.537 0.5376 0.723 0.714 0.499 0.545 0.545 0.800 0.499 0.690 0.690 0.810 0.499 0.636 0.636 0.714 0.758 0.622 0.585 0.585 0.535 -0.378 0.610 0.610 0.610 0.622 0.611 0.611 0.603 0.378 0.625 0.625 0.640 -0.473 0.487 0.487 0.516 0.495 0.527 0.552 0.552 0.487 0.527 0.527 0.527 0.549 0.473 0.560 0.560 0.643 0.578 0.089 0.518 0.518 0.571 0.500 0.089 0.339 0.339 0.393 0.089 0.518 0.518 0.500 0.089 0.482 0.482 0.500 0.482 SST-5 0.181 0.200 0.204 0.235 -0.181 0.278 0.227 0.320 0.181 0.186 0.296 0.191 0.176 0.270 0.273 0.296 -AGN 0.250 0.690 0.690 0.679 0.632 0.250 0.642 0.642 0.574 0.250 0.698 0.698 0.703 0.250 0.754 0.754 0.747 0.739 TREC 0.130 0.294 0.192 0.572 0.388 0.226 0.302 0.228 0.616 0.226 0.340 0.214 0.324 0.226 0.472 0.254 0.584 0.574</cell></row></table><note>Question Answering As the bridge between open set and closed set problems, we use BoolQ<ref type="bibr" target="#b2">(Clark et al., 2019)</ref> (BQ), which poses ques-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of scoring algorithms when using GPT-2 for zero-shot inference on multiple choice questions.</figDesc><table><row><cell>Params.</cell><cell cols="2">125M Unc LM Avg PMIDC Unc LM Avg PMIDC Unc LM Avg PMIDC Unc LM Avg PMIDC CC 350M 760M 1.6B</cell></row><row><cell cols="3">COPA 0.564 0.610 0.632 0.628 0.558 0.670 0.660 0.700 0.556 0.698 0.676 0.694 0.560 0.690 0.684 0.716 SC 0.495 0.600 0.615 0.670 0.489 0.630 0.667 0.716 0.503 0.661 0.688 0.734 0.512 0.676 0.715 0.763 HS 0.271 0.286 0.295 0.291 0.298 0.322 0.376 0.328 0.309 0.350 0.432 0.351 0.331 0.384 0.489 0.378 R-M 0.222 0.361 0.406 0.409 0.213 0.387 0.420 0.424 0.214 0.393 0.439 0.439 0.223 0.415 0.446 0.447 R-H 0.209 0.275 0.310 0.344 0.215 0.304 0.326 0.363 0.215 0.318 0.345 0.383 0.219 0.330 0.357 0.391 ARC-E 0.313 0.429 0.378 0.393 0.327 0.494 0.434 0.424 0.334 0.527 0.467 0.470 0.334 0.562 0.496 0.499 ARC-C 0.198 0.201 0.235 0.282 0.197 0.228 0.254 0.286 0.221 0.231 0.266 0.316 0.211 0.252 0.279 0.338 OBQA 0.11 0.164 0.272 0.324 0.108 0.186 0.302 0.386 0.108 0.194 0.296 0.432 0.114 0.224 0.348 0.460 CQA 0.170 0.255 0.307 0.364 0.165 0.309 0.352 0.418 0.170 0.333 0.368 0.445 0.171 0.386 0.385 0.478</cell><cell>---------</cell></row><row><cell cols="3">BQ RTE CB SST-2 0.499 0.636 0.636 0.671 0.499 0.802 0.802 0.862 0.499 0.770 0.770 0.856 0.499 0.840 0.840 0.875 0.820 0.622 0.588 0.588 0.511 0.622 0.608 0.608 0.497 0.622 0.580 0.580 0.467 0.622 0.563 0.563 0.495 -0.527 0.516 0.516 0.498 0.473 0.531 0.531 0.549 0.473 0.531 0.531 0.542 0.473 0.477 0.477 0.534 0.485 0.089 0.482 0.482 0.500 0.089 0.500 0.500 0.500 0.089 0.482 0.482 0.500 0.089 0.500 0.500 0.500 0.179 SST-5 0.181 0.274 0.244 0.300 0.176 0.185 0.272 0.393 0.176 0.203 0.267 0.220 0.176 0.304 0.291 0.408 -AGN 0.250 0.574 0.574 0.630 0.250 0.643 0.643 0.644 0.250 0.607 0.607 0.641 0.250 0.648 0.648 0.654 0.600 TREC 0.226 0.230 0.144 0.364 0.226 0.288 0.122 0.216 0.226 0.228 0.226 0.440 0.226 0.228 0.240 0.328 0.340</cell></row><row><cell></cell><cell>Percent of Ties or Wins by Method</cell></row><row><cell cols="2">Method Unc LM Avg PMI DC</cell><cell>CC</cell></row><row><cell cols="3">---6.25 12.50 12.50 80.00 20.00 125M 12.50 6.25 12.50 68.75 350M 6.25 18.75 12.50 68.75 760M 6.25 6.25 12.50 75.00 1.6B</cell></row><row><cell>2.7B 6.7B 13B 175B</cell><cell cols="2">6.25 6.25 6.25 86.66 0.00 -6.25 25.00 25.00 75.00 -6.25 18.75 18.75 68.75 6.25 12.50 18.75 62.50 6.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Percentage of datasets that a given method produced the best score or was tied for best score with other methods, aggregated over each model size. The first four rows use GPT-2 and summarize data from Table 2, while the final four rows use GPT-3 and summarize data from Table1. Since ties are included, rows sometimes sum to more than 100. CC is only measured on the 5 datasets we use where<ref type="bibr" target="#b44">Zhao et al. (2021)</ref> also report accuracies.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 :</head><label>1</label><figDesc>The man broke his toe]P [because]DP [he got a hole in his sock.]UH [I tipped the bottle]P [so]DP [the liquid in the bottle froze.]UH StoryCloze [Jennifer has a big exam tomorrow. She got so stressed, she pulled an all-nighter. She went into class the next day, weary as can be. Her teacher stated that the test is postponed for next week.]P [The story continues:]DP [Jennifer felt bittersweet about it.]UH HellaSwag [A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. the pans]P [contain egg yolks and baking soda.]UH QA RACE [There is not enough oil in the world now. As time goes by, it becomes less and less, so what are we going to do when it runs out [...].]P question: [According to the passage, which of the following statements is true]P[?]DP answer: [There is more petroleum than we can use now.]UH ARC [What carries oxygen throughout the body?]P [the answer is:]DP [red blood cells.]UH OBQA [Which of these would let the most heat travel through?]P [the answer is:]DP [a steel spoon in a cafeteria.]UH CQA [Where can I stand on a river to see water falling without getting wet?]P [the answer is:]DP [bridge.]UH Boolean QA BoolQ title: [The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016 [...]]P question: [Have the San Jose Sharks won a Stanley Cup?]P [answer:]DP [No.]UH Entailment RTE [Time Warner is the world's largest media and Internet company.]P question: [Time Warner is the world's largest company.]P [true or false? answer:]DP [true.]UH CB question: Given that [What fun to hear Artemis laugh. She's such a serious child.]P Is [I didn't know she had a sense of humor. ]P true, false, or neither? [the answer is:]DP [true.]UH Illuminating if overly talky documentary]P" [[The quote] has a tone that is]DP [positive.]UH SST-5 "[Illuminating if overly talky documentary]P" [[The quote] has a tone that is]DP [neutral.]UH AG's News title: [Economic growth in Japan slows down as the country experiences a drop in domestic and corporate [...]]P summary: [Expansion slows in Japan]P [topic:]DP [Sports.]UH TREC [Who developed the vaccination against polio?]P [The answer to this question will be]DP [a person.]UH The templates used for each task, along with an example instance (with a single random candidate answer). Original questions (premises) are colored blue, and original answers (hypotheses) are colored red. Long premises are abbreviated with "[...]". The full premises, conditional hypotheses and domain premises are marked in [•] P , [•] UH , and [•] DP respectively. For a complete description of our templating methodology, please see our code at https://github.com/peterwestuw/surface-form-competition</figDesc><table><row><cell>Type</cell><cell>Dataset</cell><cell>Template</cell></row><row><cell cols="3">Continuation Classification [Text COPA SST-2 "[</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Code is available at https://github.com/ peterwestuw/surface-form-competition</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://beta.openai.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://github.com/peterwestuw/ surface-form-competition</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by the ARO (AROW911NF-16-1-0121), the NSF (IIS-1562364), DARPA under the MCSprogram through NIWC Pacific (N66001-19-2-4031) and the Allen Institute for AI (AI2). We thank Mitchell Wortsman, Gabriel Ilharco, and Tim Dettmers for giving thorough and insightful feedback on preliminary drafts.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surface Form Competition: Why the Highest Probability Answer Isn't Always Right Supplementary Material 1 Templates</head><p>Table <ref type="table">1</ref> shows the template used for each model with an example instance.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Character-level language modeling with deeper self-attention</title>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dokook</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3159" to="3166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Boolq: Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2924" to="2936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05457</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges Workshop</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Commonsense knowledge mining from pretrained models</title>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1173" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The commitmentbank: Investigating projection in naturally occurring discourse</title>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandy</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Tonhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of Sinn und Bedeutung</title>
				<meeting>Sinn und Bedeutung</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="107" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A flexible, corpus-driven model of regular and inverse selectional preferences</title>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Padó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="723" to="763" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reporting bias and knowledge acquisition</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 workshop on Automated knowledge base construction</title>
				<meeting>the 2013 workshop on Automated knowledge base construction</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Youtube2text: Recognizing and describing arbitrary activities using semantic hierarchies and zero-shot recognition</title>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niveda</forename><surname>Krishnamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Malkarnenkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhashini</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
				<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2712" to="2719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Redundancy and syntactic reduction in spontaneous speech</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University Stanford, CA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">How can we know what language models know? Transactions of the</title>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-06">Jun Araki, and Graham Neubig. 2020</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="423" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00700</idno>
		<title level="m">Unifiedqa: Crossing format boundaries with a single qa system</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Race: Large-scale reading comprehension dataset from examinations</title>
		<author>
			<persName><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Communicative efficiency, uniform information density, and the rational speech act theory</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In CogSci</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Speakers optimize information density through syntactic reduction</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">849</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning question classifiers</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2002: The 19th International Conference on Computational Linguistics</title>
				<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving neural story generation by targeted common sense grounding</title>
		<author>
			<persName><forename type="first">Henry</forename><surname>Huanru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bodhisattwa</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Prasad Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrison</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5990" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2381" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lsdsem 2017 shared task: The story cloze test</title>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</title>
				<meeting>the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="46" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
				<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3349" to="3358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DLGNet: A transformer-based model for dialogue response generation</title>
		<author>
			<persName><forename type="first">Olabiyi</forename><surname>Oluwatobi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</title>
				<meeting>the 2nd Workshop on Natural Language Processing for Conversational AI</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ISP: Learning inferential selectional preferences</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonaventura</forename><surname>Coppola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Chklovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter</title>
				<meeting><address><addrLine>Rochester, New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="564" to="571" />
		</imprint>
	</monogr>
	<note>Proceedings of the Main Conference</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sparse sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André Ft</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1504" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Prompt programming for large language models: Beyond the few-shot paradigm</title>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07350</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmin</forename><surname>Adrian Bejan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">S</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An embarrassingly simple approach to zero-shot learning</title>
		<author>
			<persName><forename type="first">Bernardino</forename><surname>Romera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2152" to="2161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Exploiting cloze questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07676</idno>
		<imprint>
			<date type="published" when="2020">2020a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07118</idno>
		<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4222" to="4235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
				<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Targetguided open-domain conversation</title>
		<author>
			<persName><forename type="first">Jianheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5624" to="5634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Towards a clarification of probability, possibility and plausibility: how semantics could help futures practice to improve</title>
		<author>
			<persName><forename type="first">Ruud</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Helm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Foresight</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neural machine translation with byte-level subwords</title>
		<author>
			<persName><forename type="first">Changhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9154" to="9160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modeling semantic plausibility by injecting world knowledge</title>
		<author>
			<persName><forename type="first">Su</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Short Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Towards implicit contentintroducing for generative short-text conversation systems</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 conference on empirical methods in natural language processing</title>
				<meeting>the 2017 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2190" to="2199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Tony</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.09690</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised context rewriting for open domain conversation</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingsong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1834" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
