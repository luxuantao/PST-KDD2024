<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineer-ing</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<postCode>210094</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">35767D4FD4E8F2EBA8ADB6CA51BA1048</idno>
					<idno type="DOI">10.1109/TIP.2014.2317985</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixed Noise Removal by Weighted Encoding With Sparse Nonlocal Regularization</head><p>Jielin Jiang, Lei Zhang, Member, IEEE, and Jian Yang, Member, IEEE Abstract-Mixed noise removal from natural images is a challenging task since the noise distribution usually does not have a parametric model and has a heavy tail. One typical kind of mixed noise is additive white Gaussian noise (AWGN) coupled with impulse noise (IN). Many mixed noise removal methods are detection based methods. They first detect the locations of IN pixels and then remove the mixed noise. However, such methods tend to generate many artifacts when the mixed noise is strong. In this paper, we propose a simple yet effective method, namely weighted encoding with sparse nonlocal regularization (WESNR), for mixed noise removal. In WESNR, there is not an explicit step of impulse pixel detection; instead, soft impulse pixel detection via weighted encoding is used to deal with IN and AWGN simultaneously. Meanwhile, the image sparsity prior and nonlocal self-similarity prior are integrated into a regularization term and introduced into the variational encoding framework. Experimental results show that the proposed WESNR method achieves leading mixed noise removal performance in terms of both quantitative measures and visual quality.</p><p>Index Terms-Mixed noise removal, weighted encoding, nonlocal, sparse representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>D URING image acquisition and/or transmission, noise will be more or less introduced. Denoising (or noise removal) is a fundamental problem in image processing, aiming to estimate the original image from its noise-corrupted observation while preserving as much as possible the image edges, textures and fine scale details. The prior knowledge of noise distribution plays an important role in noise removal. Two types of commonly encountered noise are additive white Gaussian noise (AWGN) and impulse noise (IN). AWGN is often introduced due to the thermal motion of electron in camera sensors and circuits <ref type="bibr" target="#b21">[22]</ref>. IN is often introduced by malfunctioning pixels in camera sensors, faulty memory locations in hardware, or bit errors in transmission <ref type="bibr" target="#b22">[23]</ref>. Many papers have been published on removing either AWGN <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b19">[20]</ref> or IN <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b10">[11]</ref>. The mixture of AWGN and IN, however, is also commonly encountered in practice due to the multiple sources of noise. A variety of mixed noise removal methods have been proposed in past decades <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b35">[36]</ref>.</p><p>An image corrupted by IN will have a portion of its pixels replaced by random noise values with the remaining pixels unchanged. Two types of widely encountered IN are salt-andpepper impulse noise (SPIN) and random-valued impulse noise (RVIN). An image corrupted by SPIN shows dark pixels in bright regions and bright pixels in dark regions. Nonlinear filters such as median filters <ref type="bibr" target="#b0">[1]</ref> have been dominantly used to remove IN. However, one shortcoming of median filters is that the image local structures can be destroyed, making the denoised images look unnatural. This problem becomes serious when the IN density is high. Various improvements of median filters have been proposed to better preserve the image local structures <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Among them, the weighted median filter <ref type="bibr" target="#b1">[2]</ref>, the center-weighted median filter <ref type="bibr" target="#b2">[3]</ref> and the multistate median filter <ref type="bibr" target="#b3">[4]</ref> do not distinguish whether the current pixel is a noise pixel or not, and they tend to oversmooth the fine scale image details. An alternative way is to detect and process the corrupted IN pixels, and leave the uncorrupted pixels unchanged. The representative methods along this line include switching median filter <ref type="bibr" target="#b4">[5]</ref>, adaptive median filter (AMF) <ref type="bibr" target="#b5">[6]</ref>, tristate median filter <ref type="bibr" target="#b6">[7]</ref>, adaptive centerweighted median filter <ref type="bibr" target="#b7">[8]</ref>, conditional signal-adaptive median filter <ref type="bibr" target="#b8">[9]</ref>, and directional weighted median filter <ref type="bibr" target="#b9">[10]</ref>, etc. The genetic programming filter <ref type="bibr" target="#b10">[11]</ref> by switching between two IN detectors and their associated estimators was also developed for IN removal.</p><p>AWGN is the most widely studied noise model in image denoising literature <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b19">[20]</ref>. At each pixel of an image corrupted by AWGN, a value independently sampled from a zero-mean Gaussian distribution is added to the pixel gray level. Traditional linear filtering methods such as Gaussian filtering can smooth noise efficiently but they will over-smooth the image edges at the same time. To solve this problem, nonlinear filtering methods have been developed. The wellknown bilateral filter (BF) <ref type="bibr" target="#b11">[12]</ref> is good at edge preservation. It estimates each pixel as the weighted average of the neighboring pixels but the weights are determined by both the intensity similarity and spatial similarity. The nonlocal means (NLM)</p><p>filtering method <ref type="bibr" target="#b14">[15]</ref> can be viewed as a significant extension of BF based on the fact that similar pixels in an image can be spatially far from each other. In NLM, each pixel is estimated as the weighted average of all its similar pixels in the image, and the weights are determined by the similarity between them. By grouping the nonlocal similar patches into a 3D cube and applying transform based shrinkage, the BM3D method <ref type="bibr" target="#b13">[14]</ref> has become a benchmark for AWGN removal. Zhang et al. <ref type="bibr" target="#b15">[16]</ref> grouped the similar patches into a matrix and applied principal component analysis (PCA) to remove AWGN. The so-called LPG-PCA algorithm achieves very good edge preservation performance. In recent years, the sparse representation and dictionary learning based methods have been attracting significant attention in image restoration. The seminal work of K-SVD <ref type="bibr" target="#b12">[13]</ref> initiates the study of learning a dictionary from natural images for AWGN removal. The joint use of sparse representation and nonlocal selfsimilarity regularization has lead to state-of-the-art AWGN removal performance <ref type="bibr" target="#b16">[17]</ref>. Very recently, deep convolutional neural networks <ref type="bibr" target="#b17">[18]</ref> have also shown powerful capability to remove AWGN.</p><p>The mixture of IN and AWGN, however, makes the denoising problem much more difficult because of the very different properties of the two types of noises. A few methods have been developed to remove the mixed IN and AWGN noise <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b35">[36]</ref>. The median-based signal-dependent rank ordered mean (SDROM) filter <ref type="bibr" target="#b23">[24]</ref> can be used for IN removal as well as mixed noise removal. However, when applied to image with mixed noise, it often produces visually unpleasant artifacts. The trilateral filter (TF) <ref type="bibr" target="#b26">[27]</ref> incorporates the rank-order absolute difference (ROAD) statistics into the BF <ref type="bibr" target="#b11">[12]</ref> framework for IN detection. Switching bilateral filter (SBF) <ref type="bibr" target="#b27">[28]</ref> is also a modification of BF based on the method of detection and replacement. The reference median is computed to decide whether a current pixel is a noise pixel or not. If the absolute value between the reference median and a target pixel is large, then the target pixel is considered as a noise pixel, and consequently the mixed noise is removed by switching between the AWGN removal and IN removal. The FIRDM filter <ref type="bibr" target="#b28">[29]</ref> contains two separate steps: an IN detection step and a noise reduction step that preserves edge sharpness. It can effectively remove SPIN, but its performance in removing RVIN is not satisfactory because RVIN may not produce large gradient values. The HDIR filter <ref type="bibr" target="#b25">[26]</ref> removes mixed noise by kernel regression with Bayesian classification of the input pixels. In <ref type="bibr" target="#b29">[30]</ref>, a new IN detection mechanism based on robust outlyingness ratio (ROR) and NLM is proposed, where the image pixels are divided into four clusters according to the ROR value and by using an iterative coarse-to-fine strategy.</p><p>Cai et al. <ref type="bibr" target="#b30">[31]</ref> proposed a modified two-phase method to reconstruct images corrupted by IN and AWGN mixed noise, and the efficiency of this method is improved in <ref type="bibr" target="#b31">[32]</ref>. Xiao et al. <ref type="bibr" target="#b32">[33]</ref> proposed an l 1l 0 minimization approach to mixed noise removal. This method achieves state-of-theart denoising results but its computational complexity is somewhat high. Rodrίguez et al. <ref type="bibr" target="#b33">[34]</ref> proposed a cost functional consisting of a TV regularization term and l 2 and l 1 data fidelity terms, which aim to reduce AWGN and IN, respectively. This method achieves competitive mixed noise removal results but with much better computational performance. Dong et al. <ref type="bibr" target="#b34">[35]</ref> presented two sparsity-based regularization models for blind inpainting problems. A new variable is introduced in the data fidelity term to represent the outliers. Meanwhile, this new variable is used as a regularizer by assuming that the percentage of pixels damaged by IN is small. Recently, Liu et al. <ref type="bibr" target="#b35">[36]</ref> proposed a weighted dictionary learning model for mixed noise removal. This method integrates sparse coding and dictionary learning, image reconstruction, noise clustering and parameters estimation into a four-step framework, and each step solves a minimization problem.</p><p>Many existing mixed noise removal methods are detection based methods and they involve two sequential steps, i.e., first detect the IN pixels and then remove the noise. Such a two-phase strategy will become less effective when the AWGN or IN is strong. In this paper, we propose a simple yet effective encoding based method for mixed noise removal, namely weighted encoding with sparse nonlocal regularization (WESNR). There is no explicit impulse pixel detection in WESNR, and we encode each noise-corrupted patch over a pre-learned dictionary to remove the IN and AWGN simultaneously in a soft impulse pixel detection manner. The major difficulty of IN and AWGN mixed noise removal lies in the complex distribution of mixed noise, which has a heavy tail and cannot be readily characterized by a parametric model. The conventional l 2 -norm data fidelity term, which is well suited to characterize the Gaussian distributed data fitting residual, is not suitable to suppress the mixed noise with complex non-Gaussian distribution. In WESNR, the mixed noise is suppressed by weighting the encoding residual so that the final encoding residual will tend to follow Gaussian distribution. The weighted encoding and sparse nonlocal regularization are unified into a variational framework, which is easy to minimize. Extensive experiments are conducted to validate the proposed WESNR in comparison with state-of-the-art mixed noise removal methods.</p><p>The rest of the paper is organized as follows. Section II presents in detail the proposed WESNR scheme. Section III presents the experimental results and discussions. Section IV concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. WEIGHTED ENCODING WITH SPARSE NONLOCAL REGULARIZATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Mixed Noise</head><p>Denote by x an image and by x i, j its pixel at location (i, j ). Let y be the noisy observation of x. For additive white Gaussian noise (AWGN), each noisy pixel y i, j in y is modeled as y i, j = x i, j +v i, j , where v i, j is i.i.d. noise and follows zeromean Gaussian distribution. For impulse noise (IN), the two most common types of it are salt-and-pepper impulse noise (SPIN) and random-valued impulse noise (RVIN). Denote by [d min , d max ] the dynamic range of y. The SPIN noise model can be described as follows: y i, j = d min with probability s/2, y i, j = d max with probability s/2, and y i, j = x i, j with probability 1-s, where 0 ≤ s ≤ 1. The RVIN noise model can be defined as: y i, j = d i, j with probability r , and y i, j = x i, j with probability 1r , where 0 ≤ r ≤ 1 and d i, j is uniformly distributed within [d min , d max ].</p><p>In this paper, we consider two types of mixed noise: 1) AWGN mixed with SPIN, and 2) AWGN mixed with RVIN and SPIN. For the first case, the signal observation model can be described as</p><formula xml:id="formula_0">y i, j = ⎧ ⎨ ⎩ d min ,</formula><p>with probability s/2 d max , with probability s/2 x i, j + v i, j , with probability 1s.</p><p>(1)</p><p>For the second case, the observation model is</p><formula xml:id="formula_1">y i, j = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ d min , with probability s/2 d max , with probability s/2 d i, j , with probability r (1 -s) x i, j + v i, j , with probability (1 -r )(1 -s). (2)</formula><p>Examples of the images corrupted by the above two types of mixed noise can be found in Figs. <ref type="figure" target="#fig_7">7</ref> and<ref type="figure" target="#fig_8">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Denoising Model</head><p>Many mixed noise removal methods <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b33">[34]</ref> follow a two-phase framework. First, the IN pixels are detected and replaced, and then some AWGN removal methods are applied to estimate the image. The trilateral filter (TF) <ref type="bibr" target="#b26">[27]</ref> integrates rank-order absolute difference (ROAD) statistics into BF <ref type="bibr" target="#b11">[12]</ref> to form a simple model that does not need impulse pixel detection, and it achieves very good results for mixed AWGN and RVIN removal. However, it does not work well for either SPIN removal or mixed AWGN and SPIN removal. Furthermore, ROAD could produce false values when half of the pixels in the processing window are corrupted.</p><p>One natural question is that can we develop a mixed noise removal method which does not perform impulse pixel detection and AWGN removal separately but conducts the two tasks in a unified framework? Inspired by the robust estimation theory <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b43">[44]</ref> and the sparse coding based image restoration techniques <ref type="bibr" target="#b16">[17]</ref>, in this paper we propose a novel weighted encoding model to remove mixed noise, which does not have an explicit impulse pixel detection step and can process AWGN and IN simultaneously. The sparsity and nonlocal selfsimilarity priors of natural images are also integrated into the proposed model to make it powerful for mixed noise removal.</p><p>Denote by x ∈ R N an image. Following the notation in <ref type="bibr" target="#b12">[13]</ref>, we let</p><formula xml:id="formula_2">x i = R i x ∈ R n be the stretched vector of an image patch of size √ n × √ n,</formula><p>where R i is the matrix operator extracting patch x i from x at location i . Based on the sparse representation theory <ref type="bibr" target="#b36">[37]</ref>, we can find an over-complete dictionary Φ = [φ 1 ; φ 2 ; . . . ; φ n ] ∈ R n×m to sparsely code x i , where φ j ∈ R n is the j th atom of Φ. The representation of x i over dictionary Φ can be written as x i = Φα i , where α i is a sparse coding vector with only a few non-zero entries. The least square solution of x can be obtained as For the convenience of expression, we re-write the above equation as</p><formula xml:id="formula_3">x = i R T i R -1 i R T i Φα i .<label>(3)</label></formula><formula xml:id="formula_4">x = Φα, (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>where α is the set of all coding vectors α i .</p><p>In image denoising, the observation of x is noise-corrupted, and we can only encode the noisy observation y over the dictionary Φ to obtain the desired α. In the case of AWGN, the encoding model can be generally written as α = arg min α y -Φα 2  2 + λR(α), <ref type="bibr" target="#b4">(5)</ref> where R(α) is some regularization term imposed on α and λ is the regularization parameter. With certain regularization (e.g., sparsity) term <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b38">[39]</ref>, the resolved coding vector is the maximum a posteriori (MAP) solution for AWGN noise model. For images corrupted by mixed noise, however, the distribution of noise is generally far from Gaussian and thus the l 2 -norm data fidelity term y-Φα 2 2 in Eq. ( <ref type="formula">5</ref>) will not lead to a MAP solution for noise removal. Let's use an example to investigate the distributions of mixed noise. We simulated AWGN (standard deviation σ = 10), RVIN (r = 20%) and SPIN (s = 40%), and imposed them on image Lena, respectively. Fig. <ref type="figure" target="#fig_0">1(a)</ref> shows the distributions of data fitting residual y-Φα (i.e., y-x in the case of denoising) for AWGN, mixture of AWGN and RVIN, mixture of AWGN and SPIN, and mixture of AWGN, RVIN and SPIN, respectively. Fig. <ref type="figure" target="#fig_0">1(b)</ref> shows these distributions in log domain to better observe the heavy tails. Compared with the Gaussian distribution, we can clearly see that the distribution of mixed noise has a heavy tail, which is caused by IN. Therefore, using the l 2 -norm to characterize the data fitting residual y -Φα in Eq. ( <ref type="formula">5</ref>) is not optimal in the sense of MAP estimation.</p><p>From Fig. <ref type="figure" target="#fig_0">1</ref>, one can see that the distribution of data fitting residual is much more irregular than Gaussian, and it has a heavy tail. Intuitively, if we can modify the data fidelity term so that the residual can be more Gaussian-like, then the l 2 -norm can still be used to characterize the coding residual, making the mixed noise removal easier to handle. This motivates us to adopt the robust estimation technique <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b43">[44]</ref> to weight the data fitting residual so that its distribution can be more regular. Let e = [e 1 ; e 2 ; . . . ; e N ] = y -Φα, <ref type="bibr" target="#b5">(6)</ref> where e i = (y -Φα)(i ). Assume that e 1 , e 2 , . . . , e N are i.i.d. samples. Instead of minimizing e 2 2 = N i=1 e 2 i , which actually assumes that e i follows Gaussian distribution, we use the robust estimation technique <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b43">[44]</ref> to minimize the following loss:</p><formula xml:id="formula_6">min N i=1 f (e i ). (<label>7</label></formula><formula xml:id="formula_7">)</formula><p>The function f controls the contribution of each residual to the whole loss. In general, f should have the following properties: nonnegative, monotonic, and symmetric. That is: 1) f (e) ≥ 0 and f (0</p><formula xml:id="formula_8">) = 0; 2) f (e i ) ≥ f (e j ) if |e i | ≥ |e j |; 3) f (e) = f (-e).</formula><p>Obviously, when f (e j ) = e 2 j , the model in Eq. ( <ref type="formula" target="#formula_6">7</ref>) reduces to Eq. ( <ref type="formula">5</ref>). In order to weaken the effect of the heavy tail in mixed noise distribution, we can assign each residual a proper weight, resulting in a weighted residual:</p><formula xml:id="formula_9">e w i = w 1/2 i e i .<label>(8)</label></formula><p>In the problem of mixed AWGN and IN removal, the residuals can be classified into two categories. Those residuals obtained at the pixels corrupted by AWGN will basically follow Gaussian distribution and they can remain unchanged; that is, they should be assigned with weights close to 1. The residuals obtained at other pixels are mainly caused by IN, and they should be assigned with smaller weights to reduce the heavy tail of the distribution. Let's use an example to illustrate the effect of weighting. Suppose that an image is corrupted by AWGN (σ = 10) and SPIN (s = 40%). Fig. <ref type="figure" target="#fig_2">2</ref> i e i (how to set the weights will be discussed in the later development). Clearly, the distribution of weighted residuals is much closer to Gaussian distribution, implying that l 2 -norm can be used to model the weighted residuals for a MAP-like solution of coding vector α.</p><p>According to the above analysis, we adopt a new loss function f (e i ) = (w 2 , and consequently we have a new model for mixed noise removal:</p><formula xml:id="formula_10">1/2 i e i )</formula><formula xml:id="formula_11">α = arg min α W 1/2 (y -Φα) 2 2 + λR(α), (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>where W is a diagonal weight matrix with diagonal element W ii = w i . To make the above weighted encoding model more effective for mixed noise removal, some regularization terms R(α) can be used based on the priors of natural images. Two priors are widely used in image denoising: local sparsity and nonlocal self-similarity (NSS). The local sparsity of encoding coefficients α can be characterized by the l 1 -norm of α, while the NSS can be characterized by the prediction error of a patch by its similar patches. Inspired by the work in <ref type="bibr" target="#b16">[17]</ref>, we integrated the two priors into a sparse nonlocal regularization term and adopt it to Eq. ( <ref type="formula" target="#formula_11">9</ref>).</p><p>For each patch x i , we search the similar patches to it within a large enough window centered at location i. A patch x q i is collected as a similar patch to x i if the Euclidean distance between them is not greater than a preset threshold. Then we can select the first L closest patches to x i and use the weighted average of them, xi = L q=1 b q i x q i , to predict x i . The weight b q i is inversely proportional to the distance between patches x i and x</p><formula xml:id="formula_13">q i : b q i = exp(-x i -x q i 2 2 / h)/ω,</formula><p>where h is a preset scalar and ω is a normalization factor. If a patch and its nonlocal prediction are encoded by a given dictionary Φ i , i.e., x i = Φ i α i and xi = Φ i μ i , then the coding coefficients α i and μ i should also be similar. Therefore, we can use i α i -μ i l p as the regularization term to regularize the solution of Eq. ( <ref type="formula" target="#formula_11">9</ref>):</p><formula xml:id="formula_14">α = arg min α W 1/2 (y -Φα) 2 2 + λ i α i -μ i l p , (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>where l p ( p = 1 or 2) refers to the l p -norm.</p><p>In order to determine the value of p, we need to check the distribution of α i -μ i . Let</p><formula xml:id="formula_16">γ i = α i -μ i . (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>We assume that the elements in γ i are i.i.d. and follow generalized Gaussian distribution (GGD), which is defined as:</p><formula xml:id="formula_18">f (γ ) = β exp{-(|γ |/σ γ ) β }/(2σ γ Γ (1/β)), (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where Γ denotes the gamma function, and σ γ is a scale parameter. The value of β in Eq. ( <ref type="formula" target="#formula_18">12</ref>) determines the shape of a GGD. In particular, setting β = 1 or β = 2 leads to Laplacian distribution or Gaussian distribution, respectively.</p><p>We use an example to figure out which setting we should use for the distribution f (γ ). We run our algorithm without the regularization i α i -μ i l p in Eq. ( <ref type="formula" target="#formula_14">10</ref>) on image Lena (the algorithm is summarized in Algorithm 1). In Fig. <ref type="figure">3</ref> we plot the histogram of γ as well as the fitting Gaussian and Laplacian distributions of it. Clearly, Laplacian distribution fits the histogram of γ much better. Therefore, we approximately assume that γ follows Laplacian distribution, and hence the l 1 -norm regularization on γ could lead to a MAP-like estimation. Finally, the proposed model becomes α = arg min α { W 1/2 (y -Φα) 2  2 + λ α -μ 1 }. (13) In the above model, the data fidelity term weights the encoding residual, while the regularization term integrates sparsity and NSS priors. We call the proposed model weighted encoding with sparse nonlocal regularization (WESNR).</p><p>In the WESNR model Eq. ( <ref type="formula">13</ref>), W is a diagonal weight matrix, and its element W ii is to be automatically determined and assigned to pixel i . Clearly, the pixels corrupted by IN should have small weights to reduce their effect on the encoding of y over Φ, while the weights assigned to uncorrupted pixels should be close to 1. In our algorithm, the dictionary Φ is pre-learned from clean natural images (please refer to next sub-section for more information), and the pixels corrupted by IN will have big coding residuals. Therefore, the coding residual e i can be used to guide the setting of weight W ii , and W ii should be inversely proportional to the strength of e i . In order to make the weighted encoding stable and easy to control, we set W ii ∈ [0, 1]. One simple and appropriate choice of W ii is</p><formula xml:id="formula_20">W ii = exp(-ae 2 i ), (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>where a is a positive constant to control the decreasing rate of W ii w.r.t. e i . With Eq. ( <ref type="formula" target="#formula_20">14</ref>), the pixels corrupted by IN will be adaptively assigned with lower weights to reduce their impact in the process of encoding. Note that such a weighting scheme will make the corresponding loss function f (e i ) meet the requirements 1), 2) and 3).</p><p>Once W is given, the WESNR model in Eq. ( <ref type="formula">13</ref>) becomes an l 1 -norm sparse coding problem and many existing l 1 -norm minimization techniques <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> can be used to solve it. In this paper, we solve it via the iteratively reweighted scheme <ref type="bibr" target="#b39">[40]</ref> for its simplicity. Let V be a diagonal matrix. We first initialize it as an identity matrix, and then in the (k + 1) th iteration, each element of V is updated as</p><formula xml:id="formula_22">V (k+1) ii = λ/((α (k) i -μ i ) 2 + ε 2 ) 1/2 , (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>where ε is a scalar and α (k)   i is the i th element of coding vector α in the k th iteration. Then we update α as α(k+1) = (Φ T WΦ + V (k+1) ) -1 (Φ T Wy -Φ T WΦμ)+μ. <ref type="bibr" target="#b15">(16)</ref> By iteratively updating V and α, the desired α can be efficiently obtained. The convergence of the iteratively reweighted scheme has been proved in <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Dictionary</head><p>In sub-section II-B, we assumed that the dictionary Φ is given. The selection of dictionary is an important issue to the sparse coding and reconstruction of a signal. In particular, learning dictionaries from natural image patches has shown promising results in image restoration <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b38">[39]</ref>. The seminal work of K-SVD <ref type="bibr" target="#b12">[13]</ref> learns an over-complete and universal dictionary to process any input patch; however, it is not adaptive to the content of the given patch and is not efficient due to the large number of atoms in the over-complete dictionary. In this paper, we adopt the strategy in <ref type="bibr" target="#b38">[39]</ref> to learn a set of local PCA dictionaries from natural images.</p><p>We use the same 5 high-quality images (which are independent of the test images used in this paper) as in <ref type="bibr" target="#b38">[39]</ref> to train the PCA dictionaries. The scenes of the five images are shown in Fig. <ref type="figure" target="#fig_4">4</ref>. A number of 876,359 patches (size: 7×7) are extracted from the five images and they are clustered into 200 clusters by using the K-means clustering algorithm. For each cluster, a compact local PCA dictionary is learned. Meanwhile, the centroid of each cluster is calculated. For a given image patch, the Euclidian distance between it and the centroid of each cluster is computed, and the PCA dictionary associated with its closest cluster is chosen to encode the given patch. Note that since the selected dictionary, denoted by Φ i , is orthogonal, the μ i for patch x i can be simply computed as μ i = Φ T i xi . In our PC (3.2 GHZ CPU, 8 GB RAM memory) and under the Matlab R2011b programming environment, the patch clustering and dictionary learning process takes about 745 seconds in total. In addition, the final denoising results are not sensitive to the training images used for PCA dictionary learning. By using another five high-quality images with sufficient texture/edge regions, similar denoising results will be obtained. This is identical to the observation in <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Algorithm of WESNR</head><p>Once the dictionary Φ is adaptively determined for a given patch, the proposed WESNR model can be solved by iteratively updating W and α. The updating of W depends on the coding residual e. In the literature of mixed AWGN and SPIN noise removal <ref type="bibr" target="#b30">[31]</ref>- <ref type="bibr" target="#b33">[34]</ref>, AMF <ref type="bibr" target="#b5">[6]</ref> is widely used to detect SPIN. In order to make a fair comparison with them, in the case of AWGN+SPIN noise revoval, we apply AMF to y to obtain an initialized image x (0) , and then initialize e as: e (0) = yx (0) , <ref type="bibr" target="#b16">(17)</ref> In the case of AWGN+RVIN+SPIN noise removal, AMF cannot be applied to y to initialize x. We initialize e as</p><formula xml:id="formula_24">e (0) = y -μ y • 1,<label>(18)</label></formula><p>where μ y is the mean value of all pixels in y and 1 is a column vector whose elements are all 1. In other words, we simply use the mean value of y to initialize x. Then the initial coding residual can be roughly computed. This simple initialization strategy works very well in all our experiments. With the initialized coding residual e (0) , W can be initialized by Eq. ( <ref type="formula" target="#formula_20">14</ref>). The main procedures of the proposed WESNR based mixed noise removal algorithm are summarized in Algorithm 1.</p><p>In our algorithm, we set t = Φα (k+1) -Φα (k) 2 / Φα (k) 2 &lt; τ as the termination condition. Fig. <ref type="figure" target="#fig_5">5</ref> shows the curve of log(t) versus the number of iterations by applying the WESNR algorithm to a noisy Lena image. Because of the weighting matrix W, the IN pixels in the image can be well identified and their effect is suppressed in the encoding of y. As a result, both IN and AWGN will be gradually removed in the iteration. Generally, our algorithm will terminate in six to twelve iterations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTAL RESULTS</head><p>In this section, experiments are carried out to demonstrate the performance of the proposed WESNR algorithm. We first discuss the parameter setting in Section III-A; in Section III-B we conduct experiments on ten commonly used test images: Lena, F16, Leaves, Boat, Couple, Fingerprint, Hill, Man, Peppers and Painting, respectively (please refer to Fig. <ref type="figure" target="#fig_6">6</ref> for the scenes of the ten images); finally, we make some discussions in Section III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Setting</head><p>There are several parameters to set in the proposed WESNR algorithm, and they all can be easily fixed by experience. The parameter τ is to control the termination of iteration. In order to balance the denoising results and the number of iterations, we empirically set it to 0.003. The parameter a in Eq. ( <ref type="formula" target="#formula_20">14</ref>) controls the decreasing rate of weights w.r.t. e and we empirically set it to 0.0008.</p><p>In Eq. ( <ref type="formula">16</ref>), there are two parameters to compute the diagonal matrix V: λ and ε. In our method, the sparse nonlocal regularization is mainly to remove AWGN. In the first loop of our algorithm, since the IN is severe, the block-matching based nonlocal similar patch searching process is not accurate. Thus, the nonlocal regularization is not very helpful and we assign λ a small value (0.0001 in our algorithm) to weaken the role of nonlocal regularization term. From the second loop, the IN is largely reduced, and thus the nonlocal similar patch searching becomes more accurate. Then we assign λ a large value to remove AWGN. When the standard deviation of AWGN is higher than 10, we set λ = 1; otherwise, we set λ = 0.5 to suppress AWGN while preserving the image details as much as possible. The parameter ε is a small scalar to increase the numerical stability of computing Eq. ( <ref type="formula">16</ref>). We set it to</p><formula xml:id="formula_25">ε (k+1) = mi n(ε (k) , (medi an(|α (k) -μ|)),<label>(19)</label></formula><p>with ε (0) = 0.1. This is to ensure that ε will decrease with the iteration and it is adaptive to the range of |α (k) -μ|. All the parameters are fixed in all our following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results</head><p>We then conduct extensive experiments to demonstrate the performance of the proposed WESNR model. We consider two types of mixed noise: AWGN+SPIN, and AWGN+RVIN+SPIN. For AWGN+SPIN mixed noise, the standard deviation of AWGN varies with σ = 10, 20, 25 and the SPIN ratio varies with s = 30%, 40%, 50%, respectively. For AWGN+RVIN+SPIN mixed noise, the standard deviation of AWGN varies with σ = 5, 10, 15, the RVIN ratio varies with r = 5%, 10%, 15% and the SPIN ratio varies with s = 30%, 40%, 50%, respectively.</p><p>For AWGN+SPIN, we compare our WESNR method with the following three state-of-the-art mixed noise removal methods: ROR-NLM <ref type="bibr" target="#b29">[30]</ref>, Cai et al. <ref type="bibr" target="#b31">[32]</ref>, and l 1l 0 <ref type="bibr" target="#b32">[33]</ref>. Both Cai et al. <ref type="bibr" target="#b31">[32]</ref> and l 1l 0 <ref type="bibr" target="#b32">[33]</ref> cannot be applied to AWGN+RVIN+SPIN mixed noise removal. Therefore, for AWGN+RVIN+SPIN we compare WESNR with ROR-NLM <ref type="bibr" target="#b29">[30]</ref>, TF <ref type="bibr" target="#b26">[27]</ref> and BM3D <ref type="bibr" target="#b13">[14]</ref> coupled with median filter 1 (denoted by M+BM3D, which first applies median filtering to remove IN and then applies BM3D to remove AWGN). The size of median window is set 7 × 7.</p><p>The source codes of all the competing methods were obtained from the original authors. We use the default parameter settings except for Cai et al.'s method <ref type="bibr" target="#b31">[32]</ref>. Since Cai et al. 's method is originally designed for deblurring with IN, in the experiment we set the out-of-focus kernel to have radius 0 and set β m = [0.1, 0.3, 0.3, 0.3, 0.3]. The original setting of β m is [0.00001, 0.00002, 0.00002, 0.00002, 0.00002], but this is not suitable for mixed noise removal.</p><p>Apart from PSNR, we also compute the recently developed image perceptual quality index, FSIM <ref type="bibr" target="#b20">[21]</ref>, to evaluate titatively the results. For each experiment, we run the programs 50 times independently, and report the mean and standard deviation of the 50 outputs. The PSNR and FSIM results on the ten test images by the competing methods are listed in Tables I and II for the two types of mixed noise, 1 The adaptive median filter (AMF) and adaptive center-weighted median filter (ACWMF) are commonly used for SPIN and RVIN detection, respectively. However, for mixed noise such as AWGN+RVIN+SPIN, to the best of our knowledge, there is no adaptive filter which can detect SPIN and RVIN simultaneously. We tested to use AMF for SPIN detection and then use ACWMF for RVIN detection, followed by BM3D for AWGN removal, the experimental results are similar to coupling BM3D with median filter but the whole algorithm becomes much more complex. Thus we use BM3D coupled with median filter for comparison. respectively. For our WESNR algorithm, the average number of iterations is about 10.</p><p>From Table <ref type="table" target="#tab_0">I</ref>, it can be seen that for mixed AWGN+SPIN noise removal, the proposed WESNR method could consistently achieve much higher PSNR and FSIM indices than the ROR-NLM and Cai et al.'s methods, and better PSNR and FSIM performance than the l 1l 0 method. With the increase of the strength of either AWGN or IN, the improvement of WESNR over the l 1l 0 method is getting higher and higher. From Table <ref type="table" target="#tab_1">II</ref>, one can clearly see that for mixed AWGN+RVIN+SPIN removal, the proposed WESNR achieves significantly better PSNR and FSIM indices than all the competing methods.</p><p>Let's give some visual comparisons of the denoising results by different methods. Fig. <ref type="figure" target="#fig_7">7</ref> shows the denoising results on image Lena. Fig. <ref type="figure" target="#fig_7">7</ref>(b) and Fig. <ref type="figure" target="#fig_7">7(c</ref>) show the Lena images corrupted by AWGN+SPIN (σ = 10, s = 50%) and AWGN+RVIN+SPIN (σ = 15, r = 15%, s = 30%). In the 2 nd row of Fig. <ref type="figure" target="#fig_7">7</ref>, the denoising results by the four mixed AWGN+SPIN noise removal methods are displayed. One can see that the proposed WESNR reconstructs much cleaner and sharper image edges and generates much less artifacts, leading to visually much more pleasant denoising results than the other competing methods. The 3 rd row of Fig. <ref type="figure" target="#fig_7">7</ref> shows the denoising results of the four mixed AWGN+RVIN+SPIN noise removal methods. One can see that M+BM3D over-smoothes much the image details and destroys the image local structure; TF results in severe SPIN caused image distortions; ROR-NLM leads to better results than TF, but it remains many Gaussian like and impulse like noises. In Fig. <ref type="figure" target="#fig_8">8</ref>, we show the denoising results on image Leaves. Clearly, WESNR reconstructs much better   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discussions</head><p>As can be seen in sub-section III-B, the proposed WESNR algorithm shows very powerful mixed noise removal performance. It can deal with either mixed AWGN+SPIN noise or mixed AWGN+RVIN+SPIN noise, and runs faster than the state-of-the-art methods in <ref type="bibr" target="#b31">[32]</ref> and <ref type="bibr" target="#b32">[33]</ref>. The superior denoising performance of WESNR to other competing methods comes from both its weighted encoding based data fidelity term and sparse nonlocal regularization term. The role of weighted encoding is to suppress IN and the role of sparse nonlocal regularization is to suppress AWGN. Since the goal  <ref type="bibr" target="#b29">[30]</ref>, (e) Cai et al. <ref type="bibr" target="#b31">[32]</ref>, (f) l 1l 0 <ref type="bibr" target="#b32">[33]</ref> and (g) WESNR. Third row: denoising results of image in (c) by (h) ROR-NLM <ref type="bibr" target="#b29">[30]</ref>, (i) TF <ref type="bibr" target="#b26">[27]</ref>, (j) M+BM3D <ref type="bibr" target="#b13">[14]</ref> and (k) WESNR.</p><p>here is to remove mixed AWGN and IN noise, both of the two terms are necessary and they should work together to remove the mixed noise. Without the weighted encoding term, the IN cannot be effectively removed; without the sparse nonlocal regularization term, the AWGN noise will largely remain in the output image. The two terms play the same important role in mixed noise removal.</p><p>In WESNR, the weights W are introduced in the data fidelity term, and they are adaptively updated in the iteration process. W are with real values, and the pixels corrupted by IN will be assigned small weights to reduce their effect on the encoding of y over the dictionary Φ so that clean images can be reconstructed. In our algorithm, a set of orthogonal PCA dictionaries are pre-learned from some high quality images, and one local PCA dictionary is adaptively selected to process a given image patch. In a recent work <ref type="bibr" target="#b35">[36]</ref>, a weighted dictionary learning model is developed for mixed noise removal. Though both our method and Liu et al.'s method introduce weights in the data fidelity term, they have clear differences. First of all, the method in <ref type="bibr" target="#b35">[36]</ref> mainly focuses on weighted dictionary learning, while our method focuses on weighted encoding. In <ref type="bibr" target="#b35">[36]</ref>, the dictionary is online learned and updated in each iteration. In our method, the dictionary is offline learned and it is fixed in the whole algorithm. That is, our algorithm is purely a sparse encoding algorithm, while the algorithm in <ref type="bibr" target="#b35">[36]</ref> involves sparse coding and dictionary learning. The implementations of the two methods are also very different. The model in <ref type="bibr" target="#b35">[36]</ref> is mathematically beautiful but it is somewhat complex. It needs four steps to optimize, and in each step there is a minimization problem. Our model is much simpler and it can be easily solved by iteratively re-weighted method. In another recent work <ref type="bibr" target="#b22">[23]</ref>, a 0 or 1 valued parameter is introduced in the data fidelity term and the penalty term to detect IN and remove AWGN. This is basically a detection based method, and no dictionary is used to reconstruct the image.</p><p>In the l 1l 0 algorithm <ref type="bibr" target="#b32">[33]</ref>, a dictionary is also used to reconstruct the image. However, the use of dictionary in <ref type="bibr" target="#b32">[33]</ref>  is very different from that in our method. In <ref type="bibr" target="#b32">[33]</ref>, an overcomplete dictionary is online learned from the patches collected at those outlier-free pixels in each iteration. A modified K-SVD algorithm is used for dictionary learning. The whole algorithm needs three phases to optimize. In our method, the offline learned compact PCA dictionaries are used. This is one of the reasons why our algorithm runs much faster than <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>We presented a novel model for mixed noise removal, namely weighted encoding with sparse nonlocal regularization (WESNR). The distribution of mixed noise, e.g., additive white Gaussian noise mixed with impulse noise, is much more irregular than Gaussian noise alone, and often has a heavy tail. To address this difficulty, we adopted the weighted encoding technique to remove Gaussian noise and impulse noise jointly. We encoded the image patches over a set of PCA dictionaries learned offline, and weighted the coding residuals to suppress the heavy tail of the distribution. The weights were adaptively updated to decide whether a pixel is heavily corrupted by impulse noise or not. Meanwhile, image sparsity prior and nonlocal self-similarity prior were integrated into a single nonlocal sparse regularization term to enhance the stability of weighted encoding. The results clearly demonstrated that WESNR outperforms much other state-of-the-art mixed noise removal methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The distribution of AWGN and mixed noise in (a) linear and (b) log domains, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) shows the distribution of residuals e i and the fitting Gaussian function based on the variance of e i , Fig. 2(b) shows the distribution of weighted residuals w 1/2 i e i and the fitting Gaussian function based on the variance of w 1/2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) The distribution of residuals e i and the fitting Gaussian in log domain. (b) The distribution of weighted residuals w 1/2 i e i and the fitting Gaussian in log domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1 Fig. 3 .</head><label>13</label><figDesc>Fig. 3.The histogram of γ and the fitting Gaussian and Laplacian distributions in log domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Five high-quality images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. A typical curve of convergence of the proposed WESNR algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The ten test images. From left to right and top to bottom: Lena, F16, Leaves, Boat, Couple, Fingerprint, Hill, Man, Peppers and Painting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Denoising results of different methods on test image Lena. (a) Original image. (b) Image corrupted by mixed noise AWGN+SPIN (σ = 10, s = 50%). (c) Image corrupted by mixed noise AWGN+RVIN + SPIN (σ = 15, r = 15%, s = 30). Second row: denoising results of image in (b) by (d) ROR-NLM<ref type="bibr" target="#b29">[30]</ref>, (e) Cai et al.<ref type="bibr" target="#b31">[32]</ref>, (f) l 1l 0<ref type="bibr" target="#b32">[33]</ref> and (g) WESNR. Third row: denoising results of image in (c) by (h) ROR-NLM<ref type="bibr" target="#b29">[30]</ref>, (i) TF<ref type="bibr" target="#b26">[27]</ref>, (j) M+BM3D<ref type="bibr" target="#b13">[14]</ref> and (k) WESNR.the edges of leaves than all the other competing methods. Particularly, in the case of AWGN+RVIN+SPIN, all the other three methods fail to recover the image structures, while the proposed WESNR can still faithfully reconstruct the edge and texture features.Finally, let's compare the running time of the competing methods. All the algorithms are run under the Matlab R2011b programming environment on a PC equipped with 3.2 GHZ CPU and 8 GB RAM memory. Table III lists the running time (second) of the four mixed AWGN+SPIN noise removal methods in processing the image Lena (size: 512 × 512) with different noise levels. It can be seen that the proposed WESNR method is much faster than the other three methods. In TableIV, we list the running time (second) of the four mixed AWGN+RVIN+SPIN noise removal methods. WESNR is much faster than ROR-NLM. It is not a surprise that TF runs faster than WESNR because it is basically a type of local nonlinear filtering method. M+BM3D runs the fastest because the BM3D algorithm is implemented by C but with a Matlab interface.</figDesc><graphic coords="9,62.63,322.01,117.02,116.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Denoising results of different methods on test image Leaves. (a) Original image. (b) Image corrupted by mixed noise AWGN+SPIN (σ = 20, s = 40%). (c) Image corrupted by mixed noise AWGN+RVIN+SPIN (σ = 5, r = 5%, s = 50). Second row: denoising results of image in (b) by (d) ROR-NLM<ref type="bibr" target="#b29">[30]</ref>, (e) Cai et al.<ref type="bibr" target="#b31">[32]</ref>, (f) l 1l 0<ref type="bibr" target="#b32">[33]</ref> and (g) WESNR. Third row: denoising results of image in (c) by (h) ROR-NLM<ref type="bibr" target="#b29">[30]</ref>, (i) TF<ref type="bibr" target="#b26">[27]</ref>, (j) M+BM3D<ref type="bibr" target="#b13">[14]</ref> and (k) WESNR.</figDesc><graphic coords="10,62.03,322.97,116.90,116.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PSNR</head><label>I</label><figDesc>(dB) AND FSIM (%) RESULTS OF MIXED NOISE REMOVAL (AWGN + SPIN)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II PSNR</head><label>II</label><figDesc>(dB) AND FSIM (%) RESULTS OF MIXED NOISE REMOVAL (AWGN + RVIN + SPIN)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Table III lists the running time (second) of the four mixed AWGN+SPIN noise removal methods in processing the image Lena (size: 512 × 512)with different noise levels. It can be seen that the proposed WESNR method is much faster than the other three methods. In Table IV, we list the running time (second) of the four mixed AWGN+RVIN+SPIN noise removal methods. WESNR is much faster than ROR-NLM. It is not a surprise that TF runs faster than WESNR because it is basically a type of local nonlinear filtering method. M+BM3D runs the fastest because the BM3D algorithm is implemented by C but with a Matlab interface.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III RUNNING</head><label>III</label><figDesc>TIME (SECOND) COMPARISON ON IMAGE LENA WITH DIFFERENT LEVELS OF AWGN+SPIN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV RUNNING</head><label>IV</label><figDesc>TIME (SECOND) COMPARISON ON IMAGE LENA WITH DIFFERENT LEVELS OF AWGN+RVIN+SPIN</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the International Collaborative Research, The Hong Kong Polytechnic University, Hong Kong, under Grant G-YK79, in part by the National Science Fund for Distinguished Young Scholars under Grant 61125305, Grant 61233011, and Grant 61373063, in part by the Key Project of Chinese Ministry of Education under Grant 313030, in part by the 973 Program under Grant 2014CB349303, and in part by the Fundamental Research Funds for the Central Universities under Grant 30920140121005.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Nonlinear Digital Filters: Principles and Applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Venetsanopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The weighted median filter</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brownrigg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="807" to="818" />
			<date type="published" when="1984-08">Aug. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Center weighted median filters and their applications to image enhancement</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="984" to="993" />
			<date type="published" when="1991-09">Sep. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new class of detailpreserving filters for image processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nieminen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Heinonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Neuvo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="90" />
			<date type="published" when="1987-01">Jan. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detail-preserving median based filters in image processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Neuvo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="347" />
			<date type="published" when="1994-04">Apr. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive median filters: New algorithm and results</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Haddad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="499" to="502" />
			<date type="published" when="1995-04">Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tri-state median filter for image denosing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1834" to="1838" />
			<date type="published" when="1999-12">Dec. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive impulse detection using centerweighted median filters</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2001-01">Jan. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Selective removal of impulse noise based on homogeneity level information</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="92" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new directional weighted median filter for removal of random-valued impulse noise</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="196" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Universal impulse noise filter based on genetic programming</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Petrović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Crnojević</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1109" to="1120" />
			<date type="published" when="2008-07">Jul. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 6th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 6th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">K-SVD: An algorithm for designing of overcomplete dictionaries for sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4311" to="4322" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3D transform-domain collaborative filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A review of image denoising methods, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Two-stage image denoising by principal component analysis with local pixel grouping</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1531" to="1549" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with BM3D?</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>Int. Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sparsity-based image denoising via dictionary learning and structural clustering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>Int. Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denosing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FSIM: A feature similarity index for image quality assessment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2378" to="2386" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hybrid filter for the cancellation of mixed Gaussian noise and impulse noise</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. Int. Conf. Inf</title>
		<meeting>IEEE. Int. Conf. Inf</meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="508" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Restoration of images corrupted by impulse noise and mixed Gaussian impulse noise using blind inpainting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imag. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1227" to="1245" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new efficient approach for the removal of impulse noise from highly corrupted images</title>
		<author>
			<persName><forename type="first">E</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lightstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Arakawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1012" to="1025" />
			<date type="published" when="1996-06">Jun. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-level adaptive fuzzy filter for mixed noise removal</title>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lucke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Circuits Syst</title>
		<meeting>IEEE Int. Symp. Circuits Syst</meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
			<biblScope unit="page" from="1524" to="1527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Restoration of images corrupted by Gaussian and uniform impulsive noise</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lopez-Rubio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1835" to="1846" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A universal noise removal algorithm with an impulse detector</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huegerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1747" to="1754" />
			<date type="published" when="2005-11">Nov. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Switching bilateral filter with a texture/noise detector for universal noise removal</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2307" to="2320" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A fuzzy impulse noise detection and reduction method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nachtegael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Der Weken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Kerre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1153" to="1162" />
			<date type="published" when="2006-05">May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A universal denoising framework with a new impulse detector and nonlocal means</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1663" to="1675" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Two-phase methods for deblurring images corrupted by impulse plus Gaussian noise</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Problem Imag</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="204" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast two-phase image deblurring under impulse</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Image Vis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Restoration of images corrupted by mixed Gaussian-impulse noise via l 1 -l 0 minimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1708" to="1720" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mixed Gaussian-impulse noise image restoration via total variation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. Int. Conf. Acoust. Speech Signal Process</title>
		<meeting>IEEE. Int. Conf. Acoust. Speech Signal ess</meeting>
		<imprint>
			<date type="published" when="2012-03">Mar. 2012</date>
			<biblScope unit="page" from="1077" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wavelet frame based blind image inpainting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Harmonic Anal</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="268" to="279" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A weighted dictionary learning models for denoising images corrupted by mixed noise</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-C</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1108" to="1120" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On the role of sparse and redundant representations in image processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A T</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="972" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Regularized robust coding for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1753" to="1766" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Image deblurring and superresolution by adaptive sparse domain selection and adaptive regularization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1838" to="1857" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Iteratively re-weighted least squares minimization for sparse recovery</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Devore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fornasier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Gunturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robust regression: Asymptotics, conjectures and Monte Carlo</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="799" to="821" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A interiorpoint method for large-scale l 1 -regularized least squares</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gorinevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="606" to="617" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The split Bregman method for l 1 -regularized problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imag. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="343" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<title level="m">Robust Statistics</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
