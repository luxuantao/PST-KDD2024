<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Intelligent Optimal Control With Critic Learning for a Nonlinear Overhead Crane System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE, Haibo He, Senior Member, IEEE</roleName><forename type="first">Ding</forename><surname>Wang</surname></persName>
							<email>ding.wang@ia.ac.cn</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Derong</forename><surname>Liu</surname></persName>
							<email>derongliu@foxmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Automation</orgName>
								<orgName type="department" key="dep2">with the Beijing Engineering Research Center of In-telligent Systems and Technology</orgName>
								<orgName type="department" key="dep3">Institute of Automation</orgName>
								<orgName type="laboratory">The State Key Laboratory of Management and Control for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Electrical</orgName>
								<orgName type="department" key="dep2">Com-puter and Biomedical Engineering</orgName>
								<orgName type="institution">University of Rhode Island</orgName>
								<address>
									<postCode>02881</postCode>
									<settlement>Kingston</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Intelligent Optimal Control With Critic Learning for a Nonlinear Overhead Crane System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7BE1DA0F27DF7EEA289D09982B5C0582</idno>
					<idno type="DOI">10.1109/TII.2017.2771256</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2771256, IEEE Transactions on Industrial Informatics IEEE TRANSACTIONS 1 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2771256, IEEE Transactions on Industrial Informatics IEEE TRANSACTIONS 2</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adaptive dynamic programming</term>
					<term>artificial neural networks</term>
					<term>discounted optimal control</term>
					<term>intelligent control</term>
					<term>overhead crane</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, for achieving the discounted optimal feedback stabilization of a nonlinear overhead crane system, we establish an intelligent control strategy to obtain the solution of the corresponding Hamilton-Jacobi-Bellman equation. Specifically, neural networks are employed to serve as a necessary component to the control system, which exhibits strong online learning ability. A novel updating rule compared to the traditional adaptive critic algorithms is developed, which eliminates the requirement of the initial stabilizing controller and brings in unique advantages to the adaptive critic control design. Stability analysis of the closed-loop system based on the well-known Lyapunov approach and experimental simulation considering the nonlinear overhead dynamics with different case studies are performed to verify the effectiveness of the present control method both in theory and applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>N EURAL networks and fuzzy systems have been widely used in practical control engineering <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref>. In fact, they are often used as fundamental components of various computational intelligence techniques. For example, a novel approach was proposed in <ref type="bibr" target="#b5">[6]</ref> to achieve the output feedback control synthesis of fuzzy stochastic systems. The control and optimization of complex dynamics based on these techniques have been a long-standing topic of decision and control community <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref>. For example, the dynamics of overhead cranes incorporates complex nonlinearities and leads to a challenging control design task <ref type="bibr" target="#b10">[11]</ref>. Hence, the intelligent control design with optimality is beneficial to such a complex dynamical system. Nevertheless, for nonlinear systems including the overhead crane plant, it is often difficult to obtain the solution of the related Hamilton-Jacobi-Bellman equation. Though the optimal feedback design of general nonlinear systems is difficult, it is considerably important both in theory and in applications. Fortunately, a series of iterative methods have been established to tackle nonlinear optimal control problems <ref type="bibr" target="#b11">[12]</ref>. In particular, adaptive/approximate dynamic programming <ref type="bibr" target="#b12">[13]</ref> is regarded as an effective series of methods to develop optimal feedback controllers, where adaptive critic and neural networks are the basic framework and the function approximator, respectively. Among the recent results of adaptive/approximate dynamic programming, the adaptive-critic-based control applications are a significant aspect. This is reflected in the control of power systems <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, mechanical systems <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, and so on. Among them, the load frequency control of power systems and the trajectory tracking of air-breathing hypersonic vehicle were investigated by involving adaptive critic learning methods. Besides, a real-time event-driven adaptive critic controller was proposed in <ref type="bibr" target="#b0">[1]</ref> for acquiring near-optimal control actions and then achieving desired temperatures.</p><p>In the last two decades, adaptive/approximate dynamic programming has been promoted greatly in the field of adaptive optimal control for discrete-time systems <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b21">[22]</ref> as well as continuous-time systems <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b29">[30]</ref>. Dierks et al. <ref type="bibr" target="#b17">[18]</ref> and Wang et al. <ref type="bibr" target="#b18">[19]</ref> studied the optimal control problem of unknown affine and nonaffine nonlinear discrete-time systems with the help of neural network identification. Xiao et al. <ref type="bibr" target="#b21">[22]</ref> addressed the optimal tracking control problem for affine nonlinear continuous-time systems with completely unknown dynamics by using the reinforcement learning technique. Liu et al. <ref type="bibr" target="#b23">[24]</ref> developed an online learning algorithm based on policy iteration to solve the discounted optimal control problem of continuous-time nonlinear systems. Modares and Lewis <ref type="bibr" target="#b24">[25]</ref> studied discounted optimal tracking control of partially-unknown nonlinear systems with input constraints based on integral reinforcement learning. Jiang and Jiang <ref type="bibr" target="#b28">[29]</ref> originally constructed the framework of global adaptive dynamic programming for continuous-time nonlinear systems. In addition, the decentralized optimal control of large-scale linear systems was also studied with the idea of adaptive critic designs <ref type="bibr" target="#b29">[30]</ref>. As for the recent results, Gao and Jiang <ref type="bibr" target="#b30">[31]</ref> carried out the optimal output regulation of linear systems under the framework of adaptive critic learning. Wang et al. <ref type="bibr" target="#b31">[32]</ref> developed an event-based adaptive robust control scheme with suitable triggering conditions for a class of continuoustime nonlinear systems with uncertainties via neural dynamic programming.</p><p>However, the adaptive critic method normally includes the procedure of selecting an initial stabilizing controller <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Note that it is always difficult to obtain that kind of controllers in practical applications. In particular, for continuous-time discounted optimal control, this initial condition is also required <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Remarkably, in <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref>, a piecewise function is introduced to relax the aforementioned initial condition and also help to check the system stability. However, the theoretical analysis related to the closed-loop system is complicated so that it is not easy to implement, which motivates our research. As a result, in this paper, we focus on developing an online discounted near-optimal control method with applications to an overhead crane system via an improved neural learning mechanism. The main contribution lies in that it brings in a reinforced but simple component, so as to enhance the traditional critic learning ability, and realize the online optimal regulation as well as control engineering applications. Overall, the novel design method of intelligent discounted optimal control is developed, where the overhead crane system is regarded as a case study of industrial applications. The rest of this paper is structured as follows. The dynamical model of the overhead crane system and the general discounted optimal control problem are described in Section II. The intelligent near-optimal control method is developed with stability analysis and is applied to the present overhead crane system in Section III. The concluding remark is presented in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MAIN CONTROL PROBLEM STATEMENT</head><p>In this section, we first model a typical overhead crane plant and then describe the discounted optimal control problem of general nonlinear systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overhead Crane Dynamics Description</head><p>The feedback control design of overhead traveling cranes has attracted much attention among control engineers. In transport industry, overhead cranes are often employed to transfer cargoes as quickly and safely as possible within a pre-specified time to attain high transportation efficiency. In general, an overhead crane plant is composed of a trolley, a load, and a rope. The simple configuration of a typical overhead crane plant is exhibited in Fig. <ref type="figure" target="#fig_2">1</ref>. The main parameters used here are listed as follows.</p><p>• M t : the total mass of the trolley (unit: kg)</p><p>• M l : the mass of the load (unit: kg)</p><p>• L: the length of the rope (unit: m) • G: the gravitational acceleration (unit: m/s 2 )</p><p>• θ: the swing angle of the load with respect to vertical line • χ: the trolley position with respect to the origin <ref type="figure" target="#fig_2">1</ref>. Configuration of an overhead crane system.</p><formula xml:id="formula_0">¡ θ ¢ £ ¤ ¥ ¦ χ § ¨© © Fig.</formula><p>• u: the driving force applied to the trolley Using these parameters and based on <ref type="bibr" target="#b10">[11]</ref>, the dynamical model of the proposed overhead crane plant can be formulated as follows:</p><formula xml:id="formula_1">(M t + M l ) χ + M l L θ cos(θ) -θ2 sin(θ) = u, (<label>1a</label></formula><formula xml:id="formula_2">)</formula><formula xml:id="formula_3">M l χ cos(θ) + M l L θ = -M l G sin(θ).<label>(1b)</label></formula><p>Then, in order to obtain the state space expression of (1), we denote u as the control variable and let x = [x 1 , x 2 , x 3 , x 4 ] T be the system state, where x 1 = χ, x 2 is the trolley velocity, x 3 = θ, x 4 is the angular velocity of the load, and the superscript "T" is the transpose operation. As a result, the dynamics (1) can be rewritten as <ref type="bibr" target="#b1">(2)</ref>, placed at the bottom of this page. Note that (2) is a nonlinear plant with 4-dimensional state vector and 1-dimensional control vector. In the sequel, we consider a class of general nonlinear systems structured as <ref type="bibr" target="#b1">(2)</ref>, investigate the corresponding discounted optimal control design, and then conduct experimental simulation to the present overhead crane plant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Nonlinear Discounted Optimal Control</head><p>We first list the main notations used in what follows. R stands for the set of all real numbers. R n is the Euclidean space of all n-dimensional real vectors. R n×m is the space of all n×m real matrices. • denotes the vector norm of a vector in R n or the matrix norm of a matrix in R n×m . I n represents the n × n identity matrix. λ max (•) and λ min (•) are used to denote the maximal and minimal eigenvalues of a matrix, respectively.</p><p>Let Ω be a compact subset of R n , Ω u be a compact subset of R m , and A (Ω) be the set of admissible controllers on Ω.</p><formula xml:id="formula_4">   ẋ1 ẋ2 ẋ3 ẋ4    =         x 2 M l Lx 2 4 sin(x 3 ) + M l G sin(x 3 ) cos(x 3 ) M t + M l sin 2 (x 3 ) x 4 - (M t + M l )G sin(x 3 ) + M l Lx 2 4 sin(x 3 ) cos(x 3 ) M t + M l sin 2 (x 3 ) L         +        0 1 M t + M l sin 2 (x 3 ) 0 - cos(x 3 ) M t + M l sin 2 (x 3 ) L        u.</formula><p>(</p><formula xml:id="formula_5">)<label>2</label></formula><p>The symbol ∇(•) ∂(•)/∂x is utilized to denote the gradient operator.</p><p>For providing a general statement, we consider a class of nonlinear continuous-time systems formed as follows:</p><formula xml:id="formula_6">ẋ(t) = f (x(t)) + g(x(t))u(t),<label>(3)</label></formula><p>where</p><formula xml:id="formula_7">x(t) ∈ Ω ⊂ R n is the state variable, u(t) ∈ Ω u ⊂ R m is</formula><p>the control variable, and f (•) and g(•) are differentiable in the arguments satisfying f (0) = 0. Clearly, the nonlinear plant (2) falls within the category of system (3) with n = 4 and m = 1.</p><p>We let the initial state at t = 0 be x(0) = x 0 and x = 0 be the equilibrium point of the controlled plant. Like most of the literature of this kind, the nonlinear plant ( <ref type="formula" target="#formula_6">3</ref>) is assumed to be controllable.</p><p>For designing an infinite horizon optimal feedback control law u(x), we let</p><formula xml:id="formula_8">U (x(t), u(t)) = x T (t)Qx(t) + u T (t)Ru(t)</formula><p>represent the utility function, where Q ∈ R n×n , R ∈ R m×m are positive definite matrices, and then define the discounted cost function as <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b34">[35]</ref> </p><formula xml:id="formula_9">J(x(t), u) = ∞ t e -γ(τ -t) U (x(τ ), u(τ ))dτ,<label>(4)</label></formula><p>where γ ≥ 0 is a discount factor. The discount term e -γ(τ -t) has the same function as in discounted optimal control of discrete-time case <ref type="bibr" target="#b18">[19]</ref>. Practically, it is required to further guarantee the boundedness of the cost function. Note that when γ = 0, it becomes an undiscounted optimal control problem as usually discussed in <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b31">[32]</ref>.</p><p>In this paper, the cost function J(x(t), u) is simply denoted as J(x(t)) or J(x). Besides, the cost function from t = 0 is J(x(0)) = J(x 0 ). For an admissible control law u(x) ∈ A (Ω), if the related cost function ( <ref type="formula" target="#formula_9">4</ref>) is continuously differentiable, we can separate it into two integral parts by introducing a time instant t + T as follows:</p><formula xml:id="formula_10">J(x(t)) = t+T t e -γ(τ -t) U (x(τ ), u(τ ))dτ + ∞ t+T e -γ(τ -t) U (x(τ ), u(τ ))dτ = t+T t e -γ(τ -t) U (x(τ ), u(τ ))dτ + e -γT J(x(t + T )).<label>(5)</label></formula><p>Note that (5) can be rewritten as</p><formula xml:id="formula_11">t+T t e -γ(τ -t) U (x(τ ), u(τ ))dτ Part I + (e -γT -1)J(x(t + T )) Part II + J(x(t + T )) -J(x(t)) Part III = 0.<label>(6)</label></formula><p>Dividing ( <ref type="formula" target="#formula_11">6</ref>) by T and applying the limit operation to the three parts simultaneously, we further obtain</p><formula xml:id="formula_12">lim T →0 1 T t+T t e -γ(τ -t) U (x(τ ), u(τ ))dτ + lim T →0 1 T [(e -γT -1)J(x(t + T ))] + lim T →0 1 T [J(x(t + T )) -J(x(t))] = 0, which implies that U (x, u) -γJ(x) + J(x) = 0.<label>(7)</label></formula><p>Since J(x) = (∇J(x)) T ẋ, the infinitesimal version (7) of the discounted cost function ( <ref type="formula" target="#formula_9">4</ref>) is the nonlinear Lyapunov equation formulated as</p><formula xml:id="formula_13">0 = U (x, u(x)) -γJ(x) + (∇J(x)) T [f (x) + g(x)u(x)]</formula><p>with J(0) = 0. Similar to <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b34">[35]</ref>, we define the modified Hamiltonian of system (3) as</p><formula xml:id="formula_14">H(x, u(x), ∇J(x)) = U (x, u(x)) -γJ(x) + (∇J(x)) T [f (x) + g(x)u(x)].</formula><p>Using optimal control theory and based on <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b31">[32]</ref>, the optimal cost function J * (x) = min u∈A (Ω) J(x(t), u) guarantees that the Hamilton-Jacobi-Bellman equation</p><formula xml:id="formula_15">min u∈A (Ω) H(x, u(x), ∇J * (x)) = 0</formula><p>holds. Besides, the optimal feedback control law can be derived by</p><formula xml:id="formula_16">u * (x) = arg min u∈A (Ω) H(x, u(x), ∇J * (x)) = - 1 2 R -1 g T (x)∇J * (x).<label>(8)</label></formula><p>Using the formula (8), the Hamilton-Jacobi-Bellman equation of the discounted optimal control problem is actually</p><formula xml:id="formula_17">0 = U (x, u * (x)) -γJ * (x) + (∇J * (x)) T [f (x)+g(x)u * (x)], J * (0) = 0.</formula><p>Clearly, this means that H(x, u * (x), ∇J * (x)) = 0, which is difficult to solve in theory. Next, we focus on how to approximate the optimal control law (8) using an intelligent component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DESIGN, ANALYSIS, AND VERIFICATION OF ONLINE</head><p>INTELLIGENT OPTIMAL FEEDBACK CONTROL By introducing a component with intelligent learning ability, the adaptive-critic-based design is regarded as an important method to get approximate optimal control laws with nonlinear dynamics <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Therein, artificial neural networks are often taken to serve as a necessary intelligence complement to the control system. The primary design method, theoretical stability analysis, and experimental simulation verification are included in this section. In other words, it provides an entire process of design, analysis, and verification of the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Primary Design Method</head><p>We first design the neural-network-based online nearoptimal controller. Using the universal approximation property of neural networks, the optimal cost function J * (x) can be formulated as the following form:</p><formula xml:id="formula_18">J * (x) = ω T c σ c (x) + ε c (x),<label>(9)</label></formula><p>where ω c ∈ R lc is the ideal weight vector, l c is the number of hidden neurons, σ c (x) ∈ R lc is the activation function, and ε c (x) ∈ R is the reconstruction error. Then, we derive</p><formula xml:id="formula_19">∇J * (x) = (∇σ c (x)) T ω c + ∇ε c (x).</formula><p>Since the ideal weight vector is unavailable in advance, a critic network is constructed with output being</p><formula xml:id="formula_20">Ĵ * (x) = ωT c σ c (x),<label>(10)</label></formula><p>where ωc ∈ R lc denotes the estimated weight vector. The gradient vector of the approximate optimal cost is</p><formula xml:id="formula_21">∇ Ĵ * (x) = (∇σ c (x)) T ωc .</formula><p>Considering the feedback control function ( <ref type="formula" target="#formula_16">8</ref>) and the neural network formulation ( <ref type="formula" target="#formula_18">9</ref>), the optimal controller can be rewritten as</p><formula xml:id="formula_22">u * (x) = - 1 2 R -1 g T (x) (∇σ c (x)) T ω c + ∇ε c (x) . (<label>11</label></formula><formula xml:id="formula_23">)</formula><p>Based on the critic neural network <ref type="bibr" target="#b9">(10)</ref>, the approximate optimal feedback controller is</p><formula xml:id="formula_24">û * (x) = - 1 2 R -1 g T (x)(∇σ c (x)) T ωc . (<label>12</label></formula><formula xml:id="formula_25">)</formula><p>Using the aforementioned neural network expression, the approximate modified Hamiltonian is written as</p><formula xml:id="formula_26">Ĥ(x, û * (x), ∇ Ĵ * (x)) = U (x, û * (x)) -γ ωT c σ c (x) + ωT c ∇σ c (x)[f (x) + g(x)û * (x)].</formula><p>Since H(x, u * (x), ∇J * (x)) = 0, we easily obtain that the training error is e c = Ĥ(x, û * (x), ∇ Ĵ * (x)). Clearly, we derive that the partial derivative of the training error e c with respect to the approximate weight vector is</p><formula xml:id="formula_27">∂e c ∂ ωc = -γσ c (x) + ∇σ c (x)[f (x) + g(x)û * (x)] φ, (<label>13</label></formula><formula xml:id="formula_28">)</formula><p>where φ ∈ R lc is an l c -dimensional vector. Based on the result of <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, we find that the set {φ 1 , φ 2 , . . . , φ lc } is linearly independent, where φ 1 , φ 2 , . . . , φ lc are the elements of the vector φ. Clearly, if we remove the discount factor, this partial derivative becomes ∇σ c (x)[f (x) + g(x)û * (x)] as given in <ref type="bibr" target="#b22">[23]</ref>, which is just a special case of (13). Compared with <ref type="bibr" target="#b22">[23]</ref>, we find that the discount factor is possible to influence the weight training process due to the addition of the term -γσ c (x).</p><p>Now, we turn to train the critic network and design the weight vector ωc to minimize the objective function E c = 0.5e 2 c . Using (13), we traditionally employ</p><formula xml:id="formula_29">ω(1) c = -α c 1 (1 + φ T φ) 2 ∂E c ∂ ωc = -α c φ (1 + φ T φ) 2 e c (<label>14</label></formula><formula xml:id="formula_30">)</formula><p>to adjust the weight of the network, where α c &gt; 0 is the learning rate parameter and (1 + φ T φ) 2 is adopted for normalization. Nevertheless, we should choose an initial stabilizing controller and this is often a difficult task. This motivates us to give effort to relax the initial condition. Inspired by <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref>, we introduce an additional stabilizing term to improve the critic learning mechanism and adopt it to reinforce the critic weight updating. Similar to <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, we present the following assumption. Assumption 1: Consider system (3) with the discounted cost function ( <ref type="formula" target="#formula_9">4</ref>) and the closed-loop system under the action of the optimal feedback control (11). Let J s (x) be a continuously differentiable Lyapunov function candidate satisfying</p><formula xml:id="formula_31">Js (x) = (∇J s (x)) T [f (x) + g(x)u * (x)] &lt; 0.</formula><p>Then, there exists a positive definite matrix Λ ∈ R n×n such that the following inequality holds:</p><formula xml:id="formula_32">(∇J s (x)) T [f (x) + g(x)u * (x)] = -(∇J s (x)) T Λ∇J s (x) ≤ -λ min (Λ) ∇J s (x) 2 .</formula><p>When implementing the control algorithm, J s (x) is often selected as a polynomial of the state vector, such as J s (x) = 0.5x T x.</p><p>Considering the stability guarantee, if we apply the approximate optimal controller <ref type="bibr" target="#b11">(12)</ref> to the nonlinear plant, the case</p><formula xml:id="formula_33">(∇J s (x)) T [f (x) + g(x)û * (x)] &gt; 0</formula><p>should be avoided. Hence, we enhance the learning performance by introducing an extra term, which modulates the time derivative of J s (x) as follows:</p><formula xml:id="formula_34">ω(2) c = -α s ∂ (∇J s (x)) T (f (x) + g(x)û * (x)) ∂ ωc = -α s ∂ û * (x) ∂ ωc T ∂ (∇J s (x)) T (f (x) + g(x)û * (x)) ∂ û * (x) = 1 2 α s ∇σ c (x)g(x)R -1 g T (x)∇J s (x),<label>(15)</label></formula><p>where α s &gt; 0 is also a learning rate parameter. By adding the reinforced term <ref type="bibr" target="#b14">(15)</ref> to the traditional rule ( <ref type="formula" target="#formula_29">14</ref>), we establish the improved critic learning algorithm as follows:</p><formula xml:id="formula_35">ωc = ω(1) c + ω(2) c = -α c φ (1 + φ T φ) 2 e c + 1 2 α s ∇σ c (x)g(x)R -1 g T (x)∇J s (x),<label>(16)</label></formula><p>which reflects an improvement compared with <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b31">[32]</ref>.</p><p>Remark 1: During the general adaptive-critic-based optimal control design without using the new neural learning mechanism, we should choose an initial stabilizing control law to start the learning process. However, it is often not easy to achieve this purpose in many situations. The new updating rule used in this paper can avoid the necessity of finding the initial stabilizing controller. Hence, in such circumstance, the critic weight vector can be simply chosen as zero initially during implementation.</p><p>As the end of this part, we present the simple structural diagram of the adaptive critic control implementation to clarify the design procedure. The structure is shown in Fig. <ref type="figure" target="#fig_0">2</ref>. </p><formula xml:id="formula_36">¡ ¢£¤ ¡¥ ¦ §¢¨£© ¡ ¢ ¡ ¢£¤ ¡¥¥ £ ¤©£©¢ £ ¡ ¤ ! " # $ %&amp;&amp; ¤ ¡ '©(£ ) (© ¥ £ ¡ ¢©(¢</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Stability Analysis</head><p>We next build the critic error dynamics and study its stability. Denote the error between the ideal weight and the estimated one as ωc = ω c -ωc . Then, we obtain ωc = -ωc . For convenience of analysis, we use the following two variables:</p><formula xml:id="formula_37">φ 1 = φ 1 + φ T φ , φ 2 = 1 + φ T φ</formula><p>with φ 1 ∈ R lc and φ 2 ≥ 1. Then, by employing the tuning rule <ref type="bibr" target="#b15">(16)</ref>, we obtain the critic error dynamics which is expressed as</p><formula xml:id="formula_38">ωc = -α c φ 1 φ T 1 ωc + α c φ 1 φ 2 e cH - 1 2 α s ∇σ c (x)g(x)R -1 g T (x)∇J s (x),<label>(17)</label></formula><p>where</p><formula xml:id="formula_39">e cH = -(∇ε c (x)) T [f (x) + g(x)û * (x)]</formula><p>is the residual error of neural network approximation. As a special case of adaptive control, we should mention that for such adaptive critic designs, the persistence of excitation assumption is still needed. Note that based on <ref type="bibr" target="#b22">[23]</ref>, the persistence of excitation condition guarantees that λ min (φ 1 φ T 1 ) &gt; 0, which is useful to study stability.</p><p>Assumption 2: The control function matrix g(x) is upper bounded such that g(x) ≤ λ g , where λ g is a positive constant. On the compact set Ω, the terms ∇σ c (x), ∇ε c (x), and e cH are all upper bounded such that ∇σ c (x) ≤ λ σ , ∇ε c (x) ≤ λ ε , and |e cH | ≤ λ e , where λ σ , λ ε , and λ e are positive constants.</p><p>Remark 2: For analyzing the system stability, the above assumption is provided, as often used in the literature <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. In addition, the boundedness of the related parameters, such as the control matrix, is easy to guarantee according to the initial condition setting. Hence, it is a practical and reasonable assumption that has been commonly used.</p><p>Theorem 1: For the nonlinear system (3), we suppose that Assumptions 1 and 2 hold. The near-optimal control law is computed by <ref type="bibr" target="#b11">(12)</ref>, where the proposed critic network is updated by <ref type="bibr" target="#b15">(16)</ref>. Then, the critic weight estimation error ωc and the gradient vector ∇J s (x) are uniformly ultimately bounded by</p><formula xml:id="formula_40">2δ (2α c -1)λ min (φ 1 φ T 1 ) -2λ 2 g λ 2 σ C ω and 1 4λ min (Λ) λ 2 g λ ε β + δ α s λ min (Λ) C Js ,</formula><p>respectively, where C ω and C Jsx are positive constants, β = R -1 &gt; 0, and</p><formula xml:id="formula_41">δ = λ 2 g λ 2 ε + 1 2 α 2 c λ 2 e + 1 16λ min (Λ) α s λ 4 g λ 2 ε β 2 .</formula><p>Furthermore, the closed-loop system state x is also uniformly ultimately bounded.</p><p>Proof: Choose a Lyapunov function candidate consisting of a weight-related term and a state-related term as</p><formula xml:id="formula_42">L c (t) = L c1 (t) + L c2 (t) = 1 2 ωT c (t)ω c (t) + α s J s (x(t)).</formula><p>Computing the time derivative of the above Lyapunov function and according to <ref type="bibr" target="#b16">(17)</ref>, we have</p><formula xml:id="formula_43">Lc1 (t) = -α c ωT c φ 1 φ T 1 ωc + α c ωT c φ 1 φ 2 e cH - 1 2 α s ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x). (<label>18</label></formula><formula xml:id="formula_44">)</formula><p>The derivative Lc2 (t) can be written as</p><formula xml:id="formula_45">Lc2 (t) = α s (∇J s (x)) T [f (x) + g(x)û * (x)].<label>(19)</label></formula><p>Considering <ref type="bibr" target="#b17">(18)</ref>, we adopt the Young's inequality, employ the Assumption 2, and further obtain</p><formula xml:id="formula_46">Lc1 (t) ≤ -α c - 1 2 λ min (φ 1 φ T 1 ) ωc 2 + 1 2 α 2 c λ 2 e - 1 2 α s ωT c ∇σ c (x)g(x)R -1 g T (x)∇J s (x). (<label>20</label></formula><formula xml:id="formula_47">)</formula><p>Substituting ωc = ω c -ωc to the last term of ( <ref type="formula" target="#formula_46">20</ref>) and combining with <ref type="bibr" target="#b18">(19)</ref>, we can obtain the overall time derivative as the form</p><formula xml:id="formula_48">Lc (t) ≤ -α c - 1 2 λ min (φ 1 φ T 1 ) -λ 2 g λ 2 σ ωc 2 + λ 2 g λ 2 ε + 1 2 α 2 c λ 2 e + α s (∇J s (x)) T f (x) - 1 2 α s (∇J s (x)) T g(x)R -1 g T (x)(∇σ c (x)) T ω c . (<label>21</label></formula><formula xml:id="formula_49">)</formula><p>Based on the optimal control law <ref type="bibr" target="#b10">(11)</ref>, we find that ( <ref type="formula" target="#formula_48">21</ref>) can be rewritten as</p><formula xml:id="formula_50">Lc (t) ≤ -α c - 1 2 λ min (φ 1 φ T 1 ) -λ 2 g λ 2 σ ωc 2 + λ 2 g λ 2 ε + 1 2 α 2 c λ 2 e + α s (∇J s (x)) T [f (x) + g(x)u * (x)] + 1 2 α s (∇J s (x)) T g(x)R -1 g T (x)∇ε c (x). (<label>22</label></formula><formula xml:id="formula_51">)</formula><p>Recalling Assumptions 1 and 2, it follows from <ref type="bibr" target="#b21">(22)</ref> that</p><formula xml:id="formula_52">Lc (t) ≤ -α c - 1 2 λ min (φ 1 φ T 1 ) -λ 2 g λ 2 σ ωc 2 + λ 2 g λ 2 ε + 1 2 α 2 c λ 2 e -α s λ min (Λ) ∇J s (x) 2 + 1 2 α s λ 2 g λ ε β ∇J s (x) ,</formula><p>which can be reformulated as</p><formula xml:id="formula_53">Lc (t) ≤ -α c - 1 2 λ min (φ 1 φ T 1 ) -λ 2 g λ 2 σ ωc 2 + δ -α s λ min (Λ) ∇J s (x) - 1 4λ min (Λ) λ 2 g λ ε β 2 .</formula><p>Hence, we conclude that, if ωc or ∇J s (x) lies outside the compact sets</p><formula xml:id="formula_54">ωc : ωc ≤ C ω , ∇J s (x) : ∇J s (x) ≤ C Js ,</formula><p>the inequality Lc (t) &lt; 0 holds. Then, ωc ≤ C ω and ∇J s (x) ≤ C Js are true in the sense of uniform ultimate boundedness. Since J s (x) is chosen as a polynomial and because of the standard Lyapunov extension theorem <ref type="bibr" target="#b34">[35]</ref>, we finally obtain that the state vector x and the weight error ωc are uniformly ultimately bounded. This ends the proof.</p><p>Theorem 2: For the nonlinear system (3), the near-optimal control û * (x) converges to a neighborhood of the optimal function u * (x) with a finite bound</p><formula xml:id="formula_55">1 2 βλ g (λ σ C ω + λ ε ) C u ,</formula><p>where C u is a positive constant.</p><p>Proof: Based on Theorem 1, the weight error of the critic network, i.e., ωc , is upper bounded by a finite constant as ωc ≤ C ω . Then, according to <ref type="bibr" target="#b10">(11)</ref> and <ref type="bibr" target="#b11">(12)</ref>, we can find that</p><formula xml:id="formula_56">u * (x) -û * (x) = 1 2 R -1 g T (x) (∇σ c (x)) T ωc + ∇ε c (x) ≤ 1 2 β g(x) ∇σ c (x) ωc + ∇ε c (x) ≤ C u ,</formula><p>which ends the proof. By modifying the involved parameters, the bound can be set to an adequate level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental Simulation Verification</head><p>Finally, we experiment on the proposed overhead crane system <ref type="bibr" target="#b1">(2)</ref>, in order to illustrate the effectiveness of the present control method. For purpose of simulation, we specifically set M t = 1.1kg, M l = 0.9kg, L = 0.3m and choose G = 9.8m/s 2 . Considering the cost function from t = 0, the modified utility function can be written as e -γt U (x, u) = e -γt (x T Qx + u T Ru) with Q = 1.2I 4 , R = 0.8I. The initial state vector is chosen as x 0 = [2, 0, 0, 0] T . In what follows, we perform the near-optimal control design based on adaptive critic learning.</p><p>In view of the theoretical result, the proposed critic neural network is built as follows:</p><formula xml:id="formula_57">Ĵ * (x) = ωc1 x 2 1 + ωc2 x 1 x 2 + ωc3 x 1 x 3 + ωc4 x 1 x 4 + ωc5 x 2 2 + ωc6 x 2 x 3 + ωc7 x 2 x 4 + ωc8 x 2 3 + ωc9 x 3 x 4 + ωc10 x 2 4 .</formula><p>During the simulation, we set the learning rate parameters as α c = 3.5 to perform a quick convergence, choose J s (x) = 0.5x T x with α s = 0.03 to ensure stability, and employ a probing noise composed of some sine and cosine functions to guarantee the persistence of excitation condition. Next, we verify the effect of the discount factor by conducting three case studies. Case 1. We first consider the situation that there is no discount factor, i.e., γ = 0. This is in fact a traditionally undiscounted optimal control design process like existing ones in the literature. Through a sufficient learning process, the weight gradually converges to compute the near-optimal controller by using</p><formula xml:id="formula_58">û * (x) = - 5 8            0 1 1.1 + 0.9 sin 2 (x 3 ) 0 - cos(x 3 ) 0.33 + 0.27 sin 2 (x 3 )            T             ∂ Ĵ * (x) ∂x 1 ∂ Ĵ * (x) ∂x 2 ∂ Ĵ * (x) ∂x 3 ∂ Ĵ * (x) ∂x 4            </formula><p>, where ∂ Ĵ * (x)/∂x 1 = 2ω c1 x 1 + ωc2 x 2 + ωc3 x 3 + ωc4 x 4 is a polynomial with respect to the converged weight elements and the same for the others. Then, the performance of near-optimal feedback stabilization is verified by applying the derived control law to the nonlinear system (2) for t = 20s. Via simulation, the system trajectory is depicted in Fig. <ref type="figure">5</ref>(a) while the control curve is presented in Fig. <ref type="figure">5(b)</ref>. Hence, with the action of the obtained control law, the state vector is driven to zero as time goes on, which shows a good stabilization performance.</p><p>Case 2. We activate the discount factor by setting γ &gt; 0 to study a discounted nonlinear optimal control design. Here, we select γ = 0.25 and run the adaptive critic algorithm. The weight vector converges to  Then, we adopt the corresponding near-optimal controller û * (x) to regulate the nonlinear system (2) for t = 20s and obtain the state and control trajectories are depicted in Figs. Case 3. We continue to increase the discount factor to γ = 0.5 and then run the online algorithm again. In such a situation, the weight vector converges to    Finally, we apply the derived control law to the nonlinear system (2) for t = 20s again and derive that the state and control trajectories are shown in Figs. 9(a) and 9(b), respectively. Considering Figs. 5(a), 7(a), and 9(a), we can find that the oscillation of the state response becomes more and more relaxed. The same result can be obtained when comparing the control responses in Figs. 5(b), 7(b), and 9(b). In addition, the approximate optimal cost Ĵ * (x 0 ) of the above three cases based on the derived controllers are exhibited in Table <ref type="table" target="#tab_0">I</ref>. An obvious reduction of the cost function can be observed when increasing the discount factor. Therefore, we can reach the conclusion that the discount factor γ has a noticeable impact on the performance of the online near-optimal control design. All in all, it is verified that the nonlinear near-optimal control scheme is effective to apply to the practical overhead crane system. This completes the experimental verification of the proposed control method.</p><p>IV. CONCLUSION In this paper, we develop an intelligent near-optimal control scheme and also apply it to deal with the nonlinear overhead crane control problem. The developed learning rule does not need the initial stabilizing controller and brings in a great convenience to the adaptive control implementation. It is also shown that the present approximate optimal controller can achieve uniform ultimate boundedness of the closed-loop state. The experimental simulation with three different case studies via the overhead crane plant is also included to verify the control performance. In the future work, the robustness of the developed discounted optimal control strategy should be studied due to the wide existence of dynamical uncertainties. In this sense, the robust optimal control with neural intelligence may be constructed by incorporating the discount term e -γ(τ -t) and performing more meaningful and practical applications. In addition, other modern control approaches, like the advanced sliding-mode control method of <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, should be paid special attention to find more meaningful combinations with adaptive critic strategies. Then, the intelligence feature of adaptive critic designs can be more effectively employed to improve the performance of sliding-mode control and others traditional approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Structural diagram of the proposed control implementation. The solid line represents the signal flow while the dashed line represents the backpropagating path).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>[ 2 .Fig. 3 .Fig. 4 .</head><label>234</label><figDesc>Fig. 3. (a) Convergence of the weight vector when γ = 0 (Part I, including ωc1 , ωc2 , ωc3 , ωc4 , ωc5 ). (b) Convergence of the weight vector when γ = 0 (Part II, including ωc6 , ωc7 , ωc8 , ωc9 , ωc10 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>[ 1 .</head><label>1</label><figDesc>9616, 2.9729, -0.0436, 0.3854, 3.0738, 0.0475, 0.7336, 0.0255, -0.1785, 0.1228] T , which is shown in Figs. 6(a) and 6(b). All the weight elements have been converged at t = 450s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. (a) System state trajectory when γ = 0 (including x 1 , x 2 , x 3 , x 4 ). (b) Control input curve when γ = 0 (that is u).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>and 7(b), respectively. These figures display the good stabilization performance. Actually, when comparing Figs. 5(a) with 7(a) and Figs. 5(b) with 7(b), we find that the nonlinear control performance has been improved somewhat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>[ 1 .</head><label>1</label><figDesc>5748, 2.3014, -0.0957, 0.3051, 2.5432, 0.0444, 0.6151, 0.0342, -0.0983, 0.1238] T , as depicted in Figs. 8(a) and 8(b). Clearly, the convergence results of the two discounted cases, including Figs. 6(a), 6(b), 8(a), and 8(b) are not the same as the undiscounted case, i.e., Figs. 3(a) and 3(b). Then, we come to the conclusion that increasing the discount factor can indeed affect the convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. (a) System state trajectory when γ = 0.25 (including x 1 , x 2 , x 3 , x 4 ). (b) Control input curve when γ = 0.25 (that is u).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. (a) Convergence of the weight vector when γ = 0.5 (Part I, including ωc1 , ωc2 , ωc3 , ωc4 , ωc5 ). (b) Convergence of the weight vector when γ = 0.5 (Part II, including ωc6 , ωc7 , ωc8 , ωc9 , ωc10 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. (a) System state trajectory when γ = 0.5 (including x 1 , x 2 , x 3 , x 4 ). (b) Control input curve when γ = 0.5 (that is u).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>THE COST PERFORMANCE Ĵ * (x 0 ) VERSUS THE DISCOUNT FACTOR γ</figDesc><table><row><cell>γ</cell><cell>0</cell><cell>0.25</cell><cell>0.5</cell></row><row><cell>Ĵ *  (x0)</cell><cell>8.5996</cell><cell>7.8464</cell><cell>6.2992</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1551-3203 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2771256, IEEE Transactions on Industrial Informatics IEEE TRANSACTIONS</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grants 61773373, U1501251, 61533017, 51529701, 61520106009, and 61233001, in part by Beijing Natural Science Foundation under Grant 4162065, in part by the U.S. National Science Foundation under Grant ECCS 1053717, and in part by the Early Career Development Award of SKLMCCS.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive critic based eventtriggered control for HVAC system</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Behera</surname></persName>
		</author>
		<idno type="DOI">10.1109/TII.2017.2725899</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Vibration control of a flexible robotic manipulator in the presence of input deadzone</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A data-based state feedback control method for a class of nonlinear systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2284" to="2292" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive fuzzy controller of the overhead cranes with nonlinear disturbance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="164" to="172" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Leader-based optimal coordination control for the consensus problem of multiagent differential games via fuzzy adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="152" to="163" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A novel approach to output feedback control of fuzzy stochastic systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3268" to="3275" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Containment control of multi-agent systems with dynamic leaders based on a P I ntype approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3004" to="3017" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust adaptive neural control of flexible hypersonic flight vehicle with dead-zone input nonlinearity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nonlinear Dynamics</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1509" to="1520" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural controller designbased adaptive control for nonlinear MIMO systems with unknown hysteresis inputs</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="19" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Intelligent critic control with disturbance attenuation for affine dynamics including an application to a micro-grid system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4935" to="4944" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Control of overhead crane systems by combining sliding mode with fuzzy regulator</title>
		<author>
			<persName><forename type="first">D</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of World Congress of The International Federation of Automatic Control</title>
		<meeting>World Congress of The International Federation of Automatic Control<address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-08">Aug. 2011</date>
			<biblScope unit="page" from="9320" to="9325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Adaptive Dynamic Programming for Control: Algorithms and Stability</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Approximate dynamic programming for real-time control and neural modeling</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Intelligent Control: Neural, Fuzzy, and Adaptive Approaches</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>White</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sofge</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Van Nostrand Reinhold</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>ch. 13</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Event-driven nonlinear discounted optimal regulation involving a power system application</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="8177" to="8186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved sliding mode design for load frequency control of power system integrated an adaptive learning strategy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="6742" to="6751" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Air-breathing hypersonic vehicle tracking control based on adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="584" to="598" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adaptive critic nonlinear robust control: A survey</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3429" to="3451" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimal control of unknown affine nonlinear discrete-time systems using offline-trained neural networks with proof of convergence</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dierks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Thumati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="851" to="860" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimal control of unknown nonaffine nonlinear discrete-time systems based on adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1825" to="1832" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finite-horizon control-constrained nonlinear optimal control using single network adaptive critics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heydari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="157" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural network-based finitehorizon optimal control of uncertain affine nonlinear discrete-time systems</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="486" to="499" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Data-driven optimal tracking control for a class of affine non-linear continuous-time systems with completely unknown dynamics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="700" to="710" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online actor-critic algorithm to solve the continuous-time infinite horizon optimal control problem</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="878" to="888" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive optimal control for a class of continuous-time affine nonlinear systems with unknown internal dynamics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7-8</biblScope>
			<biblScope unit="page" from="1843" to="1850" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimal tracking control of nonlinear partially-unknown constrained-input systems using integral reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Modares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1780" to="1792" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Online adaptive approximate optimal tracking control with simplified dual approximation structure for continuous-time unknown nonlinear systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Herrmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA Journal of Automatica Sinica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="412" to="422" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Developing nonlinear adaptive optimal regulators through an improved neural learning mechanism</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<idno>058201:1-058201:3</idno>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Off-policy reinforcement learning for H∞ control design</title>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="76" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Global adaptive dynamic programming for continuous-time nonlinear systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">P</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2917" to="2929" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Decentralized adaptive optimal control of large-scale systems with application to power systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">P</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2439" to="2447" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming and adaptive optimal output regulation of linear systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">P</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4164" to="4169" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Event-driven adaptive robust control of nonlinear systems with uncertainties through NDP strategy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1358" to="1370" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Optimal control of affine nonlinear continuous-time systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dierks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the American Control Conference</title>
		<meeting>the American Control Conference<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
			<biblScope unit="page" from="1568" to="1573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Near-optimal control for nonzero-sum differential games of continuous-time nonlinear systems using singlenetwork ADP</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="206" to="216" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Guaranteed cost neural tracking control for a class of uncertain nonlinear systems using adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="80" to="90" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sliding mode control of discretetime switched systems with repeated scalar nonlinearities</title>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4604" to="4610" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Event-triggered sliding-mode control for multi-area power systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="6732" to="6741" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
