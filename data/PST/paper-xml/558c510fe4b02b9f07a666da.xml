<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Characterizing humans on Riemannian manifolds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Diego</forename><surname>Tosato</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mauro</forename><surname>Spera</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Marco</forename><surname>Cristani</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE,.</roleName><forename type="first">Vittorio</forename><surname>Murino</surname></persName>
						</author>
						<title level="a" type="main">Characterizing humans on Riemannian manifolds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2FFB128A2D2144F488508C552290A063</idno>
					<idno type="DOI">10.1109/TPAMI.2012.263</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pedestrian characterization</term>
					<term>Covariance descriptors</term>
					<term>Riemannian manifolds</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In surveillance applications, head and body orientation of people is of primary importance for assessing many behavioural traits. Unfortunately, in this context people is often encoded by few, noisy pixels, so that their characterization is difficult. We face this issue, proposing a computational framework which is based on an expressive descriptor, the covariance of features. Covariances have been employed for pedestrian detection purposes, actually, a binary classification problem on Riemannian manifolds. In this paper, we show how to extend to the multi-classification case, presenting a novel descriptor, named Weighted ARray of COvariances, WARCO, especially suited for dealing with tiny image representations. The extension requires a novel differential geometry approach, in which covariances are projected on a unique tangent space, where standard machine learning techniques can be applied. In particular, we adopt the Campbell-Baker-Hausdorff expansion as a means to approximate on the tangent space the genuine (geodesic) distances on the manifold, in a very efficient way. We test our methodology on multiple benchmark datasets, and also propose new testing sets, getting convincing results in all the cases.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>I N computer vision, and especially in videosurveil- lance, the capability of characterizing humans is surely of primary importance. In this regard, social signal processing studies <ref type="bibr" target="#b0">[1]</ref> support the hypothesis that the body appearance is critical for inferring many behavioral traits, yielding to fine activity profiles. For example, head direction is fundamental for discovering the focus of attention of individuals <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> and detecting interacting people <ref type="bibr" target="#b3">[4]</ref>, body posture and gestures during an interaction are typically indicators of speaking activity <ref type="bibr" target="#b4">[5]</ref>.</p><p>Characterizing humans becomes particularly troublesome whenever we handle small, noisy images. In such cases, tasks as body or head orientation estimation (see Fig. <ref type="figure" target="#fig_0">1(a)</ref>) turn out to be serious challenges. This fact induced researchers to design novel features, such as robust classifiers or regressors, for exploiting the available small buch of pixels at best.</p><p>Recently, the use of covariance descriptors as composite features emerged as a powerful means for pedestrian detection <ref type="bibr" target="#b5">[6]</ref>. In general, covariances showed to be naturally suited for encoding classes of objects with high intra-class variation, actually exploiting it for systematically encoding mutual relations among basic cues (as gradient, pixel intensity, etc.) <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref>. For the D. Tosato, M. Spera and M. Cristani are with the Dipartimento di Informatica, University of Verona, Strada le <ref type="bibr">Grazie 15,</ref><ref type="bibr">37134 Verona (Italy)</ref>. Contacts: D. Tosato, e-mail diego.tosato@univr.it; M.Spera, e-mail mauro.spera@univr.it, Tel: +39 045 8027816; M. Cristani, e-mail marco.cristani@univr.it, Tel: +39 045 8027988, Fax: +39 045 8027068. V. Murino is with the Istituto Italiano di Tecnologia, via Morego, <ref type="bibr" target="#b29">30,</ref><ref type="bibr">16163</ref> Genova and with the Dipartimento di Informatica, University of Verona, Strada le <ref type="bibr">Grazie 15,</ref><ref type="bibr">37134 Verona (Italy)</ref>. Contacts: e-mail vittorio.murino@iit.it, Phone: +39 010 71781 504, Mobile: +39 329 6508554, Fax: +39 010 71781 236 pedestrian case, Tuzel et al. <ref type="bibr" target="#b5">[6]</ref> employed a boosting framework on Sym + d , namely the set of positive definite d × d symmetric matrices (covariance matrices). The idea was to build weak learners by regression over the mappings of the training points on a suitable tangent space. This tangent space was defined over the weighted Karcher mean <ref type="bibr" target="#b10">[11]</ref> of the positive training data points, so to preserve their local layout on Sym + d . The negative points, instead, (i.e., all but pedestrians) were assumed to be spread on the manifold, without including them in the estimation of the mean.</p><p>In this paper, our aim is to move to a multi-class classification scenario, considering head and body orientations as object classes. In such a scenario, the above considerations do not hold any more, because we have many "positive" classes, each of them localized in a different part of the manifold. As a consequence, 1) choosing the Karcher mean of one class would privilege that class with respect to the others, and 2) the Karcher mean of all classes is inadequate. Therefore, our first contribution consists in a theoretical analysis of this space, so as to derive a point individuating a common suitable projection point that do not penalize any class. Such a point is chosen by analysing the local geometry of the manifold of the considered samples, realizing that, whenever the (sectional) curvature of the manifold is in general weak, a good candidate is the identity. This allows to consider covariance matrices as vectors in an Euclidean space where state-of-the-art classifiers can be utilized.</p><p>The second contribution consists in providing a novel measure for calculating distances between the projected points, in a way that the original geodesic distance is robustly preserved in a finer way with respect to the adoption of the Euclidean distance. This comes by considering the sectional curvature of the manifold, and adopting the general Campbell-Baker-Hausdorff (CBH) expansion <ref type="bibr" target="#b11">[12]</ref>.</p><p>In order to give a rough idea of it, and working with (square) matrices, CBH stems from the elementary fact that, since X and Y do not commute in general, one also has exp X • exp Y = exp Y • exp X = exp(X + Y ). Hence, the CBH-formula, valid in any Lie algebra, is given as a series expansion in terms of nested commutators, of the following form:</p><formula xml:id="formula_0">exp X •exp Y = exp(X + Y + 1 2 [X, Y ]+ + 1 12 [X, [X, Y ]] + 1 12 [Y, [Y, X]] + • • • ),<label>(1)</label></formula><p>where [X, Y ] = XY -Y X (the standard matrix commutator). The CBH expansion allows us to detect the role of the curvature of the manifold, showing that the higher the curvature, the rougher the approximation of the distance. At the same time, our formulation provides a new approximation for the genuine geodesic distance on the manifold, finer than the Euclidean distance previously adopted <ref type="bibr" target="#b12">[13]</ref>. We dubbed such an approximation CBH1, i.e., obtained by exploiting the first term of the CBH expansion.</p><p>As third contribution, we propose a novel object descriptor, expressively designed for encoding complex objects as pedestrians captured by few noisy pixels. The resulting descriptor is dubbed Weighted ARray of COvariances (WARCO) (see Fig. <ref type="figure" target="#fig_0">1(b)</ref>), composed by a variable number of overlapped squared patches, each of them described by a covariance matrix of image features. Each covariance is fed into a local weighted classifier (a kernel classifier), where the weight -learned during the training stage -highlights its ability in encoding a defined portion of the object of interest. All the local classifiers are then linearly combined in a strong global classifier.</p><p>Adopting WARCO in the proposed theoretical framework allows to build robust kernel classifiers in a very economical way, since the building of the Gram-matrix turns out to be linear in the number of training examples as compared with the quadratic complexity in case of the (exact) geodesic distance.</p><p>A thorough experimental section on head orientation classification/regression and body orientation classification promotes our approach as a basic module for advanced surveillance, when fine analyses have to be carried out in difficult scenarios. In particular, we test on six different benchmark datasets (including QMUL head dataset, IDIAP head pose dataset, CAVIAR), proposing three novel sets for head and body orientation estimation. In all the cases, we get convincing results.</p><p>The rest of the paper is organized as follows. In Sec. 2, we report the related literature evidencing the novel aspects of our proposal. In Sec. 3, we present the mathematical analysis of Sym + d , which has produced interesting theoretical findings exploited to design the statistical method. In Sec. 4, we describe the kernel-based classification model, which is extensively tested using several public datasets, whose results are illustrated in Sec. 5. Finally, conclusions and future perspectives are drawn in Sec. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We focus our attention on models, object representations, and features for robust human body parts description and classification. In this context, the methods can be categorized in general-purpose, where the object models can be employed for different tasks, such as whole-body or human part detection, head and body orientation classification, (e.g. <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b16">[17]</ref>) and task-specific models (e.g. <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b23">[24]</ref>).</p><p>As for the task-specific models, we consider two tasks: head and body orientation classification. Prior to this, human detection methods should be also briefly reviewed, since the object model for the detection is usually inherited by head and body orientation classification procedures.</p><p>Typically, human detection approaches represent a human as a set of unsupervised selected parts <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b30">[31]</ref>, where such parts are represented by dense features such as Haar-wavelet-based descriptors, Shapelet <ref type="bibr" target="#b24">[25]</ref>, covariance matrices <ref type="bibr" target="#b5">[6]</ref>, part-templates <ref type="bibr" target="#b31">[32]</ref>, Joint Ranking of Granules (JRoG) <ref type="bibr" target="#b28">[29]</ref>, Local Binary Patterns (LBP) <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b28">[29]</ref>, combination of HOG <ref type="bibr" target="#b17">[18]</ref>, Integral Channel Features <ref type="bibr" target="#b19">[20]</ref>, self-similarity on color channels <ref type="bibr" target="#b29">[30]</ref>, and synthesized features <ref type="bibr" target="#b30">[31]</ref>. Other works combine some of the previously mentioned features as <ref type="bibr" target="#b28">[29]</ref> where HOG and LBP are concatenated, and <ref type="bibr" target="#b26">[27]</ref> where HOG, Haar-like, and Shapelet features are used.</p><p>Most of these approaches uses boosting for both a greedy estimation of the most discriminative patches and for classifying them at the same time. A relevant exception is <ref type="bibr" target="#b17">[18]</ref>, which presents a part-based deformable model for object detection. Considering HOG features <ref type="bibr" target="#b13">[14]</ref>, the object model is defined by a constellation of discriminative learned parts that score subwindows of a ROI (Region Of Interest) containing the OI, and the classification framework is represented by latent Support Vector Machines (SVMs).</p><p>Considering now the head orientation estimation task, the literature is also vaste <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b35">[36]</ref>. For high resolution images, important methods are proposed in the context of the CLEAR07 challenge <ref type="bibr" target="#b33">[34]</ref>. Instead, for low resolution images, the head orientation estimation task often translates into the head orientation classification task, in which there are few works in the state of the art. Two recent approaches <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b36">[37]</ref> provide valid solutions to these problems. Both works organizes the overall processing scheme in two phases: detection and categorization.</p><p>Similarly to the head orientation estimation, for the human pose estimation task there are a consistent number of methods considering high-resolution images <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b37">[38]</ref>- <ref type="bibr" target="#b39">[40]</ref>. Few methods deal with small pedestrians classifying their body orientation. An interesting example is <ref type="bibr" target="#b20">[21]</ref>, where a coarse-to-fine matching of an exemplarbased shape hierarchy and Chamfer distance are used to find the best template describing a candidate human orientation.</p><p>Considering general purpose models, probably the most important example is the detector proposed by <ref type="bibr">Dalal &amp; Triggs [14]</ref>. This detector, which uses as feature the HOG, still represents an effective solution to the object detection and classification tasks. HOG describes an object as a fine set of overlapping blocks and the algorithms utilize a sliding window procedure, where a discriminative SVM model is applied to all positions and scales of an image. This approach has been also used in <ref type="bibr" target="#b37">[38]</ref> for human pose estimation, where the pose is recovered by direct regression of the HOG descriptors.</p><p>Agarwal &amp; Triggs have also demonstrated an application of non-negative matrix factorization that allows us to discriminate features of interest from background. Another interesting approach based on HOG features is proposed by Lin &amp; Davis <ref type="bibr" target="#b31">[32]</ref>. It adopts an OI model similar to the one we propose. In fact, instead of standard concatenation-style image location-based feature encoding, patches are evaluated independently and then a probabilistic framework is used to link the evaluation results. Some years later another successful work is proposed by Schwartz et al. <ref type="bibr" target="#b40">[41]</ref>. It again uses HOG features on both color and gray scale images, and the pre-process the feature space using partial least squares to reduce its dimensionality.</p><p>Recently, in <ref type="bibr" target="#b41">[42]</ref>, the HOG representation was employed to categorize the pedestrian orientations in a few classes, considering pedestrians at low resolution. Moreover, HOG is in this case combined to adaptive local receptive field features in a multi-layer neural network architecture.</p><p>In <ref type="bibr" target="#b14">[15]</ref>, a different kind of histogram-based representation is used, based on the spatial pyramid concept <ref type="bibr" target="#b42">[43]</ref>. These two models generalize the previous ones because a multi-layer analysis is performed, but a regular grid structure is still used to represent the object.</p><p>A different approach is used in <ref type="bibr" target="#b15">[16]</ref>, where patches are sampled randomly from images to build the object class model using Hough Forest, which is a Random Forest that directly maps the image patch appearance to the probabilistic vote about the possible location of the object centroid, similarly to the implicit shape model. Since fixed-size patches are used, the method is adaptable to a wide range of tasks.</p><p>The type of OI basic descriptors presented in the current work, i.e., covariance matrices, has been already exploited in the case of pedestrian detection <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref>, tracking and retrieval <ref type="bibr" target="#b43">[44]</ref> and in the biomedical research domain <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. A mathematical treatment of covariance matrices in Computer Vision is reported in <ref type="bibr" target="#b46">[47]</ref>, but the investigation of the properties of covariance matrices as objects living in a non Euclidean space is still an active research topic thanks to their versatility and effectiveness when used as descriptors for classification tasks <ref type="bibr" target="#b47">[48]</ref>- <ref type="bibr" target="#b49">[50]</ref>.</p><p>The approach proposed here can be categorized as general purpose, and a former version was presented in <ref type="bibr" target="#b12">[13]</ref>. The approach proposed here differs in several ways as a new weighted covariance descriptor is introduced, which is then exploited adopting a kernel machine architecture suitable for both classification and regression tasks. Moreover, the theoretical part is consistently new as we present a rigorous and comprehensive mathematical analysis of the covariance matrices living in a Riemannian manifold, whose findings are utilized to justify and lay down the ground of the proposed statistical classification method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THEORETICAL ANALYSIS OF Sym + d</head><p>In this section, we aim at gathering together basic differential geometry notions about Sym + d , namely the set of positive definite d × d symmetric matrices (covariance matrices), adopting the formalism of <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b50">[51]</ref>; our coverage will allow to introduce the main theoretical contribution of this work, that is, the application of the Campbell-Baker-Hausdorff expansion as a fast way to approximate distances in Sym + d .</p><p>In particular, after recalling some preliminary notions in Sec. 3.1, we show that Sym + d is a homogeneous space (Lemma 1): this means that we are entitled to select any point on Sym + d for defining a tangent space over which projecting points and in which distances are calculated. In Sec. 3.2, we show that the identity I d on Sym + d is a particularly convenient choice (under a pure computational complexity aspect) as a projection point. In Sec. 3.3, we introduce the (sectional) curvature of Sym + d which allows to measure how much Sym + d differs from a Euclidean space, which is flat. In particular, we show here that Sym + d has negative curvature (Lemma 2), and this will for instance ensure that there is only one geodesic connecting any two points; moreover, this will show that the first correction to the Euclidean distance provided by the CBH-expansion, that is, our distance approximation, is non negative. This is finally discussed in Sec. 3.4, with Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>In general, given a Lie group G and a closed Lie subgroup H thereof, the quotient set G/H consisting of all left cosets [g] := gH = {g h | h ∈ H} becomes in a unique way a smooth manifold ( this is the prototype of a G-homogeneous space). The study of the geometrical properties of homogeneous spaces is greatly eased by the fact that all points can be treated on the same footing (colloquially, the manifold appears to be the same when looked upon from whatever point therein). This is quite important from the machine learning point of view. Therefore, it is natural, for both theoretical and practical reasons, to focus the attention on the class [e] = H of the neutral element e ∈ G. A graphical example of homogeneous space is shown in Fig. <ref type="figure" target="#fig_2">2(a)</ref>. </p><formula xml:id="formula_1">Sym + d Σ → M T ΣM ∈ Sym + d , M ∈ Gl(d, R)</formula><p>. By virtue of (a corollary of) Sylvester's theorem <ref type="bibr" target="#b51">[52]</ref>, the latter action is transitive: in other words, any two positive definite symmetric matrices are congruent, i.e., there is always an M that connects them. In particular, every matrix</p><formula xml:id="formula_2">Σ ∈ Sym + d is congruent to I d (the d × d identity matrix): Σ = M T • I d • M = M T M for some M ∈ Gl(d,</formula><p>R); in our scenario we shall take, for specific calculations, M = Σ </p><formula xml:id="formula_3">+ d ∼ = Gl(d, R)/O(d, R) ∼ = Gl + (d, R)/SO(d, R</formula><p>) (one may restrict to matrices with positive determinant to get connected groups). SO(d, R) denotes the special orthogonal group, i.e. the orthogonal matrices having determinant +1.</p><p>In view of the homogeneity, we choose to work at the identity, since this will ease all subsequent computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A Riemannian metric on Sym + d</head><p>Recall that a Riemannian manifold (M, , ) is a smooth manifold equipped with a Riemannian metric , , i.e. a smoothly varying inner product , p on its tangent spaces T p M, p ∈ M. The tangent vectors (the elements of T p M) are the "velocities" of the curves in M issuing from p ∈ M or, equivalently, the "directional derivatives" of the smooth functions defined in a neighbourhood of p.</p><p>The tangent space of Sym + d at any point Σ (notation: </p><formula xml:id="formula_4">T Σ Sym +) d ), is Sym d ,</formula><formula xml:id="formula_5">+ d . Given ϕ ≡ ϕ M : Sym + d Σ → M T ΣM ∈ Sym + d , its differential ϕ * is: ϕ * : T I d Sym + d → T Σ Sym + d , W → M T W M =: W, (2) since in general D(M T ΣM ) = M T</formula><p>DΣM (here D denotes of course differentiation; notice that W is symmetric as well, as asserted before).</p><p>On T I d Sym + d it is possible to define the Frobenius inner product:</p><formula xml:id="formula_6">W 1 , W 2 I d := T r(W 1 W 2 ),<label>(3)</label></formula><p>where</p><formula xml:id="formula_7">W i ∈ Sym d .</formula><p>It is extended to a Riemannian metric, invariant under congruence via the formula:</p><formula xml:id="formula_8">W 1 , W 2 ϕ(I d )=Σ := ϕ -1 * (W 1 ), ϕ -1 * (W 2 ) I d ,<label>(4)</label></formula><p>namely (by a short computation using</p><formula xml:id="formula_9">Σ = M T M ) W 1 , W 2 Σ = T r(Σ -1 W 1 Σ -1 W 2 ),<label>(5)</label></formula><p>where</p><formula xml:id="formula_10">W 1 , W 2 ∈ T Σ Sym + d ∼ = Sym d .</formula><p>This turns out to be well-defined since the Frobenius inner product is</p><formula xml:id="formula_11">O(d, R)-invariant: indeed, if O ∈ O(d, R), we have: T r(O T W 1 O • O T W 2 O) = T r(O T W 1 W 2 O) = T r(W 1 W 2 OO T ) = T r(W 1 W 2 )<label>(6)</label></formula><p>This further entails that, given any two points</p><formula xml:id="formula_12">Σ 1 , Σ 2 ∈ Sym + d , and ϕ ≡ ϕ M : Sym + d Σ → M T ΣM ∈ Sym + d , then d(ϕ(Σ 1 ), ϕ(Σ 2 )) = d(Σ 1 , Σ 2 ), (<label>7</label></formula><formula xml:id="formula_13">)</formula><p>where d is the distance induced by the above Riemannian metric (and equals the length of a minimal geodesic connecting the two points -in our case the latter exists and it is unique, see also below); in other words, ϕ is an isometry.</p><p>In particular, we may compute all distances from a fixed point, the natural choice thereof being the identity. Also, any Σ ∈ Sym + d is of the form</p><formula xml:id="formula_14">Σ = exp W Σ , W Σ = log Σ ∈ Sym d (8) (spectral theorem), therefore d 2 (I d , Σ) = log Σ 2 = T r((log Σ) 2 ) = d i=1 (log σ i ) 2 .</formula><p>The σ i 's are the (positive) eigenvalues of Σ and, in general (setting below M T 1 M 1 = Σ 1 , and specifically</p><formula xml:id="formula_15">M 1 = Σ 1 2</formula><p>1 ):</p><formula xml:id="formula_16">d 2 (Σ 1 , Σ 2 ) = d 2 (ϕ M1 (I d ), Σ 2 ) = d 2 (I d , ϕ -1 M1 (Σ 2 )) = T r((log(Σ -1 2 1 Σ 2 Σ -1 2 1 )) 2 ) = d i=1 (log ξ i ) 2<label>(9)</label></formula><p>where the ξ i 's are the (positive) eigenvalues of</p><formula xml:id="formula_17">Σ -1 2 1 Σ 2 Σ -1<label>2</label></formula><p>1 . In fact Sym + d is actually a Riemannian symmetric space (M, , ), namely, for each point p ∈ M, there exists an isometry σ p fulfilling σ 2 p = Id M (with I d M the trivial isometry on M) and having p as an isolated fixed point ( <ref type="bibr" target="#b50">[51]</ref>). We shall not delve any further into the general theory of symmetric spaces, confining ourselves to recalling specific facts when needed. For example, it follows from it that the geodesics starting from I d are of the form</p><formula xml:id="formula_18">R t → exp(tW ) ∈ Sym + d , W ∈ Sym d , (<label>10</label></formula><formula xml:id="formula_19">)</formula><p>with exp the standard matrix exponential (since, for symmetric spaces associated to matrix groups, the Riemannian exponential coincides, at the identity, with the matrix one). An intuitive pictorial idea of the exponential map is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref> </p><formula xml:id="formula_20">κ p (X p , Y p ) := R(X p , Y p )X p , Y p p X p , X p p Y p , Y p p -X p , Y p 2 p (<label>11</label></formula><formula xml:id="formula_21">)</formula><p>where R is denoting the Riemann curvature operator (see below). Notice that the denominator represents the area squared of the parallelogram determined by X p and Y p .</p><p>It is important to pinpoint that the sectional curvature just depends on the plane spanned by X p and Y p , and indeed it turns out to coincide with the Gaussian curvature, at p, of the parametric surface S : (u, v) → exp p (uX p + vY p ) (here exp p denotes the Riemannian exponential at p). We show an example of that in Fig. <ref type="figure" target="#fig_2">2(c</ref>). In geometry, the (sectional) curvature is a measure of non-flatness of the manifold. The local vanishing of the curvature implies that the Riemannian manifold in question is actually a portion of a Euclidean space. We shall exploit this for learning purposes.</p><p>Lemma 2: The sectional curvature for Sym + d is nonpositive at any point.</p><p>Proof: Since Sym + d is a symmetric space, one can again work at the identity, whereat one gets the following expression for the Riemann curvature operator (in the symmetric space framework, see e.g. <ref type="bibr" target="#b50">[51]</ref>)</p><formula xml:id="formula_22">R(X, Y ) : Sym d Z → [[X, Y ], Z] ∈ Sym d . (<label>12</label></formula><formula xml:id="formula_23">)</formula><p>Here, [X, Y ] = XY -Y X is the matrix commutator. Then the sectional curvature κ I d at I d reads (with X,Y ∈ Sym d linearly independent): <ref type="bibr" target="#b12">(13)</ref> by the cyclical property of the trace.</p><formula xml:id="formula_24">κ I d (X, Y ) = R(X, Y )X, Y X 2 Y 2 -X, Y 2 = 2 T r((XY ) 2 -X 2 Y 2 ) T r(X 2 )T r(Y 2 ) -(T r(XY )) 2 ,</formula><p>Again, the denominator 2 is the area of the parallelogram determined by X 1 and X 2 , squared. Therefore, to prove that</p><formula xml:id="formula_25">X 1 2 X 2 2 -X 1 , X 2 2 =: A(X 1 , X 2 )</formula><formula xml:id="formula_26">κ I d (X, Y ) ≤ 0, it suffices to show that T r((XY ) 2 ) ≤ T r(X 2 Y 2 ),<label>(14)</label></formula><p>and that equality holds if and only if [X, Y ] = 0. This is implied by the following immediate consequence of the Schwarz inequality for (real) inner products</p><formula xml:id="formula_27">x, y ≤ x 2 , if x = y (<label>15</label></formula><formula xml:id="formula_28">)</formula><p>(equality holding if and only if x = y). Indeed, upon</p><formula xml:id="formula_29">setting x = XY , y = Y X, x, y = T r(x T y) = T r(y T x),</formula><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</p><p>and using X T = X, Y T = Y , we have:</p><formula xml:id="formula_30">y 2 = T r((Y X) T (Y X)) = T r(X T Y T Y X) = T r(XY Y X) = T r(X 2 Y 2 ) = x 2<label>(16)</label></formula><p>We again stress that, for learning purposes, κ p (X p , Y p ) provides a quantitative measure of how much a Riemannian manifold differs from a flat (i.e. Euclidean) one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">An expansion of the distance via the CBHformula</head><p>Recalling that Preismann's theorem (see e.g. <ref type="bibr" target="#b50">[51]</ref>) says that any two points of a complete simply connected manifold with non-positive sectional curvature are connected by precisely one geodesic, one has that, given a geodesic triangle with sides of length a, b, c, and angle θ opposite to (the side with length) c, the a 2 + b 2 -2ab cos θ ≤ c 2 inequality holds. An application of the theorem to Sym + d (which indeed satisfies the above assumptions) shows that, taking the geodesic triangle with vertices</p><formula xml:id="formula_31">I d , Σ 1 , Σ 2 , one gets d E (log I d Σ 1 , log I d Σ 2 ) ≤ d(Σ 1 , Σ 2 )</formula><p>, where d E denotes the standard Euclidean distance (induced by the Frobenius norm)</p><formula xml:id="formula_32">d 2 E (X 1 , X 2 ) = T r((X 1 -X 2 ) 2 )<label>(17)</label></formula><p>with X i = log I d Σ i . But actually one can easily get approximate formulae for the distance by exploiting the Campbell-Baker-Hausdorff formula (CBH) (see e.g. <ref type="bibr" target="#b11">[12]</ref>, p.30, where the more general Dynkin's formula is given, and below: we shall apply it to the Lie algebra consisting of real d × d matrices). Namely, we are going to show the following: Theorem 1: The crudest approximation beyond the Euclidean distance (computed on the tangent space</p><formula xml:id="formula_33">T I d Sym + d ; also set X i := log Σ i , i = 1, 2) reads: d 2 (Σ 1 ,Σ 2 ) = d 2 E (X 1 , X 2 )- 1 12 R(X 1 , X 2 )X 1 , X 2 + • • • = d 2 E (X 1 , X 2 )- 1 12 κ(X 1 , X 2 ) • A(X 1 , X 2 ) 2 + • • • (<label>18</label></formula><formula xml:id="formula_34">)</formula><p>(which we illustrate in Fig. <ref type="figure" target="#fig_2">2(d</ref>).) Proof: The calculation employs the CBH-formula (suitably truncated to second order commutators)</p><formula xml:id="formula_35">log(e X e Y ) = = X + Y + 1 2 [X, Y ] + 1 12 [X, [X, Y ]] + 1 12 [Y, [Y, X]] + • • • (19)</formula><p>which subsequently entails</p><formula xml:id="formula_36">log(e X e Y e X ) = 2X + Y - 1 6 [X, [X, Y ]] - 1 6 [Y, [X, Y ]] + • • • (20)</formula><p>The above series are indeed convergent. Upon setting X = -1 2 X 1 , Y = X 2 , the r.h.s. of the above formula becomes</p><formula xml:id="formula_37">W = X 2 -X 1 - 1 24 [X 1 , [X 1 , X 2 ]] + 1 12 [X 2 , [X 1 , X 2 ]] + • • • . (<label>21</label></formula><p>) Now, substituting the above expression in the formula for the distance (Eq. ( <ref type="formula" target="#formula_16">9</ref>)), we find, after a short computation exploiting the properties of T r:</p><formula xml:id="formula_38">d 2 (Σ 1 , Σ 2 ) = = T r[(X 2 -X 1 ) 2 ] - 1 12 T r{[X 1 , [X 1 , X 2 ]](X 2 -X 1 )} + 1 6 T r{[X 2 , [X 1 , X 2 ]](X 2 -X 1 )} + • • • (22)</formula><p>The last expression can be eventually transformed into Eq. ( <ref type="formula" target="#formula_33">18</ref>) upon recalling the formula for the Riemannian curvature operator (Eq. ( <ref type="formula" target="#formula_22">12</ref>)), together with the following general Riemann tensor identities (the third one being the Bianchi identity, see e.g. <ref type="bibr" target="#b50">[51]</ref>):</p><formula xml:id="formula_39">R(x, y, z, t) = -R(y, x, z, t) = -R(x, y, t, z) = R(z, t, x, y) (23) R(x, y, z, t) + R(y, z, x, t) + R(z, x, y, t) = 0<label>(24)</label></formula><p>where R(x, y, z, t) is defined as R(x, y)z, t . In particular, we have</p><formula xml:id="formula_40">R(X 1 , X 2 , X 1 , X 1 ) = R(X 1 , X 2 , X 2 , X 2 ) = 0,<label>(25)</label></formula><p>and we easily get the sought-for approximate formula <ref type="bibr" target="#b17">(18)</ref>. In Sec. 5 we will show the efficacy of the expansion above in approximating the geodesic distance 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE STATISTICAL FRAMEWORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The General Architecture</head><p>The WARCO classifier has been designed specifically to deal with few visual information, that is, tiny images with noisy pixel values. It consists in a grid of N p uniformly spaced and overlapped k × k patches Φ = {φ n } n=1,...,Np , where each patch is described by a covariance matrix of features. For the sake of generality, we do not specify here neither the degree of overlap nor the nature of the feature considered, postponing this aim in the experiments.</p><p>In a L-class classification scenario, ARCO instantiates a single classifier on each patch, and provides a posterior classification probability which is</p><formula xml:id="formula_41">P (l|Φ) = P (l|{φ n } n=1,...,Np ) = N P n=1 w n P (l|φ n ).<label>(26)</label></formula><p>1. We just kept the first correction to the Euclidean distance. One could work out more refined expressions upon carefully keeping track of the various summands of CBH expansion. The successive terms, depending on nested commutators, are also related to curvature. Notice that we did not provide precise estimates for the approximation error.</p><p>where l = 1, . . . , L is the class index, n = 1, . . . , N P is the patch index, P (l|φ n ) is the per-patch posterior probability of the n-th classifier and w n is a normalized weight so that n w n = 1, one for each patch classifier. This formulation is inspired by the Mixed Memory models (MMM) <ref type="bibr" target="#b52">[53]</ref>, that applies when a random variable is conditioned on the joint occurrence of a set of events; since the modeling of the joint conditional could be hard (due to complex dependencies between the variables, for example), the MMM approximates the joint conditional as a convex combination of pairwise conditionals. In our case, Eq. ( <ref type="formula" target="#formula_41">26</ref>) approximates the fact that the classifiers are not independent (they actually work on local patches that in general are overlapped). The weights are learned in the following way: a 10-fold cross-validation strategy extracts a validation set; all the classifiers are trained on the remaining training set. On the validation set, all the classifiers give their votes; counting and normalizing the times the classifiers have done the correct choice gives a temporary weight. Averaging the temporary weights of all the runs of the cross-validation gives the final weights.</p><p>In a regression scenario, WARCO instantiates a regressor for each patch, and the final output is the median of all the outputs of the single regressors.</p><p>Standard Support Vector Machine (SVM) is the tool employed for performing classification and regression, where the Gram-matrix has been calculated by employing three different distances, i.e., d E : The distance between covariance matrices based on the Frobenius norm (see Sec. 3.2)</p><formula xml:id="formula_42">d 2 E (X, Y ) = Tr ((log I d (X) -log I d (Y )) 2 ). (<label>27</label></formula><formula xml:id="formula_43">)</formula><p>d CBH1 : The distance<ref type="foot" target="#foot_1">2</ref> between covariance matrices exploiting the CBH expansion limited to the first order (see Sec. 3.4)</p><formula xml:id="formula_44">d 2 CBH1 (X, Y ) = d 2 E (X, Y ) + Ξ(κ I d ),<label>(28)</label></formula><p>where</p><formula xml:id="formula_45">Ξ(κ I d ) = - 1 12 R(log I d (X), log I d (Y )) log I d (X), log I d (Y ) . (<label>29</label></formula><formula xml:id="formula_46">)</formula><p>d G : The actual geodesic distance between covariance matrices (see Sec. 3.2)</p><formula xml:id="formula_47">d 2 G (X, Y ) = Tr (log 2 I d (X -1 2 Y X -1 2 )). (<label>30</label></formula><formula xml:id="formula_48">)</formula><p>We compute these three distances between all the training samples; therefore, for each distance, we obtain a dissimilarity matrix D. To use this distance measure in Support Vector Machines, we use the extended Gaussian Kernel <ref type="bibr" target="#b53">[54]</ref>: this amounts to apply the nonlinear transformation D = exp -D μ(D) , where μ(D) is the average value of all the elements of D, making the resulting matrix a Mercer kernel.</p><p>Looking at the three distances, one can easily imagine the complexity for building the related Gram matrices. The logarithmic projection is without doubts the most demanding operation, so that it represents the bottleneck of the framework. Using the distances ( <ref type="formula" target="#formula_42">27</ref>) and ( <ref type="formula" target="#formula_44">28</ref>), the number of logarithmic projections is linear: in particular, in the CBH1 distance, all the N elements into play have to be projected over the identity, and then the projections can be employed for building the Gram matrix. Conversely, with the geodesic distance, all the elements have to be projected on the tangent spaces of all the elements, so that the complexity results quadratic. To give an practical intuition, whereas the learning of a classifier employing CBH1 with 10K elements takes 24 hours, considering the geodesic distance this translates in 576 hours (one month) on a Quad Core Intel Xeon Processor E5603 platform (1.6 GHz).</p><p>In the literature, there is a recent study <ref type="bibr" target="#b49">[50]</ref> which shares some aspects with our approach; it proposes a fast and effective (dis)similarity function for Sym + d using Jensen-Bregman (J-B) LogDet divergence, which also provides an associated fast search tree structure. This method is also shown to be much faster than the Riemannian metric, while being more accurate than the log-euclidean metric. In our case, our aim is to build kernels for SVM with N elements of dimension d. With CBH1 the complexity is governed by the matrix multiplication which is O(d 2 ), whereas it is O(d 3 ) for the Jensen-Bregman divergence (due to the determinants' computation). Moreover, although a closer scrutiny of the mutual relationship between the J-B LogDet approach and ours would be desirable, the former method appears to be rather ad hoc. Our proposed approach, instead, which is based on the intrinsic geometry of the manifold, can in principle be extended to other situations where Riemannian geometry can be applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filter Bank Coverage Filter Bank Masks</head><p>Filter Applica on Filter Applica on In our approach, we extract from each image I (r × r pixels), a set Φ(I, x, y) of dimension r × r × d features where d = 13 and x, y are the pixel location. It is composed by:</p><formula xml:id="formula_49">Φ(I, x, y) = F 1 (Y ) . . . F 8 (Y ) Y C b C r G | | (Y ) G O (Y ) , (<label>31</label></formula><formula xml:id="formula_50">)</formula><p>where F 1 (Y ) . . . F 8 (Y ) is the filter bank, depicted in Fig. <ref type="figure" target="#fig_4">3</ref>, consisting of scaled symmetric DOOG (Difference Of Offset Gaussian) <ref type="bibr" target="#b54">[55]</ref>, applied only on the luminance channel of the perceptually uniform CIELab color space. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we extensively test our approach in different tasks related to video surveillance.</p><p>In particular, we perform head orientation analysis in Sec. 5.3 and 5.4, and human orientation classification in Sec. 5.5. We do this under different operative conditions, with in total 6 datasets, each of them bringing in different issues. We also compare our proposal with known competitors, showing convincing performances.</p><p>In Table <ref type="table" target="#tab_2">1</ref>, first 5 columns, we summarize the nature of the datasets considered and the settings of WARCO (number of patches, size of the patches). In all the experiments, the overlap among patches is 0.5, since this value it has been empirically demonstrated a convenient choice <ref type="bibr" target="#b13">[14]</ref>.</p><p>On these datasets, we show how facts and intuitions of Sec. 3 can be clearly observed (Sec. 5.2). More specifically, we analyze the sectional curvature κ I d , showing empirically that there is a relation between size of the patch, sectional curvature and approximation error of the Frobenius distance d E <ref type="bibr" target="#b26">(27)</ref> and CBH1 distance d CBH1 (28) (Sec. <ref type="bibr">3.3)</ref>. We also demonstrate that, in average,</p><formula xml:id="formula_51">d E ≤ d CBH1 ≤ d G (see Sec. 3.4).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>For head orientation classification, we consider the QMUL, the Heads Of CoffeBreak (HOCoffee), and the Heads of IIT (HIIT) <ref type="bibr" target="#b55">[56]</ref> datasets. All the datasets are partitioned into a train and test set.</p><p>The QMUL head dataset (see Fig. <ref type="figure" target="#fig_6">4(d)</ref> for some examples) is formed by head images taken from the i-LIDS dataset<ref type="foot" target="#foot_2">3</ref> portraying an airport indoor scenario. It is composed by 19292 images: 10517 for the training and 8775 for the testing phase. They are uniformly partitioned into 5 classes: Back (BA), Front (FR), Left (LE), Right (RI), and Background (BG). Background images contain portions of the background scene.</p><p>The images are 50 × 50 pixels. The best performances are achieved in <ref type="bibr" target="#b12">[13]</ref> in this case. The challenges of this dataset consist in scarce/non-homogeneous illumination, and quite severe occlusions.</p><p>The HOCoffee dataset (see Fig. <ref type="figure" target="#fig_6">4(b)</ref>) is a novel benchmark dataset extracted from the CoffeeBreak social signal processing dataset <ref type="bibr" target="#b3">[4]</ref>, where an outdoor coffee break session during a summer school was captured, for detecting automatically social interactions. It is composed by 18117 head examples, 9522 in the training and 8595 in the testing set, of 50 × 50 pixels, uniformly partitioned into 6 different classes (orientations): Back, Front, Front-Left, Front-Right, Left, and Right. The images contain a margin of 10 pixels on average, so the actual average dimension of the heads is 30 × 30 pixels. HOCoffee images show two main issues: the heads are captured automatically by a head detector, therefore they are often not centered in the images. In addition, there are several important occlusions.</p><p>The HIIT dataset (see Fig. <ref type="figure" target="#fig_6">4(a)</ref>) has been built combining some indoor image data captured in a controlled scenario (a vision lab) and the Pointing04 <ref type="bibr" target="#b56">[57]</ref>, Multi-PIE <ref type="bibr" target="#b57">[58]</ref>, and QMUL <ref type="bibr" target="#b55">[56]</ref> datasets. As the previous dataset, it has 6 classes, 2000 examples each both for the training and testing set. The size of the samples is 50 × 50 pixels, without margin around the heads. The main characteristic of this dataset is that it has a stable background and no occlusions, so that it represents the ideal scenario where to evaluate how well a classifier can perform at a given resolution.</p><p>The QMUL and the HIIT dataset contain the images of the head of thousand of different subjects, while the HOCoffee focuses on 15 subjects taken in two different experimental sessions.</p><p>Considering the head orientation estimation, we focus on two public datasets, i.e., IDIAP and CAVIAR.</p><p>The IDIAP Head Pose dataset <ref type="bibr" target="#b58">[59]</ref> (see Fig. <ref type="figure" target="#fig_6">4(f)</ref>) comes from 8 meeting sequences of 360 × 288 frame resolution, where two individuals were captured while discussing about various topics in a 4-person dialogue scenario. The total number of different subjects captured is 15. They had their head orientations continuously annotated using a magnetic field location and orientation sensor tracker. The video repository has been lately employed for the CLEAR2007 head orientation estimation contest, following the protocol described in <ref type="bibr" target="#b33">[34]</ref> (75 × 75 21152 samples were selected as training data and 23991 as testing data). Since the training samples are particularly biased on certain orientations, we flip them and then we randomly extract a subset of 5288 images, obtaining a balanced training pool. It represents a valuable benchmark set since the annotations express the pan, tilt and roll angles of the head pose. The best performances are set in <ref type="bibr" target="#b59">[60]</ref> (tilt) and <ref type="bibr" target="#b33">[34]</ref> (pan, roll).</p><p>The CAVIAR dataset <ref type="bibr" target="#b60">[61]</ref> (see Fig. <ref type="figure" target="#fig_6">4(e)</ref>) is a more challenging set for the estimation task due to the low resolution of the images and the presence of occlusions. The considered head samples, resized to 50 × 50 pixels, come from a set of sequences which have 1500 frames on average, acquired from a real surveillance camera located in a shopping centre in Lisbon. The dataset is composed by two subsets: the first is made by non-occluded head images for a total number of 21325 examples (10660 as training and 10665 as testing set), the second consists in a dataset of 21691 images partitioned in 10802 training and 10889 for testing. For the best performance on this dataset, please see Sec. 5.4.</p><p>Finally, for the body orientation task, we introduce a novel dataset dubbed Human Orientation Classification (HOC) <ref type="bibr" target="#b55">[56]</ref>. Even if this task has recently attracted the attention of researchers (see for example <ref type="bibr" target="#b41">[42]</ref>) no public available datasets are present in the literature (except the ViPER dataset <ref type="bibr" target="#b61">[62]</ref>, but it has a very low number of elements, limited to 632). HOC (see Fig. <ref type="figure" target="#fig_6">4(c)</ref>) is derived by the ETHZ <ref type="bibr" target="#b62">[63]</ref> human re-acquisition dataset representing pedestrians in different orientations and (background) conditions, captured by hand-held cameras.</p><p>ETHZ is structured in three sequences for a total of 11881 images (6860 in the training and 5021 in the testing set), each image 64 × 32 pixels containing a pedestrian. We manually split the images into 4 orientation classes (Front, Back, Left, and Right), individuating a training and a testing partition. The dataset is complex because of the low resolution, severe illumination artifacts, occlusions and consistent scale changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Geometrical properties of Sym + d</head><p>The numerical evaluation of the curvature κ I d in correspondence of the samples of a particular dataset allows to understand how concave is the related region of Sym + d . In Tab. 1, the mean value and the standard deviation of κ I d of 1K random elements for all the datasets are reported (note that QMUL † refers to the QMUL dataset with the background class). These values are calculated by considering each covariance matrix of WARCO as an independent sample, for all the WARCO descriptors of a single dataset.</p><p>In the same table, we calculate the mean values of the Frobenious distance d E <ref type="bibr" target="#b26">(27)</ref>, the CBH1 distance d CBH1 <ref type="bibr" target="#b27">(28)</ref> and the geodesic distance d G (30) between all the possible couples of the above elements. In addition, we compute the mean error and its standard deviation, considering as Frobenious (CBH1) error the absolute value of the difference between a Frobenious (CBH1) distance value and the corresponding geodesic one.</p><p>Many observations can be drawn: first, larger patches seem to lie in flatter regions, and this assumption will be validated heuristically, in a more exhaustive fashion, later in the section. Considering the approximated distances, the approximation error in the case of large patches seems to be lower than in the case of tiny regions, and in particular, as expected, Err d E ≤ Err d CBH1 ; the same applies for the standard deviations of the errors. Finally, one can note that for the mean values the inequality d E ≤ d CBH1 ≤ d G holds systematically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Head Orientation Classification</head><p>QMUL Head dataset. We test our WARCO classifier adopting both the Frobenious and the CBH distances, against the template-based discriminative approach presented in <ref type="bibr" target="#b23">[24]</ref> and the ARCO LogitBoost-based strategy <ref type="bibr" target="#b12">[13]</ref>, the latter being the current best approach.</p><p>To reproduce the former method, we considered the image features provided by the dataset authors and we follow the same experimental protocol. The confusion matrices are reported in Fig. <ref type="figure" target="#fig_7">5</ref>, considering 4 and 5 (4 orientations plus the background) classes. WARCO with CBH1 distances get the highest average classification scores. One should also pay attention to Fig. <ref type="figure" target="#fig_7">5(h)</ref>, where the accuracy in classifying the background class rises of about 10% with respect to the previous state-of-the-art results depicted in Fig. <ref type="figure" target="#fig_7">5</ref>(f). This gap is due to the CBH distance: actually, background samples are located in zones with higher curvature (validated experimentally), far from I d , so that the contribution given by the CBH   expansion becomes critical in better capturing the local geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HOCoffee dataset.</head><p>In this case we have 6 orientations. In Fig. <ref type="figure" target="#fig_9">6</ref>(e), the qualitative performances, and in Fig. <ref type="figure" target="#fig_9">6(c</ref>) and (d), the quantitative performances are reported considering both Frobenious (FROB) d E distance <ref type="bibr" target="#b26">(27)</ref> and the CBH1 d CBH1 distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HIIT dataset.</head><p>As one can note in Fig. <ref type="figure" target="#fig_9">6</ref>(a) and (b), the performance of our framework are rather high, in fact, using d CBH1 to measure the distance among covariance matrices the average accuracy is 97%. This means that our classifier manages easily low resolution head images classifying the orientation precisely.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Head Orientation Estimation by Regression.</head><p>In this context, we replace the SVM classifier with a SVM regressor <ref type="bibr" target="#b63">[64]</ref>.</p><p>IDIAP Head Pose. The head orientation evaluation protocol is taken from <ref type="bibr" target="#b33">[34]</ref>: in each one of the 8 meetings of the test set, we have 1 minute of recording for the testing, for a total of 1500 test samples. We adopt the three error measures suggested by the protocol, which  are the absolute differences with the ground-truth pan, tilt and roll angles. Table <ref type="table" target="#tab_5">2</ref> summarizes our results considering all the methods in the literature that followed the protocol above. As one can observe, we reach good results concerning the pan, while we define the best scores with the tilt and roll angles. In Fig. <ref type="figure" target="#fig_10">7</ref>, we report an analysis of the performances obtained by our framework per sample, on all the samples (employing the CBH1 distance), as compared to the ground-truth. CAVIAR. We consider the best competitor for this  dataset, which is the method presented in <ref type="bibr" target="#b36">[37]</ref>. Unfortunately, we had difficulties in producing a fair comparison. In this paper <ref type="bibr" target="#b36">[37]</ref>, ground truth annotations are made by the authors, which unfortunately are not compatible with that provided together with the dataset. In practice, they represent a quantized version of the original annotations. Employing the original annotations, we individuate two datasets, one formed by non-occluded samples, the other with occlusions, and we estimate the pan angle on both sets. Results are shown in Table <ref type="table" target="#tab_7">3</ref>, where, as in <ref type="bibr" target="#b36">[37]</ref>, the mean, the standard deviation and the median of the errors are reported.</p><p>Two main considerations pop out. The first one is that our approach gets lower errors than <ref type="bibr" target="#b36">[37]</ref>. Apart from the different methodologies in getting ground truth data, that should make the task of <ref type="bibr" target="#b36">[37]</ref> easier than ours, WARCO is noticeably more accurate. The second observation is that the errors of WARCO in the occluded cases are not dramatically higher than the un-occluded cases, and this is due to the nature of WARCO, i.e., an ensemble of local classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Human Orientation Classification dataset.</head><p>In this case, WARCO is computed on 40 overlapped patches of 24 × 24 pixels. In Fig. <ref type="figure" target="#fig_12">8</ref> one can see the accuracy result achieved by our algorithm. Despite the heavy occlusions and the bad illumination conditions, the average accuracy reaches 79%. It is worth noting how the Front and the Back classes are nicely separated: this is an impressive results, since here the most noticeable difference between the two classes lies in the head portion, which is relatively small.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Scale issues.</head><p>Here, we stress the capability of WARCO of working at low resolution, and we explore the relation between patch dimensions and manifold curvature κ I d . We produce two additional experimental sessions, where we reduce the image dimensions of each dataset by a factor of 0.75 and 0.5. Consequently, we reduce by the same factor the architecture of WARCO. In Fig. <ref type="figure">9</ref>, we report the results concerning the classification, and in Fig. <ref type="figure" target="#fig_13">10</ref> we show the results for the regression task.</p><p>As one can note, the smaller the size of the object, the higher the curvature. Furthermore, it is valuable to observe how the CBH1 distance-based framework behaves with respect to the Frobenious distance-based technique at the different resolutions: the lower the resolution, the bigger the gap between CBH1 and the Frobeniousbased strategy. Once again, this demonstrates that the contribution of CBH1 is in general more helpful in highly curved manifold regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We presented a method for characterizing tiny images of pedestrians in a surveillance scenario, specifically, for performing head orientation and body orientation estimation, employing arrays of covariances as descriptors, named WARCO. Given the results achieved, we are confident that the framework will be adopted as standard tool in surveillance applications.</p><p>We also think that our work is valuable beyond the scope of the contingent application: actually, we suggested a theoretically sound way to deal with covariance matrices, like they were points lying in an Euclidean space. This came with a measure for approximating geodesic distances, the CBH1 measure, that works better than standard Euclidean distance.</p><p>Future research on this topic will check whether the triangular inequality holds for CBH1, in order to validate CBH1 as genuine distance. Furthermore, we plan to extend WARCO as an action descriptor, including the temporal dimension in the analysis, and to inject multiple kernel reasoning for learning the weights of WARCO, instead of calculating them independently.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Example of an image from a video surveillance sequence containing pedestrians and close-up of their heads. (b) Weighted ARray of COvariance matrices (WARCO).</figDesc><graphic coords="1,311.87,330.89,113.06,63.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Homogeneous spaces. (b) Exponential map. (c) Gaussian curvature (κ p (X p , Y p )) of the 2-dimensional surface S at p. (d) Approximating the true geodesic distance.</figDesc><graphic coords="4,68.99,426.41,100.82,78.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 2 .</head><label>2</label><figDesc>Therefore, Sym + d is the space of all symmetric matrices congruent to I d . Also, I d is invariant under congruence, namely M T M = I d , if and only if M ∈ O(d, R), the group of orthogonal d × d matrices. In other words, O(d, R) is the isotropy group of I d . From this, one finds that Sym + d is the homogeneous space Sym</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>the space of symmetric matrices. By homogeneity it is enough to check this at the identity I d . Indeed, let us consider an interval J ⊂ R containing 0, and let us consider a smooth curve of matrices J t → Σ(t) ∈ Sym + d with Σ(0) = I d . Its "velocity" at I d , namely Σ(0), belongs to Sym d , since the derivative of Σ(t) is still a symmetric matrix. Vice versa, given a matrix W ∈ Sym d , it is possible to find a curve in Sym + d starting at I d with velocity given by W = Σ(0). Taking for instance Σ(t) = exp(tW ), if we diagonalize the matrix W and denote its eigenvalues by w i , i = 1, 2, . . . , d, then the eigenvalues of Σ(t) are exp(tw i ) &gt; 0, i = 1, 2, . . . , d. Therefore, the matrix is positive definite. By continuity, any curve with the same velocity at I d is locally in Sym</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. On the left Symmetric DOOG (Difference Of Offset Gaussian) filters used to populate the feature set Φ. On the right two examples of their application on an head and a human image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Y , C b , and C r are the three color channels obtained by transforming the original RGB image. G | | (Y ) and G O (Y ) are the gradient magnitude and orientation calculated on the Y channel map, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Examples of the (a) HIIT, (b) HOCoffee, (c) HOC, (d) QMUL, (e) CAVIAR, and (f) IDIAP datasets used in the experimental part. In (a), (b), (c), and (d), each row correspond to a different class. In (e) and (f), head orientation is estimated by regression. Examples are ranked from the left to the right proportionally to their degree of difficulty.</figDesc><graphic coords="9,311.87,233.09,125.66,70.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Examples and statistics of the 4 and 5-class original dataset taken by Orozco et al. [24]. (a) and (e): the original results by Orozco et al. approach [24]. (b) and (f): the Tosato et al. approach [13]. (c), (d), (g), and (h): , the proposed approach.</figDesc><graphic coords="10,322.19,496.73,79.10,59.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>.</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Confusion matrices on the (a) and (b) HIIT, and (c) and (d) CoffeeBreak head orientation datasets [56]. (e) shows a qualitative result on the CoffeeBreak dataset.</figDesc><graphic coords="10,482.03,496.73,78.50,59.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Using our framework with the CBH1 distance, we show the difference between the estimated orientation and the ground-truth for pan (a), tilt (b), and roll (c) angles for the IDIAP head pose dataset (better viewed in colors).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>.</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Confusion matrices showing the performances between the WARCO method using (a) the Frobenius distance (d E ) and (b) the CBH1 distance (d CBH1 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Comparative study of the performances of the proposed statistical regression framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>3 Non-positivity of the sectional curvature of Sym +</head><label></label><figDesc></figDesc><table /><note><p><p><p><p><p>(b)  </p>In our case, the isometry σ p of the general theory is induced at</p>I d by the map Sym d W → -W ∈ Sym d .</p>3.d</p>Given a Riemannian manifold (M, , ) its sectional curvature κ p (X p , Y p ) at p ∈ M, if X p and Y p are linearly independent tangent vectors at p, is given by</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</figDesc><table><row><cell>Dataset name</cell><cell></cell><cell cols="2">Dataset attrib.</cell><cell cols="2">WARCO</cell><cell>κI d</cell><cell></cell><cell>dE</cell><cell></cell><cell></cell><cell>dCBH1</cell><cell>dG</cell></row><row><cell></cell><cell>obj. of int.</cell><cell>images</cell><cell>avg. obj. dim.</cell><cell>patches number</cell><cell>patch dim.</cell><cell>mean</cell><cell>standard dev.</cell><cell>mean</cell><cell>Err d E</cell><cell>mean</cell><cell>Err d CBH1</cell><cell>mean</cell></row><row><cell>QMUL</cell><cell>head</cell><cell>16k</cell><cell>50 × 50</cell><cell cols="2">25 16 × 16</cell><cell cols="2">-0.035 0.017</cell><cell cols="2">7.78 0.99,(0.41)</cell><cell cols="2">8.21 0.60,(0.27)</cell><cell>8.78</cell></row><row><cell>QMUL  †</cell><cell>head</cell><cell>20k</cell><cell>50 × 50</cell><cell cols="2">25 16 × 16</cell><cell cols="2">-0.038 0.020</cell><cell cols="2">8.65 0.98,(0.41)</cell><cell cols="2">9.13 0.59,(0.27)</cell><cell>9.65</cell></row><row><cell>HIIT</cell><cell>head</cell><cell>24k</cell><cell>50 × 50</cell><cell cols="2">25 16 × 16</cell><cell cols="2">-0.031 0.018</cell><cell cols="2">7.02 0.88,(0.42)</cell><cell cols="2">7.41 0.55,(0.28)</cell><cell>8.02</cell></row><row><cell>HOCofee</cell><cell>head</cell><cell>18k</cell><cell>50 × 50</cell><cell cols="2">25 16 × 16</cell><cell cols="2">-0.035 0.015</cell><cell cols="2">6.40 0.88,(0.39)</cell><cell cols="2">8.37 0.52,(0.25)</cell><cell>8.88</cell></row><row><cell>CAVIAR (Cl.)</cell><cell>head</cell><cell>21k</cell><cell>50 × 50</cell><cell cols="2">25 16 × 16</cell><cell cols="2">-0.041 0.021</cell><cell cols="2">8.59 1.18,(0.41)</cell><cell cols="2">9.16 0.67,(0.26)</cell><cell>9.73</cell></row><row><cell>CAVIAR (Occ.)</cell><cell>head</cell><cell>22k</cell><cell>50 × 50</cell><cell cols="2">25 16 × 16</cell><cell cols="2">-0.043 0.026</cell><cell cols="2">8.12 1.19,(0.39)</cell><cell cols="2">8.88 0.69,(0.25)</cell><cell>9.12</cell></row><row><cell>IDIAP</cell><cell>head</cell><cell>66k</cell><cell>75 × 75</cell><cell cols="2">25 24 × 24</cell><cell cols="2">-0.014 0.006</cell><cell cols="2">4.79 0.43,(0.19)</cell><cell cols="2">5.01 0.27,(0.12)</cell><cell>5.34</cell></row><row><cell>HOC</cell><cell cols="3">human 11k 62 × 132</cell><cell cols="2">40 24 × 24</cell><cell cols="2">-0.024 0.014</cell><cell cols="2">7.67 0.59,(0.30)</cell><cell cols="2">7.99 0.37,(0.19)</cell><cell>8.41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1</head><label>1</label><figDesc>Curvature analysis and distance comparison of different datasets. κ I d , d E , d CBH1 , and d G are compared on the same covariance representation (see Eq. (31)). The errors Err d E and Err d CBH1 are shown with their mean value and its standard deviation (in parenthesis). See Sec. 5.2 for other details.</figDesc><table><row><cell></cell><cell cols="2">Orozco et al. '09</cell><cell></cell><cell cols="3">Tosato et al. '10</cell><cell></cell><cell cols="2">Our, Frob. distance</cell><cell></cell><cell cols="2">Our, CBH distance</cell></row><row><cell cols="3">(avg accuracy 0.8225)</cell><cell cols="4">(avg accuracy 0.935)</cell><cell cols="3">(avg accuracy 0.93227)</cell><cell cols="3">(avg accuracy 0.9425)</cell></row><row><cell>BA</cell><cell cols="2">.88 .06 .02 .04</cell><cell>BA</cell><cell>.97</cell><cell cols="2">.01 .01 .01</cell><cell>BA</cell><cell cols="2">.97 .01 .01 .01</cell><cell>BA</cell><cell cols="2">.98 .01 .01</cell></row><row><cell>FR</cell><cell cols="2">.08 .76 .10 .06</cell><cell>FR</cell><cell cols="3">.05 .90 .03 .02</cell><cell>FR</cell><cell cols="2">.05 .91 .02 .02</cell><cell>FR</cell><cell cols="2">.04 .91 .03 .02</cell></row><row><cell>LE</cell><cell cols="2">.09 .18 .71 .02</cell><cell>LE</cell><cell cols="3">.03 .07 .89 .01</cell><cell>LE</cell><cell cols="2">.02 .08 .88 .02</cell><cell>LE</cell><cell cols="2">.03 .06 .90 .01</cell></row><row><cell>RI</cell><cell>.03 .03</cell><cell>.94</cell><cell>RI</cell><cell cols="2">.01 .01</cell><cell>.98</cell><cell>RI</cell><cell>.02 .01</cell><cell>.97</cell><cell>RI</cell><cell>.01 .01</cell><cell>.98</cell></row><row><cell></cell><cell cols="2">B A F R L E R I</cell><cell></cell><cell cols="3">B A F R L E R I</cell><cell></cell><cell cols="2">B A F R L E R I</cell><cell></cell><cell cols="2">B A F R L E R I</cell></row><row><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell>(c)</cell><cell></cell><cell></cell><cell>(d)</cell></row><row><cell></cell><cell cols="2">Orozco et al., 2009</cell><cell></cell><cell cols="3">Tosato et al., 2010</cell><cell></cell><cell cols="2">Our, FROB. distance</cell><cell></cell><cell cols="2">Our, CBH distance</cell></row><row><cell></cell><cell cols="2">(avg accuracy 0.64173)</cell><cell></cell><cell cols="3">(avg accuracy 0.88957)</cell><cell></cell><cell cols="2">(avg accuracy 0.90564)</cell><cell cols="3">(avg accuracy 0.91177)</cell></row><row><cell>BA</cell><cell cols="2">.88 .05 .03 .04</cell><cell>BA</cell><cell cols="3">.92 .05 .01 .01 .01</cell><cell>BA</cell><cell cols="2">.94 .02 .01 .01 .02</cell><cell>BA</cell><cell>.95 .02 .01</cell><cell>.02</cell></row><row><cell>FR</cell><cell cols="2">.07 .62 .08 .06 .17</cell><cell>FR</cell><cell cols="3">.03 .91 .03 .02 .01</cell><cell>FR</cell><cell cols="2">.04 .89 .05 .01 .01</cell><cell>FR</cell><cell cols="2">.04 .90 .04 .01 .01</cell></row><row><cell>LE</cell><cell cols="2">.09 .15 .72 .03 .01</cell><cell>LE</cell><cell cols="3">.01 .06 .91 .01 .01</cell><cell>LE</cell><cell cols="2">.01 .06 .91 .01 .01</cell><cell>LE</cell><cell cols="2">.01 .06 .90 .01 .02</cell></row><row><cell>RI</cell><cell>.03 .02</cell><cell>.95</cell><cell>RI</cell><cell cols="2">.02 .01</cell><cell>.96 .01</cell><cell>RI</cell><cell>.02 .01</cell><cell>.96 .01</cell><cell>RI</cell><cell>.02 .01</cell><cell>.96 .01</cell></row><row><cell>BG</cell><cell cols="2">.37 .27 .21 .11 .04</cell><cell>BG</cell><cell cols="3">.06 .05 .12 .02 .75</cell><cell>BG</cell><cell cols="2">.07 .02 .07 .01 .83</cell><cell>BG</cell><cell cols="2">.06 .01 .07 .01 .85</cell></row><row><cell></cell><cell cols="2">B A F R L E R I B G</cell><cell></cell><cell cols="3">B A F R L E R I B G</cell><cell></cell><cell cols="2">B A F R L E R I B G</cell><cell></cell><cell cols="2">B A F R L E R I B G</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>89 .07 .01 .01 .01 .01</figDesc><table><row><cell></cell><cell></cell><cell cols="7">Our FROB. distance</cell><cell></cell><cell></cell><cell cols="4">Our CBH1. distance</cell></row><row><cell></cell><cell></cell><cell cols="7">(avg accuracy 0.953)</cell><cell></cell><cell></cell><cell cols="4">(avg accuracy 0.965)</cell></row><row><cell></cell><cell>FrLe</cell><cell cols="2">.90 .04</cell><cell></cell><cell></cell><cell></cell><cell>.06</cell><cell></cell><cell></cell><cell>FrLe</cell><cell cols="2">.94 .03</cell><cell></cell><cell>.03</cell></row><row><cell></cell><cell>Frnt</cell><cell cols="3">.01 .96 .03</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Frnt</cell><cell cols="3">.02 .95 .03</cell></row><row><cell></cell><cell>FrRi</cell><cell></cell><cell cols="2">.03 .93</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.04</cell><cell>FrRi</cell><cell></cell><cell cols="2">.03 .94</cell><cell>.03</cell></row><row><cell></cell><cell>Left</cell><cell>.01</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.95</cell><cell></cell><cell>.04</cell><cell>Left</cell><cell>.02</cell><cell></cell><cell></cell><cell>.98</cell></row><row><cell></cell><cell>Back</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.0</cell><cell></cell><cell>Back</cell><cell></cell><cell></cell><cell></cell><cell>1.0</cell></row><row><cell></cell><cell>Rght</cell><cell></cell><cell></cell><cell>.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.98</cell><cell>Rght</cell><cell></cell><cell></cell><cell>.02</cell><cell>.98</cell></row><row><cell></cell><cell></cell><cell>F rL e</cell><cell>F rn t</cell><cell cols="2">F rR</cell><cell>i</cell><cell>L e ft</cell><cell>B a c k</cell><cell>R g h t</cell><cell></cell><cell>F rL e</cell><cell>F rn t</cell><cell>F rR</cell><cell>i</cell><cell>L e ft</cell><cell>B a c k</cell><cell>R g h t</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell></row><row><cell></cell><cell></cell><cell cols="7">Our FROB. distance</cell><cell></cell><cell></cell><cell cols="4">Our CBH1. distance</cell></row><row><cell></cell><cell></cell><cell cols="7">(avg accuracy 0.807)</cell><cell></cell><cell></cell><cell cols="4">(avg accuracy 0.810)</cell></row><row><cell></cell><cell>FrLe</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>FrLe</cell><cell cols="4">.89 .07 .01 .01 .02 .01</cell></row><row><cell></cell><cell>Frnt</cell><cell cols="3">.03 .87 .04</cell><cell></cell><cell></cell><cell></cell><cell>.06</cell><cell></cell><cell>Frnt</cell><cell cols="3">.02 .87 .04</cell><cell>.07</cell></row><row><cell></cell><cell>FrRi</cell><cell cols="3">.02 .09 .85</cell><cell></cell><cell></cell><cell></cell><cell cols="2">.02 .01</cell><cell>FrRi</cell><cell cols="3">.01 .07 .88</cell><cell>.01 .01</cell></row><row><cell></cell><cell>Left</cell><cell cols="8">.22 .02 .02 .67 .06 .02</cell><cell>Left</cell><cell cols="4">.21 .02 .02 .67 .06 .02</cell></row><row><cell></cell><cell>Back</cell><cell cols="8">.01 .01 .01 .02 .92 .04</cell><cell>Back</cell><cell>.01</cell><cell></cell><cell cols="2">.01 .02 .92 .04</cell></row><row><cell></cell><cell>Rght</cell><cell cols="8">.03 .03 .23 .01 .05 .65</cell><cell>Rght</cell><cell cols="4">.02 .03 .26 .01 .06 .62</cell></row><row><cell></cell><cell></cell><cell>F rL e</cell><cell>F rn t</cell><cell>F rR</cell><cell cols="2">i</cell><cell>L e ft</cell><cell>B a c k</cell><cell>R g h t</cell><cell></cell><cell>F rL e</cell><cell>F rn t</cell><cell cols="2">F rR i</cell><cell>L e ft</cell><cell>B a c k</cell><cell>R g h t</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(c)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(d)</cell></row><row><cell></cell><cell>Back</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Front-Le</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Front-Right</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Right</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Le</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(e)</cell><cell>Front</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 2</head><label>2</label><figDesc>Pan, tilt and roll error statistics over evaluation data of IDIAP dataset.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 3</head><label>3</label><figDesc>Pan error statistics over evaluation data of CAVIAR dataset for both non-occlluded and occluded cases.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Fig. 9. Comparative study of the performances of the proposed statistical classification framework.</figDesc><table><row><cell cols="2">Dataset Obj. Size 25 × 25</cell><cell>κI d -0.0509</cell><cell cols="4">dE avg acc. dCBH1 avg acc. 78% 80%</cell><cell cols="2">Dataset</cell><cell cols="2">Obj. Size 25 × 25</cell><cell>κI d -0.0571</cell><cell>dE avg acc. dCBH1 avg acc. 74% 76%</cell></row><row><cell>QMUL</cell><cell>38 × 38</cell><cell>-0.0448</cell><cell>89%</cell><cell></cell><cell>90%</cell><cell></cell><cell cols="2">QMUL  †</cell><cell>38 × 38</cell><cell>-0.0470</cell><cell>86%</cell><cell>87%</cell></row><row><cell></cell><cell>50 × 50</cell><cell>-0.0361</cell><cell>91%</cell><cell></cell><cell>92%</cell><cell></cell><cell></cell><cell></cell><cell>50 × 50</cell><cell>-0.0345</cell><cell>90%</cell><cell>91%</cell></row><row><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell></row><row><cell cols="2">Dataset Obj. Size 25 × 25</cell><cell>κI d -0.0571</cell><cell cols="4">dE avg acc. dCBH1 avg acc. 88% 90%</cell><cell cols="2">Dataset</cell><cell cols="2">Obj. Size 25 × 25</cell><cell>κI d -0.607</cell><cell>dE avg acc. dCBH1 avg acc. 62% 66%</cell></row><row><cell>HIIT</cell><cell>38 × 38</cell><cell>-0.0571</cell><cell>95%</cell><cell></cell><cell>96%</cell><cell></cell><cell cols="2">HOCoffe</cell><cell cols="2">38 × 38</cell><cell>-0.0430</cell><cell>78%</cell><cell>80%</cell></row><row><cell></cell><cell>50 × 50</cell><cell>-0.0571</cell><cell>96%</cell><cell></cell><cell>96%</cell><cell></cell><cell></cell><cell></cell><cell cols="2">50 × 50</cell><cell>-0.0345</cell><cell>80%</cell><cell>80%</cell></row><row><cell></cell><cell></cell><cell>(c)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(d)</cell></row><row><cell></cell><cell></cell><cell cols="3">Dataset Obj. Size 66 × 31</cell><cell>κI d -0.0320</cell><cell></cell><cell cols="4">dE avg acc. dCBH1 avg acc. 71% 73%</cell></row><row><cell></cell><cell></cell><cell cols="2">HOC</cell><cell>99 × 47</cell><cell>-0.0230</cell><cell></cell><cell>77%</cell><cell></cell><cell cols="2">78%</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">132 × 62 -0.0192</cell><cell></cell><cell>78%</cell><cell></cell><cell cols="2">78%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(e)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Avg Pan Err.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Avg Pan Err.</cell></row><row><cell>Dataset</cell><cell></cell><cell>Obj. Size 25 × 25</cell><cell cols="2">κI d -0.0437 27.15 dE</cell><cell>dCBH1 25.63</cell><cell cols="2">Dataset</cell><cell></cell><cell cols="2">Obj. Size 25 × 25</cell><cell>dE -0.045 41.00 κI d</cell><cell>dCBH1 38.00</cell></row><row><cell cols="2">CAVIAR (Clean)</cell><cell>38 × 38</cell><cell cols="2">-0.0426 22.65</cell><cell>21.58</cell><cell cols="4">CAVIAR (Occluded)</cell><cell>38 × 38</cell><cell>-0.044 37.00</cell><cell>36.33</cell></row><row><cell></cell><cell></cell><cell>50 × 50</cell><cell cols="2">-0.0415 19.74</cell><cell>19.73</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50 × 50</cell><cell>-0.043 36.90</cell><cell>35.26</cell></row><row><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Avg Pan Err.</cell><cell cols="2">Avg Tilt Err.</cell><cell>Avg Roll Err.</cell></row><row><cell></cell><cell></cell><cell cols="2">Dataset Obj. Size 38 × 38</cell><cell cols="2">dE -0.0293 16.18 κI d</cell><cell></cell><cell>dCBH1 16.07</cell><cell>dE 6.67</cell><cell>dCBH1 6.47</cell><cell>dE 5.02</cell><cell>dCBH1 4.97</cell></row><row><cell></cell><cell></cell><cell>IDIAP</cell><cell>56 × 56</cell><cell cols="2">-0.0175 12.35</cell><cell></cell><cell>12.03</cell><cell>5.18</cell><cell>5.01</cell><cell>4.94</cell><cell>4.82</cell></row><row><cell></cell><cell></cell><cell></cell><cell>75 × 75</cell><cell cols="2">-0.0143 10.90</cell><cell></cell><cell>10.30</cell><cell>4.81</cell><cell>4.46</cell><cell>4.65</cell><cell>4.33</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(c)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Actually, we did not check whether d CBH1 is actually a distance in a rigorous mathematical sense. It is indeed symmetric, positive, and zero if and only if the points coincide, but one should further prove that it fulfils the triangle inequality; however, for our comparison purposes, we can safely call it, informally, distance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>i-LIDS dataset, http://tna.europarchive.org/ 20100413151426/scienceandresearch.homeoffice.gov.uk/hosdb/ cctv-imaging-technology/i-lids/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.SUBMISSION TO IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social Signal Processing: Survey of an emerging domain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vinciarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing Journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1743" to="1759" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tracking the visual focus of attention for a varying number of wandering people</title>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Odobez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gatica-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE PAMI</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic reasoning about causal events in surveillance video</title>
		<author>
			<persName><forename type="first">N</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Image and Video Processing</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Social interaction discovery by statistical analysis of f-formations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Paggetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fossati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Bue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tosato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Menegaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of British Machine Vision Conference</title>
		<meeting>British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Look at who&apos;s talking: Voice activity detection by automated gesture analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pesarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vinciarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crocco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Interactive Human Behavior Analysis in Open or Public Spaces</title>
		<meeting>the Workshop on Interactive Human Behavior Analysis in Open or Public Spaces</meeting>
		<imprint>
			<date type="published" when="2011">InterHub 2011</date>
			<biblScope unit="page">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pedestrian detection via classification on riemannian manifolds</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1713" to="1727" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Region covariance: A fast descriptor for detection and classification</title>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="589" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using covariance matrices for unsupervised texture segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Human Detection from Videos Using Covariance Features</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Odobez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eighth International Workshop on Visual Surveillance</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimizing discrimination-efficiency tradeoff in integrating heterogeneous local features for object detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">H</forename><surname>Karcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Riemannian Center of Mass and Mollifier Smoothing</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="509" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Lie groups</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duistermaat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kolk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-class classification on riemannian manifolds for video surveillance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tosato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farenzena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="378" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">886</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient additive kernels via explicit feature maps</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR. IEEE</title>
		<meeting>CVPR. IEEE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3539" to="3546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Class-specific hough forests for object detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Region covariance: A fast descriptor for detection and classification</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="589" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part based models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Detection and segmentation of multiple, partially occluded objects by grouping, merging, assigning part detection responses</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="204" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Integral channel features</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Monocular pedestrian detection: Survey and experiments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2179" to="2195" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A cognitive and unsupervised map adaptation approach to the recognition of the focus of attention from head pose</title>
		<author>
			<persName><forename type="first">J</forename><surname>Odobez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICME. IEEE</title>
		<meeting>ICME. IEEE</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1379" to="1382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pictorial structures revisited: People detection and articulated pose estimation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1014" to="1021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Head pose classification in Crowded Scenes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Orozco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Detecting pedestrians by learning shapelet features</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sabzmeydani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Discriminative local binary patterns for human detection in personal album</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A performance evaluation of single and multi-feature people detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wojek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="82" to="91" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Head pose estimation in computer vision: A survey</title>
		<author>
			<persName><forename type="first">E</forename><surname>Murphy-Chutorian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="607" to="626" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An HOG-LBP human detector with partial occlusion handling</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV. IEEE</title>
		<meeting>ICCV. IEEE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">New features and insights for pedestrian detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Walk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Majer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR. IEEE</title>
		<meeting>CVPR. IEEE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1030" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Part-based feature synthesis for human detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Hillel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Krupka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="127" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A pose-invariant descriptor for human detection and segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="423" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Head pose estimation in computer vision: A survey</title>
		<author>
			<persName><forename type="first">E</forename><surname>Murphy-Chutorian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="607" to="626" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evaluation of multiple cue head pose estimation algorithms in natural environements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Odobez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICME. IEEE</title>
		<meeting>ICME. IEEE</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1330" to="1333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Real time head pose estimation with random regression forests</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fanelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Supervised local subspace learning for continuous head pose estimation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Storer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Estimating gaze direction from lowresolution faces in video</title>
		<author>
			<persName><forename type="first">N</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="402" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A Local Basis Representation for Estimating Human Pose from Cluttered Images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACCV</title>
		<meeting>ACCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="50" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Poselets: Body part detectors trained using 3d human pose annotations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1365" to="1372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Improved Human Parsing with a Full Relational Model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="227" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Human Detection Using Partial Least Squares Analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Integrated pedestrian classification and orientation estimation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR. IEEE</title>
		<meeting>CVPR. IEEE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="982" to="989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient similarity search for covariance matrices via the jensenbregman logdet divergence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="2399" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Principal geodesic analysis for the study of nonlinear statistics of shape</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV Workshop</title>
		<meeting>ECCV Workshop</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="995" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Clinical DT-MRI estimation, smoothing, and fiber tracking with log-Euclidean metrics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. MI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1472" to="1482" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Geometric means in a novel vector space structure on symmetric positivedefinite matrices</title>
		<author>
			<persName><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">328</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust statistics on Riemannian manifolds via the geometric median</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Manifold valued statistics, exact principal geodesic analysis and the effect of linear approximations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lauze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hauberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient similarity search for covariance matrices via the jensenbregman logdet divergence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IICV. IEEE</title>
		<meeting>IICV. IEEE</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2399" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Riemannian Geometry -A modern introduction</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chavel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Linear algebra: a geometric approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sernesi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Mixed memory markov models: Decomposing complex stochastic processes as mixtures of simpler ones</title>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="75" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Local features and kernels for classification of texture and object categories: a comprehensive study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">2007</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Piotr&apos;s Image and Video Matlab Toolbox (PMT)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<ptr target="http://vision.ucsd.edu/∼pdollar/toolbox/doc/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">ARCO (arrray of covariance matrices), code and datasets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tosato</surname></persName>
		</author>
		<ptr target="http://sites.google.com/site/diegotosato/ARCO" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Gourier</surname></persName>
		</author>
		<ptr target="http://www-prima.imag.fr/Pointing04/data-face.html" />
		<title level="m">Head pose image database (pointing&apos;04 icpr workshop)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The cmu multi-pose, illumination, and expression (multi-pie) face database</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<idno>TR-07-08</idno>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University Robotics Institute</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">IDIAP head pose database</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Odobez</surname></persName>
		</author>
		<ptr target="http://www.idiap.ch/dataset/headpose" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Head Pose Estimation in Single-and Multi-view Environments -Results on the CLEAR&apos;07 Benchmarks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Voit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimodal Technologies for Perception of Humans, ser</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer Berlin / Heidelberg</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4625</biblScope>
			<biblScope unit="page" from="307" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">CAVIAR case scenarios</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
		<ptr target="http://groups.inf.ed.ac.uk/vision/CAVIAR/CAVIARDATA1/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Evaluating appearance models for recongnition, reacquisition and tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PETS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">ETHZ dataset for appearance-based modeling</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<ptr target="http://www.liv.ic.unicamp.br/∼wschwartz/datasets.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/∼cjlin/libsvm/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">From camera head pose to 3d global room head pose using multiple camera views</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Odobez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l. Workshop Classification of Events Activities and Relationships (CLEAR 07)</title>
		<title level="s">ser. Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Learning large margin likelihoods for realtime head pose tracking</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Odobez</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1819298.1819450" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th IEEE international conference on Image processing, ser. ICIP&apos;09</title>
		<meeting>the 16th IEEE international conference on Image processing, ser. ICIP&apos;09<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2565" to="2568" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
