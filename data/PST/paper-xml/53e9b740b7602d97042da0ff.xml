<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Music Recommendation and Discovery</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Òscar</forename><surname>Celma</surname></persName>
							<email>ocelma@bmat.com</email>
						</author>
						<author>
							<persName><forename type="first">Springer</forename><surname>Heidelberg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dordrecht</forename><surname>London</surname></persName>
						</author>
						<author>
							<persName><forename type="first">New</forename><surname>York</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Claudia</forename><forename type="middle">Lomelí</forename><surname>Buyoli</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Gillet</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hannah</forename><surname>Donovan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Norman</forename><surname>Casagrande</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Lamere</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Owen</forename><surname>Meyers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Terry</forename><surname>Jones</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kurt</forename><surname>Jacobson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Douglas</forename><surname>Turnbull</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><surname>Slee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kalevi</forename><surname>Kilkki</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Perfecto</forename><surname>Herrera</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alberto</forename><surname>Lumbreras</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Mcennis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xavier</forename><surname>Amatriain</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Long Fail, and Long Play</orgName>
								<orgName type="department" key="dep2">Digital Music Space Òscar Celma BMAT</orgName>
								<orgName type="laboratory">Music Recommendation and Discovery The Long Tail</orgName>
								<address>
									<postCode>49 08024</postCode>
									<settlement>Bruniquer, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Royal Holloway</orgName>
								<orgName type="institution" key="instit2">University of London</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Music Recommendation and Discovery</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BDA46EC7859E770CCC389DB07FD89459</idno>
					<idno type="DOI">10.1007/978-3-642-13287-2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Foreword</head><p>In the last 15 years we have seen a major transformation in the world of music. Musicians use inexpensive personal computers instead of expensive recording studios to record, mix and engineer music. Musicians use the Internet to distribute their music for free instead of spending large amounts of money creating CDs, hiring trucks and shipping them to hundreds of record stores. As the cost to create and distribute recorded music has dropped, the amount of available music has grown dramatically. Twenty years ago a typical record store would have music by less than ten thousand artists, while today online music stores have music catalogs by nearly a million artists.</p><p>While the amount of new music has grown, some of the traditional ways of finding music have diminished. Thirty years ago, the local radio DJ was a music tastemaker, finding new and interesting music for the local radio audience. Now radio shows are programmed by large corporations that create playlists drawn from a limited pool of tracks. Similarly, record stores have been replaced by big box retailers that have ever-shrinking music departments. In the past, you could always ask the owner of the record store for music recommendations. You would learn what was new, what was good and what was selling. Now, however, you can no longer expect that the teenager behind the cash register will be an expert in new music, or even be someone who listens to music at all.</p><p>With so much more music available, listeners are increasingly relying on tools such as automatic music recommenders to help them find music. Instead of relying on DJs, record store clerks or their friends to get music recommendations, listeners are also turning to machines to guide them to new music. This raises a number of questions: How well do these recommenders work? Do they generate novel, interesting and relevant music recommendations? How far into the Long Tail do they reach? Do they create feedback loops that drive listeners to a diminishing pool of popular artists? What affect will automatic music recommenders have on the collective music taste?</p><p>In this book, Dr. Celma guides us through the world of automatic music recommendation. He describes how music recommenders work, explores some of the limitations seen in current recommenders, offers techniques for evaluating the effecvii viii Foreword tiveness of music recommendations and demonstrates how to build effective recommenders by offering two real-world recommender examples. As we rely more and more on automatic music recommendation it is important for us to understand what makes a good music recommender and how a recommender can affect the world of music. With this knowledge we can build systems that offer novel, relevant and interesting music recommendations drawn from the entire world of available music.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Austin, TX, March 2010</head><p>Paul Lamere Director of Developer Community</p><p>The Echo Nest Preface I met Timothy John Taylor (aka Tyla<ref type="foot" target="#foot_0">1</ref> ) in 2000, when he established in Barcelona.</p><p>He was playing some acoustic gigs, and back then I used to record a lot of concerts with a portable DAT. After a remarkable night, I sent him an email telling that I recorded the concert, so I could give him a copy. After all, we were living in the same city. He said "yeah sure, come to my house, and give me the CD's". So there I am, another nervous fan, trying to look cool while walking to his home. . . My big brother, the first "music recommender" that I reckon, bought a vynil of The Dogs d'Amour in 1989. He liked the art cover-painted by the singer, Tyla-so he purchased it. The English rock band was just starting to be somewhat worldwide famous. They were in the UK charts, and also had played in the Top of the Pops. Then, they moved to L.A. to record an album. Rock magazines used to talk about their chaotic and unpredictable concerts, as well as the excesses of the members. Both my brother and myself felt in love with the band after listening to the album.</p><p>Tyla welcomes me at his home. We have a long chat surrounded by vintage guitars and amps, and unfinished paintings. I give him a few CDs including his last concert in Barcelona, as well as two other gigs that I recorded one year before. All of a sudden, he mentions the last project he is involved in: he has just re-joined the classic Dogs d'Amour line-up, after more than six years of inactivity. They were recording a new album. He was very excited and happy (ever after) about the project. I asked why they decided to re-join after all these years. He said: We've just noticed how much interest there is on the Internet about the band. Indeed, not being able to find the old releases made lot of profit for eBayers and the like.</p><p>When I joined The Dogs d'Amour Yahoo! mailing list in 1998 we were just a few dozens of fans that were discussing about the disbanded band, their solo projects, and related artists to fall upon. One day, the members of the band joined the list, too. It was like a big-virtual-family. Being part of the mailing list allowed us to have updated information about what the band was up to, and chat with them. One day they officially announced that the band was active again, and they had a new album x Preface ready (. . . I already knew that!). Sadly, the reunion only lasted for a couple of years, ending with a remarkable UK Monsters of Rock tour supporting Alice Cooper.</p><p>During the last few years, Tyla has released a set of solo albums. He has made his life based on viral marketing-including the help from fans-setting gigs, selling albums and paintings online, as well as in the concerts. Nowadays, he has much more control of the whole creative process than ever. The income allows him not needing any record label-he had some bad experiences with record labels back in the 80's epoch, when they controlled everything. Moreover, from the fan's point of view, living in the same city allowed me to help him in the creation process of a few albums. I even played some guitar bits in a couple of songs (and since then, I own one of his vintage Strat).</p><p>Up to now, he is still very active; he plays, paints, manages his tours, and a long etcetera. Yet, he is in the "long tail" of popularity. It is difficult to discover these type of artists when using music recommenders that do not support "less-known" artists. Indeed, for a music lover is very rewarding to discover unknown artists that fit into her music taste. In my case, music serendipity dates from 1989; with a cool album cover, and the good music taste of my brother. Now, I am willing to experience these feelings again. . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mexico City, March 2010 Òscar Celma Chief Innovation Officer Barcelona Music and Audio Technologies (BMAT)</head><p>Chapter 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction 1.1 Motivation</head><p>In recent years typical music consumption behaviour has changed dramatically. Personal music collections have grown, aided by technological improvements in networks, storage, portability of devices and Internet services. The number and the availability of songs have de-emphasised their value; it is usually the case that users own many digital music files that they have only listened to once, or not at all. It seems reasonable to suppose that with efficient ways to create a personalised order of users' collections, as well as ways to explore hidden "treasures" inside them, the value of their music collections would drastically increase.</p><p>Users own huge music collections that need proper storage and labelling. Search within digital collections gives rise to new methods for accessing and retrieving data. But, sometimes, there is no metadata-or only file names-to inform us of the audio content, and that is not enough for an effective navigation and discovery of the music collection. Users can, then, get lost searching in their own digital collections. Furthermore, the web is increasingly becoming the primary source of music titles in digital form. With millions of tracks available from thousands of websites, finding the right songs, and being informed of new music releases has become problematic.</p><p>On the digital music distribution front, there is a need to find ways of improving music retrieval and personalisation. Artist, title, and genre information might not be the only criteria to help music consumers find music they like. This is achieved using cultural or editorial metadata ("this artist is somehow related to that one"), or exploiting existing purchasing behaviour data ("since you bought this artist, you might also enjoy this one"). A largely unexplored-and potentially interestingcomplement is using semantic descriptors automatically extracted from music files, or gathered from the community of users, via social tagging. All this information can be combined and used for music recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.1">Academia</head><p>With one early exception, Shardanand's masters thesis <ref type="bibr">[1]</ref> published in 1994, research in music recommendation did not really begin until 2001. To show the increasing interest in this field, Table <ref type="table" target="#tab_0">1</ref>.1 presents the number of papers related to music recommendation since 2001. The table shows the list of related papers indexed by Google Scholar. 1 From 2004 onwards we have seen a sharp increase in the number of papers published in this field. A closer look, focusing on the Music Information Retrieval (MIR) community, also shows an increasing interest in music recommendation and discovery. Table <ref type="table" target="#tab_0">1</ref>.2 shows the list of related papers, presented in ISMIR (International Society for Music Information Retrieval) 2 conferences since 2000. The early papers focused on content-based methods <ref type="bibr">[2,</ref><ref type="bibr">3]</ref>, and user profiling aspects <ref type="bibr">[4,</ref><ref type="bibr">5]</ref>. Since 2005, research community attention has broadened to other areas, including: prototype systems <ref type="bibr">[6]</ref><ref type="bibr">[7]</ref><ref type="bibr">[8]</ref>, playlist generation <ref type="bibr">[9]</ref><ref type="bibr">[10]</ref><ref type="bibr">[11]</ref><ref type="bibr">[12]</ref><ref type="bibr">[13]</ref><ref type="bibr">[14]</ref><ref type="bibr">[15]</ref><ref type="bibr">[16]</ref><ref type="bibr">[17]</ref>, social tagging <ref type="bibr">[18,</ref><ref type="bibr">19]</ref>, visual interfaces <ref type="bibr">[20]</ref>, music similarity networks <ref type="bibr">[21]</ref><ref type="bibr">[22]</ref><ref type="bibr">[23]</ref><ref type="bibr">[24]</ref>, hybrid recommendation approaches <ref type="bibr">[25]</ref><ref type="bibr">[26]</ref><ref type="bibr">[27]</ref><ref type="bibr">[28]</ref><ref type="bibr">[29]</ref>, and sociological aspects <ref type="bibr">[30]</ref><ref type="bibr">[31]</ref><ref type="bibr">[32]</ref><ref type="bibr">[33]</ref><ref type="bibr">[34]</ref>. The "Music Recommendation Tutorial" <ref type="bibr">[35]</ref>, presented in the ISMIR 2007 conference, summarises part of the work done in this field till then.  <ref type="bibr">[16,</ref><ref type="bibr">17,</ref><ref type="bibr">23,</ref><ref type="bibr">24,</ref><ref type="bibr">29,</ref><ref type="bibr">33,</ref><ref type="bibr">34]</ref> Table <ref type="table" target="#tab_0">1</ref>.2 Papers related to music recommendation presented in the ISMIR conference since 2000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.2">Industry</head><p>Recommender systems play an important role in e-Commerce. Examples such as Last.fm, Amazon, or Netflix, where the provided recommendations are critical to retain users, show that most of the product sales result from the recommendations. Greg Linden, who implemented the first recommendation engine for Amazon, states<ref type="foot" target="#foot_1">3</ref> :</p><p>(Amazon.com) recommendations generated a couple orders of magnitude more sales than just showing top sellers.</p><p>Since October 2006, this field enjoyed an increase of interest thanks to the Netflix competition. The competition offered a prize of $1,000,000 to those that improve their movie recommendation system. <ref type="foot" target="#foot_2">4</ref> Also, the Netflix competition provided the largest open dataset, containing more than 100 million movie ratings from anonymous users. The research community was challenged in developing algorithms to improve the accuracy of the current Netflix recommendation system. After 3 years of research, in July 2009, both BellKor's Pragmatic Chaos <ref type="foot" target="#foot_3">5</ref> and The Ensemble <ref type="foot" target="#foot_4">6</ref>teams did beat the 10% threshold, in both cases by blending several approaches to improve the overall result of the predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.2.1">State of the Music Industry</head><p>The Long Tail <ref type="foot" target="#foot_5">7</ref> is composed by a small number of popular items (the hits), and the rest are located in the tail of the curve <ref type="bibr">[38]</ref>. The main goal of the Long Tail economics-originated by the huge shift from physical media to digital media, and the fall in production costs-is to make everything available, in contrast to the limitations of the brick-and-mortar stores. Thus, personalised recommendations and filters are needed to help users find the right content in the digital space.</p><p>On the music side, the 2007 "State of the Industry" report by Nielsen SoundScan presents some interesting information about music consumption in the United States <ref type="bibr">[39]</ref>. Around 80,000 albums were released in 2007 (not counting music available in Myspace.com, and similar sites). However, traditional CD sales are down 31% since 2004-but digital music sales are up 490%. Indeed, 844 million digital tracks were sold in 2007, but only 1% of all digital tracks accounted for 80% of all track sales. Also, 1,000 albums accounted for 50% of all album sales, and 450,344 of the 570,000 albums sold were purchased less than 100 times.</p><p>Music consumption based on sales is biased towards a few popular artists. Ideally, by providing personalised filters and discovery tools to users, music consumption would diversify. There is a need to assist people to discover, recommend, personalise and filter the huge amount of music content. In this sense, Echo Nest, <ref type="foot" target="#foot_6">8</ref> and BMAT <ref type="foot" target="#foot_7">9</ref> companies, created out of prominent MIR research groups, provide specific solutions to solve these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">What's the Problem with Music Recommendation?</head><p>Nowadays, we have an overwhelming number of choices of which music to listen to. We see this each time we browse a non-personalised music catalog, such as Myspace or iTunes. In The Paradox of Choice <ref type="bibr">[40]</ref>, Schwartz states that we, as consumers, often become paralyzed and doubtful when facing the overwhelming number of choices. There is a need to eliminate some of the choices, and this can be achieved by providing personalised filters and recommendations to ease users' decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1">Music = Movies and Books</head><p>Several music recommendation paradigms have been proposed in recent years, and many commercial systems have appeared with more or less success. Most of these approaches apply or adapt existing recommendation algorithms, such as collaborative filtering, into the music domain.</p><p>However, music is somewhat different from other entertainment domains, such as movies or books. Tracking users' preferences is mostly done implicitly, via their listening habits (instead of asking users to explicitly rate the items). Any user can consume an item (e.g., a track or a playlist) several times, even repeatedly and continuously. Regarding the evaluation process, music recommendation allows users instant feedback via brief audio excerpts.</p><p>The context is another big difference between music and the other two domains. People consume different music in different contexts; e.g. hard-rock early in the morning, classical piano sonatas while working, and Lester Young's cool jazz while having dinner. A music recommender has to deal with complex contextual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2">Predictive Accuracy vs. Perceived Quality</head><p>Current music recommendation algorithms try to accurately predict what people will want to listen to. However, these algorithms tend to recommend popular (or well-known to the user) artists, which decreases the user's perceived quality of the recommendations. The algorithms focus, then, on predicting the accuracy of the recommendations. That is, try to make accurate predictions about what a user could listen to, or buy next, independently of how useful the provided recommendations are to the user.</p><p>Figure <ref type="figure">1</ref>.1 depicts this phenomenon. It shows Amazon similar albums for the Beatles' White Album, <ref type="foot" target="#foot_8">10</ref> based on the consumption habits of users. Top-30 recommendations for the Beatles' White Album are strictly made of other Beatles' albums (then suddenly, on the fourth page of results, there is the first non-Beatles album; Exile on Main St. by The Rolling Stones). For the system these are the most accurate recommendations and, ideally, the ones that maximise their goal-to make a user to buy more goods. Still, one might argue about the usefulness of the provided recommendations. In fact, the goals of a recommender are not always aligned with the goals of a listener. The goal of the Amazon recommender is to sell goods, whereas the goal for a user visiting Amazon may be to find some new and interesting music. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Our Proposal</head><p>In this book we emphasise the user's perceived quality, rather than the system's predictive accuracy when providing recommendations. To allow users to discover new music, recommender systems should exploit the long tail of popularity (e.g., number of total plays, or album sales) that exists in any large music collection.</p><p>Figure <ref type="figure">1</ref>.2 depicts the long tail of popularity, and how recommender systems should help us in finding interesting information <ref type="bibr">[38]</ref>. Personalised filters assist us in filtering the available content, and in selecting those-potentially-novel and interesting items according to the user's profile. In this sense, the algorithm strengthens the user's perceived quality and usefulness of the recommendations. Two key elements to drive the users from the head to the tail of the curve are novelty, and personalised relevance. Effective recommendation systems should promote novel and relevant material (non-obvious recommendations), taken primarily from the tail of a distribution, rather than focus on accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1">Novelty and Relevance</head><p>Novelty is a property of a recommender system that promotes unknown items to a user. Novelty is the opposite of the user's familiarity with the recommended items. The Long Tail of items in a recommender system. An important role of a recommender is to drive the user from the head region (popular items) to the long tail of the curve <ref type="bibr">[38]</ref>.</p><p>Yet, serendipity, that is novel and relevant recommendations for a given user, cannot be achieved without taking into account the user profile. Personalised relevance filters the available content, and selects those (potentially novel) items according to user preferences.</p><p>Ideally, a user should also be familiar with some of the recommended items, to improve the confidence and trust in the system. The system should also give an explanation of why the items were recommended, providing higher confidence and transparency of novel recommendations. The difficult job for a recommender is, then, to find the proper level of familiarity, novelty and relevance for each user. This way, recommendations can use the long tail of popularity. Furthermore, the proper levels of familiarity, novelty and relevance for a user will change over time. As a user becomes comfortable with the recommendations, the amount of familiar items could be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.2">Key Elements</head><p>Figure <ref type="figure">1</ref>.3 depicts the main elements involved in our music recommendation approach. The item (or user) similarity graph defines the relationship among the items (or users). This information is used for recommending items (or like-minded people) to a given user, based on her preferences. The long tail curve models the popularity of the items in the dataset, according to the shared knowledge of the whole community. The user profile is represented along the popularity curve, using her list of preferred items.</p><p>Using the information from the similarity graph, the long tail of item popularity, and the user profile, we should be able to provide the proper level of familiarity, novelty and relevant recommendations to the users. Finally, an assessment of the provided recommendations is needed. This is done in two complementary ways. First, using a novel user-agnostic evaluation method based on the analysis of the item (or user) similarity network, and the item popularity. Secondly, with a userbased evaluation, that provides feedback on the list of recommended items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Summary of Contributions</head><p>The main contributions of this book are:</p><p>1. A formal definition of the recommendation problem, including the key elements that affect the recommendations provided by a system. Also, we present the existing recommendation methods to recommend items (and also like-minded people) to users, and we mention the pros and cons of each approach. 2. An instantiation of the general recommenddation problem for the music domain, highlighting its common use cases, as well as presenting different approaches to user profiling and modelling, and how to link it with the the musical items (i.e. artists and songs). We also present the main elements that describe the musical items, using editorial, cultural, and audio-based descriptors. 3. A novel network-based evaluation method (or user-agnostic) for recommender systems, based on the analysis of the item (or user) similarity network, and the item popularity. This method has the following properties:</p><p>a. it measures the novelty component of a recommendation algorithm, b. it makes use of complex network analysis to analyse the similarity graph, c. it models the item popularity curve, d. it combines both the complex network and the item popularity analysis to determine the underlying characteristics of the recommendation algorithm, and e. it does not require any user intervention in the evaluation process.</p><p>We apply this evaluation method in the music domain, using large-scale artist and user similarity networks. <ref type="bibr">4</ref>. A user-centric evaluation based on the immediate feedback of the provided recommendations. This evaluation method has the following advantages (compared to other system-oriented evaluations):</p><p>a. it measures the novelty factor of a recommendation algorithm in terms of user knowledge, b. it measures the relevance (e.g., like it or not) of the recommendations, and c. the users provide immediate feedback to the evaluation system, so the system can react accordingly.</p><p>This method complements the previous, user-agnostic, evaluation approach. We use this method to evaluate three different music recommendation approaches (social-based, content-based, and a hybrid approach using expert human knowledge). In this experiment, 288 subjects rated their personalised recommendations in terms of novelty (does the user know the recommended song/artist?), and relevance (does the user like the recommended song?). 5. A music search engine, named Searchsounds, that allows users to discover unknown music mentioned on music-related blogs. Searchsounds provides keyword based search, as well as the exploration of similar songs using audio similarity. 6. A system prototype, named FOAFing the music, to provide music recommendations based on the user preferences and her listening habits. The main goal of the Foafing the Music system is to recommend, to discover and to explore music content; based on user profiling, context-based information (extracted from music related RSS feeds), and content-based descriptions (automatically extracted from the audio itself). Foafing the Music allows users to:</p><p>a. get new music releases from iTunes, Amazon, Yahoo Shopping, etc. b. download (or stream) audio from MP3-blogs and Podcast sessions, c. discover music with radio-a-la-carte (i.e., personalised playlists), d. view upcoming concerts happening near the user's location, and e. read album reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Book Outline</head><p>This book is structured as follows: Chap. 2 introduces the basics of the recommendation problem, and presents the general framework that includes user preferences and representation. Then, Chap. 3 adapts the recommendation problem to the music domain, and presents related work in this area. Once the users, items, and recommendation methods are presented, Chap. 4 introduces the Long Tail model and its usage in recommender systems. Chapters 5, 6 and 7 present the different ways of evaluating and comparing different recommendation algorithms. Chapter 5 presents the existing metrics for system-, network-, and user-centric approaches. Then, Chap. 6 presents a complement to the classic system-centric evaluation, focusing on the analysis of the item (or user) similarity network, and its relationships with the popularity of the items. Chapter 7 complements the previous approach by entering the users in the evaluation loop, allowing them to evaluate the quality of the recommendations via immediate feedback. Chapter 8 presents two real prototypes. These systems, named Searchsounds and FOAFing the music show how to exploit music related content that is available on the web, for music discovery and recommendation. Chapter 9 draws some conclusions and discusses open issues and future work. To summarise the outline of the book, Fig. <ref type="figure">1</ref>.4 presents an extension of Fig. <ref type="figure">1</ref>.3, including the main elements of the book and its related chapters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 2</head><p>The Recommendation Problem</p><p>Generally speaking, the reason people could be interested in using a recommender system is that they have so many items to choose from-in a limited period of time-that they cannot evaluate all the possible options. A recommender should be able to select and filter all this information to the user. Nowadays, the most successful recommender systems have been built for entertainment content domains, such as: movies, music, or books. This chapter is structured as follows: Sec. 2.1 introduces a formal definition of the recommendation problem. After that, Sec. 2.2 presents some use cases to stress the possible usages of a recommender. Section 2.3 presents the general model of the recommendation problem. An important aspect of a recommender system is how to model the user preferences and how to represent a user profile. This is discussed in Sec. 2.4. After that, Sec. 2.5 presents the existing recommendation methods to recommend items (and also like-minded people) to users. Finally, Sec. 2.6 presents some key elements that affect the recommendation problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Formalisation of the Recommendation Problem</head><p>Intuitively, the recommendation problem can be split into two subproblems. The first one is a prediction problem, and is about the estimation of the items' likeliness for a given user. The second problem is to recommend a list of N items-assuming that the system can predict likeliness for yet unrated items. Actually, the most relevant problem is the estimation. Once the system can estimate items into a totally ordered set, the recommendation problem reduces to list the top-N items with the highest estimated value.</p><p>• The prediction problem can be formalised as follows <ref type="bibr">[1]</ref>: Let U = {u 1 , u 2 ,...u m } be the set of all users, and let I = {i 1 , i 2 ,...i n } be the set of all possible items that can be recommended.</p><p>Each user u i has a list of items I u i . This list represents the items that the user has expressed her interests. Note that I u i ⊆ I, and it is possible that I u i be empty, <ref type="foot" target="#foot_12">1</ref>I u i = / 0 . Then, the function, P u a ,i j is the predicted likeliness of item i j for the active user u a , such as i j / ∈ I u a . • The recommendation problem is reduced to bringing a list of N items, I r ⊂ I, that the user will like the most (i.e. the ones with higher P u a ,i j value). The recommended list should not contain items from the user's interests, i.e. I r ∩ I u i = / 0.</p><p>The space I of possible items can be very large. Similarly, the user space U, can also be enormous. In most recommender systems, the prediction function is usually represented by a rating. User ratings are triples u, i, r where r is the value assigned-explicit or implicitly-by the user u to a particular item i. Usually, this value is a real number (e.g. from 0 to 1), a value in a discrete range (e.g. from 1 to 5), or a binary variable (e.g. like/dislike).</p><p>There are many approaches to solve the recommendation problem. One widely used approach is when the system stores the interaction (implicit or explicit) between a user and the item set. The system can provide informed guesses based on the interaction that all the users have provided. This approximation is called collaborative filtering. Another approach is to collect information describing the items and then, based on the user preferences, the system is able to predict which items the user will like the most. This approach is generally known as content-based filtering, as it does not rely on other users' ratings but on the description of the items. Context-based filtering approach uses contextual information about the items to describe them. Another approach is demographic filtering, that stereotypes the kind of users that like a certain item. Finally, the hybrid approach combines some of the previous approaches. Section 2.5 presents all these approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Use Cases</head><p>Herlocker et al. identify some common usages of a recommender system <ref type="bibr">[2]</ref>:</p><p>• Find good items. The aim of this use case is to provide a ranked list of items, along with a prediction of how much the user would like each item. Ideally, a user would expect some novel items that are unknown to the user, as well as some familiar items, too. • Find all good items. The difference of this use case from the previous one is with regard the coverage. In this case, the false positive rate should be lower, thus presenting items with a higher precision. • Recommend sequence. This use case aims at bringing to the user an ordered sequence of items that is pleasing as a whole. A paradigmatic example is a music recommender's automatic playlist generation.</p><p>• Just browsing. In this case, users find pleasant to browse into the system, even if they are not willing to purchase any item. Simply as an entertainment. • Find credible recommender. Users do not automatically trust a recommender.</p><p>Then, they "play around" with the system to see if the recommender does the job well. A user interacting with a music recommender will probably search for one of her favourite artists, and check the output results (e.g. similar artists, playlist generation, etc.) • Express self. For some users is important to express their opinions. A recommender that offers a way to communicate and interact with other users (via forums, weblogs, etc.) allows the self-expression of users. Thus, other users can get more information-from tagging, reviewing or blogging processes-about the items being recommended to them. • Influence others. This use case is the most negative of the ones presented. There are some situations where users might want to influence the community in viewing or purchasing a particular item. For example: Movie studios could rate high their latest new release, to push others to go and see the movie. In a similar way, record labels could try to promote their artists into the recommender.</p><p>All these use cases are important when evaluating a recommender. The first task of the evaluators should be to identify the most important use cases for which the recommender will be used, and base their decisions on that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">General Model</head><p>The main elements of a recommender are the users and the items. Users need to be modelled in a way that the recommender can exploit their profiles and preferences. Besides, an accurate description of the items is also crucial to achieve good results when recommending items to users.</p><p>Figure <ref type="figure">2</ref>.1 describes the major entities and processes involved in the recommendation problem. The first step is to model both the users and the items, and it is presented in Sec. 2.4. After that, two type of recommendations can be computed; presenting the recommended items to the user (Top-N predicted items), and matching like-minded people (Top-N predicted neighbours). Once the user gets a list of recommended items, she can provide feedback, so the system can update her profile accordingly (profile adaptation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">User Profile Representation</head><p>There are two key elements when describing user preferences: the generation and maintenance of the profiles, and the exploitation of the profile using a recommendation algorithm <ref type="bibr">[3]</ref>. On the one hand, profile generation involves the representation, initial generation, and adaptation techniques. On the other hand, profile exploitation involves the information filtering method used (i.e. the recommendation method), the matching between a user profile and the items, and the matching between user profiles (i.e. creation of neighbourhoods).</p><p>There are several approaches to represent user preferences. For instance, using the history of purchases in an e-Commerce website, web usage mining (analysis of the links, and time spent in a webpage), the listening habits (songs that a user listens to), etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Initial Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.1">Empty</head><p>An important aspect of a user profile is its initialisation. The simplest way is to create an empty profile, that will be updated as soon as the user interacts with the system. However, the system will not be able to provide any recommendation until the user has been into the system for a while.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.2">Manual</head><p>Another approach is to manually create a profile. In this case, a system might ask to the users to register their interests (via tags, keywords or topics) as well as some demographic information (e.g. age, marital status, gender, etc.), geographic data (city, country, etc.) and psychographic data (interests, lifestyle, etc.). The main drawback is the user's effort, and the fact that maybe some interests could still be unknown by the user himself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.3">Data Import</head><p>To avoid the manually creation of a profile, the system can ask to the user for available, external, information that already describes her. In this case, the system only has to import this information from the external sources that contain relevant information of the user. <ref type="foot" target="#foot_13">2</ref> Besides, there have been some attempts to allow users to share their own interests in a machine-readable format (e.g. XML), so any system can use it and extend it. An interesting proposal is the Attention Profile Markup Language (APML). <ref type="foot" target="#foot_14">3</ref>The following example <ref type="foot" target="#foot_15">4</ref> shows a fragment of an APML file derived from the listening habits of a last.fm user. <ref type="foot" target="#foot_16">5</ref> The APML document contains a tag cloud representation created from the tags defined in the user's top artists.</p><p>&lt;Profile name="music"&gt; &lt;ImplicitData&gt; &lt;Concepts&gt; &lt;Concept key="rock" value="1.0" /&gt; &lt;Concept key="hard rock" value="0.41770712" /&gt; &lt;Concept key="sleaze rock" value="0.39724553" /&gt; &lt;Concept key="rock n roll" value="0.3311153" /&gt; &lt;Concept key="glam rock" value="0.23445463" /&gt; &lt;Concept key="classic rock" value="0.2062444" /&gt; &lt;Concept key="singer songwriter" value="0.17533751" /&gt; &lt;Concept key="alternative" value="0.1623969" /&gt; ... &lt;/Concepts&gt; &lt;/ImplicitData&gt; &lt;/Profile&gt; Listing 2.1 Example of a user profile in APML. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.4">Training Set</head><p>Another method to gather information is using a pre-defined training set. The user has to provide feedback to concrete items, marking them as relevant or irrelevant to her interests. The main problem, though, is to select representative examples. For instance, in the music domain, the system might ask for concrete genres or styles, and filter a set of artists to be rated by the user. Figure <ref type="figure">2</ref>.2 shows an example of the iLike music recommender. Once a user created an account, the system presents a list of artists that the user has to rate. This process is usually perceived by the users as a tedious and unnecessary work. Yet, it gives some information to the system to avoid the user cold-start problem (see Sec. 2.6 for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1.5">Stereotyping</head><p>Finally, the system can gather initial information using stereotyping. This method resembles to a clustering problem. The main idea is to assign a new user into a cluster of similar users that are represented by their stereotype, according to some demographic, geographic, or psychographic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Maintenance</head><p>Once the profile has been created, it does not remain static. Therefore, user's interests might (and probably will) change. A recommender system needs up-to-date information to automatically update a user profile. User feedback may be explicit or implicit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2.1">Explicit Feedback</head><p>One option is to ask to the users for relevance feedback about the provided recommendations. Explicit feedback usually comes in the form of ratings. This type of feedback can be positive or negative. Usually, users provide more positive feedback, although negative examples can be very useful for the system.</p><p>Ratings can be in a discrete scale (e.g. from 0 to N), or a binary value (like/dislike). Yet, it is proved that sometimes users rate inconsistently <ref type="bibr">[4]</ref>, thus ratings are usually biased towards some values, and this can also depend on the user perception of the ratings' scale. Inconsistency in the ratings arouse a natural variability when the system is predicting the ratings. Herlocker et al. presents a study showing that even the best algorithm could not get beyond a Root mean squared error (RMSE) of 0.73, on a five-point scale <ref type="bibr">[2]</ref>. In <ref type="bibr">[5]</ref> the authors present an experiment where users have to rate the items several times over a period of time. Then, they calculated the RMSE between different trials. RMSE ranged between 0.557 and 0.8156, depending on the ellapsed time (an improvement of 10% in the Netflix prize equals to an RMSE of 0.8563, so any algorithm has a very small margin of error). User consistency over time has strong consequences for recommender systems based on maximising the predictive accuracy, by trying to minimise the RMSE.</p><p>Another way to gather explicit feedback is to allow users to write comments and opinions about the items. In this case, the system can present the opinions to the target user, along with the recommendations. This extra piece of information eases the decision-making process of the target user, although she has to read and interpret other users' opinions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2.2">Implicit Feedback</head><p>A recommender can also gather implicit feedback from the user. A system can infer the user preferences passively by monitoring user's actions. For instance, by analysing the history of purchases, the time spent on a webpage, the links followed by the user, the mouse movements, or analysing a media player usage (tracking the play, pause, skip and stop buttons).</p><p>However, negative feedback is not reliable when using implicit feedback, because the system can only observe positive (implicit) feedback, by analysing user's actions. On the other hand, implicit feedback is not as intrusive as explicit feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Adaptation</head><p>The system has to adapt to the changes of the users' profiles. The techniques to adapt to new interests and forget the old ones can be done in three different ways. First, done manually by the user, although this requires some extra effort to the user. Secondly, by adding new information into the user profiles, while keeping the old interests. Finally, by gradually forgetting the old interests and promoting the new ones <ref type="bibr">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Recommendation Methods</head><p>Once the user profile is created, the next step is to exploit user preferences, to provide interesting recommendations. User profile exploitation is tightly related with the method for filtering information. The method adopted for information filtering has led to the standard classification of recommender systems, that is: demographic filtering, collaborative filtering, content-based and hybrid approaches. We add another method, named context-based, which recently has grown popularity due to the feasibility of gathering external information about the items (e.g. gathering information from weblogs, analysing the reviews about the items, etc.).</p><p>The following sections present the recommendation methods for one user. It is worth to mention that another type of (group-based) recommenders also exist. These recommenders focus on providing recommendations to a group of users, thus trying to maximise the overall satisfaction of the group <ref type="bibr">[7,</ref><ref type="bibr">8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Demographic Filtering</head><p>Demographic filtering can be used to identify the kind of users that like a certain item <ref type="bibr">[9]</ref>. For example, one might expect to learn the type of person that likes a certain singer (e.g. finding the stereotypical user that listens to Jonas Brothers<ref type="foot" target="#foot_17">6</ref> band). This technique classifies the user profiles in clusters according to some personal data (age, marital status, gender, etc.), geographic data (city, country) and psychographic data (interests, lifestyle, etc.). An early example of a demographic filtering system is the Grundy system <ref type="bibr">[9]</ref>. Grundy recommended books based on personal information gathered from an interactive dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1.1">Limitations</head><p>The main problems of this method is that a system recommends the same items to people with similar demographic profiles, so recommendations are too general (or, at least, not very specific for a given user profile). Another drawback is the generation of the profile, that needs some effort from the user. Some approaches try to get (unstructured) information from the user's homepage, weblog, etc. In this case, text classification techniques are used to create the clusters and classify the users <ref type="bibr">[10]</ref>. All in all, this is the simplest recommendation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Collaborative Filtering</head><p>Collaborative filtering (CF) approach predicts user preferences for items by learning past user-item relationships. That is, the user gives feedback to the system, so the system can provide informed guesses based on the feedback (e.g. ratings) that other users have provided.</p><p>The first system that implemented the collaborative filtering method was the Tapestry project at Xerox PARC <ref type="bibr">[11]</ref>. The project coined the collaborative filtering term. Other early systems are: a music recommender named Ringo <ref type="bibr">[12,</ref><ref type="bibr">13]</ref>, and Group Lens, a system for rating USENET articles <ref type="bibr">[14]</ref>. A compilation of other relevant systems from that time period can be found in <ref type="bibr">[15]</ref>.</p><p>CF methods work by building a matrix M, with n items and m users, that contains the interaction (e.g. ratings, page views, plays, etc.) of the users with the items. Each row represents a user profile, whereas the columns are items. The value M u a ,i j is the rating of the user u a for the item i j . Figure <ref type="figure">2</ref>.3 depicts the matrix of user-item ratings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2.1">Item-Based Neighbourhood</head><p>Item-based method exploits the similarity among the items. This method looks into the set of items that a user has rated, and computes the similarity among the target item (to decide whether is worth to recommend it to the user or not). Figure <ref type="figure">2</ref>.4 depicts the co-rated items from different users. In this case it shows the similarity between items i j and i k . Note that only users u 2 and u i are taken into account, but u m-1 is not because it has not rated both items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2.4</head><p>User-item matrix with co-rated items for item-based similarity. To compute the similarity between items i j and i k , only users u 2 and u i are taken into account, but u m-1 is not because it has not rated both items (i k rating value is not set).</p><p>The first step is to obtain the similarity between two items, i and j. This similarity can be calculated using cosine similarity, Pearson correlation, adjusted cosine, or computing the conditional probability, P( j|i). Let the set of users who rated i and j be denoted by U, and r u,i denotes the rating of user u on item i. Equation (2.1) shows the definition of the cosine similarity:</p><formula xml:id="formula_0">sim(i, j) = cos(i, j) = i • j i * j = ∑ u∈U r u,i r u, j ∑ u∈U r 2 u,i ∑ u∈U r 2 u, j<label>(2.1)</label></formula><p>However, for the item-based similarity, the cosine similarity does not take into account the differences in rating scale between different users. The adjusted cosine similarity (Eq. 2.2) makes use of user average rating from each co-rated pair, and copes with the limitation of cosine similarity. ru is the average rating of the u-th user:</p><formula xml:id="formula_1">sim(i, j) = ∑ u∈U (r u,i -ru )(r u, j -ru ) ∑ u∈U (r u,i -ru ) 2 ∑ u∈U (r u, j -ru ) 2 (2.2)</formula><p>Correlation-based similarity commonly uses the Pearson correlation. The correlation between two variables reflects the degree to which the variables are related.</p><p>Equation (2.3) defines the correlation similarity. ri is the average rating of the i-th item:</p><formula xml:id="formula_2">sim(i, j) = Cov(i, j) σ i σ j = ∑ u∈U (r u,i -ri )(r u, j -r j ) ∑ u∈U (r u,i -ri ) 2 ∑ u∈U (r u, j -r j ) 2 (2.3)</formula><p>Equation (2.4) defines similarity using conditional probability, P( j | i):</p><formula xml:id="formula_3">sim(i, j) = P( j | i) f (i ∩ j) f (i) (2.4)</formula><p>where f (X) equals to the number of customers who have purchased the item set X. This is the only metric that is asymmetric. That is, sim(i, j) = sim( j, i).</p><p>Once the similarity among the items has been computed, the next step is to predict to the target user, u, a value for the active item, i. A common way is to capture how the user rates the similar items of i. Let S k (i; u) denote the set of k neighbours of item i, that the user u has rated. The predicted value is based on the weighted sum of the user's ratings, ∀ j ∈ S k (i; u). Equation (2.5) shows the predicted value for item i to user u.</p><formula xml:id="formula_4">ru,i = ∑ j∈S k (i;u) sim(i, j)r u, j ∑ j∈S k (i;u) sim(i, j) (2.5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2.2">User-Based Neighbourhood</head><p>The predicted rating value of item i, for the active user u, ru,i , can also be computed by taking into account those users that are similar (are like-minded) to u. Equation (2.6) shows the predicted rating score of item i, for user u. ru is the average rating of user u, and r u,i denotes the rating of the user u for the item i. Let S k (u) denote the set of k neighbours for user u, ru,i is defined as:</p><formula xml:id="formula_5">ru,i = ru + ∑ v∈S(u) k sim(u, v)(r v,i -rv ) ∑ v∈S(u) k sim(u, v) (2.6)</formula><p>Yet, to predict ru,i , the algorithm needs to know beforehand the set of users similar to u, S k (u), as well as how similar they are, sim <ref type="bibr">(u, v)</ref>.</p><p>The most common approaches to find the neighbours in either item-based S k (i; u), or user-based neighbourhood S(u) k approaches are Pearson correlation (Eq. 2.3), cosine similarity (Eq. 2.1), and matrix factorisation approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2.3">Matrix Factorisation</head><p>Matrix factorisation techniques-such as Singular Value Decomposition (SVD), Non-negative Matrix Factorisation (NMF), or Principal Component Analysis (PCA)-are useful when the M user-item matrix is sparse, which is very common in any recommender system. Any factorisation technique aims at reducing the dimensionality of the original matrix, generating two matrices U and V that approximate the original matrix. For instance, Singular Value Decomposition (SVD) method computes matrices (n × k)U and (m × k)V , for a given number of dimensions k, such that:</p><formula xml:id="formula_6">M = UΣV T , (2.7)</formula><p>where Σ is a diagonal matrix containing the singular values of M. Matrix decomposition is not unique. There are different methods to approximate Eq. (2.7). For instance, Least squares method requires that the estimated matrices has to deviate as little as possible from M. Or stochastic gradient descent, that iteratively approximates matrices U and V , and updates them in order to minimise the squared error between the predictions and the actual ratings <ref type="bibr">[16]</ref>.</p><p>Once the matrix has been reduced to k dimensions, the predicted rating value of item i for a user u, ru,i , can be approximated as the dot product between the user's U u ∈ R k and the item's feature vector,</p><formula xml:id="formula_7">V i ∈ R k . ru,i = U u •V T i = k ∑ f =0 U u, f V f ,i<label>(2.8)</label></formula><p>Matrix factorisation is used in collaborative filtering to deal with the sparsity problem, by reducing the matrix M to k dimensions (or latent factors). Furthermore, matrix factorisation can also be applied to derive user or item similarity in the reduced k-space, using cosine similarity in the U (users' latent factors) or V (items) matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2.4">Limitations</head><p>Collaborative filtering is one of the most used recommendation methods, yet it presents some drawbacks:</p><p>• Data sparsity and high dimensionality are two inherent properties of the datasets.</p><p>With a relative large number of users and items, the main problem is the low coverage of the users' ratings among the items. It is common to have a sparse user-item matrix of 1% (or less) coverage. Thus, sometimes it can be difficult to find reliable neighbours (specially for user-based CF). • Another problem, related with the previous one, is that users with atypical tastes (that vary from the norm) will not have many users as neighbours. Thus, this will lead to poor recommendations. This problem is also known as gray sheep <ref type="bibr">[17]</ref>. • Cold-start problem This problem appears for both elements of a recommender: users and items. Due to CF is based on users' ratings, new users with only a few ratings become more difficult to categorise. The same problem occurs with new items, because they do not have any rating when added to the collection. These cannot be recommended until users start rating it. This problem is known as the early-rater problem <ref type="bibr">[18]</ref>. Moreover, the first user that rates new items gets only little benefit (this new item does not match with any other item yet). • CF is based only on the feedback provided by the users (in terms of ratings, purchases, downloads, etc.), and does not take into account the description of the items. It is a subjective method that aggregates the social behaviour of the users, thus commonly leading towards recommending the most popular items. • Related with the previous issue, the popularity bias is another problem that commonly happens in CF. It is analogous to the rich gets richer paradigm. Popular items of the dataset are similar to (or related with) lots of items. Thus, it is more probable that the system recommends these popular items. This clearly happens for item-based similarity using conditional probability (defined in Eq. 2.4). The main drawback is that the recommendations are sometimes biased towards popular items, thus not exploring the Long Tail of unknown items. Sometimes, these less-popular items could be more interesting and novel for the users. • Given the interactive behaviour of CF systems, previous social interaction influences the current user behaviour, which, in turn, feedbacks into the system, creating a loop. This issue is also known as feedback loop <ref type="bibr">[19]</ref>. This effect has strong consequences when the system starts gathering initial feedback from the users. Indeed, the early raters have effects on the recommendations that the incoming users will receive when entering to the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3">Content-Based Filtering</head><p>In the content-based (CB) filtering approach, the recommender collects information describing the items and then, based on the user's preferences, it predicts which items the user could like. This approach does not rely on other user ratings but on the description of the items. The process of characterising the item data set can be automatic (e.g. extracting features by analysing the content), based on manual annotations by the domain experts. The key component of this approach is the similarity function among the items (see Fig. <ref type="figure">2</ref>.5). Initial CB approaches have its roots in the information retrieval (IR) field. The early systems focused on the text domain, and applied techniques from IR to extract meaningful information from the text. Yet, recently have appeared some solutions that cope with more complex domains, such as music. This has been possible, partly, because the multimedia community emphasised on and improved the feature extraction and machine learning algorithms.</p><p>The similarity function computes the distance between two items. Content-based similarity focus on an objective distance among the items, without introducing any subjective factor into the metric (as CF does). Most of the distance metrics deal with numeric attributes, or single feature vectors. Some common distances, given two feature vectors x and y, are: Euclidean (Eq. 2.9), Manhattan (Eq. 2.10), Chebychev (Eq. 2.11), cosine distance for vectors (see previously defined Eq. 2.1), and Mahalanobis distance (Eq. 2.12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>d(x, y)</head><formula xml:id="formula_8">= n ∑ i=1 (x i -y i ) 2</formula><p>(2.9)</p><formula xml:id="formula_9">d(x, y) = n ∑ i=1 |x i -y i | (2.10) d(x, y) = max i=1..n |x i -y i | (2.11) d(x, y) = (x -y) T S -1 (x -y) (2.12)</formula><p>Euclidean, Manhattan and Chebychev distance are assuming that the attributes are orthogonal. The Mahalanobis distance is more robust to the dependencies among attributes, as it uses the covariance matrix S.</p><p>If the attributes are nominal (not numeric), a delta function can be used. A simple definition of a delta function could be: δ (a, b) = 0 ⇔ a = b, and δ (a, b) = 1 otherwise. Then, a distance metric among nominal attributes can be defined as:</p><formula xml:id="formula_10">d(x, y) = ω n ∑ i=1 δ (x i , y i ),<label>(2.13)</label></formula><p>where ω is a reduction factor, e.g. 1  n ). Finally, if the distance to be computed has to cope with both numeric and nominal attributes, then the final distance has to combine two equations (2.13 for nominal attributes and one of 2.9. . . 2.12 for numeric attributes). In some cases, items are not modelled with a single feature vector, but using a bag-of-vectors, a time series, or a probability distribution over the feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3.1">Limitations</head><p>CB approach presents some drawbacks:</p><p>• The cold-start problem occurs when a new user enters to the system. The system has yet to adapt to the user preferences. • The gray-sheep problem (users with atypical tastes) can occur, too, depending on the size of the collection, or if the collection is biased towards a concrete genre. • Another potential caveat could be the novelty problem. Assuming that the similarity function works accurately, then one might assume that a user will always receive items too similar to the ones in her profile. To cope with this shortcoming, the recommender should use other factors to promote the eclecticness of the recommended items. • Depending on the domain complexity, another drawback is the limitation of the features that can be (automatically) extracted from the objects. For instance in the multimedia arena, nowadays, is still difficult to extract high-level descriptors with a clear meaning for the user. Music analysis is not ready yet to accurately predict the mood of a song but, on the other hand, it does the job well when dealing with descriptors such as: harmony, rhythm, etc. Thus, even though an item description might not be meaningful for a user, still its description is useful to compute item similarity. • Another shortcoming is that the recommender is focused on finding similarity among items, using only features describing the items. This means that subjectivity (or personal opinions) is not taken into account when the recommendations are computed.</p><p>CB methods solve some of the shortcomings of the collaborative filtering. The early-rater problem disappears. When adding a new item into the collection-and computing the similarity among the rest of the items-it can be recommended without being rated by any user. The popularity bias is solved too. Because there is no human intervention in the process, all the items are considered (in principle) to be of equal importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.4">Context-Based Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.4.1">Context vs. Content</head><p>Context is any information that can be used to characterise the situation of an entity <ref type="bibr">[20]</ref>. Context-based recommendation uses, then, contextual information to describe and characterise the items. To compare content and context-based filtering, one example is the different methods used for email spam detection. The common one is based on the text analysis of the mail (i.e. content-based), whereas context filtering does not deal with the content of the mail. It rather uses the context of the Simple Mail Transfer Protocol (SMTP) connection to decide whether an email should be marked as spam or not. Now, we briefly outline two techniques, named Web mining and Social tagging, that can be used to derive similarity among the items (or users). Web mining is based on analysing the available content on the Web, as well as the usage and interaction with the content. Social tagging mines the information gathered from a community of users that tag items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.4.2">Web Mining</head><p>Web mining techniques aim at discovering interesting and useful information from the analysis of the content and its usage. Kosala and Blockeel identify three different web mining categories: content, structure and usage mining <ref type="bibr">[21]</ref>.</p><p>• Web content mining includes text, hypertext, markup, and multimedia mining. Some examples are: opinion extraction (sentiment analysis), weblog analysis, mining customer reviews, extract information from forums or chats, topic recognition and demographic identification (gender, age, etc.), and trend identification. Item similarity can be derived out of the analysis of this information. • Web structure mining focuses on link analysis (in-and out-links). That is the network topology analysis (e.g. hubs, authorities), and the algorithms that exploits the topology (e.g. Hits and PageRank). • Web usage mining uses the information available on session logs. This information can be used to derive user habits and preferences, link prediction, or item similarity based on co-occurrences in the session log. Thus, web usage mining can determine sequential patterns of usage (e.g. "people who visit this page also visited this one"). For instance, Mobasher et al. use association rules to determine the sequential patterns of web pages, and recommend web pages to users <ref type="bibr">[22]</ref>.</p><p>Combining these three approaches, a recommender system derives the similarity among the items (e.g. items that co-occur in the same pages, items that are visited in the same session log, etc.) and also models the users, based on their interaction with the content. If the information about the content is in textual form, classic measures from Information Retrieval can be applied to characterise the items. For instance, vector space-based models can be used to model both the items and the user profile. Then, similarity between an item description (using the bag-of-words model) and a user profile can be computed using, for instance, cosine based similarity.</p><p>Cosine similarity between an item i j , and a user profile u i is defined as:</p><formula xml:id="formula_11">sim(u i , i j ) = ∑ t w t,u i w t,i j ∑ t w 2 t,u i ∑ t w 2 t,i j (2.14)</formula><p>A common term weighting function, w i, j , is the T F-IDF. T F stands for Term Frequency, whereas IDF is the Inverse Document Frequency <ref type="bibr">[23]</ref>. The term frequency in a given document measures the importance of the term i within that particular document. Equation (2.15) defines T F:</p><formula xml:id="formula_12">T F = n i ∑ k n k (2.15)</formula><p>with n i being the number of occurrences of the considered term, and the denominator is the number of occurrences of all the terms in the document. The Inverse Document Frequency, IDF, measures the general importance of the term, in the whole collection of items:</p><formula xml:id="formula_13">IDF = log |D| |(d i ⊃ t i )| (2.16)</formula><p>where |D| is the total number of items, and the denominator counts the number of items where t i appears. Finally, the weighting function w t, j , of a term t in the item description d j is computed as:  Another useful measure to compute item similarity is the Pointwise mutual information (PMI). PMI estimates the semantic similarity between a pair of terms by how frequently they co-occur. The PMI of two terms i and j quantifies the discrepancy between their joint distribution probability, versus their individual distribution probability (assuming independence):</p><formula xml:id="formula_14">w t, j = T F • IDF (2.</formula><formula xml:id="formula_15">PMI(i, j) = log p(i, j) p(i)p( j) (2.18)</formula><p>PMI measure is symmetric, that is PMI(x, y) = PMI(y, x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.4.3">Social tagging</head><p>Social tagging (also known as Folksonomy, or Collaborative tagging) aims at annotating web content using tags. Tags are freely chosen keywords, not constrained to a predefined vocabulary. A bottom-up classification emerge when grouping all the annotations (tags) from the community of users; the wisdom of the crowds.</p><p>Recommender systems can derive social tagging data to derive item (or user) similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2.6</head><p>The user-item-tag cube. A 3-order tensor containing user, item,tag triples.</p><p>When users tag items, we get tuples of user, item,tag . These triples conform a 3-order matrix (also called tensor; a multidimensional matrix). Figure <ref type="figure">2</ref>.6 depicts a 3-order tensor, containing the tags that users apply to items.</p><p>There are two main approaches to use social tagging information to compute item (and user) similarity. These are:</p><p>1. Unfold the 3-order tensor in three bidimensional matrices (user-tag, item-tag and user-item matrices), and 2. Directly use the 3-order tensor.</p><p>Unfolding the 3-order tensor consists on decomposing the multidimensional data into the following bidimensional matrices:</p><p>• User-Tag (U matrix). U i, j contains the number of times user i applied the tag j. Using matrix U, a recommender system can derive a user profile (e.g. a tag cloud for each user, denoting her interests, or the items she tags). U can also be used to compute user similarity, by comparing two user tag clouds of interests (using, for instance, cosine similarity between the two user vectors). • Item-Tag (I matrix). I i, j contains the number of times an item i has been tagged with tag j. The matrix I contains the contextual description of the items, based on the tags that have been applied to. Matrix I can be used to compute item or user similarity. As an example, Fig. <ref type="figure">2</ref>.7 shows a way to derive user similarity from I, using their top-N artists in last.fm. Figure <ref type="figure">2</ref>.7 depicts two user tag clouds (top and middle images) and their intersection (bottom image), using matrix I. In this example, users' tag clouds are derived from the last.fm listening habits, using their top-N most listened artists-in this case, the items in I. The third image (bottom) shows the tags that co-occur the most in the two profiles. Similarity between the two users is done by constructing a new tag vector where each tag's weight is given by the minimum of the tag's weights in the user's vectors. Using this approach, the similarity value between ocelma and lamere last.fm users is 70.89%. Another similarity metric could be the cosine distance, using TFxIDF to weight each tag. • User-Item (R binary matrix). R i, j denotes whether the user i has tagged the item j. In this case, classic collaborative filtering techniques can be applied on top of R.</p><p>To recap, item similarity using matrix I, or user similarity derived from U or I, can be computed using cosine-based distance (see Eq. 2.1), or also by applying dimensionality reduction techniques-to deal with the sparsity problem-such as Singular Value Decomposition (SVD), or Non-negative matrix factorisation (NMF). Once the item (or user) similarity is computed, either the R user-item matrix, or the user (tag cloud) profile obtained from U or I are used to predict the recommendations for a user. For instance, <ref type="bibr">[24]</ref> presents a framework based on the three matrices, U, I and R, to recommend web pages (based on http://del.icio.us data). Also, <ref type="bibr">[25]</ref> uses matrix I to improve the accuracy results of the recommendations, after combining I with the results obtained by classic collaborative filtering. Levy applies Latent Semantic Analysis (that is; SVD and cosine similarity in the reduced space) to compute and visualise artist similarity derived from tags gathered from last.fm <ref type="bibr">[26]</ref>.</p><p>Finally, it is worth mentioning that inverting either U or I matrices, one can also compute tag similarity. Tag similarity have many usages in recommendation and search engines. For instance, tag synonym detection can be used for query expansion, or tag suggestion when annotating the content. Using the 3-order tensor (instead of decomposing the tensor in bidimensional matrices) is the second approach to mine the data, and provide recommendations. The available techniques are (high-order) extensions of SVD and NMF. HOSVD is a higher order generalisation of matrix SVD for tensors, and Non-negative Tensor Factorisation (NTF) is a generalisation of NMF.</p><p>In <ref type="bibr">[27]</ref>, the authors apply HOSVD to a music dataset (user-artists-tags) taken from last.fm. Their results show significant improvements in terms of the effectiveness measured through precision and recall. Yanfei et al. present a similar method using bookmarking data from del.icio.us <ref type="bibr">[28]</ref>. They apply SVD on the R matrix, compute cosine distance among the users (to find the neighbours), and then apply classic CF user-based recommendation (see Sec. 2.5.2). The authors could improve the results over a CF approach based on SVD and cosine similarity (e.g. Latent Semantic Analysis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.4.4">Limitations of Social Tagging</head><p>One of the main limitations of social tagging is the coverage. On the one hand, it is quite common that only the most popular items are described by several users, creating a compact description of the item. On the other hand, long tail items usually do not have enough tags to characterise them. This makes the recommendation process very difficult, specially to promote these unknown items. Another issue is that without being constrained to a controlled vocabulary, tags present the following problems: polysemy (I love this song, versus this song is about love), synonymy (hip-hop, hiphop, and rap), and usefulness of the personal tags to derive similarity among users or items (e.g. seen live, or to check). These issues make more difficult to mine and extract useful relationships among the items and the users.</p><p>Tag sparsity is another issue. In some domains, some tags are widely used (e.g. rock or pop, in the music domain), whereas other tags are rarely applied (e.g. gretsch guitar). A biased distribution of the terms has also consequences when exploiting social tagging data.</p><p>Last but not least, any recommender system that relies on user explicit input can be attacked, or vandalised. Users can deliberately mistag some items in order to provoke an undesired effect in the recommendations (see Paris Hilton example presented in Sec. 3.3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.5">Hybrid Methods</head><p>The main purpose of a hybrid method is to achieve a better recommendations by combining some of the previous stand-alone approaches. Most commonly, collab-orative filtering is combined with other techniques. There are several methods to integrate different approaches into a hybrid recommender. Some of the methods that Burke defines are <ref type="bibr">[29]</ref>:</p><p>• Weighted. A hybrid method that combines the output of separate approaches using, for instance, a linear combination of the scores of each recommendation technique. • Switching. The system uses some criterion to switch between recommendation techniques. One possible solution is that the system uses a technique, and if the results are not confident enough, it switches to another technique to improve the recommendation process. • Mixed. In this approach, the recommender does not combine but expand the description of the data sets by taking into account the users' ratings and the description of the items. The new prediction function has to cope with both types of descriptions. • Cascade. The cascade involves a step by step process. In this case, a recommendation technique is applied first, producing a coarse ranking of items. Then, a second technique refines or re-rank the results obtained in the previous step.</p><p>A hybrid method can alleviate some of the drawbacks that suffer a single technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Factors Affecting the Recommendation Problem</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.1">Novelty and Serendipity</head><p>The novelty factor is a very important aspect of the recommendation problem. It has been largely acknowledged that providing obvious recommendations can decrease user satisfaction <ref type="bibr">[2,</ref><ref type="bibr">30]</ref>. Obvious recommendations have two practical disadvantages: users who are interested in those items could probably already know them, and secondly, managers in stores (i.e. experts of the items' domain) do not need any recommender to tell them which products are popular overall.</p><p>Although, obvious recommendations do have some value for new users. Users like to receive some recommendations they already are familiar with <ref type="bibr">[31]</ref>. This is related with the Find credible recommender use case (see Sec. 2.2). Yet, there is a trade-off between the desire for novel versus familiar recommendations. A high novelty rate might mean, for a user, that the quality of the recommendation is poor, because the user is not be able to identify most of the items in the list of recommendations. However, by providing explanations (transparency) of the recommendations, the user can feel that is a credible recommender. Thus, the user can be more open to receive novel, justified, recommendations.</p><p>Another important feature, closely related with novelty is the serendipity effect. That is the good luck in making unexpected and fortunate discoveries. A recommender should help the user to find a surprisingly interesting item that she might not be able to discover otherwise. Recommendations that are serendipitous are also novel and relevant for a user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.2">Explainability</head><p>Explainability (or transparency) of the recommendations is another important element. Giving explanations about the recommended items could increase user trustiness and loyalty of the system, and also her satisfaction.</p><p>A recommender should be able to explain to the user why the system recommends the list of top-K items <ref type="bibr">[32]</ref>. Herlocker et al. present an experimental evidence that shows that providing explanations can improve the acceptance of those recommender systems based on collaborative filtering <ref type="bibr">[33]</ref>. Actually, giving explanations about why the items were recommended is as important as the actual list of recommended items. Tintarev and Masthoff summarise the possible aims for providing recommendations. These are: transparency, scrutability, trust, effectiveness, persuasiveness, efficiency, and satisfaction. They also stress the importance of personalising the explanations to the user <ref type="bibr">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.3">Cold Start Problem</head><p>As already mentioned, the cold start problem of a recommender (also known as the learning rate curve, or the bottleneck problem) happens when a new user (or a new item) enters into the system <ref type="bibr">[35]</ref>. On the one hand, cold start is a problem for users that just signed-up, because the system does not have enough information about them. If the user profile initialisation is empty (see Sec. 2.4.1), she has to dedicate some time using the system before getting some useful recommendations. On the other hand, when a new item is added to the collection, the system should have enough information to be able to recommend this item to users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.4">Data Sparsity and High Dimensionality</head><p>Data sparsity is an inherent property of the dataset. With a relative large number of users and items, the main problem is the low coverage of the users' interaction with the items. A related factor is the high dimensionality of the dataset, that consists of many users and items.</p><p>There are some methods, based on dimensionality reduction, that alleviate data sparsity and high dimensionality of the dataset. Singular Value Decomposition (SVD), and Non-negative Matrix Factorisation (NMF) <ref type="bibr">[16,</ref><ref type="bibr">36,</ref><ref type="bibr">37]</ref> are the two most used methods in recommendation. Takács et al. present in <ref type="bibr">[38]</ref> several matrix factorisation algorithms, and evaluate the results against the Netflix Prize dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.5">Coverage</head><p>The coverage of a recommender measures the percentage of the items in the collection over which the system, or make recommendations. A low coverage of the domain might be less valuable to users, as it limits the space of possible items to recommend. Moreover, this feature is important for the Find all good items use case (see Sec. 2.2). Also, a low coverage of the collection can be very frustrating for the users, and clearly affects the novelty and serendipity factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.6">Trust</head><p>Trust-aware recommender systems determine which users are reliable, and which are not. Trust computational models are needed, for instance, in user-based CF to rely on the user's neighbours.</p><p>In <ref type="bibr">[39]</ref>, the authors present two computational models of trust and show how they can be readily incorporated into CF. Furthermore, combining trust and classic CF can improve the predictive accuracy of the recommendations. Massa et al. emphasise the "web of trust" provided by every user. They use the "web of trust" to propagate trust among users, and also use it to alleviate the data sparsity problem. An empirical evaluation shows that using trust information improves the predictive accuracy, as well as the coverage of the recommendations <ref type="bibr">[40,</ref><ref type="bibr">41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.7">Attacks</head><p>Recommender systems can be attacked in various ways, degrading the quality of the recommendations. For instance, sybil attacks try to subvert the system by creating a large number of sybil identities in order to gain a lot of influence in the system. These attacks can promote or demote some particular items.</p><p>A related problem is the user profile injection, where a malicious user fakes some of her data creating an incongruent profile. Then, using a particular rating pattern that highly rates a set of target items, and then rating other items so they become similar. This is known as shilling attacks <ref type="bibr">[42]</ref>.</p><p>Another problem is deliberate mistagging. That is when a group of users tag an item using a (malicious) tag. This behavior can affect the performance of socialbased recommenders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.8">Temporal Effects</head><p>Temporal effects are found in both items and users. On the one hand, the timestamp of an item (e.g. when the item was added to the collection) is an important factor for the recommendation algorithm. The prediction function can take into account the age of an item. A common approach is to treat the older items as less relevant than the new ones, promoting new items that are continously added in the collection.</p><p>On the other hand, the system has to decide which items from a user profile are taken into account when computing the recommendations. Should the system use all the information of a profile, or only the latest activity? Depending on the criteria, it might change the output recommendations.</p><p>In this context, <ref type="bibr">[43]</ref> presents the recommendation problem as a sequential optimisation problem. It is based on Markov decision processes (MDP). MDP uses the long-term effects of the recommendations, but it is also configurable to use only the last k-actions of a user. The main problem, though is the computationally complexity of the algorithm, which makes it unusable for large datasets.</p><p>Temporal effects are also found in the manner how users rate items. Users' ratings can also vary over time. When a user has to rate a given set of items over a period of time, the ratings provided by her are not always consistent <ref type="bibr">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.9">Understanding the Users</head><p>Modelling user preferences, including psychographic information, is another challenging problem. Psychographic variables include attributes related with personality; such as attitudes, interests, or lifestyles. It is not straightforward to encode all this information and use it in the recommender system. This problem is similar in Information Retrieval (IR) systems, where users have to express their needs via a keyword-based query. There is a loss of information when a user is formulating a query using a language that the machine can understand and process. When dealing with user profiles and sensitive personal information, privacy is an important aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Summary</head><p>This chapter has presented and formalised the recommendation problem. The main components of a recommender are users and items. Based on the user preferences and the exploitation of a user profile, a recommender can solve the problem of recommending a list of items to a user, or a list of like-minded users. There are several factors that affect the recommendation problem, and in this book we emphasise the novelty one. We believe that this is an important topic that deserves to be analysed in depth.</p><p>To recap, Table <ref type="table" target="#tab_2">2</ref>.1 presents the main elements involved in the recommendation problem, that is user profiling (generation, maintenance, and adaptation), and the recommendation methods (matching items-or users-to a user, and the filtering methods to match them). Chapter 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Music Recommendation</head><p>This chapter focuses on the recommendation problem in the music domain. Section 3.1 presents some common use cases in music recommendation. After that, Sec. 3.2, discusses user profiling and modelling, and how to link the elements of a user profile with the music concepts. Then, Sec. 3.3 presents the main components to describe the musical items, that are artists and songs. The existing music recommendation methods (collaborative filtering, content, context-based, and hybrid) and the pros and cons of each approach are presented in Sect. 3.4. Finally, Sec. 3.5 summarises the work presented, and provides some links with the remaining chapters of the book.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Use Cases</head><p>The main task of a music recommendation system is to propose interesting music, consisting of a mix of known and unknown artists-as well as the available tracksgiven a user profile. Most of the work done in music recommendation focuses on presenting to a user a list of artists, or creating an ordered sequence of songs (a personalised playlist). Yet, there are other interesting scenarios. For instance, providing recommendations for a group of users, in a particular context <ref type="bibr">[1,</ref><ref type="bibr">2]</ref>. That is, an automatic DJ that selects music to please as much people in the party as possible.</p><p>Or, proposing background music for a restaurant, given some constraints such as the type of music (ambient, relaxed, or only instrumental, etc.), the lyrics' language (e.g. only Italian songs in a pizzeria), as well as other particularities that the restaurant might impose. Another scenario could be a very specialised advanced search system for a music producer. The producer might need to search for a specific bassline or bass sound, that should fit into the whole song. A music recommender should be able to assist both the boss of the restaurant and the producer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Artist Recommendation</head><p>According to the general model presented in Chap. 2 (see Fig. <ref type="figure">2</ref>.1), artist recommendation follows the user-item matching, were items are recommended to a user according to her profile. However, artist recommendation should involve a broader experience with the user, more than presenting a list of relevant artists, plus some accompanying metadata. In this sense, there is a lot of music related information on Internet: music performed by "unknown" -long tail-artists that can suit perfectly for new recommendations, new music releases, related news, concerts listings, album reviews, mp3-blogs, podcasts, t-shirts, and a long etcetera. Indeed, music websites syndicate (part of) their web content-noticing the user about new releases, artists' related news, upcoming gigs, etc.-in the form of RSS (Really Simple Syndication) feeds. For instance, the iTunes Music Store<ref type="foot" target="#foot_19">1</ref> provides an RSS feed generator<ref type="foot" target="#foot_20">2</ref> updated once a week, that publishes all the new releases of the week. A music recommendation system could take advantage of all these publishing services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Playlist Generation</head><p>Cunningham et al. make the distinction between a playlist and a mix. In a mix, the order of the songs is important, whilst a playlist focuses more on a desired emotional state, or acts as a background to an activity (while working, while reading, while jogging, etc.) <ref type="bibr">[3]</ref>.</p><p>Playlist generation is an important application in music recommendation, as it allows users to listen to the music as well as provide immediate feedback, so the system can react accordingly. There are several ways to automatically create a playlist; shuffle (i.e random), based on a given seed song-or artist-or based on a userprofile (including her like-minded neighbours). With regard to the available music, there are two main modes of playlist generation: (i) using tracks drawn from the users own collection (ii) using tracks drawn from the celestial jukebox.<ref type="foot" target="#foot_21">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.1">Shuffle, Random Playlists</head><p>Interestingly enough, some experiments have been carried out to investigate serendipity in random playlists. Nowadays, shuffle is still the usual way to generate playlists on personal computers and portable music players. A study of serendipity through shuffle playlists is presented in <ref type="bibr">[4]</ref>. The authors argue that shuffle can invest new meanings to a particular song. It provides opportunities for unexpected rediscoveries, and also in some cases re-connects songs with old memories. Although, serendipity can be achieved by creating more personalised and elaborated playlists, rather than purely based on random choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.2">Personalised Playlists</head><p>Radio-a-la-carte (personalised playlists) is another way to propose music to a user. In this case, music is selected in terms of the user preferences, within a particular context. The user can also provide feedback (e.g. Skip this song, More like this, etc.) according to her taste and the actual listening context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Neighbour Recommendation</head><p>The goal of neighbour recommendation is to find like-minded people. Neighbour similarity is based on the user-user profile matching presented in Fig. <ref type="figure">2</ref>.1. Once a user is set in a neighbourhood, she can discover music through her neighbours, or simply be part of that community (or cluster) and interact with them.</p><p>One of the main advantages of creating neighbourhoods is that a user can explore and discover music via her neighbours. Also, it promotes the creation of tight communities, connecting people that share similar interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">User Profile Representation</head><p>Music is an important vehicle for telling other people something relevant about our personality, history, etc. Musical taste and music preferences are affected by several factors, including demographic and personality traits. It seems reasonable to think that music preferences and personal aspects-such as: age, gender, origin, occupation, musical education, etc.-can improve music recommendation <ref type="bibr">[5]</ref>.</p><p>User modelling has been studied for many years. Yet, extending a user profile with music related information has not been largely investigated. Indeed, it is an interesting way to communicate with other people, and to express their music preferences.<ref type="foot" target="#foot_22">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Type of Listeners</head><p>The Phoenix 2 UK Project from 2006 summarises the four degrees of interest in music, or type of listeners <ref type="bibr">[6]</ref>. This study is based on the analysis of different type of listeners, with an age group ranging from 16 to 45. The classification, depicted in Fig. <ref type="figure" target="#fig_18">3</ref>.1, includes:</p><p>• Savants. Everything in life seems to be tied up with music.  Each type of listener needs different type of recommendations. Savants do not really need popular recommendations, but risky and clever ones. They are the most difficult listeners to provide recommendations, because they are very exigent. Enthusiasts appreciate a balance between interesting, unknown, recommendations and familiar ones. Casuals and indifferents (72% of the population) do not need any complicated recommendations. Probably, popular, mainstream music that they can easily identify would fit their musical needs. Thus, a recommender system should be able to detect the type of user and act accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.1">Context in Music Perception</head><p>Lesaffre et al. reveal in <ref type="bibr">[7]</ref> that music perception is affected by contextual information, and this context depends on each user. The study explores the dependencies of demographic and musical background for different users in an annotation experiment. Subject dependencies are found for age, music expertise, musicianship, taste and familiarity with the music. The authors propose a semantic music retrieval system based on fuzzy logic. The system incorporates the annotations of the experiment, and music queries are done using semantic descriptors. The results are returned to the user, based on her profile and preferences. Again, one of the main conclusions of their research is that music search and retrieval systems should distinguish between the different categories of users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.2">Subjective Perception of Music Similarity</head><p>In <ref type="bibr">[8]</ref>, the authors present a music recommendation engine based on user's perceived similarity. User similarity is defined as a combination of timbre, genre, tempo, year and mood. The system allows users to define the weights for personalised playlist generation.</p><p>Sotiropoulos et al. state that different users assess music similarity via different feature sets, which are in fact subsets of some set of objective features. They define a subset of features, for a specific user, using relevance feedback and a neural network for incremental learning <ref type="bibr">[9]</ref>.</p><p>Going one step beyond, the work presented in <ref type="bibr">[10]</ref> allows users to defining their own semantic concepts (e.g. happy, blue, morning-music, etc.), providing some instances-sound excerpts-that characterise each concept. The system adapts, then, can adapt to these user's concepts and it predicts (using audio content-based similarity) the labels for the newly added songs. This process is also known as autotagging. The system can also generate a playlist based on one or more user's concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.3">The User in the Community</head><p>A single user profile can be extended taking into account her interaction with the community of peers. Tracking social network activity allows a system to infer user preferences. Social networks have a big potential not only for the social interactions among the users, but also to exploit recommendations based on the behaviour of the community, or even to provide group-based recommendations.</p><p>In <ref type="bibr">[11]</ref>, the authors present a recommendation framework based on social filtering. The user profile consists on static and dynamic social aspects. The dynamic aspect includes the interaction with other users, and the relationships among them (e.g. duration, mutual watchings of web pages, common communications, etc.).</p><p>Analysing this information, the authors present novel ways of providing social filtering recommendations.</p><p>Another example is the Bluetuna system. Bluetuna is a "socialiser engine" based on sharing user preferences for music <ref type="bibr">[12]</ref>. Bluetuna allows users to share musical tastes with other people who are (physically) near by. The application runs on bluetooth enabled mobile phones. The idea is to select those users that have similar musical tastes, facilitating the meeting process.</p><p>Firan et al. create tag-based user profiles using social tagging information derived from the collective annotation <ref type="bibr">[13]</ref>. Once a user profile is described using a tag cloud, the authors present several approaches to compute music recommendations. The results show an accuracy improvement using tag-based profiles over traditional collaborative filtering at song level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.4">Privacy Issues</head><p>When dealing with user profiles and sensitive personal information, privacy is an important aspect. In <ref type="bibr">[14]</ref>, the authors present some results about the acquisition, storage and application of sensitive personal information. There is a trade-off between the benefits of receiving personalised music recommendations and the lost of privacy. The factors that influence disclosing sensitive personal information are:</p><p>• the purpose of the information disclosure, • the people that get access to the information, • the degree of confidentiality of the sensitive information, and • the benefits they expect to gain from disclosing it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">User Profile Representation Proposals</head><p>As noted in the previous section, music recommendation is highly dependent on the type of user. Also, music is an important vehicle for conveying to others something relevant about our personality. User modelling, then, is a crucial step in understanding user preferences.</p><p>However, in the music recommendation field, there have been few attempts to explicitly extend user profiles by adding music related information. The most relevant (music-related) user profile representation proposals are: the User modelling for Information Retrieval Language, the MPEG-7 standard that describes user preferences, and the Friend of a Friend (FOAF) initiative (hosted by the Semantic Web community). The complexity, in terms of semantics, increases with each proposal. The following sections present these three approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.1">User Modelling for Information Retrieval (UMIRL)</head><p>The UMIRL language, proposed by <ref type="bibr">[15]</ref>, allows one to describe perceptual and qualitative features of the music. It is specially designed for music information retrieval systems. The profile can contain both demographic information and direct information about the music objects: favourite bands, styles, songs, etc. Moreover, a user can add her definition of a perceptual feature and his meaning, using music descriptions. For instance: "a romantic piece has a slow tempo, lyrics are related with love, has a soft intensity, and the context to use this feature is while having a special dinner with user's girlfriend".</p><p>The representation they proposed uses the XML syntax, without any associated schema nor document type definition to validate the profiles. <ref type="bibr">Listing</ref>  This proposal is one of the first attempts in the Music Information Retrieval community. The main goal was to propose a representation format, as a way to interchange profiles among systems, though, it lacks formal semantics to describe the meaning of their descriptors and attributes. To cope with this limitation, the following section presents an approach using the MPEG-7 standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.2">MPEG-7 User Preferences</head><p>MPEG-7, formally named Multimedia Content Description Interface, is an ISO/IEC standard developed by the Moving Picture Experts Group (MPEG). The main goal of the MPEG-7 standard is to provide structural and semantic description mechanisms for multimedia content. The standard provides a set of description schemes (DS) to describe multimedia assets. In this section, we only focus on the descriptors that describes user preferences of multimedia content. An in-depth description of the whole standard appears in <ref type="bibr">[16]</ref>.</p><p>User preferences in MPEG-7 includes content filtering, searching and browsing preferences and usage history, which represents the user history of interaction with multimedia items, can be denoted too. Filtering and searching preferences include the user preferences regarding classification (i.e. country of origin, language, available reviews and ratings, reviewers, etc.) and creation preferences. The creation preferences describes the creators of the content (e.g. favourite singer, guitar player, composer, and music bands). Also, it allows one to define a set of keywords, location and a period of time. Using a preference value attribute, a user can express positive (likes) and negative (dislikes) preferences for each descriptor. The following example shows a partial user profile definition, stating that this user likes the album To bring you my love from P.J. Harvey: MPEG-7 usage history is defined following the usage history description scheme. UsageHistory DS contains a history of user actions. It contains a list of actions (play, play-stream, record, etc.), with an associated observation period. The action has a program identifier (an identifier of the multimedia content for which the action took place) and, optionally, a list of related links or resources.</p><formula xml:id="formula_16">&lt;UserPreferences&gt;</formula><p>Tsinaraki et al. present a way to overcome some of the limitations of describing user preferences in MPEG-7 <ref type="bibr">[17]</ref>. They argue that there is still a lack of semantics when defining user preferences, as the whole MPEG-7 standard is based on XML Schemas. For example, filtering and search preferences allow one to specify a list of textual keywords, without being related to a taxonomy or ontology. Their imple-mentation is integrated into a framework, based on an upper ontology that covers the MPEG-7 multimedia description schemes. This upper ontology uses the Web Ontology Language (OWL) <ref type="foot" target="#foot_23">5</ref> notation. So it does the next proposal, based on the Friend of a Friend initiative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.3">FOAF: User Profiling in the Semantic Web</head><p>The Friend of a Friend project provides conventions and a language "to tell" a machine the type of things a user says about herself in her homepage. Friend of a Friend is based on the RDF/XML vocabulary. As we noted before, the knowledge held by a community of "peers" about music is also a source of valuable metadata. Friend of a Friend nicely allows one to easily relate and connect people.</p><p>Friend of a Friend profiles include demographic information (name, gender, age, sex, nickname, homepage, depiction, web accounts, etc.) geographic (city and country, geographic latitude and longitude), social information (relationship with other persons), pyschographic (i.e. user's interests) and behavioural (usage patterns). There are some approaches to model music preferences music taste in a Friend of a Friend profile.</p><p>The simplest way to show interest for an artist is shown in the following example:</p><p>&lt;foaf:interest&gt; rdf:resource="http://www.pjharvey.net" dc:title="P.J. Harvey" /&gt; Listing 3.3 Example of a user interest using FOAF.</p><p>The Semantic Web approach facilitates the integration of different ontologies. Listing 8.5 shows how to express that a user likes an artist, using the general Music Ontology proposed in <ref type="bibr">[18]</ref>.</p><p>Listing 3.4 Example of a user interest using FOAF, and the music ontology to describe the artist.</p><p>To conclude this section, Example 3.5 shows a complete Friend of a Friend profile. This profile contains demographic and geographic information, as well as user's interests -with a different level of granularity when describing the artists.</p><p>&lt;rdf:RDF (XML namespaces here)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 3.5 Example of a user's FOAF profile</head><p>This approach, based on the Friend of a Friend notation, is the one used in one of the two prototypes, named Foafing the music, presented in Chap. 8 (Sect. 8.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Item Profile Representation</head><p>Now we describe the representation and modelling of music items. That is, the main elements that describe artists and songs. First we introduce, in Sec. 3.3.1, the Music Information Plane (MIP). MIP defines the different levels of complexity and abstraction to describe music assets. After that, we classify these semantic descriptions using the music knowledge classification (editorial, cultural and acoustic metadata) proposed by Pachet in <ref type="bibr">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">The Music Information Plane</head><p>In the last twenty years, the signal processing and computer music communities have developed a wealth of techniques and technologies to describe audio and music content at the lowest (close to the signal) level of representation. However, the gap between these low-level descriptors and the concepts that music listeners use to relate it with a music collection (the so-called "semantic gap") is still, to a large extent, waiting to be bridged.</p><p>Due to the inherent complexity when describing multimedia objects, a layered approach with different levels of granularity is needed. In the multimedia field and, specially, in the music field we foresee three levels of abstraction: low-level basic features, mid-level semantic features, and high-level human understanding. The first level includes physical features of the objects, such as the sampling rate of an audio file, as well as some basic features like the spectral centroid of an audio frame, or even the predominant chord in a sequential list of frames. A mid-level of abstraction aims at describing concepts such as a guitar solo, or tonality information (e.g. key and mode) of a track. Finally, the higher level should use reasoning methods or semantic rules to retrieve, for instance, several audio files with "similar" guitar solos over the same key.</p><p>We describe the music information plane in two dimensions. One dimension considers the different media types that serve as input data (audio, text and image). The other dimension is the level of abstraction in the information extraction process of this data. Figure <ref type="figure" target="#fig_18">3</ref>.2 depicts the music information plane.</p><p>The input media types, in the horizontal axis, include data coming from: audio (music recordings), text (lyrics, editorial text, press releases, etc.) and image (video clips, CD covers, printed scores, etc.). On the other side, for each media type there are different levels of information extraction (in the vertical axis). The lowest level is located at the signal features. This level lays far away from what an end-user might find meaningful. Anyway, it is the basis to describe the content and to produce more elaborated descriptions of the media objects on top of that. This level includes basic audio features (such as: energy, frequency, mel frequency cepstral coefficients, or even the predominant chord in a sequential list of frames), or basic natural language processing for the text media. At the mid-level (the content objects level), the information extraction process and the elements described are a bit closer to the end-user. This level includes description of musical concepts (such as a guitar solo, or tonality information-e.g. key and mode-of a music title), or named entity recognition for text information. Finally, the higher-level, includes information related with human beings and their interaction with music knowledge. This level could use inference methods and semantic rules to retrieve, for instance, several audio files with similar guitar solos over the same key. Also, in this level, there is the user and her social relationships with a community of users. Figure <ref type="figure" target="#fig_18">3</ref>.2 depicts the music information plane.</p><p>Nonetheless, the existing semantic gap between concept objects and human knowledge makes it more difficult for a music recommender system. This semantic gap has many consequences to music understanding and music recommendation. Yet, there are some open questions, such as: which are the music elements that makes a person feel certain emotions, or to evoke some particular memories? How is a personal identity linked with music? Only a multi-modal approach, that takes into account as much elements from MIP as possible, would be able to (partly) answer some of these questions. Neither pure bottom-up nor top-down approaches can lead to bridge this gap. We foresee, then, an approximation in both ways: users need to interact with the content to add proper (informal) semantics (e.g. via tagging), and also content object descriptions must be somehow understandable by the users.</p><p>Pachet classifies the music knowledge management in three categories <ref type="bibr">[19]</ref>. The three categories are: editorial, cultural and acoustic metadata. This classification allows one to create meaningful descriptions of music, and to exploit these descriptions to build music recommendation systems. In the following sections, we depict each category in the music information plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Editorial Metadata</head><p>Editorial metadata (EM) consists of information manually entered by an editor. Usually, the information is decided by an expert or a group of experts. Figure <ref type="figure" target="#fig_18">3</ref>.3 depicts the relationship between editorial metadata and the music information plane. Editorial metadata includes simple creation and production information (e.g. the song C'mon Billy, written by P.J. Harvey in 1995, was produced by John Parish and Flood, and the song appears as track number 4, on the album "To bring you my love"). Editorial metadata includes, in addition, artist biography, genre information, relationships among artists, etc. Thus, editorial information is not necessarily objective. It is usual the case that different experts cannot agree in assigning a concrete genre to a song or to an artist. Even more difficult is a common consensus of a taxonomy of musical genres.</p><p>The scope of Editorial metadata is rather broad. Yet, it usually refers to these items: the creator (or author) of the content, the content itself, and the structure of the content. Regarding the latter, editorial metadata can be fairly complex. For example, an opera performance description has to include the structure of the opera. It is divided in several acts. Each act has some scenes. In a given scene, there is a soprano singing an Aria piece, and many musicians playing. It has lyrics to sing, and these can be in different languages (sung in Italian, but displayed in English), etc.</p><p>In terms of music recommendation, EM conforms the core for non content-based methods for music recommenders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Cultural Metadata</head><p>Cultural metadata (CM) is defined as the information that is implicitly present in huge amounts of data. This data is usually gathered from Internet; via weblogs, forums, music radio programs, etc. CM has a clear subjective component as it is based on the aggregation of personal opinions. Figure <ref type="figure" target="#fig_18">3</ref>.4 depicts the relationship between cultural metadata and the music information plane. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.1">Web-MIR Techniques to Describe Artists</head><p>Web Music Information Retrieval (Web-MIR) is a recent field of research in the MIR community. Web-MIR focuses on the analysis and exploitation of cultural information. So far, Web-MIR performances close to classic content-based approaches are reported on artist genre classification and artist similarity <ref type="bibr">[20]</ref><ref type="bibr">[21]</ref><ref type="bibr">[22]</ref>. Yet, it is not clear how Web-MIR methods can deal with long tail content.</p><p>The origins of Web-MIR can be found in the earlier work of Whitman et al. <ref type="bibr">[20,</ref><ref type="bibr">23]</ref>. They describe artists using a list of weighted terms. To gather artist related terms, they query a general search engine with the name of the artist. To limit the size of the page results, they add some keywords to the query, such as "music" and "review". From the retrieved pages, the authors extract unigrams, bigrams and noun phrases. In <ref type="bibr">[23]</ref>, Whitman uses an unsupervised method for music understanding, using the power spectral density estimate over each 5 seconds of audio. Then, it keeps the semantically dimensions that contain the most significant meanings. Similarly, in <ref type="bibr">[24]</ref> Baumann et al. improved this approach by filtering irrelevant content of the web pages (e.g. adverts, menus, etc.). The description of an artist is conformed by the terms with the highest normalised T F-IDF value. That includes the most relevant nouns, adjectives and simple phrases, as well as un-tagged unigrams and bigrams.</p><p>In <ref type="bibr">[25]</ref>, the authors present different ways to describe artists using web data, based on co-occurrence analysis between an artist and the labels. The set of labels are previously defined, and conform a corpus of music related terms (e.g. genres, instruments, moods, etc.). The three methods they use are: Pagecount-based mapping (PCM), Pattern-based mapping (PM), and Document-based mapping (DM). PCM uses the total number of hits retrieved by Google search engine. However, some terms appear more often than others (e.g. pop, or rock versus cumbia). So, they provide a normalised version, inspired by Pointwise mutual information (see Sect. 2.5.4). Pattern-based mapping uses a set of predefined English phrase patterns. For example "(genre) artists such as (artist)". An instance of the pattern could be: "Country artists such as". This way, the method can retrieve the most prominent Country artists. Table <ref type="table" target="#tab_6">3</ref>.1 shows the results for the Country style pattern. <ref type="foot" target="#foot_25">6</ref> Finally, document-based mapping analyses the content of the top-k pages returned by Google. That is, the algorithm downloads the most representative pages, according to the query, and then counts the music related terms found in the k pages. It is worth noting that these three methods can also be used not only to characterise the artists, but to compute artist similarity.</p><p>Similar work based on co-occurrences is presented in <ref type="bibr">[21,</ref><ref type="bibr">22]</ref>. In <ref type="bibr">[21]</ref>, the authors define artist similarity as the conditional probability of an artist that occurs on a web page that was returned as response to querying another artist. In <ref type="bibr">[22]</ref>, the authors focus on artist genre classification, using three different genre taxonomies. An artist assignment to a genre is considered as a special form of co-occurrence analysis. An evaluation performed on a small dataset shows an accuracy of over 85%. Related to this, Zadel and Fujinaga investigate artist similarity using Amazon and Listmania! APIs, and then Google to refine the results, using artist co-occurrences in webpages <ref type="bibr">[26]</ref>.</p><p>One of the main drawbacks of Web-MIR is the polysemy of some artists' names, such as Kiss, Bush, Porn <ref type="bibr">[27]</ref>. This problem is partially solved by the same authors, in <ref type="bibr">[28]</ref>. Based on T F-IDF, they penalise the terms with high DF, that is the terms that appear in lots of documents.</p><p>A common drawback of all the previous approaches is the high dimensionality of the datasets. To avoid this problem, Pohle et al. use Non-negative Matrix Factorisation to reduce the dimensionality of the artist-term matrix <ref type="bibr">[29]</ref>. They also use a predefined vocabulary of music terms, and analyse the content of the top-100 web pages related to each artist. To get the most relevant pages, they use a similar approach as Whitman and Lawrence <ref type="bibr">[20]</ref>. The original matrix contains all the terms applied to the artists, using T F-IDF weights. This matrix is decomposed into 16 factors, or "archetypical" concepts using non-negative matrix factorisation. Then, each artist is described by a 16-dimensional vector. After that, a music browser application allows users to navigate the collection by adjusting the weights of the derived concepts, and also can recommend similar artists using cosine distance over the artists' vectors.</p><p>Another source to derive artist or song similarity is based on the analysis of available (or manually created) playlists on the web. Automatic playlists based on song co-occurrences typically use web data mining techniques to infer song similarity. That is crawling public playlists, and computing song or artist co-occurrence from this data. For instance, Baccigalupo et al. <ref type="bibr">[30]</ref> analysed artists co-occurrences using a set of more than 1 million playlists from the MyStrands web. Pachet also computes artist and song co-occurrences from radio sources using a big database of CD compilations, extracted from CDDB <ref type="bibr">[31]</ref>. Cunningham et al. state that playlists contain a lot of context, and only humans are able to interpret it (e.g. "music about my holidays back in 1984") <ref type="bibr">[3]</ref>. According to a user survey done by the same authors, only 25% of the mixes are organised using content related information, such as artist, genre or style. The rest is based on contextual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.2">Collecting Ground Truth Data</head><p>An important aspect when trying to evaluate similarity metrics using cultural metadata is the creation of reliable ground truth data. Different proposals are presented in <ref type="bibr">[19,</ref><ref type="bibr">24,</ref><ref type="bibr">32,</ref><ref type="bibr">33]</ref>. The problem of gathering ground-truth for music similarity evaluation is outlined in <ref type="bibr">[34]</ref>. In <ref type="bibr">[33]</ref>, Geleijnse et al. create a dynamic ground truth for artist tagging and artist similarity. The idea is to adapt to the dynamically changing data being harvested by social tagging (e.g. from last.fm), instead of defining a static and immutable ground truth.</p><p>To summarise, Turnbull et al. present five different ways to collect annotations at artist (or song) level. These approaches are <ref type="bibr">[35]</ref>:</p><p>• mining web documents, • harvesting social tags, • autotagging audio content, • deploying annotation games, and • conducting a survey Cultural information, based on Web-MIR and social tagging techniques, is the basis for context-based music recommenders. Section 3.4.2 presents the main ideas to exploit cultural information, and use it to provide music recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.3">Social Tagging Vandalism: The Paris Hilton -Brutal Death Metal Case</head><p>When using data from the wisdom of the crowds one needs to pay attention to users' intentional misuse or mistag of the items. That is, social tagging spam, or vandalism. In May 2007, while Paul Lamere and myself were preparing the Music Recommendation Tutorial for the ISMIR conference, he found out a problem with Paris Hilton artist tags in last.fm. <ref type="foot" target="#foot_26">7</ref> A group of users were deliberately tagging her with Brutal Death Metal tag. <ref type="foot" target="#foot_27">8</ref> Of course, this affected the recommendations of the system, where all of a sudden one could hear a death metal song in a Paris Hilton playlist (and the other way around!). Figure <ref type="figure" target="#fig_18">3</ref>.5 shows a last.fm screenshot <ref type="foot" target="#foot_28">9</ref> with top artists tagged with Brutal Death Metal. Top-1 artist is Paris Hilton. Indeed, looking at her raw tag counts in Table <ref type="table" target="#tab_6">3</ref>.2, we see that top-1 tag is Brutal Death Metal. Also, there are some other descriptive-so to say-tags such as atainwptiosb, <ref type="foot" target="#foot_29">10</ref> Your ears will bleed, or the worst thing ever to happen to music. It is clear that some users were having fun with her. Social tagging spam is a problem for any music recommender system that relies on this type of data to derive artist (or track) similarity. We outline some possible solutions to post-process the artist's tag list, and "clean" it: Tagger reliability. The system might try to reduce the influence of untrusted taggers (tagger reliability). Some questions that might help identifying those users are:</p><p>• Does the tagger listen to the music they are tagging (e.g. Paris Hilton music)?</p><p>• Does the tagger often use the tags that they are applying? (e.g. atainwptiosb or the worst thing ever to happen to music) • Does anyone else use those (potential spam) tags to other artists?</p><p>Once the system identifies them, it can act accordingly. For instance, diminishing the tagging effect of these users.</p><p>Tag Clustering. The idea here is to compare other Paris Hilton tags (such as pop, female vocalist, sexy or guilty pleasure) against Brutal Death metal tag. This way, we can see whether all these tags are correlated, and belong to the same semantic cluster. Table <ref type="table" target="#tab_6">3</ref>.3 shows different examples of tag similarity, using a last.fm dataset with 84,838 artists and 187,551 distinct tags. We apply Latent Semantic Analysis (LSA). That is, to compute Singular Value Decomposition (SVD) over the artist-tag-frequency matrix, reducing it to 100 factors or dimensions (see Sec. 2.5.2). After that, we use cosine similarity to compute tag similarity. There is no semantic similarity between Brutal Death Metal and pop, female vocalist, sexy or guilty pleasure. On the other hand, pop and guilty pleasure, or sexy and female vocalist are much more similar (see the last two examples in Table <ref type="table" target="#tab_6">3</ref>.3). Figure <ref type="figure" target="#fig_18">3</ref>.6 shows a denodogram, based on the LSA cosine similarity from Table <ref type="table" target="#tab_6">3</ref>.3. The resulting hierarchical clustering shows how Brutal Death Metal belongs to a different, isolated, cluster than the rest of the tags.</p><p>LSA cosine similarity(Tag 1 , Tag 2 ) sim(brutal death metal, pop) = 0.055 sim(brutal death metal, female vocalist) = 0.034 sim(brutal death metal, sexy) = 0.066 sim(brutal death metal, guilty pleasure) = 0.027 sim(pop, guilty pleasure) = 0.399 sim(sexy, female vocalist) = 0.759 Table <ref type="table" target="#tab_6">3</ref>.3 LSA cosine similarity between Brutal Death Metal and some other Paris Hilton tags.</p><p>Furthermore, one can get the tags from other artists correctly tagged with Brutal Death metal (e.g. death metal, extreme metal, gore metal or grindcore), and see whether these tags also appear in (or, in general, co-occur with) other Paris Hilton tags. The underline idea here is to detect artist tags that could be outliers (i.e. potential spam tags). Listening habits. Taking into account how many users listen to both Paris Hilton and any other Brutal Death Metal band can give us an insight on how related are those artists. That is, to compute the (co-occurrence analysis or collaborative filtering) similarity between her and some other prominent death metal artists. To conclude this section, Table <ref type="table" target="#tab_6">3</ref>.4 presents the solution proposed by last.fm. It shows a list of tags for Paris Hilton, after a post-processing and cleaning algorithm. Their solution was partly inspired on Koutrika's work <ref type="bibr">[36]</ref>. We can see how now Brutal Death Metal is not anymore at position top-1. It still appears in the list, but with a lower (normalised) relevance of 11 out of 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Acoustic Metadata</head><p>The last category of semantic music description is acoustic metadata. Acoustic metadata extracts features from the audio, using content-based analysis. Semantic acoustic descriptors are the basis for content-based music recommenders (see Sect. 3.4.3). Figure <ref type="figure" target="#fig_18">3</ref>.7 depicts the relationship between acoustic metadata and the music information plane. Most of the current music content processing systems operating on complex audio signals are mainly based on computing low-level signal features. These features are good at characterising the acoustic properties of the signal, returning a description that can be associated to a texture. A more general approach consists in describing music content according to several "musical facets" (i.e. rhythm, harmony, melody, timbre, etc.) by incorporating higher-level semantic descriptors. Semantic descriptors can be computed directly from the audio signal combining signal processing, machine learning, and musical knowledge. The following sections are devoted to outlining some relevant music description facets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.1">Low-Level Timbre Descriptors</head><p>To describe the audio it is very usual to decompose the audio signal with spectral and temporal features. Spectral features are considered more robust to polyphonic and complex textures. The signal is segmented into (overlapping) frames, generally from 10 to 100 ms with, say, 50% overlap. For each frame, a feature vector is computed. Now, we briefly present some of the most important low-level timbre features to describe the audio signal. Most of them are based on the Short-Time Fourier Transform (STFT):</p><p>• Spectral Centroid is a concept adapted from psychoacoustics and music cognition. Spectral Centroid is the mean value of the STFT amplitude spectrum. It measures the average frequency, weighted by amplitude, of the spectrum. • Spectral Flatness is the ratio between the geometrical mean and the arithmetical mean of the spectrum magnitude. • Spectral Skewness is the 3rd order central moment, and it gives indication about the shape of the spectrum. • Spectral Kurtosis is the 4th order central moment. It measures whether the data are peaked or flat relative to a normal (Gaussian) distribution. • Zero-Crossing Rate (ZCR) is a temporal descriptor defined as the number of time domain zero-crossings within a defined region of signal, divided by the number of samples of that region. It measures, then, the rate of sign-changes along the audio signal. • Mel Frequency Cepstrum Coefficients (MFCCs) <ref type="bibr">[37]</ref> are widely used in speech recognition applications. MFCC are calculated as follows:</p><p>1. Divide the audio signal into frames. 2. For each frame, obtain the amplitude spectrum.</p><p>3. Take the logarithm. 4. Convert to Mel spectrum. 5. Take the discrete cosine transform (DCT).</p><p>Step 4 calculates the log amplitude spectrum on the Mel scale. The Mel transformation is based on human perception experiments. Then, step 5 takes the DCT of the Mel spectra.</p><p>The bag-of-frames timbre approach consists in modelling the audio signal using a statistical distribution of the audio features, on short-time audio segments. Audio features are then aggregated together using simple statistics (e.g. mean and variance), or modelled as a Gaussian Mixture Model (GMM). However, as pointed out by Aucouturier and Pachet in <ref type="bibr">[38]</ref>, a timbre representation based on MFCCs and GMMs tend to create hubs. These are songs that are irrelevantly close to every other songs.</p><p>Furthermore, similarity methods solely based on describing timbre information tend to find similar pieces that belong to different music genres. It is very unlikely that a user will love both a Franz Schubert's piano sonata, and a Meat Loaf ballad just because the two contain a prominent piano melody. In the following sections we present other music facets that complement timbre audio features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.2">Instrumentation</head><p>Extracting truly instrumental information from music, as pertaining to separate instruments or types of instrumentation implies classifying, characterising and describing information which is buried behind many layers of highly correlated data. Given that the current technologies do not allow a sufficiently reliable separation, most research work has concentrated on the characterisation of the "overall" timbre or "texture" of a piece of music as a function of low-level signal features. This approach implied describing mostly the acoustical features of a given recording, gaining little knowledge about its instrumental contents <ref type="bibr">[39]</ref>.</p><p>Even though it is not yet possible to fully separate the different contributions and "lines" of the instruments, there are some simplifications that can provide useful descriptors (e.g. lead instrument recognition, solo detection). The recognition of idiosyncratic instruments, such as percussive ones, is another valuable simplification. Given that the presence, amount and type of percussion instruments are very distinctive features of some music genres percusive information can be exploited to provide other natural partitions to large music collections. Herrera et al. define semantic descriptors such as the percussion index, or the percussion profile <ref type="bibr">[40]</ref>. Although they can be computed after doing (simple) source separation, reasonable approximations can be achieved using simpler sound classification approaches that do not attempt separation <ref type="bibr">[41]</ref>. Additionally, <ref type="bibr">[42]</ref> presents an instrument identification, of mono-instrumental music, using line spectral frequencies (LSF) and k-means classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.3">Rhythm</head><p>In its most generic sense, rhythm refers to all of the temporal aspects of a musical work, whether represented in a score, measured from a performance, or existing only in the perception of the listener <ref type="bibr">[43]</ref>. In the literature the concept of "automatic rhythm description" groups many applications as diverse as tempo induction, beat tracking, rhythm quantisation, meter induction and characterisation of timing deviations, to name a few. Many of these different aspects have been investigated, from the low-level onset detection, to the characterisation of music according to rhythmic patterns.</p><p>At the core of automatic rhythmic analysis lies the issue of identifying the start, or onset time, of events in the musical data. As an alternative to standard energybased approaches, another methodologies have recently appeared: a method that works solely with phase information <ref type="bibr" target="#b153">[44]</ref>, or that are based on predicting the phase and energy of signal components in the complex domain <ref type="bibr" target="#b154">[45]</ref>, greatly improving results for both percussive (and tonal) onsets. However, there is more to rhythm than the absolute timings of successive musical events. For instance, <ref type="bibr" target="#b155">[46]</ref> proposes a general model of beat tracking, based on the use of comb-filtering techniques on a continuous representation of "onset emphasis". This method was expanded to combine this general model with a context-dependent model by including a state space switching model. This improvement has been shown to significantly improve upon previous results, in particular with respect to maintaining a consistent metrical level and preventing phase switching between off-beats and on-beats.</p><p>Furthermore, the work done by <ref type="bibr">Gouyon and Dixon ([47,</ref><ref type="bibr" target="#b157">48]</ref>) demonstrates the use of high-level rhythmic descriptors for genre classification of recorded audio. An example is a tempo-based classification showing the high relevance of this feature while trying to characterise dance music <ref type="bibr" target="#b156">[47]</ref>. However, this approach is limited by the assumption that, given a musical genre, the tempo of any instance is among a very limited set of possible tempi. To address this, <ref type="bibr" target="#b157">[48]</ref> use bar-length rhythmic patterns for the classification of dance music. The method dynamically estimates the characteristic rhythmic pattern on a given musical piece, by a combination of beat tracking, meter annotation and a k-means classifier. Genre classification results are greatly improved by using these high-level descriptors, showing the relevance of musically-meaningful representations for Music Information Retrieval tasks. Dannenberg presents in <ref type="bibr" target="#b158">[49]</ref> a holistic approach toward automated beat tracking, taking into account music structure. Last but not least, for a complete overview of the state of the art on rhythmic description the reader is referred to <ref type="bibr">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.4">Harmony</head><p>The harmony of a piece of music can be defined by the combination of simultaneous notes, or chords; the arrangement of these chords along time, in progressions; and their distribution, which is closely related to the key or tonality of the piece. Chords, their progressions, and the key are relevant aspects of music perception that can be used to accurately describe and classify music content.</p><p>Harmonic based retrieval has not been extensively explored before. A successful approach at identifying harmonic similarities between audio and symbolic data was presented in <ref type="bibr" target="#b159">[50]</ref>. It relied on automatic transcription, a process that is partially effective within a highly constrained subset of musical recordings (e.g. mono-timbral, no drums or vocals, small polyphonies). To avoid such constraints <ref type="bibr" target="#b160">[51]</ref> adopts the approach where describes the harmony of the piece, without attempting to estimate the pitch of notes in the mixture. Avoiding the transcription step allows to operate on a wide variety of music. This approach requires the use of a feature set that is able to emphasise the harmonic content of the piece, such that this representation can be exploited for further, higher-level, analysis. The feature set of choice is known as a Chroma or Pitch Class Profile, and they represent the relative intensity of each of the twelve semitones of the equal-tempered scale.</p><p>Gómez et al. present in <ref type="bibr" target="#b161">[52]</ref> an approach of the tonality estimation by correlating chroma distributions with key profiles, derived from music cognition studies. Results show high recognition rates for a database of classical music. The studies done in <ref type="bibr" target="#b162">[53]</ref> have also concentrated on chord estimation based on chroma features, using tuning, and a simple template-based model of chords. Recognition rates of over 66% were found for a database of recorded classical music, though the algorithm is being used also with other musical genres. A recent development includes the generation of a harmonic representation using a Hidden Markov Model, initialised and trained using musical theoretical and cognitive considerations <ref type="bibr" target="#b163">[54]</ref>. This methodology has already shown great promise for both chord recognition and structural segmentation. For a deeper overview of harmonic and tonality description see <ref type="bibr" target="#b164">[55]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.5">Structure</head><p>Music structure refers to the ways music materials are presented, repeated, varied or confronted along a piece of music. Strategies for doing that are artist, genre and style-specific (i.e. the A-B themes exposition, development and recapitulation of a sonata form, or the intro-verse-chorus-verse-chorus-outro of "pop music"). Detecting the different structural sections, the most repetitive segments, or even the least repeated segments, provide powerful ways of interacting with audio content based on summaries, fast-listening and musical gist-conveying devices, and on-thefly identification of songs.</p><p>The section segmenter developed by Ong and Herrera in <ref type="bibr" target="#b165">[56]</ref> extracts segments that roughly correspond to the usual sections of a pop song or, in general, to sections that are different (in terms of timbre and tonal structure) from the adjacent ones. The algorithm first performs a rough segmentation with the help of change detectors, morphological filters adapted from image analysis, and similarity measurements using low-level descriptors. It then refines the segment boundaries using a different set of low-level descriptors. Complementing this type of segmentation, the most repetitive musical pattern in a music file can also be determined by looking at self-similarity matrices in combination with a rich set of descriptors including timbre and tonality (i.e. harmony) information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.6">Intensity</head><p>Subjective intensity, or the sensation of energeticness we get from music, is a concept commonly and easily used to describe music content. Although intensity has a clear subjective facet, Sandvold et al. hypothesised that it could be grounded on automatically extracted audio descriptors. Inspired by the findings of Zils and Pachet in <ref type="bibr" target="#b166">[57]</ref>, Sandvold et al. created a model of subjective intensity built from energy and timbre low-level descriptors extracted from the audio data <ref type="bibr" target="#b167">[58]</ref>. They have proposed a model that decides among 5 labels (ethereal, soft, moderate, energetic, and wild), with an estimated effectiveness of nearly 80%. The model has been developed and tested using several thousands of subjective judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.7">Genre</head><p>Music genres are connected to emotional, cultural and social aspects, and all of them influence our music understanding. The combination of these factors produce a personal organization of music which is, somehow, the basis for (human) musical genre classification. Indeed, musical genres have different meanings for different people, communities, and countries <ref type="bibr" target="#b168">[59,</ref><ref type="bibr" target="#b169">60]</ref>.</p><p>The use of musical genres has been deeply discussed by the MIR community. A good starting point is the review by McKay <ref type="bibr" target="#b170">[61]</ref>. The authors suggest that musical genres are an inconsistent way to organize music. Yet, musical genres remain a very effective way to describe and tag artists. Broadly speaking, there are two complementary approaches when defining a set of genre labels: (i) the definition of a controlled vocabulary by a group of experts or musicologists, and (ii) the collaborative effort of a community (social tagging). The goal of the former approach is the creation of a list of terms, organised in a hierarchy. A hierarchy includes the relationships among the terms; such as hyponymy. The latter method, social tagging, is a less formal bottom-up approach, where the set of terms emerge during the (manual) annotation process.</p><p>Music genre classification is a classic MIR problem. The setup consists of predicting one (or more) genre labels from the audio. Most of the approaches use machine learning methods to train a classifier per genre, using a combination of audio features. Early work in automatic genre classsification is presented by Tzanetakis and Cook <ref type="bibr" target="#b171">[62]</ref>. The authors use timbre related features (Spectral Centroid, Spectral Rolloff, Spectral Flux, and MFCC) as well as rhythm features based on the beat histogram. A complete state of the art on music genre classification is presented in <ref type="bibr" target="#b172">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.8">Mood</head><p>According to Juslin and Laukka, people listen to music mostly to change their emotional state <ref type="bibr" target="#b173">[64]</ref>. When dealing with such subjective question, we are faced with several issues. The first one is the emotion representation paradigm. There exist two main mood representations from psychology: a dimensional, continuous model, and a categorical, discrete list. As advised by Juslin et al., one should consider few categories when building a ground truth that maximises the agreement between people <ref type="bibr" target="#b174">[65]</ref>.</p><p>Extracting moods from the audio is a very challenging task. In the Music Information Retrieval field only recent work, using exclusively audio content, deals with this problem. Most of these approaches use machine learning techniques, training a classifier with some selected audio features <ref type="bibr" target="#b175">[66]</ref><ref type="bibr" target="#b176">[67]</ref><ref type="bibr" target="#b177">[68]</ref>. Laurier et al. observe from the audio analysis (using timbre, rhythm and tonal descriptors) the correlation between psychological emotions and musical features <ref type="bibr" target="#b177">[68]</ref>. For example a fast tempo (onset rate feature) and major tonality song is classified as happy, while a slow tempo and minor tonality might correspond to a sad emotion. Given the limitations to classify music emotions using only audio content-based features, recent approaches include hybrid methods combining contextual (e.g mood tags) and audio content information <ref type="bibr" target="#b178">[69]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.9">Tools and Resources</head><p>We briefly present in Table <ref type="table" target="#tab_6">3</ref>.5 some audio processing tools and libraries. This software is widely used in the Music Information Retrieval community. It is not our goal to detail the pros and cons of each tool. We list them here as starting point for those readers interested in extracting audio features, and computing audio content-based similarity on top of them. Other libraries that extract low-level descriptors such as MFCC/GMM are: Music Browser (in Matlab), 11 and Auditory Toolbox, 12 also in Matlab. Furthermore, "The Tools We Use" webpage 13 compiles a list of resources that the MIR community widely uses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Recommendation Methods</head><p>In this section, we present the music recommendation methods to match user preferences (see Sec. 3.2) with the artist and music description (presented in the previous Sec. 3.3). 11 http://www.jj-aucouturier.info/projects/mir/ 12 http://cobweb.ecn.purdue.edu/ ˜malcolm/interval/1998-010/ 13 http://www.music-ir.org/evaluation/tools.html</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Collaborative Filtering</head><p>Collaborative filtering (CF) techniques have been largely applied in the music domain. CF makes use of the editorial and cultural information. Early research was based on explicit feedback, based on the ratings about songs or artists. Yet, tracking user listening habits has become the most common way in music recommendation. In this sense, CF has to deal with implicit feedback (instead of explicit ratings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.1">Explicit Feedback</head><p>Ringo, described in <ref type="bibr" target="#b179">[70]</ref>, is the first music recommender based on collaborative filtering and explicit feedback (ratings). The author applies user-based CF approach (see Sec. 2.5.2). Similarity among users is computed with Pearson normalised correlation (see Eq. 2.3). Then, the recommendations are computed as the mean of the ratings done by the similar users of the active user (see Eq. 2.6).</p><p>Racofi (Rule Applying COllaborative FIltering) approach combines collaborative filtering based on ratings, and a set of logic rules based on Horn clauses <ref type="bibr" target="#b180">[71]</ref>. The rules are applied after the ratings have been gathered. The five rating dimensions they define are: impression, lyrics, music, originality, and production. The objective of the rules is to prune the output of the collaborative filtering, and promote the items that the user will be most familiar with. Anderson et al. exemplifies a rule <ref type="bibr" target="#b180">[71]</ref>: If a user rates 9 the originality of an album by artist X then the predicted originality rating, for this user, of all other albums by artist X is increased by a value of 0.5.</p><p>These kind of rules implicitly modify the ratings that a user has done previously. The Indiscover music recommender system <ref type="foot" target="#foot_30">14</ref> implements this approach, as well as the Slope One collaborative filtering method, presented in <ref type="bibr" target="#b181">[72]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.2">Implicit Feedback</head><p>Implicit feedback in the music domain is usually gathered from users' listening habits. The main drawback is that the value that a user assigns to an item is not always in a predefined range (e.g. from 1..5 or like it/hate it). Instead, the interaction between users and items is usually described by songs she listens to, or the total playcounts. Thus, the system can only track (implicit) positive feedback. Negative feedback cannot be gathered. Only when users explicitly rate the content, the range of values include both positive and negative feedback (e.g. from 1..5 stars, where 1 means a user does not like the item, 3 indifference, and 5 she loves it).</p><p>Furthermore, recommendations are usually performed at artist level (unless the system generates a playlist for that user), whilst listening habits are at song level. In this case, an aggregation process-from song plays to artist total playcounts-is needed. To use CF with implicit feedback at artist level, there are different options:</p><p>• Convert the implicit data into a binary user-artist matrix M. Non-zero cells mean that the user has listened to the artist at least once. • Transform the implicit data into a normalised matrix. Instead of assigning 0/1 to a cell, the value can denote how much a user listens to the artist. E.g. [0..5], where 5 denotes that she listens to a lot the artist, 1 means only from time to time, and 0 never. This matrix has a more fine-grained description of the user listening habits than the previous, binary, normalisation. • Normalise each row (users), so that the sum of the row entries equal 1. This option, then, describes the artist probability distribution of a user. • Do not normalise the matrix. The matrix contains for each user and artist (M i, j ) the total playcounts.</p><p>In any case, after the dataset is represented in the user-artist matrix, one can apply any CF methods with explicit feedback (presented in Sec. 2.5.2).</p><p>It is common that the user's listening habits distribution is skewed to the right, so it shows a heavy-tailed curve. That is, a few artists have lots of plays in the user profile, and the rest of artists have much less playcounts. Figure <ref type="figure" target="#fig_18">3</ref>.8 depicts the listening habits of a user in terms of total playcounts. The horizontal axis contains her top-50 artists, ranked by the total plays (i.e. artist at position 1 has 238 playcounts). Then, we compute the complementary cumulative distribution of artist plays in the user profile. Artists located in the top 80-100% of the distribution get a score of 5, artists in the 60-80% range get a 4, and so on (until the artists with less playcounts, in the 0-20% range, which get assigned a 1). The rest of the M i cells have value 0. Figure <ref type="figure" target="#fig_18">3</ref>.9 shows the complementary cumulative distribution of the artist playcounts from Fig. <ref type="figure" target="#fig_18">3</ref>.8. Sometimes, the listening habits distribution of a user is not skewed, but very homogeneous (a small standard deviation value, and a median close to the mean value). To detect this type of distribution, we use the coefficient of variation, CV . CV is a normalised measure of dispersion of a probability distribution, that divides the standard deviation by the mean value, CV = σ μ . In our case, the standard deviation of plays by the mean value of plays, for a given user. Then, if CV ≤ 0.5 we do not use the complementary cumulative distribution. Instead, we assign a value of 3 to all the user artists, meaning that all the artists in the profile have a similar number of plays.</p><p>The next step is to compute artist similarity using the user-artist M matrix. Once the normalisation process is done, it is straightforward to compute the average value of normalised plays for an artist, as well as for a user-in case that the item similarity measure to use is either adjusted cosine (Eq. 2.2) or Pearson correlation (Eq. 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.3">An Example</head><p>We have done some experiments with data obtained from last.fm. The dataset contains the top-artists playcounts for more than 500,000 users, with a total of around 30 million user, artist, playcount triples. To clean the list of artists, we only use those artists that have a Musicbrainz 15 ID, and also that at least 10 users listened to them once or more. After the cleaning process, we get a list of around 95,000 distinct artists. To apply CF, we transformed the listening habits dataset to a user-artist matrix M. M i, j represents the number of times user i has listened to artist j. To nor-malise the matrix we followed the second approach; computing the complementary cumulative distribution. That is to assign a range value [0..5] in M i, j from the user i , artist j , playcount (as shown in Fig. <ref type="figure" target="#fig_18">3</ref>.9). We present two concrete examples of item-similarity using Pearson correlation, (Eq. (2.3)) and conditional probability (Eq. 2.4) from user-artist matrix M. Table <ref type="table" target="#tab_6">3</ref>.6 (left) shows the top-10 similar artists of The Dogs d'Amour, <ref type="foot" target="#foot_32">16</ref> whilst the right column shows the results obtained using conditional probability similarity. We can see that the asymmetric conditional probability metric is completely biased towards popular artists, whilst Pearson similarity contains artists across the long tail, also ranging different styles (including some unexpected results, such as Michael Jackson or Zero 7). Top-10 similar artists list, obtained by conditional probability, contain some of the most representative and prototypical artists of the seed artist's main styles (that is, glam, rock, and hard-rock). The similarity value using conditional probability is also quite informative; 48.4% of the users who listen to The Dogs d'Amour also listen to Guns n' Roses (but not the other way around!).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Context-Based Filtering</head><p>As introduced in Sec. 3.3.3, context-based filtering uses cultural information to compute artist or song similarity. Context-based filtering is based on web mining techniques, or mining data from collaborative tagging (see Sec. 2.5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.1">An Example</head><p>Now, we present some examples from the 3-order tensor of user, artist,tag, value triples, using data from last.fm. The dataset contains 84,838 artists, and 187,551 distinct tags. We decompose the tensor, and use the artist-tag A matrix. A i, j contains the (last.fm normalised) relevance of tag j for artist i. Then, we apply Latent Semantic Analysis (LSA). LSA uses Singular Value Decomposition (SVD) to infer the hidden relationships in the data. LSA is used in Information Retrieval to compute document similarity, and also to detect term similarity (e.g. synonyms). In our case, we can consider that a document equals to an artist, and the terms that appear in the document are the artist's tags. Then, we apply SVD to reduce the matrix A to 100 factors (dimensions). After that, cosine similarity is used to derive artist similarity. Table <ref type="table" target="#tab_6">3</ref>.7 shows the top-10 similar artists to The Dogs d'Amour. One problem using this approach is that the distance to the seed artist (in the 100-dimensional space) is very high, even for an artist at position top-100 in the similarity list. For instance, The Dogs d'Amour top-20 similar artist, Gilby Clarke, has a similarity value of 0.936, and the artist at top-100 (Babylon A.D.) has 0.868. Both artists could easily appear in the list of The Dogs d'Amour similar artists, but probably they will not (at least, they will not appear in the first page). Then, when presenting a list of The Dogs d'Amour similar artists, the user can miss some artists that are at position top-80, and that are still relevant. This happens because the semantic distance based on tags (using the 100 factors after applying SVD) is very coarse. To overcome this problem, we present in sec. 3.4.3 a hybrid approach that combines collaborative filtering and social tagging, producing more reliable results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Content-Based Filtering</head><p>In the music domain, audio content-based methods rank tracks based on how similar they are according to a seed song. A music recommender system using audio content-based analysis has to compute the similarity among songs, in order to recommend music to the user. Artist similarity can also be computed, by agreggating song similarity results. There are two orthogonal ways to describe the audio content; manually or automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.1">Music Similarity Based on Manual Audio Content Description</head><p>Human-based annotation of music is very time consuming, but can be more accurate than automatic feature extraction methods. Pandora's approach is based on manual descriptions of the audio content. Pandora's web site explains their procedure<ref type="foot" target="#foot_33">17</ref> :</p><p>(...) our team of thirty musician-analysts have been listening to music, one song at a time, studying and collecting literally hundreds of musical details on every song. It takes 20-30 minutes per song to capture all of the little details that give each recording its magical sound -melody, harmony, instrumentation, rhythm, vocals, lyrics ... and more-close to 400 attributes! (...)</p><p>The analysts have to annotate around 400 parameters per song, using a ten point scale [0..10] per attribute. There is a clear scalability problem; time-constraints allow people to add about 15,000 songs per month. Also, they have to deal with the variability across the analysts. Cross validation is also needed in order to assure the quality (and avoid analysts' bias) of the annotations.</p><p>Simple weighted Euclidean distance is used to find similar songs. <ref type="foot" target="#foot_34">18</ref> Song selection is, then, based on nearest neighbors. However, they assign specific weights to important attributes, such as genre. For artist similarity they only use specific songs, not an average of all the artist's songs. Pandora's ultimate goal is to offer a mix of familiarity, diversity, and discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.2">Music Similarity Based on Automatic Audio Content Description</head><p>Early work on audio similarity is based on low-level descriptors, such as Mel Frequency Cepstral Coefficients (MFCC). These approaches aimed at deriving timbre similarity, but have also been used to take on other problems, such as genre classification. Foote proposed a music indexing system based on MFCC histograms in <ref type="bibr" target="#b182">[73]</ref>. Audio features are usually aggregated together using mean and variance, or modelling it as a Gaussian Mixture Model (GMM). Using mean and variance for the first N MFCCs, a simple (weighted) Euclidean distance, d(X,Y ), can be used to compute audio similarity between two songs X and Y .</p><p>Aucouturier et al. present a Gaussian mixture model (GMM) based on MFCCs <ref type="bibr" target="#b183">[74]</ref>. Similarity measures on top of the GMM timbre model includes Kullback-Leibler (KL) divergence, and the Earth Mover's distance (EMD). KL divergence measures the relative similarity between two Gaussian distributions of data. A small divergence in the distributions means that the two songs are similar. Equation (3.1) shows a closed form symmetric approximation of the Kullback-Leibler divergence between two songs X and Y . The timbre model used is a single Gaussian with full covariance matrix.</p><formula xml:id="formula_17">d(X,Y ) = Tr(Σ -1 X Σ Y )+Tr(Σ -1 Y Σ X )+Tr((Σ -1 X Σ -1 Y )(μ X -μ Y )(μ X -μ Y ) T )-2N MFCC (3.1)</formula><p>where μ X and μ Y are MFCC means, Σ X and Σ Y are MFCC covariance matrices, Tr(M) the trace of matrix M, and N MFCC the number of MFCCs used (for instance, 13).</p><p>Earth Mover's distance (EMD) has been largely applied in the image community to retrieve similar images <ref type="bibr" target="#b184">[75]</ref>. The EMD is defined as the minimum amount of work needed to change one (audio) signature to another. The adoption of this distance in the music field was first introduced by Logan in <ref type="bibr" target="#b185">[76]</ref>, where audio signatures are modelled with a GMM.</p><p>However, none of these two methods capture information about long-term structure elements, such as the melody, ryhthm, or harmony. To cope with this limitation, Tzanetakis extracted a set of features representing the spectrum, rhythm and harmony (chord structure) <ref type="bibr" target="#b186">[77]</ref>. Audio features are then merged into a single vector, and are used to determine song similarity. For a complete overview on audio similarity, the reader is referred to <ref type="bibr" target="#b187">[78]</ref>. One step further, Slaney et al. present in <ref type="bibr" target="#b188">[79]</ref> machine learning techniques to derive a robust metric for music similarity.</p><p>Cataltepe et al. present a music recommendation system based on audio similarity <ref type="bibr" target="#b189">[80]</ref>, where user's listening history is taken into account. The hypothesis is that users give more importance to different aspects of music. These aspects can be described and classified using semantic audio features. Using this adaptative contentbased recommendation scheme, as opposed to a static set of features, resulted in up to 60% of increment in the accuracy of the recommendations.</p><p>User's relevance feedback for a content-based music similarity system is presented in <ref type="bibr" target="#b190">[81]</ref>. To reduce the burden of users to input learning data into the system, they propose a method to generate user profiles based on genre preferences, and a posterior refinement based on relevance feedback from the recommendations <ref type="bibr" target="#b191">[82]</ref>.</p><p>Once the audio has been semantically annotated (see Sec. 3.3.4), and the audio similarity among the songs has been computed, content-based filtering for a given user is rather simple. It is based on presenting songs (or artists) that "sound" similar to the user profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.3">An Example</head><p>Now we present an example of artist similarity derived from automatic audio feature extraction. To compute artist similarity, we apply content-based audio analysis in an in-house music collection (T ) of 1.3 Million tracks of 30 secs. samples.</p><p>Distance between tracks, d(x, y), is based on the Euclidean distance over a reduced space using Principal Component Analysis (PCA). Audio features include not only timbral features (e.g. Mel frequency cepstral coefficients), but musical descriptors related to rhythm (e.g. beats per minute, perceptual speed, binary/ternary metric), and tonality (e.g. chroma features, key and mode), among others <ref type="bibr" target="#b192">[83]</ref>. Preliminary steps to compute the Euclidean distance are: (i) audio descriptor normalisation in the [0, 1] interval, and (ii) applying PCA to reduce the audio descriptors space to 25 dimensions.</p><p>To compute artist similarity we used the most representative tracks, T a , of an artist a, with a maximum of 100 tracks per artist. For each track, t i ∈ T a , we obtain the most similar tracks (excluding those from artist a).</p><formula xml:id="formula_18">sim(t i ) = argmin ∀t∈T (d(t i ,t)), (<label>3.2)</label></formula><p>and get the artists' names, A sim(t i ) , of the t i similar tracks. The list of (top-20) similar artists of a comes from A sim(t i ) , ranked by a combination of the artist frequency (how many songs from the artist are similar to seed track t i ), and the similarity distance (Eq. 3.3).</p><p>similar artists(a) = A sim(t i ) , ∀t i ∈ T a (3.3) Table <ref type="table" target="#tab_6">3</ref>.8 shows the top-20 similar artists for two seed artists, Aerosmith. <ref type="foot" target="#foot_35">19</ref> and Alejandro Sanz. <ref type="foot" target="#foot_36">20</ref> Regarding Aerosmith's top-20 similar artists, most of the bands belong to the same genre, that is classic hard rock. Yet, some bands belong to the punk/rock style (e.g. NOFX, MxPx, New Found Glory, Slick Shoes, and The Damned). These bands could still be considered relevant to a user that has a musical taste ranging from classic hard rock to punk/rock styles. However, there are two surprising and unexpected results. These are Die schäfer and Die flippers. Both bands fall into the German folk/pop style, and their music is very different from Aerosmith (or any other band in the Aerosmith's top-20 similar artists). Our guess is that they appear due to Aerosmith's quiet pop/rock ballads. Still, these two German artists can be considered as "outliers".</p><p>Alejandro Sanz is a Spanish singer/songwriter. His music fits into latin pop, ballads, and soft rock, all merged with a flamenco touch. Even though content-based is context agnostic, some similar artists also sing in Spanish (Gipsy Kings, Ricky Martin, Presuntos Implicados, Luis Miguel, Laura Pausini, Miguel Bosé and Maná). Furthermore, most of the similar artists come from his pop songs, like Ricky Martin, Harris, and Laura Pausini). In these cases, music similiarty and production artifacts probably predominate over melody and voice. Finally, there are some strange and incomprehensible artists, such as Graham Central Station (a long tail band, playing a mix of funk, soul, and rhythm and blues), and The Imperials (also a long tail band, that plays doo-wop and gospel music). Without any explanation or transparency about these recommendations, a user will probably perceive some of the similar artists as non-relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">Hybrid Methods</head><p>The combination of different approaches allows a system to minimise the issues that a solely method can have. One way to combine different recommendation methods is the cascade approach (see Sec. 2.5.5). Cascade is a step by step process. One technique is applied first, obtaining a ranked list of items. Then, a second technique refines or re-rank the results obtained in the first step.</p><p>For example, to compute artist similarity a system can first apply CF, and then reorder or combine the results according to the semantic distance from social tagging (LSA). Another option is first apply CF as well as the semantic distance from social tagging (LSA), and combine these results. After that, apply content-based audio similarity to rerank the similar artists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4.1">An example</head><p>Table <ref type="table" target="#tab_6">3</ref>.9 shows The Dogs d'Amour similar artists using a cascade hybrid method. First, The Dogs d'Amour top-100 similar artists are computed using CF, with Pearson correlation distance. In a second step, for each artist in this top-100 list we compute LSA-using SVD with 100 factors-and cosine similarity from the social tagging data, between the actual artist and the seed artist (The Dogs d'Amour). After that, we combine the results from Pearson CF with the results obtained in this second step. We use a linear combination function setting α = 0.5: <ref type="bibr">(3.4)</ref> This way we can improve the original CF results, and also the results obtained solely from social tagging. Indeed, the Pearson CF approach returned some strange and non-relevant results, such as Michael Jackson or Zero 7 (see Table <ref type="table" target="#tab_6">3</ref>.9, left). After reordering the results using social tagging data, both artists disappear from the top-10 (hybrid) list of similar artists. Also, some artists that were not in the CF top-10 appear in the final set of similar artists (Table <ref type="table" target="#tab_6">3</ref>.9, right), due to the linear combination of the two approaches (Pearson CF and LSA from tags).</p><formula xml:id="formula_19">sim(a i , a j ) Hybrid = (1 -α) • sim(a i , a j ) CF,Pearson + α • sim(a i , a j ) Context,LSA</formula><p>In this case, the cascade chain method makes sense. The first results are obtained taking into account the music users listen to; "people who listen to The Dogs d'Amour also listen to X". Then, the second step promotes those artists X that are closer, in the semantic community annotation space, to the seed artist. <ref type="foot" target="#foot_37">21</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4.2">Related Work</head><p>Related work in hybrid music recommendation is presented in Yoshii et al. <ref type="bibr" target="#b193">[84,</ref><ref type="bibr" target="#b194">85]</ref>. The origins of their work can be found in <ref type="bibr" target="#b195">[86]</ref>, where they present a hybrid music recommender system based on a probabilistic generative model, named three-way aspect model <ref type="bibr" target="#b196">[87]</ref>. The model explains the generative process for the observed data by introducing a set of latent variables. Their system integrates both explicit collaborative filtering and audio content-based features. Collaborative filtering contains the users' ratings for the songs, and it is based on a [0..2] scale. A zero means that the user does not like the song, 1 means indifference, and 2 that a user likes the song. Content-based audio features include a Gaussian Mixture Model using the 13 coefficients from MFCC. The authors improve the efficiency and scalability of the previous approach, using incremental learning in <ref type="bibr" target="#b194">[85]</ref>. Tiemann et al. investigate ensemble learning methods for hybrid music recommender algorithms in <ref type="bibr" target="#b197">[88]</ref>. This approach combines social and content-based methods, where each one produces a weak learner. Then, using a combination rule, it unifies the output of the weak learners. The results suggests that the hybrid approach reduces the mean absolute prediction error, compared to the weak learners used solely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Summary</head><p>This chapter has presented the main actors in music recommendation; user profiling and the representation of musical items, as well as the existing methods to recommend music assets given a user profile.</p><p>User preferences depends on the type of listener, and her level of engagement with the music. Furthermore, music perception is very subjective, and it is influenced by the context. In this sense, user profile representation is an important aspect. We have presented three different notations: UMIRL, MPEG-7 based, and Friend of a Friend. The former is one of the first attempts in this field. The UMIRL language is not formal enough, but a proposal that contains some interesting ideas. User preferences in MPEG-7 is the first big and serious attempt to formalise user modelling, related with the multimedia content. The main problem of this approach is that the MPEG-7 standard is too complex and verbose. It is not straight forward to generate user profiles following the notation proposed by the standard. The last proposal, Friend of a Friend profiles, is based on the Semantic Web initiative. It is the most flexible approach. As it is based on the Semantic Web premises, Friend of a Friend profiles can embed different ontologies, so it is extensible, and has richer semantics than the other two approaches.</p><p>In music recommedation, item-based similarity is the most common way to compute and predict the recommendations. Item profile representation, then, is the first step to compute item similarity, in order to provide music recommendations to a user. We describe the representation and modelling of music items via the Music Information Plane. MIP defines the different levels of complexity and abstraction of the music descriptions. Based on the MIP approach, we present three complementary ways to describe artists and songs; using editorial, cultural, and acoustic information. Similarity measures-based on the editorial, cultural, and acoustic information-are also introduced. Then, for each recommendation method, we present the resulting list of top-20 similar artists using The Dogs d'Amour rock band as seed artist. An informal evaluation shows that the hybrid approach, using a mix of collaborative filtering and social tagging, produces the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Links with the Following Chapters</head><p>An important remaining task is the formal evaluation of music (and user) similarity, as this is the basis to provide music recommendations. This evaluation is presented in Chap. 5, that presents the metrics, and Chap. 6, that contains the actual evaluation of real, and big datasets. Also, user's perceived quality of the recommendations is very important. We present, in Chap. 7, an experiment done with 288 subjects, that analyses the effects of providing novel and relevant music recommendations to users. Still, before going further into the evaluation process, we present in Chap. 4 the Long Tail phenomenon, and its effects in the music domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 4</head><p>The Long Tail in Recommender Systems</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Introduction</head><p>The Long Tail is composed of a small number of popular items, the well-known hits, and the rest are located in the heavy tail, those not sell that well. The Long Tail offers the possibility to explore and discover-using automatic tools; such as recommenders or personalised filters-vast amounts of data. Until now, the world was ruled by the Hit or Miss categorisation, due in part to the shelf space limitation of the brick-and-mortar stores. A world where a music band could only succeed selling millions of albums, and touring worldwide.</p><p>Nowadays, we are moving towards the Hit vs. Niche paradigm, where there is a large enough availability of choice to satisfy even the most Progressive-obscure-Spanish-metal fan. The problem, though, is to filter and present the right artists to the user, according to her musical taste.</p><p>Chris Anderson introduces in his book, "The Long Tail" <ref type="bibr">[1]</ref>, a couple of important conditions to exploit the content available in niche markets. These are: (i) make everything available, and (ii) help me find it. It seems that the former condition is already fulfilled; the distribution and inventory costs are nearly negligible. Yet, to satisfy the latter we need recommender systems that exploit the from hits to niches paradigm. The main question, though, is whether current recommendation techniques are ready to assist us in this discovery task, providing recommendations of the hidden gems in the Long Tail.</p><p>In fact, recommenders that appropriately discount popularity may increase total sales, as well as potentially increase the margins by suggesting more novel, or less known, products <ref type="bibr">[2]</ref>. Tucker et al. develop a theoretical model which shows how the existence of popular items can, in fact, benefit the perceived quality of niche products <ref type="bibr">[3]</ref>. As these niche items are less likely to attract customers, the ones they attract perceive the products as higher quality than the mainstream ones. The authors' findings contribute to the understanding that popularity affects the long tail of e-Commerce. Even though web 2.0 tools based on the user's history of purchases promote the popular goods, their results suggest that mainstreamness benefits the perceived quality of niche products. Again, the big problem is to develop filters and tools that allow users to find and discover these niche products.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Pre-and post-filters</head><p>In the brick-and-mortar era, the market pre-filtered those products with lower probability of being bought by people. The main problem was the limited physical space to store the goods. Nowadays, with the unlimited shelf space, there is no need to prefilter any product <ref type="bibr">[1]</ref>. Instead, what users need are post-filters to make the products available and visible, and get personalised recommendations, according to their interests. Still, when publishers or producers pre-filter the content they also contribute to cultural production. E.g. many books or albums would be a lot worse without their editors and producers.</p><p>One should assume that there are some extremely poor quality products along the Long Tail. These products do not need to be removed by the gatekeepers anymore, but can remain in the Long Tail forever. The advisors are the ones in charge of not recommending low quality goods. In this sense, <ref type="bibr">[4]</ref> proved that increasing the strength of social influence increased both inequality and unpredictability of success. As a consequence, popularity was only partly determined by quality. In fact, the quality of a work cannot be assessed in isolation, because our experience is so tied up with other people's experience of that work. Therefore, one can find items to match anyone's taste along the Long Tail. It is the job of the post-filters to ease the task of finding them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Music Long Tail</head><p>As already mentioned in Chap. 1, the "State of the Industry" report <ref type="bibr">[5]</ref> presents some insights about the long tail in music consumption. For instance, 844 million digital tracks were sold in 2007, but only 1% of all digital tracks-the head part of the curve-accounted for 80% of all track sales. Also, 1,000 albums accounted for 50% of all album sales, and 450,344 of the 570,000 albums sold were purchased less than 100 times. Music consumption is biased towards a few mainstream artists. Ideally, by providing personalised filters and discovery tools to the listeners, music consumption would be diversified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">The Long Tail of Sales Versus the Long Tail of Plays</head><p>When computing a Long Tail distribution, one should define how to measure the popularity of the items. In the music domain, this can be achieved using the total number of sales or the total number of plays. On the one hand, the total number of sales denote the current trends in music consumption. On the other hand, the total number of playcounts tell us what people listen to, independently of the release year of the album (or song).</p><p>In terms of coverage, total playcounts is more useful, as it can represent a larger number of artists. An artist does not need to have an album released, but a Myspacelike page, which includes the playcounts for each song. Gathering information about the number of plays is easier than collecting the albums an artist has sold. Usually, the number of sales are shown in absolute values, aggregating all the information, and these numbers are used to compare the evolution of music consumption over the years. The total number of plays give us more accurate information, as it describes what people listen to. Thus, we will define the Long Tail in music using the total playcounts per artist.</p><p>As an example, Table <ref type="table" target="#tab_18">4</ref>.1 shows the overall most played artists at last.fm in July, 2007. These results come from more than 20 million registered users. Although the list of top-10 artists are biased towards this set of users, it still represents the listening habits of a large amount of people. In contrast, Table <ref type="table" target="#tab_18">4</ref>.2 shows the top-10 artists in 2006 based on total digital track sales (last column) according to Nielsen Soundscan 2006 report <ref type="bibr">[6]</ref>. The second column (values in parenthesis) shows the corresponding last.fm artist rank. There is not a clear correlation between the two lists, and only one artist (Red Hot Chili Peppers) appears in both top-10 lists.</p><p>Furthermore, Table <ref type="table" target="#tab_18">4</ref>.3 shows the top-10 selling artists in 2006 based on total album sales (last column), again according to the Nielsen 2006 report. In this case, classic artists such as Johnny Cash (top-2) or The Beatles (top-5) appear. This reflects the type of users that still buy CDs. Regarding Carrie Underwood, she is an American country pop music singer who became famous after winning the fourth season of American Idol (2005). Carrie Underwood album, released in late 2005, became the fastest selling debut Country album. Keith Urban, Tim McGraw and Rascal Flatts are American country/pop songwriters with a leading male singer. In all these cases, they are not so popular in the last.fm community.</p><p>All in all, only The Beatles (in  From this informal analysis we conclude that popularity is a nebulous concept that can be viewed in different ways.</p><p>From now on, we characterise music popularity using the total playcounts of an artist, keeping in mind that the data is not correlated with the actual number of sales, and also that the data will be biased towards the subset of users that are taken into account (in our case, the entire last.fm community).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Collecting Playcounts for the Music Long Tail</head><p>In the music field, total artist playcounts allow us to determine artist popularity. There are at least two different ways to collect artists' plays from the web. The first one is using last.fm data, and the second one is using the data from Myspace. In principle, one should expect a clear correlation among both datasets. That is, if an artist has a lot of plays in one system then the same should happen in the other one. However, each system measures different listening habits. On the one hand, last.fm monitors what users listen to in virtually any device, whereas Myspace only tracks the number of times a song has been played in their embedded Flash player. On the other hand, Myspace data can track the number of plays for those artists that have not released any album, but a list of songs (or demos) that are available on the Myspace artist profile. In this case, it is very unlikely to gather this data from last.fm because the only available source to listen to the songs is via Myspace (specially if the artist forbids users to download the songs from Myspace). For example, the artist Thomas Aussenac has (on October 21st, 2008) 12,486 plays in Myspace<ref type="foot" target="#foot_39">1</ref> but only 63 in last.fm. <ref type="foot" target="#foot_40">2</ref> Therefore, sometimes (e.g. head and mid artists) both systems can provide similar listening habits results, whilst in other cases they track and measure different trends. Some plausible reasons about these differences could be due to the demographics and locale of both users and artists in the two systems.</p><p>Figure <ref type="figure" target="#fig_22">4</ref>.1 depicts the total playcounts for an artist in last.fm versus the total playcounts in Myspace (data gathered during January, 2008). That is, given the playcounts of an artist in last.fm, it plots its total plays in Myspace. We remark two interesting areas; upper left and bottom right. These areas are the ones with those artists whose playcounts are clearly uncorrelated between the two datasets. For instance, the upper left area shows the artists that have lots of plays in Myspace, but just a few in last.fm. The formula used to select the artists in this area is (it is analogous for the last.fm versus Myspace-in the bottom right area): That is, artists that have more than 100,000 plays in Myspace, but much less in last.fm. In this case, we could consider that some of these artists are well-known in the Myspace area, having lots of fans that support them, but the artist still has no effect outside Myspace. Maybe this type of artists can reach a broader popularity after releasing an album. For instance, Michael Imhof, <ref type="foot" target="#foot_41">3</ref> a German house and r&amp;b artist, has more than 200,000 playcounts in Myspace, but only 2 in last.fm. A more extreme example is Curtis Young<ref type="foot" target="#foot_42">4</ref> (aka Hood Surgeon), the son of legendary hiphop producer Dr. Dre, who has 13,814,586 plays in Myspace but less than 20,000 in last.fm. It is worth mentioning that there are some services <ref type="foot" target="#foot_43">5</ref> that allow a Myspace artist to automatically increase their total playcounts, without the need for real users.</p><formula xml:id="formula_20">Plays Myspace &gt; 10 5 ∧ log(Plays Myspace ) log(Plays Last. f m ) ≥ 1.5 (4.1)</formula><p>All in all, there are different ways of measuring an artist's popularity, and might even exist different domains of popularity; what is popular in one domain can be unknown in another. As previously stated, popularity is a nebulous concept that can be viewed in different ways.  devices) to track users' listening behaviour. It also provides a Flash player embedded in their website, and a client for PC, Mac and Linux that can create personalised audio streams. Figure <ref type="figure" target="#fig_22">4</ref>.2 corroborates the music consumption reports by Nielsen Soundscan <ref type="bibr">[5]</ref>; a few artists concentrate most of the total plays, whilst many musicians hold the rest. Figure <ref type="figure" target="#fig_22">4</ref>.3 presents the same data as Fig. <ref type="figure" target="#fig_22">4</ref>.2, in log-log scale. The best fit for the curve is a log-normal distribution, with parameters mean of log μ = 6.8, and standard deviation of log σ = 2.18 (more information about fitting a curve with a distribution model is presented in Sec. 4.3.2). It is worth noting that the fast drop in the tail is in part due to misspelled artists (e.g. incorrect metadata in the ID3 tags).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">An Example</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Definitions</head><p>The Long Tail of a catalog is measured using the frequency distribution (e.g. purchases, downloads, etc.), ranked by item popularity. We present now two definitions for the Long Tail. The first one is an informal, intuitive one. The second one is a quantitative definition that uses a formal model to characterise the shape of the curve, and a method to fit the data to some well-known distributions (e.g. powerlaw, power-law with exponential decay, log-normal, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Qualitative, Informal Definition</head><p>According to Chris Anderson <ref type="bibr">[1]</ref>, the Long Tail is divided in two separate parts: the head and the tail. The head part contains the items one can find in the old brickand-mortar markets. The tail of the curve is characterised by the remainder of the existing products. This includes the items that are available in on-line markets. Chris Anderson's definition, based on the economics of the markets, is:</p><p>The Long Tail is about the economics of abundance; what happens when the bottlenecks that stand between supply and demand in our culture start to disappear and everything becomes available to everyone.</p><p>The definition emphasises the existence of two distinguished markets; the familiar one (the Head), and the long ignored but emerging since the explosion of the web (the Tail), consisting of small niche markets.</p><p>Another definition is the one by Jason Foster:</p><p>The Long Tail is the realization that the sum of many small markets is worth as much, if not more, than a few large markets. <ref type="foot" target="#foot_45">6</ref>Both definitions are based on markets and economics, and do not propose any computational model to compute and characterise any tail curve, nor fit the data to any existing distribution. Indeed, <ref type="bibr">[1]</ref> does not define how to split the head and the tail parts, that are the two key elements in both definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.1">Physical Apples Versus Online Oranges</head><p>Since The Long Tail book became a top-seller, there is a lot of criticism against Anderson's theory. The most common criticism is the lack of scientific backup when comparing different data sources. That is, when comparing the online world to the physical world, Anderson simplifies too much. For instance, he considers only one brick-and-mortar store (e.g. Walmart), and compares their music catalog with the one found in the Rhapsody online store. However, in the real world there are much more music stores than Walmart. Indeed, there are specialised music stores that carry out ten times the volume of Walmart's music catalog. Sadly enough, these ones are completely ignored in Anderson's studies <ref type="bibr">[7]</ref>.</p><p>In addition, there is no clear evidence that online stores can monetise the Long Tail. According to Elberse et al. there is no evidence of a shift in online markets towards promoting the tail <ref type="bibr">[8]</ref>. The tail is long, but extremely flat. In their results, hit-driven economies are found in both physical and online markets. Furthermore, in an older study <ref type="bibr">[9]</ref>, Elberse found that the long tail of movies, those that sell only a few copies every week nearly doubled during their study period. However, the number of non-selling titles rose four times, thus increasing the size of the tail. Regarding the head of the curve; a few mainstream movies still accounted for most of the sales.</p><p>Another drawback of the theory is the creation of online oligarchies. "Make everything available" is commonly achieved by One-Big-Virtual-Tent rather than Many-Small-Tents. <ref type="foot" target="#foot_46">7</ref> That is to say, there is only one Amazon that provides most of the content.</p><p>Last but not least, Anderson's theory states that the Long Tail follows a powerlaw distribution. That is a straight line in a log-log plot. However, only plotting a curve in a log-log scale is not enough to verify that the curve follows a power-law. It can better fit to other distributions, such as log-normal or a power-law with an exponential decay of the tail. We need, then, a model that allows us to quantitative define the shape of the Long Tail curve, without the need of linking it with niche markets, economics, and profitable (or not) e-Commerce websites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Quantitative, Formal Definition</head><p>The Long Tail model, F(x), simulates any heavy-tailed distribution <ref type="bibr">[10]</ref>. It models the cumulative distribution of the Long Tail data. F(x) represents the share (%) of total volume covered by objects up to rank x:</p><formula xml:id="formula_21">F(x) = β ( N 50 x ) α + 1 (4.2)</formula><p>where α is the factor that defines the S-shape of the function, β is the total volume share (and also describes the amount of latent demand), and N 50 , the median, is the number of objects that cover half of the total volume, that is F(N 50 ) = 50.</p><p>Once the Long Tail is modelled using F(x), we can divide the curve in three parts: head, mid, and the tail. The boundary between the head and the mid part of the curve is defined by:</p><formula xml:id="formula_22">X head→mid = N 2/3 50 (4.3)</formula><p>Likewise, the boundary between the mid part and the tail is: Interestingly enough, the top-737 artists, 0.28% of all the artists, account for 50% of the total playcounts, F(737) = 50(N 50 = 737), and only the top-30 artists hold around 10% of the plays. Another measure is the Gini coefficient. This coefficient measures the inequality of a given distribution, and it determines the degree of imbalance <ref type="bibr">[11]</ref>. In our Long Tail example, 14% of the artists hold 86% of total playcounts, yielding a Gini coefficient of 0.72. This value describes a skewed distribution, higher than the classic 80/20 Pareto rule, with a Only top-737 artists, 0.28% of all the artists, accumulates the 50% of total playcounts (N 50 ). Also, the curve is divided in three parts: head, mid and tail (X head→mid = 82, and X mid→tail = 6, 655), so each artist is located in one section of the curve. value of 0.6. Figure <ref type="figure" target="#fig_22">4</ref>.4 also shows the three different sections of the Long Tail. The head of the curve, X head→mid consists of only 82 artists, whilst the mid part has 6,573 (X mid→tail = 6, 655). The rest of the artists are located in the tail.</p><formula xml:id="formula_23">X mid→tail = N 4/3 50 X 2 head→mid (4.4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.1">Fitting a Heavy-Tailed Distribution Using F(x)</head><p>To use the F(x) function we need to fit the curve with an estimation of α, β and N 50 parameters. We do a non-linear regression, using Gauss-Newton method for nonlinear least squares, to fit the observations of the cumulative distribution to F(x). <ref type="foot" target="#foot_47">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Qualitative Versus Quantitative Definition</head><p>On the one hand, the qualitative definition by Anderson emphasises the economics of the markets, and the shift from physical to virtual, online, goods. On the other hand, the quantitative definition is based on a computational model that allows us to fit a set of observations (of the cumulative distribution) to a given function, F(x).</p><p>The main difference between the two definitions (qualitative and quantitative) is the way each method split the curve into different sections (e.g. the head and the tail). The qualitative approach is based on the % covered by x (e.g. "20% of the products represent 80% of sales") whereas the quantitative definition splits the x (log) axis equally in three (head, mid, and tail) parts. The main problem is that when adding many more products (say 10,000) in the curve, the changes in the head and tail boundaries are very radical in the qualitative definition. The quantitative approach does not suffer from this problem. The changes in the section boundaries are not so extreme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Characterising a Long Tail Distribution</head><p>An early mention of the "long tail", in the context of the Internet, was Clay Shirky's essay in February, 2003. <ref type="foot" target="#foot_48">9</ref> After that, <ref type="bibr">[1]</ref> converted the term to a proper noun, and defined a new trend in economics. Since then, the spotlight on the "Long Tail" noun has created many different opinions about it.</p><p>In our context, we use a "Long Tail" curve to describe the popularity phenomenon in any recommender system, to show how popularity can affect the recommendations. So, given a long tail distribution of the items' popularity, an important step is to characterise the shape of the curve to understand the amount of skewness.</p><p>We characterise a Long Tail distribution using Kilkki's F(x) function. Its parameters α, β , and N 50 defines the shape of the curve. Yet, it is also important to determine the shape of the curve according to wellknown probability density distributions. There are different probability density distribution functions that can fit a heavy-tailed curve. We present some of them here: power-law, power-law with exponential decay, and log-normal distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Not All Long Tails Are Power-Law</head><p>A power-law distribution is described using the probability density distribution (pdf ), f (x):</p><formula xml:id="formula_24">f (x) = ax -γ (4.5)</formula><p>Power-law distribution has the property of (asymptotic) scale invariance. This type of distribution cannot be entirely characterised by its mean and variance. Also, if the γ power-law exponent has a value close to 1, γ 1, then this means that the long tail is fat. <ref type="foot" target="#foot_49">10</ref> In other words, a power-law with γ 1 consists of a thin tail (with values close to 0), and a short head with a high probability value.</p><p>Power-law with an exponential decay distribution differs from a power-law by the shape of the tail. Its pdf is defined by:</p><formula xml:id="formula_25">f (x) = x -γ e -λ x , (<label>4.6)</label></formula><p>There exists an N that denotes the threshold between the power-law distribution (x -γ , x ≤ N), and the exponential decay (e -λ x , x &gt; N). This means that the tail of the curve is better represented with an exponential cut-off.</p><p>In a log-normal distribution the logarithm of the variable is normally distributed. That is to say, if a variable X is normally distributed, then Y = e X has a log-normal distribution. Log-normal distribution promotes the head of the curve. It is a distribution skewed to the right, where the popular items have a strong effect, whilst the tail has a very small contribution in the pdf :</p><formula xml:id="formula_26">f (x) = 1 x e - (ln(x)-μ) 2 2σ 2 (4.7)</formula><p>Thus, the main problem is, given a curve in a log-log scale representation, to decide which is the best model that explains the curve. It is worth noting that, according to Anderson's theory (i.e. the Long Tail is profitable), the curve should be modelled as a power-law, with γ 1, meaning that the tail is fat. However, if the best fit is using another distribution, such as a log-normal-which is very common-then Anderson's theory cannot be strictly applied in that particular domain, and context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">A Model Selection: Power-Law or Not Power-Law?</head><p>To characterise a heavy-tailed distribution, we follow the steps described in Clauset et al. <ref type="bibr">[12]</ref>. As previously mentioned, the main drawbacks when fitting a Long Tail distribution are: (i) to plot the distribution on a log-log plot, and see whether it follows a straight line or not, and (ii) use linear regression by least squares to fit a line in the log-log plot, and then use R 2 to measure the fraction of variance accounted for the curve. This approach gives a poor estimate of the model parameters, as it is meant to be applied to regression curves, not to compare distributions. Instead, to decide whether a heavy-tailed curve follows a power-law distribution, <ref type="bibr">[12]</ref> propose the following steps:</p><p>1. Estimate γ. Use the maximum likelihood estimator (MLE) for the γ scaling exponent. MLE always converge to the correct value of the scaling exponent. 2. Detect x min . Use the goodness of fit value to estimate where the scaling region begins (x min ). The curve can follow a power-law on the right or upper tail, so above a given threshold x min . The authors propose a method that can empirically find the best scaling region, based on the Kolmogorov-Smirnov D statistic. 3. Goodness of the model. Use, again, the Kolmogorov-Smirnov D statistic to compute the discrepancy between the empirical distribution and the theoretical one. The Kolmogorov-Smirnov (K-S) D statistic will converge to zero, if the empirical distribution follows the theoretical one (e.g. power-law). The K-S D statistic for a given cumulative distribution function F(x), and its empirical distribution function F n (x) is:</p><formula xml:id="formula_27">D n = sup x |F n (x) -F(x)|, (<label>4.8)</label></formula><p>where sup |S| is the supremum of a set S. That is the lowest element of S that is greater than or equal to each element of S. The supremum is also referred to as the least upper bound. 4. Model selection. Once the data is fitted to a power-law distribution, the only remaining task is to check among the different alternatives. That is, to detect whether other non power-law distributions could have produced the data. This is done using pairwise comparison (e.g. power-law versus power-law with exponential decay, power-law versus a log-normal, etc.), and <ref type="bibr">[12]</ref> use the Vuong's test <ref type="bibr">[13]</ref>. Vuong's test uses the log-likelihood ratio and the Kullback-Leibler information criterion to make probabilistic statements about the two models. Vuong's statistical test is used for the model selection problem, where one can determine which distribution is closer to the real data. A large, positive Vuong's test statistic provides evidence of the best fitting using a power-law distribution over the other distribution, while a large, negative test statistic is an evidence of the contrary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">The Dynamics of the Long Tail</head><p>Another important aspect of any Long Tail is its dynamics. E.g., does an artist stay in the head region forever? Or the other way around; will niche artists always remain in the long tail? Figure <ref type="figure" target="#fig_22">4</ref>.6 depicts the increase of the Long Tail popularity after 6 months, using 50,000 out of the 260,525 last.fm artists (see Fig.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Strike a Chord?</head><p>Table <ref type="table" target="#tab_18">4</ref>.4 shows the playcount increment, in %. In all the three regions-head, mid, and tail-the percentage increment of plays is almost the same (around 62%), meaning that not many artists move between the regions. For instance, in the head area, Radiohead at top-2 is much closer to top-1, The Beatles, due to the release of the In Rainbows album. <ref type="foot" target="#foot_50">11</ref> Still, the band remains at top-2. An interesting example in the tail area is the Nulla Costa band. This band was at rank 259,962 in July, 2007. After 6 months they increase from 3 last.fm playcounts to 4,834, positioning at rank 55,000. Yet, the band is still in the tail region. We could not detect any single artist that clearly moved from the tail to the mid region. <ref type="foot" target="#foot_51">12</ref> There exist niche artists, and the main problem is to find them. The only way to leverage the long tail is by providing recommendations that promote unknown artists.</p><p>Once the Long Tail is formally described, the next step is to use this knowledge when providing recommendations. The following section presents how one can exploit the Long Tail to provide novel or familiar recommendations, taking into account the user profile. One can agree or disagree with all these Beatles' similar artist lists. However, there are a very few, if none at all, serendipitous recommendations (the rest of the similar artists were, in no particular order: The Who, The Rolling Stones, The Beach Boys, The Animals, and so on). Indeed, some of the before mentioned systems provide filters, such as: "surprise me!" or the "popularity slider", to dive into the Long Tail of the catalog. Thus, novel recommendations are sometimes necessary to improve the user's experience and discovery in the recommendation workflow.</p><p>It is not our goal to decide whether one can monetise the Long Tail or to exploit the niche markets, but to help people discover those items that are lost in the tail. Hits exist and they always will. Our goal is to motivate and guide the discovery process, presenting to users rare, non-hit, items they could find interesting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">Recommending the Unknown</head><p>It has been largely acknowledged that item popularity can decrease user satisfaction by providing obvious recommendations <ref type="bibr">[14,</ref><ref type="bibr">15]</ref>. Yet, there is no clear recipe for providing good and useful recommendations to users. We can foresee at least three key aspects that should be taken into account. These are: novelty and serendipity, familiarity, and relevance <ref type="bibr">[16]</ref>. According to Wordnet dictionary,<ref type="foot" target="#foot_53">14</ref> novel (adj.) has two senses: "new-original and of a kind not seen before"; and "refreshingpleasantly new or different". Serendipity (noun) is defined as "good luck in making unexpected and fortunate discoveries". Familiar (adj.) is defined as "well known or easily recognised". In our context, we measure the novelty for a given user u as the ratio of unknown items in the list of top-N recommended items, L N :</p><formula xml:id="formula_28">Novelty(u) = ∑ i∈L N (1 -Knows(u, i)) N , (<label>4.9)</label></formula><p>being Knows(u, i) a binary function that returns 1 if user u already knows item i, and 0 otherwise. Likewise, user's familiarity with the list of recommended items can be defined as Familiar(u) = 1 -Novelty(u).</p><p>Nonetheless, a user should be familiar with some of the recommended items, to improve confidence and trust in the system. Also, some items should be unknown to the user (discovering hidden items in the catalog). A system should also give an explanation of why those-unknown-items were recommended, providing a higher confidence and transparency on these recommendations. The difficult job for a recommender is, then, to find the proper level of familiarity, novelty and relevance for each user.</p><p>Figure <ref type="figure" target="#fig_22">4</ref>.7 shows the long tail of item popularity, and it includes a user profile. The profile is exhibited as the number of times the user has interacted with that item. Taking into account item popularity plus the user profile information, a recommender can provide personalised and relevant recommendations that are also novel to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1.1">Trade-Off Between Novelty and Relevance</head><p>However, there is a trade-off between novelty and user's relevance. The more novel, unknown items a recommender presents to a user, the less relevant they can be perceived by her.</p><p>Figure <ref type="figure" target="#fig_22">4</ref>.8 presents the trade-off between novelty and relevance. It shows the different recommendation states for a given a user u, given a large collection of items (say, not only the user's personal collection). The gray triangle represents the area where a recommender should focus on to provide relevant items to u. On the one hand, laid-back recommendations (bottom-right) appear when the system recommends familiar and relevant items to u. On the other hand, the discovery process (top-right) starts when the system provides to the user (potentially) unknown items that could fit in her profile. The provided recommendations should conform to the user's intentions; sometimes a user is expecting familiar recommendations (laidback state), while in other cases she is seeking to actively discovery new items.</p><p>There are two more cases, that is when the recommender provides popular items, and when it provides random ones. This can happen when there is not enough information about the user (e.g. the user cold-start problem). In this case, the system can recommend popular items (bottom-left). Popular items are expected to be somehow familiar to the user, but not necessarily relevant to her. The other situation is when the system provides random recommendations to u (top-left). This case is similar to a shuffle playlist generator, with the difference that in our case the items' catalog is much bigger than the personal music collection of u. Thus, there is less chances that user u might like any of the random recommendations, as they are not personalised at all. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Related Work</head><p>Serendipity and novelty are relevant aspects in the recommendation workflow <ref type="bibr">[15]</ref>. Indeed, there is some related work that explicitly addresses these aspects. For instance, five measures to capture redundancy are presented in <ref type="bibr">[17]</ref>. These measures allow one to infer whether an item-that is considered relevant-contains any novel information to the user. Yang and Li <ref type="bibr">[18]</ref> defines novelty in terms of the user knowledge and her degree of interest in a given item. In <ref type="bibr">[19]</ref>, Weng et al. propose a way to improve the quality and novelty of the recommendations by means of a topic taxonomy-based recommender, and hot topic detection using association rules. Other proposals include disregarding items if they are too similar to other items that the user has already seen <ref type="bibr">[20]</ref>, or simple metrics to measure novelty and serendipity based on the average popularity of the recommended items <ref type="bibr">[21]</ref>.</p><p>Even though all these approaches focus on providing novel and serendipitous recommendations, there is no framework that consistently evaluates the provided recommendations. Thus, there is a need to design evaluation metrics to deal with the effectiveness of novel recommendations, not only measuring prediction accuracy, but taking into account other aspects such as usefulness and quality <ref type="bibr">[14,</ref><ref type="bibr">22]</ref>. Novelty metrics should look at how well a recommender system made a user aware of previously unknown items, as well as to what extent users accept the new recommendations <ref type="bibr">[14]</ref>.</p><p>Generally speaking, the most popular items in the collection are the ones with higher probability that a given user will recognise, or be broadly familiar with. Likewise, one can assume that items with less interaction-rating, purchasing, previewing-within the community of users are more likely to be unknown <ref type="bibr">[21]</ref>. In this sense, the Long Tail of the items' catalog assists us in deciding how novel or familiar an item could be. Yet, a recommender system must predict whether an item could be relevant, and then be recommended, to a user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Summary</head><p>Effective recommendation systems should promote novel and relevant material (non-obvious recommendations), taken primarily from the tail of a popularity distribution. In this sense, the Long Tail can be described in terms of niche markets' economics, but also by describing the item popularity curve. We use the latter definition-the Long Tail model, F(x)-to describe the cumulative distribution of the curve. In the music field, the F(x) model allows us to define artist popularity, and her location in the curve (head, mid or tail region). Hence, F(x) denotes the shared knowledge about an artist, by a community of listeners. From this common knowledge, we can derive whether an artist can be novel and relevant to a given user profile.</p><p>Our results show that music listening habits follow the hit-driven (or mainstream) paradigm; 0.28% (737 out of 260,525) of the artists account for the 50% of total playcounts. The best fit (in the log-log plot) for the music Long Tail is a log-normal distribution. A log-normal distribution concentrates most of the information in the the head region. Even though we use playcounts and not total sales to populate the curve, this finding unveils Anderson's theory about the economics and monetisation in the Long Tail. Despite Anderson's failure or success theory, his core idea still is an interesting way to explain the changes the web has provoked, in terms of the availability of all kind of products-from hits to niches.</p><p>One of the goals of a recommender should be to promote the tail of the curve by providing relevant, personalised novel recommendations to its users. That is, to smoothly interconnect the head and mid regions with the tail, so the recommendations can drive interest from one to the other. Figure <ref type="figure" target="#fig_22">4</ref>.9 presents this idea. It depicts a 3D representation of the Long Tail; showing the item popularity curve, the similarities among the items, and a user profile denoted by her preferred items (in dark gray colour). The set of candidate items (dotted lines) to be recommended to the user are shown also. Items' height denotes the relevance for that user. Candidate items located in the tail part are considered more novel-and, potentially relevant-than the ones in the head region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.1">Links with the Following Chapters</head><p>In this chapter we have presented the basics for novelty detection in a recommender system, using the popularity information and its Long Tail shape. The next step is to evaluate these types of recommendations. We can foresee two different ways to evaluate novel recommendations, and these are related with (i) exploring the available (and usually, very large) item catalog, and (ii) filtering new incoming items. We mainly focus on the former case, and we present two complementary evaluation methods. On the one hand, network-centric evaluation method (presented in Chap. 6) focuses on analysing the items' similarity graph, created using any itembased recommendation algorithm. The aim is to detect whether the intrinsic topology of the items' network has any pathology that hinders novel recommendations, promoting the most popular items. On the other hand, a user-centric evaluation aims at measuring the perceived quality of novel recommendations. This user evaluation is presented in Chap. 7. Yet, before presenting the evaluation results we introduce, in Chap. 5, the metrics that we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 5 Evaluation Metrics</head><p>This chapter presents the different evaluation methods for a recommender system. We introduce the existing metrics, as well as the pros and cons of each method. This chapter is the background for the following Chap. 6 and 7, where the proposed metrics are used in real, large size, recommendation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Strategies</head><p>We classify the evaluation of recommender algorithms in three groups; system-, network-, and user-centric.</p><p>• System-centric evaluation measures how accurate the system can predict the actual values that user have previously assigned. This approach has been extensively used in collaborative filtering with explicit feedback (e.g. ratings). • Network-centric evaluation aims at measuring the topology of the item (or user) similarity network. It uses metrics from complex network analysis (CNA). Network-centric evaluation measures the inherent structure of the item (or user) similarity network. The similarity network is the basis to provide the recommendations. Thus, it is important to analyse and understand the underlying topology of the similarity network. • User-centric evaluation focuses on the user's perceived quality and usefulness of the recommendations. This evaluation requires the user intervention -via survey, or gaterhing information from the user activity in the system.</p><p>The following sections are devoted to explain each evaluation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 5.1</head><p>System-centric evaluation is based on the analysis of the subcollection of items of a user, using the leave-n-out method <ref type="bibr">[1]</ref>, and aggregating (e.g. averaging) the results for all users to provide a final compact metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">System-Centric Evaluation</head><p>As of today, system-centric evaluation has been largely applied. The most common approaches are based on the leave-n-out method <ref type="bibr">[1]</ref>, that resembles to the classic n-fold cross validation. Given a dataset where a user has implicitly or explicitly interacted with (via ratings, purchases, downloads, previews, etc.), split the dataset in two-usually disjunct-sets: training and test. Accuracy evaluation is based only on a user's dataset, so the rest of the items of the catalog are ignored. Figure <ref type="figure">5</ref>.1 presents the method. The evaluation process includes, then, several metrics such as: predictive accuracy (Mean Absolute Error, Root Mean Square Error), decision based (Mean Average Precision, Recall, F-measure, and ROC), and rank based metrics (Spearman's ρ, Kendall-τ, and half-life utility) <ref type="bibr">[2,</ref><ref type="bibr">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Predictive-Based Metrics</head><p>Predictive metrics aim at comparing the predicted values against the actual values. The result is the average over the deviations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.1">Mean Absolute Error (MAE)</head><p>Given a test set T of user-item pairs (u, i) with ratings r u,i , the system generates predicted ratings ru,i . Mean Absolute Error (MAE) measures the deviation between the predicted value and the real value:</p><formula xml:id="formula_29">MAE = 1 |T | ∑ (u,i)∈T |r u,i -r u,i | , (5.1)</formula><p>where ru,i is the predicted value of user u for item i, and r u,i the true value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.2">Root Mean Squared Error (RMSE)</head><p>Mean Squared Error (MSE) is also used to compare the predicted value with the real value a user has assigned to an item. The difference between MAE and MSE is that MSE heavily penalise large errors.</p><formula xml:id="formula_30">MSE = 1 |T | ∑ (u,i)∈T (r u,i -r u,i ) 2 (5.2)</formula><p>Root Mean Squared Error (RMSE) equals to the square root of the MSE value.</p><formula xml:id="formula_31">RMSE = √ MSE (5.3)</formula><p>RMSE is one of the most used metrics in collaborative filtering based on explicit ratings. RMSE is the metric that was used in the Netflix $1,000,000 prize.</p><p>Related metrics are Average RMSE and Average MAE. In this case, we compute the RMSE (or MAE) for each item and then take the average over all items. Likewise, we can compute the RMSE (or MAE) separately for each user and then take the average over all users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Decision-Based Metrics</head><p>Decision-based metrics evaluates the top-N recommendations for a user. Recommendations comes in a ranked list of items, ordered by decreasing relevance. There are four different cases to take into account:</p><p>• True positive (TP). The system recommends an item the user is interested in.</p><p>• False positive (FP). The system recommends an item the user is not interested in.</p><p>• True negative (TN). The system does not recommend an item the user is not interested in. • False negative (FN). The system does not recommend an item the user is interested in.</p><p>Precision (P) and recall (R) are obtained from the 2 × 2 contingency table (or confusion matrix) shown in Table <ref type="table">5</ref>.1. The recommended items are separated into two classes; relevant or not relevant according to the user profile. When the rating scale is not binary, we need to transform it into a binary scale, to decide whether the item is relevant or not. E.g. in a rating scale of [1..5], ratings of 4 or 5 are considered relevant, and ratings from 1..3 as not-relevant. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.1">Precision</head><p>Precision measures the fraction of relevant items over the recommended ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Precision = T P T P + FP</head><p>(5.4)</p><p>Precision can also be evaluated at a given cut-off rank, considering only the top-n recommendations. This measure is called precision-at-n or P@n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.2">Recall</head><p>The recall measures the coverage of the recommended items, and is defined as:</p><formula xml:id="formula_32">Recall = T P T P + FN (5.5)</formula><p>Recall is also known as sensitivity, true positive rate (TPR), or hit-rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.3">F-Measure</head><p>F-measure combines P and R results, using the weighted harmonic mean. The general formula (for a non-negative real β ) is:</p><formula xml:id="formula_33">F β = (1 + β 2 ) • (precision • recall) (β 2 • precision + recall) (5.6)</formula><p>Two common F-measures are F 1 and F 2 . In F 1 recall and precision are evenly weighted, and F 2 weights recall twice as much as precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.4">Accuracy</head><p>Accuracy is the simplest way to evaluate the predicted recommendations. Accuracy measures the ratio of correct predictions versus the total number of items evaluated. Accuracy is also obtained from the 2 × 2 contingency table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy = T P + T N T P + FP + T N + FN</head><p>(5.7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.5">Receiver Operating Characteristic (ROC) Curve</head><p>The previous decision-based metrics (P, R, F-measure) use a fixed recommendation list length. Receiver Operating Characteristic (ROC) curve measures the selection of high-quality items over a range of different recommendation list lengths, for a given user. ROC measures the trade-off between hit-rates (TPR) and false-alarm rates (or false positive rates, FPR). Hit-rate, or True Positive Rate, is defined as:</p><formula xml:id="formula_34">T PR = Recall = T P T P + FN (5.8)</formula><p>False positive rate (FPR) equals to:</p><formula xml:id="formula_35">FPR = FP FP + T N (5.9)</formula><p>ROC can visualise the trade-off between TPR and FPR. The random curve assigns a probability of 50% to each of the two classes (recommended, not recommended). The area under the curve (AUC) is a measure that summarises a ROC result. A random curve has an AUC of 0.5. The closer the AUC to 1, the better.</p><p>The main drawback of all the previous decision-based metrics is that do not take into account the ranking of the recommended items. Thus, item at top-1 has the same relevance as item at top-20. To avoid this limitation, one can use rank-based metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Rank-Based Metrics</head><p>There are two approaches to evaluate ranked lists of recommendations. The first one it to determine the order of the predicted items for a given user, and compare this with the correct order, or reference ranking. The second approach is to measure the utility of the predicted list. In this case, items in the top positions are considered more rellevant than the ones in the bottom of the list (e.g. the bottom of a webpage). Whenever the list of recommendations is very large, a pagination is also provided, so the user can browse the whole list of recommended items.</p><p>When using a reference ranking to compare against, the following measures can be applied: Spearman's rho (ρ), Kendall-tau (τ), and Normalised distance-based performance (NDPM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.1">Spearman's Rho (ρ)</head><p>Spearman's ρ computes the rank-based Pearson correlation of two ranked lists. It compares the predicted list with the user preferences (e.g. the ground truth data). Spearman's ρ is defined as:</p><formula xml:id="formula_36">ρ = 1 n u ∑ i (r u,i -r)(r u,i -r) σ (r)σ (r) (5.10)</formula><p>where • and σ (• ) denote the mean and standard deviation, and n u the number of items for user u.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.2">Kendall-Tau (τ)</head><p>Kendall-τ also compares the recommended list with the user's preferred list of items. Kendall-τ rank correlation coefficient is defined as:</p><formula xml:id="formula_37">τ = C + -C - 1 2 n(n -1) (5.11)</formula><p>where C + is the number of concordant pairs, and C -is the number of discordant pairs in the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.3">Normalised Distance-Based Performance</head><p>Normalised Distance-based Performance metric (NDPM) was introduced in <ref type="bibr">[4]</ref> to evaluate their collaborative filtering recommender system, named FAB.</p><p>NDPM is a normalised distance ([0..1]), between the user's classification for a set of documents and the system's classification for the same documents <ref type="bibr">[5]</ref>. In recommender systems, NDPM measures the difference between a user's and the system's choices. NDPM is defined as:</p><formula xml:id="formula_38">NDPM = 2C -+C u 2C i (5.12)</formula><p>where C -is number of mismatched preference relations between the system and user rankings, C u is the number of compatible preference relations, and C i is the total number of preferred relationships in the user's ranking.</p><p>The previous metrics compares two ranked lists, but do not take into account its utility. Top items are considered more relevant than items in the bottom of the recommendation list. Utility-based ranking metrics take into account the item position in the predicted list of recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.4">Average Reciprocal Hit-Rate</head><p>Average Reciprocal Hit-Rate (ARHR) is defined as:</p><formula xml:id="formula_39">ARHR = 1 n h ∑ i=1 1 p i (5.13)</formula><p>where h is the number of hits that occurred at positions p 1 , p 2 , ..., p h within the top-n list. Hits that occur earlier in the top-n list are weighted higher than hits that occur later in the list. ARHR rewards each hit based on where is located in the top-N list. It resembles to the Mean Reciprocal Rank metric from Information Retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.5">Half-Life Utility</head><p>Half-life utility (or R-Score) metric attempts to evaluate the utility of the predicted list of items <ref type="bibr">[1]</ref>. The utility is defined as the deviation between a user's rating and the default rating for an item. So, half-life utility can be used in algorithms that are based on user explicit feedback, such as ratings. Breese et al. describe the likelihood that a user will view each successive item in the ranked list with an exponential decay function. The strength of the decay is described by a half-life parameter α <ref type="bibr">[1]</ref>. Half-life utility is defined as:</p><formula xml:id="formula_40">R u = ∑ i ∑ j max(r i j -d, 0) 2 j-1 α-1 (5.14)</formula><p>where, r i j represents the rating of user u on item i j (in the j-position of the ranked list), d is the default rating, and α is the half-life parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.6">Discounted Cumulative Gain</head><p>Discounted cumulative gain penalises relevant predicted items that are located in the bottom of the recommendation list (e.g. these items should be on top).</p><formula xml:id="formula_41">DCG p = rel 1 + p ∑ i=2 rel i log 2 i (5.15)</formula><p>where rel i is the graded relevance of the recommended item at position i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Limitations</head><p>The main limitation of system-centric evaluation is the set of items that can evaluate. System-centric evaluation cannot avoid the selection bias of the dataset. Users do not rate all the items they receive, but rather they select the ones to rate. The observations a system-centric approach can evaluate is a skewed, narrowed and unrepresentative population of the whole collection of items. That is, for a given user, the systemcentric approach only evaluates the items the user has interacted with, neglecting the rest of the collection. The same procedure is applied for the rest of the users, and the final metrics are averaged over all the users. System-centric metrics present some drawbacks:</p><p>• The coverage of the recommended items cannot be measured. The collection of items used in the evaluation is limited to the set of items that a user has interacted with. • The novelty of the recommendations cannot be measured. System-centric evaluates the set of items a user has interacted with. Thus, it cannot evaluate the items that are outside this set. Some of these items could be unknown, yet relevant, to the user. • Neither transparency (explainability) nor trustworthiness (confidence) of the recommendations can be measured using system-centric metrics. • The perceived quality of the recommendations cannot be measured. Usefulness and effectiveness of the recommendations are two very important aspects for the users. However, system-based metrics cannot measure user satisfaction.</p><p>Other user-related elements aspects that a system-centric approach cannot evaluate are the eclecticness (preference for disparate and dissimilar items), and mainstreamness (preference for popular items) of a user.</p><p>To summarise, system-centric metrics evaluate how well a recommender system can predict items that are already in a user profile (assuming that the profile is splited during the train and test steps). The most difficult part is to develop evaluation metrics to deal with the effectiveness of the recommendations. That is, not only measuring prediction accuracy, but taking into account other aspects such as usefulness and quality <ref type="bibr">[6]</ref>. Indeed, accuracy is not correlated with the usefulness and subjective quality of the recommendations <ref type="bibr">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Network-Centric Evaluation</head><p>Network-centric evaluation measures the inherent structure of the item (or user) similarity network. The similarity network is the basis to provide the recommendations. Thus, it is important to analyse and understand the underlying topology of the similarity network.</p><p>Network-centric evaluation complements the metrics proposed in the systemcentric approach. It actually measures other components of the recommender system, such as the coverage, or diversity of the recommendations. However, it only focuses on the collection of items, so the user stays outside the evaluation process. Figure <ref type="figure">5</ref>.2 depicts this idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Complex Network Analysis</head><p>We propose several metrics to analyse a recommendation graph; G := (V, E), being V a set of nodes, and E a set of unordered pairs of nodes, named edges. The items (or users) are nodes, and the edges denote the (weighted) similarity among them, using any recommendation algorithm. When using the item similarity graph, we focus on the algorithms that use item-based neighbour similarity. On the other hand, the user similarity graph is the basis for the algorithms that use user-based neighbour similarity. It is worth mentioning that in either case, the similarity network can be created using any recommendation method (e.g. collaborative filtering, contentbased, hybrid, etc.). All the proposed metrics are derived from Complex Network and Social Network analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Navigation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2.1">Average Shortest Path</head><p>The average shortest path (or mean geodesic length) measures the distance between two vertices i and j. They are connected if one can go from i to j following the edges in the graph. The path from i to j may not be unique. The minimum path distance (or geodesic path) is the shortest path distance from i to j, d i j . The average shortest path in the network is:</p><formula xml:id="formula_42">d = 1 1 2 n(n + 1) ∑ i, j∈V,i = j d i j (5.16)</formula><p>In a random graph, the average path approximates to:</p><formula xml:id="formula_43">d r ∼ logN log k , (<label>5.17)</label></formula><p>where N = |V |, and k denotes the mean degree of all the nodes. The longest path in the network is called its diameter (D). In a recommender system, average shortest path and diameter inform us about the global navigation through the network of items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2.2">Giant Component</head><p>The strong giant component, SGC, of a network is the set of vertices that are connected via one or more geodesics, and are disconnected from all other vertices. Typically, networks have one large component that contains most of the vertices. It is measured as the % of nodes that includes the giant component. In a recommender system, SGC informs us about the catalog coverage, that is the total percentage of available items the recommender recommends to users <ref type="bibr">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Connectivity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3.1">Degree Distribution</head><p>The degree distribution, p k , is the number of vertices with degree k:</p><formula xml:id="formula_44">p k = ∑ v∈V | deg(v)=k 1, (5.18)</formula><p>where v is a vertex, and deg(v) its degree. More frequently, the cumulative degree distribution (the fraction of vertices having degree k or larger), is plotted:</p><formula xml:id="formula_45">P c (k) = ∞ ∑ k =k p k (5.19)</formula><p>A cumulative plot avoids fluctuations at the tail of the distribution and facilitates the computation of the power coefficient γ, if the network follows a power law. P c (k) is, then, usually plotted as the complementary cumulative distribution function (ccdf ). The complementary cumulative distribution function, F c (x), is defined as:</p><formula xml:id="formula_46">F c (x) = P[X &gt; x] = 1 -F(x) (5.20)</formula><p>where F(x) is the cumulative distribution function (cdf ):</p><formula xml:id="formula_47">F(x) = P[X ≤ x] (5.21)</formula><p>F(x) can be regarded as the proportion of the population whose value is less than x. Thus, P c (k), derived from F c (x), denotes the fraction of nodes with a degree greater than or equal to k.</p><p>In a directed graph, that is when a recommender algorithm only computes the top-n most similar items, P(k in ) and P(k out ), the cumulative incoming (outcoming) degree distribution, are more informative. Complementary cumulative indegree distribution, P c (k in ), detects whether a recommendation network has some nodes that act as hubs. That is, that they have a large amount of attached links. This clearly affects the recommendations and navigability of the network. Also, the shape of the curve helps us to identify the network's topology. Regular networks have a constant distribution, "random networks" have a Poisson degree distribution <ref type="bibr">[8]</ref> meaning that there are no hubs, and "scale-free networks" follow a power-law distribution in the cumulative degree distribution <ref type="bibr">[9]</ref>, so there are a few hubs that control the network. It is worth noting that many real-world networks, including the world wide web linking structure, are known to show a right-skewed distribution (often a power law P(k) ∝ k -γ with 2 &lt; γ &lt; 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3.2">Degree-Degree Correlation</head><p>Another metric used is the degree correlation. It is equal to the average nearestneighbour degree, k nn , as a function of k: <ref type="bibr">(5.22)</ref> where p(k |k) is the fraction of edges that are attached to a vertex of degree k whose other ends are attached to vertex of degree k . Thus, k nn (k) is the mean degree of the vertices we find by following a link emanating from a vertex of degree k.</p><formula xml:id="formula_48">k nn (k) = ∞ ∑ k =0 k p(k |k),</formula><p>A closely related concept is the degree-degree correlation coefficient, also known as assortative mixing, which is the Pearson r correlation coefficient for degrees of vertices at either end of a link. A monotonically increasing (decreasing) k nn means that high-degree vertices are connected to other high-degree (low-degree) vertices, resulting in a positive (negative) value of r <ref type="bibr">[10]</ref>. In recommender systems, it measures to which extent nodes are connected preferentially to other nodes with similar characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3.3">Mixing Patterns</head><p>We can generalise the vertex assortative mixing to any network pattern. Assortative mixing has an impact on the structural properties of the network. Mixing by a discrete characteristic of the network (e.g. race, language, or age in social networks) tend to separate the network into different communities. In social networks, this is also known as homophily.</p><p>We use the formula defined in <ref type="bibr">[11]</ref> to compute mixing patterns for discrete attributes. Let E be an N × N matrix, where E i j contains the number of edges in the network that connect a vertex of type i to one of type j (E i j = E ji in undirected networks). The normalised mixing matrix is defined as:</p><formula xml:id="formula_49">e = E E (5.23)</formula><p>where x means the sum of all elements in the matrix x. Mixing characteristics is measured in the normalised matrix e. Matrix e satisfies the following sum rules: ∑ i j e i j = 1, (5.24)</p><p>∑ j e i j = a i , (5.25)</p><p>∑ i e i j = b j , <ref type="bibr">(5.26)</ref> where a i and b i are the fraction of each type of an end of an edge that is attached to nodes of type i. The assortative mixing coefficient r is defined as:</p><formula xml:id="formula_50">r = ∑ i e ii -∑ i a i b i 1 -∑ i a i b i =</formula><p>Tr(e)-e 2  1-e 2 <ref type="bibr">(5.27)</ref> This quantity equals to 0 in a randomly mixed network, and 1 in a perfectly mixed network. Dissassortative networks have a negative r value, whilst assortative networks have a positive one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Clustering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4.1">Local Clustering Coefficient</head><p>The local clustering coefficient, C i , of a node i represents the probability of its neighbours to be connected within each other.</p><formula xml:id="formula_51">C i = 2|E i | k i (k i -1)</formula><p>, <ref type="bibr">(5.28)</ref> where E i is the set of existing edges that are direct neighbours of i, and k i the degree of i. C i denotes, then, the portion of actual edges of i from the potential number of total edges. C is defined as the average over the local measure C i <ref type="bibr">[12]</ref>:</p><formula xml:id="formula_52">C = 1 n n ∑ i=1 C i (5.29)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4.2">Global Clustering Coefficient</head><p>The global clustering coefficient is a sign of how cliquish (tightly knit) a network is. It estimates the conditional probability that two neighbouring vertices of a given vertex are neighbours themselves. The global clustering coefficient, C, It is quan-tified by the abundance of triangles in a network, where a triangle is formed when three vertices are all linked to one another. C = 3 × number of triangles number of connected triples .</p><p>(5.30)</p><p>Here, a connected triple means a pair of vertices connected via another vertex. Since a triangle contains three triples, C is equal to the probability that two neighbours of a vertex are connected as well. For random graphs, the clustering coefficient is defined as C r ∼ k /N. Typically, real networks have a higher clustering coefficient than C r . Some real-world networks are known to show a behaviour of C(k) ∝ k -1 , usually attributed to the hierarchical nature of the network <ref type="bibr">[13]</ref>. This behaviour has been found in metabolic networks, as well as in the WWW, and movie actor networks <ref type="bibr">[14]</ref>. The reasons for modular organisation in these networks relate, respectively, to the function in metabolic interaction networks, the topology of Internet, and the social activities in social networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5">Centrality</head><p>Centrality, as its name suggests, is a concept that differentiates vertices according to how influential they are in a network. Given the inhomogeneity of link patterns around vertices in a complex network, we could certainly imagine that the position and roles of vertices will vary significantly from one vertex to another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5.1">Degree</head><p>Degree centrality is defined as the number of links incident upon a node. It is reasonable to assume that items with particularly many acquaintances can be looked as being important figures. However, degree is primarily local in scope (e.g. talking loudly does not mean that you are affecting others more effectively than somebody who speaks quietly but very eloquently).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5.2">Closeness</head><p>Closeness centrality is defined as the mean geodesic distance between a vertex v and all other vertices reachable from it. Those nodes that tend to have short geodesic distances to other vertices within the graph have higher closeness. Closeness can be regarded as a measure of how long it will take information to spread from a given vertex to other reachable vertices in the network <ref type="bibr">[15]</ref>.</p><formula xml:id="formula_53">C C (v) = ∑ t∈V \v d(v,t) N -1 (5.31)</formula><p>where N ≥ 2 is the size of the graph component reachable from node v.</p><p>A complementary way to define closeness centrality is the reciprocal of the sum of geodesic distances to all other vertices of v <ref type="bibr">[16]</ref>.</p><formula xml:id="formula_54">C C (v) = 1 ∑ t∈V \v d(v,t)</formula><p>(5.32)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5.3">Betweenness</head><p>Betweenness Freeman centrality measures whether a central vertex will act as a relay of information between vertices, a role endowed thanks to being on a geodesic between vertices (hence the name betweenness) <ref type="bibr">[17]</ref>.</p><p>The definition of Freeman (betweenness) centrality C B of a vertex v is defined as:</p><formula xml:id="formula_55">C B (v) = 1 2 ∑ i, j</formula><p>g iv j g i j , <ref type="bibr">(5.33)</ref> where g i j is the total number of geodesics between vertices i and j, and g iv j is the number of the ones that pass through the vertex v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.6">Limitations</head><p>The main limitation of the network-centric approach is that users remain outside the evaluation process. There is no user intervention, not even the information of a user profile is taken into account in the evaluation. The main drawbacks of networkcentric approach are:</p><p>• Accuracy of the recommendations cannot be measured. In the network-centric approach there is no way to evaluate how well the algorithm is predicting the items already in a user's profile. • Neither transparency (explainability) nor trustworthiness (confidence) of the recommendations can be measured. • The perceived quality (i.e. usefulness and effectiveness) of the recommendations cannot be measured. The only way to solve this limitation is by letting users to step in the evaluation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.7">Related Work in Music Information Retrieval</head><p>During the last few years, complex network analysis has been applied to music information retrieval, and music recommendation in particular. In <ref type="bibr">[18]</ref>, we compared different music recommendation algorithms based on the network topology. The results show that social based recommenders present a scale-free network topology, whereas human expert-based controlled networks does not. An empirical study of the evolution of a social network constructed under the influence of musical tastes, based on playlist co-occurrence, appears in Buldu et al. <ref type="bibr">[19]</ref>. The analysis of collaboration among contemporary musicians, in which two musicians are connected if they have performed in or produced an album together, appears in <ref type="bibr">[20]</ref>. Anglade et al. present a user clustering algorithm that exploits the topology of a user-based similarity network <ref type="bibr">[21]</ref>.</p><p>Aucouturier presents in <ref type="bibr">[22]</ref> a network of similar songs based on timbre similarity. Interestingly enough, the network is scale-free, thus a few songs appear in almost any list of similar tracks. This has some problems when generating automatic playlists. Jacobson and Sandler <ref type="bibr">[23]</ref> present an analysis of the Myspace social network, and conclude that artists tend to form on-line communities with artists of the same musical genre.</p><p>In <ref type="bibr">[24]</ref>, Lambiotte and Ausloos present a method for clustering genres, by analysing correlations between them. The analysis is based on the users' listening habits, gathered from last.fm. From the user, artist, plays triples the authors compute genre similarity based on the percolation idea in complex networks, and also visualise a music genre cartography, using a tree representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">User-Centric Evaluation</head><p>User-centric evaluation aims at measuring the user's perceived quality and usefulness of the recommendations. In this case, the evaluation requires the user intervention to provide feedback of the provided recommendations-via a survey, or gaterhing information from the user activity in the system.</p><p>User-centric evaluation copes with the limitations of both system-and networkcentric approaches. Figure <ref type="figure">5</ref>.3 depicts this method, we named user-centric evaluation with feedback. Two important limitations of system-and network-centric approaches are the impossibility to evaluate the novelty and the perceived quality of the recommendations. User-centric allows us to evaluate these two elements. The main difference with a system-centric approach is that user-centric expands the evaluation dataset to those items that the user has not yet seen (i.e. rated, purchased, previewed, etc.). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Gathering Feedback</head><p>In the user-centric approach, the recommender system presents relevant items (from outside the user's dataset), and asks user for feedback. Feedback gathering can be done in two ways: implicitly or explicitly. Measuring implicit feedback includes, for instance, the time spent in the item's webpage, purchasing or not the item, previewing it, etc. Explicit feedback is based on two related questions; (i) whether the user already knew the item (novelty), and (ii) whether she likes it or not (perceived quality). Obviously, it requires an extra effort from the users, but at the same time it provides unequivocal information about the intended dimensions (which in the case of implicit measures could be ambiguous or inaccurate).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.1">Perceived Quality</head><p>The easiest way to measure the perceived quality of the recommended items is by explicitly asking to the users. Users must examine the recommended items and validate, to some extent, whether they like the items or not <ref type="bibr">[2]</ref>. In this sense, a user needs the maximum information about the item (e.g. metadata information, a preview, etc.), and the reasons why the item was recommended, if possible. Then, the user has to rate the quality of each recommended item (e.g. in a rating scale of [1..5]), or the quality of the list as a whole. Last but not least, the user should be able to select those attributes of the item that makes her feel that the novel item is relevant to her taste.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.2">Novelty</head><p>To evaluate novel items we need, again, to ask to the users whether they recognise the predicted item or not. Users have to examine the list of recommended items and express, for each item, whether she previously knew the item or not.</p><p>Combining both aspects, perceived quality and novelty, allows the system to infer whether a user likes to receive and discover unknown items, or in contrast, she prefers to get more conservative and familiar recommendations. Adding the transparency (explainability) in the recommendations, the user can perceive the new items as of higher quality, as the system can give an explanation of why this unknown item was recommended to the user. All in all, the user's intentions with regard novelty detection depends on the context and the recommendation domain. Furthermore, it is expected that the intentions change over time. For instance, a user is sometimes open to discovering new artists and songs, while sometimes she just wants to listen to her favourites. Detecting these modes and acting accordingly would increase user's satisfaction with the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.3">A/B Testing</head><p>Another approach to gather feedback from the users is via an A/B test. In A/B testing, the system unleash two different versions of an algorithm (or two completely different algorithms), to evaluate which one performs the best. The performance is measured by the impact the new algorithm (say A) has on the visitors' behaviour, compared with the baseline algorithm (B). A/B testing became very popular on the Web, because it is easy to create different webpage versions, and show them to visitors. One of the first successful examples that used A/B test was Amazon.com. When they saw the results, they decided to show recommendations (similar products) in the product page. <ref type="foot" target="#foot_56">1</ref>In A/B testing, the evaluation is performed by only changing a few aspects between the two versions. Once a baseline is established, the system starts optimising the algorithm by making one change at a time, and evaluating the results and impact with real visitors of the page. A/B testing uses between subjects evaluation. That is, the system splits the users in two groups. Each group only evaluates one approach (or algorithm), but not the other. Contrastingly, in a within subjects evaluation each user evaluates all the possible approaches (or algorithms) instead of only one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Limitations</head><p>The main limitation of the user-centric approach is the need of user intervention in the evaluation process. Gathering feedback from the user can be tedious for some users (filling surveys, rating items, providing feedback, etc.). In this sense, the system should ease and minimise the user intervention, using (whenever is possible) an unintrusive way. On the other hand, the main limitations from the two previous approaches (perceived quality and novelty detection) are solved in this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Summary</head><p>We classify the evaluation of recommender algorithms in: system-, network-, and user-centric approaches. System-centric evaluation measures how accurately the recommender system can predict the actual values that users have previously assigned. Network-centric evaluation aims at measuring the topology of the item (or user) network similarity, and it uses metrics from complex network analysis. Finally, user-centric evaluation focuses on the user's perceived quality and usefulness of the recommendations. Combining the three methods we can cover all the facets of a recommender algorithm; the system-centric approach evaluates the performance accuracy of the algorithm, the network-centric approach analyses the structure of the similarity network, and with the inclusion of the user intervention we can measure the satisfaction about the recommendations they receive. Figure <ref type="figure">5</ref>.4 depicts this idea. We can see that, when using the three evaluation approaches, all the components are evaluated-algorithm accuracy, similarity network analysis, and feedback from users. Last but not least, Table <ref type="table">5</ref>.2 summarises the limitations of each approach. The table presents some of the factors that affect the recommendations, and whether the approach can evaluate it or not. Applying the three evaluation approaches, we can assess all the facets of a recommender system, and also cope with the limitations of each evaluation approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy Coverage Novelty Diversity Transp. Quality</head><formula xml:id="formula_56">System-centric ✓ ✗ ✗ ✓ ✗ ✗ Network-centric ✗ ✓ ✓ ✓ ✗ ✗ User-centric ✗ ✗ ✓ ✓ ✓ ✓ Table 5</formula><p>.2 A summary of the evaluation methods. It shows the factors that affect the recommendations, and whether the approach can evaluate it or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Links with the Following Chapters</head><p>In this chapter we have presented the three methods to evaluate recommender algorithms. In the following two chapters we apply the metrics in real recommendation datasets. The evaluation based on network-centric is presented in Chap. 6. Then, user-centric evaluation is presented in Chap. 7. In the remaining of the book, we do not present any results using system-centric metrics. Long Tail and its indegree. This measure allows us to detect whether the hubs in the network are also the most popular items. Section 6.2 presents the experiments about the popularity effect in three different music artists recommendation algorithms: collaborative filtering (CF) from last.fm, content-based audio filtering (CB), and expert-based recommendations (EX) from Allmusic.com (AMG) musicologists. Then, Sec. 6.3 compares two user similarity networks created using collaborative filtering (CF) again from last.fm, and a user similarity network derived from the users' listening habits. In this case, we use content-based audio similarity (CB) to create the links among users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Artist Network Analysis</head><p>We aim to evaluate three artist similarity networks: collaborative filtering (CF), content-based audio similarity (CB), and human expert-based resemblance. Also, we analyse the popularity effect for each recommendation network. We measure the popularity effect by contrasting the properties from the network with the Long Tail information of the catalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.1">Social-Based, Collaborative Filtering Network</head><p>Artist similarity is gathered from last.fm, using Audioscrobbler web services, <ref type="foot" target="#foot_58">1</ref> and selecting the top-20 similar artists. Last.fm has a strong social component, and their recommendations are based on a combination of an item-based collaborative filtering, plus the information derived from social tagging. We denote this network as CF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.2">Human Expert-Based Network</head><p>We have gathered human-based expert recommendations from All Music Guide (AMG). <ref type="foot" target="#foot_59">2</ref> AMG makes use of professional editors to interconnect artists, according to several aspects, such as: influenced by, followers of, similar artists, performed songs by, etc. In order to create an homogeneous network, we only use the similar artists links. We denote this network as EX.</p><p>Table <ref type="table" target="#tab_32">6</ref>.1 shows the number of nodes and edges, for each network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of artists Number of relations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.3">Content-Based Network</head><p>To compute artist similarity in the CB network, we apply content-based audio analysis in an in-house music collection (T ) of 1.3 Million tracks of 30 s samples. Distance between tracks, d(x, y), is based on the Euclidean distance over a reduced space using Principal Component Analysis (PCA). The audio features used include not only timbral features (e.g. Mel frequency cepstral coefficients), but musical descriptors related to rhythm (e.g. beats per minute, perceptual speed, binary/ternary metric), and tonality (e.g chroma features, key and mode), among others <ref type="bibr">[1]</ref>. Preliminary steps to compute the Euclidean distance are: (i) audio descriptor normalisation in the [0, 1] interval, and (ii) applying PCA to reduce the audio descriptors space to 25 dimensions. Then, to compute artist similarity we used the most representative tracks, T a , of an artist a, with a maximum of 100 tracks per artist. For each track, t i ∈ T a , we obtain the most similar tracks (excluding those from artist a):</p><formula xml:id="formula_57">sim(t i ) = argmin ∀t∈T (d(t i ,t)), (<label>6.1)</label></formula><p>and get the artists' names, A sim(t i ) , of the similar tracks. The list of (top-20) similar artists of a is composed by all A sim(t i ) , ranked by frequency and weighted by the audio similarity distance:</p><formula xml:id="formula_58">similar artists(a) = A sim(t i ) , ∀t i ∈ T a (6.2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Network Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.1">Small World Navigation</head><p>Table <ref type="table" target="#tab_32">6</ref>.2 shows the network properties of the three datasets. All the networks exhibit the small-world phenomena <ref type="bibr">[2]</ref>. Each network has a small directed shortest path d d comparable to that of their respective random network. Also all the clustering coefficients, C, are significantly higher than the equivalent random networks C r . This is an important property, because recommender systems can be structurally optimised to allow surfing to any part of a music collection with a few of mouse clicks, and so that they are easy to navigate using only local information <ref type="bibr">[3,</ref><ref type="bibr">4]</ref>.</p><p>The human-expert network has a giant component, SGC, smaller than CF and CB networks. More than 4% of the artists in the human-expert network are isolated, and cannot be reached from the rest. This has strong consequences concerning the coverage of the recommendations and network navigation. 0.92 0.14 0.17 C (C r ) 0.230 (0.0001) 0.027 (0.00007) 0.025 (0.0002) Table <ref type="table" target="#tab_32">6</ref>.2 Artist recommendation network properties for last.fm collaborative filtering (CF), content-based audio filtering (CB), and Allmusic.com (AMG) expert-based (EX) networks.N is the number of nodes, and k the mean degree, d d is the avg. shortest directed path, and d r the equivalent for a random network of size N, D is the diameter of the (undirected) network. SGC is the size (percentage of nodes) of the strong giant component for the undirected network, γ in is the power-law exponent of the cumulative indegree distribution, r is the indegree-indegree Pearson correlation coefficient (assortative mixing), C is the clustering coefficient for the undirected network, and C r for the equivalent random network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.2">Clustering Coefficient</head><p>The clustering coefficient for the CF network is significantly higher than that of the CB or EX networks (C CF = 0.230). This means, given an artist a, the neighbours of a are also connected with each other with a probability of 0.230. For instance, U2's list of similar artists includes INXS and Crowded House, and these two bands are also connected, forming a triangle with U2. This has an impact on the navigation of the network, as one might get stuck in a small cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.3">Indegree Distribution</head><p>The shape of the (complementary) cumulative indegree distribution informs us about the topology of the recommendation network (random, or scale-free). We follow the steps defined in Sec. 4.4 to decide whether or not the indegree distribution follows a power-law (and, thus, it is a scale-free network). Model selection for the indegree distribution of the three artist networks. For each network we give a p-value for the fit to the power-law model (first column). The first p-value equals to the Kolmogorov-Smirnov D statistic (see Eq. 4.8). We also present the likelihood ratios for the alternative distributions (power-law with an exponential cut-off, and log-normal), and the p-values for the significance of each of the likelihood ratio tests (LLR). Table <ref type="table" target="#tab_32">6</ref>.3 presents the model selection for the indegree distribution. For each network we give a p-value for the fit to the power-law model (first column). A higher p-value means that the distribution is likely to follow a power-law. In Table <ref type="table" target="#tab_32">6</ref>.3, we also present the likelihood ratios for the alternative distributions (power-law with an exponential cut-off, and log-normal), and the p-values for the significance of each of the likelihood ratio tests. In this case, a p-value close to zero means that the alternative distribution can also fit the distribution. In all the three networks, the distribution can be fitted using either a power-law with an exponential decay, or a log-normal. For the log-normal, non-nested alternative, we give the normalised log likelihood ratio R/ √ nσ , as <ref type="bibr">[5]</ref>. For the power law with an exponential cut-off, a nested distribution, we give the actual log likelihood ratio. The final column of the table lists our judgement of the statistical support for the power-law hypothesis for each artist network.</p><p>The best fit for the CF network (according to the log-likelihood <ref type="foot" target="#foot_61">3</ref> ) is obtained with a power-law with an exponential decay (starting at x cuto f f ≈ 102), x -2.31 e -7x . In the expert-based network, the best fit (with a log-likelihood of 581.67) is obtained with a log-normal distribution, 1</p><p>x e</p><formula xml:id="formula_59">- (ln(x)-μ) 2 2σ 2</formula><p>, with parameters mean of log μ = 7.36, and standard deviation of log, σ = 3.58. Finally, the CB network follows a moderate a power-law with an exponential decay, x -1.61 e -7.19x (x cuto f f ≈ 326). Yet, in this case the log-normal can be considered as good as the power-law distribution with cut-off. Figure <ref type="figure" target="#fig_43">6</ref>.2 shows the cumulative indegree distribution for each network. EX follows a log-normal distribution, whereas CF and CB follow a power law with an exponential decay (cut-off). CF has a power-law exponent, γ = 2.31, similar to those detected in many scale free networks, including the world wide web linking structure <ref type="bibr">[6]</ref>. These networks are known to show a right-skewed power law distribution, P(k) ∝ k -γ with 2 &lt; γ &lt; 3, relying on a small subset of hubs that control the network <ref type="bibr">[7]</ref>. CF clearly presents the assortative mixing phenomenon (r CF = 0.92). Neither CB nor expert-based present any correlation (r CB = 0.14, r Expert = 0.17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.4">Assortative Mixing</head><p>Another difference in the three networks is the assortative mixing, or indegreeindegree correlation. Figure <ref type="figure" target="#fig_43">6</ref>.3 shows the correlation for each network. The CF network presents a high assortative mixing (r = 0.92). That means that the most connected artists are prone to be similar to other top connected artists. Neither CB nor EX present indegree-indegree correlation, thus artists are connected independently of their inherent properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.5">Mixing by Genre</head><p>We are also interested in the assortative mixing of the network, according to the musical genre. E.g. do similar artists tend to belong to the same genre? To do this, we gather the artists' tags from last.fm, and filter those tags that do not refer to a genre. To match the tags with a predefined list of 13 seed genres, we follow the approach presented in <ref type="bibr">[8]</ref> Table <ref type="table" target="#tab_32">6</ref>.4 shows the result after applying our algorithm to match the genres from the list of weighted tags <ref type="bibr">[8]</ref>. We can see that the tag 80s is filtered, and classic rock and rock tags are merged into the Rock genre (the weight is the sum of the two tags' weights). Once we get the matched genres for all the artists, we can analyse whether similar artists tend to belong to the same (or a semantically close) genre. Mixing correlation by genre coefficient r is computed using Eq. (5.27), over the normalised correlation matrix e (see Eq. 5.23). We create the correlation matrix e for the three networks following three steps:</p><p>1. For each artist a i , get the list of weighted genres G a i , as well as the list of genres from the similar artists of a i , G sim(a i ) . 2. Create the correlation matrix E. For each genre g a i ∈ G a i , and g j ∈ G Sim(a i ) , increment E g a i ,g j combining the artist similarity value, similarity(a i , a j ), for artists a j ∈ Sim(a i ), with the sum of the two genres' weights. E g a i ,g j = E g a i ,g j + similarity(a i , a j ) • (g a i + g j ) 3. Create the normalised correlation matrix e from E, using Eq. (5.23), and normalising it with ∑ i j e i j = 100. Tables 6.5, 6.6, and 6.7 present the matrices e for the CF, EX and CB networks, (bold denotes the highest values) respectively. Then, Table <ref type="table" target="#tab_32">6</ref>.8 shows the assortative mixing coefficient r for each network, computed over e (using Eq. 5.23). The higher r coefficient is found in the human expert network, r EX = 0.411. According to human experts, then, artist genre is a relevant factor to determine artist similarity. As expected, the content-based network does not present mixing by genre (r CB = 0.089). Our results are aligned with the findings in <ref type="bibr">[9]</ref>. They use the Myspace.com network of artists' friends, and set only one genre label per artist. The mixing by genre coefficient value they obtain is r = 0.350. Therefore, Myspace artists prefer to maintain friendship links with other artists in the same genre.</p><p>In our three artist networks, metal, pop, punk and rock genres accumulate more than 50% of the fraction of links (see a i , last column of the tables). So, the three networks are biased towards these few genres, which have a big impact in the similarity network. This bias concords with the type of users in the last.fm community, and the In the audio CB network, country and rock genres dominate over the rest. Country subsumes blues, jazz and soul genres. For instance, folk artists share a high fraction of links with country artists (e CB f olk,country = 0.65, compared with e CB f olk, f olk = 0.23), yet e CB f olk,rock also presents a high correlation. This finding is aligned with our previous research presented in <ref type="bibr">[8]</ref>, where we conclude that folk and country genres are similar, using content-based audio similarity. Similarly, the same phenomenon happens for e CB blues,country , and e CB jazz,country , although in the latter case it is more arguably the similarity between the two genres.</p><p>Actually, in the CB network the bias towards rock and country genres is more prominent than in the two other networks. Artist similarity is derived from audio track similarity, thus preponderant genres have more chances to have links from other artists' genres. This is the reason why artists from infrequent genres correlate and "collapse" with the most prevalent ones (see Table <ref type="table" target="#tab_32">6</ref>.7).</p><p>Contrastingly, in the experts' network, country, jazz and soul artists present a high intra-correlation value (a high fraction of vertices linking artists of the same genre, e EX i,i ). For instance, e EX jazz, jazz = 11.71, and the sum of the row (last column), a EX jazz , is 15.17. So, given a jazz artist, 77% of his similar artists are also jazz musicians ( At this point, we conclude the analysis of the three similar artist networks. Now, the following section presents the main findings about the correlation between artist popularity and their prominence in the similarity network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Popularity Analysis</head><p>We have outlined in the previous section the main topological differences among the three networks. We add now the popularity factor (measured with the total playcounts per artist), by combining artists' rank in the Long Tail with the results from the network analysis. Two experiments are performed. The former reports the relationships among popular and unknown artists. The latter experiment aims at analysing the correlation between artists' indegree in the network and their popularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3.1">Artist Similarity</head><p>Figure <ref type="figure" target="#fig_43">6</ref>.4 depicts the correlation among an artist's total playcounts and the total playcounts of its similar artists. That is, given the total playcounts of an artist (x axis) it shows, in the vertical axis, the average playcounts of its similar artists. CF network has a clear correlation (r CF = 0.503); the higher the playcounts of a given artist, the higher the avg. playcounts of its similar artists. The AMG human expert network presents a moderate correlation (r EX = 0.259). Thus, in some cases artists are linked according to their popularity. CB network does not present correlation (r CB = 0.08). In this case, artists are linked independently of their popularity.  <ref type="table" target="#tab_32">6</ref>.9 Artist similarity and their location in the Long Tail. Given an artist, a i , it shows (in %) the Long Tail location of its similar artists (results are averaged over all artists). Each row represents, also, the Markov chain transition matrix for CF, CB, and expert-based methods.  This information is directly derived from Table <ref type="table" target="#tab_32">6</ref>.9.</p><formula xml:id="formula_60">a i →</formula><p>Table <ref type="table" target="#tab_32">6</ref>.9 presents artist similarity divided into the three sections of the Long Tail curve. Given an artist, a i , it shows (in %) the Long Tail location of its similar artists (results are averaged over all artists). In the CF network, given a very popular artist, the probability of reaching (in one click) a similar artist in the tail is zero. Actually, half of the similar artists are located in the head part-that contains only 82 artistsand the rest are in the mid area. Artists in the mid part are tightly related (71.75%), and only 1/5 of the similar artists are in the tail part. Finally, given an artist in the tail, its similar artists remain in the same area. Contrastingly, the CB and EX networks promote the mid and tail parts much more in all the cases (specially in the head part).</p><p>Similarly to the mixing by genre, where we compute the correlation among the genres in linked artists, we can do the same for artist popularity. In fact, Table <ref type="table" target="#tab_32">6</ref>.9 directly provides us this information. For instance, given an artist in the Head part Table <ref type="table" target="#tab_32">6</ref>.9 shows the fraction of edges that are attached to the artist whose other ends are attached to artists of type Head, Mid or Tail. The mixing by popularity correlation coefficients are: r CF = 0.397, r EX = -0.002, and r CB = -0.032. Again, the correlation values show that the CF network presents assortative mixing by popularity, whilst neither EX nor CB does.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3.2">From Head to Tail</head><p>To simulate a user surfing the recommendation network, we apply a Markovian stochastic process <ref type="bibr">[10]</ref>. Indeed, each row in Table <ref type="table" target="#tab_32">6</ref>.9 can be seen as a Markov chain transition matrix, M, where the head, mid and tail parts are the different states. For example, Fig. <ref type="figure" target="#fig_43">6</ref>.5 shows the Markov chain for the CF network. The values of matrix M denote the transition probabilities, p i, j , between two states i, and j (e.g. p CF head,mid = 0.5468). The Markovian transition matrix, M k , denotes the probability of going from any state to another state in k steps (clicks). The initial distribution vector, P (0) , sets the probabilities of being at a determined state at the beginning of the process. Then, P (k) = P (0) × M k , denotes the probability distribution after k clicks, starting in the state defined by P (0) .</p><p>Using P (k) and defining P (0) = (1 H , 0 M , 0 T ), we can get the probability of reaching any state, starting in the head part. Table <ref type="table" target="#tab_32">6</ref>.10 shows the number of clicks needed to reach the tail from the head, with a probability p head,tail ≥ 0.4. In CF, one needs k P (k) , with Table <ref type="table" target="#tab_32">6</ref>.10 Navigation along the Long Tail of artists in terms of a Markovian stochastic process. Second and third columns depict the number of clicks (k) to reach the tail from the head part, with a probability p head,tail ≥ 0.4. Fourth and fifth columns show the stationary distribution π, as well as the number of steps, n, to reach π (with an error ≤ 10 -6 ).</p><formula xml:id="formula_61">P (0) = (1 H , 0 M , 0 T ) π n CF 5 (0.</formula><p>five clicks to reach the tail, whereas in CB and expert-based only two clicks are needed.</p><p>Finally, the stationary distribution π is a fixed point (row) vector whose entries sum to 1, and that satisfies π = πM. The last two columns in Table <ref type="table" target="#tab_32">6</ref>.10 present the stationary distribution vector for each algorithm, and the number of steps to converge to π, with an error ≤ 10 -6 . CF transition matrix needs more than three times the number of steps of CB or EX to reach the steady state, due to the transition p CF head,tail = 0. Furthermore, even though the probability to stay in the tail in CF is higher than in CB or EX, this is due to the high probability to remain in the tail once it is reached (p CF tail,tail = 0.8260).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3.3">Artist Indegree</head><p>Up to now, we have analysed the popularity in terms of the relationships among the artists. Now, we analyse the correlation between the artists' indegree in the network and their popularity. As a starting point, we present in Table <ref type="table" target="#tab_32">6</ref>.11 the top-10 artists with the highest indegrees for each network. CF and expert-based contains two and eight mainstream artists, respectively. CF contains U2 and R.E.M., but the rest of the list contains more or less well known jazz musicians, including some in the top of the tail area. The whole list for the expert-based AMG network is made up of very popular artists. Our guess is that the editors connect long tail artists with the most popular ones, because these popular artists are considered influential and many bands are considered followers of these mainstream artists. The CB network has a more eclectic top-10 list, as one would expect. Oddly enough, there is no new or actual artists, but some classic bands and artists ranging several musical genres.Some bands are, in fact, quite representative of a genre (e.g. Lynyrd Skynyrd, and The Charlie Daniels Band for Southern-rock, The Carpenters for Pop in the 1970s, George Strait for Country, and Cat Stevens for Folk/Rock). Probably, their high indegree is due to being very influential in their respective musical styles. In some sense, there are other bands that "cite" or imitate their sound. Although, the results could be somewhat biased; our sampled CF and expert networks are subsets of the whole last.fm and AMG similar artist networks, thus our sampling could not be a good representation of the whole dataset. Furthermore, the differences in the maximum indegree value (k in for top-1 artist) among the three networks are due to the different sizes (N) and average degree k of the networks (5.47 EX versus 14.13 CF , and 19.80 CB ), but also due to the topology of the networks. CF and CB follow a power-law cumulative indegree distribution, whereas EX best fits a log-normal distribution. Therefore the maximum indegree k in for EX is much smaller than that of CF or CB.</p><p>To conclude this analysis, Fig. <ref type="figure" target="#fig_43">6</ref>.6 shows the correlation between artists' indegree (k in ), and artists' popularity, using artist's total playcounts. The figure shows whether the artists with higher indegree in the network (hubs) are the most popular artists. Again, we see that in CF and expert-based networks the artists with higher indegree (hubs) are mostly located in the head and mid part, whereas in CB they are more spread out through all the curve. Both CF and expert-based networks confirm the expectations, as there is a clear correlation between the artist indegree and total playcounts (r CF = 0.621, and r EX = 0.475). Artists with high indegree are the most popular ones. In CB, given a high indegree value it contains, on average, artists ranging different levels of popularity (r CB = 0.032).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.4">Discussion</head><p>The results show that the last.fm social-based recommender tends to reinforce popular artists, at the expense of discarding less-known music. Thus, the popularity effect derived from the community of users has consequences in the recommendation network. This reveals a somewhat poor discovery ratio when just browsing through the network of similar music artists. It is not easy to reach relevant long tail artists, starting from the head or mid parts (see Table <ref type="table" target="#tab_32">6</ref>.10). This could be related to the existence of positive feedback loops in social-based recommenders. The first users that enters to the system heavily affects the initial relationships among the items. After that, the users that come later, find an environment shaped by earlier users. These new users will be affected by the early raters that create the similarities among the items. Thus, positive feedback also affects the navigation through the Long Tail. Given a long tail artist, its similar artists are all located in the tail area as well. This does not always guarantee novel music recommendations; a user that knows an artist in the Long Tail quite well is likely to know most of the similar artists too (e.g. the solo project of the band's singer, collaborations with other musicians, and so on). Thus, these might not be considered good novel recommendations to that user, but familiar ones. CF contains, then, all the elements to conclude that popularity has a strong effect in the recommendations, because: (i) it presents assortative mixing (indegree-indegree correlation), see Fig. <ref type="figure" target="#fig_43">6</ref>.3, (ii) there is a strong correlation between an artist's total playcounts and the total playcounts of its similar artists (see Fig. <ref type="figure" target="#fig_43">6</ref>.4), (iii) most of the hubs in the network are popular artists (see Fig. <ref type="figure" target="#fig_43">6</ref>.6), and (iv) it is not easy to reach relevant Long Tail artists, starting from the head or mid parts (see Table <ref type="table" target="#tab_32">6</ref>.10).</p><p>Human expert-based recommendations are more expensive to create and have a smaller Long Tail coverage compared to automatically generated recommendations like those in CF and CB. Regarding popularity, the hubs in the expert network are comprised of mainstream music, thus potentially creating a network dominated by popular artists (see Table <ref type="table" target="#tab_32">6</ref>.11 and Fig. <ref type="figure" target="#fig_43">6</ref>.6). However, the topology-specially the log-normal cumulative indegree distribution-indicates that these artists do not act as hubs, as in the power law distributions with a γ exponent between 2 and 3 <ref type="bibr">[7]</ref>. Furthermore, the expert network does not present assortative mixing (see Fig. <ref type="figure" target="#fig_43">6</ref>.3), so artists are linked in a heterogeneous way; popular artists are connected with other less-known artists and the other way around (see Table <ref type="table" target="#tab_32">6</ref>.9 and Fig. <ref type="figure" target="#fig_43">6</ref>.4).</p><p>According to the stationary distribution π (see Table <ref type="table" target="#tab_32">6</ref>.10), the key Long Tail area in the CB and EX networks are the artists in the mid part. These artists allow users to navigate inside the Long Tail acting as entry points, as well as main destinations when leaving the Long Tail. Also, users that listen to mainly very Long Tail music are likely to discover unknown artists-for them-that are in the mid part, and that are easily reachable from the artists in the tail. One should pay attention to the quality data in the Long Tail as well. Assuming that there exists some extremely poor quality music, CB is not able to clearly discriminate against it. In some sense, the popularity effect drastically filters all these low quality items. Although, it has been proved by <ref type="bibr">[11]</ref> that increasing the strength of social influence increased both inequality and unpredictability of success and, as a consequence, popularity was only partly determined by quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">User Network Analysis</head><p>One of the main goals of neighbourhood-based recommendation algorithms is to find like-minded people, and through them, discover unknown music. In this sense, a user similarity network resembles a social network, automatically connecting people that share similar interests.</p><p>We present an evaluation of two user similarity networks. Both networks are derived from the users' listening habits. The first one is based on collaborative filtering (CF). Again, we gather this information from last.fm. For the second network we use content-based audio similarity (CB) to compute user similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1.1">Social-Based, Collaborative Filtering Network</head><p>User similarity is gathered from last.fm., using Audioscrobbler webservices. For each user we collect the top-20 similar users. Last.fm derives user similarity from the item-based approach, so it connects users that share common musical tastes. Table <ref type="table" target="#tab_32">6</ref>.12 shows the number of users and links in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1.2">Content-Based Network</head><p>User similarity for the CB network is computed using content-based audio analysis from a music collection (T ) of 1.3 Million tracks of 30 s samples. To compute similar users we used all the tracks, T u , that a user u has listened to.</p><p>Distance between tracks, d(x, y), is based on the Euclidean distance over a reduced space using Principal Component Analysis (PCA). The audio features used include not only timbral features (e.g. Mel frequency cepstral coefficients), but musical descriptors related to rhythm (e.g. beats per minute, perceptual speed, binary/ternary metric), and tonality (e.g chroma features, key and mode), among others <ref type="bibr">[1]</ref>. Preliminary steps to compute the Euclidean distance are: (i) audio descriptor normalisation in the [0, 1] interval, and (ii) applying PCA to reduce the audio descriptors space to 25 dimensions. For each track, t i ∈ T u , we obtain the most similar tracks:</p><formula xml:id="formula_62">sim(t i ) = argmin ∀t∈T (d(t i ,t)), (<label>6.3)</label></formula><p>Then, we get all the users, U sim(t i ) , that listened to any track similar to t i . The list of (top-20) similar users of u is composed by the users in U sim(t i ) for all t i ∈ T u , weighted by the audio similarity distance:</p><formula xml:id="formula_63">similar users(u) = U sim(t i ) , ∀t i ∈ T u (6.4)</formula><p>To select the maximum number of similar users per user we compute, for all the users, the average distance between the user and her top-20 similar users. We use this average distance as a threshold to get the top-N most similar users, setting a maximum of N = 20.</p><p>The main difference between the two approaches is that in CF two users have to share at least one artist in order to become-potentially-similar. In the CB we can have two similar users that do not have share any artist, yet the music they listen to is similar. For instance, two users that listen to, respectively, u i = [Ramones, The Clash, Buzzcocks, and Dead Kennedys], and u j = [Sex Pistols, The Damned, The Addicts, and Social Distortion] could be very similar using CB similarity, but not using CF (unless the system also makes use of higher-level information, such as artist similarity derived from social tagging data).</p><p>However, due to the similar users(u) equation we choose for the CB network, a user with a high number of songs in her profile has a higher chance of being considered similar to other users. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Network Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2.1">Small World Navigation</head><p>Table <ref type="table" target="#tab_32">6</ref>.13 presents the properties of the two networks. The two networks moderately present the small-world phenomena <ref type="bibr">[2]</ref>. They have a small average directed shortest path, d d , but higher than the d r in the equivalent random network (twice as much). Also the two clustering coefficients, C, are significantly higher than the equivalent random networks C r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2.2">Clustering Coefficient</head><note type="other">Figure 6</note><p>.7 shows the clustering coefficient as a function of node degree C(k), for the undirected network. We can see that the higher the indegree of a user, the lower her clustering coefficient. In this sense, the CB network resembles a hierarchical network <ref type="bibr">[12]</ref>, although it is not a scale free network. In a hierarchical network there are many small densely linked clusters that are combined to form larger but less cohesive groups, that a few prominent nodes interconnect. In our CB network, C CB (k) ∼ k -0.87 , starting at k = 20 the α = 0.87 is close to the scaling law, C(k) ∼ k -1 . The scaling law is used to determine the presence of hierarchy in real networks <ref type="bibr">[12]</ref>. C(k) is computed for the undirected networks. That is the reason that the C CB (k) ∼ k -0.87 power law starts at k = 20. In the undirected network most of the nodes have k ≥ 20-the node outlinks, k out , plus the incoming links they receive k in . However, in some cases a node has k out &lt; 20, because the threshold has been applied (see the creation of datasets, in Sec. 6.3.1). These few nodes are located on the left side of Fig. <ref type="figure" target="#fig_43">6</ref>.7 (0 &lt; k &lt; 20), and are discarded to compute C(k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2.3">Indegree Distribution</head><p>Table <ref type="table" target="#tab_32">6</ref>.14 presents the model selection for the indegree distribution. For each network we give a p-value of the fit to the power-law model (first column). A higher p-value means that the distribution is likely to follow a power-law. We also present the likelihood ratios for the alternative distributions (power-law with an exponential cut-off, and log-normal), and the p-values for the significance of the likelihood ratio tests. In this case, a p-value close to zero means that the alternative distribution can also fit the distribution (see Sec. 4.4 for an in-depth explanation about fitting a probability density distribution, and the model selection procedure). For each network we give a p-value for the fit to the power-law model (first column). We also present the likelihood ratios for the alternative distributions (power-law with an exponential cut-off, and lognormal), and the p-values for the significance of each of the likelihood ratio tests (LLR). Figure <ref type="figure" target="#fig_43">6</ref>.8 shows the cumulative indegree distribution for each network. Neither of the two networks are scale free, because the cumulative indegree distribution does not follow a power law (see Table <ref type="table" target="#tab_32">6</ref>.14, first column). In both networks the best fitting distribution, according to their log-likelihood, is a log-normal distribution. The best fit for the CF network is obtained with a log-normal distribution,</p><formula xml:id="formula_64">f (x) = 1 x e - (ln(x)-μ) 2 2σ 2</formula><p>. The parameters are mean of log μ = 6.49, and standard deviation of log, σ = 2.80. The best fit for the CB network is obtained with a log-normal distribution. The parameters are mean of log μ = 8.51, and standard deviation of log, σ = 2.74.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2.4">Assortative Mixing</head><p>Figure <ref type="figure" target="#fig_43">6</ref>.9 depicts the assortative mixing-indegree indegree correlation-in the two user networks. CF presents assortative mixing, whilst CB does not (r CF = 0.86 and r CB = 0.17). The CF user similarity network resembles a social network, where it is very common the find homophily. Users with a high indegree, k in , are connected to other users also with a high k in , whereas users with a low indegree are connected to peers that also have a low indegree.</p><p>At this point, we conclude the analysis of the two user networks. The following section presents the analysis about the correlation between the user's location in the Long Tail of artist popularity and the user's prominence in the similarity network. Fig. <ref type="figure" target="#fig_43">6</ref>.9 Assortative mixing in the two user networks. CF presents assortative mixing, whilst CB does not (r CF = 0.86 and r CB = 0.17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Popularity Analysis</head><p>Similar to the analysis performed in the artist networks, we present two experiments about the popularity effect in the user networks. The first reports the relationships among the users and their location in the Long Tail. The user's location in the Long Tail is measured by averaging the Long Tail location of the artists in the user profile. The second experiment analyses the correlation between users' indegree in the network and their location in the Long Tail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3.1">User Similarity</head><p>To compute a user's location in the music Long Tail, we get the artists that user u listens to the most (A u ). Summing all the artists' playcounts in A u must hold at least 66% of the user's total playcounts, so it is a sound representation of the musical tastes of u. Then, the user's Long Tail location is computed as the weighted average of A u . That is, for each a ∈ A u we combine the user playcounts for artist a with the Long Tail location of a. Figure 6.10 shows an example of a user's location in the Long Tail.</p><p>Interestingly, most of the users are located in the Mid part of the curve. Thus, on average a user listens to mainstream music (from the head and mid areas), but also some unknown bands. Because the Mid area is very dense, we split this part into three subsections: Mid top , Mid middle , Mid end . Table <ref type="table" target="#tab_32">6</ref>.15 presents the user similarity in terms of Long Tail locations. The main difference between the two similarity networks is for the users in the Head part. In the CF network more than 55% of the   <ref type="table" target="#tab_32">6</ref>. <ref type="bibr">15</ref> Similarities among the users, and their location in the Long Tail. Given a user, u i , it shows (in %) the Long-Tail location of its similar artists, u j . The results are averaged over all users in each part of the curve.</p><p>We represent each row in Table <ref type="table" target="#tab_32">6</ref>.15 as a Markov transition matrix. Using a Markovian stochastic process we can simulate a user surfing the similarity network. In the artist network (see Sec. 6.2.2), we were interested in the navigation from head to tail artists. Now, in the user network, the users are already located in the Long Tail according to the artists' popularity in their profile. Thus, we are more interested in the Long Tail location of the similar users, rather than in the navigation from head to tail users. For instance, using P (3) and defining P (0) = (0 Head , 0 M-top , 1 M-mid , 0 M-end , 0 Tail ), we get the probability of a user located in the mid part of the curve (Mid middle ) to move to the left side (Head, and M top ), to stay in the same Mid middle area, or to move to the right (Mid end , and Tail). Table <ref type="table" target="#tab_32">6</ref>. <ref type="bibr">16</ref> shows the probability distributions. Second column shows the probability distribution of a user located in the Mid middle after 3 clicks, P (3) . The CF network has a tendency to stay in the same Mid middle area, whilst in the CB network the user slightly moves towards the right, tail, area. In both cases, the probability to move to the Head (left) is around 0.2. P (3) , with P (0) = (0, 0, 1, 0, 0) π n CF 0.210 Le f t , 0.407 Stay , 0.383 Right (0.012 Head , 0.199 M-top , 0.407 M-mid , 0.309 M-end , 0.074 Tail ) 5 CB 0.190 Le f t , 0.368 Stay , 0.442 Right (0.039 Head , 0.151 M-top , 0.368 M-mid , 0.351 M-end , 0.091 Tail ) 5 Table <ref type="table" target="#tab_32">6</ref>. <ref type="bibr">16</ref> Long Tail navigation in terms of a Markovian stochastic process. Second column shows the probability distribution of a user in the Mid middle after 3 clicks. Third and fourth columns show the stationary distribution π, as well as the number of steps, n, to reach π (with an error ≤ 10 -5 ). Table <ref type="table" target="#tab_32">6</ref>.16 also shows the stationary distribution π, that satisfies π = πM. The last two columns present the stationary distribution vector for each algorithm, and the number of steps to converge to π, with an error ≤ 10 -5 . Both networks need the same number of steps to reach the steady state, confirming that overall the probability distributions are not very dissimilar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3.2">User Indegree</head><p>We analyse the correlation between the users' indegree and their location in the Long Tail. Table <ref type="table" target="#tab_32">6</ref>.17 shows, for each network, the top-5 users with the highest indegrees. Users in the network with a high indegree can be considered as influential users or simply influentials. There is a big difference in the two networks; the influentials in CB are the users with the most playcounts, while the influentials in CF are the users that are closer to the Head part of the curve, independently of their total playcounts. In fact, only the top-4 users in the CF network have the same order of magnitude of total plays as the top-5 users in the CB network. Yet, around 60% of the CF top-4 user's playcounts correspond to The Beatles, the top-1 artist in the Long Tail of artist popularity. Therefore, the reason that CF top-4 user has a high indegree is not due to the high number of playcounts, but because most of the music she listens to is very mainstream.</p><p>Indeed, looking at the whole distribution of users-not only the top-5-in Fig. <ref type="figure" target="#fig_43">6</ref>.11, the CF presents no correlation between the user's Long Tail position and their network indegree (r CF = -0.012). However, CB network presents a correlation of r CB = 0.446. Thus, as previously stated, users with higher indegree are the ones with the higher total playcounts in the CB network.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.4">Discussion</head><p>The results of the analysis shows that the CB user similarity network resembles a hierarchical network (with the exception that CB is not a scale-free network). Thus, in the CB network there are a few nodes that are connecting smaller clusters. These nodes are the ones with the highest indegree which, according to Fig. <ref type="figure" target="#fig_43">6</ref>.11, are the ones with higher total playcounts. Therefore, the users that listen to more music are the authorities in the CB network, independently of the quality or popularity of the music they listen to. This affects the navigation of the user similarity network. Contrastingly, in the CF network the users with a higher indegree are the ones that listen to more mainstream music. These users could have an impact for a recommender algorithm that uses user-based, instead of item-based, recommendations.</p><p>The key Long Tail area in the two user similarity networks is the Mid part. This area concentrates most of the users. To improve music discovery through user sim-ilarity, the recommendation algorithm should also promote users in the tail area. When computing user similarity, a recommender should take into account the users' location in the Long Tail curve.</p><p>An important missing aspect in our analysis is the dynamics of the user networks. It would be interesting to detect who are the tastemakers (or trendsetters). Users that create trends and have an impact in the musical tastes of other users are very relevant. This is related with the taxonomy of users presented in Sec. 3.2.1. Ideally, the Savants should be correlated with the tastemakers and influentials in the network. Detecting and tracking these users is a key point to improve music discovery through the network of similar users. However, detecting tastemakers can only be achieved by constantly gathering information about the users' music consumption. This way, we could analyse the dynamics and evolution of the user similarity network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Summary</head><p>Recommender systems should assist us in the process of filtering and discovering relevant information hidden in the Long Tail. Popularity is the element that defines the characteristic shape of the Long Tail. We measure popularity in terms of total playcounts, and the Long Tail model is used in order to rank all music artists. We have analysed the topology and the popularity bias in two music recommendation scenarios; artist and user similarity. As expected by its inherent social component, the collaborative filtering approach is prone to popularity bias. This has some consequences on the discovery ratio, as well as navigation through the Long Tail.</p><p>Music recommender systems have to deal with biased datasets; a bias towards mainstream popular artists, towards a few prominent musical genres, or towards a particular type of user. Assortative mixing measures the correlation of these elements in the similarity network. In this sense, it is important to understand which contextual attributes have an impact when computing artist similarity (e.g. popularity, genre, decade, language, activity, etc.), or user similarity (e.g. age, race, language, etc.). The Last.fm social-based recommender presents several assortative mixing patterns. The artist network has assortative mixing on the nodes' indegree, but also presents mixing by genre, and mixing by popularity; i.e. the classical homophily issues that arise in social networks. Yet, as we will see in the next chapter, this does not necessarily have an impact on the quality of the recommendations.</p><p>The temporal effects in the Long Tail are another aspect one should take into account. Some new artists can be very popular, gathering a spike of attention when they release an album, but then they can slowly move towards the mid or tail area of the curve as time goes by. Thus, one-time hit items can be lost and forgotten in the Long Tail. Indeed, the music back-catalogue located in the Long Tail is an example of old and forgotten items that offer the possibility to be re-discovered by the users. A recommender system should be able to present and recommend these items to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">Links with the Following Chapters</head><p>We have presented a network-centric analysis of the similarities between artists, and between users. The network-based approach does not put the user into the evaluation loop. Without any user intervention it is impossible to evaluate the quality and user satisfaction of the recommendations, which does not necessarily correlate with predicted accuracy <ref type="bibr">[13]</ref>. So, we still need to evaluate the quality of the recommendations as well as the popularity effect when providing recommendations to the users. For this reason, we present the user-based evaluation in the next chapter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 7</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User-Centric Evaluation</head><p>Up to now, we have presented a user agnostic network-based analysis of the recommendations. In this chapter we present a user-centric evaluation of the recommender algorithms. This user-based approach focuses on evaluating the user's perceived quality and usefulness of the recommendations. The evaluation method considers not only the subset of items that the user has interacted with, but also the items outside the user's profile. The recommender algorithm predicts recommendations to a particular user-taking into account her profile-and then the user provides feedback about the recommended items. Figure <ref type="figure" target="#fig_56">7</ref>.1 depicts the approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Music Recommendation Survey</head><p>We aim at measuring the novelty and perceived quality of music recommendation, as neither system-nor network-centric approaches can measure these two aspects. However, we need to explicitly ask the users whether they already know the provided recommendations or not.</p><p>The proposed experiment is based on providing song recommendations to users, using three different music recommendation algorithms. Feedback gathered from the users consists of (i) whether a user already knows the song, and (ii) the relevance of the recommendations-whether she likes the recommended song or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">Procedure</head><p>We designed a web-based survey experiment to evaluate the novelty and relevance of music recommendations from the point of view of the users. The survey is divided in two sections. The first one asks the participants for basic demographic Fig. <ref type="figure" target="#fig_56">7</ref>.1 User-centric evaluation focuses on evaluating the user's relevance and usefulness of the recommendations. The evaluation method considers not only the subset of items that the user has interacted with, but also the items outside the user's profile. information (age range and gender), previous musical knowledge, and the average number of listening hours per day. The second part of the survey provides a set of rounds, each round containing an unsorted list of ten recommended songs evenly distributed from three different recommendation approaches. The participants do not know which recommendation method is used to recommend each song. A participant has to rate at least 10 songs, but she can rate as many songs as she likes.</p><p>The participant's feedback includes whether she knows the song (no, recall only the artist, recall artist name and song title), and the quality of the recommendations -whether she likes the song or not-on a rating scale from 1 (I don't like it) to 5 (I like it very much). The recommended songs do not contain any metadata, neither artist name nor song title, but only an audio preview of 30 s. The participant can listen to the preview of the recommended song as many times as she wishes. Figure <ref type="figure" target="#fig_56">7</ref>.2 shows a screenshot of the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Datasets</head><p>The three music recommendation algorithms used are: collaborative filtering (CF), content-based audio similarity (CB), and a hybrid approach (HY) combining Allmusic.com human expert information, and content-based similarity. CF song similarity comes, again, from last.fm,<ref type="foot" target="#foot_63">1</ref> using the Audioscrobbler web services (API v1.0). The CB method is the one explained in Sec. 6.2.1, Eq. (6.1). Hybrid method (HY) is based on combining related artists from Allmusic.com musicologists, and CB audio similarity at track level. That is, to get the similar tracks from a seed track, first it gets the related artists (according to the AMG human experts) of the artist's seed track. Then, it ranks the retrieved tracks from the related artists using content-based audio similarity with the seed track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3">Participants</head><p>In order to characterise the participants, at the beginning of the survey they were asked to provide some basic demographic information (age range, and gender), as well as the participants musical background knowledge, the average number of listening hours per day (more than 4 h a day, between 2 and 4 h a day, less than 2 h a day, almost never listen to music), and the context while listening to music. All the fields were optional, so the participants could fill-in or not the information (only 9 participants did not fill-in all the data). Regarding the musical background, the survey offered the following single choice options:</p><p>• None: no particular interest in music related topics.</p><p>• Basic: lessons at school, reading music magazines, blogs, etc.</p><p>• Advanced: regular choir singing, amateur instrument playing, remixing or editing music with the computer, etc. • Professional: professional musician-conductor, composer, high level instrument player-music conservatory student, audio engineer, etc.</p><p>Regarding the context while listening to music, the participants were asked to choose (multiple selection was allowed) the situations were they often listen to music. The options are:</p><formula xml:id="formula_65">• While working, • Reading, • Cleaning, • Traveling, • Doing sport, • Cooking,</formula><p>• Usually I just listen to music (and don't do anything else), and • Other (please specify) Furthermore, musical tastes of the participants were modelled using some seed tracks of their top-20 most played artists from their last.fm profile. These seed tracks are the ones used to provide song similarity using CF, CB and HY approaches.</p><p>To assemble a significant number of participants, we sent an email to the MIRlist<ref type="foot" target="#foot_65">2</ref> that described the survey and the procedure. Also, the survey was kindly announced in Paul Lamere's Duke Listens blog<ref type="foot" target="#foot_66">3</ref> on March 3rd, 2008.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Results</head><p>After running the experiment during the first two weeks in March 2008, 5,573 tracks were rated by 288 participants (with an average of 19 tracks rated per participant). Section 7.2.1 presents the analysis of the participants' data. Then, Sect. 7.2.2 presents the results of the three music recommendation approaches, including the analysis of the perceived quality, as well as the novelty and familiarity elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Demographic Data</head><p>We present the results of the demographic and musical background data gathered from the participants. Figure <ref type="figure" target="#fig_56">7</ref>.3 shows the information about the participants' demographics. Most of the participants were adult males between 19 and 35 years old.</p><p>Figure <ref type="figure" target="#fig_56">7</ref>.4 shows the distribution of the participants' musical background. Participants had a basic or advanced musical background, and most of them spent an average of two or more hours per day listening to music. The four pie charts have a 3% of not-available (NA), missing data. This missing data comes from nine participants that answered none of the questions.</p><p>To recap, our predominant participants were male young adults, with a basic or advanced musical background, who listen to quite a lot of music during the day. We consider that this is a biased sample of the population of listeners open to receiving music recommendations. Yet, it is the group we could engage to answer the survey.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Quality of the Recommendations</head><p>Now, we present the results of the second part of the survey, which consists on the evaluation of the three music recommendation methods. During the experiment, a list of 5,573 tracks rated by 288 participants was compiled. Feedback for each recommended song includes whether the user identifies the song (no, recall only the artist, recall artist name and song title), and the relevance of the recommendation (on a [1..5] scale) based on the 30 s audio excerpt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2.1">Overall Results</head><p>Table <ref type="table">7</ref>.1 presents the overall results for the three algorithms. It shows, for each algorithm, the percentage of recommended songs that the participants identified (i.e. they are familiar with), as well as the unknown-novel-ones. The last column shows the relevance of the recommendations (average rating in a scale of [1..5], and standard deviation).  ). In the three approaches, familiar recommendations score very high; specially when the participant identifies the song, but also when it only recognises the artist. Yet, providing familiar recommendations is not the most challenging part of a recommender system. In fact, one can always play songs from the artists in the user's profile, but then the discovery ratio will be null. As expected, the quality of the ratings drastically decrease when the participantis do not recognise the recommendations. The worst case is on the novel songs. Only the CF approach has an average rating score above 3 (see Table <ref type="table">7</ref>.1, and the box-and-whisker plots in Fig. <ref type="figure" target="#fig_56">7</ref>.8). These bad results are comprehensible because in the experiment we intentionally did not provide any context about the recommendations, not even basic metadata such as the artist name or song title. One of the goals of the experiment is also to measure the novelty component, so the only input the participants can receive is the audio content. Our belief is that adding basic metadata and an explanation of why the song was recommended, the perceived relevance of the novel songs could be drastically increased in the three algorithms.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2.3">Analysis of Variance</head><p>We use the overall results from Table <ref type="table">7</ref>.1 to compare the three algorithms, performing a (non-parametric) Kruskal-Wallis one-way ANOVA within subjects, at 95% confidence level. As for familiar recommendations (including both artist and song known and recall only artist), there is no statistically significant difference in the relevance of the recommendations for the three algorithms. The main differences are found in the ratings of unknown songs, F = 29.13, with p 0.05, and in the percentage of known songs, F = 7.57, p 0.05. In the former case, the Tukey's test for pairwise comparisons confirms that CF average rating scores higher than HY and CB, at 95% family-wise confidence level (see Fig. <ref type="figure" target="#fig_56">7</ref>.8 and 7.9). However, according to the latter case (percentage of known songs), CF generates more famil-Fig. <ref type="figure" target="#fig_56">7</ref>.8 Box-and-whisker plot for the ratings of unknown songs. Fig. <ref type="figure" target="#fig_56">7</ref>.9 Tukey's test for the ratings of unknown songs. Tukey's test does a pairwise comparison of the average ratings of unknown songs, and it confirms that CF avg. rating scores higher than HY and CB approaches, at 95% family-wise confidence level. iar songs than CB and HY. Thus, CB and HY provide more novel recommendations, although their quality is not as good as CF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Discussion</head><p>The results from the user-centric evaluation show that user perceived quality for novel, unknown recommendations -in the three methods-is on the negative side (avg. rating around 3/5 or less, in Table <ref type="table">7</ref>.1). This emphasises the need for adding more context when recommending unknown music. Users might want to understand why a song was recommended to them. Recommender systems should give as many reasons as possible, even including links to external sources (reviews, blog entries, etc.) to support their decision. Besides, the limitation in the experiment of using only 30 sec. samples did not help to assess the quality of the song. Yet, there are lots of industrial music recommender systems that can only preview songs due to licensing constraints. This constraint, then, is not that far from the reality.</p><p>We were expecting some correlation between the users musical background and the ratings or percentage of unknown songs. For instance, a user that listens to many hours of music daily could have more chances to identify more recommended songs. Yet, no big statistically significant differences were found, regarding the age, gender, musical background, number of hours, or context when listening to music. Only two minor statistically significant findings were found, with a p-value p 0.05. The first one is that participants aging 36-45 (7% of the total) give lower ratings for the known songs than the rest of the participants. The second finding is that participants with no musical background (9% of the total) are the ones that penalise the unkonwn songs with lower ratings. Yet, these two results could have appeared by chance, given the low percentage of these two groups of participants.</p><p>An interesting experiment would be to identify each participant as a savant, enthusiast, casual or indifferent (see Sect 3.2.1), and see whether there is any difference in the ratings when providing novel music. This would measure how open to receiving novel recommenations each type of user is. Indeed, this would help music recommender systems to decide whether being risky or confident with the personalised recommendations. However, with the participants data that we gatehered it was not straightforward to decide which type of user each participant was.</p><p>Regarding recommendation approaches, the context-free and popularity agnostic CB algorithm sometimes points in the wrong direction (it is not that easy to discriminate between a, say, classical guitar and a harpsichord, based solely on the audio content), and gives poor or non-sense recommendations. This leaves room for improving the audio similarity algorithm. In this sense, the proposed hybrid approach drastically reduces the space of possible similar tracks to those artists related to the original artist. This avoids, most of the time, the mistakes performed by the pure CB, but on the other hand the HY results are less eclectic than CB. CF tends to be more conservative, providing less novel recommendations, but of higher quality, relevant to the user. We can envision different solutions to cope with novelty in recommender systems. The first one is to use CF, promoting unknown artists by means of exploiting the Long Tail popularity of the catalog and the topology of the recommendation network. Another option is switching among algorithms when needed. For instance, to avoid the cold-start problem whilst promoting novelty, one option is to use CB or the hybrid approach, although this one heavily relies on human resources. After a while, the system can move to a stable CF or HY approaches. Or, we could also take into account the artist's (or user) location in the Long Tail, and use one or another algorithm accordingly. Furthermore, the system should be able to change the recommendation approach according to the user's needs. Sometimes, a user is open to discovering new artists and songs (novelty), while sometimes she just wants to listen to her favourites (familiarity). Detecting these modes and acting accordingly should increase the user's satisfaction with the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Limitations</head><p>To conclude, we also want to point out some limitations of the experiment. Users had to rate songs using only a 30 s audio preview. Even though the participants could listen to the songs repeatedly, it is not easy to rate a song the first time one listens to it. Sometimes, one can love a song after hearing it several times, in different contexts and moods. We could not measure this effect in the experiment. One solution could be to allow participants to download the full songs, and then after a period of time (e.g. 1 week, 1 month) they notify us with the total playcounts for each recommended song. Relevant songs could be inferred from the listening habits about the recommended songs. However, in this case a limitation is that we would collect less answers from the participants (i.e. only the songs that were listened to at least once).</p><p>The results are presented sequentially. Even though we clearly stated that the result is not playlist, thus there is no order. Still, the previously listened tracks can influence the user opinion of the current song. Also, if the first songs seem inappropriate, the songs displayed afterwards may seem better than they actually are.</p><p>Another issue is that musical tastes from the participants were gathered from last.fm, which is also one of the recommendation approaches used. This means that, beforehand, the participants were used to this system and the recommendations it provides. Yet, we decided that this music profile is more compact and reliable than asking the participant, at the beginning of the experiment, to enter a list of her favourite artists. Furthermore, another constraint is that only users with a last.fm account could participate in the survey.</p><p>The blind recommendation method approach-without providing any contextdoes not help in assessing the relevance of the novel recommendations. It might be the case that some of the novel songs were rated badly, but when explaining the relationships with the user's favourite artists, the artist biography, images, etc. the perceived quality could be increased. In real recommender systems, blind recommendations with no explanations are useless. Why is as important as what is being recommended.</p><p>Last but not least, we are not interested on judging which recommendation method performs the best, but on detecting the main differences among the approaches, and how people respond to each approach. In this sense, it is not fair to compare a real system like last.fm to the other two straight-forward plain approaches. In addition, we did not include a fourth method, say a random recommender, that could serve us as a baseline for the recommendations. This way, we could assess whether the three methods perform, at least, better than the baseline. Instead, we chose to gather more ratings from the three real methods than adding another-baseline-method in the survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 8</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applications</head><p>This chapter presents two implemented prototypes that are related with the main topics presented in the book; music discovery and recommendation. The first system, named, Searchsounds, is a music search engine based on text keyword searches, as well as a more like this button, that allows users to discover music by means of audio similarity. Thus, Searchsounds allows users to dig into the Long Tail, by providing music discovery using audio content-based similarity. The second system, named FOAFing the Music, is a music recommender system that focuses on the Long Tail of popularity, promoting unknown artists. The system also provides related information about the recommended artists, using information available on the web gathered from music related RSS feeds.</p><p>The main difference between the two prototypes is that Searchsounds is a nonpersonalised music search engine, whilst FOAFing the Music takes into account the user profile and the listening habits to provide personalised recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Searchsounds: Music Discovery in the Long Tail</head><p>Searchsounds, is a web-based music search engine that allows users to discover music using content-based similarity. Section 8.1.1 introduces the motivations and background of the system implemented. In Sec. 8.1.3 we present the architecture of the system. Finally, the last section summaries the work done and outlines the remaining work regarding the functionality of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.1">Motivation</head><p>Nowadays, the increasing amount of available music in the World Wide Web makes very difficult, to the user, to find music she would like to listen to. To overcome this problem, there are some audio search engines that can fit the user's needs. Some of the current existing search engines are, nevertheless, not fully exploited because their companies would have to deal with copyright infringing material. As general search engines, music search engines have a crucial component: an audio crawler, that scans the web for audio files, and also gathers related information about files <ref type="bibr">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.1.1">Syndication of Web Content</head><p>During the last years, syndication of web content-a section of a website made available for other sites to use-has become a common practice for websites. This originated with news and weblog sites, but nowadays is increasingly used to syndicate any kind of information. Since the beginning of 2003, a special type of weblog, named audio weblogs (or MP3 blogs), has become very popular. These blogs make music titles available for download. The posted music is explained by the blog author, and usually it has links that allow users to buy the complete album or work. Sometimes, the music is hard to find or has not been issued in many years, and many MP3 blogs link strictly to music that is authorised for free distribution. In other cases, MP3 blogs include a disclaimer stating that they are willing to remove music if the copyright owner objects. Anyway, this source of semi-structured information is a jewel for web crawlers, as it contains the user's object of desire-the music-and some textual information that is referring to the audio file.</p><p>The file format used to syndicate web content is XML. Web syndication is based on the RSS family and Atom formats. The RSS abbreviation is used to refer to the following standards: Really Simple Syndication (RSS 2.0), Rich Site Summary (RSS 0.91 and 1.0) or RDF Site Summary (1.0).</p><p>Of special interest are the feeds that syndicate multimedia content. These feeds publish audiovisual information that is available on the net. An interesting example is the Media RSS (mRSS) specification,<ref type="foot" target="#foot_69">1</ref> lead by Yahoo! and the multimedia RSS community. mRSS allows bloggers to syndicating multimedia files (audio, video, image) in RSS feeds, and adds several enhancements to RSS enclosures. Although mRSS is not yet widely used on the net, some websites syndicate their multimedia content following the specification. These feeds contain textual information, plus a link to the actual audiovisual file. As an example, Listing 8.1 shows a partial RSS feed. The example shows an item with all its information: the title of the item, the description, the publication date, the editor of the entry, and a set of categories (similar to tags, but controlled from a given taxonomy). Searchsounds mines this information in order to retrieve relevant audio files based on keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.2">Goals</head><p>The main goal of the system is to allow users to discover unknown music. For this reason, Searchsounds mines music related information available in MP3-weblogs, and attaches textual information to the audio files. This way, users can search and retrieve music related to the query, as well as music that sounds similar to the retrieved audio files. This exploration mode allows users to discover music-related to his original (keyword based) query-that would be more difficult to discover using only textual queries.</p><p>Figure <ref type="figure" target="#fig_66">8</ref>.1 shows the relationship between the music information plane (see Sec. 3.3), and the information that Searchsounds uses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.3">System Overview</head><p>Searchsounds exploits and mines all the music related information available from MP3-weblogs. The system gathers editorial, cultural, and acoustic information from the crawled audio files. The input of the system is a query composed by text keywords. From these keywords, the system is able to retrieve a list of audio files related with the query. Each audio file provides a link to the original weblog, and a list of similar titles. This similarity is computed using content-based audio description. Thus, from the results of a keyword query, a user can discover related music by navigating onto the audio similarity plane. It is worth to mention that there is no user profiling or any kind of user representation stored in the system. This is a limitation, as the system does not make any personalised recommendations. However, this limitation is solved in the next prototype (explained in Sec. 8.2). The main components of the system are the audio crawler and the audio retrieval system. Figure <ref type="figure" target="#fig_66">8</ref>.2 depicts the architecture of the system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.3.1">Audio Crawler</head><p>The system has an audio spider module that crawls the web. All the gathered information is stored into a relational database. The audio crawler starts the process from a manually selected list of RSS links (that point to MP3-blogs). Each RSS file contains a list of entries (or items) that link to audio files. The crawler seeks for new incoming items-using the pubDate item value and comparing with the latest entry in the database-and stores the new information into the database. Thus, the audio crawler system has an historic information of all the items that appeared in a feed. From the previous RSS example (see Example 8.1, presented in Section 8.1.1.1), the audio crawler stores the title, the content of the description, the assigned terms from the taxonomy (category tags), and the link to the audio file (extracted from the enclosure url attribute).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.3.2">Audio Retrieval System</head><p>The logical view of a crawled feed item can be described by the bag-of-words approach: a document is represented as a number of unique words, with a weight (in our case, the t f /id f function) assigned to each word <ref type="bibr">[2]</ref>. Special weights are assigned to the music related terms, as well as the metadata (e.g. ID3 tags) extracted from the audio file. Similar to our approach, <ref type="bibr">[3]</ref> presents a proposal of modifying the weights of the terms pertaining to the musical domain.</p><p>Moreover, basic natural language processing methods are applied to reduce the size of the item description (elimination of stopwords, and apply Porter's stemming algorithm <ref type="bibr">[4]</ref>). The information retrieval (IR) model used is the classic vector model approach, where a given document is represented as a vector in a multidimensional space of words (each word of the vocabulary is a coordinate in the space).</p><p>The similarity function, sim(d j , q), between a query (q) and a document (d j ) is based on the cosine similarity, using T F-IDF weighting function (already presented in Sec. 2.5.4). Our approach is well suited not only for querying via artists' or songs' names, but for more complex keyword queries such as: funky guitar riffs or traditional Irish tunes. The retrieval system outputs the documents (i.e. feed entries) that are relevant to the user's query, ranked by the similarity function.  Based on the results obtained from the user's textual query, the system allows users to find similar titles using content-based audio similarity. Each link to an audio file has a Find similar button that retrieves the most similar audio files, based on a set of low and mid-level audio descriptors. These descriptors are extracted from the audio and represent properties such as: rhythm, harmony, timbre and instrumentation, intensity, structure and complexity <ref type="bibr">[5]</ref>. This exploration via browsing allows users to discover music-related to his original (keyword based) query-that would be more difficult to discover by using textual queries only. There is an analogy between this type of navigation and, for example, Google's "find web pages that are similar to a given HTML page". In our case, similarity among items are based on audio similarity, whereas Google approach is based on the textual content of the HTML page. Still, both browsing approaches are based on the content analysis of the retrieved object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.4">Summary</head><p>We developed a web-based audio crawler that focuses on MP3-weblogs. Out of the crawling process, each feed item is represented as a text document, containing the content of the item, as well as the links to the audio files. Then, classic text retrieval system outputs relevant feed items related to the user's query. Furthermore, a content-based navigation allows users to browse through the retrieved items and discover new music and artists using audio similarity.</p><p>Ongoing work includes the automatic extraction of music related tags (i.e. guitar, rock, 1970s) from the text, as well as applying autotagging to incoming audio files; using audio content-based similarity <ref type="bibr">[6]</ref>. We also plan to add relevance feedback to tune the system and get more accurate results, specially for the content-based similarity.</p><p>The system is available at http://www.searchsounds.net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">FOAFing the Music: Music Recommendation in the Long Tail</head><p>Now we present the second of the two prototypes developed. It is a music recommender system, named FOAFing the Music, that allows users to discover a wide range of music located along the Long Tail. The system exploits music related information that is being syndicated (as RSS feeds) on thousands of websites. Using the crawled information, the system is able to filter it and recommend it to the user, according to her profile and listening habits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.1">Motivation</head><p>The World Wide Web has become the host and distribution channel for a broad variety of digital multimedia assets. Although the Internet infrastructure allows simple straightforward acquisition, the value of these resources lacks powerful content management, retrieval and visualisation tools. Music content is no exception: although there is a sizeable amount of text-based information related to music (album reviews, artist biographies, etc.) this information is hardly ever associated with the objects it refers to, that being the music files themselves (MIDI or audio). Moreover, music is an important vehicle for communicating to other people something relevant about our personality, history, etc. There is a clear interest in the Semantic Web field in creating a Web of machinereadable homepages describing people, the links among them, and the things they create and do. The Friend of a Friend (Friend Of A Friend) project<ref type="foot" target="#foot_71">3</ref> provides conventions and a language to describe homepage-like content and social networks. The Friend of a Friend vocabulary provides properties and classes for describing common features of people and their social networks. Friend of a Friend is based on the Resource Description Framework (RDF<ref type="foot" target="#foot_72">4</ref> ) vocabulary.</p><p>We foresee that with a complete user's Friend of a Friend profile, our system would get a better representation of the user's musical needs. On the other hand, the RSS vocabulary <ref type="foot" target="#foot_73">5</ref> allows systems one to syndicate Web content on the Internet. Syndicated content includes data such as news, event listings, headlines, project updates, as well as music related information, such as new music releases, album reviews, podcast sessions, and upcoming gigs.</p><p>To our knowledge, nowadays it does not exist any system that recommends items to a user, based on her Friend of a Friend profile. Yet, it is worth to mention the FilmTrust system. <ref type="foot" target="#foot_74">6</ref> It is a part of a research study aimed to understanding how social preferences might help web sites to present information in a more useful way <ref type="bibr">[7]</ref>. The system collects user reviews and ratings about movies, and holds them into the user's Friend of a Friend profile <ref type="bibr">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.2">Goals</head><p>The main goal of the FOAFing the Music system is to recommend, to discover and to explore music content; based on user profiling (via Friend of a Friend descriptions), context based information (extracted from music related RSS feeds), and content based descriptions (automatically extracted from the audio itself). All of that being based on a common ontology that describes the musical domain.</p><p>Figure <ref type="figure" target="#fig_66">8</ref>.4 shows the relationship between the music information plane, and the different sources of metadata that the system exploits. Compared to the first prototype (Searchsounds), Foafing the Music holds a user profile representation, based on the Friend of a Friend initiative (already presented in Sec. 3.2). A Friend of a Friend user profile allows to filter music related information according to user's preferences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3">System Overview</head><p>The overview of the Foafing the Music system is depicted in Fig. <ref type="figure" target="#fig_66">8</ref>.5. The system is divided in two main components, that is (i) how to gather data from external third party sources (presented in Sec. 8.2.3.1), and (ii) how to recommend music to the user based on the crawled data, and the semantic description of the music titles (Sec. 8.2.3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3.1">Gathering Music Related Information</head><p>Personalised services can raise privacy concerns due to the acquisition, storage and application of sensitive personal information <ref type="bibr">[9]</ref>. In our system, information about the user is not stored in the system in any way. Instead, the system has only a link pointing to the user's Friend of a Friend profile (often a link to a Livejournal ac-count). Thus, the sensitivity of this data is up to the user, not to the system. Users' profiles in Foafing the Music are distributed over the net.</p><p>Regarding music related information, our system exploits the mashup approach. The system uses a set of public available APIs and web services sourced from third party websites. This information can come in any of the different RSS formats (v2.0, v1.0, v0.92 and Yahoo! Media RSS), as well as in the Atom format. Thus, the system has to deal with syntactically and structurally heterogeneous data. Moreover, the system keeps track of all the new items that are published in the feeds, and stores the new incoming data in a historic relational database. Input data of the system is based on the following information sources: • User listening habits. To keep track of the user's listening habits, the system uses the services provided by last.fm. This system offers a list of RSS feeds that provide the most recent tracks a user has played. Each item feed includes the artist name, the song title, and a timestamp-indicating when the user has listened to the track. • New music releases. The system uses a set of RSS feeds that gathers new music releases from iTunes, Amazon, Yahoo! Shopping and Rhapsody. • Upcoming concerts. The system uses a set of RSS feeds that syndicates music related events. The websites are: Eventful.com, and Upcoming.org. Once the system has gathered the new items, it queries the Google Maps API to get the geographic location of the venues, so it can be filtered according to the user's location. • Podcast sessions. The system gathers information from a list of RSS feeds that publish podcast sessions. • MP3 Blogs. The system gathers information from a list of MP3 blogs that talk about artists and new music releases. • Album reviews. Information about album reviews are crawled from the RSS feeds published by Rateyourmusic.com, Pitchforkmedia.com, online magazines Rolling Stone, <ref type="foot" target="#foot_75">7</ref> BBC, <ref type="foot" target="#foot_76">8</ref> New York Times, <ref type="foot" target="#foot_77">9</ref> and 75 or less records. <ref type="foot" target="#foot_78">10</ref>Table <ref type="table">8</ref>.1 shows some basic statistics of the data that has been gathered since mid April, 2005 until the first week of March, 2010. These numbers show that the system has to deal with daily incoming data. Based on the user's Friend of a Friend profile, the system filters this information, and presents the most relevant items according to her musical taste.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3.2">Music Ontologies</head><p>An ontology is an explicit and formal specification of a conceptualisation <ref type="bibr">[10]</ref>. In general, an ontology describes formally a domain of discourse. The requeriments for Ontology languages are: a well-defined syntax, a formal semantics, and a reasoning support that checks the consistency of the ontology, checks for unintended relationships between classes, and automatically classifies instances in classes. The Web Ontology Language (OWL <ref type="foot" target="#foot_79">11</ref> ) has a richer vocabulary description language for describing properties and classes than RDF Schema (RDFS <ref type="foot" target="#foot_80">12</ref> ). OWL has relations between classes, cardinality, equality, characteristics of properties and enumerated classes. The OWL language is build on top of RDF and RDFS, and uses RDF/XML syntax. OWL documents are, then, RDF documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 8.3 Example of a track individual</head><p>These individuals are used in the recommendation process, to retrieve artists and songs related with the user's musical taste.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3.3">Providing Music Recommendations</head><p>This section explains the music recommendation process, based on all the information that has continuously been gathered from the RSS feeds and the crawler. Music recommendations, in the Foafing the Music system, are generated according to the following steps:</p><p>1. Get music related information from user's Friend of a Friend interests, and listening habits from last.fm, 2. Detect artists and bands, 3. Compute similar artists, and 4. Rate the results by relevance, according to the user's profile.</p><p>To gather music related information from a Friend of a Friend profile, the system extracts the information from the FOAF interest property (if dc:title is given then it gets its value, otherwise it gathers the text from the &lt;title&gt; tag of the HTML resource). The system can also extract information from a user's Friend of a Friend interest that includes the artist description based on the general Music Ontology <ref type="bibr">[12]</ref>.</p><p>The following example presents a way to express interest in an artist, by means of the general Music Ontology. Based on the music related information gathered from the user's profile and listening habits, the system detects the artists and bands that the user is interested in, by doing a SPARQL query to the artist RDF repository. Once the user's artists have been detected, artist similarity is computed. This process is achieved by exploiting the RDF graph of artists' relationships (e.g. influenced by, followers of, worked with, etc.), as shown in Listing 8.2.</p><p>The system offers two ways of recommending music information. On the one hand, static recommendations are based on the favourite artists encountered in the Friend of a Friend profile. We assume that a Friend of a Friend profile would be rarely manually updated or modified. On the other hand, dynamic recommendations are based on user's listening habits, which are updated much more often than the user's profile. Following this approach a user can discover a wide range of new music and artists on a daily basis.</p><p>Once the recommended artists have been computed, Foafing the Music filters music related information coming from the gathered music information (see Sec. 8.2.3.1) to:</p><p>• Get new music releases from iTunes, Amazon, Yahoo Shopping, etc.</p><p>• Download (or stream) audio from MP3-blogs and Podcast sessions, • Create, automatically, XSPF <ref type="foot" target="#foot_82">14</ref> playlists based on audio similarity, • View upcoming gigs happening near to the user's location, and • Read album reviews. Syndication of the website content is done via an RSS 1.0 feed. For most of previous functionalities, there is a feed subscription option to get the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3.4">Usage Data</head><p>Since its inception in August 2005, the system has an average of 60 daily unique accesses, from more than 5,000 registered users, including casual users that try the demo option. More than half of the users automatically created an account using an external Friend of a Friend profile (most of the times, around 70%, the profile came from their Livejournal Friend of a Friend account). Also, more than 65% of the users add her last.fm account, so we can use their listening habits from last.fm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.4">Summary</head><p>We have proposed a system that filters music related information, based on a given user's Friend of a Friend profile and her listening habits. A system based on Friend of a Friend profiles and user's listening habits allows the system to "understand" a user in two complementary ways; psychological factors-personality, demographic preferences, social relationships-and explicit musical preferences. In the music field, we expect that filtering information about new music releases, artists' interviews, album reviews, and so on, can improve user satisfaction as it provides the context and needed information to backup the system's recommendations.</p><p>Describing music assets is a crucial task for a music recommender system. The success of a music recommender can depend on the accuracy and level of detail of the musical objects, and its links within a user profile. Furthermore, we formalise into an ontology the basic musical concepts involved in the recommendation process. Linking these musical objects with the user profile eases the recommendation process.</p><p>Furthermore, high-level musical descriptors can increase the accuracy of content retrieval, as well as provide better personalised recommendations. Thus, going one step beyond, it would be desirable to combine mid-level acoustic features with as much editorial and cultural metadata as possible. From this combination, more sophisticated inferences and semantic rules would be possible. These rules could derive hidden high-level metadata that could be easily understood by the end-user, also enhancing their profiles. Since the existence of the general Music Ontology (MO) <ref type="bibr">[12]</ref>, we foresee that linking our recommendation ontology with it, as well as using all the linked information available in the Web of Data, <ref type="foot" target="#foot_83">15</ref> we can improve our recommender, becoming a truly semantically-enhanced music recommender.</p><p>Foafing the Music is available at http://foafing-the-music.iua.upf. edu.</p><p>similarity networks. We also present a survey with 288 subjects that provided feedback about the (personalised) recommendations. This survey evaluates the user's perceived quality and novelty factor of the music recommended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Book Summary</head><p>This book presents a number of novel ideas that address existing limitations in recommender systems, and the lack of systematic methods to evaluate the novelty and perceived quality of recommendations in the music domain. Furthermore, two real web-based systems have been implemented to demonstrate the ideas derived from the theoretical work. The main outcomes of the book are:</p><p>1. A novel network-centric evaluation method for recommender systems, based on the analysis of the item (or user) similarity graph, and the combination with items' popularity, using the Long Tail curve. An exhaustive study comparing different approaches of music recommendation networks is presented in Chap. 6. 2. A user-centric evaluation, based on the immediate feedback of the provided recommendations, that measures the user's perceived quality and novelty factor of the recommendations. An in-depth user-based evaluation of three different music recommendation approaches is presented in Chap. 7. 3. A music search engine, named Searchsounds, that allows users to discover unknown music that is available on music related blogs. 4. A system prototype, named FOAFing the music, that provides music recommendation based on the user preferences and listening habits.</p><p>The first two contributions are more scientific, whilst the third and fourth are more engineering oriented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.1">Scientific Contributions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.1.1">A Network-Based Evaluation Method for Recommender Systems</head><p>We have formulated a network-based evaluation method for recommender systems,</p><p>We have applied the network-based analysis to two different similarity graphs; for artists, and users. The results from the artist network analysis show that the last.fm social-based recommender tends to reinforce popular artists, at the expense of discarding less-known music. Thus, the popularity effect derived from the community of users has consequences in the recommendation network. This reveals a somewhat poor discovery ratio when just browsing through the network of similar music artists. Allmusic.com expert-based recommendations are more expensive to create, and also have a smaller Long Tail coverage, compared to automatically generated recommendations like collaborative filtering or audio content-based similarity. Regarding popularity, the hubs in the expert network are comprised of mainstream music. Our guess is that the editors connect long tail artists with the most popular ones, either for being influential or because many bands are considered followers of these mainstream artists. An audio content-based similarity network is not affected by the popularity bias of the artists, however it is prone to the musical genre biases of the collection, where the predominant genres includes most of the similar artists. The main problem of audio content-based systems is the assumption that just because two songs sound similar, any user will like both. It is very unlikely that a user will love both a Franz Schubert's piano sonata, and a Meat Loaf piano ballad (such as "Heaven Can Wait") just because the two contain a prominent piano melody.</p><p>The results from the user network analysis show that user similarity network derived from collaborative filtering resembles a social network, whilst the network derived from audio content-based similarity has the properties of a hierarchy, where a few nodes connect small clusters. The authorities in the CB network are the users that listen to more music, independently of the quality or popularity of the music they listen to. Contrastingly, the authorities in the CF network are the users that listen to more mainstream music. These considerations have a big impact on recommendation algorithms that compute recommendations by means of user neighbourhood information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.1.2">A User-Based Evaluation Method for Recommender Systems</head><p>Our proposed evaluation measures the user's perceived quality and novelty of the recommendations. The user-centric evaluation approach has the following advantages:</p><p>1. It measures the novelty factor of a recommendation algorithm considering the user's knowledge of the items. 2. It measures the perceived quality (e.g., like it or not) of the recommendations. 3. Users provide immediate feedback to the evaluation system, so the algorithm can adapt accordingly.</p><p>This method complements the previous, user-agnostic, network-based evaluation approach. We use the user-centric method to evaluate and compare three different music recommendation approaches. In this experiment, 288 subjects rated the recommendations in terms of novelty (does the user know the recommended song/artist?), and relevance (does the user like the recommended song?).</p><p>The results from the music recommendation survey show that, in general, users' perceived quality for novel recommendations is neutral or negative (mean rating around 3/5 or less). This emphasises the need for adding context when recommending unknown music. Recommender systems should give as many reasons as possible to support their decisions.</p><p>In terms of algorithms, the rating scores for the last.fm social-based approach are higher than those for the hybrid and pure audio content-based similarity. However, the social-based recommender generates more familiar (less novel) songs than CB and HY. Thus, content-based and hybrid approaches provide more novel recommendations, although their quality is not as good as the ones from last.fm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.2">Industrial Contributions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.2.1">FOAFing the Music: A Music Recommendation System</head><p>The system prototype, named FOAFing the Music, provides music recommendation based on the user preferences and listening habits. The main goal of FOAFing the Music is to recommend, to discover and to explore music content via user profiling, context-based information (extracted from music related RSS feeds), and contentbased descriptions (automatically extracted from the audio itself). The system has an average of 60 daily unique accesses, from more than 5,000 registered users and also casual users that try the demo option. FOAFing the music allows users to:</p><p>1. get new music releases from iTunes, Amazon, Yahoo Shopping, etc. 2. download (or stream) audio from MP3-blogs and Podcast sessions, 3. discover music with radio-a-la-carte (i.e. personalised playlists), 4. view upcoming nearby concerts, and 5. read album reviews.</p><p>Since the existence of the general Music Ontology <ref type="bibr">[3]</ref>, we foresee that linking our recommendation ontology with it, as well as exploiting all the linked information available in the Web of Data, <ref type="foot" target="#foot_86">1</ref> we can improve our system, becoming a truly semantically-enhanced music recommender.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.2.2">Searchsounds: A Music Search Engine</head><p>We have implemented a music search engine, named Searchsounds, that allows users to discover unknown music mentioned on music-related blogs. Searchsounds provides keyword based search, as well as the exploration of similar songs using audio similarity. The system allows users to dig into the Long Tail, by providing music discovery using audio content-based similarity, that could not be easily retrieved using classic text retrieval techniques. Over 400,000 audio files are currently indexed, using both text and audio features.</p><p>Ongoing work includes the automatic extraction of music related tags (i.e. guitar, rock, 1970s) from the text, as well as applying autotagging to incoming audio files; using audio content-based similarity <ref type="bibr">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Limitations and Further Research</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.1">Dynamic Versus Static Data</head><p>It goes without saying that there are many ways in which the work presented in this book could be extended or improved. One of the main limitations of our approach is that it is not dynamic. We work with a snapshot of the item (or user) similarity network, and the analysis is based on this data. However, the recommendation network dynamics is an important aspect of any recommender system. Users' taste change over time, and so it does the similarity among items. Further work in this area would include a detailed study of a dynamic model in the network-including trend and hype-item detection-and a comparison with our stationary model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.2">Domain Specific</head><p>The work done has been applied only to music recommendation. Even though we did not use any domain-specific metrics in the network-centric evaluation, our findings cannot be directly extrapolated to other domains. Further work could be to extend the network-centric experiments to other domains, such as movie recommendation using the Netflix dataset.</p><p>Besides, the user-centric evaluation contains a lot of particularities from the music recommendation domain. In other domains (e.g., movies, books, or travels), explicit user feedback about the recommended items cannot be provided in real-time. Furthermore, our music recommendation survey design is based on providing blind recommendations. Future work should be to compare our results with a new experiment that provides contextual information and transparency about the music being recommended. The related question would be whether the ratings of novel items increase (i.e. are perceived with better quality) when providing more information about the recommended songs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.3">User Evaluation</head><p>In our user-centric evaluation we could not classify a participant into the four type of listeners (savant, enthusiasts, casuals and indifferents). In fact, it would be interesting to look at recommendation evaluations through the lense of the four types of listeners. The type and utility of recommendations varies greatly depending on the type of user. When testing against the general population-since most listeners fall into the casual or indifferent bucket-recommenders that appeal to these types of listeners would score well when compared to recommenders that are designed for the enthusiast or savant. However, enthusiasts and savants are likely to be much more active consumers, so from an economic point of view, there may be more value targeting them. Recommenders for savants and enthusiasts would probably favour novelty and long tail content, while recommendations for a casual listener would probably favour low-risk exploration. Indeed, a new task for music recommenders could be to help casual listeners appreciate diversity and exploration to unknown content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.4">User Understanding</head><p>User understanding is another important aspect when providing personalised recommendations. Our approach to model a user profile is a rather simple list of preferred artists. Extending the user profile model, adding relevant and contextual information, would allow recommender systems to have a better understanding of the user.</p><p>Ideally, a recommender system should provide different and personalised recommendations for a given item. That is, when visiting the Beatles' White Album in Amazon store, the system should present the list of recommendations according to the user profile. Depending on the user's taste, the system should stress the pop side of the band, whilst in other situations it could promote the more psychedelic or experimental music they did. Ongoing work by Lamere and Maillet <ref type="bibr">[5]</ref> is aligned with this idea. They have implemented a prototype system that creates transparent, steerable recommendations. Users can modify the list of recommended artists, by changing the tag cloud of the seed artist. This way, users focus on some particular styles or aspects of the musician (e.g. give me The Beatles similar artists, but emphasizing their psychedelic rock side).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.5">Recommendations with No Explanation</head><p>Blind recommendations do not provide any context nor explanation. Thus, it does not help in assessing the relevance of novel recommendations. It might be the case that some novel songs recommended are perceived as non-relevant, but when explaining the ties with the user profile the perceived quality could be increased. In fact, why is as important as what is being recommended. Again, <ref type="bibr">[5]</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 . 1</head><label>11</label><figDesc>Fig. 1.1 Amazon recommendations for The Beatles' "White Album".</figDesc><graphic coords="20,53.63,54.43,340.24,233.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 . 2</head><label>12</label><figDesc>Fig. 1.2The Long Tail of items in a recommender system. An important role of a recommender is to drive the user from the head region (popular items) to the long tail of the curve[38].</figDesc><graphic coords="21,106.07,53.43,226.69,130.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 . 3</head><label>13</label><figDesc>Fig. 1.3 Diagram that depicts the key elements of the book. It consists of the similarity graph, the long tail of item popularity, the user profile, the provided recommendations, and the evaluation part.</figDesc><graphic coords="22,53.63,54.38,339.99,289.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 1 . 4</head><label>14</label><figDesc>Fig. 1.4 Extension of Fig. 1.3 adding the corresponding chapters.</figDesc><graphic coords="24,53.63,265.76,340.20,299.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 . 1</head><label>21</label><figDesc>Fig. 2.1 General model of the recommendation problem.</figDesc><graphic coords="31,106.01,53.16,226.89,252.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 . 2</head><label>22</label><figDesc>Fig. 2.2 Example of a pre-defined training set to model user preferences when a user created an account in iLike.</figDesc><graphic coords="33,106.06,53.36,226.47,222.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 2 . 3</head><label>23</label><figDesc>Fig. 2.3 User-item matrix for the collaborative filtering approach.</figDesc><graphic coords="36,134.36,396.89,169.90,115.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 2 . 5</head><label>25</label><figDesc>Fig. 2.5 Distance among items using content-based similarity.</figDesc><graphic coords="40,162.76,53.46,113.29,123.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>17</head><label>17</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 2 . 7</head><label>27</label><figDesc>Fig. 2.7 Two examples of users' tag clouds derived from their last.fm listening habits. Top and middle images show two last.fm user tag clouds. The third image (bottom) shows the tags that cooccur the most in the two profiles. According to Anthony Liekens' algorithm, the similarity value between ocelma and lamere last.fm users is 70.89%. Image courtesy of Anthony Liekens, taken from http://anthony.liekens.net/pub/scripts/last.fm/compare.php.</figDesc><graphic coords="46,106.05,53.31,226.56,190.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 3 . 1</head><label>31</label><figDesc>Fig. 3.1 The four type of music listeners: savants, enthusiasts, casuals, and indifferents. Each type of listener needs different type of recommendations.</figDesc><graphic coords="58,141.52,284.77,155.56,92.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 3 . 2</head><label>32</label><figDesc>Fig. 3.2 The music information plane. The horizontal axis includes the input media types. The vertical axis represents the different levels of information extraction for each media type. At the top, a user interacts with the music content and the social network of users.</figDesc><graphic coords="66,91.84,53.22,255.23,237.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 3 . 3</head><label>33</label><figDesc>Fig. 3.3 Editorial metadata and the music information plane.</figDesc><graphic coords="67,91.84,137.07,255.23,237.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 3 . 4</head><label>34</label><figDesc>Fig. 3.4 Cultural metadata and the music information plane.</figDesc><graphic coords="68,91.84,252.63,255.23,245.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 3 . 5</head><label>35</label><figDesc>Fig. 3.5 Last.fm screenshot with top artists tagged with Brutal Death Metal. Screenshot taken on May, 23rd 2007.</figDesc><graphic coords="72,134.44,53.59,169.54,245.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 3 . 6</head><label>36</label><figDesc>Fig. 3.6 Dendogram for some Paris Hilton tags, including Brutal Death Metal, using the cosine similarity results from Table 3.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 3 . 7</head><label>37</label><figDesc>Fig. 3.7 Acoustic metadata and the music information plane.</figDesc><graphic coords="75,91.84,160.98,255.23,237.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3.8 A user listening habits represented with frequency distribution of playcounts per artist in the user's profile.</figDesc><graphic coords="83,106.07,296.45,226.57,158.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 3 . 9</head><label>39</label><figDesc>Fig. 3.9 User listening habits from Fig. 3.8 represented with the complementary cumulative distribution. Top-1 and 2 artists receive a score of 5. Artists at position 3..7 have a score of 4, artists in 8..15 a 3, and so on.</figDesc><graphic coords="84,106.07,53.36,226.39,159.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 4 . 1</head><label>41</label><figDesc>Fig. 4.1 Correlation between last.fm and Myspace artist playcounts. Data gathered during January, 2008.</figDesc><graphic coords="102,106.07,53.44,226.55,162.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 4 . 2</head><label>42</label><figDesc>Fig. 4.2 The music Long Tail effect. A log-linear plot depicting the total number of plays per artist. Data gathered during July, 2007, for a list of 260,525 artists.</figDesc><graphic coords="103,106.07,53.44,227.07,155.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4.2 depicts the Long Tail popularity, using total playcounts, for 260,525 music artists. The horizontal axis contains the list of artists ranked by its total playcounts. For example The Beatles, at position 1, has more than 50 million playcounts.This data was gathered from last.fm during July, 2007. Last.fm provides plugins for almost any desktop music player (as well as iPhones and other mobile</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 4 . 3</head><label>43</label><figDesc>Fig. 4.3The music Long Tail effect. Same plot as Fig.4.2 here in log-log scale. The best fit is a log-normal distribution, with a mean of log μ = 6.8, and standard deviation of log, σ = 2.18. The fast drop in the tail is in part due to misspelled artists (e.g. incorrect metadata in the ID3 tags).</figDesc><graphic coords="104,106.07,53.34,226.61,155.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4.4 depicts the cumulative distribution of the Long Tail of the 260,525 music artists presented in Fig. 4.2.Interestingly enough, the top-737 artists, 0.28% of all the artists, account for 50% of the total playcounts, F(737) = 50(N 50 = 737), and only the top-30 artists hold around 10% of the plays. Another measure is the Gini coefficient. This coefficient measures the inequality of a given distribution, and it determines the degree of imbalance[11]. In our Long Tail example, 14% of the artists hold 86% of total playcounts, yielding a Gini coefficient of 0.72. This value describes a skewed distribution, higher than the classic 80/20 Pareto rule, with a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 4 . 4</head><label>44</label><figDesc>Fig. 4.4 Example of the Long Tail model. It shows the cumulative percentage of playcounts of the 260,525 music artists from Fig. 4.2.Only top-737 artists, 0.28% of all the artists, accumulates the 50% of total playcounts (N 50 ). Also, the curve is divided in three parts: head, mid and tail (X head→mid = 82, and X mid→tail = 6, 655), so each artist is located in one section of the curve.</figDesc><graphic coords="107,106.06,53.14,226.59,159.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 4 .</head><label>4</label><figDesc>5  shows an example of the fitted distribution using the F(x) model. The data is the one from artist popularity in last.fm (Fig.4.4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 4 . 5</head><label>45</label><figDesc>Fig. 4.5 Example of fitting a heavy-tailed distribution (the one in Fig. 4.4) with F(x). The black dots represent the observations while the white dotted curve represents the fitted model, with parameters α = 0.73, and β = 1.02.</figDesc><graphic coords="108,77.72,53.16,283.76,196.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>4.2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head></head><label></label><figDesc>Figure 4.6 shows the dynamics of the curve comparing two snapshots; one from July 2007, and the other from January 2008. The most important aspect is the increase of total playcounts in each area of the curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Fig. 4 . 6</head><label>46</label><figDesc>Fig. 4.6 The dynamics of the Long Tail after 6 months (between July, 2007 and January, 2008). Radiohead, at top-2, is now closer to The Beatles (top-1), due to the release of their In Rainbows album.</figDesc><graphic coords="111,106.07,184.94,227.07,157.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Fig. 4 . 7 A</head><label>47</label><figDesc>Fig. 4.7 A user profile represented in the Long Tail. The profile is exhibited as the number of times the user has interacted with that item.</figDesc><graphic coords="114,106.07,53.43,226.69,130.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Fig. 4 . 8</head><label>48</label><figDesc>Fig. 4.8 Trade-off between novelty and relevance for a user u.</figDesc><graphic coords="115,120.23,53.28,198.25,175.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Fig. 4 . 9 A</head><label>49</label><figDesc>Fig. 4.9 A 3D representation of the Long Tail. It adds another dimension; the similarities among the items, including the representation of a user profile (in gray). The set of candidate items to be recommended to the user are shown (in dotted lines) and its height denotes the relevance for the user.</figDesc><graphic coords="117,77.71,53.36,283.31,335.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Fig. 5 . 2</head><label>52</label><figDesc>Fig. 5.2 Network-centric evaluation determines the underlying topology of the item (or user) similarity network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Fig. 5 . 3</head><label>53</label><figDesc>Fig. 5.3 User-centric evaluation, including feedback about the received recommendations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Fig. 5 . 4</head><label>54</label><figDesc>Fig. 5.4 System-, network-, and user-centric evaluation methods. Combining the three methods we can cover all the facets when evaluating a recommendation system.</figDesc><graphic coords="136,106.09,346.47,226.64,154.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Fig. 6 . 1</head><label>61</label><figDesc>Fig. 6.1 General framework for the network-centric evaluation. The network-centric approach determines the underlying topology of the similarity network, and combines this information with the Long Tail of popularity.</figDesc><graphic coords="140,63.55,53.42,311.89,290.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Fig. 6 . 2</head><label>62</label><figDesc>Fig. 6.2 Cumulative indegree distribution for the three artist networks.</figDesc><graphic coords="144,53.59,54.20,340.12,123.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Fig. 6 . 3</head><label>63</label><figDesc>Fig. 6.3 Indegree-indegree correlation (assortative mixing) for the three artist recommendation networks: collaborative filtering (CF) from last.fm, Content-based (CB), and Allmusic.com experts. CF clearly presents the assortative mixing phenomenon (r CF = 0.92). Neither CB nor expert-based present any correlation (r CB = 0.14, r Expert = 0.17).</figDesc><graphic coords="145,120.28,53.56,197.87,173.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head></head><label></label><figDesc><ref type="bibr" target="#b186">77)</ref>. Similar values are found for country and soul artists. Neither in CF nor in CB networks we can find these high intra-correlation values (only for the reggae genre in the CF network, with a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>Fig. 6 . 4</head><label>64</label><figDesc>Fig. 6.4 A log-log plot depicting the correlation between an artist's total playcounts and similar artists' playcounts (average values are shown in black, whilst grey dots display all the values). Pearson correlation coefficient r values are: r CF = 0.503, r EX = 0.259 and r CB = 0.081.</figDesc><graphic coords="150,113.12,53.19,212.63,507.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head>Fig. 6 . 5</head><label>65</label><figDesc>Fig. 6.5 Example of the Markov decision process to navigate along the Long Tail in the CF network. This information is directly derived from Table6.9.</figDesc><graphic coords="151,134.46,53.54,169.52,65.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6.6 A log-log plot showing the correlation between artist indegree (k in , in horizontal axis) and its total playcounts (avg. values in black), in vertical axis. Pearson r values are: r CF = 0.621, r EX = 0.475, and r CB = 0.032.</figDesc><graphic coords="154,108.88,53.20,221.23,513.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Fig. 6 . 7</head><label>67</label><figDesc>Fig. 6.7 Clustering coefficient C(k) versus degree k. The CB network resembles a hierarchical network (C CB (k) ∼ k -0.87 ), although it is not a scale free network.</figDesc><graphic coords="159,120.31,53.69,197.98,173.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Fig. 6 . 8</head><label>68</label><figDesc>Fig. 6.8 Cumulative indegree distribution for the CF and CB user networks.</figDesc><graphic coords="160,53.60,54.23,340.15,160.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_46"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6.10 Example of a user's location in the Long Tail of artists. The circle denotes the user's location, computed as the weighted average of the user profile artists' playcounts and popularity.</figDesc><graphic coords="162,106.03,53.19,227.02,160.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_47"><head></head><label></label><figDesc>Top-5 indegree (k in ) users. Influential users in CF are those located in the head of the Long Tail (column LT Rank), whilst influentials in CB are the ones with most playcounts (column Plays).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_48"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6.11 Correlation between users' indegree and total playcounts. CB has a correlation of r CB = 0.446, whilst CF does not present any correlation (r CF = -0.012).</figDesc><graphic coords="164,53.60,224.32,340.33,130.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><head>Fig. 7 . 2</head><label>72</label><figDesc>Fig. 7.2 Screenshot of the Music recommendation survey.</figDesc><graphic coords="169,53.62,54.35,339.84,193.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_50"><head>Fig. 7 . 3</head><label>73</label><figDesc>Fig. 7.3 Demographic information (age and gender distribution) of the participants.</figDesc><graphic coords="171,63.60,222.47,311.20,123.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_51"><head>Fig. 7 . 4</head><label>74</label><figDesc>Fig. 7.4 Musical background and daily listening hours information of the participants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><head>Figure 7 . 5 , 7 . 6 ,</head><label>7576</label><figDesc>Figure 7.5, 7.6, and 7.7  show the histogram of the ratings when the participants knows the artist name and song title (Fig.7.5), only identifies the artist (Fig.7.6), and the song is completely unknown to the participant (Fig.7.7). In the three approaches, familiar recommendations score very high; specially when the participant identifies the song, but also when it only recognises the artist. Yet, providing familiar recommendations is not the most challenging part of a recommender system. In fact, one can always play songs from the artists in the user's profile, but then the discovery ratio will be null.As expected, the quality of the ratings drastically decrease when the participantis do not recognise the recommendations. The worst case is on the novel songs. Only the CF approach has an average rating score above 3 (see Table7.1, and the box-and-whisker plots in Fig.7.8). These bad results are comprehensible because in the experiment we intentionally did not provide any context about the recommendations, not even basic metadata such as the artist name or song title. One of the goals of the experiment is also to measure the novelty component, so the only input the participants can receive is the audio content. Our belief is that adding basic metadata and an explanation of why the song was recommended, the perceived relevance of the novel songs could be drastically increased in the three algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head>Fig. 7 . 5</head><label>75</label><figDesc>Fig. 7.5 Histogram of the ratings (on a [1..5] scale) when the participant identifies the artist and song (left: CF, center: CB, and Right: HY).</figDesc><graphic coords="173,63.60,181.87,311.17,79.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_54"><head>Fig. 7 . 6</head><label>76</label><figDesc>Fig. 7.6 Histogram of the ratings (on a [1..5] scale) when the participant only recognises the artist (left: CF, center: CB, and Right: HY).</figDesc><graphic coords="173,63.60,308.48,311.17,80.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head>Fig. 7 . 7</head><label>77</label><figDesc>Fig. 7.7 Histogram of the ratings (on a [1..5] scale) when the recommended song is unknown to the participant (left: CF, center: CB, and Right: HY).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_56"><head>Figure 7 .</head><label>7</label><figDesc>10 summarises the comparison of the three approaches, based on the trade-off between novelty and relevance (presented in Chap. 4, Fig. 4.8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_57"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7.10 Location of the three music recommendation approaches in the novelty vs. relevance axis (presented in Chap. 4, Fig. 4.8).</figDesc><graphic coords="176,134.40,53.29,169.97,150.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_58"><head>Fig. 8 . 1</head><label>81</label><figDesc>Fig. 8.1 Searchsounds makes use of editorial, cultural and acoustic metadata. The system retrieves (1) audio files from a keyword query, as well as (2) a list of (content-based) similar titles.</figDesc><graphic coords="181,63.54,53.33,311.67,290.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_59"><head>Fig. 8 . 2</head><label>82</label><figDesc>Fig. 8.2 Searchsounds architecture. The main components are the audio crawler, and the audio retrieval system.</figDesc><graphic coords="182,63.53,53.31,311.98,250.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_60"><head></head><label></label><figDesc>Figure 8.3 depicts the retrieved audio files for traditional Irish music query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_61"><head>Fig. 8 . 3</head><label>83</label><figDesc>Fig. 8.3 Screenshot of the Searchsounds application, showing the first 10 results from traditional Irish music query.</figDesc><graphic coords="183,63.55,264.76,311.66,186.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_62"><head>Fig. 8 . 4</head><label>84</label><figDesc>Fig. 8.4 FOAFing the Music and the music information plane.</figDesc><graphic coords="186,63.54,53.33,311.67,290.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_63"><head>Fig. 8 . 5</head><label>85</label><figDesc>Fig. 8.5 Architecture of the Foafing the Music system.</figDesc><graphic coords="187,63.68,193.69,310.75,225.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_64"><head>Listing 8 . 4</head><label>84</label><figDesc>&lt;foaf:interest rdf:resource="http://www.tylaandthedogsdamour.com/" dc:title="The Dogs d'Amour" /&gt; Example of a Friend of a Friend interest with a given dc:title.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_65"><head>Listing 8 . 5</head><label>85</label><figDesc>FOAF example of an artist description that a user is interested in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_66"><head>Figure 8 .</head><label>8</label><figDesc>6 shows the number of logins over time, since August 2005 till July 2008. The peaks are clearly correlated with related news about the project (e.g. local TV and radio interviews, and reviews on the web).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_67"><head>Fig. 8 . 6</head><label>86</label><figDesc>Fig. 8.6 Daily accesses to Foafing the Music. The system has an average of 60 daily unique accesses, from more than 4,000 registered users and also casual users that try the demo option.</figDesc><graphic coords="192,106.15,53.71,226.22,167.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Year Num. papers</cell></row><row><cell>1994</cell><cell>1</cell></row><row><cell>-</cell><cell>-</cell></row><row><cell>2001</cell><cell>3</cell></row><row><cell>2002</cell><cell>4</cell></row><row><cell>2003</cell><cell>3</cell></row><row><cell>2004</cell><cell>8</cell></row><row><cell>2005</cell><cell>14</cell></row><row><cell>2006</cell><cell>19</cell></row><row><cell>2007</cell><cell>21</cell></row><row><cell>2008</cell><cell>19</cell></row><row><cell>2009</cell><cell>19</cell></row></table><note><p>1 Number of scientific articles related to music recommendation, indexed by Google Scholar.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .1</head><label>2</label><figDesc>Summary of the elements involved in the recommendation problem.</figDesc><table><row><cell>User profile</cell><cell>⎧ ⎪ ⎪ ⎪ ⎨</cell><cell>empty manual</cell></row><row><cell>Initial generation</cell><cell>⎪ ⎪ ⎪ ⎩</cell><cell>data import training set stereotyping</cell></row><row><cell>Maintenance</cell><cell>⎧ ⎨</cell><cell>implicit relevance f eedback explicit relevance f eedback manual</cell></row><row><cell>Adaptation</cell><cell>⎩</cell><cell>add new in f ormation gradually f orget old interests</cell></row><row><cell>Recommendation methods</cell><cell></cell><cell></cell></row><row><cell>Matching</cell><cell>⎧ ⎪ ⎪ ⎪ ⎨</cell><cell>user-item pro f ile user-user pro f ile(neighbours) demographic f iltering collaborative f iltering</cell></row><row><cell>Filtering method</cell><cell>⎪ ⎪ ⎪ ⎩</cell><cell>content based f iltering context based f iltering hybrid methods</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Their musical knowledge is very extensive. As expected, they only represent 7% of the 16-45 age group. • Enthusiasts. Representing 21% of the 16-45 age group, for the enthusiasts music is a key part of life but is also balanced by other interests. • Casuals. Music plays a welcome role, but other things are far more important. They represent 32% of the 16-45 age group. • Indifferents would not lose much sleep if music ceased to exist. Representing 40% of the 16-45 age group, they are a predominant type of listeners of the whole population.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>3.1 shows a possible user profile: Example of a user profile in UMIRL.</figDesc><table><row><cell>&lt;user&gt;</cell></row><row><cell>&lt;generalbackground&gt;</cell></row><row><cell>&lt;name&gt;Joan Blanc&lt;/name&gt;</cell></row><row><cell>&lt;education&gt;MsC&lt;/education&gt;</cell></row><row><cell>&lt;citizen&gt;Catalan&lt;/citizen&gt;</cell></row><row><cell>&lt;/generalbackground&gt;</cell></row><row><cell>&lt;musicbackground&gt;</cell></row><row><cell>&lt;education&gt;none&lt;/education&gt;</cell></row><row><cell>&lt;instrument&gt;guitar&lt;/instrument&gt;</cell></row><row><cell>&lt;/musicbackground&gt;</cell></row><row><cell>&lt;musicpreferences&gt;</cell></row><row><cell>&lt;genre&gt;rock&lt;/genre&gt;</cell></row><row><cell>&lt;album&gt;</cell></row><row><cell>&lt;title&gt;To bring you my love&lt;/title&gt;</cell></row><row><cell>&lt;artist&gt;P.J. Harvey&lt;/artist&gt;</cell></row><row><cell>&lt;/album&gt;</cell></row><row><cell>&lt;/musicpreferences&gt;</cell></row><row><cell>&lt;/user&gt;</cell></row><row><cell>Listing 3.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Example of a user profile in MPEG-7.</figDesc><table><row><cell>Name&gt;</cell></row><row><cell>&lt;/UserIdentifier&gt;</cell></row><row><cell>&lt;FilteringAndSearchPreferences&gt;</cell></row><row><cell>&lt;CreationPreferences&gt;</cell></row><row><cell>&lt;Title preferencValue="8"&gt;To bring you my love&lt;/Title&gt;</cell></row><row><cell>&lt;Creator&gt;</cell></row><row><cell>&lt;Role&gt;</cell></row><row><cell>&lt;Name&gt;Singer&lt;/Name&gt;</cell></row><row><cell>&lt;/Role&gt;</cell></row><row><cell>&lt;Agent xsi:type="PersonType"&gt;</cell></row><row><cell>&lt;Name&gt;</cell></row><row><cell>&lt;GivenName&gt;Polly Jean&lt;/GivenName&gt;</cell></row><row><cell>&lt;FamilyName&gt;Harvey&lt;/FamilyName&gt;</cell></row><row><cell>&lt;/Name&gt;</cell></row><row><cell>&lt;/Agent&gt;</cell></row><row><cell>&lt;/Creator&gt;</cell></row><row><cell>&lt;Keyword&gt;dramatic&lt;/Keyword&gt;</cell></row><row><cell>&lt;Keyword&gt;fiery&lt;/Keyword&gt;</cell></row><row><cell>&lt;DatePeriod&gt;</cell></row><row><cell>&lt;TimePoint&gt;1995-01-01&lt;/TimePoint&gt;</cell></row><row><cell>&lt;Duration&gt;P1825D&lt;/Duration&gt;</cell></row><row><cell>&lt;/DatePeriod&gt;</cell></row><row><cell>&lt;/CreationPreferences&gt;</cell></row><row><cell>&lt;/FilteringAndSearchPreferences&gt;</cell></row><row><cell>&lt;/UserPreferences&gt;</cell></row><row><cell>Listing 3.2</cell></row></table><note><p>&lt;UserIdentifier protected="true"&gt; &lt;Name xml:lang="ca"&gt;Joan Blanc&lt;/</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>1 A list of prominent Country artists obtained using Pattern-based matching on Google (on September, 9th 2008). The results were manually analysed, and only the first page (top-10 results) was used.</figDesc><table><row><cell cols="2">Artist # occurrences</cell></row><row><cell>Garth Brooks</cell><cell>2</cell></row><row><cell>Hank Williams</cell><cell>2</cell></row><row><cell>Shania Twain</cell><cell>2</cell></row><row><cell>Johnny Cash</cell><cell>1</cell></row><row><cell>Crystal Gayle</cell><cell>1</cell></row><row><cell>Alan Jackson</cell><cell>1</cell></row><row><cell>Webb Pierce</cell><cell>1</cell></row><row><cell>Carl Smith</cell><cell>1</cell></row><row><cell>Jimmie Rodgers</cell><cell>1</cell></row><row><cell>Gary Chapman</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Tag Raw count</cell></row><row><cell>Brutal Death Metal</cell><cell>1,145</cell></row><row><cell>atainwptiosb</cell><cell>508</cell></row><row><cell>Crap</cell><cell>290</cell></row><row><cell>Pop</cell><cell>287</cell></row><row><cell>Officially Sh * t</cell><cell>248</cell></row><row><cell>Sh * t</cell><cell>143</cell></row><row><cell>Your ears will bleed</cell><cell>140</cell></row><row><cell>emo</cell><cell>120</cell></row><row><cell>whore</cell><cell>103</cell></row><row><cell>in prison</cell><cell>98</cell></row><row><cell>female vocalist</cell><cell>80</cell></row><row><cell>whore untalented</cell><cell>79</cell></row><row><cell>Best Singer in the World</cell><cell>72</cell></row><row><cell>sexy</cell><cell>50</cell></row><row><cell>the worst thing ever to happen to music</cell><cell>47</cell></row><row><cell>b * tch</cell><cell>42</cell></row><row><cell>dance</cell><cell>41</cell></row><row><cell>Guilty Pleasures</cell><cell>40</cell></row><row><cell>Death Metal</cell><cell>30</cell></row><row><cell>Female</cell><cell>29</cell></row><row><cell>Slut</cell><cell>29</cell></row></table><note><p>2 Last.fm raw tag counts for Paris Hilton artist. Accessed on May, 23rd 2007, via its API v1.0.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Tag Last.fm relevance</head><label></label><figDesc></figDesc><table><row><cell>Pop</cell></row><row><cell>Female Vocalists</cell></row><row><cell>Dance</cell></row><row><cell>American</cell></row><row><cell>Sexy</cell></row><row><cell>Brutal Death Metal</cell></row><row><cell>rnb</cell></row><row><cell>female vocalist</cell></row><row><cell>female</cell></row><row><cell>00s</cell></row><row><cell>Guilty Pleasure</cell></row><row><cell>California</cell></row><row><cell>emo</cell></row><row><cell>Crap</cell></row><row><cell>Reggae</cell></row><row><cell>awful</cell></row><row><cell>party</cell></row><row><cell>underrated</cell></row><row><cell>Best Singer in the world</cell></row><row><cell>atainwptiosb</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 . 4</head><label>34</label><figDesc>Last.fm normalised tags for Paris Hilton after doing a post-processing to clean tag spam.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 3 .</head><label>3</label><figDesc>5  A list of tools to extract audio features from the signal.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>The Dogs d'Amour Similarity Pearson The Dogs d'Amour Similarity Cond</head><label></label><figDesc>.Prob.</figDesc><table><row><cell>Los Fabulosos Cadillacs</cell><cell>0.806</cell><cell>Guns n' Roses</cell><cell>0.484</cell></row><row><cell>Electric Boys</cell><cell>0.788</cell><cell>Aerosmith</cell><cell>0.416</cell></row><row><cell>Lillian Axe</cell><cell>0.784</cell><cell>AC/DC</cell><cell>0.379</cell></row><row><cell>Michael Jackson</cell><cell>0.750</cell><cell>Led Zeppelin</cell><cell>0.360</cell></row><row><cell>Ginger</cell><cell>0.723</cell><cell>Metallica</cell><cell>0.354</cell></row><row><cell>The Decemberists</cell><cell>0.699</cell><cell>Alice Cooper</cell><cell>0.342</cell></row><row><cell>The Byrds</cell><cell>0.667</cell><cell>Mötley Crüe</cell><cell>0.341</cell></row><row><cell>Zero 7</cell><cell>0.661</cell><cell>David Bowie</cell><cell>0.335</cell></row><row><cell>Rancid</cell><cell>0.642</cell><cell>Red Hot Chili Peppers</cell><cell>0.334</cell></row><row><cell>The Sonics</cell><cell>0.629</cell><cell>The Beatles</cell><cell>0.334</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table /><note><p><p>6  </p>The Dogs d'Amour top-10 similar artists using CF with Pearson correlation distance (left) and conditional probability (right).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">The Dogs d'Amour Similarity LSA</cell></row><row><cell>d-a-d</cell><cell>0.9605</cell></row><row><cell>Mike tramp</cell><cell>0.9552</cell></row><row><cell>Metal majesty</cell><cell>0.9541</cell></row><row><cell>Nightvision</cell><cell>0.9540</cell></row><row><cell>Bulent ortacgil -sebnem ferah</cell><cell>0.9540</cell></row><row><cell>Marty casey and lovehammers</cell><cell>0.9540</cell></row><row><cell>Hey hey jump</cell><cell>0.9539</cell></row><row><cell>Camp freddy</cell><cell>0.9538</cell></row><row><cell>Hard rocket</cell><cell>0.9537</cell></row><row><cell>Paine</cell><cell>0.9536</cell></row></table><note><p><p>7  </p>The Dogs d'Amour top-10 similar artists using social tagging data from last.fm. Similarity is computed using LSA (SVD with 100 factors, and cosine distance) from the artist-tag matrix.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 3 . 8</head><label>38</label><figDesc>Similar artists for Aerosmith (left column) and Alejandro Sanz (right column).</figDesc><table><row><cell cols="2">Aerosmith Similarity CB</cell><cell cols="2">Alejandro Sanz Similarity CB</cell></row><row><cell>Bon Jovi</cell><cell>3.932</cell><cell>Ricky Martin</cell><cell>3.542</cell></row><row><cell>.38 Special</cell><cell>3.397</cell><cell>Jackson Browne</cell><cell>2.139</cell></row><row><cell>Guns N' Roses</cell><cell>3.032</cell><cell>Gipsy Kings</cell><cell>1.866</cell></row><row><cell>Def Leppard</cell><cell>2.937</cell><cell>Presuntos Implicados</cell><cell>1.781</cell></row><row><cell>Ozzy Osbourne</cell><cell>2.795</cell><cell>Emmylou Harris</cell><cell>1.723</cell></row><row><cell>Helloween</cell><cell>2.454</cell><cell>Luis Miguel</cell><cell>1.668</cell></row><row><cell>Kiss</cell><cell>2.378</cell><cell>Laura Pausini</cell><cell>1.529</cell></row><row><cell>Bryan Adams</cell><cell>2.180</cell><cell>Ry Cooder</cell><cell>1.479</cell></row><row><cell>Poison</cell><cell>2.088</cell><cell>Harry Chapin</cell><cell>1.370</cell></row><row><cell>The Damned</cell><cell>2.044</cell><cell>Dwight Yoakam</cell><cell>1.332</cell></row><row><cell>Tesla</cell><cell>2.030</cell><cell>Nek</cell><cell>1.331</cell></row><row><cell>Die Schäfer</cell><cell>1.963</cell><cell>Miguel Bosé</cell><cell>1.298</cell></row><row><cell>Mötley Crüe</cell><cell>1.949</cell><cell>Maná</cell><cell>1.241</cell></row><row><cell>Nofx</cell><cell>1.807</cell><cell>The Doobie Brothers</cell><cell>1.235</cell></row><row><cell>MXPX</cell><cell>1.733</cell><cell>Uncle Kracker</cell><cell>1.217</cell></row><row><cell>New Found Glory</cell><cell>1.718</cell><cell>Seal</cell><cell>1.184</cell></row><row><cell>Slick Shoes</cell><cell>1.677</cell><cell>Anika Moa</cell><cell>1.174</cell></row><row><cell>Die Flippers</cell><cell>1.662</cell><cell>Graham Central Station</cell><cell>1.158</cell></row><row><cell>Uriah Heep</cell><cell>1.659</cell><cell>The Imperials</cell><cell>1.157</cell></row><row><cell>Alice Cooper</cell><cell>1.608</cell><cell>The Corrs</cell><cell>1.152</cell></row></table><note><p>Presuntos Implicados, Nek, Seal, Maná, Miguel Bosé and The Corrs. His flamenco and acoustic facets are also present in the Gipsy Kings band. Luis Miguel appears in the list because of Alejandro Sanz's quiet ballads. The rest of the artists fall into the broad range of singer/songwriter, folk and Americana styles, and includes: Jackson Browne, Emmy Lou Harris, Ry Cooder, Dwight, Uncle Kracker and Harry Chapin. In this case, similarity with Alejandro Sanz is more arguably. Also, a few similar artists are female singers (Anika Moa, The Corrs, Presuntos Implicados, Emmylou</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>The Dogs d'Amour Similarity Pearson The Dogs d'Amour Similarity Hybrid</head><label></label><figDesc></figDesc><table><row><cell>Los Fabulosos Cadillacs</cell><cell>0.806</cell><cell>Electric Boys</cell><cell>0.868</cell></row><row><cell>Electric Boys</cell><cell>0.788</cell><cell>Lillian Axe</cell><cell>0.826</cell></row><row><cell>Lillian Axe</cell><cell>0.784</cell><cell>Ginger</cell><cell>0.752</cell></row><row><cell>Michael Jackson</cell><cell>0.750</cell><cell>Enuff z'nuff</cell><cell>0.732</cell></row><row><cell>Ginger</cell><cell>0.723</cell><cell>Michael Monroe</cell><cell>0.724</cell></row><row><cell>The Decemberists</cell><cell>0.699</cell><cell>Hardcore Superstar</cell><cell>0.692</cell></row><row><cell>The Byrds</cell><cell>0.667</cell><cell>Faster Pussycat</cell><cell>0.691</cell></row><row><cell>Zero 7</cell><cell>0.661</cell><cell>Firehouse</cell><cell>0.690</cell></row><row><cell>Rancid</cell><cell>0.642</cell><cell>Nashville Pussy</cell><cell>0.677</cell></row><row><cell>The Sonics</cell><cell>0.629</cell><cell>The Wildhearts</cell><cell>0.651</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 3 . 9</head><label>39</label><figDesc>The Dogs d'Amour top-10 similar artists using CF with Pearson correlation distance (left), and (right) a hybrid version using only the top-100 similar artists from CF, and reordering the artists using LSA and cosine distance from social tagging.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 4 . 1</head><label>41</label><figDesc>Top-10 popular artists in last.fm according to the total number of plays (last column). Data gathered during July, 2007.</figDesc><table><row><cell>1. The Beatles</cell><cell>(50,422,827)</cell></row><row><cell>2. Radiohead</cell><cell>(40,762,895)</cell></row><row><cell>3. System of a Down</cell><cell>(37,688,012)</cell></row><row><cell cols="2">4. Red Hot Chili Peppers (37,564,100)</cell></row><row><cell>5. Muse</cell><cell>(30,548,064)</cell></row><row><cell>6. Death Cab for Cutie</cell><cell>(29,335,085)</cell></row><row><cell>7. Pink Floyd</cell><cell>(28,081,366)</cell></row><row><cell>8. Coldplay</cell><cell>(27,120,352)</cell></row><row><cell>9. Nine Inch Nails</cell><cell>(24,095,408)</cell></row><row><cell>10. Blink 182</cell><cell>(23,330,402)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 4 .</head><label>4</label><figDesc>3), and Red Hot Chili Peppers (in Table 4.2) appear in the top-10 last.fm chart (see Table 4.1). It is worth noting that in 2006 The Beatles music collection was not (legally) available for purchase in digital</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 4 . 3</head><label>43</label><figDesc>Top-10 selling artists in 2006 (based on total album sales, last column) according to Nielsen report. The second column (values in parenthesis) shows the corresponding last.fm artist rank. form. On the other hand, last.fm listening habits denote what people listen to, and that does not necessarily correlate with the best sellers. For instance, classic bands such as Pink Floyd, Led Zeppelin (at top-15), Tool (top-16) or Nirvana (top-18) did not release any new album during 2006, but still they are in the top-20 (at mid-2007).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 4 . 4</head><label>44</label><figDesc>Increase of the Long Tail regions (in %) after 6 months (comparing two snapshots in July, 2007 and January, 2008). Beatles seed song-one gets four out of ten songs from the Beatles, plus one song from John Lennon, so it makes half of the playlist. It is worth mentioning that these recommenders use different approaches, such as: collaborative filtering, social tagging, web mining and co-occurrence analysis of playlists. To conclude this informal analysis, the most noticeable fact is that only last.fm remembers Ringo Starr!13  </figDesc><table><row><cell cols="2">Long Tail region Increase (%)</cell></row><row><cell>Head</cell><cell>61.20</cell></row><row><cell>Mid</cell><cell>62.29</cell></row><row><cell>Tail</cell><cell>62.32</cell></row></table><note><p><p>4.6 Novelty, Familiarity and Relevance</p>If you like The Beatles you might like...X. Now, ask several different people and you will get lots of different X s. Each person, according to her ties with the band's music, would be able to propose interesting, surprising or expected X s. Nonetheless, asking the same question to different recommender systems we are likely to get similar results. Indeed, two out of five tested music recommenders contain John Lennon, Paul McCartney and George Harrison in their top-10 (last.fm and the.echotron.com by The Echo Nest company). Yahoo! Music recommends John Lennon and Paul Mc-Cartney (1st and 4th position), whereas Mystrands.com only contains John Lennon (at top-10). Neither ilike nor Allmusic.com contain any of these musicians in their list of Beatles' similar artists. Furthermore, Amazon's top-30 recommendations for the Beatles' White Album is strictly made of other Beatles' albums (all of a sudden, at the fourth page of the navigation there is the first non-Beatles album; Exile on Main St. by The Rolling Stones). Finally, creating a playlist from OneLlama.comstarting with a</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 5 . 1</head><label>51</label><figDesc>Contingency table showing the categorisation of the recommended items in terms of relevant or not. Precision and recall metrics are derived from the table.</figDesc><table><row><cell></cell><cell cols="2">Relevant Not relevant</cell></row><row><cell>Recommended</cell><cell>TP</cell><cell>FP</cell></row><row><cell>Not recommended</cell><cell>FN</cell><cell>TN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 6 . 1</head><label>61</label><figDesc>Datasets for the artist similarity networks.</figDesc><table><row><cell>Last.fm social filtering (CF)</cell><cell>122,801</cell><cell>1,735,179</cell></row><row><cell>Allmusic.com expert-based (EX)</cell><cell>74,494</cell><cell>407,483</cell></row><row><cell>Content-based (CB)</cell><cell>59,583</cell><cell>1,179,743</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>power-law power-law + cut-off log-normal support</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>for</cell></row><row><cell></cell><cell>p</cell><cell>LLR</cell><cell>p x cuto f f LLR</cell><cell>p</cell><cell>power-law</cell></row><row><cell>CF</cell><cell>0.9</cell><cell cols="4">-165.48 0.00 ≈ 102 -25.15 0.00 with exp. decay cut-off</cell></row><row><cell>Expert</cell><cell>0.43</cell><cell cols="4">-41.05 0.00 ≈ 66 -5.86 0.00 moderate, with cut-off</cell></row><row><cell>CB</cell><cell>0.12</cell><cell cols="4">-905.96 0.00 ≈ 326 -99.68 0.00 moderate, with cut-off</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 6 . 3</head><label>63</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head></head><label></label><figDesc>. Listing 6.1 shows an snippet of the last.fm normalised tags for Bruce Springsteen (tag weight ranges [1..100]): Snippet of Last.fm tags for Bruce Springsteen.</figDesc><table><row><cell>Listing 6.1</cell><cell></cell><cell></cell></row><row><cell>Bruce Springsteen</cell><cell>classic rock</cell><cell>100</cell></row><row><cell>Bruce Springsteen</cell><cell>rock</cell><cell>95</cell></row><row><cell>Bruce Springsteen</cell><cell>pop</cell><cell>80</cell></row><row><cell>Bruce Springsteen</cell><cell>80s</cell><cell>72</cell></row><row><cell>Bruce Springsteen</cell><cell>classic</cell><cell>50</cell></row><row><cell>Bruce Springsteen</cell><cell>folk-rock</cell><cell>25</cell></row><row><cell>...</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 6 . 4</head><label>64</label><figDesc>Assigned genres for Bruce Springsteen from the artist's tag cloud presented in Listing 6.1.</figDesc><table><row><cell>Tag</cell><cell cols="2">Matched genre Weight</cell></row><row><cell>classic rock, rock</cell><cell>Rock</cell><cell>195</cell></row><row><cell>pop</cell><cell>Pop</cell><cell>80</cell></row><row><cell>classic</cell><cell>Classical</cell><cell>50</cell></row><row><cell>folk-rock</cell><cell>Folk</cell><cell>25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 6 . 7</head><label>67</label><figDesc>Normalised mixing matrix e CB for the audio content-based network.</figDesc><table><row><cell cols="2">Network Mixing coeff. r</cell></row><row><cell>CF</cell><cell>0.343</cell></row><row><cell>EX</cell><cell>0.411</cell></row><row><cell>CB</cell><cell>0.089</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head>Table 6 . 8</head><label>68</label><figDesc>Assortative mixing by genre coefficient r for the three networks, based on the matrices e in Tables 6.5, 6.6 and 6.7.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head>a j Head(%) Mid(%) Tail(%) CF</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>Head 45.32</cell><cell>54.68</cell><cell>0</cell></row><row><cell></cell><cell>Mid 5.43</cell><cell cols="2">71.75 22.82</cell></row><row><cell></cell><cell>Tail 0.24</cell><cell cols="2">17.16 82.60</cell></row><row><cell></cell><cell>Head 5.82</cell><cell cols="2">60.92 33.26</cell></row><row><cell>Expert</cell><cell>Mid 3.45</cell><cell cols="2">61.63 34.92</cell></row><row><cell></cell><cell>Tail 1.62</cell><cell cols="2">44.83 53.55</cell></row><row><cell></cell><cell>Head 6.46</cell><cell cols="2">64.74 28.80</cell></row><row><cell>CB</cell><cell>Mid 4.16</cell><cell cols="2">59.60 36.24</cell></row><row><cell></cell><cell>Tail 2.83</cell><cell cols="2">47.80 49.37</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head></head><label></label><figDesc>075 H , 0.512 M , 0.413 T ) (0.044 H , 0.414 M , 0.542 T ) 26 Expert 2 (0.030 H , 0.560 M , 0.410 T ) (0.027 H , 0.544 M , 0.429 T ) 8 CB 2 (0.038 H , 0.562 M , 0.400 T ) (0.037 H , 0.550 M , 0.413 T ) 7</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_32"><head>Table 6 .</head><label>6</label><figDesc>11 Top-10 artists with higher indegree (k in ) for each recommendation network. The table shows too, the artist ranking in the Long Tail.</figDesc><table><row><cell>CF</cell><cell></cell></row><row><cell>k in Artist</cell><cell>Long Tail rank</cell></row><row><cell>976 Donald Byrd</cell><cell>6,362</cell></row><row><cell>791 Little Milton</cell><cell>19,190</cell></row><row><cell>772 Rufus Thomas</cell><cell>14,007</cell></row><row><cell>755 Mccoy Tyner</cell><cell>7,700</cell></row><row><cell>755 Joe Henderson</cell><cell>8,769</cell></row><row><cell>744 R.E.M.</cell><cell>88</cell></row><row><cell>738 Wayne Shorter</cell><cell>4,576</cell></row><row><cell>717 U2</cell><cell>35</cell></row><row><cell>712 Horace Silver</cell><cell>5,751</cell></row><row><cell>709 Freddie Hubbard</cell><cell>7,579</cell></row><row><cell>Expert</cell><cell></cell></row><row><cell>k in Artist</cell><cell>Long Tail rank</cell></row><row><cell>180 R.E.M.</cell><cell>88</cell></row><row><cell>157 Radiohead</cell><cell>2</cell></row><row><cell>137 The Beatles</cell><cell>1</cell></row><row><cell>119 David Bowie</cell><cell>62</cell></row><row><cell>117 Nirvana</cell><cell>19</cell></row><row><cell>111 Tool</cell><cell>17</cell></row><row><cell>111 Pavement</cell><cell>245</cell></row><row><cell>109 Foo Fighters</cell><cell>45</cell></row><row><cell>104 Soundgarden</cell><cell>385</cell></row><row><cell>103 Weezer</cell><cell>51</cell></row><row><cell>CB</cell><cell></cell></row><row><cell>k in Artist</cell><cell>Long Tail rank</cell></row><row><cell>1,955 George Strait</cell><cell>2,632</cell></row><row><cell>1,820 Neil Diamond</cell><cell>1,974</cell></row><row><cell>1,771 Chris Ledoux</cell><cell>13,803</cell></row><row><cell>1,646 The Carpenters</cell><cell>1,624</cell></row><row><cell>1,547 Cat Stevens</cell><cell>623</cell></row><row><cell>1,514 Peter Frampton</cell><cell>4,411</cell></row><row><cell>1,504 Steely Dan</cell><cell>1,073</cell></row><row><cell>1,495 Lynyrd Skynyrd</cell><cell>668</cell></row><row><cell>1,461 Toby Keith</cell><cell>2,153</cell></row><row><cell>1,451 Charlie Daniels Band</cell><cell>22,201</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_33"><head>Number of users Number of relations</head><label></label><figDesc></figDesc><table><row><cell>Last.fm social filtering (CF)</cell><cell>158,209</cell><cell>3,164,180</cell></row><row><cell>Content-based (CB)</cell><cell>207,863</cell><cell>4,137,500</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_34"><head>Table 6 .</head><label>6</label><figDesc>12  Datasets for the user similarity networks.</figDesc><table><row><cell cols="2">Property CF (last.fm)</cell><cell>CB</cell></row><row><cell>N</cell><cell>158,209</cell><cell>207,863</cell></row><row><cell>k</cell><cell>20</cell><cell>19.90</cell></row><row><cell cols="3">SGC γ in NA (log-normal) NA (log-normal) 100% 99.97%</cell></row><row><cell cols="2">d dir ( d rand ) 9.72 (3.97)</cell><cell>7.36 (4.09)</cell></row><row><cell>D</cell><cell>12</cell><cell>10</cell></row><row><cell>r</cell><cell>0.86</cell><cell>0.17</cell></row><row><cell cols="3">C (C rand ) 0.071 (1.2 -4 ) 0.164 (9.57 -5 )</cell></row><row><cell>C(k) ∼ k -α</cell><cell>0.57</cell><cell>0.87</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_35"><head>Table 6 .</head><label>6</label><figDesc>13  User network properties for the last.fm collaborative filtering network (CF), and content-based audio filtering (CB). N is the number of nodes, and k the mean degree, d d is the avg. shortest directed path, and d r the equivalent for a random network of size N, D is the diameter of the (undirected) network. SGC is the size (percentage of nodes) of the strong giant component for the undirected network, γ in is the power-law exponent of the cumulative indegree distribution (if applicable), r is the indegree-indegree Pearson correlation coefficient (assortative mixing), C is the clustering coefficient for the undirected network, C r for the equivalent random network, and C(k) ∼ k -α is the α exponent for the clustering coefficient as a function of node degree (scaling law).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36"><head>power-law power-law + cut-off log-normal support for</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>p</cell><cell>LLR</cell><cell>p</cell><cell>LLR</cell><cell cols="2">p power-law</cell></row><row><cell>CF</cell><cell>0.00</cell><cell>-192.20</cell><cell>0.00</cell><cell cols="2">-14.41 0.00</cell><cell>none</cell></row><row><cell>CB</cell><cell>0.00</cell><cell>-836.89</cell><cell>0.00</cell><cell cols="2">-37.05 0.00</cell><cell>none</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_37"><head>Table 6 .</head><label>6</label><figDesc>14  Model selection for the indegree distribution of the two user networks.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_38"><head></head><label></label><figDesc>u i → u j Head Mid top Mid middle Mid end Tail</figDesc><table><row><cell></cell><cell>Head 9.36% 46.22% 26.66% 14.97% 2.78%</cell></row><row><cell>CF</cell><cell>Mid 1.11% 20.52% 41.96% 30.22% 6.18%</cell></row><row><cell></cell><cell>Tail 0.41% 7.23% 26.98% 42.43% 22.95%</cell></row><row><cell></cell><cell>Head 10.64% 23.70% 34.42% 25.91% 5.32%</cell></row><row><cell>CB</cell><cell>Mid 3.79% 15.43% 37.95% 34.92% 7.90%</cell></row><row><cell></cell><cell>Tail 1.92% 8.34% 26.94% 40.81% 21.98%</cell></row><row><cell>Table</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_39"><head>Table 6 .17</head><label>6</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_40"><head>Table 7 . 1</head><label>71</label><figDesc>User-centric evaluation of the novelty component for collaborative filtering (CF), Hybrid (HY), and audio content-based (CB) algorithms. Recall A&amp;S means that a participant recognises both artist and song title. Recall only A means that a participant identifies only the artist but not the song title.</figDesc><table><row><cell>Method</cell><cell>Case</cell><cell cols="2">% Avg. Rating (Stdev)</cell></row><row><cell></cell><cell cols="2">Recall A&amp;S 14.93</cell><cell>4.64(±0.67)</cell></row><row><cell>CF</cell><cell cols="2">Recall only A 12.23</cell><cell>3.88(±0.99)</cell></row><row><cell></cell><cell cols="2">Unknown 71.69</cell><cell>3.03(±1.19)</cell></row><row><cell></cell><cell cols="2">Recall A&amp;S 10.07</cell><cell>4.55(±0.81)</cell></row><row><cell>HY</cell><cell cols="2">Recall only A 10.31</cell><cell>3.67(±1.18)</cell></row><row><cell></cell><cell cols="2">Unknown 78.34</cell><cell>2.77(±1.20)</cell></row><row><cell></cell><cell cols="2">Recall A&amp;S 9.91</cell><cell>4.56(±1.21)</cell></row><row><cell>CB</cell><cell cols="2">Recall only A 7.95</cell><cell>3.61(±1.10)</cell></row><row><cell></cell><cell cols="2">Unknown 80.97</cell><cell>2.57(±1.19)</cell></row></table><note><p>7.2.2.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_41"><head>2 Novelty and Familiarity Based on Perceived Quality</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_42"><head></head><label></label><figDesc>2   Example of a media RSS feed.</figDesc><table><row><cell>&lt;description&gt;</cell></row><row><cell>Recently published media items from Ourmedia.org</cell></row><row><cell>&lt;/description&gt;</cell></row><row><cell>&lt;language&gt;en&lt;/language&gt;</cell></row><row><cell>&lt;item&gt;</cell></row><row><cell>&lt;title&gt;Fanky beats&lt;/title&gt;</cell></row><row><cell>&lt;link&gt;http://www.ourmedia.org/node/...&lt;/link&gt;</cell></row><row><cell>&lt;description&gt;Rock music with a funky beat and electric lead</cell></row><row><cell>guitar riffs (...)&lt;/description&gt;</cell></row><row><cell>&lt;pubDate&gt;Mon, 17 Apr 2007 01:35:49 -0500&lt;/pubDate&gt;</cell></row><row><cell>&lt;dc:creator&gt;John Brettbutter&lt;/dc:creator&gt;</cell></row><row><cell>&lt;category domain="urn:ourmedia:term:35"&gt;</cell></row><row><cell>Alternative Rock</cell></row><row><cell>&lt;/category&gt;</cell></row><row><cell>&lt;category domain="urn:ourmedia:term:582"&gt;funk&lt;/category&gt;</cell></row><row><cell>&lt;category domain="urn:ourmedia:term:727"&gt;guitar&lt;/category&gt;</cell></row><row><cell>&lt;enclosure url="http://archive.org/.../file.mp3"</cell></row><row><cell>length="3234212" type="application/octet-stream" /&gt;</cell></row><row><cell>&lt;/item&gt;</cell></row><row><cell>&lt;item&gt;</cell></row><row><cell>&lt;title&gt;Another item&lt;/title&gt;</cell></row><row><cell>...</cell></row><row><cell>&lt;/item&gt;</cell></row><row><cell>&lt;/channel&gt;</cell></row><row><cell>&lt;/rss&gt;</cell></row><row><cell>Listing 8.1</cell></row><row><cell>&lt;rss version="2.0"</cell></row><row><cell>xml:base="http://www.ourmedia.org"</cell></row><row><cell>xmlns:media="http://search.yahoo.com/mrss"</cell></row><row><cell>xmlns:dc="http://purl.org/dc/elements/1.1/"</cell></row><row><cell>&gt;</cell></row><row><cell>&lt;channel&gt;</cell></row><row><cell>&lt;title&gt;Example of a mRSS feed&lt;/title&gt;</cell></row><row><cell>&lt;link&gt;http://www.ourmedia.org/user/45801&lt;/link&gt;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_43"><head>Table 8 . 1</head><label>81</label><figDesc>Information gathered from music related RSS feeds is stored into a relational database.</figDesc><table><row><cell>Source</cell><cell cols="2"># RSS seed feeds # Items stored</cell></row><row><cell>New releases</cell><cell>44</cell><cell>1,283,640</cell></row><row><cell>MP3 blogs</cell><cell>127</cell><cell>991,997</cell></row><row><cell>Podcasts</cell><cell>833</cell><cell>288,992</cell></row><row><cell>Album reviews</cell><cell>18</cell><cell>206,265</cell></row><row><cell>Upcoming concerts</cell><cell>16</cell><cell>369,651</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_44"><head></head><label></label><figDesc>is a novel exam-</figDesc><table><row><cell>Index</cell><cell></cell></row><row><cell>acoustic metadata, 63</cell><cell>Earth mover's distance, 75</cell></row><row><cell>Amazon, 3, 5, 177</cell><cell>editorial metadata, 55</cell></row><row><cell>Analysis of variance, 163</cell><cell>Euclidean distance, 28, 77</cell></row><row><cell>audio crawler, 173</cell><cell>evaluation, 109</cell></row><row><cell>audio features, 63</cell><cell>A/B testing, 125</cell></row><row><cell></cell><cell>network-centric, 116, 129</cell></row><row><cell>Chebychev distance, 28 chroma distribution, 66 cold-start problem, 27, 36 Collaborative filtering, 23, 70</cell><cell>survey, 157 system-centric, 110 user-centric, 123, 157 explicit feedback, 21, 70</cell></row><row><cell>item-based, 24 Limitations, 26 user-based, 25 collaborative tagging, 31</cell><cell>familiarity, 101, 162 folksonomy, 31 Friend of a Friend, 51, 175</cell></row><row><cell>complex network analysis, 116, 132, 148 assortative mixing, 119, 135, 150 average shortest path, 117</cell><cell>Gaussian distribution, 75 Gaussian mixture model, 64, 75</cell></row><row><cell>centrality, 121 clustering, 120 degree distribution, 118 Limitations, 122</cell><cell>harmony, 66 High Order Singular Value Decomposition, 32 hybrid recommendation, 34, 78</cell></row><row><cell>small world, 132 strong giant component, 118 Conditional probability, 25 Content-based filtering, 28, 75</cell><cell>implicit feedback, 21, 70 instrumentation, 65 iTunes, 177</cell></row><row><cell>Limitations, 29 Context-based filtering, 30 Limitations, 34</cell><cell>Kruskal-Wallis one-way ANOVA, 163 Kullback-Leibler divergence, 75</cell></row><row><cell>Cosine distance, 24, 74 cultural metadata, 56</cell><cell>last.fm, 3, 90, 130 dataset, 71, 158</cell></row><row><cell></cell><cell>Latent Semantic Analysis, 33, 74</cell></row><row><cell>Decision-based metrics, 111</cell><cell>log-normal distribution, 98</cell></row><row><cell>precision, recall, F-measure, 112</cell><cell>Long Tail, 4, 6, 7, 87</cell></row><row><cell>Receiver Operating Characteristic curve</cell><cell>definition, 93</cell></row><row><cell>(ROC), 113</cell><cell>distribution, 97</cell></row><row><cell>Demographic filtering, 22</cell><cell>dynamics, 100</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.myspace.com/tylaandthedogsdamour</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>http://glinden.blogspot.com/2007/05/google-news-personalizationpaper.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>  4  The goal was to reduce by 10% the Root mean squared error (RMSE) of the predicted movie</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>ratings 5 http://www2.research.att.com/ ˜volinsky/netflix</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>/bpc.html 6 http://www.the-ensemble.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>From now on, considered as a proper noun with capitalised letters</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>http://echonest.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7"><p>http://bmat.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8"><p>http://www.amazon.com/Beatles-White-Album/dp/B000002UAX, accessed on October, 9th, 2008</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p>Ò. Celma, Music Recommendation and Discovery,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_10"><p>DOI 10.1007/978-3-642-13287-2 2, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_11"><p>The Recommendation Problem</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_12"><p>Specially when the user creates an account to a recommender system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_13"><p>A de-facto standard, in the Semantic Web community, is the Friend of a Friend initiative (FOAF). FOAF provides conventions and a language "to tell" a machine the sort of things that a user says about herself. This approach is the one been used in our prototype, presented in Chap. 8</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_14"><p>http://www.apml.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_15"><p>Generated via http://TasteBroker.org, accessed on January, 10th 2008</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_16"><p>http://research.sun.com:8080/AttentionProfile/apml/last.fm/ocelma, accessed on January, 10th 2008</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_17"><p>http://www.jonasbrothers.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_18"><p>DOI 10.1007/978-3-642-13287-2 3, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_19"><p>http://www.apple.com/itunes</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_20"><p>http://ax.itunes.apple.com/rss, accessed April, 17th 2009</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_21"><p>For example music that comes from the Playdar music content resolver service http://www. playdar.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_22"><p>Nowadays, it is very common to embed to a webpage a small widget that displays the most recent tracks a user has played.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_23"><p>http://www.w3.org/TR/owl-features/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_24"><p>Music Recommendation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_25"><p>The query was performed on September, 9th 2008, using Google search engine. The results were manually analysed, and only the first page (top-10 results) was used.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_26"><p>http://www.last.fm/music/Paris+Hilton</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_27"><p>http://blogs.sun.com/plamere/entry/the_1_brutal_death_metal</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_28"><p>Screenshot taken on May, 23rd 2007</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_29"><p>Acronym of all things annoying in the world put together into one stupid b*tch</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_30"><p>http://www.indiscover.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_31"><p>http://www.musicbrainz.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_32"><p>http://en.wikipedia.org/wiki/The_Dogs_D'Amour</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_33"><p>http://www.pandora.com/corporate/index.shtml Last accessed date: September 10th, 2008</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_34"><p>  18  Personal communication with Pandora staff, on July 2007, while preparing the Music Recommendation Tutorial for the 2007 ISMIR conference.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_35"><p>For more information about the band see http://en.wikipedia.org/wiki/Aerosmith</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_36"><p>For more information about the artist see http://en.wikipedia.org/wiki/Alejandro _Sanz</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_37"><p>After some inspection, and according to the author's knowledge of The Dogs d'Amour band, the hybrid approach produces much better results than both LSA from social tagging and Pearson CF alone.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_38"><p>DOI 10.1007/978-3-642-13287-2 4, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_39"><p>http://www.myspace.com/thomasaussenac</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_40"><p>http://www.last.fm/music/thomas+aussenac</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_41"><p>http://www.myspace.com/michaelimhof</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_42"><p>http://www.myspace.com/curtisyoungofficial</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_43"><p>Such as http://www.somanymp3s.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_44"><p>The Long Tail in Recommender Systems</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_45"><p>From http://longtail.typepad.com/the_long_tail/2005/01/definitions _fin.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_46"><p>See Tom Slee critical reader's companion to "The Long Tail" book at http://whimsley.typepad.com/whimsley/2007/03/the_long_tail_l.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_47"><p>To solve the non-linear least squares we use the R statistical package. The code is available at http://mtg.upf.edu/ ˜ocelma/PhD</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_48"><p>See http://shirky.com/writings/powerlaw_weblog.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_49"><p>This is the only case where Anderson's Long Tail theory can be applied.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_50"><p>In Rainbows album was released on October 10th, 2007</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_51"><p>Last.fm has the "hype artist" weekly chart, http://www.last.fm/charts/hypeartist, a good source to track the movements in the Long Tail curve.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_52"><p>This informal analysis was done in July, 2007.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_53"><p>http://wordnet.princeton.edu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_54"><p>DOI 10.1007/978-3-642-13287-2 5, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_55"><p>Evaluation Metrics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_56"><p>http://glinden.blogspot.com/2006/04/early-amazon-shopping-cart.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_57"><p>DOI 10.1007/978-3-642-13287-2 6, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_58"><p>http://www.audioscrobbler.net/data/webservices/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_59"><p>http://www.allmusic.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_60"><p>Network-Centric Evaluation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_61"><p>Not to be confused with the Log-likelihood ratio (LLR), that we use to compare two distributions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_62"><p>DOI 10.1007/978-3-642-13287-2 7, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_63"><p>See for example http://www.last.fm/music/U2/_/One/+similar</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_64"><p>User-Centric Evaluation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_65"><p>Message sent to music-ir@listes.ircam.fr on February, 28th, 2008</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_66"><p>http://blogs.sun.com/plamere/entry/evaluating_music_recommendations</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_67"><p>DOI 10.1007/978-3-642-13287-2 8, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_68"><p>Applications</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_69"><p>http://search.yahoo.com/mrss/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_70"><p>Adapted from a real example published in OurMedia website. http://www.ourmedia.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_71"><p>http://www.foaf-project.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_72"><p>http://www.w3.org/RDF</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_73"><p>http://web.resource.org/rss/1.0/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_74"><p>http://trust.mindswap.org/FilmTrust</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_75"><p>http://www.rollingstone.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_76"><p>http://www.bbc.co.uk/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_77"><p>http://www.nytimes.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_78"><p>http://www.75orless.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_79"><p>http://www.w3.org/TR/owl-guide/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_80"><p>http://www.w3.org/TR/rdf-schema/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_81"><p>http://foafing-the-music.iua.upf.edu/music-ontology#</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_82"><p>http://www.xspf.org/. XSPF is a playlist format based on XML syntax</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_83"><p>See http://linkeddata.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_84"><p>DOI 10.1007/978-3-642-13287-2 9, c Springer-Verlag Berlin Heidelberg 2010</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_85"><p>Conclusions and Further Research</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_86"><p>See http://linkeddata.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_87"><p>DOI 10.1007/978-3-642-13287-2, c Springer-Verlag Berlin Heidelberg 2010</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>http://scholar.google.com that contain "music recommendation" or "music recommender" in the title of the article. Accessed on Feburary 3rd, 2010 2 http://www.ismir.net/ Name Language Link MA Toolbox Matlab http://www.ofai.at/ ˜elias.pampalk/ma/ MIR Toolbox Matlab http://users.jyu.fi/ ˜lartillo/ Marsyas C++ http://marsyas.info/ CLAM C++ http://clam-project.org/ SMIRK ChucK http://smirk.cs.princeton.edu/ Echo nest Web API http://developer.echonest.com/pages/overview</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network-Centric Evaluation</head><p>In this chapter we present the network-centric evaluation approach. This method analyses the similarity network, created using any recommendation algorithm. Network-centric evaluation uses complex networks analysis to characterise the item collection. Also, we can combine the results from the network analysis with the popularity of the items, using the Long Tail model.</p><p>We perform several experiments in the music recommendation field. The first experiment aims at evaluating the popularity effect using three music artists recommendation approaches: collaborative filtering (CF), content-based audio similarity (CB), and human expert-based resemblance. The second experiment compare two user networks created by CF and CB derived from the users' listening habits. In all the three experiments, we measure the popularity effect by contrasting the properties from the network with the Long Tail information (e.g. are the hubs in the recommendation network the most popular items? Or, are the most popular items connected with other popular items?). Once each item in the recommendation network is located in the head, mid, or tail part (see Sec. 4.3.2), the next step is to combine the similarity network with the Long Tail information. Two main analysis are performed: first, we measure the similarity among the items in each part of the curve. That is, for each item that belongs to the head part, compute the percentage of similar items that are located in the head, mid and tail part (similarly, for the items in the mid and tail part). This measures whether the most popular items are connected with other popular items, and vice versa. Second, we measure the correlation between an item's rank in the tags they apply the most. The EX and CB networks have more country artists than the CF network artists. Also, in the expert network there is a lot of jazz artists. Additionally, in the three networks there is an underrepresentation of the classical, folk and soul artists. The reality is that a recommender system has to deal with biased collections, and make the best out of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Network Analysis and the Long Tail Model</head><p>In terms of genre cohesion, classical is always "misclassified" as pop/rock. In our case, the problem with the classical genre is that some non-classical music artists are tagged as classic. Our algorithm matches this tag with the seed genre Classical (see the Bruce Springsteen example in Table <ref type="table">6</ref>.4). Actually, if we remove the classical genre from the list of 13 genres, the r correlation coefficient increases by 0.1, in the CF and EX networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 9</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions and Further Research</head><p>Research in recommender systems is multidisciplinary. It includes several areas, such as: search and filtering, data mining, personalisation, social networks, text processing, complex networks, user interaction, information visualisation, signal processing, and domain specific models, among others. Furthermore, current research in recommender systems has strong industry impact, resulting in many practical applications.</p><p>We have an overwhelming number of choices about which music to listen to. As stated in The Paradox of Choice <ref type="bibr">[1]</ref>, we-as consumers-often become paralysed and doubtful when facing the overwhelming number of choices. The main problem is the awareness of content, not the actual access to the content (think on Spotify or YouTube services, for example). Personalised filters and recommender systems are key elements in this scenario. Effective recommendation systems should promote novel and relevant material (non-obvious recommendations), taken primarily from the tail of the music popularity distribution.</p><p>One of the main goals in this book is music discovery via the functionality that recommender systems offer. In this sense, novelty and relevance of the recommendations are the two most important aspects. We make use of the Long Tail shape to model the popularity bias that exists in any recommender system, and use this data to recommend unknown items, hidden in the tail of the popularity curve. Our experience is that using the F(x) function (see Chap. 4) to model the Long Tail curve, we get more accurate results than fitting the curve to well-known distributions, such as a power-law or log-normal <ref type="bibr">[2]</ref>.</p><p>Music is somewhat different from other entertainment domains, such as movies or books. Tracking users' preferences is mostly done implicitly, via their listening habits (instead of asking users to explicitly rate the items). Any user can consume an item (e.g., a track or a playlist) several times, even repeatedly and continuously. Regarding the evaluation process, music recommendation allows users instant feedback via brief audio excerpts. Thus, we have proposed new approaches to evaluate the effectiveness of the recommendations in the music domain. The evaluation focuses on the central pillar of any recommender system: the similarity among objects (e.g. items or users). In our case, we evaluate and analyse the artist and user ple of a system that gives transparent explanations about the provided recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Outlook</head><p>We are witnessing an explosion of practical applications coming from Music Information Retrieval research field: music identification systems, music recommenders and playlist generators, music search engines, extraction of semantic audio features, autotagging, and this is just the beginning.</p><p>A few years ago, music was a key factor in taking the Internet from its textcentered origins to being a complete multimedia environment. Music might do the same for the next web generation. The "Celestial Jukebox" is about to become a reality. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">155</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">1 Links with the Following Chapters . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">156</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">156</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">User-Centric Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">157</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">1 Music Recommendation Survey . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157 7.1.1 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">157</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158 7.1.3 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">159</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 7.2.1 Demographic Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">160</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2 Quality of the Recommendations . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">165</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">4 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">166</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">169</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Music Discovery in the Long Tail . . . . . . . . . . . . . . . . 169 8.1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">169</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2 Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171 8.1.3 System Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172 8.1.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">175</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">FOAFing the Music: Music Recommendation in the Long Tail</title>
		<imprint>
			<biblScope unit="page">175</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">175</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2.2 Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 8.2.3 System Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177 8.2.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">182</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184 Conclusions and Further Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">185</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Book Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186 9.1.1 Scientific Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">186</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2 Industrial Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">188</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2 Limitations and Further Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189 9.2.1 Dynamic Versus Static Data . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">189</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2 Domain Specific . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">189</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2.3 User Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">190</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2.4 User Understanding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<date>190</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">2.5 Recommendations with No Explanation . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">190</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">3 Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">191</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">191</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<biblScope unit="page">193</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Social information filtering for music recommendation</title>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-09">September 1994</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Massachussets Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Content-based playlist generation: Exploratory experiments</title>
		<author>
			<persName><forename type="first">B</forename><surname>Logan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Music Information Retrieval</title>
		<meeting>3rd International Conference on Music Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Music recommendation from song sets</title>
		<author>
			<persName><forename type="first">B</forename><surname>Logan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using user models in music information retrieval systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vercoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1st International Conference on Music Information Retrieval</title>
		<meeting>1st International Conference on Music Information Retrieval<address><addrLine>Plymouth, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A review of factors affecting music recommender success</title>
		<author>
			<persName><forename type="first">A</forename><surname>Uitdenbogerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Schnydel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Music Information Retrieval</title>
		<meeting>3rd International Conference on Music Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Foafing the music: A music recommendation system based on RSS feeds and user preferences</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Music Information Retrieval</title>
		<meeting>6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visual playlist generation on the artist map</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Gulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vignoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Music Information Retrieval</title>
		<meeting>6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="520" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Musicsun: A new approach to artist recommendation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pampalk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pats: Realization and user evaluation of an automatic playlist generator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pauws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eggen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Music Information Retrieval</title>
		<meeting>3rd International Conference on Music Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic playlist generation based on skipping behavior</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pampalk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pohle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Music Information Retrieval</title>
		<meeting>6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An implementation of a simple playlist generator based on audio similarity measures and user feedback</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pampalk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="389" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">User evaluation of a new interactive playlist generation concept</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pauws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van De Wijdeven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Music Information Retrieval</title>
		<meeting>6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="638" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Papa: Physiology and purpose-aware automatic playlist generation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kregor-Stickles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="250" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Development of an automatic music selection system based on Runner&apos;s step frequency</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niitsuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takaesu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Demachi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania in USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="193" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Playlist generation using start and end songs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Arthur Flexer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schnitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania in USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="219" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Steerable playlist generation by learning song similarity from radio station playlists</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Francois Maillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="345" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Evaluating and analysing dynamic playlist generation heuristics using radio logs and fuzzy set theory</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bosteels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pampalk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Kerre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Uncovering affinity of artists to multiple genres from social behaviour data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baccigalupo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donaldson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania in USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="275" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ternary Semantic Analysis of Social Tags for Personalized Music Recommendation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Symeonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruxanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="219" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Music recommendation mapping and interface based on structural network entropy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Donaldson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="811" to="817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Virtual communities for creating shared music channels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anglade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tiemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vignoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Social playlists and bottleneck measurements: Exploiting musician social graphs using content-based dissimilarity and pairwise maximum flow values</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rhodes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Casey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania in USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="559" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Browsing music recommendation networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Klaus Seyerlehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="129" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Heterogeneous embedding for subjective artist similarity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcfee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="513" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Towards ensemble learning for hybrid music recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tiemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pauws</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Vienna, Austria</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Hybrid collaborative and content-based music recommendation using probabilistic model with latent user preferences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Komatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="296" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Improving efficiency and scalability of model-based music recommender system based on incremental training</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Komatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A comparison of signal-based music recommendation to genre labels, collaborative filtering, musicological analysis, human recommendation, and random baseline</title>
		<author>
			<persName><forename type="first">T</forename><surname>Magno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sable</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="161" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Continuous PLSI and smoothing techniques for hybrid music recommendation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="339" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">More of an Art than a Science: Supporting the creation of playlists and mixes</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Falconer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="240" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Sociology and music recommendation systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Extending content-based recommendation: The case of Indian classical music</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania in USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="571" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Exploring social music behavior: An investigation of music selection at parties</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="747" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Smarter than genius? Human evaluation of music recommender systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Barrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="357" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Music recommendation tutorial</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Exploiting recommended usage metadata: Exploratory analyses</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Downie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Ehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Fast generation of optimal music playlists using local search</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pauws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Verhaegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="138" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Why the future of business is selling less of more</title>
		<author>
			<persName><forename type="first">C</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Hyperion</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>The Long Tail</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">State of the industry</title>
		<author>
			<persName><forename type="first">N</forename><surname>Soundscan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nielsen Soundscan Report. National Association of Recording Merchandisers</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">The Paradox of Choice: Why More Is Less</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-01">January 2005</date>
			<publisher>Harper Perennial</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 10th International Conference on World Wide Web</title>
		<meeting>10th International Conference on World Wide Web<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
	<note>in WWW&apos;01</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Evaluating collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="53" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A taxonomy of recommender agents on the internet</title>
		<author>
			<persName><forename type="first">M</forename><surname>Montaner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>De La Rosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="285" to="330" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Recommending and evaluating choices in a virtual community of use</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="194" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Rate it again: Increasing recommendation accuracy by user re-rating</title>
		<author>
			<persName><forename type="first">X</forename><surname>Amatriain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tintarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Recommender Systems</title>
		<meeting>the ACM Conference on Recommender Systems<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Feature based modelling: A methodology for producing coherent, consistent, dynamically changing models of agents&apos; competencies</title>
		<author>
			<persName><forename type="first">G</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuzmycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="150" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Group recommender systems: A critiquing based approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salamó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Coyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mcginty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Intelligent User Interfaces</title>
		<meeting>the 11th International Conference on Intelligent User Interfaces<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="267" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A group recommendation system with consideration of interactions among group members</title>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2082" to="2090" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">User modeling via stereotypes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="329" to="354" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A framework for collaborative, content-based and demographic filtering</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="393" to="408" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Collaborative filtering to weave and information tapestry</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Oki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="1992-12">December 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Social information filtering for music recommendation</title>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-09">September 1994</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Massachussets Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Social information filtering: Algorithms for automating &quot;word of mouth</title>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Grouplens: An open architecture for collaborative filtering of netnews</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Iacovou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bergstorm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work</title>
		<meeting>ACM 1994 Conference on Computer Supported Cooperative Work<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Recommender systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Varian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="56" to="58" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Combining content-based and collaborative filters in an online newspaper</title>
		<author>
			<persName><forename type="first">M</forename><surname>Claypool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gokhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Murnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR Workshop on Recommender Systems</title>
		<meeting>ACM SIGIR Workshop on Recommender Systems<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Recommender systems for evaluating computer messages</title>
		<author>
			<persName><forename type="first">C</forename><surname>Avery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zeckhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="88" to="89" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Experimental study of inequality and unpredictability in an artificial cultural market</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Salganik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">311</biblScope>
			<biblScope unit="page" from="854" to="856" />
			<date type="published" when="2006-02">February 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Towards a better understanding of context and context-awareness</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Abowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Steggles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Symposium on Handheld and Ubiquitous Computing</title>
		<meeting>the 1st International Symposium on Handheld and Ubiquitous Computing<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="304" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Web mining research: A survey</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kosala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Blockeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD Explorations</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Automatic personalization based on web usage mining</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cooley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="142" to="151" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Introduction to Modern Information Retrieval</title>
		<author>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>McGraw-Hill, Inc</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Collaborative tagging in recommender systems</title>
		<author>
			<persName><forename type="first">A.-T</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australian Conference on Artificial Intelligence</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4830</biblScope>
			<biblScope unit="page" from="377" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Tag-aware recommender systems by fusion of collaborative filtering algorithms</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H L</forename><surname>Tso-Sutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Marinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Applied Computing</title>
		<meeting>the ACM Symposium on Applied Computing<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1995" to="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A semantic space for music derived from social tags</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Ternary semantic analysis of social tags for personalized music recommendation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Symeonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruxanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 9th International Conference on Music Information Retrieval</title>
		<meeting>9th International Conference on Music Information Retrieval<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Cubic analysis of social bookmarking for personalized recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers of WWW Research and Development</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="733" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Hybrid recommender systems: Survey and experiments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="331" to="370" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Being accurate is not enough: How accuracy metrics have hurt recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Human Interaction. Human Factors in Computing Systems</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1097" to="1101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Beyond algorithms: An HCI perspective on recommender systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Swearingen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR. Workshop on Recommender Systems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="393" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">The role of transparency in recommender systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swearingen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI -Extended Abstracts on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="830" to="831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Explaining collaborative filtering recommendations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Supported Cooperative Work</title>
		<meeting>the ACM Conference on Computer Supported Cooperative Work<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Effective explanations of recommendations: User-centered design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tintarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Recommender Systems</title>
		<meeting>the ACM Conference on Recommender Systems<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="153" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Pointing the way: Active collaborative filtering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ehrlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="202" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Positive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paatero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Tapper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmetrics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="126" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999-10">October 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Investigation of various matrix factorization methods for large recommender systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Takács</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pilászy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Németh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tikk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd KDD Workshop on Large Scale Recommender Systems and the Netflix Prize Competition</title>
		<meeting>the 2nd KDD Workshop on Large Scale Recommender Systems and the Netflix Prize Competition<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Trust in recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>O'donovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Intelligent User Interfaces</title>
		<meeting>the 10th International Conference on Intelligent User Interfaces<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Using trust in recommender systems: An experimental analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of iTrust International Conference</title>
		<meeting>iTrust International Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="221" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Trust-aware recommender systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Avesani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Recommender Systems</title>
		<meeting>the ACM Conference on Recommender Systems<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Preventing shilling attacks in online recommender systems</title>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Chirita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zamfir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Annual ACM International Workshop on Web Information and Data Management</title>
		<meeting>the 7th Annual ACM International Workshop on Web Information and Data Management<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">An MDP-based recommender system</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Brafman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="453" to="460" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Poolcasting: a social web radio architecture for group customisation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baccigalupo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution AXMEDIS</title>
		<meeting>the 3rd International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution AXMEDIS</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Flytrap: Intelligent group music recommendation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Crossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Budzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Hammond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Intelligent User Interfaces</title>
		<meeting>the 7th International Conference on Intelligent User Interfaces<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="184" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">More of an art than a science: Supporting the creation of playlists and mixes</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Falconer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="240" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">The serendipity shuffle</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vetere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 19th Conference of the Computer-Human Interaction Special Interest Group</title>
		<meeting>19th Conference of the Computer-Human Interaction Special Interest Group<address><addrLine>Narrabundah, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">A review of factors affecting music recommender success</title>
		<author>
			<persName><forename type="first">A</forename><surname>Uitdenbogerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Schnydel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Music Information Retrieval</title>
		<meeting>3rd International Conference on Music Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">Net, Blogs and Rock &apos;n&apos; Roll: How Digital Discovery Works and What it Means for Consumers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jennings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Nicholas Brealey Publishing</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">A user-oriented approach to music information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lesaffre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Content-Based Retrieval</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">A music retrieval system based on user driven similarity and its evaluation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vignoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pauws</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Music Information Retrieval</title>
		<meeting>the 6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="272" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Evaluation of modeling music similarity perception via feature subset selection</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Sotiropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Lampropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Tsihrintzis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">User Modeling</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4511</biblScope>
			<biblScope unit="page" from="288" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Good vibrations: Music discovery through personal musical concepts</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sandvold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aussenac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Recommendation framework for online social networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kazienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Web Intelligence and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Bluetuna: Let your neighbour know what music you like</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bassoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wisniowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI -extended abstracts on Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1941" to="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">The benefit of using tag-based profiles</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Firan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Latin American Web Conference (LA-WEB)</title>
		<meeting>the 2007 Latin American Web Conference (LA-WEB)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="32" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">The sensitivities of user profile information in music recommender systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Ruyter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Markopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eggen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Private, Security, Trust</title>
		<meeting>Private, Security, Trust<address><addrLine>New Brunswick, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Using user models in music information retrieval systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vercoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1st International Conference on Music Information Retrieval</title>
		<meeting>1st International Conference on Music Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Salembier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<title level="m">Introduction to MPEG 7: Multimedia Content Description Language</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Semantic user preference descriptions inMPEG-7/21</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tsinaraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christodoulakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hellenic Data Management Symposium</title>
		<meeting><address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">The music ontology</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Raimond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giasson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Management and Musical Metadata. Idea Group</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Inferring descriptions and similarity for music from community metadata</title>
		<author>
			<persName><forename type="first">B</forename><surname>Whitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Computer Music Conference</title>
		<meeting>International Computer Music Conference<address><addrLine>Goteborg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Towards an automatically generated music information system via web content mining</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pohle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th European Conference on Information Retrieval (ECIR&apos;08)</title>
		<meeting>the 30th European Conference on Information Retrieval (ECIR&apos;08)<address><addrLine>Glasgow, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">A deeper look into web-based classification of music artists</title>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pohle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2nd Workshop on Learning the Semantics of Audio Signals</title>
		<meeting>2nd Workshop on Learning the Semantics of Audio Signals<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Semantic rank reduction of music audio</title>
		<author>
			<persName><forename type="first">B</forename><surname>Whitman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</title>
		<meeting>the Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)<address><addrLine>New paltz, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="135" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Enhancing music recommendation algorithms using cultural metadata</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hummel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of New Music Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Web-based artist categorization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Geleijnse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Korst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Music Information Retrieval</title>
		<meeting>the 7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="266" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Web services for music information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zadel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fujinaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">A web-based approach to assessing artist similarity using co-occurrences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 4th International Workshop on Content-Based Multimedia Indexing</title>
		<meeting>4th International Workshop on Content-Based Multimedia Indexing<address><addrLine>Riga, Latvia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Improving prototypical artist detection by penalizing exorbitant popularity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Symposium on Computer Music Modeling and Retrieval</title>
		<meeting>3rd International Symposium on Computer Music Modeling and Retrieval<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="196" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Building an interactive next-generation artist recommender based on automatically derived high-level concepts</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pohle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Content-Based Multimedia Indexing</title>
		<meeting>the 5th International Workshop on Content-Based Multimedia Indexing<address><addrLine>Bordeaux, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Uncovering affinity of artists to multiple genres from social behaviour data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baccigalupo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donaldson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="275" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Musical data mining for electronic music distribution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Laigre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1st International Conference on Web Delivering of Music</title>
		<meeting>1st International Conference on Web Delivering of Music</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">The quest for ground truth in musical artist similarity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Whitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berenzweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Symposium on Music Information Retrieval</title>
		<meeting>3rd International Symposium on Music Information Retrieval<address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="170" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">The quest for ground truth in musical artist tagging in the social web era</title>
		<author>
			<persName><forename type="first">G</forename><surname>Geleijnse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">A large-scale evalutation of acoustic and subjective music similarity measures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berenzweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Whitman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 4th International Symposium on Music Information Retrieval</title>
		<meeting>4th International Symposium on Music Information Retrieval<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Five approaches to collecting tags for music</title>
		<author>
			<persName><forename type="first">D</forename><surname>Turnbull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Music Information Retrieval, (Philadelphia, PA)</title>
		<meeting>the 9th International Conference on Music Information Retrieval, (Philadelphia, PA)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="225" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Combating spam in tagging systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koutrika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Effendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gyöngyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international workshop on Adversarial information retrieval on the web</title>
		<meeting>the 3rd international workshop on Adversarial information retrieval on the web<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Juang</surname></persName>
		</author>
		<title level="m">Fundamentals of Speech Recognition</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">A scale-free distribution of false positives for a large class of audio similarity measures</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Aucouturier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="272" to="284" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Improving timbre similarity: How high&apos;s the sky</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Aucouturier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Negative Results in Speech and Audio Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Percussion-related semantic descriptors of music audio files</title>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sandvold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gouyon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 25th International AES Conference</title>
		<meeting>25th International AES Conference<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Automatic drum sound description for real-world music using template adaptation and matching methods</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Musical instrument identification using LSF and Kmeans</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chetry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 118th Convention of the AES</title>
		<meeting>the 118th Convention of the AES<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">A review of automatic rhythm description systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gouyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Music Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="34" to="54" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Phase-based note onset detection for music signals</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE ICASSP</title>
		<meeting>IEEE ICASSP<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">On the use of phase and energy for musical onset detection in the complex domain</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Duxbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="page" from="533" to="556" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Causal tempo tracking of audio</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E P</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Plumbley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Dance music classification: A tempo-based approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gouyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Towards characterization of music via rhythmic patterns</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gouyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Toward automated holistic beat tracking, music analysis, and understanding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dannenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Music Information Retrieval</title>
		<meeting>6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Polyphonic score retrieval using polyphonic audio queries: A harmonic modelling approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pickens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dovey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Music Information Retrieval</title>
		<meeting>3rd International Conference on Music Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Tonal description of polyphonic audio for music content processing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS Journal on Computing, Special Cluster on Computation in Music</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Estimating the tonality of polyphonic audio files: Cognitive versus machine learning modelling strategies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Automatic chord identification using a quantised chromagram</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Harte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 118th Convention of the AES</title>
		<meeting>the 118th Convention of the AES<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">A robust mid-level representation for harmonic content in music signals</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pickens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th International Conference on Music Information Retrieval</title>
		<meeting>6th International Conference on Music Information Retrieval<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<title level="m" type="main">Tonal Description of Music Audio Signals</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gómez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Barcelona, Spain</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universitat Pompeu Febra</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Semantic segmentation of music audio contents</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Computer Music Conference</title>
		<meeting>International Computer Music Conference<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Extracting automatically the perceived intensity of music titles</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zils</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Digital Audio Effects</title>
		<meeting>the 6th International Conference on Digital Audio Effects<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Towards a semantic descriptor of subjective intensity in music</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sandvold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Browsing music spaces: Categories and the musical mind</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fabbri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IASPM Conference</title>
		<meeting>the IASPM Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Intepreting Popular Music</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brackett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Canbridge University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Musical genre classification: Is it worth pursuing and how can it be improved?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mckay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fujinaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Music Information Retrieval</title>
		<meeting>the 7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Musical genre classification of audio signals</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tzanetakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="293" to="302" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<title level="m" type="main">Audio content processing for automatic music genre classification: descriptors, databases, and classifiers</title>
		<author>
			<persName><forename type="first">E</forename><surname>Guaus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Expression, perception, and induction of musical emotions: A review and a questionnaire study of everyday listening</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Laukka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of New Music Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="217" to="238" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sloboda</surname></persName>
		</author>
		<title level="m">Music and Emotion: Theory and Research</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Music information retrieval by detecting mood via computational media aesthetics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WI &apos;03: Proceedings of the 2003 IEEE/WIC International Conference on Web Intelligence</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">235</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Automatic mood detection and tracking of music audio signals</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="5" to="18" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Exploring relationships between audio features and emotion in music</title>
		<author>
			<persName><forename type="first">C</forename><surname>Laurier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lartillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eerola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Toiviainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of European Society for the Cognitive Sciences of Music</title>
		<meeting><address><addrLine>Jyväskylä, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Music mood and theme classification a hybrid approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bischoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Firan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laurier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sordo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Music Information Retrieval</title>
		<meeting>the 10th Conference on Music Information Retrieval<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Social information filtering for music recommendation</title>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-09">September 1994</date>
		</imprint>
		<respStmt>
			<orgName>Massachussets Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Racofi: A rule-applying collaborative filtering system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Boley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Howse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lemire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcgrath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Collaboration Agents Workshop, IEEE/WIC</title>
		<meeting>the Collaboration Agents Workshop, IEEE/WIC<address><addrLine>Halifax, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Slope one predictors for online rating-based collaborative filtering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lemire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maclachlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIAM Data Mining</title>
		<meeting>SIAM Data Mining<address><addrLine>Newport Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Multimedia Storage and Archiving Systems II</title>
		<author>
			<persName><forename type="first">J</forename><surname>Foote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proceedings of SPIE</title>
		<imprint>
			<biblScope unit="page" from="138" to="147" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Content-based retrieval of music and audio</note>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Music similarity measures: What&apos;s the use?</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Aucouturier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd International Conference on Music Information Retrieval</title>
		<meeting>3rd International Conference on Music Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<title level="m" type="main">The earth mover&apos;s distance as a metric for image retrieval</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>tech. rep., Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">A music similarity function based on signal analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo</title>
		<imprint>
			<date type="published" when="2001">2001. 2001. 2001</date>
			<biblScope unit="page" from="745" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">Manipulation, Analysis and Retrieval Systems for Audio Signals</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tzanetakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b187">
	<monogr>
		<title level="m" type="main">Computational Models of Music Similarity and their Application to Music Information Retrieval</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pampalk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Learning a metric for music similarity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Slaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Music Information Retrieval</title>
		<meeting>the 9th Conference on Music Information Retrieval<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="313" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Music recommendation based on adaptive feature and user grouping</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cataltepe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Altinel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International International Symposium on Computer and Information Sciences</title>
		<meeting>the 22nd International International Symposium on Computer and Information Sciences<address><addrLine>Ankara, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Personalization of user profiles for content-based music retrieval based on relevance feedback</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hoashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of eleventh ACM international conference on Multimedia</title>
		<meeting>eleventh ACM international conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Relevance feedback in information retrieval</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The SMART Retrieval System: Experiments in Automatic Document Processing</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</editor>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
	<note>Prentice-Hall Series in Automatic Computation</note>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">An industrial-strength content-based music recommendation system</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koppenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 28th International ACM SIGIR Conference</title>
		<meeting>28th International ACM SIGIR Conference<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">An efficient hybrid music recommender system using an incrementally trainable probabilistic generative model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Komatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Audio Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="435" to="447" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Improving efficiency and scalability of model-based music recommender system based on incremental training</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Komatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Hybrid collaborative and content-based music recommendation using probabilistic model with latent user preferences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Komatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 7th International Conference on Music Information Retrieval</title>
		<meeting>7th International Conference on Music Information Retrieval<address><addrLine>Victoria, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="296" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pennock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting><address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="437" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Towards ensemble learning for hybrid music recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tiemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pauws</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Vienna, Austria</note>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<title level="m" type="main">Table 4.2 Top-10 artists in 2006 based on total digital track sales (last column) according to Nielsen report. The second column (values in parenthesis) shows the corresponding last</title>
		<imprint/>
	</monogr>
	<note>Sean Paul (2,764,505. fm artist rank. 1. (912) Rascal Flatts (4,970,640</note>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<title level="m" type="main">Why the Future of Business Is Selling Less of More</title>
		<author>
			<persName><forename type="first">C</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Hyperion</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>The Long Tail</note>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Blockbuster culture&apos;s next rise or fall: The impact of recommender systems on sales diversity</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Fleder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hosanagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SSRN eLibrary</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">How does popularity information affect choices? theory and a field experiment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SSRN eLibrary</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Experimental study of inequality and unpredictability in an artificial cultural market</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Salganik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">311</biblScope>
			<biblScope unit="page" from="854" to="856" />
			<date type="published" when="2006-02">February 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">State of the industry</title>
		<author>
			<persName><forename type="first">N</forename><surname>Soundscan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nielsen Soundscan Report. National Association of Recording Merchandisers</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Soundscan</surname></persName>
		</author>
		<title level="m">Nielsen soundscan report. Year-end music industry report</title>
		<meeting><address><addrLine>White Plains, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<monogr>
		<title level="m" type="main">A critical reader&apos;s companion to the long tail</title>
		<author>
			<persName><forename type="first">T</forename><surname>Slee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">Should you invest in the long tail?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elberse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Business Review</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">7/8</biblScope>
			<biblScope unit="page" from="88" to="96" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Superstars and underdogs: An examination of the long tail phenomenon in video sales</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elberse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Oberholzer-Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Harvard Business School Working Paper</title>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">A practical model for analyzing long tails</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kilkki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Measurement of inequality and incomes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Economic Journal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="124" to="126" />
			<date type="published" when="1921">1921</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Power-law distributions in empirical data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clauset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Shalizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Reviews</title>
		<imprint>
			<date type="published" when="2007-06">June 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Likelihood ratio tests for model selection and non-nested hypotheses</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Vuong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="307" to="333" />
			<date type="published" when="1989-03">March 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Evaluating collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Information System</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="53" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Being accurate is not enough: How accuracy metrics have hurt recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Human Interaction. Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1097" to="1101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Music recommendation tutorial</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Conference on Music Information Retrieval</title>
		<meeting>8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Novelty and redundancy detection in adaptive filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 25th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Interest-based recommendation in digital library</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="46" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Improving recommendation novelty based on topic taxonomy</title>
		<author>
			<persName><forename type="first">L.-T</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nayak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology</title>
		<meeting>the IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="115" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">User modeling for adaptive news access</title>
		<author>
			<persName><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="147" to="180" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Improving recommendation lists through topic diversification</title>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on World Wide Web</title>
		<meeting>the 14th International Conference on World Wide Web<address><addrLine>New York, NY)</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<monogr>
		<title level="m" type="main">Empirical analysis of predictive algorithms for collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note>tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Evaluating collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="53" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<monogr>
		<title level="m" type="main">Evaluating recommender systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gunawardana</surname></persName>
		</author>
		<idno>MSR-TR-2009-159</idno>
		<imprint>
			<date type="published" when="2009-11">November 2009</date>
		</imprint>
	</monogr>
	<note>tech. rep., Microsoft Research</note>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">Fab: Content-based, collaborative recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balabanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="66" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">Measuring retrieval effectiveness based on user preference of documents</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="145" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Being accurate is not enough: How accuracy metrics have hurt recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Human Interaction. Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1097" to="1101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">On random graphs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Erdös</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Réyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">290</biblScope>
			<biblScope unit="page" from="290" to="298" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999-10">October 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Assortative mixing in networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">20</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Mixing patterns in networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">Collective dynamics of &apos;small-world&apos; networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="page" from="440" to="442" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Hierarchical organization in complex networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<date type="published" when="2003-02">February 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">Hierarchical organization of modularity in metabolic networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Somera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mongru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">N</forename><surname>Oltvai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">297</biblScope>
			<biblScope unit="issue">5586</biblScope>
			<biblScope unit="page" from="1551" to="1555" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">A measure of betweenness centrality based on random walks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="39" to="54" />
			<date type="published" when="2005-01">January 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">The centrality index of a graph</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sabidussi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="581" to="603" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">Centrality in social networks: Conceptual clarification</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="239" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Topology of music recommendation networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koppenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin-Buldú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos: An Interdisciplinary Journal of Nonlinear Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">013107</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">The complex network of musical tastes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martin-Buldú</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koppenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Almendral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boccaletti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">172</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">The social network of contemporary popular musicians</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koppenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin-Buldú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Bifurcation and Chaos</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2281" to="2288" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">Complex-network theoretic clustering for identifying groups of similar listeners in p2p systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anglade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tiemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vignoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM conference on Recommender systems</title>
		<meeting>the ACM conference on Recommender systems<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">A scale-free distribution of false positives for a large class of audio similarity measures</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Aucouturier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="272" to="284" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">Musically meaningful or just noise? an analysis of on-line artist networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Symposium on Computer Music Modeling and Retrieval</title>
		<meeting>the 6th International Symposium on Computer Music Modeling and Retrieval<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">Uncovering collective listening habits and music genres in bipartite networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lambiotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ausloos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<analytic>
		<title level="a" type="main">Centric Evaluation k in LT Rank Plays Artists (number of plays) CF 2,877 123 1,307 Arcade Fire</title>
	</analytic>
	<monogr>
		<title level="m">The Shins (43)</title>
		<imprint>
			<publisher>Sufjan Stevens</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<title level="m">Arcade Fire (108)</title>
		<imprint/>
	</monogr>
	<note>675 75 2,995 Interpol. Radiohead</note>
</biblStruct>

<biblStruct xml:id="b247">
	<monogr>
		<title level="m" type="main">266 191 4,585 Broken Social Scene (172), Decemberists (128)</title>
		<imprint/>
	</monogr>
	<note>Arch. Helsinki (128</note>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">The Doors (1,822</title>
	</analytic>
	<monogr>
		<title level="m">The Beatles</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
	<note>Bob Dylan (1,588</note>
</biblStruct>

<biblStruct xml:id="b249">
	<monogr>
		<idno>CB 5,568 217 88</idno>
		<title level="m">689 Red Hot Chili Peppers</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
	<note>Led Zeppelin (6,595), GN&apos;R (3,457</note>
</biblStruct>

<biblStruct xml:id="b250">
	<monogr>
		<title level="m">The Cure (13,945), NIN (12,938)</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page">77</biblScope>
		</imprint>
	</monogr>
	<note>Smashing Pumpkins (8,460</note>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">An industrial-strength content-based music recommendation system</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koppenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 28th International ACM SIGIR Conference</title>
		<meeting>28th International ACM SIGIR Conference<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title level="a" type="main">Collective dynamics of &apos;small-world&apos; networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="page" from="440" to="442" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">Navigation in a small world</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">406</biblScope>
			<biblScope unit="page">845</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">The structure and function of complex networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="256" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">Power-law distributions in empirical data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clauset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Shalizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Reviews</title>
		<imprint>
			<date type="published" when="2007-06">June 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Power-law distribution of the world wide web</title>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bianconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">287</biblScope>
			<biblScope unit="page">2115</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999-10">October 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">The quest for musical genres: Do the experts and the wisdom of crowds agree</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sordo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Guaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Music Information Retrieval</title>
		<meeting>the 9th International Conference on Music Information Retrieval<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Musically meaningful or just noise? an analysis of on-line artist networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Symposium on Computer Music Modeling and Retrieval</title>
		<meeting>the 6th International Symposium on Computer Music Modeling and Retrieval<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Meyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Tweedie</surname></persName>
		</author>
		<title level="m">Markov Chains and Stochastic Stability</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<analytic>
		<title level="a" type="main">Experimental study of inequality and unpredictability in an artificial cultural market</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Salganik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">311</biblScope>
			<biblScope unit="page" from="854" to="856" />
			<date type="published" when="2006-02">February 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<analytic>
		<title level="a" type="main">Hierarchical organization in complex networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<date type="published" when="2003-02">February 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<analytic>
		<title level="a" type="main">On the other hand, we have defined a simple music recommendation OWL DL ontology 13 that describes some basic properties of the artists and music titles, as well as some descriptors automatically extracted from the audio files (e.g. tonality, rhythm, moods, music intensity, etc.). In [11] we propose a way to map our ontology and the Musicbrainz ontology, onto the MPEG-7 standard, which acts as an upperontology for multimedia description</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan ; Magnatune</surname></persName>
		</author>
		<author>
			<persName><surname>Cdbaby</surname></persName>
		</author>
		<author>
			<persName><surname>Garageband</surname></persName>
		</author>
		<ptr target="http://www.radiohead.com" />
	</analytic>
	<monogr>
		<title level="m">:type rdf:resource=&quot;{\&amp;}music;Artist&quot;/&gt; &lt;foaf:name&gt;Randy Coleman&lt;/foaf:name&gt; &lt;music:decade&gt;1990&lt;/music:decade&gt; &lt;music:decade&gt;2000&lt;/music:decade&gt; &lt;music:genre&gt;Pop&lt;/music:genre&gt; &lt;foaf:based_near rdf:resource=</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1097" to="1101" />
		</imprint>
	</monogr>
	<note>:influencedBy rdf:resource=</note>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">3 shows the description of an individual track of the previous artist, including basic editorial metadata, and some features extracted automatically from the audio file</title>
		<author>
			<persName><forename type="first">&lt;/</forename><surname>Rdf</surname></persName>
		</author>
		<ptr target="http://www.garageband.com/artist/randycoleman&quot;/&gt;&lt;music:duration&gt;247&lt;/music:duration&gt;&lt;music:intensity&gt;Energetic&lt;/music" />
	</analytic>
	<monogr>
		<title level="m">song?|pe1| S8LTM0LdsaSkaFeyYG0&quot;&gt; &lt;rdf:type rdf:resource=&quot;{\&amp;}music;Track&quot;/&gt; &lt;music:title&gt;Last Salutation&lt;/music:title&gt; &lt;music:playedBy rd:resource=</title>
		<title level="s">Description&gt; Listing 8.2 RDF example of an artist individual Listing</title>
		<imprint>
			<publisher>Description&gt;</publisher>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
	<note>&lt;rdf:Description rdf:about=. intensity&gt; &lt;music:key&gt;D&lt;/music:key&gt; &lt;music:keyMode&gt;Major&lt;/music:keyMode&gt; &lt;music:tonalness&gt;0.84&lt;/music:tonalness&gt; &lt;music:tempo&gt;72&lt;/music:tempo&gt; &lt;/rdf</note>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">Aroooga: An audio search engine for the world wide web</title>
		<author>
			<persName><forename type="first">I</forename><surname>Knopke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Conference on Music Information Retrieval</title>
		<meeting>5th International Conference on Music Information Retrieval<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Modern Information Retrieval</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
	<note>1st edn.</note>
</biblStruct>

<biblStruct xml:id="b267">
	<analytic>
		<title level="a" type="main">A self-organizing map based knowledge discovery for music recommendation systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vembu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Symposium on Computer Music Modeling and Retrieval</title>
		<meeting>the 2nd International Symposium on Computer Music Modeling and Retrieval<address><addrLine>Esbjerg, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<analytic>
		<title level="a" type="main">An algorithm for suffix stripping</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<analytic>
		<title level="a" type="main">An industrial-strength content-based music recommendation system</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koppenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 28th International ACM SIGIR Conference</title>
		<meeting>28th International ACM SIGIR Conference<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">Annotating music collections how content-based similarity helps to propagate labels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sordo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laurier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<analytic>
		<title level="a" type="main">Trust network-based filtering of aggregated claims</title>
		<author>
			<persName><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Metadata, Semantics and Ontologies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<monogr>
		<title level="m" type="main">Computing and Applying Trust in Web-based Social Networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>College Park, MD</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b273">
	<analytic>
		<title level="a" type="main">The sensitivities of user profile information in music recommender systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Ruyter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Markopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eggen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Private, Security, Trust</title>
		<meeting>Private, Security, Trust</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<analytic>
		<title level="a" type="main">Towards principles for the design of ontologies used for knowledge sharing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Gruber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Ontology in Conceptual Analysis and Knowledge Representation</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Guarino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</editor>
		<meeting><address><addrLine>Deventer, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Semantic integration and retrieval of multimedia metadata</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 4th International Semantic Web Conference. Knowledge Markup and Semantic Annotation Workshop</title>
		<meeting>4th International Semantic Web Conference. Knowledge Markup and Semantic Annotation Workshop<address><addrLine>Galway, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">The music ontology</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Raimond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giasson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<monogr>
		<title level="m" type="main">The Paradox of Choice: Why More Is Less</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-01">January 2005</date>
			<publisher>Harper Perennial</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<analytic>
		<title level="a" type="main">A practical model for analyzing long tails</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kilkki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">The music ontology</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Raimond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giasson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">Annotating music collections how content-based similarity helps to propagate labels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sordo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laurier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting>the 8th International Conference on Music Information Retrieval<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">Creating transparent, steerable recommendations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lamere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Latebreaking Demos. Proceedings of the 8th International Conference on Music Information Retrieval</title>
		<meeting><address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
