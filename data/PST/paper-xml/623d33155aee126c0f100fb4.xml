<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?</title>
				<funder ref="#_cTEWNM2">
					<orgName type="full">Ramanujan Fellowship, CAI, IIIT-Delhi and ihub-Anubhuti-iiitd Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-24">24 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Subhabrata</forename><surname>Dutta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeevesh</forename><surname>Juneja</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dipankar</forename><surname>Das</surname></persName>
							<email>dipankar.dipnil@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
							<email>tanmoy@iiitd.ac.in</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Jadavpur University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Delhi Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Jadavpur University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-24">24 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2203.12881v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying argument components from unstructured texts and predicting the relationships expressed among them are two primary steps of argument mining. The intrinsic complexity of these tasks demands powerful learning models. While pretrained Transformerbased Language Models (LM) have been shown to provide state-of-the-art results over different NLP tasks, the scarcity of manually annotated data and the highly domaindependent nature of argumentation restrict the capabilities of such models. In this work, we propose a novel transfer learning strategy to overcome these challenges. We utilize argumentation-rich social discussions from the ChangeMyView subreddit as a source of unsupervised, argumentative discourse-aware knowledge by finetuning pretrained LMs on a selectively masked language modeling task. Furthermore, we introduce a novel promptbased strategy for inter-component relation prediction that compliments our proposed finetuning method while leveraging on the discourse context. Exhaustive experiments show the generalization capability of our method on these two tasks over within-domain as well as out-of-domain datasets, outperforming several existing and employed strong baselines. 1 * *Equal contribution 1 We release all code, models and data used at https: //github.com/Jeevesh8/arg_mining</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computational argument mining from texts is the fine-grained process of understanding opinion dynamics. In the most fundamental sense, argument understanding requires the identification of the opinions posed and justifications provided to support or falsify them. Generally, automated argument mining is a multi-stage pipeline identified with three general steps <ref type="bibr" target="#b17">(Lippi and Torroni, 2015;</ref><ref type="bibr" target="#b29">Stab and Gurevych, 2017)</ref> -separating argumentative spans from non-argumentative ones, classi- fying argument components, and inducing a structure among them <ref type="bibr">(support, attack, etc.)</ref>. While different argumentation models define different taxonomies for argument components, popular approaches broadly categorize them as 'claims' and 'premises' <ref type="bibr" target="#b29">(Stab and Gurevych, 2017;</ref><ref type="bibr" target="#b8">Egawa et al., 2019;</ref><ref type="bibr" target="#b21">Mayer et al., 2020)</ref>. As these components are not necessarily aligned to sentence-level segments and can be reflected within clausal levels, the task of argument component identification requires a token-level boundary detection of components and component type classification.</p><p>Context of argumentation in online discussions. Online discussions originating from backand-forth posts from users reflect a rich interaction of opinion dynamics on large scale. In Figure <ref type="figure" target="#fig_0">1</ref>, we show a sample argument component annotation of consecutive posts from two users. The token-level granularity of components ensures that a single sentence may contain multiple components of the same (in 1st post) or different kinds (in 2nd and 4th posts). Moreover, two adjacent spans of texts, even with the same argumentative role, can be defined as two separate components (see the 4th post for example). It is trivial to say that the meaning of any post (as well as its argumentative role) is de-pendent on the context. To be specific, the third post can be identified as argumentative (a premise in this case) only when its predecessor post and its components are taken as the context. Similarly, a certain span of the first post is quoted in the second one signaling a concrete manifestation of dialogic continuity. One may even observe the user-specific argumentation styles: 1st user (author of the first and third posts) usually keeps claims and premises in separate sentences, while the 2nd user prefers to use multi-component, complex sentences. Existing studies on argumentation formalism recognize such continuity and define inter-post component relations <ref type="bibr" target="#b11">(Ghosh et al., 2014;</ref><ref type="bibr" target="#b14">Hidey et al., 2017)</ref>. However, the previous approaches for automated extraction, classification and relating argumentative components work on individual posts only and define the inter-post discourse in the later stages of relation prediction. This is trivially counter-intuitive for two major reasons: (i) if we consider two text spans from separate comments to be linked by some argumentative relation, then there exists a continuity of discourse between these spans and a model is likely to benefit if it decides the boundaries and types of these two components conditioned on that continuous information; (ii) users carry their style of argumentation (simple consecutive sentences vs. long complex ones, usage of particular markers like 'I think that' etc.), and if the model is informed about these while observing the complete conversation with back-and-forth posts, it is more likely to extract correct components easily.</p><p>Scarcity of labeled data. Irrespective of the domain, argument annotation is a resource-intensive process. A few previous studies <ref type="bibr" target="#b12">(Habernal and Gurevych, 2015;</ref><ref type="bibr" target="#b0">Al-Khatib et al., 2016)</ref> attempted to exploit a large amount of unlabeled data in a semi-supervised fashion. However, such methods require the components to be defined at sentencelevel (and thereby adding redundant spans into the predictions) as they perform some sentence similarity matching to generate pseudo-labels. Pretrained language models like BERT <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref> provide a workaround to handle the scarcity of task-specific annotated data. A parameter-intensive model is initially trained in a self-supervised manner on a large bulk of text; this pretraining enables the model to learn general language representation, which is then finetuned on task-specific labeled data. However, the amount of the latter still deter-mines the expressive power of such models <ref type="bibr" target="#b31">(Wang et al., 2020)</ref>.</p><p>Present work. Considering these challenges, we formulate a novel transfer learning method using Transformer-based language models. We use large amount of unlabelled discussion threads from Reddit's r/ChangeMyView (CMV) community as the source of argumentative knowledge. Pretrained, Transformer-based language models are finetuned on this dataset using a Masked Language Modelling task. Instead of randomly masking tokens to predict, we select several markers in the text that are shown to signal argumentative discourse in previous works <ref type="bibr" target="#b2">(Chakrabarty et al., 2019;</ref><ref type="bibr" target="#b7">Eckle-Kohler et al., 2015)</ref>. The language models are then made to predict these markers in the MLM task, thereby learning to relate different components of text according to their role in the argumentation presented. We call this novel finetuning method Selective Masked Language Modeling (sMLM). Furthermore, to explore the role of context in argument mining, we use sMLM to finetune a post-level language model based on BERT <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref> and RoBERTa <ref type="bibr" target="#b19">(Liu et al., 2019)</ref> and a thread-level language model based on Longformer <ref type="bibr" target="#b1">(Beltagy et al., 2020)</ref>. We present efficient incorporation of several Reddit-specific structural cues into the Longformer architecture. These finetuned language models are then used for two fundamental components of argument mining: tokenlevel argument component identification (ACI) and inter-component relation type prediction (RTP). To further utilize the sMLM-based training of the language models, we propose a novel prompt-based approach to predict relations among argument components. We perform exhaustive experiments to explore the efficacy of our proposed methods for argument mining in both in-domain and out-ofdomain benchmark datasets: manually annotated Reddit discussions and scientific papers. Our experiments show clear improvements achieved by our methods (0.59 and 0.69 F1 for ACI and RTP, respectively) over several state-of-the-art baselines.<ref type="foot" target="#foot_0">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A general overview of argument mining can be found in the survey articles by <ref type="bibr" target="#b20">Lytos et al. (2019)</ref> and <ref type="bibr" target="#b16">Lawrence and Reed (2019)</ref>. In the current scope, we look into three major areas of research in argument mining.</p><p>Argument component detection and classification. Previous studies have sought to address argument boundary detection and component type prediction either as separate, successive tasks in the pipeline <ref type="bibr" target="#b29">(Stab and Gurevych, 2017)</ref> or jointly in a single computational pass <ref type="bibr" target="#b9">(Eger et al., 2017)</ref>. Studies also explored classical machine learning frameworks like SVM-HMM <ref type="bibr" target="#b13">(Habernal and Gurevych, 2017)</ref>, CRF <ref type="bibr" target="#b29">(Stab and Gurevych, 2017)</ref>, etc. with rich manual feature engineering. With the development of neural network-based algorithms, BiLSTM-CNN-CRF models emerged as a popular choice <ref type="bibr" target="#b28">(Schulz et al., 2018;</ref><ref type="bibr" target="#b9">Eger et al., 2017;</ref><ref type="bibr" target="#b4">Chernodub et al., 2019)</ref>. Very recently, large pretrained language models like BERT have also been utilized <ref type="bibr" target="#b21">(Mayer et al., 2020;</ref><ref type="bibr" target="#b2">Chakrabarty et al., 2019)</ref>.</p><p>Discourse markers for learning language representation. Similar to our sMLM finetuning strategy, <ref type="bibr" target="#b24">Nie et al. (2019)</ref> proposed an unsupervised sentence representation learning strategy where a neural model is trained to predict the appropriate discourse marker connecting two input sentences. Using a set of 15 markers, they showed that such a finetuning can help models in downstream NLI tasks. <ref type="bibr" target="#b2">Chakrabarty et al. (2019)</ref> used a distant supervision approach using a single marker In my honest opinion to finetune BERT on a large collection of ChangeMyView threads and then performed argument component classification. However, they did not deal with the component identification task and performed classification of already identified components at sentence-level. <ref type="bibr" target="#b25">Opitz and Frank (2019)</ref> suggested that while identifying the relation between two components, these models often rely more on the context and not the content of the components; discourse markers present within the context provide strong signals for the relation prediction task.</p><p>Argument mining over Reddit. A few recent studies explored argumentation over Reddit. <ref type="bibr" target="#b14">Hidey et al. (2017)</ref> proposed a two-tier annotation scheme of claim-premise components and their relations, defining five different semantic roles of premises, using ChangeMyView discussion data. <ref type="bibr" target="#b8">Egawa et al. (2019)</ref> also analyzed semantic roles of argument components over ChangeMyView threads; however, their primary focus remained on the dynamics of persuasion, similar to <ref type="bibr" target="#b6">Dutta et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Selective MLM finetuning of Pretrained Language Models</head><p>Though pretrained language models are developed to overcome the problem of small annotated data on different language processing tasks, they still require task-specific finetuning for better results <ref type="bibr" target="#b31">(Wang et al., 2020)</ref>. In the specific domain of argument mining, annotated data is scarce, and attempting to finetune a massive language model with very small training data comes with the risk of overfitting. Moreover, different datasets follow different strategies for annotation. We seek to devise a novel transfer learning strategy where a given Transformer-based pretrained language model is directed to focus on argumentative discourse using large-scale, unlabelled data. We choose the ChangeMyView (CMV) community as the source of this transfer for two specific reasons: (i) it provides us with a large, readily available resource of interactions strictly focused on debates around versatile topics, and (ii) discussions in CMV contain a mixture of dialogic continuity over successive turns along with elaborate argumentation presented in a single turn. We hypothesize that such a versatile combination of discourse can make the language model more generalizable over dialogic as well as monologic argument mining tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discourse structure of CMV</head><p>Discussion forums like Reddit facilitate users to begin a discussion with an initial post (submissions, in the case of Reddit) and then comments under that post to instantiate a discussion. Users may post a comment in reply to the submission as well as the already posted comments. A typical discussion over Reddit forms a tree-like structure rooted at the submission. Any path from the root to a leaf comment can be perceived as an independent dialogic discourse among two or multiple users; henceforth, we will call such paths as threads. Formally, a thread T is an ordered sequence {(u i , P j )|i, j ? N, u i ? U T }, where P j is a text object (a submission when j = 1 and a comment, otherwise), u i is the author of P j , and U T is the set of all unique users engaged in the thread T .</p><p>For brevity, we indicate P j as a post in general.</p><p>The dialogic nature of discussions naturally assumes this context to be the whole thread T . However, if we consider any two successive posts P j and P j+1 in T , they manifest the interests and styles of two separate participants along with the discourse continuity of the overall thread, which must be distinguished within the definition of the context. To take into account the complete dialogic context of the thread, we represent a thread as a single contiguous sequence of tokens with each post P j from user u i being preceded by a special token</p><formula xml:id="formula_0">[USER-i] with i ? {0, ? ? ? , |U T | -1},</formula><p>to encode which post is written by which user.</p><p>Reddit also offers users a quoting facility: users can quote a segment from the previous post (one to which they are replying) within their posts and emphasize that their opinions are specifically focused on that segment. We delimit such quoted segments with special tokens [STARTQ] and [ENDQ] in the quoting post to demarcate the dialogic discourse. <ref type="bibr" target="#b2">Chakrabarty et al. (2019)</ref> also used quoting as signals for following premises. Additionally, we replace URLs with the special token [URL] to inform the presence of external references that often act as justifications of subjective opinions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Selective MLM finetuning</head><p>Masked Language Modeling is a common strategy of training large language models; a certain fraction of the input tokens are masked and the model is trained to predict them, consequently learning a generalized language representation. Instead of randomly selecting tokens to mask, we select specific markers that might signal argumentative discourse. While the model is trained to predict these markers, it learns the roles and relationships of the text spans preceding and following them. Following the work by <ref type="bibr" target="#b7">Eckle-Kohler et al. (2015)</ref>, we select multiple markers signaling Opinion, Causation, Rebuttal, Fact presentation, Assumption, Summary, and some additional words, which serve multiple purposes depending on the context.</p><p>As shown in Figure <ref type="figure" target="#fig_1">2</ref>, to predict the marker I think in the first post, the model needs to learn that the following text span "that most Jewish people ? ? ? " expresses the user's opinion on the topic. Similarly, in the second post, for the input segment " span 0 So span 1 if span 2 ", to correctly predict the masked markers as So and if, a language model needs to learn the fact that the truth value of the statement expressed in span 1 is conditioned upon span 2 , and this dependence is inferred from span 0 .</p><p>Effect of context sizes. CMV threads provide a natural segmentation of the discourse context into comment/post-level vs. thread-level. We seek to ex- plore the effect of the context size at different modules of argument mining (i.e., argument component detection and relation type prediction). For this, we use our proposed selective MLM approach to finetune a pretrained RoBERTa/BERT-base model in the comment/post-level regime, and train Longformer models in the thread-level regime. Longformer uses sparse, global attention (i.e., some tokens attend to all the tokens in the input sequence) to capture the long-range dependencies. We use the special tokens indicating the users (c.f. Section 3.1) as the globally attending tokens for Longformer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Argument component identification</head><p>After finetuning the language model on the selective MLM task, we proceed to our first task of identifying argument components in threads. Since the detection is done in tokenlevel, we use the standard BIO tagging scheme: for a component class type , the beginning and the continuation of that component are marked as Btype and Itype , respectively, while any non-component token is labeled as O. Therefore, if one uses the usual claim-premise model of argumentation, the label set becomes {B-claim, I-claim, B-premise, I-premise, O}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inter-component relation prediction</head><p>While identifying the relation between two given related argument components, it is important to understand the role of those text segments within the context of the discourse. Furthermore, we seek USER-1 CMV: I feel skill is largely determined by experience. Compliments on skill are almost meaningless. In high school, I thought I was "good at math" as I'm the son of a math teacher and electrical engineer. In college, I learned that math was not something you're "good at" but something you have to put hard work into and is almost the sole determiner in the level of skill you obtain. So then isn't almost any compliment almost to be expected? I've spent a lot of time with similar problems --how could I not know all the details and little tricks of these problems? I feel a compliment recognizes something given: I feel everyone is passionate about something, whether it be math or psychology or medicine. I don't hear "you're so good at biology" but I think I should. USER-2 Then wouldn't a complement be just an acknowledgement of the time and effort you put into something that most people see as hard or worthwhile? This implies the complement is meaningful. ( Most people don't do this -either they don't put the time and effort into something generally hard or worthwhile or the time and effort isn't hard or worthwhile .) tion where we seek to classify the relation between the claims posed by USER-1 and USER-2, highlighted in red and green, respectively; the thread is converted to the prompt input by appending the prompt template. The language model the converts this prompt token sequence into fixed dimensional vectors from which the vector corresponding to the position of the masking token is used for relation classification.</p><p>to utilize the knowledge acquired by a language model in the sMLM finetuning step as well. Keeping these two factors in mind, we propose a novel, prompt-based identification of argument components. This approach is inspired by recent popularity of prompt-based fine-tuning methods in the community <ref type="bibr" target="#b18">(Liu et al., 2021)</ref>. At its core, these methods involve directly prompting the model for the required knowledge, rather than fine-tuning [CLS] or mean-pooled embeddings. For example, to directly use a model to summarise a text, we can append "TL;DR:" to the text <ref type="bibr" target="#b26">(Radford et al., 2019)</ref>, and let the model generate tokens following it; we expect the next few tokens to constitute a summary of all the previous text.</p><p>Since the underlying Transformer LMs have been trained using some Cloze task (i.e., filling the blanks from the context) previously, it is more natural for it to predict a token given a context. However, there are two challenges: (i) one needs to design a suitable prompt, and (ii) in case of classification tasks like RTP, it is challenging to perform Answer Mapping, i.e., to map all the possible tokens to some particular relation class. To tackle these challenges, we design our proposed relation prediction method in the following manner (see Figure <ref type="figure">3</ref>)</p><p>For each pair of related components, say, component-1 and component-2, said by user-i and user-j, respectively, where component-2 refers to component-1, we append to the thread, a prompt with the template: "[USER-i] said &lt;component1&gt; [MASK] [MASK] [MASK] [USER-j] said &lt;com-ponent2&gt;" (we used three mask tokens since that is the upper bound of the marker size used for sMLM). We expect that the words predicted at the masked position such as "because", "in spite of what" etc. would be indicative of the relation of the two components. For the example thread shown in Figure <ref type="figure">3</ref>, in a zero-shot prediction, sMLM-finetuned Longformer predicts "I", "disagree", "I" at the three masked positions. This "disagree" clearly corresponds to the undercutter relation between the two components. In fact, the base Longformer without sMLM finetuning predicts a space, a full stop and another space at the three masked positions. This additionally proves the efficacy of the sMLM finetuning.</p><p>Instead of engineering a token-to-relation type mapping, the predicted token embeddings at the masked positions are concatenated and fed into a linear layer to predict probabilities over the set of relation types. This way, we allow the model to learn and map from the token space to the relation type space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>For the sMLM finetuning, we use the subset of Winning Args (ChangeMyView) (CMV) dataset <ref type="bibr" target="#b30">(Tan et al., 2016)</ref> provided in ConvoKit <ref type="bibr" target="#b3">(Chang et al., 2020)</ref>. We use 99% of this data for training, and reserve 1% for checking accuracy on the sMLM task. The entire data consists of 3, 051 submissions and 293, 297 comments posted in the ChangeMyView subreddit by 34, 911 unique users. We extract the threads from these posts following the reply structure and end up with 120, 031 threads in total.</p><p>To train and evaluate all the models for ACI and RTP, we use the manually annotated Reddit discussion threads provided by <ref type="bibr" target="#b14">Hidey et al. (2017)</ref> and further extended by <ref type="bibr" target="#b2">Chakrabarty et al. (2019)</ref> for training and evaluation. The extended version of this dataset contains 113 CMV discussion threads manually annotated with argument components following the standard claim-premise model.</p><p>Additionally, we use the argument annotated Dr. Inventor Corpus <ref type="bibr" target="#b15">(Lauscher et al., 2018)</ref> which consists of 40 scientific publications from the field of computer graphics. There are three types of argumentative components here: Background Claims (BC), consisting of claims from previous works in the paper, Own Claim (OC) consisting of the new claims made by the authors of the paper, and Data. The Data class mainly consists of citations, references to figures, etc. This dataset has three relation types, viz., support, contradicts and semantically same. Additional dataset details are provided in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline methods</head><p>For ACI, we consider two state-of-the-art tokenlevel argument identification models: ? LSTM-MTL. <ref type="bibr" target="#b9">Eger et al. (2017)</ref> proposed an end-to-end argument mining architecture which uses a BiLSTM-CNN-CRF sequence tagger to jointly learn component detection, classification, and relation parsing tasks. ? LSTM-MData. <ref type="bibr" target="#b28">Schulz et al. (2018)</ref> proposed a BiLSTM-CNN-CRF based model which aims to generalize argument mining using multidomain training data in an MTL setting. We augment our data with their original set of 6 datasets.</p><p>For RTP, as no prior work exists to the best of our knowledge, we consider our own baselines. First, we consider ? Context-less RoBERTa, a pretrained RoBERTa model, which takes the two components with a [SEP] token between them and predicts the relation using [CLS] token's embedding. It is context-less as only two components without the surrounding context are used to predict the label. Second, we consider ? Contextless QR-Bert. This uses the same fine-tuning methodology as Contextless RoBERTa and is initialized from the pre-trained Quote-Response relation prediction model of <ref type="bibr" target="#b2">Chakrabarty et al. (2019)</ref>.</p><p>For RTP, we try another traditional strategy, instead of prompting, for our models: ? Mean Pooling. The mean pooling approach first finds an embedding of each of the two related components by averaging the Transformer embeddings at all token positions within a component. These embeddings are concatenated and passed into a linear layer for predicting the type of relation between the two related components.</p><p>To further evaluate the efficacy of our sMLM training strategy, we finetune a pretrained Longformer on the Winning Args Corpus, with the usual MLM, i.e., masking 15% of tokens at random, instead of selective masking. We call this the domainadapted Longformer, DA-LF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation details</head><p>We use the pretrained base version of Longformer (12 layers, 768 model size). The size of the local attention window was set to the default 512. The maximum sequence length was fixed at 4096.</p><p>Following the suggestions in Reimers and Gurevych (2017), we repeat our experiments on the 5 different data splits. The scores reported in the tables for various models correspond to the average value of the mean of 5 runs, over the last 5 epochs for that particular metric. We provide additional implementation details in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>We evaluate the models based on precision, recall, and F1 scores for predicting claims and premises. For a more rigorous setting, we use exact match of the whole span between gold and predicted labels, i. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Argument component identification</head><p>Table <ref type="table">1</ref> shows the results for argument component identification on the CMV Modes dataset. We compare models based on their micro-averaged F1 over the two component types (claims, premises), and token level accuracy. Firstly, we observe huge difference in token-level accuracy scores as we move from the existing best performing LSTM based methods with accuracy of 0.54 to BERT,  having an accuracy of 0.62. Such a difference is expected since pretrained language models like BERT provide a head-start in case of small datasets like CMV Modes. Though the token-level accuracy increases, the micro-averaged F1 for exact component match does not increase much till we start using RoBERTa. Since pretrained Longformer was trained originally from the RoBERTa checkpoint <ref type="bibr" target="#b1">(Beltagy et al., 2020)</ref>, we can conclude that RoBERTa provides significant performance gain compared to BERT, owing to its larger training data and protocol. Longformer trained with our proposed sMLM finetuning clearly outperforms the rest of the models in terms of overall F1 score for component identification. However, the effects of selective MLM is more prominant in case of thread-level context (i.e, Longformer) compared to comment-level context (i.e, RoBERTa). We can observe that context plays different roles for different component types: while sMLMfinetuned Longformer and RoBERTa perform comparably for claim detection, in case of premises, the access to the complete context helps the Longformer to perform better. We can observe a similar trend in ACI-task on Dr. Inventor dataset (see Table 2). While Base Longformer performs comparable to its sMLM counterpart to detect Background and Own Claims, sMLM provides a 4 point improvement in F1 score for the Data class which plays a similar role of premises towards the claims. Intuitively, textual segments expressing claims contain independent signals of opinion that is less dependent on the context; pretrained language models might be able to decipher their roles without additional information either from the thread-level context (in case of CMV Modes, specifically) or enhanced relation-awareness induced by the sMLM finetuning. However, identifying segments that serve the role of premises to a claim intrinsically depends on the claims as well as the discourse expressed in a larger context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Relation type prediction</head><p>In Table <ref type="table" target="#tab_2">3</ref>, we present the results for relation type identification on the CMV Modes dataset. We again compare models based on their microaveraged F1 over all relation types. Firstly, we consider the traditional mean pooling approach. Within this approach, we observe a 3 point improvement for the sMLM pre-trained Longformer on the 80-20 split, while maintaining same performance on the 50-50 split. Furthermore, the prompt based methods consistently outperform the mean pooling one, irrespective of whether we use base Longformer or sMLM pretrained one. Within the prompting approach, we also observe increased and consistent improvement in performance due to sMLM pretraining on both 80-20 and 50-50 splits. The gap in micro-F1 scores between sMLM and base Longformer for 80-20 split increases from 3 points in mean pooling to 5 points in prompting (0 to 7 points improvements for 50-50 split). As we can observe in Figure <ref type="figure" target="#fig_4">4</ref>, sMLMfinetuned Longformer admits a very narrow margin of variation on random splits, compared to the base Longformer. Furthermore, sMLM finetuning consistently outperforms domain-adapted finetuning (DA-LF), indicating the unique knowledge transfer achieved by the former.</p><p>We hypothesise that this approach works better as this regime models our final RTP task, as a task that is more natural (in a sense similar to the (?, B)-natural tasks of <ref type="bibr" target="#b27">Saunshi et al. (2021)</ref>) for a Longformer model pre-trained with sMLM. Intuitively, the model learns to predict discourse markers at masked positions during sMLM pre-training and during fine-tuning on downstream tasks too, the model will naturally try to predict discourse markers at the masked positions. The discourse markers occurring at the masked positions are directly related to the relation between the two components. For instance, when there is a "but" between two components, we know that the two components present opposing views more or less. Here again, we observe that sMLM does not hurt the base performance under domain shift (Table <ref type="table" target="#tab_3">4</ref>).</p><p>We observe that the RoBERTa model performs worse than Base-LF-prompt, which incorporates the entire context of the thread. Also the effect worsens with reduced training set size, and RoBERTa model performs worse by 7 points in terms of micro-F1 for the 50-50 split. Furthermore, we observe that the mean pooling strategy, even though it uses context, performs worse (by 4 points  former for predicting segments having some markers in "near" (5 tokens on either side of its) boundaries, and the rest of segments ("far").</p><p>on 80-20 split) than the context-less RoBERTa. Though, our sMLM pretrained model, manages to perform at par with the context-less RoBERTa with the mean pooling strategy. This means, that the using the right fine-tuning method is essential. Extra context can be utilised fully in longformer, only when pre-training and fine-tuning tasks are nicely aligned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Dependence on the presence of markers</head><p>Following the analyses presented by <ref type="bibr" target="#b25">Opitz and Frank (2019)</ref>, we investigate whether the presence/absence of the markers used in the sMLM step within the vicinity of the components play any role in the ACI or RTP performances. Since the relation type among component-pairs that reside distant from each other are less likely to be inferred by the presence of markers in the context, we analyse the percentage of wrong predictions as we vary the distance between two related components, in Figure <ref type="figure" target="#fig_5">5</ref>. While error rate does vary proportionally to the distance, we observe that sMLM-LF consistently yields lower percentage of wrong predictions as we vary the distance between the related components compared to base Longformer. This clearly indicates the superior capability induced by the sMLM finetuning to decipher the relationship among components not linked by direct context (i.e., not within a sentence or a single comment).</p><p>For the ACI task, however, we observe that the absence of markers in the vicinity of the components actually enables better identification, both in case of sMLM finetuned and pretrained Longformer (see Table <ref type="table" target="#tab_5">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented the results for two important tasks in the argument mining pipeline, viz., ACI and RTP. The experiments clearly elucidated the importance of alignment between the downstream and pre-trainig tasks, and the effect of various ways of modelling the tasks. The importance of entire thread's context in discussion forums, as well as how to incorporate that into transformer-based models fruitfully has also been made clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Dataset Details</head><p>Stats for the CMV Modes dataset are provided in Table <ref type="table">6</ref>. These stats are obtained after truncation of threads to 4096 token sequence length. During data analysis, we observed that several threads share the same initial post(submission). Hence, we make sure that all threads with the same initial post entirely lie in either the train split, or the test.</p><p>For both CMV Modes, and Dr. Inventor Corpus, we only consider contiguous spans of texts as single components, as opposed to the labelling in the dataset. Discontiguous spans are re-labelled as separate components and the model is trained and tested with these new labels, instead.</p><p>For CMV Modes dataset, we add an extra "continue" class of relations to denote relation between two dis-contiguous spans of same argumentative component annotated in the data. We group together various relation types annotated in the CMV modes data into the 5 broad classes as follows: support("continue" class and "support" class), agreement("agreement", "understand" classes), direct attack("attack", "rebuttal attack", "rebuttal", "disagreement" classes), undercutter attack("undercutter", "undercutter attack" classes), partial("partial agreement", "partial attack", "partial disagreement" classes). These groupings are based on the broad annotation guidelines provided for the annotations of CMV Modes data.</p><p>For Dr. Inventor Corpus, due to the low number of semantically same relations(44) compared to support(4535) and contradicts(564) in the original dataset, we add the label("parts-of-same") which indicates that two dis-contiguous spans belong to the same argumentative component to the semantically same category. We also, merge together sections of papers to efficiently utilise 4096 token length of Longformer model. The detailed statistics after truncation to 4096 sequence length are presented in Table <ref type="table">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details</head><p>We use the pretrained base version of Longformer (12 layers, 768 model size). The size of the local attention window was set to the default 512. The maximum sequence length was fixed at 4096. We added the special tokens that we used, to the pretrained Longformer tokenizer. For ACI our models use a CRF layer<ref type="foot" target="#foot_1">3</ref> . sMLM training for Longformer runs, and error regions correspond to the Bessel corrected standard deviation. The scores reported in the tables for various models correspond to the average value of the mean of 5 runs, over the last 5 epochs for that particular metric.       </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional results</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Token-level claim (red) and premise (blue) annotation of a discussion thread formed by consecutive posts from two users. Second post quotes a span from the first (shown in italics). Highlighted regions signify component boundaries (to demarcate consecutive components of the same kind as in the fourth post).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example of selective masking in a sample CMV thread; sMLM finetuning requires a pretrained language model to predict the masked (highlighted in red) tokens (or all the subwords constituting them) based on the context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3: Example outline of prompt-based relation predic-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>e., if the gold label is [O, B-claim, I-claim, I-claim, I-claim, O] then only the predictions [O, B-claim, I-claim, I-claim, I-claim, O], or [O, Iclaim, I-claim, I-claim, I-claim, O] can be considered as true positives. We use the popular SeqEval (Nakayama, 2018) framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Micro-F1 scores for predicting relation types among argument components by Base and sMLM-finetuned Longformer models over the course of training using (a) 50-50 split and (b) 80-20 split. We use 5 different runs on random splits for each model to report the mean (solid lines) and variance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Percentage of erroneous classifications for RTP for Base-LF-prompt and LF-sMLM-prompt on component-pairs at different distances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: On CMV Modes data, sMLM-LF-mp's mean F1 converges to 0.59 compared to 0.56 for Base-LF-mp in 80-20 split (a) and 0.56 in 50-50 split (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Change in sMLM-LF performance on CMV Modes RTP (a) 80-20 and (b) 50-50 split when number of mask tokens in the prompt is changed from 3 to 2. The model with 2 masked token converges to 0.70 (0.66) and the mean for 3 masked tokens converges to 0.67 (0.69).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Contextless Roberta's mean f1 converges to around 0.599, compared to 0.62 of Base Longformer on RTP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 9: Contextless Roberta's mean f1 converges to around 0.55, compared to 0.617 of Base Longformer on RTP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Both Base LF and our sMLM pretrained Longformer converge to an f1 of 0.85 with promptbased RTP on Dr. Inventor corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Results on Dr. Inventor dataset for argument component identification using sMLM-finetuned and base Longformer models.</figDesc><table><row><cell>Model</cell><cell></cell><cell>P</cell><cell>Claim R</cell><cell>F1</cell><cell>P</cell><cell>Premise R</cell><cell>F1</cell><cell cols="2">F1 Acc</cell></row><row><cell>sMLM-LF</cell><cell></cell><cell cols="8">0.49 0.57 0.53 0.61 0.67 0.64 0.59 0.74</cell></row><row><cell>Base-LF</cell><cell></cell><cell cols="8">0.50 0.50 0.50 0.58 0.64 0.61 0.56 0.74</cell></row><row><cell cols="10">sMLM-RoBERTa 0.49 0.60 0.53 0.55 0.57 0.55 0.55 0.72</cell></row><row><cell>RoBERTa</cell><cell></cell><cell cols="8">0.49 0.55 0.51 0.56 0.62 0.59 0.56 0.73</cell></row><row><cell>BERT</cell><cell></cell><cell cols="8">0.21 0.25 0.23 0.19 0.26 0.22 0.22 0.62</cell></row><row><cell cols="2">LSTM-MData</cell><cell cols="8">0.19 0.18 0.18 0.26 0.23 0.24 0.22 0.54</cell></row><row><cell>LSTM-MTL</cell><cell></cell><cell cols="8">0.19 0.18 0.18 0.24 0.25 0.24 0.21 -</cell></row><row><cell cols="10">Table 1: Performance of different models on ACI-task on</cell></row><row><cell cols="10">CMV Modes dataset (P: Precision, R: Recall, F1: F1 score).</cell></row><row><cell cols="10">The F1 and Acc. in the rightmost columns denote the micro-</cell></row><row><cell cols="10">averaged F1 score over claims and premises and the token</cell></row><row><cell cols="10">level accuracy of predicting argumentative tags, respectively.</cell></row><row><cell>Model</cell><cell>P</cell><cell>BC R</cell><cell>F1</cell><cell>P</cell><cell>OC R</cell><cell>F1</cell><cell>P</cell><cell>Data R</cell><cell>F1</cell></row><row><cell cols="10">sMLM-LF 0.45 0.52 0.48 0.39 0.45 0.42 0.50 0.48 0.48</cell></row><row><cell cols="10">Base-LF 0.49 0.51 0.50 0.38 0.50 0.43 0.44 0.44 0.44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Relation type wise Precision (P), Recall (R) and F1 score on the CMV Modes dataset for various models. The highest scores in every column are in bold. The suffix "mp" and "prompt" indicate that the model was trained using Mean Pooling and Prompting strategies, respectively. The F1 in last column is the Micro/weighted-F1 over all the prediction classes.</figDesc><table><row><cell>Relation</cell><cell cols="3">Base-LF-prompt</cell><cell cols="3">sMLM-LF-prompt</cell></row><row><cell>types</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Support</cell><cell>0.91</cell><cell>0.90</cell><cell>0.91</cell><cell>0.89</cell><cell>0.92</cell><cell>0.91</cell></row><row><cell>Contradict</cell><cell>0.60</cell><cell>0.60</cell><cell>0.60</cell><cell>0.65</cell><cell>0.55</cell><cell>0.60</cell></row><row><cell>Semantically same</cell><cell>0.74</cell><cell>0.77</cell><cell>0.75</cell><cell>0.77</cell><cell>0.75</cell><cell>0.77</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Relation Type wise Precision (P), Recall (R) and F1 score on Dr. Inventor Corpus for prompt-based relation prediction using sMLM and base Longformer models.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Performance of base Longformer and sMLM Long-</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 :</head><label>8</label><figDesc>Types and examples of different discourse markers used for selective MLM finetuning.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Table 8 provides examples of markers of various kinds, that are masked during the sMLM training.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The source codes and datasets have been submitted separately.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>We use the implementation of AllenNLP<ref type="bibr" target="#b10">(Gardner et al., 2018)</ref> </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors would like to thank <rs type="person">Chris Hidey</rs> and <rs type="person">Smaranda Muresan</rs>, for clarifications providing regarding their work. T. Chakraborty would like to acknowledge the support of <rs type="funder">Ramanujan Fellowship, CAI, IIIT-Delhi and ihub-Anubhuti-iiitd Foundation</rs> set up under the <rs type="grantName">NM-ICPS</rs> scheme of the <rs type="institution">Department of Science and Technology, India</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cTEWNM2">
					<orgName type="grant-name">NM-ICPS</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>based models was done on thread level and for BERT and RoBERTa based models on commentlevel. We used mini-batch learning; approximately similar length input threads were batched together keeping the total number of tokens per batch fixed to 8, 194 for Longformer and 1024 for BERT and RoBERTa models, and accumulated gradients over 3 batches. We trained our models for a total of 10 epochs on sMLM task, while saving checkpoints after each epoch. We used Adam optimizer with a learning rate of 10 -6 . For all downstream tasks, we train our models for 30 epochs, again, with Adam optimizer with learning rate of 2e -5 as suggested by <ref type="bibr" target="#b22">Mosbach et al. (2021)</ref>. We use same batch sizes as sMLM training and accumulate gradients over 4 batches. We observe that for prompting RTP on CMV-Modes, not making [USER-i] tokens global, leads to better performance, hence we report results for same.</p><p>We find that sMLM training for 4 epochs is most beneficial, for performance on downstream task. Hence, we report results for the same checkpoint. Following the suggestions in Reimers and Gurevych (2017), we repeat our experiments on 5 different data splits and present the distributions in the Appendix. For the results at any epoch, the score plotted corresponds to mean over the 5</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Crossdomain mining of argumentative text through distant supervision</title>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1165</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1395" to="1404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2020. 2004.05150v2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">AMPERSAND: Argument mining for PER-SuAsive oNline discussions</title>
		<author>
			<persName><forename type="first">Tuhin</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hidey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alyssa</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1291</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2933" to="2943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Chiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liye</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justine</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Convokit: A toolkit for the analysis of conversations</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TARGER: Neural argument mining at your fingertips</title>
		<author>
			<persName><forename type="first">Artem</forename><surname>Chernodub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksiy</forename><surname>Oliynyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Heidenreich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-3031</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Changing views: Persuasion modeling and argument extraction from online discussions</title>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.102085</idno>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102085</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the role of discourse markers for discriminating claims and premises in argumentative discourse</title>
		<author>
			<persName><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Kluge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1267</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2236" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Annotating and analyzing semantic role of elementary units and relations in online persuasive arguments</title>
		<author>
			<persName><forename type="first">Ryo</forename><surname>Egawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaku</forename><surname>Morio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katsuhide</forename><surname>Fujita</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-2059</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="422" to="428" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural end-to-end learning for computational argumentation mining</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Allennlp: A deep semantic natural language processing platform</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analyzing argumentative discourse units in online interactions</title>
		<author>
			<persName><forename type="first">Debanjan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Wacholder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Aakhus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Mitsui</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W14-2106</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting debate portals for semi-supervised argumentation mining in user-generated web discourse</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1255</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2127" to="2137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Argumentation Mining in User-Generated Web Discourse</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.1162/COLI_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="179" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Analyzing the semantic types of claims and premises in an online persuasive forum</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hidey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Musi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alyssa</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Mckeown</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-5102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Argument Mining</title>
		<meeting>the 4th Workshop on Argument Mining<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An argument-annotated corpus of scientific publications</title>
		<author>
			<persName><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Glava?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ponzetto</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5206</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Argument Mining</title>
		<meeting>the 5th Workshop on Argument Mining<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="40" to="46" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Argument mining: A survey</title>
		<author>
			<persName><forename type="first">John</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Reed</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli_a_00364</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="765" to="818" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Argument mining: A machine learning perspective</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory and Applications of Formal Argumentation</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="163" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Roberta: A robustly optimized bert pretraining approach</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Lytos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lagkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panagiotis</forename><surname>Sarigiannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.102055</idno>
		<title level="m">The evolution of argumentation mining: From models to social media and emerging tools. Information Processing &amp; Management</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page">102055</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transformer-based argument mining for healthcare applications</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
		<idno type="DOI">10.3233/FAIA200334</idno>
	</analytic>
	<monogr>
		<title level="m">Including 10th Conference on Prestigious Applications of Artificial Intelligence</title>
		<title level="s">Frontiers in Artificial Intelligence and Applications</title>
		<meeting><address><addrLine>Santiago de Compostela, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2020-08-08">2020. August-8 September 2020. August 29 -September 8, 2020</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2108" to="2115" />
		</imprint>
	</monogr>
	<note>ECAI 2020 -24th European Conference on Artificial Intelligence. PAIS 2020</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">On the stability of fine-tuning bert: Misconceptions, explanations, and strong baselines</title>
		<author>
			<persName><forename type="first">Marius</forename><surname>Mosbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">seqeval: A python framework for sequence labeling evaluation</title>
		<author>
			<persName><forename type="first">Hiroki</forename><surname>Nakayama</surname></persName>
		</author>
		<ptr target="https://github.com/chakki-works/seqeval" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Software available from</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DisSent: Learning sentence representations from explicit discourse relations</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erin</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1442</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4497" to="4510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dissecting content and context in argumentative relation analysis</title>
		<author>
			<persName><forename type="first">Juri</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-4503</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Argument Mining</title>
		<meeting>the 6th Workshop on Argument Mining<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2019. 2017</date>
		</imprint>
	</monogr>
	<note>Language models are unsupervised multitask learners. Nils Reimers and Iryna Gurevych</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A mathematical exploration of why language models help solve downstream tasks</title>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadhika</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-task learning for argumentation mining in low-resource settings</title>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Kahse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2006</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Short Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Parsing Argumentation Structures in Persuasive Essays</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.1162/COLI_a_00295</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="619" to="659" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions</title>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/2872427.2883081</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web, WWW &apos;16</title>
		<meeting>the 25th International Conference on World Wide Web, WWW &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="613" to="624" />
		</imprint>
		<respStmt>
			<orgName>Canton of Geneva</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adaptive self-training for few-shot neural sequence labeling</title>
		<author>
			<persName><forename type="first">Yaqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoda</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuancheng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Wu</surname></persName>
		</author>
		<idno>CoRR, abs/2010.03680v2</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Jing Gao, and Ahmed Hassan Awadallah</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
