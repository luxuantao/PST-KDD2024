<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A new improved krill herd algorithm for global numerical optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lihong</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Changchun Institute of Optics, Fine Mechanics and Physics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>130033</postCode>
									<settlement>Changchun</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gai-Ge</forename><surname>Wang</surname></persName>
							<email>gaigewang@163.com</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Jiangsu Normal University</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><forename type="middle">H</forename><surname>Gandomi C</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Civil Engineering</orgName>
								<orgName type="institution">University of Akron</orgName>
								<address>
									<postCode>443253905</postCode>
									<settlement>Akron</settlement>
									<region>OH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
							<email>ah_alavi@hotmail.com</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<addrLine>Engineering Building</addrLine>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Duan</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Education College</orgName>
								<orgName type="institution">Shihezi University</orgName>
								<address>
									<postCode>832000</postCode>
									<settlement>Shihezi</settlement>
									<region>Xinjiang</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A new improved krill herd algorithm for global numerical optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">37929A75CB500376E3C75F4D08C961D7</idno>
					<idno type="DOI">10.1016/j.neucom.2014.01.0230925-2312</idno>
					<note type="submission">Received 13 October 2012 Received in revised form 12 January 2013 Accepted 23 January 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Global optimization problem Krill herd Exchange information Multimodal function</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This study presents an improved krill herd (IKH) approach to solve global optimization problems. The main improvement pertains to the exchange of information between top krill during motion calculation process to generate better candidate solutions. Furthermore, the proposed IKH method uses a new Lévy flight distribution and elitism scheme to update the KH motion calculation. This novel meta-heuristic approach can accelerate the global convergence speed while preserving the robustness of the basic KH algorithm. Besides, the detailed implementation procedure for the IKH method is described. Several standard benchmark functions are used to verify the efficiency of IKH. Based on the results, the performance of IKH is superior to or highly competitive with the standard KH and other robust population-based optimization methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In computer science, mathematics, and computational science, the process of optimization is searching for a vector in a function that produces an optimal solution. All of feasible values are available solutions and the extreme value is optimal solution. In general, optimization algorithms have been applied to solve optimization problems <ref type="bibr" target="#b0">[1]</ref>. A simple classification way for optimization algorithms is considering the nature of the algorithms. The optimization algorithms can be divided into two main categories: deterministic algorithms, and stochastic algorithms. Deterministic algorithms using gradient such as hill-climbing have a rigorous move, and will generate the same set of solutions if the iterations commence with the same initial starting point. On the other hand, stochastic algorithms without using gradient often generate different solutions even with the same initial value. However, generally speaking, the final values, though slightly different, will converge to the same optimal solutions within a given accuracy.</p><p>The recently nature-inspired meta-heuristic algorithms perform powerfully and efficiently in solving modern nonlinear numerical global optimization problems. To some extent, all meta-heuristic algorithms strive for making balance between randomization (global search) and local search <ref type="bibr" target="#b1">[2]</ref>.</p><p>Inspired by nature, the strong meta-heuristic algorithms are applied to solve NP-hard problems such as parameter estimation <ref type="bibr" target="#b2">[3]</ref>, system identification <ref type="bibr" target="#b3">[4]</ref>, WSN dynamic deployment <ref type="bibr" target="#b4">[5]</ref>, UCAV path planning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, test-sheet composition <ref type="bibr" target="#b7">[8]</ref>, and water, geotechnical and transport engineering <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. During the 1950s and 1960s, computer scientists studied the possibility of conceptualizing evolution as an optimization tool and this generated a subset of gradient free approaches named genetic algorithms (GAs) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Since then many other nature-inspired meta-heuristic algorithms have emerged, such as ant colony optimization (ACO) <ref type="bibr" target="#b12">[13]</ref>, differential evolution (DE) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>, bat algorithm (BA) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, harmony search (HS) <ref type="bibr" target="#b17">[18]</ref>, and particle swarm optimization (PSO) <ref type="bibr" target="#b18">[19]</ref>.</p><p>Recently, Gandomi and Alavi <ref type="bibr" target="#b19">[20]</ref> proposed krill herd (KH) algorithm which is based on the simulation of the herding behavior of krill individuals in nature. In KH, the objective function for the krill movement is determined by the minimum distances of each individual krill from food and from highest density of the herd. The time-dependent position of the krill individuals is comprised of three main components: (i) movement induced by other individuals (ii) foraging motion, and (iii) random physical diffusion. One of remarkable advantage of the KH algorithm is that Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/neucom the derivative information is not necessary because it uses a stochastic random search rather than a gradient search. The other important advantage of the KH algorithm is its simplicity. Comparing with other population-based meta-heuristic algorithms, this new approach requires few control variables, in essence only a single parameter C t (time interval) to regulate (apart from the population size). This feature makes KH easy to implement, more robust, and very appropriate for parallel computation.</p><p>KH is a powerful algorithm in exploitation (i.e., local search) but at times it may trap into some local optima so that it cannot perform global search well <ref type="bibr" target="#b19">[20]</ref>. For KH, the search depends completely on random walks, so a fast convergence cannot be guaranteed. In order to better KH in optimization problems, two methods have been proposed <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, which introduces mutation scheme into KH to add the diversity of population.</p><p>Cuckoo search (CS) is another new meta-heuristic search algorithm based on the obligate brood parasitic behavior of some cuckoo species in combination with the Lévy flight behavior of some birds and fruit flies <ref type="bibr" target="#b22">[23]</ref>. Walton et al. <ref type="bibr" target="#b23">[24]</ref> improved the basic CS algorithm and introduced modified CS (MCS) method. The fist improvement was to adopt the size of the Lévy flight step size instead of a constant step size used in the CS method. The second improvement was to add information exchange between the eggs in an effort to accelerate convergence to the best solutions. In MCS, a fraction of the eggs with the best fitness were put together to form a group of top eggs. Also, all the cuckoos could exchange information through top eggs <ref type="bibr" target="#b23">[24]</ref>.</p><p>The described information exchange concept is introduced to the KH algorithm to develop an improved KH (IKH) method. The main goal is to speed up the algorithm convergence and therefore to provide a more efficient tool for a wider range of practical applications while preserving the attractive characteristics of the basic KH method. Besides, IKH adopts a new Lévy flight distribution and elitism scheme to update the KH motion calculation. The proposed approach is evaluated on 14 standard benchmark functions. Experimental results show that IKH performs better than the basic KH, GA, BA, CS, DE, HS, PSO, probability-based incremental learning (PBIL), and artificial bee colony (ABC) optimization methods.</p><p>The structure of this paper is organized as follows: Section 2 describes global numerical optimization problem and the basic KH algorithm in brief. The proposed IKH approach is presented in detail in Section 3. Subsequently, Section 4 presents the validity verification of IKH against different benchmark functions and various optimization algorithms. Finally, Section 5 consists of the conclusion and proposals for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminary</head><p>In this section, we will provide a brief background on the optimization problem and KH algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Optimization problem</head><p>In computer science, mathematics, and management science, optimization means the selection of an optimal solution from some set of feasible alternatives. In general, an optimization problem includes minimizing or maximizing a function by systematically selecting input values from a given feasible set and calculating the value of the function. More generally, optimization consists of finding the optimal values of some objective function within a given domain, including a number of different types of domains and different types of objective functions.</p><p>A global optimization problem can be described as follows:</p><p>Given: a function f: S-R from some set S to the real numbers Sought: a parameter x 0 in S such that f(x 0 )rf(x) for all x in S ("minimization") or such that f(x 0 )Zf(x) for all x in S ("maximization").</p><p>Such a formulation is named a numerical optimization problem. Many theoretical and practical problems may be modeled in this general framework. In general, S is some subset of the Euclidean space R n , often specified by a group of constraints, equalities or inequalities that the components of S have to satisfy. The domain S of f is named the search space, while the elements of S are named feasible solutions or candidate solutions. In general, the function f is called an objective function, utility function (maximization), or cost function (minimization). An optimal solution is an available solution that is the extreme of (minimum or maximum) the objective function.</p><p>Conventionally, the standard formulation of an optimization problem is stated in accordance with minimization. In general, unless both the feasible region and the objective function are convex in a minimization problem, there may be more than one local minima. A global minimum x* is defined as a point for which the following expression</p><formula xml:id="formula_0">f ðx*Þ r f ðxÞ ð<label>1Þ</label></formula><p>holds <ref type="bibr" target="#b20">[21]</ref>.</p><p>A variety of algorithms have been proposed to solve nonconvex problems. Among them, heuristics algorithms can evaluate approximate solutions to some optimization problems, as described in introduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Krill herd algorithm</head><p>KH is a novel meta-heuristic swarm intelligence optimization method for solving optimization problems <ref type="bibr" target="#b19">[20]</ref>. This method is based on the simulation of the herding of the krill swarms in response to specific biological and environmental processes. The time-dependent position of an individual krill in twodimensional surface is determined by three main actions described as follows:</p><p>(i) movement induced by other krill individuals; (ii) foraging action; and (iii) random diffusion.</p><p>In KH, the Lagrangian model is used in a d-dimensional decision space as shown in Eq. (2) <ref type="bibr" target="#b19">[20]</ref>.</p><formula xml:id="formula_1">dX i dt ¼ N i þF i þ D i<label>ð2Þ</label></formula><p>where N i is the motion induced by other krill individuals; F i is the foraging motion, and D i is the physical diffusion of the ith krill individuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Motion induced by other krill individuals</head><p>The direction of motion induced, α, is approximately evaluated by the target swarm density (target effect), a local swarm density (local effect), and a repulsive swarm density (repulsive effect). For a krill individual, this movement can be defined as <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_2">N new i ¼ N max α i þ ω n N old i<label>ð3Þ</label></formula><p>where</p><formula xml:id="formula_3">α i ¼ α local i þ α target i<label>ð4Þ</label></formula><p>and N max is the maximum induced speed, ω n is the inertia weight of the motion induced in [0, 1], N old i is the last motion induced, α local i is the local effect provided by the neighbors and</p><formula xml:id="formula_4">α target i</formula><p>is the target direction effect provided by the best krill individual. According to the experimental values of the maximum induced speed, we set N max to 0.01 (ms À 1 ) in our study <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Foraging motion</head><p>The foraging motion is influenced by the two main factors. One factor is the food location and the other one is the previous experience about the food location. For the ith krill individual, this motion can be expressed as follows <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_5">F i ¼ V f β i þω f F old i<label>ð5Þ</label></formula><p>where</p><formula xml:id="formula_6">β i ¼ β f ood i þ β best i<label>ð6Þ</label></formula><p>and V f is the foraging speed, ω f is the inertia weight of the foraging motion between 0 and 1, F old i is the last foraging motion, β f ood i is the food attractive and β best i is the effect of the best fitness of the ith krill so far. In our study, we set V f to 0.02 <ref type="bibr" target="#b19">[20]</ref>.</p><p>In KH, the virtual center of food concentration is approximately calculated according to the fitness distribution of the krill individuals, which is inspired from "center of mass". The center of food for each iteration is estimated as follows <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_7">X f ood ¼ ∑ N i ¼ 1 ð1=K i ÞX i ∑ N i ¼ 1 1=K i<label>ð7Þ</label></formula><p>where K i represents the fitness or the objective function value of the ith krill individual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Physical diffusion</head><p>The physical diffusion of the krill individuals is considered to be a random process. This motion can be expressed in terms of a maximum diffusion speed and a random directional vector. It can be formulated as follows <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_8">D i ¼ D max δ<label>ð8Þ</label></formula><p>where D max is the maximum diffusion speed, and δ is the random directional vector and its arrays are random values in [ À 1, 1]. The better the position of the krill is, the less random the motion is. The effects of the motion induced by other krill individuals and foraging motion gradually decrease with increasing the time (iterations). Thus, another term (Eq. ( <ref type="formula" target="#formula_9">9</ref>)) <ref type="bibr" target="#b19">[20]</ref> is added to Eq. ( <ref type="formula" target="#formula_8">8</ref>). This term linearly decreases the random speed with the time and performs on the basis of a geometrical annealing schedule <ref type="bibr" target="#b24">[25]</ref>:</p><formula xml:id="formula_9">D i ¼ D max 1 À 1 I max δ<label>ð9Þ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4.">Main procedure of the KH algorithm</head><p>In general, the defined motions frequently change the position of a krill individual toward the best fitness. The foraging motion and the motion induced by other krill individuals contain two global and two local strategies. These are working in parallel which make KH a powerful algorithm. Using different effective parameters of the motion during the time, the position vector of a krill individual during the interval t to t þΔt is expressed by the following equation <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_10">X i ðt þ ΔtÞ ¼ X i ðtÞþΔt dX i dt<label>ð10Þ</label></formula><p>It should be noted that Δt is one of the most important constants and should be carefully set according to the optimization problem. This is because this parameter works as a scale factor of the speed vector.</p><p>In addition, to improve the performance of the KH, genetic reproduction mechanisms are incorporated into the algorithm. The introduced adaptive genetic reproduction mechanisms are crossover and mutation which are inspired from the classical DE algorithm.</p><p>Algorithm 1. Krill herd algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin</head><p>Step 1: Initialization. Set the generation counter G ¼1; initialize the population P of NP krill individuals randomly and each krill corresponds to a potential solution to the given problem; set the foraging speed V f , the maximum diffusion speed D max , and the maximum induced speed N max .</p><p>Step 2: Fitness evaluation. Evaluate each krill individual according to its position.</p><p>Step 3: While the termination criteria is not satisfied or G oMaxGeneration do Sort the population/krill from best to worst. The basic representation of the KH can be summarized as shown in Algorithm 1. More details about the three main motions and KH algorithm can be found in <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed IKH approach</head><p>Similar to the strategy proposed in <ref type="bibr" target="#b23">[24]</ref> for improving CS, this study introduces an information exchange concept between top krill during the motion calculation process. This results in improving the IKH method while it keeps the attractive features of the original KH method.</p><p>Algorithm 2. The algorithm of exchanging information among top krill.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin</head><p>Step 1: Set max Lévy flight step size A and golden ratio φ.</p><p>Step For the KH algorithm, the search depends completely on random walks, thus a fast convergence cannot be guaranteed. To cope with this issue, new features are added to KH.</p><p>The first improvement is adding Lévy flight to KH with the step size α. Moreover, in the IKH, the value of α declines as the procedure proceeds (increasing generations). This is done for the similar reasons that the inertia constant is declined in the PSO <ref type="bibr" target="#b18">[19]</ref> and basic KH algorithm <ref type="bibr" target="#b19">[20]</ref>, i.e., to stimulate more localized searching as the krill, get closer to the solution.</p><p>Algorithm 3. Improved KH algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin</head><p>Step The second improvement is to add information exchange between the krill in an attempt to accelerate the convergence speed to the best solution. In KH, there is no information exchange between krill and the searches are implemented independently in essence, i.e., different krill work almost independently <ref type="bibr" target="#b19">[20]</ref>. In the IKH, portions of the krill with the best fitness are made up of a group of top krill. For every top krill, a second krill in this group is selected randomly and a new krill is then produced on the line connecting these two top krill. The distance along this line at which the new krill is situated is calculated, using the inverse of the golden ratio φ</p><formula xml:id="formula_11">¼ ð1 þ ffiffiffi 5 p</formula><p>Þ=2, such that it is closer to the krill with the best fitness. In the case that both krill have the same fitness, the new krill is produced at the middle point. In this step, there is a possibility that, the same krill is selected twice. In this case, a local Lévy flight search is carried out from the randomly selected krill with step size α¼A/G 2 . The detailed procedure for exchanging information between top krill involved in the improved krill herd algorithm is presented in Algorithm 2, and the basic framework of improved krill herd algorithm can be simply described as shown in Algorithm 3. In IKH, ⌈NPnp a ⌉ is an integer number whose value is not more than NPnp a . From Algorithm 2 and Algorithm 3, it is clear that there is only one parameter, the parameter of the fraction of krill to make up the top krill, which needs to be regulated in IKH. Through testing on benchmarking functions, it was found that setting the parameter of the fraction of krill placed in the top krill group to 0.25 produced the best results through a series of simulation experiments.</p><p>The third improvement is the addition of elitism scheme into IKH. As considered for other population-based optimization algorithms, we typically incorporate some sort of elitism in order to retain the best solutions in the population. This prevents the best solutions from being corrupted by motion calculation operator. Note that we use an elitism approach to save the property of the krill that has the best fitness in the IKH process. Hence, even if the motion calculation operation ruins its corresponding krill, we have saved it and can revert back to it if needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Simulation experiments</head><p>In this section, we test the performance of the proposed metaheuristic IKH algorithm through a series of experiments. In the following experiments, IKH1, IKH2, and IKH3 are corresponding to the three improvements discussed in Section 3, respectively.</p><p>To allow a fair comparison of running times, all the experiments were conducted on a PC with a Pentium IV processor running at 2.0 GHz, 512 MB of RAM and a hard drive of 160 Gbytes. Our implementation was compiled using MATLAB R2012a (7.14) running under Windows XP3. No commercial KH tool was used in the following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">General performance of IKH</head><p>In order to explore the benefits of IKH, we compared with nine other population-based optimization methods, which are ABC, BA, CS, DE, GA, HS, PBIL, and PSO. <ref type="bibr" target="#b25">[26]</ref> is a classical swarm intelligence method based on the smart behavior of honey bee swarm. BA <ref type="bibr" target="#b26">[27]</ref> is a novel powerful meta-heuristic optimization method inspired by the echolocation behavior of bats with varying pulse rates of emission and loudness. CS <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28]</ref> is a meta-heuristic optimization approach inspired by the obligate brood parasitism of some cuckoo species by laying their eggs in the nests of other host birds. DE <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> is a simple but excellent optimization method that uses the difference between two solutions to probabilistically adapt a third solution. An ES <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> is an algorithm that generally distributes equal importance to mutation and recombination, and that allows two or more parents to reproduce an offspring. A GA <ref type="bibr" target="#b10">[11]</ref> is a search heuristic that mimics the process of natural evolution. HS <ref type="bibr" target="#b32">[33]</ref> is a new meta-heuristic method inspired by behavior of musician' improvisation process. PBIL <ref type="bibr" target="#b33">[34]</ref> is a type of genetic algorithm where the genotype of an entire population (probability vector) is evolved rather than individual members. PSO <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b34">35]</ref> is also a swarm intelligence algorithm which is based on the swarm behavior of fish, and bird schooling in nature. It is worth mentioning that according to Gandomi and Alavi <ref type="bibr" target="#b19">[20]</ref>, the KH II (KH with crossover operator) has the best performance. Therefore, in this study, we use II as the basic KH algorithm.</p><p>In all experiments, we will use the same parameters for KH and IKH that are the fraction of krill placed in the top krill group p a ¼0.25, the foraging speed V f ¼0.02, the maximum diffusion speed D max ¼0.005, the maximum induced speed N max ¼ 0.01. In addition, the inertia weights (ω n , ω f ) are equal to 0.9 at the beginning of the search to emphasize exploration. These two parameters are linearly decreased to 0.1 at the end to encourage exploitation <ref type="bibr" target="#b19">[20]</ref>. For DE, GA, PBIL and PSO, we set the parameters as follows <ref type="bibr" target="#b35">[36]</ref>. For ABC, the number of colony size (employed bees and onlooker bees) NP¼ 50, the number of food sources Food Number ¼NP/2, maximum search times limit ¼ 100 (a food source which could not be improved through "limit" trials is abandoned by its employed bee). For BA, we set loudness A¼ 0.95, pulse rate r ¼0.5, and scaling factor ε¼0.1; for CS, a discovery rate p¼ 0.25.</p><p>For HS, we set harmony memory accepting rate¼ 0.75, and pitch adjusting rate¼ 0.7.</p><p>Well-defined problem sets are favorable for evaluating the performance of optimization methods proposed in this paper. Based on mathematical functions, benchmark functions can be applied as objective functions to perform such tests. The properties of these benchmark functions can be easily achieved from their definitions. Fourteen different benchmark functions are applied to verify our proposed meta-heuristic IKH algorithm. The benchmark functions described in Table <ref type="table" target="#tab_2">1</ref> are standard testing functions. The properties of the benchmark functions are given in Table <ref type="table" target="#tab_4">2</ref>. The modality property means the number of the best solutions in the search space. More details of all the benchmark functions can be found in <ref type="bibr" target="#b36">[37]</ref>.</p><p>We set population size NP ¼50 and maximum generation Maxgen ¼50 for each algorithm. We ran 100 Monte Carlo simulations of each algorithm on each benchmark function to get representative performances. Tables <ref type="table" target="#tab_5">3</ref> and<ref type="table" target="#tab_6">4</ref> illustrate the results of the simulations. Table <ref type="table" target="#tab_5">3</ref> shows the average minima found by each algorithm, averaged over 100 Monte Carlo runs. Table <ref type="table" target="#tab_6">4</ref> shows the absolute best minima found by each algorithm over 100 Monte Carlo runs. In other words, Table <ref type="table" target="#tab_5">3</ref> shows the average performance of each algorithm, while Table <ref type="table" target="#tab_6">4</ref> shows the best </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No</head><p>Name Definition performance of each algorithm. The best value achieved for each test problem is shown in bold. Note that the normalizations in the tables are based on different scales, so values cannot be compared between the two tables. Each of the functions in this study has 20 independent variables (i.e., d ¼20).</p><formula xml:id="formula_12">F01 Ackley f ð x ! Þ ¼ 20 þ e À 20 U e À 0:2 U ffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 1 n ∑ n i ¼ 1 x 2 i p À e 1 n ∑ n i ¼ 1 cos ð2πxi Þ F02 Fletcher-Powell f ð x ! Þ ¼ ∑ n i ¼ 1 ðA i À B i Þ 2 ; A i ¼ ∑ n j ¼ 1 ða ij sin α j þ b ij cos α j Þ B i ¼ ∑ n j ¼ 1 ða ij sin x j þ b ij cos x j Þ F03 Griewank f ð x ! Þ ¼ ∑ n i ¼ 1 x 2 i 4000 À ∏ n i ¼ 1 cos xi ffi i p þ 1 F04 Penalty #1 f ð x ! Þ ¼ π 30 10 sin 2 ðπy 1 Þþ∑ n À 1 i ¼ 1 ðy i À 1Þ 2 d½1þ 10 sin 2 ðπy i þ 1 Þ n þðy n À 1Þ 2 o þ ∑ n i ¼ 1 uðx i ; 10; 100; 4Þ; y i ¼ 1 þ 0:25ðx i þ 1Þ F05 Penalty #2 f ð x ! Þ ¼ 0:1 sin 2 ð3πx 1 Þþ∑ n À 1 i ¼ 1 ðx i À 1Þ 2 d½1 þ sin 2 ð3πx i þ 1 Þ n þðxn À 1Þ 2 ½1 þ sin 2 ð2πxnÞ o þ ∑ n i ¼ 1 uðx i ; 5; 100; 4Þ F06 Quartic with noise f ð x ! Þ ¼ ∑ n i ¼ 1 ðiU x 4 i þ Uð0; 1ÞÞ F07 Rastrigin f ð x ! Þ ¼ 10 U n þ ∑ n i ¼ 1 ðx 2 i À 10 U cos ð2πx i ÞÞ F08 Rosenbrock f ð x ! Þ ¼ ∑ n À 1 i ¼ 1 ½100ðx i þ 1 À x 2 i Þ 2 þðx i À 1Þ 2 F09 Schwefel 2.26 f ð x ! Þ ¼ 418:9829 Â D À ∑ D i ¼ 1 x i sin ðjx i j 1=2 Þ F10 Schwefel 1.2 f ð x ! Þ ¼ ∑ n i ¼ 1 ∑ i j ¼ 1 x j 2 F11 Schwefel 2.22 f ð x ! Þ ¼ ∑ n i ¼ 1 jx i jþ∏ n i ¼ 1 jx i j F12 Schwefel 2.21 f ð x ! Þ ¼ max i jx i j; 1 r i r n È É F13 Sphere f ð x ! Þ ¼ ∑ n i ¼ 1 x 2 i F14 Step f ð x ! Þ ¼ 6 U n þ ∑ n i ¼ 1 x i b c</formula><p>From Table <ref type="table" target="#tab_5">3</ref>, we see that, on average, IKH1 and IKH2 perform slightly different and are the most effective at finding objective function minimum on six of the 14 benchmarks (F06, F07, F10, F11, F13-F14 and F02-F05, F08, F14). IKH3 is the second most effective, performing best on two of the 14 benchmarks (F01 and F12); while GA is the third most effective, performing best on one benchmark (F09) when multiple runs are made. For the best solutions, Table <ref type="table" target="#tab_6">4</ref> shows that IKH2 has the best performance on nine of the 14 benchmarks (F02-F07, F10, F13, and F14). IKH1 and IKH3 are the second most effective, performing the best on two of the 14 benchmarks F08, F11 and F01, F12 when multiple runs are made respectively. GA is the third most effective, performing the best on only one benchmark F09 when multiple runs are made. In addition, statistical analysis on these values obtained by the 10 methods on 14 benchmark functions based on the Friedman's test <ref type="bibr" target="#b37">[38]</ref> reveals that the differences in the obtained average and best function minima are statistically significant (p ¼1.64 Â 10 À 17 and p ¼7.06 Â 10 À 17 , respectively) at the confidence level of 5%. Furthermore, to further prove the merits of the proposed IKH method, convergence plots of ABC, BA, CS, DE, GA, HS, IKH1, IKH2, IKH3, KH, PBIL, and PSO are illustrated in this section. However, here only some most representative benchmarks are illustrated Figs. <ref type="figure">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>. The solutions shown in Figs. <ref type="figure">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>are the average objective function minimum obtained from 100 Monte Carlo simulations, which are the accurate objective function solution, not normalized. In addition, note that the best solutions of the benchmarks (F04, F05, and F14) are represented in the form of the semi-logarithmic convergence plots. We use KH short for KH II in the legend of Figs. <ref type="figure">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>.</p><p>Fig. <ref type="figure">1</ref> shows the results obtained for the 12 methods when the F01 Ackley function is applied. This is a multimodal function with a narrow global minimum basin (F01 min ¼ 0) and many minor local optima. From Fig. <ref type="figure">1</ref>, we can draw the conclusion that, IKH3 is significantly superior to the other algorithms during the process of optimization, while IKH1 and IKH2 performs the second and the third best in this multimodal benchmark function, respectively. Fig. <ref type="figure">2</ref> shows the results for F04 Penalty #1 function. From Fig. <ref type="figure">2</ref>, apparently, IKH2 outperforms all other methods in this example. At last, IKH1 converges to the value that is very close to IKH2's. While, IKH1 performs the fourth best that is inferior to CS. Fig. <ref type="figure">3</ref> shows the results for F05 Penalty #2 function. From Fig. <ref type="figure">3</ref>, for this multimodal function, very similar to F02 Penalty #1 function, IKH2 performs the best that outperforms all other methods during the process of optimization, and IKH1 performs the second best that slightly inferior to IKH2 among 12 methods. Fig. <ref type="figure">4</ref> shows the optimization results for the F07 Rastrigin function, which is a complex multimodal problem with a unique global minimum of F07 min ¼0 and a large number of local optima. When attempting to solve F07, methods may easily trap into a local optimum. Hence, a method capable of maintaining a larger diversity is likely to produce better results. As can be seen in Fig. <ref type="figure">4</ref>, there is little difference between the performance of IKH1 and IKH2. However, carefully studying Table <ref type="table" target="#tab_5">3</ref> and Fig. <ref type="figure">4</ref>, we can conclude that, IKH1 performs slightly better than IKH2 in this multimodal function. For the other algorithms, similar to IKH1 and IKH2, there is little difference between the performance of ABC and IKH3. In effect, ABC performs slightly better than IKH3 in this multimodal function.</p><p>Fig. <ref type="figure">5</ref> shows the results for F10 Schwefel 1.2 function. From Fig. <ref type="figure">5</ref>, similar to F07 Rastrigin function as shown in Fig. <ref type="figure">4</ref>, the figure shows that there is little difference between the performance of IKH1 and IKH2. However, carefully studying Table <ref type="table" target="#tab_5">3</ref> and Fig. <ref type="figure">5</ref>, we can conclude that, IKH1 performs slightly better than IKH2 in this relative simple unimodal benchmark function. For other algorithms, CS works very well, because it ranks 3 among twelve methods. Fig. <ref type="figure">6</ref> shows the results for F12 Schwefel 2.21 function. It is obvious that IKH1, IKH2, IKH3 and KH perform the best and significantly outperform other algorithms. However, carefully studying Table <ref type="table" target="#tab_5">3</ref> and Fig. <ref type="figure">6</ref>, we can conclude that, IKH3 is superior to IKH2, IKH1 and KH in the whole optimization progress.   <ref type="figure">7</ref> shows the results for F14 Step function. Apparently, IKH1 and IKH2 perform almost the same during the whole optimization process. Eventually, they converge to the same final optimal values; while, IKH3 is only inferior to IKH1 and IKH2, and converges to the value that is very close to the IKH1 and IKH2.</p><p>From above-analyses about the Figs. 1-7 and Table <ref type="table" target="#tab_5">3</ref>, we can arrive at a conclusion that, on average, among 12 optimization methods, our proposed IKH1 an IKH2 approach perform the best and most effectively when solving the global numerical optimization problems and significantly outperforms the other ten approaches. Generally speaking, IKH3 and KH are only inferior to IKH1 an IKH2, and perform the second best among 12 methods. CS and ABC perform the third best only inferior to the IKH1, IKH2, IKH3 and KH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Influence of control parameter</head><p>The choice of the control parameters is of vital importance for different problems. To compare the different effects on the parameter of the fraction of fireflies placed in the top krill group p a , we ran 100 Monte Carlo simulations of the IKH2 algorithm on the above problem to get the best performances. All other parameter settings are kept unchanged (unless noted otherwise in the following paragraph). The results are recorded in Tables 5-6 after 100 Monte Carlo runs. Among them, Table <ref type="table" target="#tab_7">5</ref> shows the best minima found by IKH2 algorithm over 100 Monte Carlo runs. Table <ref type="table" target="#tab_8">6</ref> shows the average minima found by the IKH2 algorithm, averaged over 100 Monte Carlo runs. In other words, Tables <ref type="table" target="#tab_7">5</ref> and<ref type="table" target="#tab_8">6</ref> show the best and average performance of IKH2 algorithm respectively. In each table, the last row is the total number of functions on which IKH2 performs the best with specific parameters.</p><p>Tables <ref type="table" target="#tab_7">5</ref> and<ref type="table" target="#tab_8">6</ref> recorded the results performed on the benchmark problems with the fraction of krill placed in the top krill group p a ¼0, 0.1, 0.2, 0.9, 1.0. From Tables <ref type="table" target="#tab_7">5</ref> and<ref type="table" target="#tab_8">6</ref>, it can be seen that: (i) for the three benchmark functions F01, F02, F03 and F08, IKH2 performs slightly differently, that is to say, these three benchmark functions are insensitive to the parameter p a . (ii) For benchmark functions F04-F07, F09, F11-F14, IKH2 performs better on smaller p a ( o0.5). (iii) However, there are very few benchmark functions that IKH2 performs better on bigger p a <ref type="bibr">( 40.5)</ref>. As can be observed from Tables <ref type="table" target="#tab_7">5</ref> and<ref type="table" target="#tab_8">6</ref> , IKH2 performs the best in most benchmarks when p a is equal or very close to 0.2 and 0.3. Hence, we set p a ¼0.25 in other experiments. In addition, statistical analysis on these values obtained by the IKH2 with the fraction of krill placed in the top krill group p a on 14 benchmark functions based on the Friedman's test reveals that the differences in the obtained average and best function minima across various chaotic maps are statistically significant (p¼7.6 Â 10 À 16 and p¼6.7 Â 10 À 16 , respectively) at the confidence level of 5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussion</head><p>For all of the standard benchmark functions that have been considered, IKH performs better than or at least highly competitive with the standard KH and other acclaimed state-of-the-art population-based algorithms. The IKH performs excellently and efficiently because of its ability to simultaneously carry out a local search, still searching globally at the same time. It succeeds in doing this due to the information exchange between the top krill and global search via Lévy flights concurrently. A similar behavior may be performed in the PSO by using multi-swarm from a particle population initially. However, IKH's advantages include performing simpy and easily, and using only one parameter to regulate.</p><p>Benchmark evaluation is a good way for verifying the performance of the meta-heuristic algorithms, but it also has limitations. First, we did not make any special effort to tune the optimization algorithms in this section. Different tuning parameter values in the optimization algorithms might result in significant differences in their performance. Second, real-world optimization problems may not have much of a relationship to benchmark functions. Third, benchmark tests might result in different conclusions if the grading criteria or problem setup change. In our work, we examined the mean and best results obtained with a certain population size and after a certain number of generations. However, we might arrive at different conclusions if (for example) we change the generation limit, or look at how many generations it takes to reach a certain function value, or if we change the population size. In spite of these caveats, the benchmark results shown here are promising for IKH, and indicate that this novel method might be able to find a niche among the plethora of population-based optimization algorithms.</p><p>In this work, 14 benchmark functions are used to evaluate the performance of our approach. In future, will test our approach on *The values are normalized so that the minimum in each row is 1.00. These are not the absolute minima found by each algorithm, but the average minima found by each algorithm. more problems, such as the high-dimensional (d Z20) CEC 2010 test suit <ref type="bibr" target="#b38">[39]</ref> and the real-world problems. Moreover, we will compare IKH with other EAs. In addition, we only consider the unconstrained function optimization in this work. Our future work consists of adding the diversity rules into IKH for constrained optimization problems, such as constrained real-parameter optimization CEC 2010 test suit <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and future work</head><p>This paper proposed an improved meta-heuristic IKH method for optimization problem. A novel type of KH has been presented which introduces three improvements to the original method. The first improvement is adding Lévy flight to the KH with the step size α, similar to declined inertia constant in the PSO <ref type="bibr" target="#b18">[19]</ref> and basic KH algorithm <ref type="bibr" target="#b19">[20]</ref>. This strategy can inspire more localized searching as the krill get closer to the solution. Information exchange between the top krill is added to the method as the second improvement in an effort to accelerate the convergence speed to the best solution. In IKH, portions of the krill with the best fitness are made up of a group of top krill. The third improvement is the addition of elitism scheme into IKH. This prevents the optimal krill from being corrupted by three motion calculation operators. The IKH attempts to take merits of the KH and exchange information in order to avoid all krill getting trapped in inferior local optimal regions. This new method can speed up the global convergence rate without losing the strong robustness of the basic KH. From the analysis of the experimental results, it can be concluded that the proposed IKH method uses the information in past solutions more efficiently when compared to the other population-based optimization algorithms such as ABC, BA, CS, DE, GA, HS, KH, PBIL, and PSO. Based on the results, IKH significantly improves the performance of KH on most multimodal and unimodal problems. In addition, IKH is simple and easy to implement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>for i¼1:NP (all krill) do Perform the following motion calculation. Motion induced by the presence of other individuals Foraging motion Physical diffusion Implement the genetic operators. Update the krill individual position in the search space. Evaluate each krill individual according to its position. end for i Sort the population/krill from best to worst and find the current best. G ¼G þ 1. Step 4: end while Step 5: Post-processing the results and visualization. End. Various krill-inspired algorithms can be developed by idealizing the motion characteristics of the krill individuals. Generally, the KH algorithm can be described by the following steps: (I) Data structures: define the simple bounds; determine the algorithm parameter(s) etc. (II) Initialization: randomly create the initial population in the search space. (III) Fitness evaluation: evaluate each krill individual according to its position. (IV) Motion calculation: Motion induced by other krill individuals, Foraging motion Physical diffusion (V) Perform the genetic operators (VI) Updating: update the krill individual position in the search space. (VII) Repeating: go to step III until the stop criteria is reached. (VIII) Post-processing the results and visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .Fig. 2 .Fig. 3 .</head><label>123</label><figDesc>Fig. 1. Comparison of the performance of the different methods for the F01 Ackley function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.</head><label></label><figDesc>Fig.7shows the results for F14 Step function. Apparently, IKH1 and IKH2 perform almost the same during the whole optimization process. Eventually, they converge to the same final optimal values; while, IKH3 is only inferior to IKH1 and IKH2, and converges to the value that is very close to the IKH1 and IKH2.From above-analyses about the Figs. 1-7 and Table3, we can arrive at a conclusion that, on average, among 12 optimization methods, our proposed IKH1 an IKH2 approach perform the best and most effectively when solving the global numerical optimization problems and significantly outperforms the other ten approaches. Generally speaking, IKH3 and KH are only inferior to IKH1 an IKH2, and perform the second best among 12 methods. CS and ABC perform the third best only inferior to the IKH1, IKH2, IKH3 and KH.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .Fig. 5 .Fig. 6 .Fig. 7 .</head><label>4567</label><figDesc>Fig. 4. Comparison of the performance of the different methods for the F07 Rastrigin function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>2: for i ¼1:NoTop (all top krill) do Current krill at position x i Pick another krill from the top krill at random x j if x i ¼x j then Calculate Lévy flight step sizeφ'A/G 2 Perform Lévy flight from x i to generate new krill x k Evaluate the fitness f k for krill x k Choose a random krill l from all krill if (f k 4f l ) Move krill k towards l; end if else dx¼|x i À x j |/φ Move distance dx from the worst krill to the best krill to find x k Evaluate the fitness f k for krill x</figDesc><table /><note><p>k Choose a random krill l from all krill if (f k 4 f l ) then Move krill k towards l; end if end if Step 3: end for i End.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1: Initialization. Set the generation counter t¼1; initialize the population P of NP krill individuals randomly and each krill corresponding to a potential solution to the given problem; set the foraging speed V f , the maximum diffusion speed D max , and the maximum induced speed N max ; set max Lévy flight step size A, golden ratio φ and the fraction of krill placed in the</figDesc><table><row><cell>end for i</cell></row><row><cell>Replace the KEEP worst krill with the KEEP best krill stored</cell></row><row><cell>in KEEPKRILL.</cell></row><row><cell>Sort the population/krill from best to worst and find the</cell></row><row><cell>current best.</cell></row><row><cell>t¼ tþ1;</cell></row><row><cell>Step 4: end while</cell></row><row><cell>Step 5: Post-processing the results and visualization;</cell></row><row><cell>End.</cell></row><row><cell>top krill group p a ; set elitism parameter KEEP: how many of the</cell></row><row><cell>best krill to keep from one generation to the next, here</cell></row><row><cell>KEEP ¼⌈NPnð1 À p a Þ⌉</cell></row><row><cell>Step 2: Fitness evaluation. Evaluate each krill individual</cell></row><row><cell>according to its position.</cell></row><row><cell>Step 3: While the termination criteria is not satisfied or</cell></row><row><cell>toMaxGeneration do</cell></row><row><cell>Sort the population/krill from best to worst.</cell></row></table><note><p>Store the KEEP best krill as KEEPKRILL. for i¼1: ⌈NPnp a ⌉(all top frill) do Perform the following motion calculation. Motion induced by the presence of other individuals Forage motion Exchange information between top krill by Algorithm 2 Update the krill individual position in the search space. Evaluate each krill individual according to its position.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Benchmark functions.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Properties of benchmark functions, lb denotes lower bound, ub denotes upper bound, opt denotes optimum point.</figDesc><table><row><cell>No.</cell><cell>Function</cell><cell>lb</cell><cell>ub</cell><cell>opt</cell><cell>Continuity</cell><cell>Modality</cell></row><row><cell>F01</cell><cell>Ackley</cell><cell>À 32.768</cell><cell>32.768</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F02</cell><cell>Fletcher-Powell</cell><cell>À π</cell><cell>π</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F03</cell><cell>Griewangk</cell><cell>À 600</cell><cell>600</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F04</cell><cell>Penalty #1</cell><cell>À 50</cell><cell>50</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F05</cell><cell>Penalty #2</cell><cell>À 50</cell><cell>50</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F06</cell><cell>Quartic with noise</cell><cell>À 1.28</cell><cell>1.28</cell><cell>1</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F07</cell><cell>Rastrigin</cell><cell>À 5.12</cell><cell>5.12</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F08</cell><cell>Rosenbrock</cell><cell>À 2.048</cell><cell>2.048</cell><cell>0</cell><cell>Continuous</cell><cell>Unimodal</cell></row><row><cell>F09</cell><cell>Schwefel 2.26</cell><cell>À 512</cell><cell>512</cell><cell>0</cell><cell>Continuous</cell><cell>Multimodal</cell></row><row><cell>F10</cell><cell>Schwefel 1.2</cell><cell>À 100</cell><cell>100</cell><cell>0</cell><cell>Continuous</cell><cell>Unimodal</cell></row><row><cell>F11</cell><cell>Schwefel 2.22</cell><cell>À 10</cell><cell>10</cell><cell>0</cell><cell>Continuous</cell><cell>Unimodal</cell></row><row><cell>F12</cell><cell>Schwefel 2.21</cell><cell>À 100</cell><cell>100</cell><cell>0</cell><cell>Continuous</cell><cell>Unimodal</cell></row><row><cell>F13</cell><cell>Sphere</cell><cell>À 5.12</cell><cell>5.12</cell><cell>0</cell><cell>Continuous</cell><cell>Unimodal</cell></row><row><cell>F14</cell><cell>Step</cell><cell>À 5.12</cell><cell>5.12</cell><cell>0</cell><cell>Discontinuous</cell><cell>Unimodal</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Mean normalized optimization results in 14 benchmark functions. The values shown are the minimum objective function values found by each algorithm, averaged over 100 Monte Carlo simulations.</figDesc><table><row><cell></cell><cell>ABC</cell><cell>BA</cell><cell>CS</cell><cell>DE</cell><cell>GA</cell><cell>HS</cell><cell>IKH1</cell><cell>IKH2</cell><cell>IKH3</cell><cell>KH</cell><cell>PBIL</cell><cell>PSO</cell></row><row><cell>F01</cell><cell>3.08</cell><cell>4.49</cell><cell>2.54</cell><cell>2.85</cell><cell>3.91</cell><cell>4.46</cell><cell>1.11</cell><cell>1.16</cell><cell>1.00</cell><cell>1.23</cell><cell>4.54</cell><cell>3.75</cell></row><row><cell>F02</cell><cell>1.44</cell><cell>7.51</cell><cell>1.17</cell><cell>2.15</cell><cell>2.26</cell><cell>5.06</cell><cell>1.04</cell><cell>1.00</cell><cell>1.98</cell><cell>7.51</cell><cell>4.99</cell><cell>4.65</cell></row><row><cell>F03</cell><cell>9.25</cell><cell>50.73</cell><cell>3.56</cell><cell>5.05</cell><cell>9.64</cell><cell>46.64</cell><cell>1.01</cell><cell>1.00</cell><cell>1.40</cell><cell>7.44</cell><cell>55.33</cell><cell>18.97</cell></row><row><cell>F04</cell><cell>3.6E5</cell><cell>1.9E7</cell><cell>1.5E3</cell><cell>7.1E4</cell><cell>1.9E5</cell><cell>1.4E7</cell><cell>5.53</cell><cell>1.00</cell><cell>3.5E3</cell><cell>1.2E6</cell><cell>1.8E7</cell><cell>1.4E6</cell></row><row><cell>F05</cell><cell>914.27</cell><cell>2.6E4</cell><cell>33.73</cell><cell>340.31</cell><cell>411.80</cell><cell>1.9E4</cell><cell>1.01</cell><cell>1.00</cell><cell>24.63</cell><cell>2.0E3</cell><cell>2.3E4</cell><cell>2.9E3</cell></row><row><cell>F06</cell><cell>85.26</cell><cell>1.4E3</cell><cell>10.36</cell><cell>34.89</cell><cell>75.12</cell><cell>1.2E3</cell><cell>1.00</cell><cell>1.26</cell><cell>10.46</cell><cell>202.64</cell><cell>1.4E3</cell><cell>231.00</cell></row><row><cell>F07</cell><cell>2.58</cell><cell>7.35</cell><cell>3.01</cell><cell>4.28</cell><cell>4.55</cell><cell>6.50</cell><cell>1.00</cell><cell>1.02</cell><cell>2.61</cell><cell>5.02</cell><cell>7.05</cell><cell>5.07</cell></row><row><cell>F08</cell><cell>8.96</cell><cell>54.64</cell><cell>2.86</cell><cell>7.30</cell><cell>13.41</cell><cell>42.93</cell><cell>1.08</cell><cell>1.00</cell><cell>3.15</cell><cell>14.41</cell><cell>52.03</cell><cell>14.97</cell></row><row><cell>F09</cell><cell>1.90</cell><cell>4.39</cell><cell>2.05</cell><cell>2.44</cell><cell>1.00</cell><cell>3.68</cell><cell>1.41</cell><cell>1.44</cell><cell>2.36</cell><cell>4.18</cell><cell>3.82</cell><cell>3.66</cell></row><row><cell>F10</cell><cell>9.26</cell><cell>18.68</cell><cell>2.48</cell><cell>11.00</cell><cell>8.33</cell><cell>11.69</cell><cell>1.00</cell><cell>1.02</cell><cell>5.53</cell><cell>9.97</cell><cell>12.05</cell><cell>8.65</cell></row><row><cell>F11</cell><cell>2.99</cell><cell>12.80</cell><cell>2.66</cell><cell>3.26</cell><cell>5.87</cell><cell>9.75</cell><cell>1.00</cell><cell>1.11</cell><cell>4.53</cell><cell>11.66</cell><cell>9.82</cell><cell>7.28</cell></row><row><cell>F12</cell><cell>6.48</cell><cell>6.95</cell><cell>2.75</cell><cell>5.28</cell><cell>5.39</cell><cell>6.62</cell><cell>1.17</cell><cell>1.09</cell><cell>1.00</cell><cell>1.41</cell><cell>6.78</cell><cell>5.27</cell></row><row><cell>F13</cell><cell>11.41</cell><cell>66.67</cell><cell>4.68</cell><cell>6.43</cell><cell>23.79</cell><cell>60.99</cell><cell>1.00</cell><cell>1.02</cell><cell>1.80</cell><cell>9.72</cell><cell>70.54</cell><cell>25.08</cell></row><row><cell>F14</cell><cell>7.46</cell><cell>42.69</cell><cell>3.06</cell><cell>3.86</cell><cell>7.14</cell><cell>37.56</cell><cell>1.00</cell><cell>1.00</cell><cell>1.02</cell><cell>6.07</cell><cell>45.14</cell><cell>14.87</cell></row><row><cell>Total</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>6</cell><cell>6</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table><note><p>*The values are normalized so that the minimum in each row is 1.00. These are not the absolute minima found by each algorithm, but the average minima found by each algorithm.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Best normalized optimization results in 14 benchmark functions. The values shown are the minimum objective function values found by each algorithm.</figDesc><table><row><cell></cell><cell>ABC</cell><cell>BA</cell><cell>CS</cell><cell>DE</cell><cell>GA</cell><cell>HS</cell><cell>IKH1</cell><cell>IKH2</cell><cell>IKH3</cell><cell>KH</cell><cell>PBIL</cell><cell>PSO</cell></row><row><cell>F01</cell><cell>4.26</cell><cell>7.32</cell><cell>3.10</cell><cell>4.36</cell><cell>5.72</cell><cell>7.22</cell><cell>1.42</cell><cell>1.37</cell><cell>1.00</cell><cell>1.14</cell><cell>7.50</cell><cell>5.94</cell></row><row><cell>F02</cell><cell>2.43</cell><cell>10.45</cell><cell>1.54</cell><cell>3.01</cell><cell>1.60</cell><cell>10.64</cell><cell>1.06</cell><cell>1.00</cell><cell>3.35</cell><cell>12.98</cell><cell>6.53</cell><cell>7.85</cell></row><row><cell>F03</cell><cell>7.06</cell><cell>36.55</cell><cell>3.29</cell><cell>5.16</cell><cell>6.24</cell><cell>60.35</cell><cell>1.02</cell><cell>1.00</cell><cell>1.23</cell><cell>8.38</cell><cell>66.77</cell><cell>22.73</cell></row><row><cell>F04</cell><cell>3.2E3</cell><cell>7.8E6</cell><cell>7.92</cell><cell>7.5E3</cell><cell>15.08</cell><cell>1.2E7</cell><cell>1.11</cell><cell>1.00</cell><cell>13.01</cell><cell>1.2E6</cell><cell>2.5E7</cell><cell>6.0E5</cell></row><row><cell>F05</cell><cell>5.7E4</cell><cell>5.0E6</cell><cell>530.77</cell><cell>8.2E3</cell><cell>2.9E3</cell><cell>5.2E6</cell><cell>1.27</cell><cell>1.00</cell><cell>868.43</cell><cell>9.9E5</cell><cell>1.2E7</cell><cell>6.8E5</cell></row><row><cell>F06</cell><cell>13.92</cell><cell>3.6E3</cell><cell>23.02</cell><cell>133.00</cell><cell>21.16</cell><cell>5.4E3</cell><cell>1.49</cell><cell>1.00</cell><cell>30.25</cell><cell>765.35</cell><cell>7.1E3</cell><cell>399.65</cell></row><row><cell>F07</cell><cell>3.33</cell><cell>12.03</cell><cell>4.66</cell><cell>7.44</cell><cell>6.81</cell><cell>10.90</cell><cell>1.02</cell><cell>1.00</cell><cell>3.32</cell><cell>8.45</cell><cell>12.76</cell><cell>7.57</cell></row><row><cell>F08</cell><cell>7.17</cell><cell>26.15</cell><cell>2.07</cell><cell>7.06</cell><cell>7.39</cell><cell>40.91</cell><cell>1.00</cell><cell>1.02</cell><cell>3.23</cell><cell>14.27</cell><cell>41.82</cell><cell>12.59</cell></row><row><cell>F09</cell><cell>3.61</cell><cell>9.75</cell><cell>3.56</cell><cell>5.05</cell><cell>1.00</cell><cell>8.29</cell><cell>2.05</cell><cell>2.40</cell><cell>4.62</cell><cell>8.58</cell><cell>8.43</cell><cell>6.90</cell></row><row><cell>F10</cell><cell>26.22</cell><cell>26.28</cell><cell>4.19</cell><cell>31.86</cell><cell>16.39</cell><cell>32.18</cell><cell>1.96</cell><cell>1.00</cell><cell>13.94</cell><cell>27.80</cell><cell>26.58</cell><cell>23.26</cell></row><row><cell>F11</cell><cell>4.29</cell><cell>18.73</cell><cell>1.98</cell><cell>4.76</cell><cell>6.76</cell><cell>16.12</cell><cell>1.00</cell><cell>1.29</cell><cell>4.51</cell><cell>16.12</cell><cell>16.34</cell><cell>8.99</cell></row><row><cell>F12</cell><cell>12.37</cell><cell>12.43</cell><cell>4.52</cell><cell>11.80</cell><cell>8.78</cell><cell>12.37</cell><cell>1.72</cell><cell>1.47</cell><cell>1.00</cell><cell>2.11</cell><cell>12.93</cell><cell>8.27</cell></row><row><cell>F13</cell><cell>8.66</cell><cell>64.92</cell><cell>6.16</cell><cell>11.16</cell><cell>19.90</cell><cell>65.99</cell><cell>1.13</cell><cell>1.00</cell><cell>2.07</cell><cell>15.02</cell><cell>134.42</cell><cell>40.88</cell></row><row><cell>F14</cell><cell>13.05</cell><cell>91.79</cell><cell>6.39</cell><cell>8.68</cell><cell>3.19</cell><cell>82.29</cell><cell>1.52</cell><cell>1.00</cell><cell>1.39</cell><cell>13.21</cell><cell>110.11</cell><cell>32.75</cell></row><row><cell>Total</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>2</cell><cell>9</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table><note><p><p>n</p>The values are normalized so that the minimum in each row is 1.00. These are the absolute best minima found by each algorithm. L. Guo et al. / Neurocomputing ∎ (∎∎∎∎) ∎∎∎-∎∎∎</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Best normalized optimization results in 14 benchmark functions with different p a . The numbers shown are the best results found after 100 Monte Carlo simulations of IKH2 algorithm.</figDesc><table><row><cell></cell><cell>p a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell>F01</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>F02</cell><cell>2.9E3</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>F03</cell><cell>6.03</cell><cell>2.3</cell><cell>11.00</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell></row><row><cell>F04</cell><cell>1.69</cell><cell>1.69</cell><cell>106.66</cell><cell>1.00</cell><cell>1.69</cell><cell>1.13</cell><cell>1.69</cell><cell>1.69</cell><cell>1.69</cell><cell>1.69</cell><cell>1.69</cell></row><row><cell>F05</cell><cell>7.28</cell><cell>2.31</cell><cell>2.31</cell><cell>6.8E3</cell><cell>1.00</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell></row><row><cell>F06</cell><cell>1.00</cell><cell>52.17</cell><cell>61.84</cell><cell>34.69</cell><cell>10.38</cell><cell>56.16</cell><cell>4.24</cell><cell>32.21</cell><cell>8.03</cell><cell>46.64</cell><cell>2.45</cell></row><row><cell>F07</cell><cell>4.55</cell><cell>1.36</cell><cell>1.00</cell><cell>2.31</cell><cell>2.31</cell><cell>11.61</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell></row><row><cell>F08</cell><cell>4.62</cell><cell>2.61</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.01</cell><cell>8.47</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>F09</cell><cell>305.76</cell><cell>7.28</cell><cell>2.31</cell><cell>1.00</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>508.16</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell></row><row><cell>F10</cell><cell>192.19</cell><cell>6.03</cell><cell>1.36</cell><cell>1.00</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>1.1E3</cell><cell>2.31</cell><cell>2.31</cell></row><row><cell>F11</cell><cell>759.73</cell><cell>1.00</cell><cell>751.20</cell><cell>751.20</cell><cell>325.79</cell><cell>751.20</cell><cell>751.20</cell><cell>751.20</cell><cell>751.20</cell><cell>2.4E3</cell><cell>751.20</cell></row><row><cell>F12</cell><cell>23.60</cell><cell>1.00</cell><cell>46.71</cell><cell>14.40</cell><cell>37.65</cell><cell>14.40</cell><cell>14.40</cell><cell>14.40</cell><cell>14.40</cell><cell>14.40</cell><cell>27.86</cell></row><row><cell>F13</cell><cell>1.00</cell><cell>18.55</cell><cell>2.29</cell><cell>31.79</cell><cell>48.74</cell><cell>23.34</cell><cell>53.81</cell><cell>18.73</cell><cell>40.81</cell><cell>29.05</cell><cell>53.81</cell></row><row><cell>F14</cell><cell>109.99</cell><cell>1.36</cell><cell>1.00</cell><cell>2.31</cell><cell>2.31</cell><cell>6.03</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell><cell>2.31</cell></row><row><cell></cell><cell>3</cell><cell>4</cell><cell>6</cell><cell>6</cell><cell>4</cell><cell>2</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Mean normalized optimization results in 14 benchmark functions with different p a . The numbers shown are the best results found after 100 Monte Carlo simulations of IKH2 algorithm. The values are normalized so that the minimum in each row is 1.00. These are the absolute best minima found by each algorithm. L. Guo et al. / Neurocomputing ∎ (∎∎∎∎) ∎∎∎-∎∎∎</figDesc><table><row><cell></cell><cell>p a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell>F01</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>F02</cell><cell>180.37</cell><cell>2.40</cell><cell>1.00</cell><cell>1.63</cell><cell>2.37</cell><cell>1.90</cell><cell>2.17</cell><cell>2.11</cell><cell>3.07</cell><cell>2.78</cell><cell>1.78</cell></row><row><cell>F03</cell><cell>1.80</cell><cell>1.60</cell><cell>1.00</cell><cell>1.01</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.03</cell><cell>1.01</cell><cell>1.01</cell></row><row><cell>F04</cell><cell>5.2E3</cell><cell>125.22</cell><cell>9.4E3</cell><cell>1.00</cell><cell>1.21</cell><cell>1.13</cell><cell>1.02</cell><cell>1.05</cell><cell>27.85</cell><cell>2.21</cell><cell>13.95</cell></row><row><cell>F05</cell><cell>220.69</cell><cell>4.16</cell><cell>1.00</cell><cell>23.33</cell><cell>2.82</cell><cell>5.45</cell><cell>1.32</cell><cell>2.14</cell><cell>2.59</cell><cell>3.80</cell><cell>1.41</cell></row><row><cell>F06</cell><cell>1.00</cell><cell>2.9E5</cell><cell>1.6E3</cell><cell>3.9E3</cell><cell>2.9E5</cell><cell>31.18</cell><cell>31.16</cell><cell>31.17</cell><cell>31.17</cell><cell>31.18</cell><cell>31.16</cell></row><row><cell>F07</cell><cell>4.31</cell><cell>5.1E3</cell><cell>1.00</cell><cell>51.28</cell><cell>123.01</cell><cell>9.2E3</cell><cell>1.04</cell><cell>1.78</cell><cell>1.02</cell><cell>1.05</cell><cell>1.01</cell></row><row><cell>F08</cell><cell>10.15</cell><cell>118.71</cell><cell>8.9E3</cell><cell>81.06</cell><cell>49.92</cell><cell>119.73</cell><cell>9.0E3</cell><cell>1.00</cell><cell>1.08</cell><cell>1.08</cell><cell>1.04</cell></row><row><cell>F09</cell><cell>82.69</cell><cell>4.4E4</cell><cell>1.10</cell><cell>1.00</cell><cell>42.75</cell><cell>26.63</cell><cell>62.92</cell><cell>4.7E3</cell><cell>1.18</cell><cell>1.41</cell><cell>1.23</cell></row><row><cell>F10</cell><cell>110.21</cell><cell>616.66</cell><cell>1.9E3</cell><cell>3.4E3</cell><cell>46.43</cell><cell>32.44</cell><cell>21.03</cell><cell>47.90</cell><cell>3.5E3</cell><cell>1.00</cell><cell>1.26</cell></row><row><cell>F11</cell><cell>37.91</cell><cell>1.00</cell><cell>1.8E3</cell><cell>14.58</cell><cell>25.57</cell><cell>1.8E3</cell><cell>1.2E3</cell><cell>740.76</cell><cell>1.8E3</cell><cell>1.3E5</cell><cell>14.76</cell></row><row><cell>F12</cell><cell>2.44</cell><cell>8.9E3</cell><cell>9.0E3</cell><cell>1.00</cell><cell>9.0E3</cell><cell>95.89</cell><cell>119.24</cell><cell>81.86</cell><cell>50.37</cell><cell>120.85</cell><cell>9.1E3</cell></row><row><cell>F13</cell><cell>1.00</cell><cell>8.14</cell><cell>1.7E5</cell><cell>9.7E3</cell><cell>1.88</cell><cell>3.38</cell><cell>186.26</cell><cell>231.59</cell><cell>158.98</cell><cell>97.82</cell><cell>234.73</cell></row><row><cell>F14</cell><cell>85.17</cell><cell>2.0E3</cell><cell>651.82</cell><cell>50.59</cell><cell>1.00</cell><cell>3.6E3</cell><cell>44.82</cell><cell>39.44</cell><cell>48.92</cell><cell>34.62</cell><cell>20.77</cell></row><row><cell></cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>4</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>3</cell><cell>1</cell><cell>2</cell><cell>1</cell></row></table><note><p>*</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Please cite this article as: L. Guo, et al., A new improved krill herd algorithm for global numerical optimization, Neurocomputing (2014), http://dx.doi.org/10.1016/j.neucom.2014.01.023i</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the State Key Laboratory of Laser Interaction with Material Research Fund under Grant no. SKLLIM0902-01 and the Key Research Technology of Electric-discharge Non-chain Pulsed DF Laser under Grant no. LXJJ-11-Q80.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Some hybrid models to improve Firefly algorithm performance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Abshouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nasiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meybodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="97" to="117" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature-Inspired Metaheuristic Algorithms</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Luniver Press</publisher>
			<pubPlace>Frome</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parameter estimation of fuzzy neural network controller based on a modified differential evolution</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="178" to="192" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The system identification and control of Hammerstein system using non-uniform rational B-spline neural network and particle swarm optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="216" to="223" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dynamic deployment of wireless sensor networks by biogeography based optimization algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sens. Actuator Netw</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A modified firefly algorithm for UCAV path planning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Hybrid Inf. Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="123" to="144" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A hybrid meta-heuristic DE/CS algorithm for UCAV path planning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inform. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="4811" to="4818" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Test-sheet composition using analytic hierarchy process and hybrid metaheuristic algorithm TS/BBO</title>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Probl. Eng</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<title level="m">Metaheuristics in Water, Geotechnical and Transport Engineering</title>
		<meeting><address><addrLine>Waltham, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<title level="m">Metaheuristic Applications in Structures and Infrastructures</title>
		<meeting><address><addrLine>Waltham, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Genetic Algorithms in Search, Optimization and Machine learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A two-stage genetic algorithm for automatic clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="49" to="59" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Active leading through obstacles using ant-colony algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vatankhah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Etemadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alasty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-R</forename><surname>Vossoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boroushaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="67" to="77" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coupled eagle strategy and differential evolution for unconstrained and constrained global optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Math. Appl</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="191" to="200" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel hybrid bat algorithm with harmony search for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1155/2013/696491</idno>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Path planning for UCAV using bat algorithm with mutation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. World J</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hybridizing harmony search with biogeography based optimization for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Theor. Nanosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2318" to="2328" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Neural Networks</title>
		<meeting>the IEEE International Conference on Neural Networks<address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Krill Herd: a new bio-inspired optimization algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Nonlinear Sci. Numer. Simul</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="4831" to="4845" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Incorporating mutation scheme into krill herd algorithm for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="853" to="871" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lévy-flight krill herd algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Probl. Eng</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Engineering optimisation by cuckoo search</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Math. Model. Numer. Optim</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="330" to="343" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modified cuckoo search: a new gradient free optimisation algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos Soliton Fract</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="710" to="718" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bat algorithm: a novel approach for global engineering optimization</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="464" to="483" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A hybrid meta-heuristic DE/CS algorithm for UCAV three-dimension path planning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. World J</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Integrating a differential evolution feature weighting scheme into prototype generation</title>
		<author>
			<persName><forename type="first">I</forename><surname>Triguero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Derrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="332" to="343" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Path planning for uninhabited combat aerial vehicle using hybrid meta-heuristic DE/BBO algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Sci. Eng. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="550" to="564" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<title level="m">Evolutionary Algorithms in Theory and Practice</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Beyer</surname></persName>
		</author>
		<title level="m">The Theory of Evolution Strategies</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new heuristic optimization algorithm: harmony search</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Geem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Loganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="60" to="68" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shumeet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Pittsburgh PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A hybrid co-evolutionary cultural algorithm based on particle swarm optimization for solving global optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="76" to="89" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A new improved firefly algorithm for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Theor. Nanosci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="477" to="485" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evolutionary programming made faster</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="82" to="102" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A comparison of alternative tests of significance for the problem of m rankings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="1940">1940</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Benchmark Functions for the CEC&apos;2010 Special Session and Competition on Large Scale Global Optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Inspired Computation and Applications Laboratory</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Hefei, China</pubPlace>
		</imprint>
	</monogr>
	<note>USTC</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Her areas of interest include computer vision, and computer application. She is a recognized Supervisor to guide the Ph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">D. scholars in Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Singapore; China; China</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note>Chinese Academy of Sciences</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">/ Neurocomputing ∎ (∎∎∎∎) ∎∎∎-∎∎∎</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
