<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Low Patch-Rank Interpretation of Texture *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-02-12">February 12, 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hayden</forename><surname>Schaeffer</surname></persName>
							<email>hschaeffer@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of California at Los Angeles</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stanley</forename><surname>Osher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of California at Los Angeles</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Low Patch-Rank Interpretation of Texture *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-02-12">February 12, 2013</date>
						</imprint>
					</monogr>
					<idno type="MD5">260DCF1599C88D116A4E92FEB2BD2597</idno>
					<idno type="DOI">10.1137/110854989</idno>
					<note type="submission">Received by the editors November 11, 2011; accepted for publication (in revised form) September 13, 2012;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>texture</term>
					<term>low-rank</term>
					<term>optimization</term>
					<term>sparse reconstruction AMS subject classifications. 65K05</term>
					<term>49M27</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel cartoon-texture separation model using a sparse low-rank decomposition. Our texture model connects the separate ideas of robust principal component analysis (PCA) [E. J.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction.</head><p>One of the most important problems in image processing is the recovery of a corrupted image, f , which may be degraded by noise, blur, missing data, etc. The goal is to reconstruct important structural features of the original image, such as large scale objects (smooth regions), edges (discontinuities), textures (patterned small scale details), and noise (random and of mean zero). This problem is typically written as an inverse problem: given f , find a u which is a smooth approximation of f in some sense <ref type="bibr" target="#b0">[1]</ref>. Specifically, given an f , decompose f = u + v, where u is the recovered image and v is the residual assumed to be noise. For such two component decompositions, the general formulation is inf</p><formula xml:id="formula_0">(u,v)∈X 1 ×X 2 E(u, v) = {μ||u|| X 1 + ||v|| X 2 } subject to (s.t.) f = u + v,</formula><p>where μ &gt; 0 is a tuning parameter. The recovered image is assumed to reside in the space X 1 , which contains functions of positive differentiability (i.e., the "derivative" is well behaved in some sense), and the noise is taken to be in X 2 = L 2 . In this class of image recovery methods, notable models include those by Rudin, Osher, and Fatemi (ROF) <ref type="bibr" target="#b32">[32]</ref> and Chambolle and Lions <ref type="bibr" target="#b10">[11]</ref>. In particular, the ROF model is inf</p><formula xml:id="formula_1">(u,v)∈BV ×L 2 E ROF (u, v) = μ||u|| T V + 1 2 ||v|| 2 L 2</formula><p>(1.1)</p><formula xml:id="formula_2">s.t. f = u + v,</formula><p>which is known to reconstruct piecewise constant solutions very well, thereby recovering both large scale features and edges. Recall that a function u is of bounded variation (BV ) if and only if u ∈ L 1 and there exists a finite Radon measure Du such that total variation (TV )</p><formula xml:id="formula_3">(1.2) ||u|| T V := Ω |Du| := Ω u div (φ) dx φ ∈ C 1 c (Ω, (R) n ), ||φ|| L ∞ ≤ 1</formula><p>is finite. When the function u ∈ W 1,1 (defined as the space of functions u such that u, ∇u ∈ L 1 ), the T V seminorm becomes ||u|| T V = Ω |∇u| dx, where ∇u is the weak derivative.</p><p>With the introduction of the Bregman technique <ref type="bibr" target="#b29">[29]</ref> and the split Bregman method <ref type="bibr" target="#b19">[20]</ref>, T V regularized problems can be solved quickly and efficiently while also remedying defects such as loss of contrast.</p><p>On the other hand, the texture is considered to be highly oscillatory, which is not well captured by the X 1 norms. Thus in many of these reconstruction models, v also contains some textures and edges. In order to further decompose the texture and noise, texture regularized models have appeared in the literature, beginning with the work of Meyer <ref type="bibr" target="#b28">[28]</ref>, who first proposed recovering texture using spaces that are weaker than L 2 . These weak spaces encourage oscillatory behavior, since their norms decrease as the number of oscillations increases. In this framework, the image is decomposed into the cartoon component and the texture component, while also removing any noise or residual. This becomes a three component decomposition: given f , decompose f = u + v + ρ by solving inf</p><formula xml:id="formula_4">(u,v)∈BV ×T E C-T (u, v) = μ||u|| T V + γ||v|| T + 1 2 ||u + v -f || 2 L 2 . (1.3)</formula><p>The cartoon component u is appropriately modeled by the space BV , using the T V seminorm in the energy (see <ref type="bibr">(1.2)</ref>). The recovered image is now u + v, the sum of the cartoon and texture components. The residual, ρ, is assumed to reside in L 2 , although other L p norms can be used. Meyer proposed several texture norms in his work; most notably, the G-norm (the predual of BV , i.e., G * = BV ) has seen much success in applications including color Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php image restoration <ref type="bibr" target="#b4">[5]</ref>, road detection <ref type="bibr" target="#b18">[19]</ref>, denoising <ref type="bibr" target="#b17">[18]</ref>, inpainting <ref type="bibr" target="#b5">[6]</ref>, image classification <ref type="bibr" target="#b3">[4]</ref>, and anomaly removal and pattern regularization <ref type="bibr" target="#b16">[17]</ref>. The space G is defined as follows.</p><p>Definition 1.1. The space G consists of all distributions v which can be written as v = div( g), where g = (g 1 , g 2 ) and g 1 , g 2 ∈ L ∞ . The norm on this space is defined as</p><formula xml:id="formula_5">||v|| G := inf g 2 1 + g 2 2 ∞</formula><p>v = div( g) . <ref type="bibr">(1.4)</ref> This texture space is particularly elegant because of its symmetry (specifically duality) with the cartoon space BV . However, this space is difficult to handle numerically. In <ref type="bibr" target="#b33">[33]</ref>, Vese and Osher proposed a method to approximate the G-norm by using the Sobolev spaces of negative differentiability, defined as W -1,p := v = div g g 1 , g 2 ∈ L p , and sending p → ∞. Rather than working with the texture v directly, this method works with the vector-field g:</p><formula xml:id="formula_6">inf (u,g)∈BV ×(L p ) 2 E OV (u, g) = μ||u|| T V + || g|| L p + λ 2 ||u + div g -f || 2 L 2 . (1.5)</formula><p>This formulation yields appropriate Euler-Lagrange equations for all p ≥ 1, which is easy to compute numerically. The results give satisfactory decompositions, particularly in the case of p = 1. Osher, Solé, and Vese <ref type="bibr" target="#b30">[30]</ref> proposed an alternative norm for the case of p = 2, which coincides with the space H -1 (the dual of the Hilbert space H 1 ). This dual space has an explicit norm defined as ||v|| H -1 = ||∇Δ -1 v|| L 2 , and the resulting Euler-Lagrange equation of the model reduces to a fourth order nonlinear partial differential equation. Later, Aujol et al. <ref type="bibr" target="#b2">[3]</ref> used projections to solve the original BV -G decomposition model and applied it to denoising of cartoon images (where the G-norm captures the noise) and to cartoon-texture separation. These weak spaces inspired many other texture norms, mainly in the form of dual spaces. In Lieu and Vese <ref type="bibr" target="#b23">[24]</ref>, the negative Hilbert spaces H -s for s &gt; 0, which are dual to the Hilbert-Sobolev spaces (H s ) * , were used for texture extraction and noise removal. Later, in Kim and Vese <ref type="bibr" target="#b21">[22]</ref>, the negative exponential Sobolev spaces W α,p for -2 ≤ α &lt; 0, which are dual to the Sobolev spaces with pseudoderivatives, were used for texture reconstruction in the presence of blur.</p><p>There are, in fact, an almost infinite number of texture norms that have been proposed, and this brief discussion just introduces this active field. In much of this work, the texture norms provide extra regularization on the recovered image, better recovering many of the features from the original image. However, these norms tend to be particularly difficult to implement in practice and do not deal well with noise.</p><p>Rather than considering the cartoon and texture components separately, the nonlocal methods simultaneously reconstruct these components. The nonlocal (NL) methods were first proposed by Buades, Coll, and Morel <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> as a nonlocal filter and were later formulated in a variational framework by Gilboa and Osher <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. The general framework involves replacing local derivatives by their nonlocal counterpart:</p><formula xml:id="formula_7">(∇ w u) (x, y) := (u(y) -u(x)) w(x, y) for all x, y ∈ Ω, where w(x, y) = e -d(u(x),u(y)) , d(u(x), u(y)) = Ω G(t)|u(x+t)-u(y+t)| 2 dt</formula><p>, and G(t) is a Gaussian with appropriate parameters. In the discrete version, each pixel is associated with a patch, and local differences are replaced by differences between pixels that have similar patches. Using these patch-based differences in the energy encourages repetitive behavior in the reconstructed image, thereby recovering the cartoon and texture while removing random noise. In particular, the nonlocal extension of the classical ROF model,</p><formula xml:id="formula_8">inf u E(u) = ||∇ w u|| L 1 + λ||u -f || 2 L 2 , (1.6)</formula><p>has been shown to recover the texture well. Although these models are useful, due to the global nature of images, they tend to be very slow in practice because of the frequent recomputation of the weight function w(x, y), especially for tasks such as deblurring and sparse reconstruction.</p><p>In this paper, we will combine cartoon-texture decomposition with the powerful patchbased methods using a texture norm motivated by recent work called robust principal component analysis (PCA). Robust PCA was proposed by Candès et al. <ref type="bibr" target="#b9">[10]</ref> in order to recover the sparse and low-rank parts of a given matrix f . This is also formulated as a decomposition problem: decompose f = u + v, where u is sparse and v is low-rank, by minimizing inf u,v</p><formula xml:id="formula_9">E P CA (u, v) = ||u|| L 1 + λ||v|| * s.t. f = u + v,</formula><p>where ||•|| * is the nuclear (or trace) norm, which is the sum of the singular values. Because this method almost exactly recovers the original sparse and low-rank components, it is becoming increasingly popular in practice. In the past few years, robust PCA has been applied to video surveillance <ref type="bibr" target="#b9">[10]</ref>, face recognition <ref type="bibr" target="#b9">[10]</ref>, video denoising <ref type="bibr" target="#b20">[21]</ref>, alignment <ref type="bibr" target="#b31">[31]</ref>, and low matrix rank textures <ref type="bibr" target="#b35">[35]</ref>. This variational model was later extended by Gao et al., who replaced the L 1 norm with a tight frame regularization <ref type="bibr" target="#b13">[14]</ref> and a T V regularization <ref type="bibr" target="#b14">[15]</ref>. The PCA models also benefit from the split Bregman method, making their implementation both efficient and fast.</p><p>Similar sparse decomposition methods exist in the class of dictionary learning techniques. The main idea of this technique is to find a sparse representation for an image with respect to a (learned) redundant dictionary. Elad and Aharon <ref type="bibr" target="#b12">[13]</ref> and Zhou et al. <ref type="bibr" target="#b36">[36]</ref> both applied (different) Bayesian approaches in order to construct dictionaries composed of subparts of the given image. In <ref type="bibr" target="#b27">[27]</ref>, Mairal, Elad, and Sapiro extended the idea of sparse representation over a dictionary to color image restoration, in particular, denoising, inpainting, and demosaicing. The idea of sparse coding was later combined with the nonlocal methods in the work of Mairal et al. <ref type="bibr" target="#b25">[26]</ref>. Similarly, in <ref type="bibr" target="#b11">[12]</ref>, the idea of structural clustering and dictionary learning was proposed and used for highly textured image restoration. Works such as <ref type="bibr" target="#b24">[25]</ref> have also provided more efficient and less costly ways to implement these dictionary learning methods.</p><p>At the time of this work, the PCA-based methods have not been combined with cartoontexture models, although they are of a very similar nature. Both PCA methods and cartoontexture models decompose a given f into two main components, where one is "sparse" in some sense and the other is "patterned." In this paper, we will connect the cartoon-texture models, robust PCA, and patch-based methods. The paper is divided as follows. In section 2, we derive and discuss our proposed texture norm and the proposed model. In section 3, Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php some theoretical remarks are made on the model, with characterization of the minimizers (for proofs, see Appendix B). In section 4, we describe the numerical implementation based on the split Bregman algorithm. Finally, in section 5, we detail the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Description of the model.</head><p>The proposed model will be of a form similar to that of the classical cartoon-texture decomposition models. Given an f , we decompose f = A(u + v) + ρ by minimizing the following energy:</p><formula xml:id="formula_10">inf u,v E(u, v) = μ||u|| T V + γ||v|| T exture + λ 2 ||A(u + v) -f || 2 2 ,</formula><p>where A is some degradation operator, for example, a reduction operator for missing data.</p><p>In practice, we solve this minimization using a double Bregman splitting, which can enforce f = A(u + v) exactly or can be relaxed in the presence of noise. The cartoon norm we use is the (discrete) total variation defined as</p><formula xml:id="formula_11">||u|| T V := ||Du|| 1 = i,j |Du i,j |, where D = [D x , D y ] is a differencing operator and |Du i,j | = (D x u i,j ) 2 + (D y u i,j ) 2 .</formula><p>For the rest of this work, we take D to be the forward differences. Before going into more detail, we first define our texture norm.</p><p>2.1. The texture norm. From an intuitive perspective, the texture component is a global and well-patterned structure within a given image. The distinct patterns that make up the entire texture are called base textures. We expect the number of base textures to be low, since an image may exhibit only a few individual patterns. In particular, each patch (i.e., subblock) should be composed of a combination of these base textures. Therefore, the overall collection of patches can be spanned by a small set of base patches. If the patches are written as vectors, then the collection of patch-vectors are (highly) linearly dependent and thus have low rank. This is the key to our definition of texture and its norm. Using this idea we have the following definition for the collection of patches and the texture norm.</p><p>Definition 2.1. The patch map P : M n,m → M r 2 , nm r 2 is defined by the following: for v ∈ M n,m , partition v into r by r (nonoverlapping) submatrices, labeled {B i } nm r 2 i=1 . Next, transform each of the B i 's into a column vector of length r 2 , called w i . Then augment the vectors together to form the new matrix</p><formula xml:id="formula_12">Pv := w 1 • • • w nm r 2</formula><p>.</p><p>The specific ordering which maps the patch to a patch-vector is not important, as long as it is consistent (see Lemma 3.7). For the results in this paper, a raster scan (row by row) was used to arrange the patches, and a second raster scan was used to rewrite each patch as a vector.</p><p>Note that the patch map does not increase the number of terms since the patches are nonoverlapping. Also, the collection of texture patches is found by applying the patch map to the texture. Figure <ref type="figure" target="#fig_0">1</ref> depicts the patch map applied to a matrix. Using Definition 2.1 and the behavior we expect on the texture, the natural norm on Pv would be ||v|| T : ? = rank (Pv) . Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php However, this energy is nonconvex and difficult to use in practice. Furthermore, rank is not a norm in the mathematical sense. Using the ideas from robust PCA <ref type="bibr" target="#b9">[10]</ref>, we can replace the rank by the nuclear/trace norm, which is the convex envelope to the rank and is in fact a norm. Thus, the suggested texture norm can be relaxed to the following: Definition 2.2. A function v ∈ T if it is mean zero and if the following quantity is finite:</p><formula xml:id="formula_13">||v|| T := ||Pv|| * ,</formula><p>where || • || * is the nuclear/trace norm, i.e., the sum of the singular values. For a discrete function v, the norm ||v|| T is always finite, but we use this definition for a more general v which will be addressed in future work. Unlike the nonlocal methods, this norm does not explicitly calculate the weights between patches, but rather compares the patches implicitly. In this way, our nonlocal measure is computationally more efficient, while still being easy to compute and simple to minimize. To better understand Definition 2.2, here is an example of a texture and its norm.</p><p>Example 2.3. Let the texture be the zero mean vertical stripe pattern defined as</p><formula xml:id="formula_14">v i,j = 1, j is even, -1</formula><p>otherwise of size N by N . Then after applying the patch map with 2 by 2 patches, we have the following:</p><formula xml:id="formula_15">P 2×2 v = ⎡ ⎢ ⎢ ⎣ -1 -1 1 1 • • • -1 -1 1 1 ⎤ ⎥ ⎥ ⎦ .</formula><p>Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>Similarly, after applying the patch map with 3 by 3 patches we have the following:</p><formula xml:id="formula_16">P 3×3 v = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ -1 1 1 -1 -1 1 -1 1 1 -1 • • • -1 1 -1 1 1 -1 -1 1 ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ .</formula><p>In both cases the resulting matrices are of rank </p><formula xml:id="formula_17">= A(u + v) + ρ by minimizing E(u, v) = μ||Du|| 1 + γ||Pv|| * + λ 2 ||A(u + v) -f || 2 2 (2.1)</formula><p>for all (u, v) ∈ A, where the admissible set is</p><formula xml:id="formula_18">A := (u, v) u = f, v = 0 .</formula><p>In practice, the minimizers remain in this admissible set without any formal constraints. The operator A is assumed to be linear. For denoising, A is the identity; for deblurring, it is a convolution with a blur kernel; and for inpainting or sparse reconstruction, it is a reduction operator.</p><p>Recall that minimizing this energy ensures that the cartoon will be in discrete BV , thereby being piecewise smooth with sharp edges. The texture norm ensures a low patch-rank collection of textures and thus a small amount of repetitive textures. The residual (or noise) term ρ := A(u + v)f remains in L 2 since it is assumed to have no particular structure. In our examples, the noise is Gaussian; however, the residual term λ 2 ||ρ|| 2 2 can be replaced with other norms depending on the type of corruption. For example, impulse noise and blind inpainting (of small regions) is better captured by using the L 1 norm, i.e., λ||ρ|| 1 .</p><p>In Figure <ref type="figure" target="#fig_1">2</ref>, we provide a simple decomposition example. The cartoon consists of concentric annuli, the texture is a repetitive stripe pattern, and the noise is random. In this example, the rank of the texture is 1, while the cartoon and noise components have full rank. It is worth noting that this decomposition is not equivalent to thresholding the input images' singular values. Figure <ref type="figure" target="#fig_2">3</ref> plots the singular values in descending order of each of the images from Figure <ref type="figure" target="#fig_1">2</ref> (after applying the patch map). The texture has only one singular value since it is composed of only one pattern. The cartoon has many patch patterns based on the various alignments of edges between the homogeneous regions, all with varying degrees of importance, with the most important being the constant patch. The noise has almost no coherent structures, which can be seen in its singular values. From Figure <ref type="figure" target="#fig_2">3</ref>, it is clear that the texture is the only component to have many zero singular values. Even if the "smaller" singular values were thresholded, the texture component would still have the smallest singular value support.</p><p>In Figure <ref type="figure" target="#fig_4">4</ref>, we see that even seemingly random textures have a small patch-rank. Remark 2.4. Like the cartoon-texture symmetry from the BV -G model, our cartoon and texture norms are related in a curious way. For the cartoon u, the operator D is applied and the result is measured in L 1 . For the texture v, the patch-texture is decomposed by the singular value decomposition; consequently, there exist two unitary matrices U and V such that Pv = U ΣV * , where Σ is a diagonal matrix that contains the singular values of Pv. This is equivalent to the L 1 norm on Σ, i. Remark 2.5. There are many ways to view our texture norm. 1. From the perspective of nonlocal methods, our norm measures the similarity between patches based on linear dependence rather than elementwise differences. In these methods, the typical measure of similarity is the exponential of the L 2 distance between patches. This can cause problems when two patches agree exactly in texture but have different means. Specifically, if the difference in means is large, then the patches are considered to be dissimilar, which can lead to improper comparisons between patches.</p><p>In practice, this leads to problems in contrast (see Figure <ref type="figure" target="#fig_17">19</ref>). 2. From a dictionary approach, our texture norm creates a basis B i for i = 1, . . . , rank (Pv) composed of the singular vectors of Pv. All patches are thus composed of linear combinations from this basis, creating an implicit dictionary based on the image itself.  which is used in the energy. As with the functional spaces, the proposed texture norm decreases as the pattern becomes more repetitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Theoretical and analytical remarks.</head><p>In this section we will examine the behavior of the cartoon-texture separation model, with the constraint that the input data f is of mean zero. This is not a restriction in practice since it is simply a rescaling of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Characterization of minimizers by duality.</head><p>In the continuous framework, the predual of BV is G, the space of generalized functions. As in Definition 1.1, the space G is equivalent to the space of functions which are the divergence of L ∞ vector fields. The space and norm first appeared in the characterization of minimizers for the ROF model and then in cartoon-texture models <ref type="bibr" target="#b28">[28]</ref>. For our discrete model, we would like an analogous space which has a similar duality to our discrete BV space. In <ref type="bibr" target="#b1">[2]</ref>, a discrete G is given as follows.</p><p>Definition 3.1. The dual of (discrete) BV is the (discrete) space G, which has the following norm:</p><formula xml:id="formula_19">||v|| G := inf v=div g (g 1 i,j ) 2 + (g 2 i,j ) 2 L ∞ ,</formula><p>where g i,j = (g 1 i,j , g 2 i,j ). We will consider the discrete divergence operator to be div = D - x , D - y •, where D - i are the backward differences. It can be shown that this definition of divergence yields div = -D * , Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php where D * is the adjoint of the operator from the definition of discrete T V . This is necessary to ensure a discrete duality principle, or, in other words, for any u and v, | u, v | ≤ ||Du|| 1 ||v|| G . A similar duality is needed with respect to the texture norm, which follows from the following properties of the patch map.</p><p>Lemma There are sharper bounds for condition 3 above; however, they depend on the patch size and the texture component. The proofs for each of the above are easy to show. From these properties, the texture duality can be shown to be | u, v | ≤ ||Pu|| s ||Pv|| * . Based on these dualities, there are four characterization theorems given below. The characterization is centered around the pure decomposition version of the model (when A = I):</p><formula xml:id="formula_20">E(u, v) = μ||Du|| 1 + γ||Pv|| * + λ 2 ||u + v -f || 2 2 . (3.1)</formula><p>The theorems give a relationship between the parameters (μ, γ, λ) and the quantities ||f || G and ||Pf || s = σ max (Pf ) (which is the maximum singular value of the patch-form of the image). The first two theorems address the two trivial decompositions where no cartoon appears and the optimal solutions vary between the texture and residual terms. The proofs of these theorems can be found in Appendix B.</p><formula xml:id="formula_21">Theorem 3.3. If 0 &lt; γ &lt; 2μ n , then the minimizer (u, v, ρ) must have u = 0. If, in addition, ||Pf || s ≤ γ λ , then the minimizer (u, v, ρ) yields u = ρ = 0 and v = f . Theorem 3.4. If ||f || G ≤ μ λ and ||Pf || s ≤ γ λ , then the minimizer (u, v, ρ) must yield u = v = 0 and ρ = f .</formula><p>The last two theorems are the more interesting cases. By choosing the parameters accordingly, the resulting optimal solutions will provide nontrivial decompositions.</p><p>Theorem 3.5.</p><formula xml:id="formula_22">If ||f || G &gt; μ λ and ||Pf || s &gt; γ λ , then the minimizer yields ||ρ|| G = μ λ , ||Pρ|| s = γ λ , ρ, u = μ λ ||Du|| 1 , and ρ, v = γ λ ||Pv|| * . Theorem 3.6. If ||f || G ≤ μ</formula><p>λ and ||Pf || s &gt; γ λ , then three optimal cases hold:</p><formula xml:id="formula_23">(1) u = 0, ||ρ|| G &lt; μ λ , ||Pρ|| s ≤ γ λ , and ρ, v = γ λ ||Pv|| * . (2) v = 0, ||ρ|| G = μ λ , ||Pρ|| s &lt; γ λ , and ρ, u = μ λ ||Du|| 1 . (3) ||ρ|| G = μ λ , ||Pρ|| s = γ λ , ρ, v = γ λ ||Pv|| * ,</formula><p>and ρ, u = μ λ ||Du|| 1 . These theorems provide some insight into choosing coefficients to obtain particular behaviors in the minimizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Characterization of texture based on P.</head><p>We can further characterize solutions based on our patch map. The operator P is implicitly dependent on both the way in which the elements are reassigned and the patch size. First, to address the "reshaping" we have the following theorem.</p><p>Lemma 3.7. Let P 1 and P 2 be two patch maps which are identical except for the order in which they map the subblocks of v into the columns of P i v, and the elements within the subblock of v into the rows of P i v. Then we have that, for all v, ||P 1 v|| * = ||P 2 v|| * . Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php By this lemma we see that our method is independent of the ordering used to reshape the texture matrix into the patch-form.</p><p>Next, let us address the dependence of the texture component on the patch size r (for now assume that the patches are square). Like the tuning parameters in the energy, this parameter also determines certain characteristics of the minimizers. For example, the patch size has a subtle relationship with the various "texture frequencies." Consider the following example.</p><p>Example 3.8. Let f (x, y) be a mean zero function that has an oscillation of period T only in the x-direction (and constant along the y-direction). Let r be the length of the square patches.</p><p>1. If T &lt; r, then the patch-rank must be larger than or equal to 1. If there are small scale symmetries during one period, then the patch-rank can be equal to 1. For example, take r</p><formula xml:id="formula_24">= T 2 . If f (x, y) = -f (x + T 2 , y), then the patch on [1, T 2 ] × [1, T 2 ] is equal to the negative of the patch on [ T 2 + 1, T ] × [ T 2 + 1, T ].</formula><p>It follows that there is only one underlying base patch, so the rank is 1. 2. If T &gt; r, then the patch-rank must be larger than or equal to 1. This can be shown by using the previous argument with r = 3T 2 . 3. If T = r, then the patch-rank will be 1.</p><p>From this example, it is clear that to minimize the number of patches needed to describe a given texture, the parameter r should be as close to the pattern period as possible.</p><p>Last, the following lemma address the partitioning of the texture component. Lemma 3.9. Let P be a patch map, and let S be a index shifting operator (with periodic boundary conditions); then for any matrix v, ||PSv|| * = ||Pv|| * holds.</p><p>The lemma shows that the patch map is invariant under uniform translations of the indices; therefore our proposed method is invariant of the partitioning grid. This is easy to show, since shifting the grid is equivalent to reordering the indices but does not change the relationship between indices, as in Lemma 3.7.</p><p>4. Numerical method. The cartoon and texture are both defined with respect to fine (lower-dimensional) structures: codimensional 1 edges in the cartoon and codimensional 1 and 2 patterns in the texture. They are also both measured by L 1 -type norms, which are efficiently solved by splitting methods -in our case the split Bregman method <ref type="bibr" target="#b19">[20]</ref>. The added advantage of these splitting methods is that lower-dimensional structures get enhanced. This is normally referred to as contrast enhancement, i.e., the sharpening of edges. An analogous effect seems to sharpen the "texture contrast," specifically linear features and isolated point structures. It is interesting to note that in practice, the Bregman iteration removes any block effects from the texture component, which occur from the nonoverlapping patch structure.</p><p>Below is an outline of the split Bregman technique applied to our model. We use a double Bregman, since both terms u and v are split. First introduce the auxiliary variables d 1 = Du and d 2 = Pv:</p><formula xml:id="formula_25">min d 1 =Du,d 2 =Pv μ||d 1 || 1 + γ||d 2 || * + λ 2 ||A(u + v) -f || 2 2 .</formula><p>Next add back the constraints d 1 = Du and d 2 = Pv, enforcing them with the Bregman Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><formula xml:id="formula_26">variables b 1 , b 2 : min d 1 ,d 2 ,u,v μ||d 1 || 1 + γ||d 2 || * + λ 2 ||A(u + v) -f || 2 2 + λ 1 2 ||d 1 -Du + b 1 || 2 2 + λ 2 2 ||d 2 -Pv + b 2 || 2 2 .</formula><p>This splitting decouples the original equation into the following system:</p><formula xml:id="formula_27">(u n+1 , v n+1 ) = argmin u n ,v n λ 2 ||A(u n + v n ) -f + f n || 2 2 + λ 1 2 ||d n 1 -Du n -b n 1 || 2 2 (4.1) + λ 2 2 ||d n 2 -Pv n -b n 2 || 2 2 , d n+1 1 = argmin d n 1 μ||d n 1 || 1 + λ 1 2 ||d n 1 -Du n+1 -b n 1 || 2 2 , (4.2) d n+1 2 = argmin d n 2 γ||d n 2 || * + λ 2 2 ||d n 2 -Pv n+1 -b n 2 || 2 2 , (4.3) b n+1 1 = b n 1 + Du n+1 -d n+1 1 , (4.4) b n+1 2 = b n 2 + Pv n+1 -d n+1 2 . (4.5)</formula><p>In (4.1), we have also included the Bregman variable f n , which is used when one wants to enforce the constraint A(u + v) = f . Each of the subproblems above can be easily solved, as follows. For the first subproblem, from Lemma 3.7 and the tensor discussion in Appendix A, we can rewrite (4.1) as</p><formula xml:id="formula_28">(u n+1 , v n+1 ) = argmin u n ,v n λ 2 ||A(u n + v n ) -f + f n || 2 2 + λ 1 2 ||d n 1 -Du n -b n 1 || 2 2 + λ 2 2 ||P -1 d n 2 -v n -P -1 b n 2 || 2 2 .</formula><p>Since this problem is differentiable, taking the first variation yields the following linear system:</p><formula xml:id="formula_29">(4.6) (λA * A -λ 1 Δ) u n+1 + λA * Av n+1 = F 1 , λA * Au n+1 + (λA * A + λ 2 ) v n+1 = F 2 ,</formula><p>where</p><formula xml:id="formula_30">F 1 = λA * (f -f n ) -λ 1 D * (d n 1 -b n 1 ) and F 2 = λA * (f -f n ) + λ 2 P -1 (d n 2 -b n 2 )</formula><p>. This equation can be solved completely (in the Fourier domain) or approximated with a few iterations of a Gauss-Seidel (GS) sweep. Next, (4.2) can be written out explicitly as a simple shrink:</p><formula xml:id="formula_31">d n+1 1 = shrink Du n+1 + b n 1 , μ λ 1 ,</formula><p>where the shrink function above is defined pointwise for two-dimensional vectors x as shrink(x, τ ) := max (|x| 2τ, 0) x |x| 2 , and where | • | 2 is the vector 2-norm and τ ∈ R. Last, (4.3) can be written explicitly as</p><formula xml:id="formula_32">d n+1 2 = SV T Pv n+1 + b n 2 , γ λ 2 ,</formula><p>where SV T is singular value thresholding, which is defined as follows: for a matrix M whose singular value decomposition (SVD) is given by M = U ΣV * , the singular value thresholding function is defined as SV T (M, τ ) := U max(Σ-τ I, 0) V * , where the max is taken elementwise. There are methods for computing the SV T without using the SVD (see <ref type="bibr" target="#b8">[9]</ref>), which can speed up the computations for large matrices. Using these formulas, the algorithm is presented in the next section.</p><p>4.1. The algorithm. The splitting from the previous section reduces the problem from a difficult nonlinear one to a sequence of simple linear (or explicit) subproblems. The algorithm involves two main loops: the inner loop, which solves each minimization, and the outer loop, which adds back the error and re-solves the minimization. The outer loop's termination is dependent on the problem we are solving, specifically on the amount of noise. Given a tolerance tol, for pure decomposition with no noise or for inpainting with no noise, the outer loop is iterated until ||f -A(u n+1 + v n+1 )|| 2 ≤ tol. In the presence of noise with standard deviation σ noise , the stopping criterion becomes ||f -A(u n+1v n+1 )|| 2 ≈ σ noise . The number of outer loops also determines the amount of texture-noise separation that occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Initialize</p><formula xml:id="formula_33">u 0 = f , v 0 = 0, d 0 1,x = d 0 1,y = b 0 1,x = b 0 1,y = 0 n,n , and d 0 2 = b 2 = 0 r 2 , n 2 r 2</formula><p>while Outer Iteration do while Inner Iteration do</p><formula xml:id="formula_34">(u n+1 , v n+1 ) = GS n d n+1 1 = shrink Du n+1 + b n 1 , μ λ 1 , d n+1 2 = SV T Pv n+1 + b n 2 , γ λ 2 , b n+1 1 = b n 1 + Du n+1 -d n+1 1 , b n+1 2 = b n 2 + Pv n+1 -d n+1 2 end while f n+1 = f n + f -u n+1 + v n+1 end while</formula><p>In the algorithm, GS n is the application of Gauss-Seidel sweeping to (4.6). Typically, only a few sweeps are necessary, since only partial convergence is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results.</head><p>In the previous section, methods for choosing appropriate parameters were given in the examples and theorems. Before discussing the numerical results, a summary with one more parameter bound will be provided. Informally, an upper bound on the number of expected textures can be predicted, thereby providing a bound on rank(Pv). As previously mentioned, the texture is composed of highly oscillatory functions. If we model them as sums of sines and cosines, then the Fourier transform yields sums of Dirac delta functions at those frequencies. In practice, the textures appear as pairs of spikes (of various amplitudes) in the Fourier domain (see Figure <ref type="figure" target="#fig_5">5</ref>). By counting the number of spikes in the Fourier domain, Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. one can estimate an upper bound for the patch-rank (it is only an upper bound since jump discontinuities can contribute to the spikes).</p><p>Let r × r be the patch size of Pv; then we have the following: 1. From the argument above, take r 2 to be close to half the number of "large" spikes in |F (v) |. 2. From Example 3.8, if the largest texture period is T , then take r to be as close to T as possible. 3. Choose (μ, γ, λ) based on Theorems 3.3-3.6. Also, the ratio μ λ 1 determines the amount of cartoon, while the ratio γ λ 2 determines the amount of texture. 4. Normalizing f such that |f i,j | = 1 (or max |f i,j | = 1) and f i,j = 0 helps when choosing (μ, γ, λ). 5. Setting λ = λ 1 = λ 2 gives appropriate results and removes two parameters from the model. 6. In regard to the algorithm, the number of outer loops determines the "amount of edges and texture" that is added back. If the original image is noisy, this parameter must be tuned in order to avoid adding back the noise. As mentioned in <ref type="bibr" target="#b19">[20]</ref>, the number of GS sweeps can be fixed to a value of 2-5 (only partially converging), and the method will give satisfactory results. For the results that follow we take 5 by 5 patches (unless otherwise stated), λ = 1, μ ∈ [.75, 2], and γ ≈ σ max (Pv).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Decomposition.</head><p>For the pure cartoon-texture decomposition problem, we would like to remove the texture component without removing other key features such as edges and shading. Take, for example, the Barbara image (Figure <ref type="figure" target="#fig_6">6</ref>). We estimated approximately 25 spikes in the Fourier domain, so a patch size of 5 by 5 is more than sufficient. In Figure <ref type="figure">7</ref>, our method is compared to the standard T V -G model <ref type="bibr" target="#b2">[3]</ref> and the T V -L 2 model (i.e., ROF model). For T V -L 2 , we use the split Bregman approach from <ref type="bibr" target="#b19">[20]</ref>. For all models, the parameters are chosen in order to have the same L 2 norm on the texture component. As seen in Figure <ref type="figure">7</ref>, our method provides results similar to those of the classical T V -G separation while removing fewer edges, for example, Barbara's hair and the background. Unlike our method, the T V -L 2 model does not remove the texture evenly.</p><p>In Figure <ref type="figure">8</ref>, the texture component's dependence on the patch size is examined. The similarity between the textures suggests some flexibility in determining the patch size, although the smaller patch size yields less texture, while the large patch size removes nontexture features. In Figure <ref type="figure">9</ref>, the texture component's dependence on γ (the texture norm's coefficient in the energy) is investigated by fixing μ and λ. Increasing γ gives smaller patch-ranks and removes fewer nontexture features, while decreasing γ removes more details from the cartoon (see Theorem 3.3).</p><p>Fixing the texture from Figure <ref type="figure">8</ref>(d) and decomposing the patch-form by the SVD yields Pv = U ΣV * , i.e., v = P -1 (U ΣV * ), where the diagonal matrix Σ = diag(σ 1 , . . . , σ r , 0, . . . , 0) contains the r singular values in descending order. In Figure <ref type="figure" target="#fig_17">10</ref>, this texture is then reconstructed using only some singular vectors (thresholding Σ). Note that the singular values capture the relative significances of the base textures.</p><p>Last, Figure <ref type="figure" target="#fig_4">4</ref> shows the wide range of textures that can be captured by our model. The Tank and Grass images have visually random patterns yet have small patch-ranks (51.0% and 19.1%, respectively). Section 5.5.1 will discuss in more detail the types of textures that can be well represented by our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Pattern regularization.</head><p>Since our texture norm penalizes nonuniform behavior between patches, our decomposition can be applied to image regularization. By regularizing the patterns, irregularities in the image are removed. In Figures <ref type="figure" target="#fig_17">11</ref> and<ref type="figure" target="#fig_17">12</ref>, we regularize the highly textured Brodatz image using (3.1). The image f is decomposed into f = u + v + ρ, where u + v is the regularized image and ρ contains the irregularities. In Figure <ref type="figure" target="#fig_17">12</ref>, it can be seen that, in our method, the essential vertical pattern is preserved, while the unwanted point structures are removed. Furthermore, our method also retains more texture than the standard median filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Denoising.</head><p>In Figure <ref type="figure" target="#fig_1">2</ref>, we saw the nearly perfect recovery of a noisy synthetic image. Texture-noise separation is difficult for most cartoon-texture decomposition methods; see Figure <ref type="figure" target="#fig_10">13</ref>. In Figures <ref type="figure" target="#fig_17">14</ref> and<ref type="figure" target="#fig_18">15</ref>, the Brodatz image is degraded by Gaussian noise of zero mean and recovered by T V -L 2 , NLT V -L 2 , and our method. For NLT V -L 2 , to make the Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php comparison as similar as possible, we use a semilocal version with the same patch size as in our method <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. In both the T V -L 2 and the NLT V -L 2 models, the noise is removed from Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php the top left quadrant. However, in more textured quadrants, more texture loss is seen (see Figure <ref type="figure" target="#fig_18">15</ref>). For T V -L 2 (peak signal-to-noise ratio (PSNR) = 30.2), although some texture Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php    particular level of smoothness. Our method recovers both parts well, with the highest PSNR of 32.8, while being faster than the semilocal method (restricting the window size to 11 by 11). The slight oscillatory pattern that appears in the top left quadrant is an artifact of the nonlocality of SVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3.1.</head><p>Denoising: Quantitative comparisons. In general, there are no exact metrics in which to compare textures; however, there are some features which one prefers. In particular, a "good texture" component is noise-free and contains many sharp small scale details. Since noise is dense and has many false spikes, we can measure the noise level in the texture component by computing the sparsity of the texture component (as a percent of total pixels) and the percent of pixels which are considered edges (after applying a gradient-based edge detector). The smaller the value of both the edge and the intensity sparsity, the better the texture. To measure the amount of noise that is removed by a method, we compute the entropy of the noise component and compare it to the known entropy of the added noise. The entropy is also applied to the error term to measure the amount of structure and texture that is lost to the noise component. A small error entropy means that the recovered image is closer to the original in terms of small scale features (since oscillations may appear as larger entropy). Last, for reference, the patch-rank is computed for each method. We compare our proposed texture method to standard ones using various texture and noise metrics.</p><p>In Table <ref type="table" target="#tab_3">1</ref>, the synthetic image from Figure <ref type="figure" target="#fig_1">2</ref> is denoised by various methods. Each method has the same variance on its corresponding noise component. Since the true cartoon and true texture are known, we compare only the SNR of each component. Note that both of the entropy metrics order the methods in a way that is similar (but not exactly equivalent) to that of the SNR. In Table <ref type="table" target="#tab_4">2</ref>, a noisy version of the Brodatz-Wood image is denoised. Our method does as well as the nonlocal methods in terms of SNR, but does better in terms of removing the appropriate noise distribution (measured by entropy). Compared to the other standard cartoon-texture methods, our proposed model outputs a less noisy texture component. In Tables 3 and 4, we compare our method only with other cartoon-texture decomposition methods. In both cases, it is clear that our method better handles texture-noise separation. Using these results, we can partially conclude that this pattern-based interpretation is a more appropriate Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php definition for texture than those that are based on oscillations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Deblurring.</head><p>Blurry images tend to have severe texture loss and require methods which reconstruct the texture well. In Figure <ref type="figure" target="#fig_17">16</ref>, the Barbara image is blurred by a Gaussian kernel with a standard deviation of 1.1. We compare our recovered image with the T V -L 2 and NLT V -L 2 <ref type="bibr" target="#b34">[34]</ref> deblurring methods. In terms of PSNR, our method better reconstructs the image with the NLT V method getting very close results. Visually, the textures on the </p><formula xml:id="formula_35">T V -H -1 -L 2 9</formula><p>.57 0.3% 1 67.8% 100% 3.34 3.49 1 The T V -H -1 -L 2 decomposition has a texture component that is mostly low amplitude noise, so the gradient detector outputs almost no edges.</p><p>left and right ends of the scarf are sharper in our recovered image than in the others. Since the production of sharp edges is the key to deblurring methods, we can also quantitatively compare the results by measuring the percent of edge pixels in the image (using a gradientbased edge detector). The blurred image has 15.4% edge pixels, the T V method has 16.3% Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php edge pixels, and the NLT V method has 18.6% edge pixels, while ours has the most at 19.2% edge pixels. Using this metric, we can conclude that our method better produces features of sharp contrast. On a side note, in practice the texture regularized images do not seem to have the typical ringing effect associated with deconvolution problems. This leads us to believe that texture regularized models are more stable for deblurring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Inpainting: Sparse reconstruction.</head><p>In this and the next section, we discuss textureregularized inpainting. There are two main types of inpainting: missing regions and sparse reconstruction. For inpainting missing regions, the image is first separated into its components, with the cartoon part recovered using a "structure" based inpainting, while the texture part is inpainted by texture-based techniques (for more on this methodology, see <ref type="bibr" target="#b5">[6]</ref>). The numerical results presented here focus on sparse reconstruction. As an example, our method recovers an image almost perfectly (root mean square error (RMSE) is less than 0.08) with more than 50% of the pixels randomly removed; see Figure <ref type="figure" target="#fig_17">17</ref>. In Figures <ref type="figure" target="#fig_17">18</ref> and<ref type="figure" target="#fig_17">19</ref>, we compare our method to T V -L 2 and NLT V -L 2 inpainting on an image with more than 65% of the pixels randomly removed. Our method is comparable in speed to T V -L 2 and faster than NLT V -L 2 . Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. 5.5.1. Sparse reconstruction and denoising: Quantitative comparisons. Last, we investigate the type of textures which can be well represented within this framework. To do so, we generate a set of corrupt highly textured images by adding a fixed amount of noise to 100 images from <ref type="bibr" target="#b22">[23]</ref> and then sparse sampling these images (removing half of the number of pixels). Our algorithm was applied to all of the corrupt images with parameters set at around μ = 1, λ = λ 1 = λ 2 = 1, 3 GS sweeps, 5 inner iterations, and 15 outer iterations. The patch size varied from 10 by 10 to 20 by 20 to match the texture scale of each individual image. The parameters were chosen to yield patch-ranks under 50. Table <ref type="table" target="#tab_7">5</ref> displays statistics on the RMSE between the recovered image and the original, the RMSE between the original and the corrupt image, the percentage decrease in RMSE after the recovery, and the patch-rank (which is normalized out of 100). By considering the RMSE, the amount the RMSE changed, the patch-rank, and visual metrics, we can evaluate which textures are well represented by our method.</p><p>Although the patches are formed on a grid, the resulting textures do not have to be gridlike in structure or in pattern. Based on this experiment, our method is not sensitive to the angle or directionality of the texture pattern, the texture plane (i.e., frontal versus nonfrontal textures), the geometry of the pattern, or the geometry of the texture plane. For example, in Figure <ref type="figure" target="#fig_15">20</ref>, the texture resides on a warped or nonuniform geometry, which does not align with the patch grid. However, our method preforms well on this textured image and others like it. Our method has difficulty in capturing texture which does not have a regular pattern or has highly deviating structures. An example of this can be found in Figure <ref type="figure" target="#fig_16">21</ref>, where the patterns have many irregular shapes over many scales. In this example, the texture component does not have a geometrically uniform pattern, and we can see loss of texture in the recovered image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion.</head><p>In this paper, we have presented a different way to model image texture or patterns in data. From the matrix perspective, we proposed measuring the patch-based singular values as a norm for the texture space. The new texture norm was used as a regularizer in models for decomposing, pattern regularizing, denoising, deblurring, and sparse reconstruction. Given a corrupt image f , the recovered image is reconstructed componentwise as u + v, where u is the cartoon (piecewise smooth) part, while v is the oscillatory/patterned texture  part. The various results support the benefit of including a texture regularizer rather than only reconstructing the smooth component. While other techniques for texture reconstruction exist, our method has the advantage of separating texture from noise, as well as its simplicity of construction, ease of implementation, and speed. The tensor is bijective since it is a unique invertible mapping. Furthermore, the tensor is a unitary transformation with respect to the elementwise inner product since for all v 1 and v 2 , Pv 1 , Pv 2 = v 1 , v 2 holds. Appendix B. Proofs of theorems. The proofs below are a generalization of the theory from Gilles and Meyer's work <ref type="bibr" target="#b18">[19]</ref>. The main difference is that extra care must be given since there is no duality between our cartoon and texture norms. the following hold:</p><formula xml:id="formula_36">1. If ||f || ≤ 1 λ , then u = 0 and v = f . 2. If ||f || &gt; 1 λ , then ||v|| = 1 λ and u, v = 1 λ ||u||. Lemma B.</formula><p>1 will be used in many of the arguments in the various proofs. As in <ref type="bibr" target="#b18">[19]</ref>, the cartoon, texture, and error norms have a proper ordering.</p><p>Lemma B.2. For all n by n matrices g (with mean zero), we have the following:</p><formula xml:id="formula_37">||Pg|| * ≤ √ n||g|| 2 ≤ n 2 ||Dg|| 1 .</formula><p>The lemma above provides a comparison between the terms in the energy and allows for the generalization of duality. More precisely, Lemma B.3 describes the dual pairing relationships.</p><p>Lemma B.3. For all n by n matrices u and v, we have the following:</p><formula xml:id="formula_38">| u, v | ≤ ||Du|| 1 ||v|| G , | u, v | ≤ ||Pu|| s ||Pv|| * .</formula><p>Proof. For the first inequality, take any (u, v) and let there exist a g such that v = divg, and thus</p><formula xml:id="formula_39">| u, v | = | u, divg | = | Du, g | ≤ ||Du|| 1 ||g|| ∞ .</formula><p>Then taking the infimum with respect to all possible g yields the inequality. For the second inequality, we use the properties of P:</p><formula xml:id="formula_40">| u, v | = | Pu, Pv | ≤ ||Pu|| s ||Pv|| * .</formula><p>Note that the spectral and trace norms are dual.</p><p>In order to apply Lemma B.1 to our model, we look at the pair (u, v) simultaneously. To do so, define w = u + v to be the reconstructed image composed of both components with the induced norm ||w|| = inf {μ||Du|| 1 + γ||Pv|| * }. The dual norm is defined as ||g|| = sup 1 μ ||g|| G , 1 γ ||Pg|| s . Writing the energy in terms of w yields</p><formula xml:id="formula_41">E(w) = ||w|| + λ 2 ||f -w|| 2 2 .</formula><p>We will consider this in many of the proofs that follow. Throughout Appendix B, the energy E will be a functional with arguments u, v, and ρ depending on the particular proof; however, all are equivalent by the relationship u+v +ρ = f with f given.</p><p>Theorem B.4. If 0 &lt; γ &lt; 2μ n , then the optimal decomposition yields u = 0. Proof. Examining the energy with respect to the cartoon component u and the residual ρ, the energy can be bounded below by using Lemma B.2 and positivity of the norms:</p><formula xml:id="formula_42">E(u, ρ) = μ||Du|| 1 + γ||P(f -u -ρ)|| * + λ 2 ||ρ|| 2 2 ≥ 2μ n ||Pu|| * + γ||P(f -u -ρ)|| * + λ 2 ||ρ|| 2 2 ≥ γ {||Pu|| * + ||P(f -u -ρ)|| * } + λ 2 ||ρ|| 2 2 ≥ γ||P(f -ρ)|| * + λ 2 ||ρ|| 2 2 = E(0, ρ).</formula><p>For all u = 0 we have ||Pu|| * &gt; 0; therefore u = 0 is the minimizer.</p><p>Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>Next, using Theorem B.4 with an additional constraint on f yields another trivial minimizer.</p><p>Theorem B.5. If 0 &lt; γ &lt; 2μ n and ||Pf || s ≤ γ λ , then the optimal decomposition yields u = ρ = 0 and v = f . Proof. From Theorem B.4, since 0 &lt; γ &lt; 2μ n , the energy is equivalent to the following:</p><formula xml:id="formula_43">E(0, ρ) = γ||P(f -ρ)|| * + λ 2 ||ρ|| 2 2 .</formula><p>By Lemma B.1, since ||Pf || s ≤ γ λ , then ρ is identically 0. The theorems above provide the conditions in which the texture and/or residual component contains all of the information. The theorem below provides the final trivial case.</p><p>Theorem B.6. If ||f || G ≤ μ λ and ||Pf || s ≤ γ λ , then the optimal decomposition yields u = v = 0 and ρ = f . Proof. Consider the simultaneous energy (with respect to w)</p><formula xml:id="formula_44">E(w) = ||w|| + λ 2 ||f -w|| 2 2 .</formula><p>The value of f in the dual norm can be calculated by using the assumptions</p><formula xml:id="formula_45">||f || = sup 1 μ ||f || G , 1 γ ||Pf || s ≤ sup 1 λ , 1 λ = 1 λ .</formula><p>Applying Lemma B.1 yields w = 0, which implies both u = 0 and v = 0. For the first nontrivial decomposition, Theorem B.7 characterizes minimizers when f is large with respect to particular norms.</p><p>Theorem B. </p><formula xml:id="formula_46">1) u = 0, ||ρ|| G &lt; μ λ , ||Pρ|| s = γ λ , and ρ, v = γ λ ||Pv|| * . (2) v = 0, ||ρ|| G = μ λ , ||Pρ|| s &lt; γ λ , and ρ, u = μ λ ||Du|| 1 . (3) ||ρ|| G = μ λ , ||Pρ|| s = γ λ , ρ, v = γ λ ||Pv|| * ,</formula><p>and ρ, u = μ λ ||Du|| 1 . All of the cases above are also the optimal decompositions for the energy.</p><p>Proof. Consider the simultaneous energy in terms of w:</p><formula xml:id="formula_47">E(w) = ||w|| + λ 2 ||f -w|| 2 2 .</formula><p>Under the assumptions of this theorem, the simultaneous dual norm of f is bounded below, i.e., ||f || &gt; 1 λ , and by Lemma B.1, ||ρ|| = 1 λ , and ρ, w = 1 λ ||w||. This can occur in three ways. The proof is divided into several subproofs for each of the cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">First assume that ||ρ||</head><formula xml:id="formula_48">G &lt; μ λ , ||Pρ|| s = γ λ . Since w = u + v, the result of Lemma B.1 is equivalent to ρ, u + v = 1 λ {μ||Du|| 1 + γ||Pv|| * } .</formula><p>However, by the duality principles and the assumptions of this case, the following inequalities hold: By canceling terms, we get</p><formula xml:id="formula_49">ρ, u</formula><formula xml:id="formula_50">μ||D(u -v)|| 1 + γ||Pv|| * ≥ μ||Du|| 1 .</formula><p>Using the equalities we found and the fact that γ = λ||Pρ|| s , the following inequalities are equivalent:</p><formula xml:id="formula_51">μ||D(u -v)|| 1 + λ||Pρ|| s ||Pv|| * ≥ μ||Du|| 1 , μ λ ||D(u -v)|| 1 + v, ρ ≥ μ λ ||Du|| 1 , ||ρ|| G ||D(u -v)|| 1 + v, ρ ≥ μ λ ||Du|| 1 .</formula><p>However, by Lemma B.3, As before, perturb v by V , with the corresponding energy:</p><formula xml:id="formula_52">||ρ|| G ||D(u -v)|| 1 ≥ u -v, ρ = u, ρ -v,</formula><formula xml:id="formula_53">(B.3) E(u, v + V ) = μ||Du|| 1 + γ||P(v + V )|| * + λ 2 ||ρ -u -V || 2 2 .</formula><p>By Lemma B.3 and the assumptions of this case, we have the following inequality:</p><formula xml:id="formula_54">||P(v + V )|| * ||Pρ|| s ≥ v + V, ρ ≥ v, ρ + V, ρ = γ λ ||Pv|| * + V, ρ .</formula><p>Since we assume ||Pρ|| s = γ λ , the previous inequality is equivalent to Returning to (B.3), we have the following lower bound:</p><formula xml:id="formula_55">||P(v + V )|| * ≥ ||Pv|| * + λ γ V, ρ .</formula><formula xml:id="formula_56">E(u, v + V ) ≥ λ | u, ρ | + γ||Pv|| * + λ V, ρ + λ 2 ||ρ|| 2 2 -λ u, ρ -λ V, ρ ≥ γ||Pv|| * + λ 2 ||ρ|| 2 2 = E(0, v).</formula><p>Thus the decomposition f = v + ρ is optimal. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>≥ E(u, ρ).</head><p>This implies U = 0 and P = 0; therefore (u, ρ) is the minimizer.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Patch map.</figDesc><graphic coords="6,219.84,96.04,172.87,171.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Decomposition of a synthetic example image.</figDesc><graphic coords="8,185.31,368.68,89.83,89.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Singular values in descending order.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 .</head><label>3</label><figDesc>From a cartoon-texture point of view, our texture norm induces a space (T, ||P • || * ) Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Copyright © by SIAM. Unauthorized reproduction of this article is prohibited.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Examples of image decomposition. The patch-rank of the texture components for the Tank and Grass images is 51.0% and 19.1%, respectively. Even seemingly random textures have a small patch-rank. Notice that spiking (or point structures) in the original images (a) and (d) are found in the cartoon components (b) and (e) and not the texture components (c) and (f).</figDesc><graphic coords="10,131.11,227.81,109.44,109.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Fourier transform of Brodatz.</figDesc><graphic coords="15,218.61,96.39,171.72,171.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Barbara.</figDesc><graphic coords="16,246.42,96.65,119.65,119.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 Figure 7 .</head><label>27</label><figDesc>Figure 7. Decomposing Barbara.</figDesc><graphic coords="17,146.60,449.07,153.85,153.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(a) Cartoon r = 4 (b) Texture r = 4 (c) Cartoon r = 5 (d) Texture r = 5 (e) Cartoon r = 7 (f) Texture r = 7 Figure 8 .</head><label>4455778</label><figDesc>Figure 8. Decomposing Barbara with various patch sizes.</figDesc><graphic coords="18,146.60,448.75,153.85,154.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .Figure 10 .Figure 11 .Figure 12 .</head><label>9101112</label><figDesc>Figure 9. Decompositions with different patch-ranks (fixed μ and λ; γ variable).</figDesc><graphic coords="19,146.60,448.75,153.85,154.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Decomposition of a synthetic example image using T V -G.</figDesc><graphic coords="21,242.07,501.84,128.32,128.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Decomposition of a synthetic example image.</figDesc><graphic coords="22,171.93,96.75,128.52,128.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>8 (Figure 15 .</head><label>815</label><figDesc>Figure 15. Denoising of Brodatz.</figDesc><graphic coords="23,241.89,398.31,128.52,128.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>( a ) 7 Figure 16 .</head><label>a716</label><figDesc>Figure 16. Deblurring comparison.</figDesc><graphic coords="25,150.34,268.95,150.48,150.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 17 . 0 Figure 18 .Figure 19 .</head><label>1701819</label><figDesc>Figure 17. Inpainting example.</figDesc><graphic coords="26,241.29,285.39,128.52,128.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 20 .</head><label>20</label><figDesc>Figure 20. Joint sparse reconstruction and denoising: warped/nonuniform geometry.</figDesc><graphic coords="28,168.67,324.88,131.84,99.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 21 .</head><label>21</label><figDesc>Figure 21. Joint sparse reconstruction and denoising: multiscale with irregularities.</figDesc><graphic coords="29,168.67,217.36,131.84,99.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Lemma B. 1 .</head><label>1</label><figDesc>Take any Banach space with norm || • || and dual norm || • || . Given an f that is decomposed into f = u + v by minimizing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>5 .</head><label>5</label><figDesc>ρ , which implies u, ρ = μ λ ||Du|| 1 , so if we have equality, then ||ρ|| G ||D(uv)|| 1 = uv, ρ . Assume that f = v + ρ, ||ρ|| G &lt; μ λ , ||Pρ|| s = γ λ , and ρ, v = γ λ ||Pv|| * ; then the decomposition f = v + ρ is optimal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Note that the decompositions of f , namelyf = u + v + V + ρ and f = ρ + v, yield ||u + V || 2 2 = ||fρ -v|| 2 2 = 0.Using this fact and expanding the L 2 norm in (B.3) gives(B.4) ||ρu -V || 2 2 = ||ρ|| 2 2 -2 u, ρ -2 V, ρ .The second term on the right-hand side of (B.4) can be bounded by using Lemma B.3 and the assumption ||ρ|| G &lt; μ λ :λ | u, ρ | ≤ λ||Du|| 1 ||ρ|| G ≤ μ||Du|| 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>2.2. Proposed model. With</head><label></label><figDesc>1. It is easy to show that there is only one nonzero singular value equal to rN . Consequently, ||P r×r v|| * = rN . Of course, v has the same value in all L p norms, ||v|| L p = N 2 , and its total variation is ||v|| T V = 2N 2 . Since N is much larger than r, the norms are well ordered: ||P r×r v|| * ||v|| T V and ||P r×r v|| * ||v|| L p . This type of behavior is desired in cartoon-texture models. Definition 2.2, our proposed model is as follows: given an f , we decompose f</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>3.2. If P is a patch map, then the following hold: 1. It is a bijective linear operator. 2. P is an isometry with respect to all elementwise norms. 3. ||Pv|| * ≤ √ n||v|| 2 , where n 2 is the size of the matrix v. 4. The dual norm of ||P • || * is ||P • || s , where || • || s is the spectral norm.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>Denoising of the synthetic image. Each method has the same noise variance (L 2 norm). The entropy of the true noise is 4.53.</figDesc><table><row><cell>Method</cell><cell>Recovered SNR</cell><cell cols="3">Cartoon SNR Texture SNR Noise entropy</cell><cell>Error entropy</cell></row><row><cell>Ours</cell><cell>19.3</cell><cell>19.0</cell><cell>17.3</cell><cell>4.43</cell><cell>3.34</cell></row><row><cell>T V -L 2</cell><cell>8.6</cell><cell>N/A</cell><cell>N/A</cell><cell>3.48</cell><cell>4.29</cell></row><row><cell>NLT V -L 2</cell><cell>19.1</cell><cell>N/A</cell><cell>N/A</cell><cell>4.42</cell><cell>3.50</cell></row><row><cell>T V -G-L 2</cell><cell>11.2</cell><cell>13.4</cell><cell>5.9</cell><cell>4.36</cell><cell>4.31</cell></row><row><cell>T V -H -1 -L 2</cell><cell>10.8</cell><cell>11.6</cell><cell>6.6</cell><cell>4.35</cell><cell>4.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Denoising of a noisy Brodatz-Wood image. Each method has the same noise variance (L 2 norm) and same L 2 norm on the texture component. The entropy of the true noise is 3.81. The patch-ranks for T V -G-L 2 and T V -H -1 -L 2 are computed after thresholding the smaller singular values.</figDesc><table><row><cell>Method</cell><cell>SNR</cell><cell>Edges</cell><cell>Sparsity</cell><cell cols="2">Patch-rank Noise entropy</cell><cell>Error entropy</cell></row><row><cell>Ours</cell><cell cols="2">15.14 10.9%</cell><cell>61.8%</cell><cell>15.1%</cell><cell>3.81</cell><cell>3.72</cell></row><row><cell>T V -L 2</cell><cell>14.37</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>3.75</cell><cell>3.78</cell></row><row><cell>NLT V -L 2</cell><cell>15.14</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>3.80</cell><cell>3.79</cell></row><row><cell>T V -G-L 2</cell><cell>11.13</cell><cell>16.4%</cell><cell>63.3%</cell><cell>83.9%</cell><cell>4.00</cell><cell>4.15</cell></row><row><cell>T V -H -1 -L 2</cell><cell>11.50</cell><cell>11.6%</cell><cell>64.4%</cell><cell>82.6%</cell><cell>4.05</cell><cell>4.14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Denoising of the noisy Grass image. Each method has the same noise variance (L 2 norm) and same L 2 norm on the texture component. The entropy of the true noise is 3.80. The patch-ranks for T V -G-L 2 and T V -H -1 -L 2 are computed after thresholding the smaller singular values.</figDesc><table><row><cell>Method</cell><cell>SNR</cell><cell cols="2">Edges Sparsity</cell><cell cols="2">Patch-rank Noise entropy</cell><cell>Error entropy</cell></row><row><cell>Ours</cell><cell cols="2">7.83 8.8%</cell><cell>66.5%</cell><cell>15.6%</cell><cell>3.79</cell><cell>3.28</cell></row><row><cell>T V -G-L 2</cell><cell>4.26</cell><cell>10.6%</cell><cell>66.6%</cell><cell>98.1%</cell><cell>3.78</cell><cell>3.94</cell></row><row><cell>T V -H -1 -L 2</cell><cell>5.84</cell><cell>13.0%</cell><cell>67.3%</cell><cell>100%</cell><cell>3.78</cell><cell>3.78</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Denoising of the noisy Tank image. Each method has the same noise variance (L 2 norm) and the exact same cartoon component. The entropy of the true noise is 3.28. The patch-ranks for T V -G-L 2 and T V -H -1 -L 2 are computed after thresholding the smaller singular values.</figDesc><table><row><cell>Method</cell><cell>SNR</cell><cell cols="2">Edges Sparsity</cell><cell cols="2">Patch-rank Noise entropy</cell><cell>Error entropy</cell></row><row><cell>Ours</cell><cell cols="2">11.86 7.2%</cell><cell>65.6%</cell><cell>40%</cell><cell>3.29</cell><cell>3.26</cell></row><row><cell>T V -G-L 2</cell><cell>9.53</cell><cell>30.2%</cell><cell>67.6%</cell><cell>100%</cell><cell>3.35</cell><cell>3.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Statistics on our algorithm applied to 100 images from the database in<ref type="bibr" target="#b22">[23]</ref>.</figDesc><table><row><cell>Statistic</cell><cell cols="4">Recovered RMSE Original RMSE RMSE decrease Patch-rank</cell></row><row><cell>Minimum</cell><cell>0.035</cell><cell>0.091</cell><cell>-33.4%</cell><cell>5.5</cell></row><row><cell>Maximum</cell><cell>0.159</cell><cell>0.333</cell><cell>-83.0%</cell><cell>50.5</cell></row><row><cell>Mean</cell><cell>0.088</cell><cell>0.228</cell><cell>-61.0%</cell><cell>29.4</cell></row><row><cell>Median</cell><cell>0.085</cell><cell>0.231</cell><cell>-59.3%</cell><cell>30.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Calculating the simultaneous dual norm yields the lower bound ||f || ≥ 1 λ , and therefore by Lemma B.1 ||ρ|| = 1 λ and w, ρ = 1 λ ||w||. Since the simultaneous dual norm is defined as ||ρ|| = sup 1 μ ||ρ|| G , 1 γ ||Pρ|| s , we have the following bounds on the residual ρ: . Last, when f is small in one dual norm and large in the other, many cases occur. The following theorem provides the various optimal solutions and their characterizations. Theorem B.8. If ||f || G ≤ μ λ and ||Pf || s &gt; γ λ , then three case hold: (</figDesc><table><row><cell></cell><cell>Together, these inequalities give</cell></row><row><cell>Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</cell><cell>||ρ|| G ≤ ||Pρ|| s ≤ By the duality principles from Lemma B.3, the following also hold: μ λ , γ λ . ρ, u ≤ ||Du|| 1 ||ρ|| G = μ λ ||Du|| 1 , ρ, v ≤ ||Pv||  *  ||Pρ||  *  = γ λ ||Pv||  *  . u + v, ρ ≤ 1 λ {μ||Du|| 1 + γ||Pv||  The inequality above is equivalent to w, ρ ≤ 1 λ ||w|| for w = u + v. However, by Lemma B.1 w, ρ = 1 λ ||w||; thus equality holds for all related inequalities: ||ρ|| G = μ λ , ||Pρ|| s = γ λ , ρ, u = μ λ ||Du|| 1 , and ρ, v = γ λ ||Pv||</cell></row></table><note><p>7. If ||f || G &gt; μ λ and ||Pf || s &gt; γ λ , then the following holds for all minimizers: ||ρ|| G = μ λ , ||Pρ|| s = γ λ , ρ, u = μ λ ||Du|| 1 , and ρ, v = γ λ ||Pv|| * . Proof. * } . *</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Thus u = 0 and ρ, v = γ λ ||Pv|| * to avoid the contradiction.2. Next, assume that ||ρ||G = μ λ , ||Pρ|| s &lt; γ λ . By repeating the argument above, v = 0 ρ, u = μ λ ||Du|| 1 must hold. 3. Assume that ||ρ|| G = μ λ , ||Pρ|| s = γ λ ; then ρ, v = γ λ ||Pv|| * ,and ρ, u = μ λ ||Du|| 1 for the optimal solution. Similarly to the other two cases, by Lemma B.1, we have Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php The duality principles (Lemma B.3) and the assumptions of this case yield the following inequalities: Thus the equalities ρ, u = μ λ ||Du|| 1 and ρ, v = γ λ ||Pv|| * must hold. 4. For the next three cases, we show that the solutions are optimal. Assume ||ρ|| G = μ λ , ||Pρ|| s ≤ γ λ , ρ, u = μ λ ||Du|| 1 , and f = u + ρ; then for all U and v we have μ||D(u + U )|| 1 + γ||Pv|| * + To show this, first rescale (B.1) by dividing by λ = μ||ρ|| -1 G to get ||D(u + U )|| 1 ||ρ|| G + By the texture duality principle, i.e., v, ρ ≤ ||Pρ|| s ||Pv|| * , and the assumptions of this case, we have v, ρ ≤ γ μ ||ρ|| G ||Pv|| * , which is used in the inequalities above. If equality holds, then U = -v and v, ρ = γ μ ||ρ|| G ||Pv|| * . Also ||Pρ|| s = γ λ and v, ρ = ||Pρ|| s ||Pv|| * would hold. Returning to (B.1),</figDesc><table><row><cell>(B.1) (B.2)</cell><cell>ρ, u + v = ρ, v ≤ ||Pρ|| s ||Pv||  *  = 1 λ λ 2 ||ρ -U -v|| 2 μ λ ||Du|| 1 , γ λ ||Pv||  *  . 2 ≥ μ||Du|| 1 + ||Pv||  *  ||ρ|| G + 1 2 ||ρ -U -v|| 2 2 ≥ u + U,ρ + γ μ γ μ ||Pv||  *  ||ρ|| G + 1 2 ||ρ|| 2 2 + 1 2 ||U + v|| 2 λ 2 ||ρ|| 2 2 . 2 -ρ, U -v, ρ ≥ u, ρ + γ μ ||Pv||  *  ||ρ|| G + 1 2 ||ρ|| 2 2 + 1 2 ||U + v|| 2 2 -v, ρ = μ λ ||Du|| 1 + γ μ ||Pv||  *  ||ρ|| G + 1 2 ||ρ|| 2 2 + 1 2 ||U + v|| 2 2 -v, ρ ≥ μ λ ||Du|| 1 + 1 2 ||ρ|| 2 2 . {μ||Du|| 1 + γ||Pv||  ρ, u ≤ ||ρ|| G ||Du|| 1 = μ||D(u -v)|| 1 + γ||Pv||  *  + λ 2 ||ρ|| 2 2 ≥ μ||Du|| 1 + λ 2 ||ρ|| 2 2 .</cell></row></table><note><p><p><p>≤ ||Du|| 1 ||ρ|| G &lt; μ λ ||Du|| 1 , ρ, v ≤ ||Pv|| * ||Pρ|| * = γ λ ||Pv|| * .</p>Combining these statements produces the contradictory strict inequality</p>ρ, u + v &lt; 1 λ {μ||Du|| 1 + γ||Pv|| * } . * } .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php6. Last, assume that ||ρ||G = μ λ , ||Pρ|| s = γ λ , ρ, v = γ λ ||Pv|| * ,and ρ, u = μ λ ||Du|| 1 hold; then the decomposition is optimal. Perturb the functions u by U and ρ by P with the perturbed energy:(B.5) E(u + U, ρ + P ) = μ||Du|| 1 + γ||P(v -U -P )|| * + λ 2 ||ρ + P || 2 2 .Next, by combining the various assumptions in this case, we get||Pρ|| s = γ λ &gt; ||Pf || s and ||ρ|| G = μ λ ≥ ||f || G . For the texture norm, Lemma B.3 yields ||Pρ|| s ||P(v -U -P )|| * ≥ ρ, v -U -P .By using this inequality and the assumption that ||Pρ|| s = γ λ , the following holds:(B.6) γ||P(v -U -P )|| * ≥ λ ρ, vλ ρ, Uλ ρ, P .</figDesc><table><row><cell cols="6">With respect to the cartoon norm, Lemma B.3 yields</cell></row><row><cell>(B.7)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>+</cell><cell>1 2</cell><cell>||ρ|| 2 2 +</cell><cell>1 2</cell><cell>||P || 2 2 + P, ρ</cell></row><row><cell>≥ λ u + v, ρ +</cell><cell>1 2</cell><cell>||ρ|| 2 2 +</cell><cell>1 2</cell><cell cols="2">||P || 2 2</cell></row><row><cell cols="3">= μ||Du|| 1 + γ||Pv||  *  + λ</cell><cell cols="2">1 2</cell><cell>||ρ|| 2 2 +</cell><cell>1 2</cell><cell>||P || 2 2</cell></row></table><note><p><p><p><p><p><p>||D(u + U )|| 1 ||ρ|| G ≥ u + U, ρ .</p>By the assumption ||ρ||</p>G = μ λ , (B.7) is equivalent to (B.8) μ||D(u + U )|| 1 ≥ λ u, ρ + λ U, ρ .</p>Combining (B.7) and (B.8) with (B.5) and canceling terms gives the following lower bound for the energy:</p>E(u + U, ρ + P ) = μ||Du|| 1 + γ||P(v -U -P )|| * + λ 2 ||ρ + P || 2 2</p>≥ λ u, ρ + U, ρ + ρ, vρ, Uρ, P</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Downloaded 04/01/13 to 128.206.9.138. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We would like to thank Professor Luminita Vese for her help and time discussing cartoon-texture models. We would also like to thank the reviewers and the editors for their constructive comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This research was supported by grants ONR N00014-08-1-1119, ONR N00014-11-0719, NSF DMS-1118971, NSF DMS-0914561, and an ARO MURI subcontract from Rice University, and was supported by the Department of Defense (DoD) through the National Defense Science and Engineering Graduate Fellowship (NDSEG) Program.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A. A tensor interpretation. As a small remark, since the patch map is a linear map between matrices, it can be associated with a tensor. The map P is a rank 4 tensor (not to be confused with matrix rank) which maps R n,n into R r 2 , n 2 r 2 . Associating the map P with the tensor P = [P k,l i,j ], the operation P : v → w is defined by the following (using Einstein notation, where repeated indices are summed):</p><p>where the elements of the tensor are defined as </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mathematical Problems in Image Processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kornprobst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Partial Differential Equations and the Calculus of Variations</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Aujol</surname></persName>
		</author>
		<title level="m">Contribution à l&apos;analyse de textures en traitement d&apos;images par méthodes variationnelles et équations aux dérivées partielles</title>
		<meeting><address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Université de Nice Sophia Antipolis</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image decomposition into a bounded variation component and an oscillating component</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Blanc-Féraud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="71" to="88" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining geometrical and textured information to perform image classification</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Rep</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1004" to="1023" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Color image decomposition and restoration</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Rep</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="916" to="928" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simultaneous structure and texture image inpainting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="882" to="889" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A review of image denoising algorithms, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neighborhood filters and PDE&apos;s</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fast Singular Value Thresholding without Singular Value Decomposition</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<idno>10-24</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>UCLA, Los Angeles, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">UCLA CAM Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust principal component analysis?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image recovery via total variation minimization and related problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-L</forename><surname>Lions</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="167" to="188" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sparsity-based image denoising via dictionary learning and structural clustering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust principal component analysis-based four-dimensional computed tomography</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="3181" to="3198" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Multi-energy CT based on a prior rank, intensity and sparsity model (PRISM), Inverse Problems</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">115012</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonlocal linear image regularization and supervised segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="595" to="630" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nonlocal operators with applications to image processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1005" to="1028" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noisy image decomposition: A new structure, texture and noise model based on local adaptivity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gilles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vision</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="285" to="295" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Properties of BV -G structures + textures decomposition models. Application to road detection in satellite images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gilles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2793" to="2800" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The split Bregman method for L1-regularized problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="323" to="343" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust video denoising using low rank matrix completion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1791" to="1798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Image recovery using functions of bounded variation and Sobolev spaces of negative differentiability</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Probl. Imaging</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="43" to="68" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A sparse texture representation using local affine regions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1265" to="1278" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image restoration and decomposition via bounded total variation and negative Hilbert-Sobolev spaces</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Lieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Optim</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="167" to="193" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Online learning for matrix factorization and sparse coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="19" to="60" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 IEEE 12th International Conference on Computer Vision</title>
		<meeting>the 2009 IEEE 12th International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2272" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Redistribution subject to SIAM license or copyright</title>
		<idno>Downloaded 04/01/13 to 128.206.9.138</idno>
		<ptr target="http://www.siam.org/journals/ojsa.phpCopyright©bySIAM" />
		<imprint/>
	</monogr>
	<note>Unauthorized reproduction of this article is prohibited</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sparse representation for color image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="53" to="69" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Oscillating Patterns in Image Processing and Nonlinear Evolution Equations: The Fifteenth Dean Jacqueline B. Lewis Memorial Lectures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>AMS</publisher>
			<pubPlace>Providence, RI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An iterative regularization method for total variation-based image restoration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="460" to="489" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image decomposition and restoration using total variation minimization and the H -1 norm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="349" to="370" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">RASL: Robust alignment by sparse and lowrank decomposition for linearly correlated images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="763" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Modeling textures with total variation minimization and oscillating patterns in image processing</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="553" to="572" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bregmanized nonlocal regularization for deconvolution and sparse reconstruction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="253" to="276" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TILT: Transform invariant low-rank textures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Non-parametric Bayesian dictionary learning for sparse image representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual Conference on Neural Information Processing Systems</title>
		<meeting>the 23rd Annual Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2295" to="2303" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
