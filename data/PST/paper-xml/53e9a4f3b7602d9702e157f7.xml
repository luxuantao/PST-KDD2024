<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-dimensional top-k dominating queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-09-30">30 September 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Man</forename><surname>Lung</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Mamoulis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<settlement>Aalborg</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-dimensional top-k dominating queries</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-09-30">30 September 2008</date>
						</imprint>
					</monogr>
					<idno type="MD5">139301DD08C97130BBF532CA05C0AA5F</idno>
					<idno type="DOI">10.1007/s00778-008-0117-y</idno>
					<note type="submission">Received: 18 January 2008 / Revised: 17 July 2008 / Accepted: 12 August 2008 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Top-k retrieval</term>
					<term>Preference dominance</term>
					<term>Score counting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The top-k dominating query returns k data objects which dominate the highest number of objects in a dataset. This query is an important tool for decision support since it provides data analysts an intuitive way for finding significant objects. In addition, it combines the advantages of top-k and skyline queries without sharing their disadvantages: (i) the output size can be controlled, (ii) no ranking functions need to be specified by users, and (iii) the result is independent of the scales at different dimensions. Despite their importance, top-k dominating queries have not received adequate attention from the research community. This paper is an extensive study on the evaluation of top-k dominating queries. First, we propose a set of algorithms that apply on indexed multi-dimensional data. Second, we investigate query evaluation on data that are not indexed. Finally, we study a relaxed variant of the query which considers dominance in dimensional subspaces. Experiments using synthetic and real datasets demonstrate that our algorithms significantly outperform a previous skyline-based approach. We also illustrate the applicability of this multi-dimensional analysis query by studying the meaningfulness of its results on real data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Consider a dataset D of points in a d-dimensional space R d . Given a (monotone) ranking function F : R d → R, a top-k query <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref> returns k points with the smallest F value. For example, Fig. <ref type="figure" target="#fig_12">1a</ref> shows a set of hotels modeled by points in the 2D space, where the dimensions correspond to (preference) attribute values; traveling time to a conference venue and room price. For the ranking function F = x + y, the top-2 hotels are p 4 and p 6 . An obvious advantage of the top-k query is that the user is able to control the number of results (through the parameter k). On the other hand, it might not always be easy for the user to specify an appropriate ranking function. In addition, there is no straightforward way for a data analyst to identify the most important objects using top-k queries, since different functions may infer different rankings.</p><p>A skyline query <ref type="bibr" target="#b1">[2]</ref> retrieves all points which are not dominated by any other point. Assuming that smaller values are preferable to larger at all dimensions, a point p dominates another point p (i.e., p p ) when</p><formula xml:id="formula_0">(∃ i ∈ [1, d], p[i] &lt; p [i]) ∧ (∀ i ∈ [1, d], p[i] ≤ p [i])</formula><p>where p[i] denotes the coordinate of p in the ith dimension. Continuing with the example in Fig. <ref type="figure" target="#fig_12">1a</ref>, the skyline query returns points p 1 , p 4 , p 6 , and p 7 . Börzsönyi et al. <ref type="bibr" target="#b1">[2]</ref> showed that the skyline contains the top-1 result for any monotone ranking function; therefore, it can be used by decision makers to identify potentially important objects to some database users. A key advantage of the skyline query is that it does not require the use of a specific ranking function; its results only depend on the intrinsic characteristics of the data. Furthermore, the skyline is not affected by potentially different scales at different dimensions (monetary unit or time unit in the example of Fig. <ref type="figure" target="#fig_12">1a</ref>); only the order of the dimensional projections of the objects is important. On the other hand, the size of the skyline cannot be controlled by the user and it can be as large as the data size in the worst case. As a result, the user may be overwhelmed as she may have to examine numerous skyline points manually in order to identify the ones that will eventually be regarded as important. In fact, the skyline may not be used as an informative and concise summary for the dataset. It is well known that <ref type="bibr" target="#b1">[2]</ref>: for a fully correlated dataset, the skyline contains exactly 1 point, which is not informative about the distribution of other data points; for a totally anti-correlated dataset, the skyline is the whole dataset, which is definitely not a concise data summary.</p><p>To summarize, top-k queries do not provide an objective order of importance for the points, because their results are sensitive to the preference function used. Skyline queries, on the other hand, only provide a subset of important points, which may have arbitrary size. To facilitate analysts, who may be interested in a natural order of importance, according to dominance, we propose the following intuitive score function:</p><formula xml:id="formula_1">τ ( p) = | { p ∈ D | p p } |<label>(1)</label></formula><p>In words, the score τ ( p) is the number of points dominated by point p. The following monotone property holds for τ :</p><formula xml:id="formula_2">∀ p, p ∈ D, p p ⇒ τ ( p) &gt; τ(p )<label>(2)</label></formula><p>Based on the τ function, we can define a natural ordering of the points in the database. Accordingly, the top-k dominating query returns k points in D with the highest score. For example, the top-2 dominating query on the data of Fig. <ref type="figure" target="#fig_12">1a</ref> retrieves p 4 (with τ ( p 4 ) = 3) and p 5 (with τ ( p 5 ) = 2). This result may indicate to a data analyst (i.e., conference organizer) the most popular hotels to the conference participants (considering price and traveling time as selection factors).</p><p>Here the popularity of a hotel p is defined based on over how many other hotels would p be preferred, for any preference function.</p><p>As another example on how the τ function is related to popularity, consider a dataset with 54 hotels, as shown in Fig. <ref type="figure" target="#fig_12">1b</ref>. 50 of these points are not shown explicitly; the figure only illustrates a rectangle which includes all of them. The top-2 dominating points in this case are p 1 (with τ ( p 1 ) = 51) and p 2 (with τ ( p 2 ) = 50). Even though p 2 is not a skyline point, it becomes important after the top-1 hotel p 1 has been fully booked. The reason is that p 2 is guaranteed to be better than at least 50 points, regardless of any monotone preference ranking function considered by individual conference participants. On the other hand, skyline point p 3 may not provide such guarantee; in the worst case, all conference participants may just be looking for cheap hotels, so p 3 is no good at all. A similar observation holds for the skyline point p 4 .</p><p>The above examples illustrate that a top-k dominating query is a powerful decision support tool, since it identifies the most significant objects in an intuitive way. From a practical perspective, top-k dominating queries combine the advantages of top-k queries and skyline queries without sharing their disadvantages. The number of results can be controlled without specifying any ranking function. In addition, data normalization is not required; the results are not affected by different scales or data distributions at different dimensions.</p><p>The top-k dominating query was first introduced by Papadias et al. <ref type="bibr" target="#b23">[24]</ref> as an extension of the skyline query. However, the importance and practicability of the query was not identified there. This paper is an extensive study of this analysis query. We note that the R-tree (used in <ref type="bibr" target="#b23">[24]</ref>) may not be the most appropriate index for this query; since computing τ ( p) is in fact an aggregate query, we can replace the R-tree by an aggregate R-tree (aR-tree) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23]</ref>. In addition, we observe that the skyline-based approach proposed in <ref type="bibr" target="#b23">[24]</ref> may perform many unnecessary score countings, since the skyline size could be much larger than k.</p><p>Motivated by these observations, our first contribution includes two specialized and very efficient methods for evaluating top-k dominating queries on a dataset indexed by an aR-tree. We propose (i) a batch counting technique for computing scores of multiple points simultaneously, (ii) a counting-guided search algorithm for processing top-k dominating queries, and (iii) a priority-based tree traversal algorithm that retrieves query results by examining each tree node at most once. We enhance the performance of (ii) with lightweight counting, which derives relatively tight upper bound scores for non-leaf tree entries at low I/O cost. Furthermore, to our surprise, the intuitive best-first traversal order <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24]</ref> turns out not to be the most efficient for (iii) because of potential partial dominance relationships between visited entries. Thus, we perform a careful analysis on (iii) and propose a novel, efficient tree traversal order for it. Extensive experiments show that our methods significantly outperform the skyline-based approach of <ref type="bibr" target="#b23">[24]</ref>.</p><p>The above algorithms have been published in the preliminary version of this paper <ref type="bibr" target="#b30">[31]</ref>, where we also propose top-k dominating query variants such as aggregate top-k dominating queries and bichromatic top-k dominating queries; these extensions are not further investigated here. Instead, in this paper, we examine two alternative topics relevant to top-k dominating queries. The first is the processing of top-k dominating queries on non-indexed data. In certain scenarios (e.g., dynamically generated data), it is not always reasonable to assume an existing aR-tree index for them a priori. In view of this, we propose a method that evaluates top-k dominating queries by accessing the (unordered) data only a few times. As we demonstrate experimentally, this method significantly outperforms the best index-based method, which requires the bulk-loading an aR-tree index before evaluation. Our second extension over <ref type="bibr" target="#b30">[31]</ref> is the proposal and study of a relaxed form of the top-k dominating query. In this query variant, the τ ( p) score is defined by the number of dimensional subspaces where point p dominates another point p . As we demonstrate, this query derives more meaningful results than the basic top-k dominating query.</p><p>The rest of the paper is organized as follows. Section 2 reviews the related work. Section 3 discusses the properties of top-k dominating search and proposes optimizations for the existing solution in <ref type="bibr" target="#b23">[24]</ref>. We then propose eager/lazy approaches for evaluating top-k dominating queries. Section 4 presents an eager approach that guides the search by deriving tight score bounds for encountered non-leaf tree entries immediately. Section 5 develops an alternative, lazy approach that defers score computation of visited entries and gradually refines their score bounds when more tree nodes are accessed. Section 6 presents techniques for processing top-k dominating queries on non-indexed data. Section 7 introduces the relaxed top-k dominating query and discusses its evaluation. In Sect. 8, experiments are conducted on both real and synthetic datasets to demonstrate that the proposed algorithms are efficient and also top-k dominating queries return meaningful results to users. Section 9 summarizes our experimental findings and discusses the case of high dimensional data. Finally, Sect. 10 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Top-k dominating queries include a counting component, i.e., multi-dimensional aggregation; thus, we review related work on spatial aggregation processing. In addition, as the dominance relationship is relevant to skyline queries, we survey existing methods for computing skylines.</p><p>2.1 Spatial aggregation processing R-trees <ref type="bibr" target="#b11">[12]</ref> have been extensively used as access methods for multi-dimensional data and for processing spatial queries, e.g., range queries, nearest neighbors <ref type="bibr" target="#b12">[13]</ref>, and skyline queries <ref type="bibr" target="#b23">[24]</ref>. The aggregate R-tree (aR-tree) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23]</ref> augments to each non-leaf entry of the R-tree an aggregate measure of   all data points in the subtree pointed by it. It has been used to speed up the evaluation of spatial aggregate queries, where measures (e.g., number of buildings) in a spatial region (e.g., a district) are aggregated. Figure <ref type="figure" target="#fig_2">2a</ref> shows a set of points in the 2D space, indexed by the COUNT aR-tree in Fig. <ref type="figure" target="#fig_2">2b</ref>. Each non-leaf entry stores the COUNT of data points in its subtree. For instance, in Fig. <ref type="figure" target="#fig_2">2b</ref>, entry e 17 has a count 10, meaning that the subtree of e 17 contains 10 points. Suppose that a user asks for the number of points intersecting the region W , shown in Fig. <ref type="figure" target="#fig_2">2a</ref>. To process the query, we first examine entries in the root node of the tree. Entries that do not intersect W are pruned because their subtree cannot contain any points in W . If an entry is spatially covered by W (e.g., entry e 19 ), its count (i.e., 10) is added to the answer without accessing the corresponding subtree. Finally, if a non-leaf entry intersects W but it is not contained in W (e.g., e 17 ), search is recursively applied to the child node pointed by the entry, since the corresponding subtree may contain points inside or outside W . Note that the counts augmented in the entries effectively reduce the number of accessed nodes. To evaluate the above example query, only 10 nodes in the COUNT aR-tree are accessed but 17 nodes in an R-tree with the same node capacity would be visited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Skyline computation</head><p>Börzsönyi et al. <ref type="bibr" target="#b1">[2]</ref> were the first to propose efficient external memory algorithms for processing skyline queries. The BNL (block-nested-loop) algorithm scans the dataset while employing a bounded buffer for tracking the points that cannot be dominated by other points in the buffer. A point is reported as a result if it cannot be dominated by any other point in the dataset. On the other hand, the DC (divideand-conquer) algorithm recursively partitions the dataset until each partition is small enough to fit in memory. After the local skyline in each partition is computed, they are merged to form the global skyline. The BNL algorithm was later improved to SFS (sort-filter-skyline) <ref type="bibr" target="#b7">[8]</ref> and LESS (linear elimination sort for skyline) <ref type="bibr" target="#b10">[11]</ref> in order to optimize the average-case running time.</p><p>The above algorithms are generic and applicable for non-indexed data. On the other hand, <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref> exploit data indexes to accelerate skyline computation. The state-of-the -art algorithm is the BBS (branch-and-bound skyline) algorithm <ref type="bibr" target="#b23">[24]</ref>, which is shown to be I/O optimal for computing skylines on datasets indexed by R-trees.</p><p>Recently, the research focus has been shifted to the study of queries based on variants of the dominance relationship. <ref type="bibr" target="#b21">[22]</ref> aims at extracting from the skyline points a k-sized subset such that it dominates the maximum number of data points; in other words, the result set cannot contain any nonskyline point. Li et al. <ref type="bibr" target="#b19">[20]</ref> proposes a data cube structure for speeding up the evaluation of queries that analyze the dominance relationship of points in the dataset. However, incremental maintenance of the data cube over updates has not been addressed in <ref type="bibr" target="#b19">[20]</ref>. Clearly, it is prohibitively expensive to recompute the data cube from scratch for dynamic datasets with frequent updates. Chan et al. <ref type="bibr" target="#b5">[6]</ref> identifies the problem of computing top-k frequent skyline points, where the frequency of a point is defined by the number of dimensional subspaces. Chan et al. <ref type="bibr" target="#b4">[5]</ref> studies the k-dominant skyline query, which is based on the k-dominance relationship. A point p is said to k-dominate another point p if p dominates p in at least one k-dimensional subspace. The k-dominant skyline contains the points that are not k-dominated by any other point. When k decreases, the size of the k-dominant skyline also decreases. Observe that <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref> cannot be directly applied to evaluate top-k dominating queries studied in this paper.</p><p>Finally, <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b31">32]</ref> study the efficient computation of skylines for every subspace; Tao et al. <ref type="bibr" target="#b28">[29]</ref> proposes a technique for retrieving the skyline for a given subspace; Balke et al. <ref type="bibr" target="#b0">[1]</ref>, Huang et al. <ref type="bibr" target="#b14">[15]</ref> investigate skyline computation over distributed data; Chaudhuri et al. <ref type="bibr" target="#b6">[7]</ref> and Godfrey <ref type="bibr" target="#b9">[10]</ref> develop techniques for estimating the skyline cardinality; Lin et al. <ref type="bibr" target="#b20">[21]</ref> studies continuous maintenance of the skyline over a data stream; and <ref type="bibr" target="#b3">[4]</ref> addresses skyline computation over datasets with partially-ordered attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminary</head><p>In this section, we discuss some fundamental properties of top-k dominating search, assuming that the data have been indexed by an aR-tree. In addition, we propose an optimized version for the existing top-k dominating algorithm <ref type="bibr" target="#b23">[24]</ref> that operates on aR-trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Score bounding functions</head><p>Before presenting our top-k dominating algorithms, we first introduce some notation that will be used in this paper. For an aR-tree entry e (i.e., a minimum bounding box) whose Observe that both e -and e + do not correspond to actual data points but they allow us to express dominance relationships among points and minimum bounding boxes conveniently. As Fig. <ref type="figure">3</ref> illustrates, there are three cases for a point to dominate a non-leaf entry. Since p 1 e - 1 (i.e., full dominance), p 1 must also dominate all data points indexed under e 1 . On the other hand, point p 2 dominates e + 1 but not e - 1 (i.e., partial dominance), thus p 2 dominates some, but not all data points in e 1 . Finally, as p 3 e + 1 (i.e., no dominance), p 3 cannot dominate any point in e 1 . Similarly, the cases for an entry to dominate another entry are: (i) full dominance (e.g., e + 2 ). Given a tree entry e, whose sub-tree has not been visited, τ (e + ) and τ (e -) correspond to the tightmost lower and upper score bounds respectively, for any point indexed under e. As we will show later, τ (e + ) and τ (e -) can be computed by a search procedure that accesses only aR-tree nodes that intersect e along at least one dimension. These bounds help pruning the search space and defining a good order for visiting aR-tree nodes. Later in Sects. 4 and 5, we replace the tight bounds τ (e + ) and τ (e -) with loose lower and upper bounds for them (τ l (e) and τ u (e), respectively). Bounds τ l (e) and τ u (e) are cheaper to compute and can be progressively refined during search, therefore trading-off between computation cost and bound tightness. The computation and use of score bounds in practice will be further elaborated there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimizing the skyline-based approach</head><p>Papadias et al. <ref type="bibr" target="#b23">[24]</ref> proposed a Skyline-Based Top-k Dominating Algorithm (STD) for top-k dominating queries, on data indexed by an R-tree. They noted that the skyline is guaranteed to contain the top-1 dominating point, since a non-skyline point has lower score than a skyline point that dominates it (see Eq. 2). Thus, STD retrieves the skyline points, computes their τ scores and outputs the point p with the highest score. It then removes p from the dataset, incrementally finds the skyline of the remaining points, and repeats the same process.</p><p>Consider for example a top-2 dominating query on the dataset shown in Fig. <ref type="figure">4</ref>. STD first retrieves the skyline points p 1 , p 2 , and p 3 (using the BBS skyline algorithm of <ref type="bibr" target="#b23">[24]</ref>). For each skyline point, a range query is issued to count the number of points it dominates. After that, we have τ ( p 1 ) = 1, τ ( p 2 ) = 4, and τ ( p 3 ) = 1. Hence, p 2 is reported as the top-1 result. We now restrict the region of searching for the next result. First, Eq. 2 suggests that the region dominated by the remaining skyline points (i.e., p 1 and p 3 ) needs not be examined. Second, the region dominated by p 2 (i.e., the previous result) may contain some points which are not dominated by the remaining skyline points p 1 and p 3 . It suffices to retrieve the skyline points (i.e., p 4 and p 5 ) in the constrained (gray) region M shown in Fig. <ref type="figure">4</ref>. After counting their scores using the tree, we have τ ( p 4 ) = 2 and τ ( p 5 ) = 1. Finally, we compare them with the scores of retrieved points (i.e., p 1 and p 3 ) and report p 4 as the next result.</p><p>In this section, we present two optimizations that greatly reduce the I/O cost of the above solution by exploiting aR-trees. Our first optimization is called batch counting. Instead of iteratively applying separate range queries to compute the scores of the skyline points, we perform them in batch. Algorithm 1 shows the pseudo-code of this recursive batch counting procedure. It takes two parameters: the current aRtree node Z and the set of points V , whose τ scores are to be counted. Initially, Z is set to the root node of the tree and τ ( p) is set to 0 for each p ∈ V . Let e be the current entry in Z to be examined. As illustrated in Sect. 3.1, if e is a non-leaf entry and there exists some point p ∈ V such that p e + ∧ p e -, then p may dominate some (but not guaranteed to dominate all) points indexed under e. Thus, we cannot immediately decide the number of points in e dominated by p. In this case, we have to invoke the algorithm recursively on the child node pointed by e. Otherwise, for each point p ∈ V , its score is incremented by COUNT(e) when it dominates e -. BatchCount correctly computes the τ score for all p ∈ V , at a single tree traversal. Algorithm 2 is a pseudo-code of the Iterative Top-k Dominating Algorithm (ITD), which optimizes the STD algorithm of <ref type="bibr" target="#b23">[24]</ref>. Like STD, ITD computes the top-k dominating points iteratively. In the first iteration, ITD computes in V the skyline of the whole dataset, while in subsequent iterations, the computation is constrained to a region M. M is the region dominated by the reported point q in the previous iteration, but not any point in the set V of retrieved points in past iterations. At each loop, Lines 6-8 compute the scores for the points in V in batches of B points each (B ≤ |V |). By default, the value of B is set to the number of points that can fit into a memory page. Our second optimization is that we sort the points in V by a space-filling curve (Hilbert ordering) <ref type="bibr" target="#b2">[3]</ref> before applying batch counting, in order to increase the compactness of the MBR of a batch. After merging the constrained skyline with the global one, the object q with the highest τ score is reported as the next dominating object, removed from V and used to compute the constrained skyline at the next iteration. The algorithm terminates after k objects have been reported.</p><p>For instance, in Fig. <ref type="figure">4</ref>, q corresponds to point (0, 0) and V = ∅ in the first loop, thus M corresponds to the whole space and the whole skyline { p 1 , p 2 , p 3 } is stored in V , the points there are sorted and split in batches and their τ scores are counted using the BatchCount algorithm. In the beginning of the second loop, q = p 2 , V = {p 1 , p 3 }, and M is the gray region in the figure. V now becomes { p 4 , p 5 } and the corresponding scores are batch-counted. The next point is then reported (e.g., p 4 ) and the algorithm continues as long as more results are required.</p><p>Algorithm 2 Iterative Top-k Dominating Algorithm (ITD) algorithm ITD(Tree R, Integer k) 1: V :=∅; q:=origin point; 2: for i := 1 to k do 3:</p><p>M:=region dominated by q but by no point in V ; 4:</p><p>V :=skyline points in M; 5:</p><p>sort the points in V by Hilbert ordering; 6:</p><p>for all batches V c of (B) points in V do 7:</p><p>initialize all scores of points in V c to 0; 8:</p><p>BatchCount(R.root,V c ); 9:</p><p>V :=V ∪ V ; 10:</p><p>q:=the point with maximum score in V ; 11: remove q from V ; 12:</p><p>report q as the ith result;</p><p>In addition, not all skyline points have large τ scores. Motivated by these observations, we study algorithms that solve the problem directly, without depending on skyline computations. This section presents an eager approach for the evaluation of top-k dominating queries, which traverses the aRtree and computes tight upper score bounds for encountered non-leaf tree entries immediately; these bounds determine the visiting order for the tree nodes. We discuss the basic algorithm, develop optimizations for it, and investigate by an analytical study the improvements of these optimizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The basic algorithm</head><p>Recall from Sect. 3.1 that the score of any point p indexed under an entry e is upper-bounded by τ (e -). Based on this observation, we can design a method that traverses aR-tree nodes in descending order of their (upper bound) scores. The rationale is that points with high scores can be retrieved early and accesses to aR-tree nodes that do not contribute to the result can be avoided. Algorithm 3 shows the pseudo code of the Simple Counting-Guided Algorithm (SCG), which directs search by counting upper bound scores of examined non-leaf entries. A max-heap H is employed for organizing the entries to be visited in descending order of their scores. W is a min-heap for managing the top-k dominating points as the algorithm progresses, while γ is the kth score in W (used for pruning). First, the upper bound scores τ (e -) of the aR-tree root entries are computed in batch (using the BatchCount algorithm) and these are inserted into the max-heap H . While the score τ (e -) of H 's top entry e is higher than γ (implying that points with scores higher than γ may be indexed under e), the top entry is deheaped, and the node Z pointed by e is visited. If Z is a non-leaf node, its entries are enheaped, after BatchCount is called to compute their upper score bounds. If Z is a leaf node, the scores of the points in it are computed in batch and the top-k set W (also γ ) is updated, if applicable.</p><p>As an example, consider the top-1 dominating query on the set of points in Fig. <ref type="figure" target="#fig_6">5</ref>. There are 3 leaf nodes and their  2 ) = 7, τ (e - 3 ) = 3) are computed by the batch counting algorithm, which incurs 3 node accesses (i.e., the root node and leaf nodes pointed by e 1 and e 3 ). Since e 2 has the highest upper bound score, the leaf node pointed by e 2 will be accessed next. Scores of entries in e 2 are computed in batch and we obtain τ ( p 1 ) = 5, τ ( p 2 ) = 1, τ ( p 3 ) = 2. Since p 1 is a point and τ ( p 1 ) is higher than the scores of remaining entries ( p 2 , p 3 , e 1 , e 3 ), p 1 is guaranteed to be the top-1 result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimizations</head><p>Now, we discuss three optimizations that can greatly reduce the cost of the basic SCG. First, we utilize encountered data points to strengthen the pruning power of the algorithm. Next, we apply a lazy counting method that delays the counting for points, in order to form better groups for batch counting. Finally, we develop a lightweight technique for deriving upper score bounds of non-leaf entries at low cost. The pruner set. SCG visits nodes and counts the scores of points and entries, based only on the condition that the upper bound score of their parent entry is greater than γ . However, we observe that points which have been counted, but have scores at most γ can also be used to prune early other entries or points, which are dominated by them. <ref type="foot" target="#foot_1">1</ref> Thus, we maintain a pruner set F, which contains points that (i) have been counted exactly (i.e., at Line 15), (ii) have scores at most γ , and (iii) are not dominated by any other point in F. The third condition ensures that only minimal information is kept in F. 2 We perform the following changes to SCG in order to use F. First, after deheaping an entry e (Line 7), we check whether there exists a point p ∈ F, such that p e -. If yes, then e is pruned and the algorithm goes back to Line 6. Second, before applying BatchCount at Lines 10 and 14, we eliminate any entries or points that are dominated by a point in F.</p><p>Lazy counting. The performance of SCG is negatively affected by executions of BatchCount for a small number of points. A batch may have few points if many points in a leaf node are pruned with the help of F. In order to avoid this problem, we employ a lazy counting technique, which works as follows. When a leaf node is visited (Line 13), instead of directly performing batch counting for the points p, those that are not pruned by F are inserted into a set L, with their upper bound score τ (e -) from the parent entry. If, after an insertion, the size of L exceeds B (the size of a batch), then BatchCount is executed for the contents of L, and all W , γ , F are updated. Just before reporting the final result set (Line 16), batch counting is performed for potential results p ∈ L not dominated by any point in F and with upper bound score greater than γ . We found that the combined effect of the pruner set and lazy counting lead to 30% I/O cost reduction of SCG, in practice.</p><p>Lightweight upper bound computation. As mentioned in Sect. 3.1, the tight upper score bound τ (e -) can be replaced by a looser, cheaper to compute, bound τ u (e). We propose an optimized version of SCG, called Lightweight Counting Guided Algorithm (LCG). Line 10 of SCG (Algorithm 3) is replaced by a call to LightBatchCount, which is a variation of BatchCount. In specific, when bounds for a set V of non-leaf entries are counted, the algorithm avoids expensive accesses at aR-tree leaf nodes, but uses entries at non-leaf nodes to derive looser bounds.</p><p>LightBatchCount is identical to Algorithm 1, except that the recursion of Line 2 is applied when Z is at least two levels above leaf nodes and there is a point in V that partially dominates e; thus, the else statement at Line 5 now refers to nodes one level above the leaves. In addition, the condition at Line 7 is replaced by p e + ; i.e., COUNT(e) is added to τ u ( p), even if p partially dominates entry e.</p><p>As an example, consider the three root entries of Fig. <ref type="figure" target="#fig_6">5</ref>. We can compute loose upper score bounds for V = {e - 1 , e - 2 , e - 3 }, without accessing the leaf nodes. Since, e - 2 fully dominates e 2 and partially dominates e 1 , e 3 , we get τ u (e 2 ) = 9. Similarly, we get τ u (e 1 ) = 3 and τ u (e 3 ) = 3. Although these bounds are looser than the respective tight ones, they still provide a good order of visiting the entries and they can be used for pruning and checking for termination. In Sect. 8, we demonstrate the significant computation savings by this lightweight counting (of τ u (e)) over exact counting (of τ (e -)) and show that it affects very little the pruning power of the algorithm. Next, we investigate its effectiveness by a theoretical analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analytical study</head><p>Consider a dataset D with N points, indexed by an aR-tree whose nodes have an average fanout f . Our analysis is based on the assumption that the data points are uniformly and independently distributed in the domain space [0, 1] d , where d is the dimensionality. Then, the tree height h and the number of nodes n i at level i (let the leaf level be 0) can be estimated by h = 1 + log f (N / f ) and n i = N / f i+1 . Besides, the extent (i.e., length of any 1D projection) λ i of a node at the ith level can be approximated by <ref type="bibr" target="#b29">[30]</ref>.</p><formula xml:id="formula_3">λ i = (1/n i ) 1/d</formula><p>We now discuss the trade-off of lightweight counting over exact counting for a non-leaf entry e. Recall that the exact upper bound score τ (e -) is counted as the number of points dominated by its lower corner e -. On the other hand, lightweight counting obtains τ u (e); an upper bound of τ (e -). For a given e -, Fig. <ref type="figure">6</ref> shows that the space can be divided into three regions, with respect to nodes at level i. The gray region M 2 corresponds to the maximal region, covering nodes (at level i) that are partially dominated by e -. While computing τ (e -), only the entries which are completely inside M 2 need to be further examined (e.g., e A ). Other entries are pruned after either disregarding their aggregate values (e.g., e B , which intersects M 1 ), or adding these values to τ (e -) (e.g., e C , which intersects M 3 ).</p><p>Thus, the probability of accessing a (ith level) node can be approximated by the area of M 2 , assuming that tree nodes at the same level have no overlapping. To further simplify our analysis, suppose that all coordinates of e -are of the same value v. Hence, the aR-tree node accesses required for computing the exact τ (e -) can be expressed as:<ref type="foot" target="#foot_3">3</ref> </p><formula xml:id="formula_4">NA exact (e -)= h-1 i=0 n i • [(1-v+λ i ) d -(1-v-λ i ) d ] (3) e _ M 1 M 2 M 3 i i i i (0,0) (0,1) (1,0) (1,1)</formula><p>e A e B e C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 6 I/O cost of computing upper bound</head><p>In the above equation, the quantity in the square brackets corresponds to the volume of M 2 (at level i) over the volume of the universe (this equals to 1), capturing thus the probability of a node at level i to be completely inside M 2 . The node accesses of lightweight computation can also be captured by the above equation, except that no leaf nodes (i.e., at level 0) are accessed. As there are many more leaf nodes than non-leaf nodes, lightweight computation incurs significantly lower cost than exact computation. Now, we compare the scores obtained by exact computation and lightweight computation. The exact score τ (e -) is determined by the area dominated by e -:</p><formula xml:id="formula_5">τ (e -) = N • (1 -v) d (4)</formula><p>In addition to the above points, lightweight computation counts also all points in M 2 for the leaf level into the upper bound score:</p><formula xml:id="formula_6">τ u (e) = N • (1 -v + λ 0 ) d (5)</formula><p>Summarizing, three factors N , v, and d affect the relative tightness of the lightweight score bound over the exact bound.</p><p>-When N is large, the leaf node extent λ 0 is small and thus the lightweight score is tight. -If v is small, i.e., e -is close to the origin and has high dominating power, then λ 0 becomes less significant in Eq. 5 and the ratio of τ u (e) to τ (e -) is close to 1 (i.e., lightweight score becomes relatively tight). -As d increases (decreases), λ 0 also increases <ref type="bibr">(decreases)</ref> and the lightweight score gets looser (tighter).</p><p>In practice, during counting-guided search, entries close to the origin have higher probability to be accessed than other entries, since their parent entries have higher upper bounds and they are prioritized by search. As a result, we expect that the second case above will hold for most of the upper bound computations and lightweight computation will be effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Priority-based traversal</head><p>In this section, we present a lazy alternative to the counting-guided method. Instead of computing upper bounds of visited entries by explicit counting, we defer score computations for entries, but maintain lower and upper bounds for them as the tree is traversed. Score bounds for visited entries are gradually refined when more nodes are accessed, until the result is finalized with the help of them. For this method to be effective, the tree is traversed with a carefully-designed priority order aiming at minimizing I/O cost. We present the basic algorithm, analyze the issue of setting an appropriate order for visiting nodes, and discuss its implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The basic algorithm</head><p>Recall that counting-guided search, presented in the previous section, may access some aR-tree nodes more than once due to the application of counting operations for the visited entries. For instance in Fig. <ref type="figure" target="#fig_6">5</ref>, the node pointed by e 1 may be accessed twice; once for counting the scores of points under e 2 and once for counting the scores of points under e 1 . We now propose a top-k dominating algorithm which traverses each node at most once and has reduced I/O cost.</p><p>Algorithm 4 shows the pseudo-code of this Priority-Based Tree Traversal Algorithm (PBT). PBT browses the tree, while maintaining (loose) upper τ u (e) and lower τ l (e) score bounds for the entries e that have been seen so far. The nodes of the tree are visited based on a priority order. The issue of defining an appropriate ordering of node visits will be elaborated later. During traversal, PBT maintains a set S of visited aR-tree entries. An entry in S can either: (i) lead to a potential result, or (ii) be partially dominated by other entries in S that may end up in the result. W is a min-heap, employed for tracking the top-k points (in terms of their τ l scores) found so far, whereas γ is the lowest score in W (used for pruning).</p><p>First, the root node is loaded, and its entries are inserted into S after upper score bounds have been derived from information in the root node. Then (Lines 8-18), while S contains non-leaf entries, the non-leaf entry e z with the highest priority is removed from S, the corresponding tree node Z is visited and (i) the τ u (τ l ) scores of existing entries in S (partially dominating e z ) are refined using the contents of Z , (ii) τ u (τ l ) values for the contents of Z are computed and, in turn, inserted to S. Note that for operations (i) and (ii), only information from the current node and S is used; no additional accesses to the tree are required. Updates and computations of τ u scores are performed incrementally with the information of e z and entries in S that partially dominate e z . W is updated with points/entries of higher τ l than γ . Finally (Line 20), entries are pruned from S if (i) they cannot lead to points that may be included in W , and (ii) are not partially dominated by entries leading to points that can reach W . It is important to note that, at Line 21 of PBT, all non-leaf entries have been removed from the set S, and thus (result) points in W have their exact scores found.</p><p>To comprehend the functionality of PBT consider again the top-1 dominating query on the example of Fig. <ref type="figure" target="#fig_6">5</ref>. For the ease of discussion, we denote the score bounds of an entry e by the interval τ (e) = [τ l (e), τ u (e)]. Initially, PBT accesses the root node and its entries are inserted into S after their lower/upper bound scores are derived (see Lines 5 At this stage, all points, except p 1 , are pruned from S, since their τ u scores are at most γ and they are not partially domi-nated by non-leaf entries that may contain potential results. Although no point from e 3 can have higher score than p 1 , we still have to keep e 3 , in order to compute the exact score of p 1 in the next round.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Traversal orders in PBT</head><p>An intuitive method for prioritizing entries at Line 9 of PBT, hinted by the upper bound principle of <ref type="bibr" target="#b18">[19]</ref> or the best-first ordering of <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24]</ref>, is to pick the entry e z with the highest upper bound score τ u (e z ); such an order would visit the points that have high probability to be in the top-k dominating result early. We denote this instantiation of PBT by UBT (for Upper-bound Based Traversal).</p><p>Nevertheless a closer look into PBT (Algorithm 4) reveals that the upper score bounds alone may not offer the best priority order for traversing the tree. Recall that the pruning operation (at Line 20) eliminates entries from S, saving significant I/O cost and leading to the early termination of the algorithm. The effectiveness of this pruning depends on the lower bounds of the best points (stored in W ). Unless these bounds are tight enough, PBT will not terminate early and S will grow very large.</p><p>For example, consider the application of UBT to the tree of Fig. <ref type="figure" target="#fig_2">2</ref>. The first few nodes accessed are in the order: root node, e 18 , e 11 , e 9 , e 12 . Although e 11 has the highest upper bound score, it partially dominates high-level entries (e.g., e 17 and e 20 ), whose child nodes have not been accessed yet. As a result, the best-k score γ (i.e., the current lower bound score of e 11 ) is small, few entries can be pruned, and the algorithm does not terminate early.</p><p>Thus, the objective of search is not only to (i) examine the entries of large upper bounds early, which leads to early identification of candidate query results, but also (ii) eliminate partial dominance relationships between entries that appear in S, which facilitates the computation of tight lower bounds for these candidates. We now investigate the factors affecting the probability that one node partially dominates another and link them to the traversal order of PBT. Let a and b be two random nodes of the tree such that a is at level i and b is at level j. Using the same uniformity assumptions and notation as in Sect. 4.3, we can infer that the two nodes a and b not intersect along dimension t with probability: <ref type="foot" target="#foot_4">4</ref>Pr(a</p><formula xml:id="formula_7">[t] ∩ b[t] = ∅) = 1 -(λ i + λ j )</formula><p>a and b have a partial dominance relationship when they intersect along at least one dimension. The probability of being such is:</p><formula xml:id="formula_8">Pr ⎛ ⎝ t∈[1,d] a[t] ∩ b[t] = ∅ ⎞ ⎠ = 1 -(1 -(λ i + λ j )) d</formula><p>The above probability is small when the sum λ i + λ j is minimized (e.g., a and b are both at low levels).</p><p>The above analysis leads to the conclusion that in order to minimize the partially dominating entry pairs in S, we should prioritize the visited nodes based on their level at the tree. In addition, among entries at the highest level in S, we should choose the one with the highest upper bound, in order to find the points with high scores early. Accordingly, we propose an instantiation of PBT, called Cost-Based Traversal (CBT). CBT corresponds to Algorithm 4, such that, at Line 9, the non-leaf entry e z with the highest level is removed from S and processed; if there are ties, the entry with the highest upper bound score is picked. In Sect. 8, we demonstrate the advantage of CBT over UBT in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Implementation details</head><p>A straightforward implementation of PBT may lead to very high computational cost. At each loop, the burden of the algorithm is the pruning step (Line 20 of Algorithm 4), which has worst-case cost quadratic to the size of S; entries are pruned from S if (i) their upper bound scores are below γ and (ii) they are not partially dominated by any other entry with upper bound score above γ . If an entry e m satisfies (i), then a scan of S is required to check (ii).</p><p>In order to check for condition (ii) efficiently, we use a main-memory R-tree I (S) to index the entries in S having upper bound score above γ . When the upper bound score of an entry drops below γ , it is removed from I (S). When checking for pruning of e m at Line 20 of PBT, we only need to examine the entries indexed by I (S), as only these have upper bound scores above γ . In particular, we may not even have to traverse the whole index I (S). For instance, if a nonleaf entry e in I (S) does not partially dominate e m , then we need not check for the subtree of e . As we verified experimentally, maintaining I (S) enables the pruning step to be implemented efficiently. In addition to I (S), we tried additional data structures for accelerating the operations of PBT (e.g., a priority queue for popping the next entry from S at Line 9), however, the maintenance cost of these data structures (as the upper bounds of entries in S change frequently at Lines 11-13) did not justify the performance gains by them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Query processing on non-indexed data</head><p>This section examines the evaluation of top-k dominating queries on non-indexed data, assuming that data points are stored in random order in a disk file D.</p><p>As discussed in <ref type="bibr" target="#b30">[31]</ref>, a practically viable solution is to first bulk-load an aR-tree (e.g., using the algorithm of <ref type="bibr" target="#b17">[18]</ref>) from the dataset and then compute top-k dominating points using the algorithms proposed in Sects. 4 and 5. The bulk-loading step requires externally sorting the points, which is known to scale well for large datasets. However, external sorting may incur multiple I/O passes over data.</p><p>Our goal is to compute the top-k dominating points with only a constant number (3) of data passes, by adopting the filter-refinement framework. The first pass is the counting pass, which employs a memory grid structure to keep track of point count in cells, while scanning over the data. This structure is then used to derive lower/upper bound scores of points in the next pass. The second pass is the filter pass, which applies pruning rules to discard unqualified points and keep the remaining ones in a candidate set. The refinement pass, being the final pass, performs a scan over the data in order to count the exact τ scores of all candidate points. Eventually, the top-k dominating points are returned.</p><p>In Sect. 6.1, we present the details of the counting pass. We investigate different techniques for the filter pass in Sects. 6.2 and 6.3; these techniques trade-off efficiency (i.e., CPU time at the filter step) for filter effectiveness (i.e., size of the candidate set). Finally, Sect. 6.4 discusses the final, refinement pass of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The counting pass</head><p>The first step of the algorithm defines a regular multi-dimensional grid over the space and performs a linear scan to the data to count the number of points in each grid cell. Such a 2-dimensional histogram (with 4 × 4 cells) is shown in Fig. <ref type="figure" target="#fig_8">7a</ref>. To ease our discussion, each grid cell is labeled as g i j . While scanning the points, we increase the counters of the cells that contain them, but do not keep the visited points in memory. In this example, at the end of scan, we have COUNT(g 11 ) = 0 and COUNT(g 12 ) = 10. We adopt the following convention so that each point contributes to the counter of exactly one cell. In case a point (e.g., p 1 ) falls on the common border of multiple cells (e.g., g 23 and g 33 ), it belongs to the cell (e.g., g 33 ) with the largest coordinates.</p><p>After the counting pass, and before the filter pass begins, we can derive lower/upper bound scores of the cells from their point counts, by using the notations of Sect. 3.1. This enables us to determine fast the cells that cannot contain topk dominating points. Given a grid cell g, its upper bound score τ u (g) is the total point count of cells it partially or fully dominates.  In Fig. <ref type="figure" target="#fig_8">7b</ref>, the cell g 33 dominates g 33 , g 43 , g 34 , and g 44 , so we have τ u (g 33 ) = 40. The lower bound score τ l (g) of g is the total point count of cells it fully dominates.</p><formula xml:id="formula_9">τ u (g) = g y ∈G∧g -g + y COUNT(</formula><formula xml:id="formula_10">τ l (g) = g y ∈G∧g + g - y COUNT(g y )</formula><p>For instance, g 33 fully dominates g 44 so we obtain τ l (g 33 ) = 10 (not shown in the figure).</p><p>Besides score bounds, pruning can also be achieved with the help of the dominance property. From Eq. 2, we observe that, a point cannot belong to the result if it is dominated by k other points. Thus, we define the dominated count g.φ of the cell g as the total point count of cells fully dominating g.</p><formula xml:id="formula_11">g.φ = g y ∈G∧g + y g - COUNT(g y )</formula><p>For example, g 32 is fully dominated by g 11 and g 21 , so we get g 32 .φ = 0 + 10 = 10. Clearly, a cell with g i j .φ ≥ k cannot contain any of the top-k results.</p><p>Let k = 2 in the example of Fig. <ref type="figure" target="#fig_8">7b</ref>. We proceed to determine the cells that cannot contain query results. These include cells with zero count (e.g., g 11 ) and cells having g i j .φ ≥ k (e.g., g 23 ). In order to obtain the value γ (lower bound score of top-k points), we enumerate the remaining cell(s) in descending order of their τ l scores, until their total point count reaches k. Since the cell g 12 contains 10 (≥ k) points and its τ l score is 60, we set γ = 60. Obviously, cells (e.g., g 14 ) whose upper score bounds below γ = 60 can be pruned. The remaining cells (containing potential results) are colored as gray in Fig. <ref type="figure" target="#fig_8">7b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Coarse-grained filter</head><p>During, the second (filter) pass, the algorithm scans the data again and determines a set of candidate points for the top-k dominating query. The first method we propose for the filter pass is called coarse-grained filter (CRS). CRS scans the database and uses the score bounds of grid cells and the dominance property (of Eq. 2) to prune points. CRS is described by Algorithm 5. Each cell g is coupled with a candidate set g.C, for maintaining candidate points that fall in g (this is done only for cells g that are not pruned after the counting pass). Initially, we have no information about the detailed contents of the cells. However, using the lower score bounds τ l of the cells and their cardinalities, we can initialize γ ; the kth highest τ l score of the top-k dominating candidates. In other words, we assume that each candidate has the maximum coordinates in its container cell g (worst case) and use τ l (g) as its lower bound. The algorithm then performs a linear scan over the dataset D at Lines 4-16. For the point p being currently examined, we initialize its upper bound τ u ( p) and dominated count p.φ using the corresponding values of its container cell g p . for each cell g ∈ G, COUNT(g) instances of the score τ l (g) are considered 4: for all p ∈ D do filter scan 5: let g p be the grid cell of p; In the loop of Lines 7-11, we search for candidate points p that dominate p and have already been read in memory. For each such occurrence, the value p.φ is incremented. Due to the presence of the dominated count g p .φ of the grid cell, it suffices to traverse only the cells that partially dominate the cell of p (as opposed to all cells). Whenever p.φ reaches k, p.φ needs not be incremented further (and the loop exits); in this case p cannot be a top-k dominating result.</p><p>In the loop of Lines 12-16, we search for candidate points p that are dominated by p and have already been read in memory. The p .φ of each such point p is incremented; and the point is pruned from the candidate set when p .φ reaches k. Note that Lines 12-16 need not be executed when p.φ is (at least) k. The reason is that any existing candidate p which is dominated by p must have also been dominated by the k dominators of p and therefore already been pruned in a previous iteration.</p><p>At Lines 17-18, we insert the current point p into the candidate set g p .C of its cell g p , only when its τ u ( p) score is above γ and its p.φ value is less than k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Fine-grained filter</head><p>CRS simply sets the score bounds of candidate points to those of their cells. Since each cell may contain a large number of points, their score bounds are not tight, weakening the filter effectiveness of CRS. In this section, we develop a fine-grained solution (FN) that tightens the score bounds of candidate points gradually. This way, more unqualified points having low scores can be eliminated from the search early.</p><p>Tightening the score bounds of points. Consider the filter step during the processing of the top-2 dominating query (i.e., k = 2) on Fig. <ref type="figure" target="#fig_8">7c</ref>. Suppose that, the points p 4 , p 5 , p 6 are existing candidates (they have already been read during the filter pass), and the next point to be processed is p 7 .</p><p>The first technique is to tighten score bounds by using the current point p 7 and existing candidate points p 4 , p 5 , p 6 . First of all, we set τ l ( p 7 ) = 40 and τ u ( p 7 ) = 90, by using score bounds of p 7 's cell g 22 . To tighten score bounds of existing candidates, we traverse the cells (i.e., g 12 , g 22 , g 21 ) that partially dominate g 22 . Since p 4 dominates p 7 , we increment τ l ( p 4 ). On the other hand, p 5 and p 6 do not dominate p 7 so their τ u scores are decremented. To tighten score bounds of the current point p 7 , we traverse the cells (e.g., g 22 , g 32 , g 42 , g 23 , g 24 ) that are partially dominated by g 22 . As p 7 dominates p 6 , we increment τ l ( p 7 ). In addition, the dominated count of p 6 now becomes 2 (≥ k) so it is removed from the local candidate set g 22 .C.</p><p>A second technique is to tighten score bounds by utilizing bounds of candidate points that have not already been pruned. Assume in Fig. <ref type="figure" target="#fig_8">7d</ref>  Writing disk partitions. We observe that the pruning effectiveness of the algorithm can be significantly improved if we are able to identify points with high scores early. To achieve this, we modify the counting pass (described in Sect. 6.1) as follows. Each grid cell g is allocated a memory partition (at least one page) to store the accessed points that fall in the cell. Whenever the memory becomes full, the largest memory partition is flushed into its corresponding disk partition g.D (i.e., a sequential file). At the end of the counting pass, remaining points in memory are flushed into their respective disk partitions. This modification costs an additional writing pass over the data, yet it permits us to access the disk partitions using different orderings (in the subsequent filter and refinement passes).</p><p>Algorithm. Algorithm 6 presents the details of our Finegrained Filter Algorithm (FN-Filter). A min-heap W is used to keep track of k points with the highest τ l scores seen so far and γ is set to the kth score in W . Like in the CRS-Filter, we first determine the kth highest lower bound score γ from the τ l scores and point counts of grid cells. Then, k dummy pairs having the score γ are inserted into W . The set S contains the grid cells whose disk partitions have yet to be visited. Initially, all grid cells are inserted into S.</p><p>At Line 10, we pick the grid cell g from S with the highest priority value, which will be elaborated shortly. In case the cell has upper bound score τ u (g) below γ and it is not partially dominated by any other grid cell g z with τ u (g z ) ≥ γ , the disk partition g.D of g is ignored. The reason is that (i) g may not contain any top-k point and (ii) its contribution to top-k candidates has already been captured in their upper/lower bounds. Otherwise, at Lines 13-38, a scan is performed over the points in g.D. At Line 14, we set the score bounds and dominated count of the current point p to that of its cell g p . At Lines 16-23, we traverse the candidates in the cells that are partially dominating g p in order to update score bounds. This is done only for cells whose partitions have been loaded before. Similarly, at Lines 24-30, we traverse the candidates in cells partially dominated by g p , in order to tighten the score bounds of the current point p. Meanwhile, we record the value of: (i) δ.l, the maximum τ l score of points dominated by p, (ii) δ.u, the minimum τ u score of points dominating p, and (iii) δ.φ, the maximum dominated count p .φ of points p dominating p. These values are then used to update the score bounds and the dominated count of the current point p. In case τ l ( p) is greater than γ , we update the top-k points in W . If τ u ( p) is at least γ , then we insert p into the local candidate set of its grid cell. At Lines 37-38, existing candidate points having τ l scores above γ are used to update W , and points with τ u scores below γ are pruned.</p><p>Order of searching disk partitions. We now investigate concrete orderings for accessing disk partitions, at Line 10 of Algorithm 6 Fine-grained Filter Algorithm (FN-Filter) the FN-Filter algorithm. We first suggest the scanline ordering as a reference, which accesses cells g in ascending order of the value:</p><formula xml:id="formula_12">SLV (g) = d i=1 (T i (g) -1) • A i-1</formula><p>where A is the number of divisions per dimension and T i (g) = A • g[i] + /ς (assuming domain as [0, ς] d ). For instance, the value of A is 4 in Fig. <ref type="figure" target="#fig_8">7a</ref>, and we have SLV</p><formula xml:id="formula_13">(g 31 ) = (3 -1) • 1 + (1 -1) • 4 = 2.</formula><p>Disk partitions of cells are visited in the order: g 11 , g 21 , g 31 , g 41 , g 12 , g 22 , . . .. This ordering is independent of score bounds of cells.</p><p>Another ordering we consider is the upper bound score ordering, which visits the cells in descending order of their upper bound scores. In the example of Fig. <ref type="figure" target="#fig_8">7b</ref>, the cells will be visited in the order: g 11 , g 21 , g 12 , g 22 , . . .. This ordering allows us to identify early points with high scores. However, it may delay accessing cells that have low upper bound, but partially dominated by those with high upper bounds. This delays the tightening of loose bounds and, in turn, the pruning of points.</p><p>Finally, we investigate a partial dominance elimination ordering, which takes partial dominance relationships among the partitions into account. We pick the cell (say, g a ) with the highest upper bound score, that partially dominates some unvisited cells. In case g a has not been visited before, we access its disk partition. Then, we access partitions of all unvisited cells g b that are partially dominated by g a , in descending order of their upper bound scores. The above procedure repeats until the cells are exhausted. For instance, in Fig. <ref type="figure" target="#fig_8">7b</ref>, we first visit the cell g 21 , and then visit the cells partially dominated by it in descending upper bound score order: g 22 , g 31 , g 23 , g 41 , g 24 . Next, we visit the cell g 12 , and unseen cells partially dominated by it: g 13 , g 32 , g 14 , g 42 .</p><p>According to these orderings, we denote the instantiations of the fine-grained method as follows: FNS (with scanline ordering), FNU (with upper bound score ordering), and FNP (with partial dominance elimination ordering).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">The refinement pass</head><p>After completing the filter pass, we obtain a set C of candidate points, which have potential to be the actual results. In the refinement pass, a linear scan is performed over the dataset D; each point p ∈ D is compared against each candidate p ∈ C and the score of p is incremented when p dominates p . This straightforward implementation requires |D| • |C| dominance comparisons and becomes expensive even for moderate-sized candidate set.</p><p>In order to accelerate the refinement pass, we take advantage of the lower score bounds of grid cells. Suppose that p 7 is a candidate point in Fig. <ref type="figure" target="#fig_8">7c</ref>. Since it falls in the cell g 22 , we set the lower bound score of p 7 to τ l ( p 7 ) = τ l (g 22 ) = 40. While scanning over D in the refinement pass, we need not compare each point p ∈ D with the candidate p 7 . Only points p in cells that are partially dominated by g 22 (i.e., g 22 , g 32 , g 42 , g 23 , g 24 ) have to be compared with p 7 .</p><p>Algorithm 7 is the pseudo-code of the grid-based refinement algorithm. G represents the grid obtained from the counting pass. Each grid cell g ∈ G is associated with a local candidate set g.C, for storing candidates (from the filter pass) that falls into the cell g. The value γ is set to the kth highest τ l score of all candidates (assuming that their score bounds are obtained from the filter pass). At Line 3, we check if a cell g has τ u score below γ and it is not partially dominated by any cell g z having some candidate point. If so, the cell is marked as irrelevant as it cannot influence the top-k result. At Line 5, the lower bound score τ l ( p) of each candidate p ∈ g.C is reset to τ l (g). Then, a scan is performed over the dataset D. In case the cell g p of the current point p ∈ D is irrelevant, the point p is discarded immediately without further processing. At Lines 11-13, only the cells partially dominating p need to be considered. Every candidate p in such a cell is compared with p , and its score τ l ( p) is incremented when p dominates p . Eventually, the k candidate points with highest scores are returned as the query results. The above refinement algorithm is generic in the sense that it does not utilize disk partitions of cells (created in FN-Filter). To optimize its performance, we replace the linear scan at Line 7 by a promising order of accessing disk partitions of cells (e.g., starting with partitions that are partially dominated by the candidate with the highest upper bound score). Nevertheless, this optimization technique cannot be applied if the filter step is performed by the CRS-Filter, which does not build disk partitions of points for cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Relaxed top-k dominating query</head><p>In this section, we study a relaxed variant of the top-k dominating query. Section 7.1 presents the motivation and definition of this query. We discuss adaptations of our tree-based algorithms for evaluating this query in Sects. 7.2, 7.3, 7.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Motivation</head><p>While the score τ ( p) models nicely the intuitive importance of a point p, the dominance requirement may be too strict in particular data distributions, where all points may have similar scores. Table <ref type="table" target="#tab_9">1</ref> shows the coordinate values of three points in the 3-dimensional space. Since each point does not dominate any other point in the dataset, we obtain τ ( p 1 ) = τ ( p 2 ) = τ ( p 3 ) = 0. In this case, we cannot identify the most "important" point from the dataset.</p><p>To avoid this problem, we propose to relax the dominance requirement as follows. Given two points p, p ∈ D, we define the set ω( p, p ) of dimensions such that p is smaller than (i.e., preferable to) p along these dimensions: </p><formula xml:id="formula_14">p 3 4 3 2 ω( p, p ) = { i | i ∈ [1, d] ∧ p[i] &lt; p [i] }<label>(6)</label></formula><p>Then, we define ψ( p, p ) = 2 |ω( p, p )| -1 (i.e., the number of non-empty dimensional subsets of ω( p, p )). As p dominates p with respect to each of these ψ( p, p ) dimensional subsets, we define the relaxed score of a point p as:</p><formula xml:id="formula_15">τ r ( p) = p ∈D ψ( p, p )</formula><p>The relaxed top-k dominating query returns k points in the dataset D with the highest τ r score.</p><p>As an example, we consider τ r scores of points in Table <ref type="table" target="#tab_9">1</ref>. By comparing p 1 with other points, we get ω( p 1 , p 2 ) = {1, 3} and ω( p 1 , p 3 ) = {1, 2}. Thus, we have τ r ( p 1 ) = ( <ref type="formula" target="#formula_2">2</ref></p><formula xml:id="formula_16">2 - 1) + (2 2 -1) = 6. Similarly, we can obtain τ r ( p 2 ) = (2 1 - 1)+(2 2 -1) = 4 and τ r ( p 3 ) = (2 1 -1)+(2 1 -1) = 2. Now,</formula><p>we are able to rank the three points based on their dominance scores (e.g., p 1 is the top-1 point in the dataset). In Sect. 8, we demonstrate that this relaxed query is appropriate for search in datasets with missing values.</p><p>Regarding the definition of ψ( p, p ), we use the number 2 |ω( p, p )| -1 of dimensional subsets, as opposed to the number of dimensions in ω( p, p ). The rationale is that, a point should be assigned a very high weight if it dominates others in a large number of dimensions. For example, consider two points p 1 and p 2 , such that p 1 dominates 10 points, each along 10 dimensions, and p 2 dominates 9 points, each along 11 dimensions. Intuitively, although p 2 dominates fewer points, p 2 should have higher score than p 1 because more combinations of dimensions are involved in the dominance relationships. The score function ψ( p, p ) captures exactly this intuition. On the other hand, if the value |ω( p, p )| is used as a replacement of ψ( p, p ) in the definition of τ r ( p), then p 1 appears better than p 2 , violating the above intuition.</p><p>It fell to our attention that the relaxed top-k dominating query shares some similarities with the concept of top-k frequent skyline points in dimensional subsets <ref type="bibr" target="#b5">[6]</ref>. The major difference of our work from <ref type="bibr" target="#b5">[6]</ref> is that we do not consider skyline points only. The dimensional subset ω( p, p ) contributes to the relaxed score τ r ( p) of p, even when p is not a skyline point in D with respect to ω( p, p ). In addition, <ref type="bibr" target="#b5">[6]</ref> emphasizes on approximate result computation but we focus on exact evaluation of our relaxed query over aR-trees. Unlike the k-dominant skyline query <ref type="bibr" target="#b4">[5]</ref>, our relaxed query does not require any apriori value of the subspace size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Adaptation of skyline-based approach</head><p>In this section, we discuss the adaptation of the skyline-based approach (in Sect. 3.2) for processing the relaxed top-k dominating query. In particular, we study the modifications of the followings: (i) the dominance property of Eq. 2, and (ii) the BatchCount procedure (Algorithm 1), which counts the exact scores for a set of points.</p><p>Monotone property for the relaxed score. First of all, we prove that the monotone property holds for the relaxed score τ r as well. This property, expressed by Eq. 7, is not only essential to the skyline-based approach, but also important for other tree-based solutions.</p><formula xml:id="formula_17">∀ p, p ∈ D, p p ⇒ τ r ( p) &gt; τ r ( p ) (<label>7</label></formula><formula xml:id="formula_18">)</formula><p>The proof is as follows. Exact score counting. Next, we study how to compute the exact τ r score of a point, by using the aR-tree. We proceed to present the relevant notations in the context of the relaxed score. Given two (non-leaf) entries e, e of the tree, we define ω l (e, e ) as the minimal set of dimensions such that e always dominates e , and ω u (e, e ) as the maximal set of dimensions such that e potentially dominates e :</p><formula xml:id="formula_19">ω l (e, e ) = { i | i ∈ [1, d] ∧ e[i] + &lt; e [i] -} ω u (e, e ) = { i | i ∈ [1, d] ∧ e[i] -&lt; e [i] + }</formula><p>As a shorthand notation, we define ψ l (e, e ) and ψ u (e, e ) as (2 |ω l (e,e )| -1) and (2 |ω u (e,e )| -1) respectively. In our subsequent discussion, these values are used to derive lower/ upper bound scores for e. Note that, ω l (e, e ) and ω u (e, e ) are equal if and only if e does not intersect e along any dimension. Otherwise, ω l (e, e ) is a proper subset of ω u (e, e ). Observe that the above notations are applicable for points p and p as well, by replacing e by p (and e by p ). We modify BatchCount (Algorithm 1) as follows so that it can be used to compute the τ r values of points (instead of their τ values). First, the sub-condition p e + ∧ p e - at Line 2 is replaced by ψ u ( p, e) &gt; ψ l ( p, e). Second, Lines 7-8 are replaced by the statement</p><formula xml:id="formula_20">τ r ( p) := τ r ( p) + ψ l ( p, e) • COUNT(e)</formula><p>As an example, we apply the above technique to compute the τ r score for the point p 0 in Fig. <ref type="figure" target="#fig_10">8a</ref>, which also shows the other points/entries to be visited in the aR-tree. Initially, the value τ r ( p 0 ) is set to zero. The detailed steps are elaborated in Fig. <ref type="figure" target="#fig_10">8b</ref>. When a point (say, p 3 ) is encountered, we simply increment τ r ( p 0 ) by ψ( p 0 , p 3 ). The same is repeated for any non-leaf entry (say, e 2 ) satisfying ψ l ( p 0 , e 2 )=ψ u ( p 0 , e 2 ), except that its count value COUNT(e 2 ) is taken into account.</p><p>In case a non-leaf entry (say, e 4 ) has different values for ψ l ( p 0 , e 4 ) and ψ u ( p 0 , e 4 ), its child node will be visited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Adaptation of counting-guided search</head><p>We proceed to elaborate the adaptation of the countingguided search (e.g., SCG, LCG) for the relaxed query. According to Eq. 7, the monotone property still holds for the relaxed score. This enables us to eliminate unqualified entries by using the pruner set (see Sect. 4.2). In addition, the technique for counting exact τ r scores of points (discussed in Sect. 7.2) can be reused for SCG and LCG.</p><p>Recall that SCG computes upper bounds of non-leaf entries (at Line 10). Due to the monotone property of Eq. 7, the tight upper bound score of an entry e is taken as τ r (e -).</p><p>In the example of Fig. <ref type="figure" target="#fig_12">10a</ref>, the lower corner of e 1 is e - 1 and the value τ r (e - 1 ) is a tight upper bound score for any point indexed under the subtree of e 1 . This value (i.e., τ r (e - 1 )) can be obtained by applying the exact counting technique described in Sect. 7.2.</p><p>Following the uniformity assumption and the notations from Sect. 4.3, we now analyze the cost of computing the exact τ r (e -) value for a non-leaf entry e. With respect to tree nodes at level i, the space is decomposed into two regions, as shown in Fig. <ref type="figure">9</ref>. The region M (in gray) fully contains the nodes whose parent entries e satisfy the condition ψ u (e, e )&gt; ψ l (e, e ); whereas the white region intersects all other nodes. By translating the area of M to the access cost, the aR-tree node accesses for computing the exact τ r (e -) can be expressed as: Unlike Eq. 3, the cost in Eq. 8 is independent of the location of e -is the space. Also, this cost is always greater than or equal to the cost in Eq. 3.</p><formula xml:id="formula_21">NA relax exact (e -) = h-1 i=0 n i • [d(2λ i ) d-1 -(d -1)(2λ i ) d ]<label>(8) e</label></formula><formula xml:id="formula_22">_ M λ i λ i λ i λ i (0,0)<label>(0,1) (1,0) (1,1) e A e</label></formula><p>Lightweight upper bound score counting. In contrast to SCG, LCG utilizes a lightweight counting technique in order to obtain upper bound scores of non-leaf entries with low cost (see Sect. 4.2). We now present a modification of this technique for deriving an upper bound score τ u r (e) for the entry e such that: (i) the computation requires no accesses to leaf nodes (thus saving significant cost), and (ii) τ u r (e) always upper bounds the exact τ r (e -). The access cost of this lightweight technique is given by Eq. 8, except that leaf nodes (at level 0) are ignored.</p><p>Figure <ref type="figure" target="#fig_12">10a</ref>, b exemplify how to obtain the value τ u r (e 1 ) for the entry e 1 . The technique is the same as the one for computing the exact τ r (e - 1 ) value, except that level-1 entries (i.e., pointing to leaf nodes) are handled in another way. For the sake of demonstration, suppose that all entries shown in Fig. <ref type="figure" target="#fig_12">10a</ref> are level-1 entries. For any encountered level-1 entry (say, e z ), we increment τ u r (e 1 ) by ψ u (e 1 , e z ) • COUNT(e z ), regardless of the ψ l (e 1 , e z ) value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Adaptation of priority-based traversal</head><p>In this section, we propose a priority-based traversal solution, called RelaxedPBT (Algorithm 8), for processing the relaxed query. The set S, the min-heap W , and the value γ have the same interpretation as in PBT (Algorithm 4). The major differences of RelaxedPBT from PBT are: (i) initialization of score bounds (Line 4-7), (ii) adjustment of score bounds (Lines 11-17), and (iii) elimination of unqualified entries (Line 20). As we will see later, several operations of the algorithm rely on the following property: Proof When ψ l (e, e ) equals to ψ u (e, e ), ω l (e, e ) is identical to ω u (e, e ). In this case, e and e do not intersect along any dimension. Combining this fact with the bounding property of entries, we have ω( p, p ) = ω l (e, e ) = ω u (e, e ), for any p ∈ e, p ∈ e . As a result, we obtain ψ( p, p ) = α.</p><p>RelaxedPBT begins by examining entries in the root node of the tree and deriving their lower/upper bound scores based on only entries in the root node. In each iteration (of the loop at Lines 8-20), a non-leaf entry e z is selected from S according to a priority order (see Sect. 5.2). The child node (say, Z ) of e z is then read from the disk.</p><p>At Lines 11-13, we update score bounds for existing entries e y in S, by comparing them against e z . By Property 1, we need not adjust the score bounds of e y when ψ u (e y , e z ) = ψ l (e y , e z ). In case of ψ u (e y , e z ) &gt; ψ l (e y , e z ), the score contribution of e z to e y is replaced by those of entries in Z . Based on the same logic, Lines 14-17 are used to adjust score bounds of entries e x in Z .</p><p>Next, we insert entries of Z into the set S and update the top-k results in W with entries (in S) having lower bound score τ l r (e) above γ . At Line 20, an entry e m is removed from S when (i) its upper bound score τ u r (e m ) is below γ , and (ii) it cannot be used to adjust score bounds of any other entry in S with upper bound score above γ . The loop continues until S does not contain any no non-leaf entries. Finally, W is returned as the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Experimental evaluation</head><p>In this section, we experimentally evaluate the performance of the proposed algorithms. All algorithms in Table <ref type="table" target="#tab_12">2</ref> were implemented in C++ and experiments were run on a Pentium D 2.8 GHz PC with 1 GB of RAM. For fairness to the STD algorithm <ref type="bibr" target="#b23">[24]</ref>, it is implemented with the spatial aggregation technique (discussed in Sect. 2.1) for optimizing counting operations on aR-trees. In Sect. 8.1 we present an extensive experimental study for the efficiency of the algorithms with synthetically generated data. Section 8.2 studies the performance of the algorithms on real data and demonstrates the meaningfulness of top-k dominating points.  or all other dimensions. Table <ref type="table" target="#tab_13">3</ref> lists the range of parameter values and their default values (in bold type). Each dataset is indexed by an aR-tree with 4 KB page size. We used an LRU memory buffer whose default size is set to 5% of the tree size.</p><p>Lightweight counting optimization in Counting-Guided search. In the first experiment, we investigate the performance savings when using the lightweight counting heuristic in the counting-guided algorithm presented in Sect. 4. Using a default uniform dataset, for different locations of a non-leaf entry e -(after fixing all coordinates of e -to the same value v), we compare (i) node accesses of computing the exact τ (e -) with that of computing a conservative upper bound τ u (e) using the lightweight approach and (ii) the difference between these two bounds. Figure <ref type="figure" target="#fig_13">11a</ref> shows the effect of v (i.e., location of e -) on node accesses of these two computations. Clearly, the lightweight approach is much more efficient than the exact approach. Their cost difference can be two orders of magnitude when e -is close to the origin. Figure <ref type="figure" target="#fig_13">11b</ref> plots the effect of v on the value of upper bound score. Even though lightweight computation accesses much fewer nodes, it derives a score that tightly upper bounds the exact score (τ u (e) is only 10% looser than τ (e -)). Summarizing, the lightweight approach is much more efficient than the exact approach while still deriving a reasonably tight upper bound score.</p><p>Orderings in priority-based traversal. In Sect. 5.  The size of S in CBT is much lower than that in UBT. Hence, CBT requires less CPU time than UBT on book-keeping the information of visited entries and negligible memory compared to the problem size. Both figures show that our carefully-designed priority order in CBT outperforms the intuitive priority order in UBT by a wide margin.</p><p>Comparison of all algorithms and variants thereof. We now compare all algorithms and their variants (STD, ITD, SCG, LCG, UBT, CBT) for the default query parameters on UI, CO, and AC datasets (Fig. <ref type="figure" target="#fig_3">13</ref>). In this and subsequent experiments, we compile the I/O and CPU costs of each algorithm, by charging 10ms I/O time per page fault, and show their I/O-CPU cost-breakdown. ITD performs much better than the baseline STD algorithm of <ref type="bibr" target="#b23">[24]</ref> (even though STD operates on the aR-tree), due to the effectiveness of the batch counting and Hilbert ordering techniques for retrieved (constrained) skyline points. LCG and CBT significantly outperform ITD, as they need not compute the scores for the whole skyline, whose size grows huge for AC data. Note that the optimized version of counting-guided search (LCG) outperforms the simple version of the algorithm that computes exact upper bounds (SCG) by a wide margin. Similarly, for priority-based traversal, CBT outperforms UBT because of the reasons explained in the previous experiment. Observe that the best priority-traversal algorithm (CBT) has lower I/O cost than optimized counting-guided search (LCG), since CBT accesses each node at most once but LCG may access some nodes more than once during counting operations.</p><p>In remaining experiments, we only compare the best algorithms from each gender (ITD, LCG, and CBT), for a wide range of query and system parameter values. First, we study the effect of the buffer on the performance of the algorithms. Figure <ref type="figure" target="#fig_12">14</ref> shows the cost of the algorithms as a function of buffer size (%). Observe that the costs of LCG and CBT with the smallest tested buffer (1% of the tree size) are still much lower than that of ITD with the largest buffer size (20%). Since CBT accesses each tree node at most once, its cost is independent of the buffer. Clearly, CBT outperforms its competitors for all tested buffer sizes. We note that the memory usage (for storing visited tree entries) of ITD, LCG, and CBT for UI data are 0.03, 0.02, 0.96% of the tree size, respectively, and are further reduced by 30% for CO data.</p><p>For AC data the corresponding values are 2.72, 0.11, and 1.48%. Besides, their memory usage increases slowly with k and rises sublinearly with N . Even at d = 5, their memory usage is only two times of that at d = 3. We also investigated the effect of k on the cost of the algorithms (see Fig. <ref type="figure" target="#fig_12">15</ref>). In some tested cases of Fig. <ref type="figure" target="#fig_12">15a</ref>, the cost of ITD is too high for the corresponding bar to fit in the diagram; in these cases the bar is marked with a "≈" sign and the actual cost is explicitly given. Observe that LCG and CBT outperform ITD in all cases. As k increases, ITD performs more constrained skyline queries, leading to more counting operations on retrieved points. CBT has lower cost than LCG for UI data because CBT accesses each tree node at most once. For CO data, counting operations in LCG become very efficient and thus LCG and CBT have similar costs. On the other hand, for AC data, there is a wide performance gap between LCG and CBT.</p><p>Figure <ref type="figure" target="#fig_12">16</ref> plots the cost of the algorithms as a function of the data dimensionality d. Again, ITD is inferior to its competitors for most of the cases. As d increases, the number of skyline points increases rapidly but the number of points examined by LCG/CBT increases at a slower rate. Again, CBT has lower cost than LCG for all cases. Figure <ref type="figure" target="#fig_12">17</ref> investigates the effect of the data size N on the cost of the algorithms.</p><p>When N increases, the number of skyline points increases considerably and ITD performs much more batch counting operations than LCG. Also, the performance gap between LCG and CBT widens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Experiments with real data</head><p>Datasets. We experimented with three real multi-dimensional datasets: FC, <ref type="foot" target="#foot_5">5</ref> NBA, <ref type="foot" target="#foot_6">6</ref> and BASEBALL. <ref type="foot" target="#foot_7">7</ref> FC contains 581,012 forest land cells (i.e., data objects), having four attributes: horizontal distance to hydrology (hh), vertical distance to hydrology (vh), horizontal distance to roadways (hr), and horizontal distance to fire points (hf). For FC, small values are preferable to large ones at all dimensions. NBA contains regular season statistics of 19,112 NBA players (i.e., data objects). In order for the query to be meaningful, only few important attributes are selected for NBA players: games played (gp), points (pts), rebounds (reb), and assists (ast). BASEBALL consists of statistics of 36898 baseball pitchers (i.e., data objects). Similarly, few important attributes are chosen for baseball pitchers: wins (w), games (g), saves (sv), and strikeouts (so). In the last two datasets, large values are preferable for all dimensions and each player is uniquely identified by his/her name and year. Performance experiment. Table <ref type="table" target="#tab_3">4</ref> shows the cost of the algorithms on two largest datasets (FC and BASEBALL) for  different values of k, by fixing the buffer size to 5% of the tree size. Observe that the cost of ITD becomes prohibitively expensive at high values of k. Clearly, CBT has the lowest cost and the performance gap between the algorithms widens as k increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meaningfulness of top-k dominating query results.</head><p>Table <ref type="table" target="#tab_16">5</ref> shows the dominating scores and the attribute values of the top-5 dominating players in the NBA and BASEBALL datasets. Readers familiar with these sports can easily verify that the returned results match the public view of super-star players. Although the ranking of objects by their τ -scores may not completely match with every personalized ranking suggested by individuals, a top-k dominating query at least enables them to discover some representative "top" objects without any specific domain knowledge. In addition, we note that some of the top-k results do not belong to the skyline. For example, the NBA player "Kevin Garnett/2002" is the top-3 result, even though he is dominated by the top-1 result (i.e., not a skyline point). Similarly, the top-4 BASEBALL pitcher is dominated by the top-2. These players could not be identified by skyline queries.</p><p>In general, various approaches could be applied to measure the meaningfulness of query results. Yet, there is no standardized notion for capturing the meaningfulness of results. We regard the τ score as a reasonable, obvious, and quantitative measure of the result meaningfulness; due to the rationale that, each individual top-k dominating player is guaranteed to overqualify a large number of other players (in other teams). However, we are not advocating the τ score as the best possible measure of result meaningfulness.</p><p>As an alternative choice of result meaningfulness, we also measure the number of distinct data points dominated by the query result set <ref type="bibr" target="#b21">[22]</ref>, on real datasets. For the NBA dataset, the top-1, top-2, and top-5 (dominating) query results dominate respectively 97.24, 98.13, and 98.80% of distinct points in the dataset. For the BASEBALL dataset, the top-1, top-2, and top-5 (dominating) query results dominate respectively 93.93, 94.88, and 98.67% of data points. It turns out that, some points in the result set are well separated from the others, causing the overall result set to dominate a substantial number of distinct data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Experiments with non-indexed data</head><p>In this section, we evaluate the performance of our proposed solutions for top-k dominating queries on non-indexed data. We use CRS to denote the version of our algorithm which uses the CRS-filter in the filter pass. The version using the FN-Filter has variants with different search orderings in the filter step: (i) FNS, with the scanline ordering, (ii) FNU, with the upper bound score ordering, and (iii) FNP, with the partial-dominance reduction ordering. As a reference, we compare these methods with CBT, which is the best aR-tree based algorithm. In order to apply CBT, we need to bulk-load the aR-tree from the data first, so we include the cost of the tree creation in its overhead.</p><p>Note that the I/O accesses of our non-indexed solutions (and the bulk-loading stage before CBT) are mostly sequential (with negligible random disk page accesses). Each sequential page access is charged 1ms I/O time. For instance, CRS performs three full read passes over data. Each fine-grained solution (i.e., FNS, FNU, FNP) performs one full read pass and one full write pass in the counting pass, and two partial read passes (i.e., some partitions are not accessed in filter and refinement steps). For fairness to CBT, we assume that the main memory is large enough for the aR-tree bulk-loading stage to complete in two full read passes and two full write passes.</p><p>Figure <ref type="figure" target="#fig_12">18</ref> illustrates the cost breakdown of our proposed methods on non-indexed data, for default parameter values on UI, CO, and AC datasets. Each bar is decomposed into filter CPU time, refinement CPU time, and the total sequential I/O time (of all steps/passes). For CBT, sequential I/O time indicates its cost in the bulk-loading stage, whereas its filter time represents the total query evaluation time (i.e., CPU time and random I/O time) using the aR-tree. Due to the bulk-loading stage, CBT is more expensive than most of our non-indexed methods, especially for the UI dataset. CRS is a coarse-grained solution so its filter step is cheap; however, many candidates are produced and the refinement step is expensive. In particular, its computational time is high for the AC dataset, because of the huge candidate size. On the other hand, the fine-grained solutions (FNS, FNU, FNP)  have robust performance across different data distributions because they tighten score bounds of existing candidates while reading new points in the filter step. We proceed to examine the filter effectiveness of the proposed non-indexed solutions. Specifically, we measure the candidate size |C| and the top-k lower bound score γ (known so far) at the end of the filter step. Both of them provide the user early insight about the results. Table <ref type="table" target="#tab_17">6</ref> shows the values of |C| and γ , obtained by our methods, on different data distributions. As a comparison, we include into the last row the number of results and the actual top-k score. In summary, FNP has the best filter effectiveness, followed by FNS, FNU, and CRS. Since CRS relies mainly on the dominance property to prune unqualified points, it can hardly reduce the candidate size for the AC dataset. FNU is a fine-grained solution and performs tightening of score bounds for candidate points in the filter step; thus, it is more effective than CRS. However, FNU visits the disk partitions in descending order of their upper bound scores, and it shares the same drawback as its tree-based counterpart UBT (see Sect. 8.1). Interestingly, the visiting order of FNS is independent of the underlying data distributions, yet it is more effective than FNU. The FNP method, with our carefully-designed visiting order, leads to extremely low candidate sizes |C| and tight top-k lower bound score γ . In particular, for the UI data, the candidate set of FNP is exactly the same as the final result set and γ is only 0.002% lower than the actual top-k score. Therefore, we recommend FNP as the best non-indexed solution for top-k dominating queries. We then investigate the progressiveness of our non-indexed solutions. During the execution of an algorithm, the top-k lower bound score γ (known so far) provides the user an early and rough picture over the actual score. Figure <ref type="figure" target="#fig_18">19</ref> plots the γ value of the algorithms (CBT, FNS, FNP) as a function of time (including both I/O time and CPU time). Observe that both FNS and FNP acquire high γ value early at 10-15 s. Since the application of CBT on nonindexed data requires aR-tree bulk-loading, it starts obtaining high γ value only after 25 s. In summary, both FNS and FNP allow the user to attain early a tight lower bound estimate of the actual top-k score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Experiments with the relaxed query</head><p>Performance experiment. Figure <ref type="figure" target="#fig_19">20</ref> shows the cost of our algorithms for the relaxed top-k dominating query on UI, CO, and AC datasets, with the default parameter values. In general, CBT has the best performance and it is stable for different data distributions. Since ITD and LCG access some tree node multiple times (through different counting operations), they become expensive for processing the relaxed query, especially on the AC dataset. In contrast, CBT reads each tree node at most once and adjusts score bounds of existing entries incrementally.</p><p>Data analysis on real data with missing values. In real-life, the data may have missing values, either inherently, or introduced by the data owner in purpose. This may happen, for example, in an attempt to avoid leakage of sensitive values. Another example is that the data owner chooses to publish a "trial" dataset with missing values and only reveals the original dataset to the client upon purchase.</p><p>We now demonstrate the robustness of the relaxed query on a real dataset with missing values. Specially, for each tuple in the NBA dataset, an attribute is randomly chosen and its value is set to NULL. The resulting dataset is called the NBA miss dataset. Since our algorithms operate on aR-tree indexed data,each NULL value in the tree needs to be replaced by the worst value. Table <ref type="table" target="#tab_8">7</ref> shows the relaxed top-16 dominating players on the NBA miss dataset. The results are then compared with the top-70 dominating points on the original dataset NBA. For instance, the 4th point in NBA miss is the 7th point in NBA; the 5th point in NBA miss is marked as "-", meaning that it is outside the top-70 in NBA. It turns out that, the relaxed query is able to retrieve a decent number of meaningful results, even though in the presence of many missing values in NBA miss . The robustness of the relaxed query is explained by the fact that the contribution of a score component is less restrictive in the (relaxed) τ r function than in the (original) τ function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>In this section, we present the summary of our experimental results and discuss the scalability of the proposed techniques for high dimensional data.</p><p>Summary of experimental results. Regarding the processing of top-k dominating queries on aR-tree indexed data, our performance experiments suggest that CBT has stable performance across different data distributions. Also, it has the best performance for the case of relaxed top-k dominating queries. Thus, it is recommended for evaluating top-k dominating queries on indexed data.</p><p>In case the data is not indexed, the FNP method outperforms its competitors and it has robust performance for dif- ferent data distributions. In addition, its processing cost is better than the best index-based approach (CBT), if the latter includes the cost of bulk-loading the index.</p><p>High dimensional data. Recall that, in Eq. 1, the score of point p is defined by the number of points p dominated by p. When the dimensionality of the problem is high, the dominance condition becomes too restrictive and even the top points may have low scores. Consequently, there may not exist a distinctive top object having much higher scores than the rest, implying that the top-k dominating query is not meaningful, due to the dimensionality curse. In order to produce meaningful results, we consider only low dimension data (from 2 to 5) in our experiments. In addition, both our indexed and non-indexed algorithms become inefficient for high dimensional data.</p><p>To extend the applicability of top-k dominating analysis for high dimensional data, we introduce the relaxed top-k dominating query, which is able to capture "partial" dominance relationships among the data points. Thus, meaningful top-k results can be obtained from the relaxed query over high dimensional data. Still, our techniques proposed in Sect. 7 operate on multi-dimensional indexes or grids, which degenerate at high dimensionality. As part of our future work, we will focus on the development of efficient solutions for the relaxed query over high dimensional data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>In this paper, we studied the interesting and important problem of processing top-k dominating queries on multi-dimensional data. Although the skyline-based algorithm in <ref type="bibr" target="#b23">[24]</ref> is applicable to the problem, it suffers from poor performance, as it unnecessarily examines many skyline points. This motivated us to develop carefully-designed solutions that exploit the intrinsic properties of the problem for accelerating query evaluation. First, we proposed ITD, which integrates the algorithm of <ref type="bibr" target="#b23">[24]</ref> with our optimization techniques (batch counting and Hilbert ordering). Next, we developed LCG, a top-k dominating algorithm that guides search by computing upper bound scores for non-leaf entries, and utilizes a lightweight (i.e., I/O-inexpensive) technique for computing upper bound scores. Then, we proposed I/O efficient algorithm CBT that accesses each node at most once. The effectiveness of our optimizations (lightweight counting technique in LCG and traversal order in CBT) were analyzed theoretically.</p><p>In addition to algorithms that apply on indexed data, we also propose a methodology for evaluating top-k dominating queries over non-indexed data that are stored in a sequential file. Our method can compute the query result within three passes over the data. In the first pass, a grid-histogram is computed to capture the distribution of the points. The grid is used to derive three types of bounds for multi-dimensional regions, which are helpful to determine a set of candidate topk points during the second pass. In the third and final pass, the dominance scores of the candidates are counted exactly to derive the final result. We proposed and compared variants for the second (filter) pass of the algorithm.</p><p>The final contribution of the paper is the proposal of a relaxed version of the top-k dominating query, where the dominance relationships between points in all dimensional subspaces are considered. The score of a point is determined by summing the number of points it dominates from all subspaces. We exemplified and showed experimentally the flexibility of this query compared to the strict version of the problem. In addition, we showed how the proposed algorithms can be adapted to solve this relaxed top-k dominating query.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Features of hotels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 aR-tree example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 Fig. 3</head><label>13</label><figDesc>Fig. 3 Dominance relationship among aR-tree entries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 e - 3 )</head><label>13</label><figDesc>, (ii) partial dominance (e.g., e - no dominance (e.g., e - 1 e +</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>7 p 4 p 5 MFig. 4</head><label>754</label><figDesc>Fig. 4 Constrained skyline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5</head><label>5</label><figDesc>Fig.<ref type="bibr" target="#b4">5</ref> Computing upper bound scores corresponding entries in the root node are e 1 , e 2 , and e 3 . First, upper bound scores for the root entries (i.e., τ (e - 1 ) = 3, τ (e - 2 ) = 7, τ (e - 3 ) = 3) are computed by the batch counting algorithm, which incurs 3 node accesses (i.e., the root node and leaf nodes pointed by e 1 and e 3 ). Since e 2 has the highest upper bound score, the leaf node pointed by e 2 will be accessed next. Scores of entries in e 2 are computed in batch and we obtain τ ( p 1 ) = 5, τ ( p 2 ) = 1, τ ( p 3 ) = 2. Since p 1 is a point and τ ( p 1 ) is higher than the scores of remaining entries ( p 2 , p 3 , e 1 , e 3 ), p 1 is guaranteed to be the top-1 result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>-6); τ (e 1 ) = [0, 3], τ (e 2 ) = [0, 9], τ (e 3 ) = [0, 3]. Assume for now, that visited nodes are prioritized (Lines 9-10) based on the upper bound scores τ u (e) of entries e ∈ S. Entry e 2 , of the highest score τ u in S is removed and its child node Z is accessed. Since e - 1 e + 2 and e - 3 e + 2 , the upper/lower score bounds of remaining entries {e 1 , e 3 } in S will not be updated (the condition of Line 11 is not satisfied). The score bounds for the points p 1 , p 2 , and p 3 in Z are then computed; τ ( p 1 ) = [1, 7], τ ( p 2 ) = [0, 3], and τ ( p 3 ) = [0, 3]. These points are inserted into S, and W = { p 1 } with γ = τ l ( p 1 )=1. No entry or point in S can be pruned, since their upper bounds are all greater than γ . The next nonleaf entry to be removed from S is e 1 (the tie with e 3 is broken arbitrarily). The score bounds of the existing entries S = {e 3 , p 1 , p 2 , p 3 } are in turn refined; τ (e 3 ) remains [0, 3] (unaffected by e 1 ), whereas τ ( p 1 ) = [3, 6], τ ( p 2 ) = [1, 1], and τ ( p 3 ) = [0, 3]. The scores of the points indexed by e 1 are computed; τ ( p 4 ) = [0, 0], τ ( p 5 ) = [0, 0], and τ ( p 6 ) = [1, 1] and W is updated to p 1 with γ = τ l ( p 1 ) = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7 Using the grid in the filter step, k = 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Algorithm 5</head><label>5</label><figDesc>Coarse-grained Filter Algorithm (CRS-Filter) algorithm CRS-Filter(Dataset D, Integer k, Grid G) 1: for all cell g ∈ G do 2: g.C:=new set; candidate set of the cell 3: γ :=the kth highest τ l score of cells in G;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Exact computation of the τ r value for a point</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 Ie 1 add ( 2 2r (e 1 )Fig. 10</head><label>912110</label><figDesc>Fig. 9 I/O cost of computing upper bound</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Property 1</head><label>1</label><figDesc>Consider two (non-leaf) entries e and e of the tree and a binding integer value α. If ψ l (e, e ) = ψ u (e, e ) = α, then ψ( p, p ) = α for any p ∈ e, p ∈ e .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11</head><label>11</label><figDesc>Fig. 11 The effect of v, UI, N = 1 M, d = 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 3 timeFig. 13</head><label>12313</label><figDesc>Fig.<ref type="bibr" target="#b11">12</ref> The effect of ordering priorities, UI, N = 1 M, d = 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 14 Fig. 15</head><label>1415</label><figDesc>Fig. 14 Cost vs. buffer size (%), k = 16, N = 1 M, d = 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 16 16 NFig. 17</head><label>161617</label><figDesc>Fig. 16 Cost vs. d, N = 1 M, k = 16</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>18</head><label></label><figDesc>Fig.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 19</head><label>19</label><figDesc>Fig. 19 Top-k score γ vs. time, N = 1 M, k = 16</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 20</head><label>20</label><figDesc>Fig. 20 Query cost of relaxed query (k = 16, N = 1 M, d = 3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1 Batch Counting</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>algorithm BatchCount(Node Z , Point set V )</cell></row><row><cell cols="2">1: for all entries e ∈ Z do 2: if Z is non-leaf and ∃ p ∈ V, p e + ∧ p e -then</cell></row><row><cell>3:</cell><cell>read the child node Z pointed by e;</cell></row><row><cell>4:</cell><cell>BatchCount(Z , V );</cell></row><row><cell>5:</cell><cell>else</cell></row><row><cell>6: 7:</cell><cell>for all points p ∈ V do if p e -then</cell></row><row><cell>8:</cell><cell>τ ( p):=τ ( p)+COUNT(e);</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Algorithm 4</head><label>4</label><figDesc>Priority-Based Tree Traversal Algorithm (PBT)    </figDesc><table><row><cell></cell><cell cols="2">algorithm PBT(Tree R, Integer k)</cell></row><row><cell cols="2">1: S:=new set;</cell><cell cols="2">entry format in S: e, τ l (e), τ u (e)</cell></row><row><cell cols="2">2: W :=new min-heap;</cell><cell></cell><cell>k points with the highest τ l</cell></row><row><cell cols="2">3: γ :=0;</cell><cell cols="2">the kth highest τ l score found so far</cell></row><row><cell cols="4">4: for all e x ∈ R.root do 5: τ l (e x ):= e∈R.root∧e + x e -COUNT(e); 6: τ u (e x ):= e∈R.root∧e -x e + COUNT(e); 7: insert e x into S and update W ;</cell></row><row><cell cols="3">8: while S contains non-leaf entries do</cell></row><row><cell>9:</cell><cell cols="3">remove e z : non-leaf entry of S with the highest priority;</cell></row><row><cell>10: 11:</cell><cell cols="3">read the child node Z pointed by e z ; for all e y ∈ S such that e + y e -z ∧ e -y</cell><cell>e + z do</cell></row><row><cell>12:</cell><cell cols="3">τ l (e y ):=τ l (e y ) + e∈Z ∧e + y e -COUNT(e);</cell></row><row><cell>13: 14: 15: 16:</cell><cell cols="3">τ u (e y ):=τ l (e y ) + e∈Z ∧e + y S z :=Z ∪ {e ∈ S | e + z e -∧ e -z for all e x ∈ Z do τ l (e x ):=τ l (e z ) + e∈Sz ∧e + x e -COUNT(e); e -∧e -y e + COUNT(e); e + };</cell></row><row><cell>17:</cell><cell cols="2">τ u (e x ):=τ l (e x ) + e∈Sz ∧e + x</cell><cell>e -∧e -x e + COUNT(e);</cell></row><row><cell>18:</cell><cell cols="2">insert all entries of Z into S;</cell></row><row><cell>19:</cell><cell></cell><cell></cell></row></table><note><p>update W (and γ ) by e ∈ S whose score bounds changed; 20: remove entries e m from S where τ u (e m ) &lt; γ and ¬∃e ∈ S, (τ u (e) ≥ γ ) ∧ (e + e - m ∧ e -e + m ); 21: report W as the result;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>g y )</figDesc><table><row><cell>y</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>g 14</cell><cell>10</cell><cell>g 24</cell><cell>10</cell><cell>g 34</cell><cell>10</cell><cell>g 44 p 3</cell><cell>10</cell><cell></cell><cell></cell><cell></cell></row><row><cell>g 13</cell><cell>10</cell><cell>g 23</cell><cell>10</cell><cell>p 1 g 33</cell><cell>10</cell><cell>g 43</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>g 12</cell><cell>10</cell><cell>p 2 g 22</cell><cell>10</cell><cell>g 32</cell><cell>10</cell><cell>g 42</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>g 11</cell><cell>0</cell><cell>g 21</cell><cell>10</cell><cell>g 31</cell><cell>10</cell><cell>g 41</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">(a) Point counts of cells</cell><cell cols="4">(b) Derived values of cells</cell></row><row><cell>y</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>y</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>g 24</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">p 11</cell><cell cols="2">p 14</cell></row><row><cell>g 12</cell><cell>p 4</cell><cell>p 7 g 23 g 22 g 21</cell><cell>p 5 p 6</cell><cell>g 32</cell><cell></cell><cell>g 42</cell><cell></cell><cell>g 31</cell><cell>p 17</cell><cell>p 23</cell><cell>p 26</cell><cell>p 29</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell>x</cell></row></table><note><p>(c) Tightening of score bounds (d) Points in the same cell</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>that, the point p 17 is visited after points p 11 and p 14 (intermediate points like p 12 have been pruned). In this case, τ l ( p 17 ) can be tightened to max{τ l ( p 17 ), τ l ( p 11 ), τ l ( p 14 )}. As another example, suppose that the point p 29 is visited after points p 23 and p 26 . Then, the upper bound score of p 29 can be tightened to min{τ</figDesc><table /><note><p>u ( p 29 ), τ u ( p 23 ), τ u ( p 26 )}.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>algorithm FN-Filter(Dataset D, Integer k, Grid G) 1: γ :=the kth highest τ l score of cells in G;for each cell g ∈ G, COUNT(g) instances of the score τ l (g) are considered 2: W :=new min-heap; k points with the highest τ l 3: insert k dummy pairs NU L L, γ into W ;</figDesc><table><row><cell cols="2">4: S:=new set;</cell><cell></cell><cell>set of grid cells</cell></row><row><cell cols="2">5: for all cell g ∈ G do</cell><cell></cell></row><row><cell>6:</cell><cell>g.C:=new set;</cell><cell></cell><cell>candidate set of the cell</cell></row><row><cell>7:</cell><cell cols="3">let g.D be the disk partition of g;</cell></row><row><cell>8:</cell><cell>insert g into S;</cell><cell></cell></row><row><cell cols="3">9: while S is non-empty do</cell></row><row><cell>10:</cell><cell cols="3">remove g: the cell in S with the highest priority;</cell></row><row><cell>11:</cell><cell cols="3">if τ u (g) &lt; γ and ¬∃g z ∈ G, (τ u (g z ) ≥ γ ) ∧ (g + z g -∧ g -z g + ) then</cell></row><row><cell>12:</cell><cell cols="3">ignore further processing for the disk partition g.D;</cell></row><row><cell>13:</cell><cell cols="2">for all p ∈ g.D do</cell><cell>scan over points in disk partition g.D</cell></row><row><cell>14:</cell><cell cols="3">τ l ( p):=τ l (g); τ u ( p):=τ u (g); p.φ:=g.φ;</cell></row><row><cell>15: 16: 17:</cell><cell cols="3">δ.l:=-1; δ.u:=|D|; δ.φ:=-1; for all cell g z ∈ G such that g -z for all p ∈ g z .C do existing candidates in memory g + ∧ g + g -do z</cell></row><row><cell>18:</cell><cell>if p</cell><cell>p then</cell></row><row><cell cols="4">19: τ 21: δ.φ:=max{ δ.φ, p .φ };</cell></row><row><cell>22:</cell><cell>else</cell><cell></cell></row><row><cell>23:</cell><cell>τ</cell><cell></cell></row></table><note><p>l ( p ):=τ l ( p ) + 1; p.φ:= p.φ + 1; 20: δ.u:=min{ δ.u, τ u ( p ) }; u ( p ):=τ u ( p ) -1; 24: for all cell g z ∈ G such that g -g + z ∧ g + g - z do 25: for all p ∈ g z .C do existing candidates in memory 26: if p p then 27: τ l ( p):=τ l ( p) + 1; p .φ:= p .φ + 1; 28: δ.l:=max{ δ.l, τ l ( p ) }; 29: else 30: τ u ( p):=τ u ( p) -1; 31: τ l ( p):=max{ τ l ( p), δ.l }; τ u ( p):=min{ τ u ( p), δ.u }; 32: p.φ:=max{ p.φ, δ.φ + 1 }; 33: if τ l ( p) &gt; γ and p.φ &lt; k then 34: update W (and γ ), by p, τ l ( p) ; 35: if τ u ( p) ≥ γ and p.φ &lt; k then 36: insert p into g.C; 37: update W (and γ ) by points whose τ l scores &gt; γ ; 38: remove points p ∈ g y .C (where g y ∈ G) satisfying the condition p .φ ≥ k or τ u ( p ) &lt; γ ;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Algorithm 7</head><label>7</label><figDesc>Grid-based Refinement Algorithm algorithm GridRefinement(Dataset D, Integer k, Grid G) 1: γ :=the kth highest τ l score of candidates in cells of G; 2: for all cell g ∈ G do 3: if τ u (g) &lt; γ and ¬∃g z ∈ G, (|g z .C| &gt; 0) ∧ (g +</figDesc><table><row><cell></cell><cell>g + ) then</cell><cell>z</cell><cell>g -∧g -z</cell></row><row><cell>4:</cell><cell>mark the cell g as irrelevant;</cell><cell></cell></row><row><cell>5:</cell><cell>for all p ∈ g.C do</cell><cell></cell></row><row><cell>6:</cell><cell>τ l ( p):=τ l (g);</cell><cell cols="2">reset lower bound score</cell></row><row><cell cols="2">7: for all p ∈ D do</cell><cell></cell></row><row><cell>8:</cell><cell>let g p be the grid cell of p ;</cell><cell></cell></row><row><cell>9:</cell><cell>if g p is irrelevant then</cell><cell></cell></row><row><cell>10: 11:</cell><cell cols="3">ignore further processing for point p ; for all cell g ∈ G such that g -g + p ∧ g + g -p do</cell></row><row><cell>12:</cell><cell cols="2">for all p ∈ g.C such that p p do</cell></row><row><cell>13:</cell><cell>τ</cell><cell></cell></row></table><note><p>l ( p):=τ l ( p) + 1; 14: return k points in g∈G g.C with the highest τ l scores;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 1 Example</head><label>1</label><figDesc></figDesc><table><row><cell>of points in the 3-dimensional space</cell><cell>Point p</cell><cell>p[1]</cell><cell>p[2]</cell><cell>p[3]</cell></row><row><cell></cell><cell>p 1</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell>p 2</cell><cell>3</cell><cell>1</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Algorithm 8</head><label>8</label><figDesc>Variant of PBT for the relaxed query ) -ψ u (e y , e z ) • COUNT(e z ) + e∈Z ψ u (e y , e) • COUNT(e); 14: S z :=Z ∪ { e ∈ S | ψ u (e z , e) &gt; ψ l (e z , e) };</figDesc><table><row><cell></cell><cell>algorithm RelaxedPBT(Tree R, Integer k)</cell></row><row><cell cols="2">1: S:=new set; 2: W :=new min-heap; 3: γ :=0; 4: for all e x ∈ R.root do 5: τ l r (e x ):= e∈R.root ψ l (e x , e) • COUNT(e); entry format in S: e, τ l r (e), τ u r (e) k points with the highest τ l r the kth highest τ l r score found so far 6: τ u r (e x ):= e∈R.root ψ u (e x , e) • COUNT(e);</cell></row><row><cell>7:</cell><cell>insert e x into S and update W ;</cell></row><row><cell cols="2">8: while S contains non-leaf entries do</cell></row><row><cell>9:</cell><cell>remove e z : non-leaf entry of S with the highest priority;</cell></row><row><cell>10: 11: 12:</cell><cell>read the child node Z pointed by e z ; for all e y ∈ S such that ψ u (e y , e z ) &gt; ψ l (e y , e z ) do τ l r (e y ):=τ l r (e y )-ψ l (e y , e z )•COUNT(e z )+ e∈Z ψ l (e y , e)•</cell></row><row><cell></cell><cell>COUNT(e);</cell></row><row><cell cols="2">13: r (e y 15: τ u r (e y ):=τ u for all e x ∈ Z do 16: τ l r (e x ):=τ l r (e z )-ψ l (e z , e z )•COUNT(e z )+ e∈Sz ψ l (e x , e)•</cell></row><row><cell></cell><cell>COUNT(e);</cell></row><row><cell>17:</cell><cell>τ u r (e COUNT(e);</cell></row><row><cell>18:</cell><cell>insert all entries of Z into S;</cell></row><row><cell>19:</cell><cell>update W (and γ ) by e ∈ S whose score bounds changed;</cell></row><row><cell>20:</cell><cell>remove entries e</cell></row></table><note><p>x ):=τ u r (e z )-ψ u (e z , e z )•COUNT(e z )+ e∈Sz ψ l (e x , e)• m from S where τ u r (e m ) &lt; γ and ¬∃e ∈ S, (τ u r (e) ≥ γ ) ∧ (ψ u (e, e m ) &gt; ψ l (e, e m )); 21: report W as the result;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 2</head><label>2</label><figDesc>Description of the algorithms In other words, for a point p, its ith coordinate p[i] is close to p[ j] in all other dimensions j = i. Finally, AC contains datasets where point coordinates are anti-correlated. In this case, points that are good in one dimension are bad in one</figDesc><table><row><cell>Name</cell><cell>Description</cell></row><row><cell>STD</cell><cell>Skyline-Based Top-k Dominating Algorithm [24]</cell></row><row><cell>ITD</cell><cell>Optimized version of STD (Sect. 3.2)</cell></row><row><cell>SCG</cell><cell>Simple Counting Guided Algorithm (Sect. 4)</cell></row><row><cell>LCG</cell><cell>Lightweight Counting Guided Algorithm (Sect. 4)</cell></row><row><cell>UBT</cell><cell>Upper-bound Based Traversal Algorithm (Sect. 5)</cell></row><row><cell>CBT</cell><cell>Cost-Based Traversal Algorithm (Sect. 5)</cell></row><row><cell cols="2">Section 8.3 investigates the efficiency of our solutions for</cell></row><row><cell cols="2">processing top-k dominating queries on non-indexed data.</cell></row><row><cell cols="2">Section 8.4 presents the experimental study for the relaxed</cell></row><row><cell cols="2">top-k dominating query.</cell></row><row><cell cols="2">8.1 Experiments with synthetic data</cell></row><row><cell cols="2">Data generation and query parameter values. We produced</cell></row><row><cell cols="2">three categories of synthetic datasets to model different sce-</cell></row><row><cell cols="2">narios, according to the methodology in [2]. UI contains data-</cell></row><row><cell cols="2">sets where point coordinates are random values uniformly</cell></row><row><cell cols="2">and independently generated for different dimensions. CO</cell></row><row><cell cols="2">contains datasets where point coordinates are correlated.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 3</head><label>3</label><figDesc>Range of parameter values</figDesc><table><row><cell>Parameter</cell><cell>Values</cell></row><row><cell>Buffer size (%)</cell><cell>1, 2, 5, 10, 20</cell></row><row><cell>Data size, N (million)</cell><cell>0.25, 0.5, 1, 2, 4</cell></row><row><cell>Data dimensionality, d</cell><cell>2, 3, 4, 5</cell></row><row><cell>Number of results, k</cell><cell>1, 4, 16, 64, 256</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>) causes one tree node access. Since γ rises faster in CBT than in UBT, CBT has higher pruning power and thus terminates earlier. Figure12bplots the size of S (i.e., number of entries in memory) with respect to the number of loops.</figDesc><table><row><cell>2, we intro-</cell></row><row><cell>duced two priority orders for selecting the next non-leaf</cell></row><row><cell>entry to process at PBT: (i) UBT chooses the one with the</cell></row><row><cell>highest upper bound score, and (ii) CBT, among those with</cell></row><row><cell>the highest level, chooses the one with the highest upper</cell></row><row><cell>bound score. Having theoretically justified the superiority of</cell></row><row><cell>CBT over UBT (in Sect. 5.2), we now demonstrate this expe-</cell></row><row><cell>rimentally. For the default top-k dominating query on a UI</cell></row><row><cell>dataset, we record statistics of the two algorithms during their</cell></row><row><cell>execution. Figure 12a shows the value of γ (i.e., the best-k</cell></row><row><cell>score) for both UBT and CBT as the number of loops exe-</cell></row><row><cell>cuted. Note that in UBT/CBT, each loop (i.e., Lines 8-20 of</cell></row><row><cell>Algorithm 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 4</head><label>4</label><figDesc>Query cost vs. k, real datasets</figDesc><table><row><cell>k</cell><cell>T i m e( s )</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>FC</cell><cell></cell><cell></cell><cell cols="2">BASEBALL</cell><cell></cell></row><row><cell></cell><cell>ITD</cell><cell>LCG</cell><cell>CBT</cell><cell>ITD</cell><cell>LCG</cell><cell>CBT</cell></row><row><cell>1</cell><cell>262.3</cell><cell>162.0</cell><cell>62.0</cell><cell>4 .6</cell><cell>13.0</cell><cell>0.9</cell></row><row><cell>4</cell><cell>413.0</cell><cell>166.6</cell><cell>69.7</cell><cell>9 .4</cell><cell>16.5</cell><cell>1.8</cell></row><row><cell>16</cell><cell>814.2</cell><cell>204.2</cell><cell>78.9</cell><cell>2 2 .8</cell><cell>18.4</cell><cell>2.5</cell></row><row><cell>64</cell><cell>2,772.7</cell><cell>282.2</cell><cell>99.4</cell><cell>6 9 .7</cell><cell>22.8</cell><cell>3.5</cell></row><row><cell>256</cell><cell>9,942.1</cell><cell>523.0</cell><cell>176.4</cell><cell>271.1</cell><cell>38.6</cell><cell>5.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 5</head><label>5</label><figDesc>Top-5 dominating players</figDesc><table><row><cell>Score</cell><cell>NBA Player/Year</cell><cell cols="2">gp pts</cell><cell>reb</cell><cell>ast</cell></row><row><cell cols="2">18,585 Wilt Chamberlain/1967</cell><cell cols="4">82 1,992 1,952 702</cell></row><row><cell cols="2">18,299 Billy Cunningham/1972</cell><cell cols="4">84 2,028 1,012 530</cell></row><row><cell cols="2">18,062 Kevin Garnett/2002</cell><cell cols="4">82 1,883 1,102 495</cell></row><row><cell cols="2">18,060 Julius Erving/1974</cell><cell cols="3">84 2,343 914</cell><cell>462</cell></row><row><cell cols="6">17,991 Kareem Abdul-Jabbar/1975 82 2,275 1,383 413</cell></row><row><cell>Score</cell><cell>BASEBALL Pitcher/Year</cell><cell>w</cell><cell>g</cell><cell>sv</cell><cell>so</cell></row><row><cell>34,659</cell><cell>Ed Walsh/1912</cell><cell>27</cell><cell>62</cell><cell>10</cell><cell>254</cell></row><row><cell>34,378</cell><cell>Ed Walsh/1908</cell><cell>40</cell><cell>66</cell><cell>6</cell><cell>269</cell></row><row><cell>34,132</cell><cell>Dick Radatz/1964</cell><cell>16</cell><cell>79</cell><cell>29</cell><cell>181</cell></row><row><cell>33,603</cell><cell>Christy Mathewson/1908</cell><cell>37</cell><cell>56</cell><cell>5</cell><cell>259</cell></row><row><cell>33,426</cell><cell>Lefty Grove/1930</cell><cell>28</cell><cell>50</cell><cell>9</cell><cell>209</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 6</head><label>6</label><figDesc>Candidate size |C| and top-k score γ (k = 16, N = 1 M, d = 3)</figDesc><table><row><cell cols="2">Method UI</cell><cell></cell><cell>CO</cell><cell></cell><cell>AC</cell></row><row><cell></cell><cell>|C|</cell><cell>γ</cell><cell>|C|</cell><cell>γ</cell><cell>|C|</cell><cell>γ</cell></row><row><cell>CRS</cell><cell>616</cell><cell cols="2">669,651 522</cell><cell cols="3">841,191 34,575 10,773</cell></row><row><cell>FNS</cell><cell>411</cell><cell cols="2">821,608 125</cell><cell cols="2">991,319 135</cell><cell>91,530</cell></row><row><cell>FNU</cell><cell>466</cell><cell cols="2">762,140 154</cell><cell cols="2">990,137 2,864</cell><cell>89,452</cell></row><row><cell>FNP</cell><cell>16</cell><cell>960,650</cell><cell>93</cell><cell cols="2">992,488 48</cell><cell>123,315</cell></row><row><cell>Results</cell><cell>16</cell><cell>960,670</cell><cell>16</cell><cell cols="2">994,637 16</cell><cell>123,462</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 7</head><label>7</label><figDesc>Relaxed top-16 dominating players on the NBA miss dataset</figDesc><table><row><cell>τ r rank</cell><cell>Original τ rank</cell><cell>NBA Player/Year</cell></row><row><cell>on NBA miss</cell><cell>on NBA</cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>Billy Cunningham/1972</cell></row><row><cell>2</cell><cell>-</cell><cell>-</cell></row><row><cell>3</cell><cell>4</cell><cell>Julius Erving/1974</cell></row><row><cell>4</cell><cell>7</cell><cell>Kevin Garnett/2004</cell></row><row><cell>5</cell><cell>-</cell><cell>-</cell></row><row><cell>6</cell><cell>6</cell><cell>Don Adams/1975</cell></row><row><cell>7</cell><cell>44</cell><cell>John Havlicek/1970</cell></row><row><cell>8</cell><cell>-</cell><cell>-</cell></row><row><cell>9</cell><cell>9</cell><cell>Julius Erving/1973</cell></row><row><cell>10</cell><cell>-</cell><cell>-</cell></row><row><cell>11</cell><cell>48</cell><cell>Rogera Brown/1969</cell></row><row><cell>12</cell><cell>-</cell><cell>-</cell></row><row><cell>13</cell><cell>12</cell><cell>Larry Bird/1980</cell></row><row><cell>14</cell><cell>62</cell><cell>Billy Cunningham/1969</cell></row><row><cell>15</cell><cell>-</cell><cell>-</cell></row><row><cell>16</cell><cell>59</cell><cell>Kevin Garnett/2001</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>Counting-guided searchThe skyline-based solution becomes inefficient for datasets with large skylines as τ scores of many points are computed.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>Suppose that a point p satisfies τ ( p) ≤ γ . Applying Eq.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>2, if a point p is dominated by p, then we have τ ( p ) &lt; γ .<ref type="bibr" target="#b1">2</ref> Note that F is the skyline of a specific data subset.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>For simplicity, the equation does not consider the boundary effect (i.e., v is near the domain boundary). To capture the boundary effect, we need to bound the terms (1 -v + λ i ) and (1 -v -λ i ) within the range [0, 1].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>The current equation is simplified for readability. The probability equals 0 when λ i + λ j &gt; 1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>Forest cover dataset, UCI KDD Archive. http://kdd.ics.uci.edu.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>NBA Statistics v2.0. http://basketballreference.com.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>The Baseball Archive v5.3. http://baseball1.com/statistics.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This work was supported by grant HKU 7149/07E from Hong Kong RGC.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Efficient distributed skylining for web information systems</title>
		<author>
			<persName><forename type="first">W.-T</forename><surname>Balke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Güntzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>EDBT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The skyline operator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Börzsönyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Alternative algorithm for Hilbert&apos;s space-filling curve</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Butz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput. C</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="424" to="426" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Stratified computation of skylines with partially-ordered domains</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-K</forename><surname>Eng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Finding k-dominant skylines in high dimensional space</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">On high dimensional skylines</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>EDBT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust cardinality and cost estimation for skyline operator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Skyline with presorting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chomicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gryz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PODS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Skyline cardinality for relational processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Godfrey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>FoIKS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Maximal vector computation in large data sets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shipley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gryz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">R-Trees: A dynamic index structure for spatial searching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Guttman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD</title>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distance browsing in spatial databases</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hjaltason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="318" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">PREFER: a system for the efficient execution of multiparametric ranked queries</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hristidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Papakonstantinou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Skyline queries against mobile lightweight devices in MANETs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Shooting stars in the sky: an online algorithm for skyline queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ramsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Progressive approximate aggregate queries with a multi-resolution tree structure</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lazaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">STR: a simple and efficient algorithm for R-Tree packing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Edgington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename></persName>
		</author>
		<title level="m">Supporting ad hoc ranking aggregates</title>
		<imprint>
			<publisher>SIGMOD</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">DADA: a data cube for dominant relationship analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stabbing the sky: efficient skyline computation over sliding windows</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Selecting stars: The k most representative skyline operator</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Efficient OLAP operations in spatial data warehouses</title>
		<author>
			<persName><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>SSTD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Progressive skyline computation in database systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="82" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Computing compressed multidimensional skyline cubes efficiently</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Catching the best views of skyline: a semantic approach based on decisive subspaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards multidimensional subspace skyline analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1335" to="1381" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient progressive skyline computation</title>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-K</forename><surname>Eng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SUBSKY: efficient computation of skylines in subspaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDE</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A model for the prediction of R-tree performance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Theodoridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Sellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PODS</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Efficient processing of top-k dominating queries on multi-dimensional data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mamoulis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Efficient computation of the skyline cube</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
