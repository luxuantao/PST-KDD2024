<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OAG: Toward Linking Large-scale Heterogeneous Entity Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<email>yuxdong@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Peiran</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaotao</forename><surname>Gu</surname></persName>
							<email>xiaotao2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
							<email>kuansan.wang@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<addrLine>{zfj17,liuxiao17, ypr15,j-z16</addrLine>
									<country>China, yan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tsinghua</forename><surname>University</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Microsoft</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bin</forename><surname>Shao</surname></persName>
							<email>binshao@microsoft.com</email>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>11 pages</addrLine>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OAG: Toward Linking Large-scale Heterogeneous Entity Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3292500.3330785</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems → Information integration</term>
					<term>Entity resolution</term>
					<term>Entity Linking, Name Ambiguity, Heterogeneous Networks, OAG</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Linking entities from different sources is a fundamental task in building open knowledge graphs. Despite much research conducted in related fields, the challenges of linking large-scale heterogeneous entity graphs are far from resolved. Employing two billion-scale academic entity graphs (Microsoft Academic Graph and AMiner) as sources for our study, we propose a unified framework -LinKG -to address the problem of building a large-scale linked entity graph. LinKG is coupled with three linking modules, each of which addresses one category of entities. To link word-sequence-based entities (e.g., venues), we present a long short-term memory networkbased method for capturing the dependencies. To link large-scale entities (e.g., papers), we leverage locality-sensitive hashing and convolutional neural networks for scalable and precise linking. To link entities with ambiguity (e.g., authors), we propose heterogeneous graph attention networks to model different types of entities. Our extensive experiments and systematical analysis demonstrate that LinKG can achieve linking accuracy with an F1-score of 0.9510, significantly outperforming the state-of-the-art. LinKG has been deployed to Microsoft Academic Search and AMiner to integrate the two large graphs. We have published the linked results-the Open Academic Graph (OAG) 1 , making it the largest publicly available heterogeneous academic graph to date.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Entity linking, also called ontology alignment and disambiguation <ref type="bibr" target="#b11">[12]</ref>, is the task of determining the identity of entities across different sources. The problem of entity linking is related to entity matching <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b35">36]</ref>, entity resolution <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, web appearance disambiguation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11]</ref>, name identification <ref type="bibr" target="#b15">[16]</ref>, object distinction <ref type="bibr" target="#b36">[37]</ref>, and name disambiguation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40]</ref>, and has been extensively studied for decades by different communities.</p><p>However, despite the bunch of research, the challenges of linking Web-scale heterogeneous entity graphs from different sources are far from resolved. First, the Web-based entity graphs are usually heterogeneous, in the sense that they consist of various types of entities, such as author, paper, and venue entities in academic graphs. Second, it is very common to observe ambiguous entity mentions in entity graphs. For example, there are more than 10,000 authors with the name "James Smith" in Microsoft Academic Graph (MAG) <ref type="bibr" target="#b25">[26]</ref>. Finally, the scale of entity graphs on the Web is usually large, with billions of entities.</p><p>In this work, we employ two academic entity graphs (MAG and AMiner <ref type="bibr" target="#b32">[33]</ref>) to conduct a systematical analysis for the problem of linking large-scale heterogeneous entity graphs. A straightforward method to address this problem is to find the entity alignments using heuristic rules <ref type="bibr" target="#b14">[15]</ref>. However, such an ad-hoc strategy cannot be flexibly generalized to other scenarios. Several efforts have also been made to find the alignments via learning algorithms such as neural networks <ref type="bibr" target="#b16">[17]</ref> and probabilistic frameworks <ref type="bibr" target="#b23">[24]</ref>. However, the complexity of these methods (usually O(n 2 )) is very expensive, making them not scalable for handling large graphs in practice. Additionally, recent works attempt to combine human annotators into the loop of entity linking <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>. Still, these methods are insufficient to handle large heterogeneous graphs. Figure <ref type="figure" target="#fig_0">1</ref> illustrates an example of linking the heterogeneous MAG and AMiner academic graphs. As can be seen, there are 16,392 authors with the name "Jing Zhang" in AMiner and 7,170 in MAG. The entity linking methods must address this inherent ambiguity. In addition, both graphs consist of different types of entities, such as authors, venues, and papers. How to leverage the heterogeneous structure to improve the linking accuracy is largely unexplored. Last, the AMiner graph comprises more than 285,450,905 entities, and MAG covers over 462,112,348 entities. Therefore it is desired to design efficient and scalable techniques to conquer the computational challenge.</p><p>We propose a unified framework-LinKG-to address the above challenges, toward building a large-scale linked entity graph. The framework is coupled with three linking modules, each of which corresponds to one type of entity: venues, papers, and authors. To link venues, which are coarse-grained and word-sequence dependent entities, we customize the long short-term memory networks <ref type="bibr" target="#b9">[10]</ref> (LSTM) to capture the sequential dependency in venue names; To link paper entities, which are relatively less ambiguous but at a very large scale, we present a locality-sensitive hashing <ref type="bibr" target="#b5">[6]</ref> and convolutional neural network <ref type="bibr" target="#b13">[14]</ref> (CNN) based techniques for fast and accurate matching; To link large-scale author entities, which are highly ambiguous, we propose heterogeneous graph attention networks (HGAT). In addition to leveraging information from each graph, we also incorporate the linked venue and paper entities in previous steps into HGAT.</p><p>To summarize, our work makes the following contributions.</p><p>• First, we propose to study the entity linking problem in two largescale heterogeneous entity graphs, in which each type of entity has different properties and thus the linking of them faces different challenges. We develop an effective and efficient framework-LinKG, which leverages state-of-the-art deep neural networks for linking heterogeneous entities. • Second, we conduct large-scale linking experiments between the MAG and AMiner graphs. The results show that our framework can achieve very high accuracy of 0.9926 for linking venue entities, 0.991 for papers, and 0.9741 for authors. We also conduct extensive experiments to demonstrate our design choice of each module in the framework. • Finally, with the linking results, we published the Open Academic Graph (OAG). OAG consists of 0.7 billion entities and 2 billion relationships, making it the largest public academic data to date <ref type="foot" target="#foot_0">2</ref> . The dataset can be used for various research topics, such as network science and graph mining (collaboration and citation), text mining and natural language processing (title and abstract), science of science, computational social science, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we review relevant literature about entity linking. Entity linking, also known as data integration, record linkage etc., is a classical problem which was put forward more than six decades ago <ref type="bibr" target="#b6">[7]</ref>. Some literature reviews can be found in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>There are various approaches to tackle this problem. Li et al. <ref type="bibr" target="#b14">[15]</ref> argue for rule-based methods and develop a rule discovery algorithm. Another important thread of research is based on machine learning algorithms. Tang et al. <ref type="bibr" target="#b30">[31]</ref> regard entity matching as minimizing Bayesian risk of decision making. Some works <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> attempt to use less labeled data and employ semi-supervised or unsupervised matching algorithms. For example, Rong et al. <ref type="bibr" target="#b21">[22]</ref> transfer the entity matching problem to a binary classification problem and use pairwise similarity vectors as training data. Wang et al. <ref type="bibr" target="#b34">[35]</ref> present a factor graph model to learn the alignment across knowledge bases. For data integration across social networks or other networks, some <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b38">39]</ref> incorporate network structure to develop effective algorithms. Zhang et al. <ref type="bibr" target="#b38">[39]</ref> propose COSNET, an energy-based model which considers global and local consistency of multiple networks.</p><p>Recently, network embedding based approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> have been proposed to address the user alignment problem across social networks. For example, Liu et al. <ref type="bibr" target="#b16">[17]</ref> propose an optimization framework to learn user embedding simultaneously across networks, by considering hard and soft constraints. Heimann et al. <ref type="bibr" target="#b8">[9]</ref> propose an embedding-based solution for graph alignment based on the factorization of a user-similarity matrix of two graphs. However, for large-scale graphs, constructing the similarity matrix is very expensive. Similarly, Zhang et al. <ref type="bibr" target="#b37">[38]</ref> propose MEgo2Vec, which employs attention mechanisms and graph neural networks elaborately to match ego networks of two candidate users.</p><p>However, few studies aim to find a unified solution for largescale heterogeneous entity linking. For such a problem, one must consider efficiency, heterogeneity, ambiguity issues. In this paper, we propose a unified framework to deal with these issues. We present a hashing-based method to efficiently find linkings with less ambiguity. We use LSTM to perform fuzzy-sequence linking and CNN to perform fine-grained text matching . Finally, based on results obtained by the aforementioned approaches, we use graph attention networks to perform linking with more ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>In this section, we formalize the problem of entity linking across heterogeneous entity graphs. For example, an academic graph is a heterogeneous entity graph comprises multiple types of entities: authors, papers, and venues. Its relation set D includes 1) the authorship relation between authors and papers, 2) the paper-publish-in-venue relation between papers and venues, 3) the co-authorship relation between authors, and 4) the author-publish-in-venue relation between authors and venues. Problem 3.1. Entity Linking across HEGs. Given two heterogeneous entity graphs HG 1 and HG 2 , the goal is to generate entity linkings L = {(e 1 , e 2 )|e 1 ∈ HG 1 , e 2 ∈ HG 2 } such that e 1 and e 2 represent exactly the same entity in HG 1 and HG 2 .</p><p>In this work, we focus on the problem of entity linking across two heterogeneous academic entity graphs: Microsoft Academic Graph and AMiner, each of which consists of author, paper, and venue entities. The goal is to link these three types of entities for the two large-scale graphs. The proposed approaches are general and can be extended to handle other heterogeneous networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE LINKG FRAMEWORK</head><p>We present a unified framework, LinKG, which is coupled with three modules for linking venue, paper, and author entities, respectively, across the MAG and AMiner heterogeneous graphs. In each module, we present techniques that are capable of addressing the unique challenges in linking each type of entities. Figure <ref type="figure" target="#fig_1">2</ref> illustrates the overview of the LinKG framework.</p><p>(1) Venue linking. The venue entity linking task is formulated as:</p><p>given the full names of venues in each graph, the goal is to connect the same venues from both graphs. Though additional information can be utilized for venue linking, we find that the single usage of venue full names is simple, efficient, and effective. The venue linking module consists of two technical components: venue name matching and sequence encoding empowered by long short-term memory networks. (2) Paper linking. To link paper entities, we fully leverage the heterogeneous information, including a paper's title and publication year, as well as the other two types of entities, i.e., its authors and publication venue. Notice that both graphs contain hundreds of millions of paper entities and billions of relations between papers and their authors. Thus, we propose to leverage 1) the hashing technique (e.g., locality-sensitive hashing) for fast processing and 2) the convolution neural networks for effective linking. (3) Author linking. To link author entities, we generate a heterogeneous subgraph for each author. One author's subgraph is composed of his or her coauthors, papers, and publication venues. Moreover, we incorporate the venue and paper linking results from the first two modules into author linking. This linking task faces not only the scalability issue but also the long-standing challenge of "name disambiguation" <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30]</ref>. To tackle them, we present a heterogeneous graph attention network based technique for linking author entities.</p><p>Due to the different properties of the three types of entities, we design three different neural networks for addressing their associated challenges. Empirical results in Section 5 demonstrate the effectiveness of our design and modeling choices over other alternative methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Linking Venues -Sequence-based Entities</head><p>The first category entity we are going to deal with is word-sequence dependent entity -i.e., venues in the academic graph. Ideally, all attributes associated with venues can be leveraged for linking them across the two graphs, including the venue full name, keywords, and its publications, as well as those publications' authors. However, many journals in the dataset publish millions of papers that are also associated with millions of authors, making it difficult to utilize them straightforwardly and efficiently.</p><p>Furthermore, the keyword attribute also contributes little to the distinction between venues in similar fields. For instance, the two journals 'Diagnostic and interventional imaging' and 'Journal of Diagnostic Imaging and Interventional Radiology' share exactly the same keywords "diagnostic", "interventional", and "imaging", resulting in a very high similarity by using common similarity metrics, such as Jaccard Index.</p><p>Name Matching. More importantly, it turns out that the direct matching between two graphs' venue entities by using their full names and abbreviations can link more than 27,000 venue pairs, corresponding to the majority of the final linking results. The challenging part of this task lies in the remaining venues that cannot be matched directly. In specific, these venues usually have the following characteristics: (1) Word order inversion: The same journal is observed with different word orders in two graphs, such as Journal of Shenzhen University and Shenzhen University Journal.</p><p>(2) Extra or missing prefix or suffix: For many venues, their names contain additional annotations, such as Proceedings of the Second international conference on Advances in social network mining and analysis.</p><p>LSTM. Name matching is not able to handle those venues that cannot be exactly matched. We observe that the relative word or keyword sequences in the full name is generally preserved. Therefore, we propose to model both the Integral Sequence and Keyword Sequence in venue names. Integral Sequence is the raw word sequence from venue names, and Keyword Sequence is derived from the keywords extracted from the Integral Sequence. We present an enhanced long short-term memory networks (LSTM) to address the issues above. Given a venue i in one graph, let u</p><p>i be the input Integral Sequence and v (0) i be the Keyword Sequence, we can have:</p><formula xml:id="formula_1">u (2) i = lstm u2 (lstm u1 (u (0) i )), v<label>(2)</label></formula><formula xml:id="formula_2">i = lstm v2 (lstm v1 (v (0) i )) (1)</formula><p>where lstm denotes the LSTM layers. Then we calculate the differences d i j with venue j from the other graph:</p><formula xml:id="formula_3">d i j (u) = u (2) i − u (2) j , d i j (v) = v (2) i − v (2) j (2)</formula><p>Finally, we concatenate all of them with Jaccard Index (JA i j ) and the number of inversion pairs in Keyword Sequence (IV i j ), and employ fully-connected layers to calculate the similarity between the two venues:</p><formula xml:id="formula_4">s i j = [u (2) i , v (2) i , u (2) j , v (2) j , d i j (u), d i j (v), JA i j , IV i j ] y i j = f c(s i j )<label>(3)</label></formula><p>where f c denotes the fully-connected layers and y is the similarity between venue i and j. In training, we use venues from labeled candidate pairs to learn parameters in the LSTM layers and f c layer; and in matching, we use the learned parameters to predict the similarity between two venues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Linking Papers -Large-scale Entities</head><p>The second category entity is of large-scale. This makes the paper linking problem faces several challenges. First, the overall volume of academic publications at each of the graphs is at the scale of hundreds of millions, requiring efficient linking techniques. Second, it is commonly observed from not only the MAG and AMiner graphs but also the official publishers (such as ACM and IEEE) that paper titles are often truncated if they contain punctuation marks, such as ':' and '?', making the linking task more challenging. Finally, there also exist papers with exactly the same titles even in the same venue in both graphs, such as the two different "robust influence maximization" papers published in KDD 2016, making this task harder and harder.</p><p>To address these challenges, we propose to leverage the hashing technique and convolution neural networks for linking paper entities across the two graphs.</p><p>Locality-sensitive Hashing. If we compare all possible pairs of papers from both sides, the matching complexity is at least O(n 2 ), where n is the number of papers in each graph. To reduce the computational cost, we propose to leverage the hashing technique to match paper entities. Specifically, we use the locality-sensitive hashing (LSH) algorithm, which is widely used for efficient nearest neighbor search.</p><p>An intuitive way to map titles to binary codes is to use word onehot encoding. However, this will make binary representations highdimensional, and mapping them to low-dimensional binary space using LSH is likely to lose information. We adopt Doc2Vec <ref type="bibr" target="#b12">[13]</ref> to first transform titles to low-dimensional real-valued vectors. Then LSH is applied to further map real-valued vectors to binary codes.</p><p>For efficient linking, we directly query the indexed binary codes and obtain uniquely matched papers in O(1) time. We find that recall will get much lower when leveraging other heterogeneous attributes, such as authors, venues. Therefore, we just employ title hashing to deal with easy cases for paper linking.</p><p>Convolution Neural Networks (CNN). LSH can match papers from the large-scale MAG and AMiner graphs efficiently. However, due to its probabilistic nature, the information loss in LSH, e.g., during its randomized projection stage, would result in missing paper candidates. Therefore, we also propose to leverage a more elaborate method, that is, convolution neural networks, to capture fine-grained matching signals for those unlinked papers.</p><p>The CNN based linking strategy consists of three steps: 1) candidate paper pair search; 2) paper similarity matrix construction; 3) CNN-based pairwise similarity learning.</p><p>To avoid n 2 pairs of candidate papers, we employ the inverted index technique based on title keywords to filter candidate paper pairs. We then construct two similarity matrices for each candidate pair, by using their paper titles and authors, respectively, as the input of the CNN model. Each element z (0) i j in the similarity matrix is set to 1 if the i-th word (name initial) and j-th word (name initial) in two paper's titles (authors) are the same, -1 otherwise. Instead of concatenating the two matrices, we model them individually in the first CNN layers. This is because there is no need to measure cross-entity similarities, such as between one paper's title and the For the first layer of CNN, the n-th filter w (1,n) scans over each input similarity matrix z (0) to generate a feature map z (1,n) :</p><formula xml:id="formula_5">z (1,n) x,y = σ ( r n −1 i=0 r n −1 j=0 w (1,n) i, j • z (0) x +i,y+j + θ (1,n) ),<label>(4)</label></formula><p>where r n and θ (1,n) denote the size and the bias of the n-th filter, respectively. Herein, the square filter and ReLU <ref type="bibr" target="#b4">[5]</ref> are adopted. Moreover, multiple filters are used to capture different similarity patterns to deal with the data heterogeneity issue.</p><p>The following layers are convolutional or pooling layers for capturing the higher-order matching features. After flattening the hidden layer matrix to a dense vector and concatenating the two vectors learned from title and author similarity matrices, Multi-Layer Perception (MLP) is used to produce the final matching score. Finally, softmax function is utilized to output the matching probability and cross entropy is used as the objective.</p><p>In our framework, we first leverage locality-sensitive hashing to link easily matched paper pairs. For those papers which can not obtain confident matching results via LSH, we further employ CNN to perform fine-grained linking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Linking Authors -Ambiguous Entities</head><p>In this subsection, we introduce the author linking module, which is more challenging than linking papers and venues, due to the author name ambiguity issue. The good news is that linked entities (i.e., venues and papers) in previous steps can help alleviate this problem. Similar to the paper linking task, it is impractical to link hundreds of millions of authors from two graphs. Therefore, the first step is to generate candidate pairs for authors if they have similar names; Second, for each author in the candidate pair, we construct a heterogeneous ego subgraph, and two ego subgraphs can be connected with each other if they share common venues or papers that have been linked before; Finally, a heterogeneous graph attention network is applied for determining author matching.</p><p>Paired Subgraph Construction. For each author in a candidate pair, its direct (heterogeneous) neighbors are selected, including its coauthors, papers, and venues. The left part of Figure <ref type="figure" target="#fig_4">5</ref> illustrates an example of the construction process. If two authors' papers or venues have been linked in previous steps, we can connect the two authors' subgraphs together. Note that we construct a fixed-size paired subgraph based on collaboration and publication frequencies in order to better feed into graph neural networks. In addition, we also include coauthors' papers and venues for constructing the paired subgraph (i.e. a two-hop ego network).</p><p>Heterogeneous Graph Attention Networks (HGAT). The common neighbors of candidate author pairs (such as papers and venues) could provide evidence for author pair matching. We propose using graph attention networks to combine all the information by aggregating needed pieces of information from neighbors. Next we will introduce pre-training, encoder layers and output layers of this model.</p><p>We pre-train input features for each entity based on both semantic and structure information. For semantic features, we first train a skip-gram word embedding model <ref type="bibr" target="#b18">[19]</ref> for all words on the AMiner publication corpus (including titles, authors, abstracts, etc.) . Then the semantic embedding of each entity is obtained by averaging over its associated words' embeddings. For structure features, we train the LINE model <ref type="bibr" target="#b31">[32]</ref>, due to its simplicity, on a large heterogeneous entity graph (HEG) and get the structural embeddings for each entity. Two types of embeddings are concatenated together as entity input features h to graph attention networks.</p><p>Encoder layers. The encoder is actually multiple graph attention layers <ref type="bibr" target="#b33">[34]</ref>. The goal of graph attention is to learn the attention coefficient attn(e i , e j ), which implies the aggregation weight of source entity e j 's embedding on target entity e i . The attention coefficient is learned by self-attention mechanism, i.e.,</p><formula xml:id="formula_6">o i j = attn(W h i ,W h j )<label>(5)</label></formula><p>where o i j indicates the importance of node e j 's features to node e i , h i is node e i 's input features, and W is a shared projection matrix. By utilizing the subgraph structure, the graph attention layer only needs to compute o i j for nodes e j ∈ N i , where N i is the neighborhood of node e i . Then o i j can be normalized across all possible e j by using softmax function. In this work, the normalized attention coefficient α i j is specified as below:</p><formula xml:id="formula_7">α i j = exp(LeakyReLU(c ⊤ τ (e i ) W h i + c ⊤ τ (e j ) W h j )) k ∈N i exp(LeakyReLU(c ⊤ τ (e i ) W h i + c ⊤ τ (e k ) W h k ))<label>(6)</label></formula><p>where c τ (e i ) denotes the attention parameter vector of entity e i 's type τ (e i ). Note that different from the original GAT <ref type="bibr" target="#b33">[34]</ref>, we use different attention parameters for each type of entities because different types of entities play different roles in author linking. The heterogeneous attention mechanism are plotted in Figure <ref type="figure" target="#fig_4">5</ref>. Then we employ the multi-head attention to generate node e i 's output embedding h ′ i as</p><formula xml:id="formula_8">h ′ i = K k =1 σ ( j ∈N i α k i j W k h j )<label>(7)</label></formula><p>where represents concatenation, σ is the activation function and K is the head number of one layer. In our model, we use two graph attention layers to instantiate the encoder part. Output layers. Passed through the graph encoder, each node has a hidden embedding by aggregating its near neighbors. Let ĥMAG and ĥAMiner denote the embeddings of two focal authors in a candidate pair. We fuse these two embeddings into one vector and then use two fully-connected layers to produce output representation for each pair,</p><formula xml:id="formula_9">y = f c( ĥMAG ⊗ ĥAMiner )<label>(8)</label></formula><p>where f c(•) denotes the fully-connected layers and we choose the element-wise multiplication operator as the vector operation ⊗. Finally, we optimize the negative log-likelihood loss function by comparing the output vectors with ground truths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Further Discussions</head><p>In this section, we use academic entity graphs as the example to explain how the proposed framework LinKG deals with the three challenges: large-scale, heterogeneity, and ambiguity, in our problem. The proposed methods are general and can be also applied to various different heterogeneous entity graphs, for example the heterogeneous social networks <ref type="bibr" target="#b38">[39]</ref>. The method for linking venues can be used to link entities with word-sequence information, while the LSH method for linking papers can be used to link entities of large scale. In case recall is also very important, the combination of LSH and CNN could achieve a better trade-off between efficiency and effectiveness. The method for linking authors leverages the graph structure information and also linking results of the other entities, thus could achieve a high linking accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>We • Dedupe <ref type="bibr" target="#b3">[4]</ref> 3 : This is an open-source toolkit to perform deduplication, record linkage on structured data. Basically, it uses blocking <ref type="bibr" target="#b26">[27]</ref> technique to reduce the number of record comparisons and employs active learning and logistic regression to learn weights of attribute features.</p><p>• COSNET <ref type="bibr" target="#b38">[39]</ref>: This method is a factor graph model which considers user pairwise features as local factors and the relationship between user pairs as correlation factors. An efficient dual decomposition method is developed to optimize original objective. This method is used for author linking problem. • MEgo2Vec <ref type="bibr" target="#b37">[38]</ref>: This method feeds ego networks of two users as inputs, and uses graph neural networks to map the subgraphs to vectors and then predict the labels of user pairs. This method is used for author linking problem. • LinKG C : For each candidate pair, this method first constructs similarity matrices and then use CNN to map these matrices to similarity vectors. Finally, similarity vectors of different attributes are concatenated and passed into fully-connected layers to output matching scores. • LinKG L : In this method, each attribute is treated as a word sequence. The content of each attribute is embedded as vector by LSTM. For each pair, vectors of the same attribute are merged (by concatenation, subtract, etc.) into similarity vectors, which are fed into fully-connected layers to predict labels. • LinKG: Our best model is indicated by LinKG, which uses different methods tailored for different entity linking problems.</p><p>-For venues, LinKG L is our best model. We use LSTM to model venue features as described in Sec. 4.1.</p><p>-For papers, we first leverage LSH to perform fast paper linking, and then use CNN to cope with harder cases which can not matched via LSH (Cf. 4.2). -For authors, the best model is described in Sec. 4.3. We employ heterogeneous graph attention networks on constructed paired subgraphs to generate prediction results. We also introduce some discriminative features (such as paper/venue matching ratio of two authors) to enhance results.</p><p>3 https://github.com/dedupeio/dedupe</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall Results</head><p>Table <ref type="table" target="#tab_0">1</ref> shows the overall linking performance of different methods. Our method (LinKG) consistently outperforms other alternatives (+4.05%-36.87% in terms of F1-score). The overall F1-score is weighted by the number of test samples on different linking problems (i.e. 361, 9234 and 5000 test pairs for venues, papers, authors respectively). Next we compare and analyze results on the linking of venues, papers and authors one by one. For venue linking, LinKG (namely LinKG ) outperforms other methods. Keyword and SVM perform poorly owing to problems mentioned above in Section 4.1, such as word order reversion or mismatched prefix and suffix. LinKG C can also achieve good performance for venue linking, because CNN is capable of capturing word order matching pattern. The advantage of LSTM is that it can capture not only word order information but also coarse-grained information. Besides, compared with CNN, LSTM can process variablesized sequences while CNN cannot.</p><p>For paper linking, LinKG and LinKG C obviously outperform other methods. Dedupe can achieve high precision but has a low recall, which indicates it prefers a high threshold for the classifier. Compared with Keyword and SVM, CNN uses low-level word similarity matrix and can learn fine-grained matching patterns automatically.</p><p>For author linking, our method LinKG, i.e. employing graph attention networks by combining linked venue and paper results, achieves the best performance among other methods. By full name matching, Keyword performs poorly because different authors with the same name are linked incorrectly and the same author is likely to have different name formats. LinKG C and LinKG L take many author attributes, including affiliations, papers, and venues, but perform worse than methods incorporating graph structures, such as COSNET and MEgo2Vec. For COSNET, prediction of an author pair will be influenced by the prediction of their neighbor pairs thus it may suffer from the error propagation problem. Compared with MEgo2Vec, our method uses simpler attention mechanism and is able to distinguish the effects of different types of entities. Furthermore, our method can incorporate the effect of distant neighbors besides direct neighbors while MEgo2Vec can not. Table <ref type="table" target="#tab_1">2</ref> shows the linking results of our model variants. In general, CNN-based methods outperform LSH significantly. LSH can achieve high precision. One possible reason is that the same title will be definitely mapped to the same binary code. Thus, under these circumstances, using hashing can avoid unnecessary computational cost, but will sacrifice recall. For hybrid method LSH+CNN, LSH can speed up the matching process and keep high precision and recall at the same time.</p><p>Efficiency Performance on Paper Linking. Furthermore, we test the efficiency of different methods for paper linking as shown in Table <ref type="table" target="#tab_2">3</ref>. We measure three types of running time: training time, testing time and predicting time. Testing time refers to the total time for test while predicting time focuses on core matching process which ignores some data processing steps since these steps are not the bottleneck of our methods. Predicting time sometimes is longer Contribution Analysis for HGAT on Author Linking. The results in Table <ref type="table" target="#tab_3">4</ref> show the contribution of components of our author linking model. GAT means directly applying original GAT on paired subgraphs and HGAT refers to using different attention mechanisms in GAT for different types of entities. SVM-struct refers to using some structural statistical features, including venue/paper matching ratio of two authors. HGAT-esb1 and HGAT-esb2 are two ensemble methods which add features used in SVM-struct (denoted as f st at ) to HGAT. Specifically, HGAT-esb1 concatenates f st at and output vector h enc of the encoder in HGAT as the final feature vector f cat , and uses the objective of HGAT to train. HGAT-esb2 uses SVM as the classifier and f cat as input features.</p><p>As shown in Table <ref type="table" target="#tab_3">4</ref>, using different attention parameters for different entities is better than treating them equally (0.9% F1-score improvement). Furthermore, the result of HGAT-esb2 is a little bit better than HGAT-esb1, which shows SVM does better here in processing combined features of statistical features and features generated by neural networks. Also, SVM-struct performs well (close to pure GAT), which demonstrates the effectiveness of heterogeneous structure information (venue/paper linking results) for author linking problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Open Academic Graph (OAG)</head><p>Based on our proposed framework, we have published Open Academic Graph (OAG) 1 , which is the largest publicly available heterogeneous academic graph as far as we know.</p><p>In OAG, we generated 91,137,597 paper linking pairs and its accuracy is 99.10%. We also successfully linked 29,841 venue pairs with accuracy of 99.26%. For authors, we only considered authors who published more than five papers since both AMiner and MAG are faced with the under-conflation and the over-conflation problem for author profiles. Finally, there were 6,855,193 authors in AMiner and 13,173,936 authors in MAG. We generated 1,717,680 author pairs and the estimated accuracy is 97.41%. The evaluation was based on a subset of sampled matchings (around one thousand venue/paper/author pairs). OAG has considerable applications. It can be used as a benchmark for studying citation networks, author name disambiguation, paper content, as well as comparing methodologies for data integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we study an important problem of linking large-scale heterogeneous entity graphs. We particularly focus on building a large linked academic entity graph. We propose a unified framework, LinKG, to deal with the linking problem. LinKG is coupled with three linking modules, each of which addresses one category of entities. We evaluated the proposed framework and compared it with several state-of-the-art approaches. Experimental results show that our proposed framework LinKG can achieve a very high linking accuracy with a F1-score of 0.9510, significantly outperforming the states-of-the-arts. LinKG has been deployed to Microsoft Academic Search and AMiner to integrate the two large sources. The linked results have been published as Open Academic Graph (OAG).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Baselines</head><p>A.2.1 Keywords.</p><p>• For venues: we use Python package Scikit-learn 0. • For authors: we simply compare the two name strings to match authors.</p><p>A.2.2 SVM. We use Python package Scikit-learn 0.19.1 to build the SVM model on a macOS 10.14.2 laptop with an Intel Core i5 (2.9GHz) and 16GB RAM.</p><p>• For venues: we calculate the Jaccard Index and Cosine Similarity (using tf-idf values) for each pair, and let them be the two dimensions of the input vector. • For papers: we calculate the character-level n-gram similarity of paper title (n=4), and authors (n=3). • For authors: we calculate the character-level n-gram similarity (here we set n=4) of name, affiliation, top venue name, paper title keywords, and top coauthor name from each candidate pair. Note that paper title keywords are extracted from the first 15 papers in the paperlist of an author. MAG papers are replaced by their matched AMiner papers.</p><p>A.2.3 Dedupe. We use Open Source Dedupe 1.9.4 from Github. We employ the bottom layer interface dedupe.core.scoreDuplicates to obtain pairwise similarity scores between entities.</p><p>• For venues: we simply pass names of training pairs to Dedupe, and use the model to predict on test pairs. • For papers: we pass paper's title, authors' name, venue, year as a dict to Dedupe. • For authors: we pass author's name, affiliation, top venue name, and top coauthor name as a dict to Dedupe. The experiment was conducted on a CentOS server with two Intel Xeon(R) CPU E5-4650 (2.7GHz) and 500G RAM.</p><p>• Code: https://github.com/dedupeio/dedupe</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustrative example of the large-scale heterogeneous entity linking problem. The table above displays the overall 0.7 billion entities in this large-scale graph. The graph in the middle illustrates ambiguity in author linking, where name distinction and affiliation shift exist. At the bottom, node and attribute heterogeneity increase great difficulty in linking.</figDesc><graphic url="image-1.png" coords="2,53.19,83.69,243.78,158.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The architecture of LinKG.</figDesc><graphic url="image-2.png" coords="3,67.62,83.69,212.59,255.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The LSTM model for modeling sequencial dependency in venue full names.</figDesc><graphic url="image-3.png" coords="4,55.29,83.69,243.78,142.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The CNN model for modeling heterogeneous attributes of paper entities.</figDesc><graphic url="image-4.png" coords="5,52.77,83.69,240.93,121.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The heterogeneous graph attention networks for modeling heterogeneous structures around authors. p 1 and p ′ 1 , v 1 and v ′ 1 are conflated as the same entity in previous steps, respectively. The boxes in the right represent the different roles played by heterogeneous entities in author linking, which are captured by different attention mechanisms.</figDesc><graphic url="image-5.png" coords="5,320.09,83.68,238.10,166.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The OAG data set is publicly available.1 The codes and training data are available at https://github.com/zfjsail/OAG. Like venue datasets above, we construct a difficult paper linking dataset. We create two paper sets: clean paper set CP and noisy paper set N P. The goal is to link papers between CP and N P. The clean set contains 46,170 papers extracted from AMiner. The N P dataset is constructed by adding noises to each paper. Thus, each original paper and its corresponding noisy paper become a positive matching pair. The method to add noise is based on differences in existing matched papers, such as different author name formats and missing title words. The negative paper pairs we generate share some common keywords to increase linking difficulty. We use 20% noisy papers for test (to find corresponding matched clean papers). For venues: We use TF-IDF weighted Jaccard index to measure the similarity of two venue names. -For papers: Given a paper p ∈ N P, we use its title keywords to find candidate papers in CP by inverted index table and then re-rank these candidates by edit distance between two titles and character-level similarity of its author names. -For authors: We match two authors if and only if they have exact the same full name.• SVM:-For venues: We use similarity scores of venue integral sequences and keyword sequences as input features. -For papers: We use similarity scores of paper titles and authors as input features. -For authors: We use similarity scores of author names, affiliations, venues, papers and coauthors as input features. For detailed feature definition, please refer to Appendix. A.2.2. Results of linking heterogeneous entity graphs. "-" indicates the method does not support the entity linking.</figDesc><table><row><cell>evaluate our solution in the context of two heterogeneous en-</cell></row><row><cell>tity graphs: MAG and AMiner. Microsoft Academic Graph (MAG)</cell></row><row><cell>consists of 208,915,369 papers, 52,678 venues, 253,144,301 authors</cell></row><row><cell>and so on, which is a snapshot taken in Nov. 2018. AMiner consists</cell></row></table><note>of 172,209,563 papers, 69,397 venues, 113,171,945 authors and so on, which are snapshots taken in July 2018 (for venues and authors) or Jan. 2019 (for papers). Next, we present our main experimental results on venue linking, paper linking and author linking. • Author datasets: We use the following two ways to generate positive author pairs. (1) sample author pairs with unique names and matched papers. (2) sample author pairs both of which are top coauthors (w.r.t. collaboration frequency) of strictly matched author pairs by rules. We use negative pairs which cannot be matched by strict rules but one of which can be matched to some other author by rules. Negative pairs should also have similar names. We construct 10,000 positive pairs and 10,000 negative pairs respectively. The training/validation/test split is 2:1:1. To increase the task difficulty, we also add some noises to the dataset.For example, we mask some authors' affiliations or replace a fraction of authors' papers/venues with random papers/venues.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Paper Linking performance.</figDesc><table><row><cell>Method</cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>LSH</cell><cell>98.72</cell><cell>41.78</cell><cell>58.71</cell></row><row><cell>CNN-</cell><cell>90.84</cell><cell>89.45</cell><cell>90.14</cell></row><row><cell>CNN</cell><cell>96.60</cell><cell>94.55</cell><cell>95.57</cell></row><row><cell>LSH+CNN</cell><cell>96.70</cell><cell>94.70</cell><cell>95.69</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Running time of different methods for paper linking (in second). Variants of Venue Linking. In Table1, LinKG L uses two venue attributes as input, including integral sequences and keyword sequences. We also examine the result of only using integral sequence without additional features, and F1-score is 84.31%. After adding keyword sequences, F1-score can reach 86.76%. It shows that extracting keyword sequence plays an important role in venue linking. By further integrating two additional statistical features, including the number of reverse pairs, Jaccard Index of two venue names, the final F1-score reaches 89.33%.</figDesc><table><row><cell>Method</cell><cell>Train</cell><cell>Test</cell><cell>Predict</cell></row><row><cell>Keyword</cell><cell>-</cell><cell>41.82</cell><cell>41.24</cell></row><row><cell>SVM</cell><cell>30.07</cell><cell>31.62</cell><cell>30.94</cell></row><row><cell>Dedupe</cell><cell cols="3">1.5hrs+ 1109.08 1108.94</cell></row><row><cell>LinKG L</cell><cell cols="3">369.39 1545.24 1496.04</cell></row><row><cell>LSH</cell><cell>461.70</cell><cell>0.56</cell><cell>0.16</cell></row><row><cell>CNN</cell><cell>431.40</cell><cell>164.37</cell><cell>162.32</cell></row><row><cell cols="2">LSH+CNN 893.10</cell><cell>112.86</cell><cell>108.06</cell></row><row><cell cols="3">5.3 Detailed Result Analysis</cell><cell></cell></row><row><cell cols="4">Model Variants of Paper Linking. The variants of our model</cell></row><row><cell cols="4">for paper linking are denoted as follows. (1) the method using</cell></row><row><cell cols="4">locality-sensative hashing is denoted as LSH. (2) methods using</cell></row><row><cell cols="4">CNN: The method only using paper titles to build similarity matrix</cell></row><row><cell cols="4">is denoted as CNN-. Different from CNN-, CNN considers two paper</cell></row><row><cell cols="4">attributes: titles and authors as described in Sec. 4.2. (3) hybrid</cell></row><row><cell cols="4">model: LSH+CNN is a hybrid model of LSH and CNN. It first uses</cell></row><row><cell cols="4">LSH to find matched papers efficiently. For those papers which can</cell></row><row><cell cols="4">not be matched by binary codes, it utilizes CNN for fine-grained</cell></row><row><cell>matching.</cell><cell></cell><cell></cell><cell></cell></row></table><note>Model</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Author Linking results of our model variants. Keyword method doesn't need training and the main time cost lies in string similarity calculation. LSH consumes the shortest predicting time because the complexity of matching is O(n) and binary codes query can be extremely fast. Therefore, LSH is potential to handle large-scale data in an efficient way. The training time of hashing-based methods refers to the time of training Doc2Vec model. In spite of high accuracy, CNNbased method requires constructing similarity matrices and training convolutional neural networks so its computational cost is high. LSH+CNN can leverage LSH to match about 40% papers fast, so it reduces nearly half of the time compared with CNN. Time cost of Dedupe is also high because its blocking strategy takes a lot of training time.</figDesc><table><row><cell>Method</cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>SVM-struct</cell><cell>89.12</cell><cell>96.17</cell><cell>92.51</cell></row><row><cell>GAT</cell><cell>92.26</cell><cell>93.28</cell><cell>92.77</cell></row><row><cell>HGAT</cell><cell>93.39</cell><cell>93.96</cell><cell>93.67</cell></row><row><cell>HGAT-esb1</cell><cell>93.70</cell><cell>94.75</cell><cell>94.22</cell></row><row><cell>HGAT-esb2</cell><cell>95.37</cell><cell>93.48</cell><cell>94.42</cell></row><row><cell cols="4">than training time because each paper needs to compare itself</cell></row><row><cell cols="2">with all candidate pairs.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>19.1 to build word-frequency matrix and calculate tf-idf value for each venue name. The corpus is consisted of all the appeared words in the training and testing datasets. Then we leverage Cosine Similarity implemented in numpy by ourselves to calculate the pairwise similarity. • For papers: in CP, we use the first γ words in paper titles to build inverted index table. Given a paper p ∈ N P, we use its titles to find candidate papers in CP by inverted index table and then re-rank these candidates by edit distance between titles and authors' similarity. For authors' similarity, we concatenate authors' name as a string and then calculate similarity in terms of character co-occurrence, i.e. SIM aut hor s (a 1 , a 2 ) = char s_co_occur (a 1 ,a 2 ) max(#char s(a 1 ),#char s(a 2 ))</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">The dataset has been downloaded more than 40,000 times over the past months (until 2019-02-03).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Jie Tang is the corresponding author of this paper. The work is supported by the NSFC for Distinguished Young Scholar (61825602) and NSFC (61836013), and a research fund supported by MSRA. Xiao Liu is supported by Tsinghua University Initiative Scientific Research Program and DCST Student Academic Training Program.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDICES A.1 Implementation Notes</head><p>A.1.1 LSTM for venue linking. In LinKG experiment, we build the LSTM model using Python package Keras 2.2.4. Empirically, we set the following parameters: training epochs=20, batch size=32.</p><p>We set the maximum length of integral/keyword sequence as 17/8. The embedding size of word in all sequences is 128. We use 2 LSTM layers: hidden layer size=32, dropout=0.2 and 3 Dense layers: hidden size = 64, 16, 1 Furthermore, we stack the jaccard index 32 times, number of inversion pairs 16 times to become the input vector JA i j and IV i j .This aims at enhancing their weights in the network.</p><p>We employ cross-entropy as our loss function and nadam as optimizer. All codes are implemented in Python3 and run by intepreter Python3. In terms of Graph Attention networks, we employ 2 multihead graph attention layer in it. Their parameters are as follows:</p><p>(1) Multihead graph attention layer 1: input size=1433, output size=8, n_head=8 (2) Multihead graph attention layer 2: input size=64, output =7, n_head=1</p><p>(3) Fully-connected layer 1: input length=7, output length=21 (4) Fully-connected layer 2: input length=21, output length=7 (5) Fully-connected layer 3: input length=7, output length=2</p><p>We employ Adam as our optimizer. All the HGAT codes are implemented in Python3 package Pytorch 1.0.0, and the experiment was conducted on a Ubuntu server with four Intel Xeon(R) CPU E5-2699 (2.7GHz), 256G RAM and an Nvidia Titan X(Pascal) GPU and 12G GPU RAM.</p><p>• Code: https://github.com/zfjsail/OAG/. This part of the code refers to the implementation in <ref type="bibr" target="#b20">[21]</ref>.</p><p>A.2.4 COSNET <ref type="bibr" target="#b38">[39]</ref> . We download the authors' source codes, which were written in C++. The author provides 4 samples and 5 input options to choose. We maintain the original settings as before, and examine the 4 samples. Finally we choose to generate data in the form of imdb_re f ined.dat, which contains both the pairwise shared keywords and relations between candidate pairs. In terms of the 5 options: <ref type="bibr" target="#b0">(1)</ref> training dataset: here we choose our own datasest. (2) labeling rate [0-5]: the higher rate is, the better training result will be. After tuning, we find the combination of labeling rate <ref type="bibr" target="#b4">[5]</ref>, reservoir size <ref type="bibr" target="#b3">[4]</ref>, query method[0], sampling method[0] could reach the best testing F1, and we report it in our experiment section.</p><p>This experiment was conducted on a macOS 10.14.2 laptop with an Intel Core i5 (2.9GHz) and 16GB RAM. The C++ compiler is clang-1000.11.45.5.</p><p>• Code: https://www.aminer.cn/cosnet A.2.5 MEgo2Vec <ref type="bibr" target="#b37">[38]</ref>. We download the original codes, and keep all the training settings as the same. MEgo2Vec needs two parts of input: one is attributes of a candidate pair, another is probably correct neighbor pair of a candidate pair, which is determined by name matching. Therefore, on one hand, we pass author's name, affiliation, top venue name and top coauthor name to MEgo2Vec. On the other hand, we perform a rough matching around the candidate pair, and extract neighbor pairs. We make some changes in codes to better evaluate this model:</p><p>(1) The codes were originally written in Python2. We fix a few grammar mistakes and turn codes into Python3. (2) There is no test part in the original codes, and we copy the validation part in the original codes and complete the test part. We run the model on a CentOS server with two Intel Xeon(R) CPU E5-4650 (2.7GHz) and 500G RAM.</p><p>• Code: https://github.com/BoChen-Daniel/MEgo2Vec-Embedding-Matched-Ego-Networks-for-User-Alignment-Across-Social-Networks</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Dataset</head><p>A.3.1 Venue Dataset. Initially, we performed a rough name matching using Jaccard Index with threshold of 0.4 on the original AMiner and MAG venue sets, generating 3344 pairs(1557 MAG venues, 3344 AMiner venues). We randomly selected 548 MAG venues, and generated 1202 candidate pairs for training. We labeled them manually as our ground truths.</p><p>This Venue Dataset is difficult, because candidate pairs with the same MAG venue often share a number of keywords, leading to high similarity in most of text similarity methods. This dataset will be published with our model codes.</p><p>A.3.2 Paper Dataset. we create two paper sets: clean paper sets CP and noisy paper sets N P. The first dataset is collected by extracting 46,170 papers from AMiner. Each paper contains 4 attributes: title, authors, venue and year. Another dataset is constructed by adding noise to each paper. Thus, each original paper and its corresponding noisy paper become a matching pair, which avoids the labeling cost of human labors. The method to add noise is based on our statistics of differences in existing matched papers. For example, some words in title are wrongly concatenated and authors' names have different formats, such as full name and abbreviated name. The two paper sets form one-to-one positive matching pairs. The negative paper pairs we generate share some common keywords to increase linking difficulty.</p><p>A.3.3 Author Dataset. At first, we conducted very strict rule methods on AMiner and MAG authors datasets to generate ground-truth linkings, including affiliation matching rate, venue matching rate and paper matching rate. Furthermore, we utilize the generated linked authors' coauthors to match more authors.</p><p>Since our groundtruth is generated by rules, it might be a little bit easy for Author Linking task. Therefore, we implemented the following two methods to harden this dataset:</p><p>(1) Add name ambiguity: for an already linked author entity, we searched for authors with the same name, and generated negative candidate pairs. (2) Add noisy data: we randomly replace some attributes of generated positive pairs, including affiliations, venues and papers. This author dataset contains 10,000 positive candidate pairs and 10,000 negative candidate pairs. It will also be published with our model codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Discussions</head><p>It's difficult to obtain a "ground truth" for entity linking evaluation. In this paper, we manually label venue training data and construct artificial difficult training data for papers and venues. In the future, more ground truths may be obtained via crowd-sourced data management.</p><p>In this work, we first link relatively easy entities (i.e. venues and papers) and then link authors with more ambiguity. How to link large-scale different types of entities in a joint framework is also a challenge.</p><p>Furthermore, for author linking, we only consider authors with not less than 5 papers for both sides. This is because, due to the name ambiguity problem, both AMiner and MAG are facing with the under-conflation and the over-conflation problem for author profiles. Therefore, how to improve author name disambiguation performance by leveraging current disambiguation results and linked entities is also an important challenge.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Disambiguating Web Appearances of People in a Social Network</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Bekkerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;05</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="463" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Swoosh: a generic approach to entity resolution</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Benjelloun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Menestrina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">Euijong</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="255" to="276" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Collective entity resolution in relational data</title>
		<author>
			<persName><forename type="first">Indrajit</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learnable Similarity Functions and their Applications to Clustering and Record Linkage</title>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Bilenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;04</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="981" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Improving deep neural networks for LVCSR using rectified linear units and dropout</title>
		<author>
			<persName><forename type="first">Tara</forename><forename type="middle">N</forename><surname>George E Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><surname>Hinton</surname></persName>
		</author>
		<idno>ICASSP&apos;13. 8609-8613</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Localitysensitive hashing scheme based on p-stable distributions</title>
		<author>
			<persName><forename type="first">Mayur</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><surname>Vahab</surname></persName>
		</author>
		<author>
			<persName><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SCG&apos;04</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Duplicate record detection: A survey</title>
		<author>
			<persName><forename type="first">Panagiotis</forename><forename type="middle">G</forename><surname>Ahmed K Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><surname>Vassilios</surname></persName>
		</author>
		<author>
			<persName><surname>Verykios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two Supervised Learning Approaches for Name Disambiguation in Author Citations</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kostas</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JCDL&apos;04</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="296" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Regal: Representation learning-based graph alignment</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoming</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><surname>Safavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Grape: A graph-based framework for disambiguating people appearances in web search</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lian</forename><surname>Li</surname></persName>
		</author>
		<idno>ICDM&apos;09. 199-208</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The impact of named entity normalization on information retrieval for question answering</title>
		<author>
			<persName><forename type="first">Alam</forename><surname>Mahboob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName><surname>De Rijke</surname></persName>
		</author>
		<idno>ECIR&apos;08. 705-710</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rule-Based method for entity resolution</title>
		<author>
			<persName><forename type="first">Lingli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="250" to="263" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identification and tracing of ambiguous names: Discriminative and generative approaches</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Morie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;04</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="419" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Aligning Users across Social Networks Using Network Embedding</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">K</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lejian</forename><surname>Liao</surname></persName>
		</author>
		<idno>IJCAI. 1774-1780</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Predict Anchor Links across Social Networks via an Embedding Approach</title>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Tong Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenghua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1823" to="1829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Entity linking meets word sense disambiguation: a unified approach</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="244" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deepinf: Social influence prediction with deep learning</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2110" to="2119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A machine learning approach for instance matching based on similarity metrics</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haofen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<idno>ISWC&apos;12. 460-475</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Interactive deduplication using active learning</title>
		<author>
			<persName><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anuradha</forename><surname>Bhamidipaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;02</title>
				<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="269" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A probabilistic model for linking named entities in web text with heterogeneous information networks</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD&apos;14</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1199" to="1210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Entity linking with a knowledge base: Issues, techniques, and solutions</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An overview of microsoft academic service (mas) and applications</title>
		<author>
			<persName><forename type="first">Arnab</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darrin</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo-June Paul</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Comparison of Blocking Methods for Record Linkage</title>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">C</forename><surname>Steorts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">L</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><surname>Sadinle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PSD&apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="253" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mining heterogeneous information networks: a structural analysis approach</title>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Sigkdd Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mapping Users across Networks by Manifold Alignment on Hypergraph</title>
		<author>
			<persName><forename type="first">Shulong</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyu</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuzhen</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="159" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Unified Probabilistic Framework for Name Disambiguation in Digital Library</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C M</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using Bayesian decision for ontology mapping</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bangyong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kehong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="243" to="262" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Arnet-Miner: Extraction and Mining of Academic Social Networks</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graph Attention Networks. ICLR</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cross-lingual knowledge linking across wiki knowledge bases</title>
		<author>
			<persName><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhigang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;12</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="459" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Entity Matching Across Heterogeneous Sources</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1395" to="1404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Object distinction: Distinguishing objects with identical names</title>
		<author>
			<persName><forename type="first">Xiaoxin</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE&apos;07</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1242" to="1246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">MEgo2Vec: Embedding Matched Ego Networks for User Alignment Across Social Networks</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengmei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guojie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="327" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">COSNET: Connecting Heterogeneous Social Networks with Local and Global Consistency</title>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1485" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop</title>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1002" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Hike: A hybrid human-machine method for entity alignment in large-scale knowledge bases</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuojian</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhua</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1917" to="1926" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
