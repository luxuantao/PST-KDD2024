<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Abnormal Detection Using Interaction Energy Potentials</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xinyi</forename><surname>Cui</surname></persName>
							<email>xycui@cs.rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingshan</forename><surname>Liu</surname></persName>
							<email>qsliu@cs.rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mingchen</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Abnormal Detection Using Interaction Energy Potentials</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B5A99524257595D63AE0125C3980764F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A new method is proposed to detect abnormal behaviors in human group activities. This approach effectively models group activities based on social behavior analysis. Different from previous work that uses independent local features, our method explores the relationships between the current behavior state of a subject and its actions. An interaction energy potential function is proposed to represent the current behavior state of a subject, and velocity is used as its actions. Our method does not depend on human detection or segmentation, so it is robust to detection errors. Instead, tracked spatio-temporal interest points are able to provide a good estimation of modeling group interaction. SVM is used to find abnormal events. We evaluate our algorithm in two datasets: UMN and BEHAVE. Experimental results show its promising performance against the state-of-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Abnormal event detection plays an important role in video surveillance and smart camera systems. Various abnormal activities have been studied, including restrictedarea access detection <ref type="bibr" target="#b8">[9]</ref>, car counting <ref type="bibr" target="#b5">[6]</ref>, detection of people carrying cases <ref type="bibr" target="#b6">[7]</ref>, abandoned objects <ref type="bibr" target="#b21">[22]</ref>, group activity detection <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b16">17]</ref>, social network modeling <ref type="bibr" target="#b28">[29]</ref>, monitoring vehicles <ref type="bibr" target="#b27">[28]</ref>, scene analysis <ref type="bibr" target="#b23">[24]</ref> and so on. In this paper, we focus on modeling abnormal events in human group activities, which is a very important application for video surveillance. Fig. <ref type="figure" target="#fig_0">1</ref> shows two sample frames. (a) shows a group of people fighting in the street, and (b) shows people running away from the scenes.</p><p>We propose a new method to detect abnormal events in group activities. We represent group activities by learning relationships between the current behavior state of a subject and its actions. Our goal is to explore the reasons why people take different actions under different situations.</p><p>In the real world, people are driven by their goals. They take into account of the environment as well as the influence of other people. We define an interaction energy potential function to represent the current state of a subject based on the positions/velocities of a subject itself as well as its neighbors. Fig. <ref type="figure" target="#fig_2">2</ref> shows an example of interaction energy potentials and velocities. Section 2 gives the details of the definition. Social behaviors are captured by the relationship between interaction energy potential and its action, which is then used to describe social behaviors. Uncommon Energy-Action patterns indicate an abnormal activity. Experiments on two datasets UMN <ref type="bibr" target="#b0">[1]</ref> and BEHAVE <ref type="bibr" target="#b1">[2]</ref> show that our method is powerful to model abnormal behaviors in group activities.</p><p>Our contributions. 1) The Interaction Energy Potential is proposed to model the relationship among a group of people. 2) The relationship between the current state of a subject and the corresponding reaction is explored to model the normal/abnormal patterns. 3) Our method does not rely on human detection or segmentation technique, so it is more robust to the errors that are introduced by detectoin/segmentation techniques. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work</head><p>Human action/activity modeling in video sequences is a hot topic in the communities of computer vision and pattern recognition. In recent years, a lot of algorithms have  been proposed to improve interest point detection <ref type="bibr" target="#b15">[16]</ref>, local spatio-temporal descriptors <ref type="bibr" target="#b9">[10]</ref>, building relationships among local features <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b14">15]</ref>. Most of the algorithms focus on single action with one person <ref type="bibr" target="#b19">[20]</ref>(hand-waving, running...) or pair-wise action recognition (answer phone <ref type="bibr" target="#b9">[10]</ref>, horse riding <ref type="bibr" target="#b10">[11]</ref>). These works do not consider interactions among multiple people. For most of the surveillance systems in public area, it is also important to identify group activities. Events like fighting or escaping often involve multiple people and their interactions.</p><p>Several algorithms for group activity modeling have been proposed in recent years. Different features are used for group activity: human body/body parts <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref>, optical flow <ref type="bibr" target="#b3">[4]</ref> and detecting moving regions <ref type="bibr" target="#b25">[26]</ref>. Recently, Zhou et al. <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr">Ni et al. et al. [17]</ref> use trajectory analysis to describe different group activities.</p><p>Modeling social behaviors of people is an important branch to represent group activity, and it has been widely used in evacuation dynamics, traffic analysis and graphics. Pedestrian behaviors have been studied from a crowd perspective, with macroscopic models for crowd density and velocity. On the other end, microscopic models deal with individual pedestrians. A popular model is the Social Force Model <ref type="bibr" target="#b7">[8]</ref>. In the Social Force Model, pedestrians react to energy potentials caused by other pedestrians and static obstacles through a repulsive force, while trying to keep a desired speed and motion direction. Helbing et al. in <ref type="bibr" target="#b7">[8]</ref> originally introduce it to investigate people movement dynamics. It is also applied to the simulation of crowd behavior <ref type="bibr" target="#b29">[30]</ref>, virtual reality and studies in computer graphics for creating realistic animations of the crowd <ref type="bibr" target="#b24">[25]</ref>.</p><p>Social behavior analysis has also attracted much attention in the computer vision community. Ali and Shah <ref type="bibr" target="#b2">[3]</ref> use the cellular automaton model to track in extremely crowded situations. Antonini et al. <ref type="bibr" target="#b4">[5]</ref> propose a variant of Discrete Choice Model to build a probability distribution over pedestrian positions in next time step. Scovanner and Tappen <ref type="bibr" target="#b20">[21]</ref> learns pedestrians' dynamics and motions as a continuous optimization problem. Pellegrini et al. <ref type="bibr" target="#b17">[18]</ref> propose a Linear Trajectory Avoidance (LTA) method to track multiple targets. Predictions of velocities are computed by the minimization of energy potentials. Recently, Mehran et al. <ref type="bibr" target="#b13">[14]</ref> propose a method to model behaviors among a group of people. It represents the abnormal patterns in a local region based on moving particles. Wu et al. <ref type="bibr" target="#b26">[27]</ref> uses chaotic invariants of Lagrangian Particle Trajectories to model abnormal patterns in crowded scenes. They have been successfully used in crowded scene modeling.</p><p>Different from the above work, our method is based on the relationship between the current state of a person and his/her reactions. It fully utilizes the information of interaction energy potential and the corresponding people's reactions, which contains comprehensive information to model abnormal behavior among a group of people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>We propose a new method to model group interactions for abnormal detection using interaction energy potentials. The framework is summarized in Fig. <ref type="figure" target="#fig_3">3</ref>. We first extract spatio-temporal interest points and track them. Second, an interaction energy potential is calculated for each point. Third, features are represented by relationships among interaction energy potentials and corresponding actions with a coding scheme. Finally, SVM is used to detect abnormal events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Interest Point Detection and Tracking</head><p>The ideal case for human activity analysis is to track all the subjects and estimate their positions and velocities, but human detection and tracking is still a challenging problem. Instead we use local interest points to represent subjects in a scene. The movements of subjects can be represented by the movements of interests points associated with the subjects, and interactions among the subjects can be implicitly embodied in the interactions among interest points. We use the method proposed in <ref type="bibr" target="#b9">[10]</ref> to detect the local spatio-temporal interest points (STIP), and then use the KLT tracker <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15]</ref> to track interest points. Fig. <ref type="figure" target="#fig_2">2</ref> shows an example of interest point detection and tracking.</p><p>For each tracked interest point p i , we record its positions {x 0 i ...x t i ...}, where each x t is a 2D vector, and its velocity v t i at time t is calculated by</p><formula xml:id="formula_0">v t i = x t+T i -x t i T (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where T is the time interval. A point p i is then modeled as  which implicitly represent interactions among subjects in group activities. Interactions among subjects are modeled by interaction energy potentials, which is addressed in the following section. </p><formula xml:id="formula_2">p i = (x t i , v t i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Interaction Energy Potentials</head><p>Given a set of interest points S = {p i } (i = 1...n), energy potential E i of p i is calculated based on positions and velocities of its neighbor points. The calculation of the interaction energy potentials is inspired by the idea of social behaviors <ref type="bibr" target="#b17">[18]</ref>: assuming that people are aware of the positions and velocities of other people at time t. Thus we can make a reasonable assumption that people can predict the movement of other people and have a general estimation about whether they would meet in the near future. This is also how people walk in the real world.</p><p>We first consider two subjects. Given two subjects s i and s j in a scene, we are now thinking from the perspective of s i , and treating s j as its neighbor. We define the current time as t = 0 and use x i = x 0 i for simplicity. If s i proceeds with velocity v i , then it expects to have a distance d 2 ij (t) from s j at time t.</p><formula xml:id="formula_3">d 2 ij (t) = ||x i + tv i -(x j + tv j )|| 2<label>(2)</label></formula><p>Minimal distance d ij occurs at the time of closest point t * , where t * = max{0, arg min</p><formula xml:id="formula_4">d 2 ij (t)}<label>(3)</label></formula><p>where arg min d 2 ij (t) can be obtained by setting the derivative of d ij to zero with respect to time t. Then we obtain t * as follows:</p><formula xml:id="formula_5">t * = max{0, - (x i -x j ) • (v i -v j ) ||v i -v j || 2 } (4)</formula><p>By substituting t into Eq. 2, we can obtain the minimum distance d * 2 ij between subjects i and j as</p><formula xml:id="formula_6">d * 2 ij = d 2 ij (t * ). d * 2</formula><p>ij defines how far two subjects will meet based on the current velocities. If d * 2  ij is smaller than a distance threshold d c , a close-distance meet would happen in the near future. If p j has a close-distance from p i , p j is very likely to draw p i 's attention at this moment. We therefore build an interaction energy potential function based on their distance</p><formula xml:id="formula_7">E ij = w c ij w φ ij exp(- d 2 ij (t) 2σ 2 d )<label>(5)</label></formula><formula xml:id="formula_8">w c ij = 1 d * 2 ij &lt; d c 0 otherwise (<label>6</label></formula><formula xml:id="formula_9">)</formula><formula xml:id="formula_10">w φ ij = 1 φ ij &lt; φ view 0 otherwise (7)</formula><p>where σ d is the radius of influence of p j . The closer of p j , the higher attention would p i have. φ is the current angular displacement of p j from the perspective of p i . φ view is the field-of-view, which is the angle displacement between the current moving direction and the neighbor point direction.</p><p>As people only see things in the front, φ view controls how people see things. The Interaction energy potential E ij describes the influence from p j . E ij is high when they are close, and it is minimal as their distance goes to infinity.</p><p>For the case of multiple subjects, the influence of all the other subjects can be modeled as an average of energy potential E ik . The overall interaction energy for subject p i is given by</p><formula xml:id="formula_11">E i = 1 N k =i,E ik &gt;0 E ik (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where N is the number of non-zero neighbor points. The Interaction energy potential E i describes the current behavior state of subject p i . Fig. <ref type="figure" target="#fig_4">4</ref> shows an example of 5 points with their interaction energy potentials. Now we are taking perspective of subject p 1 , with 4 neighboring points in the frame. p 1 is moving towards p 2 and p 3 . As they are going to meet based on the current velocities, p 2 and p 3 have a high influence on p 1 . p 4 is in the back, so p 1 does not see it. p 5 moves further away from p 1 , so it does not draw p 1 's attention at this moment. The total interaction energy potential of p 1 comes from p 2 and p 3 . Next we take perspective of p 5 . It moves away from all the other points, so its neighbors would not influence it at this time. It results in a low interaction energy value for p 5 . The Energy potential is calculated for each subject from its own view. Then energy values are denoted by color in the figure. Yellow dot in Fig. <ref type="figure" target="#fig_4">4</ref> shows a high energy value, while red dot shows a low energy value. In our method, E is calculated for each point. Fig. <ref type="figure" target="#fig_2">2</ref> shows an example of detected points and corresponding interaction energy potentials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Features Representation and Classification</head><p>The Interaction energy potential reflects the current interaction with the surrounding of a person. Different from <ref type="bibr" target="#b17">[18]</ref>, our goal is to find reasons why people take actions and what situations make them take actions. This can be modeled by relationships between current states (interaction energy potential E) and actions (velocities v).</p><p>Fig. <ref type="figure" target="#fig_6">5</ref> shows an example of the relationship between energy changing and velocity changing over time. In Fig. <ref type="figure" target="#fig_6">5,</ref><ref type="figure">(a</ref>) is a group of people meeting. Color lines show energy changing through time. We choose one point and its trajectory for analysis. (b) shows its energy changing over time. As people move closer, the energy increases slowly. At the same time, v m , Δv d and Δv m remain stable. They are shown in (c)(d)(e) respectively. This is a common event in the real world. People have their desires to meet, and they try to remain at a constant speed and direction. In contrast, (f) shows a group of people fighting. At time 10, Δv d changes dramatically (shown in (i)) even with low interaction energy potential (shown in (g)). This indicates an uncommon pattern. A point changes its moving direction dramatically without an obvious reason.</p><p>Each local patch around the salient points is represented by Interaction energy potentials and optical flows. Then standard bag-of-words method is used. Each video clip is represented by a bag-of-word representation. SVM is used to find the abnormal activities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>We test our algorithm on two datasets: UMN dataset <ref type="bibr" target="#b0">[1]</ref> and BEHAVE dataset <ref type="bibr" target="#b1">[2]</ref>. Details are shown in the following sessions.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The UMN Dataset</head><p>This dataset is collected from University of Minnesota <ref type="bibr" target="#b0">[1]</ref>, which contains videos of 11 different scenarios of an escape event. The videos are shot in 3 different scenes, including both indoor and outdoor. Each video clip starts with an initial part of normal behaviors and ends with sequences of abnormal behaviors. Fig. <ref type="figure" target="#fig_5">6</ref> shows some sample frames. Scenes in this dataset are crowded, with about 20 people walking around. We follow the same setup as in <ref type="bibr" target="#b13">[14]</ref>.</p><p>As in <ref type="bibr" target="#b13">[14]</ref>, we take optical flow features as the baseline. Fig. <ref type="figure" target="#fig_8">7</ref> reports the experimental results. The results of Social Force, Optical Flow are directly obtained from their papers <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>. The results show that our algorithm is competitive with these state-of-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The BEHAVE Dataset</head><p>To further demonstrate the effectiveness of our method, we conduct experiments on another dataset: the BEHAVE Dataset. We collect an abnormal activity dataset from the BEHAVE dataset <ref type="bibr" target="#b1">[2]</ref>. The BEHAVE dataset has many complex group activities, including meeting, splitting up, standing, walking together, ignoring each other, fighting, escaping as well as running. Scenarios contain various number of participants. The dataset consists of 50 clips of fighting events, and 271 normal events. Some samples are shown in Fig. <ref type="figure" target="#fig_9">8</ref>. All the activities in this dataset are common in the real world. The scene is moderately crowded. In our experiments, the average number of interest points is 43 in each video clip. The length of tracked interest points are 27.81 frames in average.</p><p>We compare our method with the optical flow based method and Mehran et al.'s method <ref type="bibr" target="#b13">[14]</ref>. Fig. <ref type="figure" target="#fig_10">9</ref> shows our results comparing to these two methods. It shows that our  Interaction Energy Potential does a better job to represent abnormal events in such complex group activities. It comes from the fact that our feature does not only consider the velocity distribution, but also utilizes the interaction among a group, which is able to improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We proposed a method to detect abnormal events in group activities. In our algorithm, we explored the reasons why people take actions and what situations make people take actions. The relationships between the current be-havior states and actions indicate normal/abnormal patterns. Pedestrians' environment is modeled by an interaction energy potential function. Abnormal activities are indicated in uncommon energy-velocity patterns. Our method does not depend on human detection or tracking algorithm. We conducted the experiments on the UMN dataset and the BEHAVE dataset. Results showed the effectiveness of our method, and it is competitive with the state-of-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Abnormal event examples. (a) a group of people fighting; (b) People are panic, trying to run away from the scene.</figDesc><graphic coords="1,315.07,480.91,112.60,84.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Interaction energy potentials of two sample frames. Green arrow is the velocity; round dot denotes energy values. Red dot shows a low energy value and blue shows a high value.</figDesc><graphic coords="2,57.91,76.77,112.60,84.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Flow chart: given an input clip, keypoint detection and tracking is performed first, then Interaction Energy Potential is calculated. After wrapping up with feature represention, SVM is used to find abnormal events.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Toy examples. Five subjects, with their current velocities. Color denotes energy values. Red color denotes a low interaction energy potential value, while yellow denotes a high energy value. Taking perspective of subject 1, it has interactions with subject 2 and 3; ignores subject 4 subject and moves away from subject 5.</figDesc><graphic coords="3,96.53,370.76,145.94,110.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The UMN Dataset. Left column: samples from the normal events; Right column: samples from the abnormal events</figDesc><graphic coords="4,434.37,558.18,120.86,90.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Two events. (a)group meeting event; (b) energy E of meeting; (c) velocity magnitude vm of meeting; (d) velocity direction changing Δv d of meeting; (e) velocity magnitude changing Δv d of meeting; (f)fighting event; (g) energy E of fighting; (h) velocity magnitude vm of fighting; (i) velocity direction changing Δv d of fighting; (j) velocity magnitude changing Δv d of fighting.</figDesc><graphic coords="5,163.44,531.02,133.80,100.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Results of abnormal detection in the UMN Dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. The BEHAVE dataset. Top row: samples from the normal events; bottom row: samples from the abnormal events: fighting</figDesc><graphic coords="6,430.75,162.93,118.61,88.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Results on BEHAVE abnormal dataset. Comparison of our method (green line) with Social Force<ref type="bibr" target="#b13">[14]</ref> and Optical Flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Besides the self-representation of velocity, we also take into account of neighbor interest points,</figDesc><table><row><cell>Input Video Clips</cell><cell></cell><cell></cell><cell>Normal/Abnormal</cell></row><row><cell>KeyPoints Detection and Tracking</cell><cell>Interaction Energy Potential Calculations</cell><cell>Feature Representation</cell><cell>SVM</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://mha.cs.umn.edu/Movies/Crowd-Activity-All.avi.3161" />
		<title level="m">Unusual Crowd Activity Dataset</title>
		<imprint>
			<biblScope unit="volume">3164</biblScope>
			<biblScope unit="page">3166</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://homepages.inf.ed.ac.uk/rbf/BEHAVE/.3161" />
		<title level="m">BEHAVE</title>
		<imprint>
			<biblScope unit="volume">3164</biblScope>
			<biblScope unit="page">3166</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Floor fields for tracking in high density crowd scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modelling crowd scenes for event detection</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blunsden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Behavioral priors for detection and tracking of pedestrians in video sequences</title>
		<author>
			<persName><forename type="first">G</forename><surname>Antonini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bierlaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Thiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. IJCV</title>
		<imprint>
			<biblScope unit="page">3162</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image segmentation in video sequences: A probabilistic approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UAI</title>
		<meeting>UAI</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page">3161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Haritaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<title level="m">Realtime surveillance of people and their activities. Trans. PAMI</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">3161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="page">3162</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Motion detection and estimation. Handbook of Image and Video Processing, 2nd Edition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Konrad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">3161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning realistic human actions from movies</title>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marszałek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rozenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recognizing realistic actions from videos &apos;in the wild</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Event detection and from video streams</title>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brémond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hongeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. PAMI</title>
		<imprint>
			<biblScope unit="page">3162</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">3162</biblScope>
			<biblScope unit="page">3166</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Activity recognition using the velocity histories of tracked keypoints</title>
		<author>
			<persName><forename type="first">R</forename><surname>Messing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comparison of affine region detectors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schaffalitzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. IJCV</title>
		<imprint>
			<biblScope unit="page">3162</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recognizing human group activities with localized causalities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kassim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">3161</biblScope>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">3162</biblScope>
			<biblScope unit="page">3164</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using circular statistics for trajectory shape analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recognizing human actions: A local svm approach</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schuldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning pedestrian dynamics from the real world</title>
		<author>
			<persName><forename type="first">P</forename><surname>Scovanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Detecting abandoned luggage items in a public space</title>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Quelhas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gatica-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PETS</title>
		<imprint>
			<biblScope unit="page">3161</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical spatio-temporal context modeling for action recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Cheong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Functional scene element recognition for video scene analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Swears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hoogs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WMVC</title>
		<imprint>
			<biblScope unit="page">3161</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Treuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Popovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Continuum crowds</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A scalable approach to activity recognition based on object use</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Osuntogun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Chaotic invariants of Lagrangian particle trajectories for anomaly detection in crowded scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3162</biblScope>
			<biblScope unit="page">3166</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Motion pattern interpretation and detection for tracking moving vehicles in airborne video</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">3161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Monitoring, recognizing and discovering social networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krahnstoever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">3161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling crowd turbulence by many-particle simulations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="page">3162</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pair-activity classification by bi-trajectories analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">3161</biblScope>
			<biblScope unit="page">3162</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
