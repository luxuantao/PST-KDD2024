<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systemwide Energy Minimization in Real-Time Embedded Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-05">May, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ravindra</forename><surname>Jejurikar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Embedded Computer Systems</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>92697-3425</postCode>
									<settlement>Irvine Irvine</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Rajesh</forename><surname>Gupta</surname></persName>
							<email>gupta@cs.ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Embedded Computer Systems</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>92697-3425</postCode>
									<settlement>Irvine Irvine</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Systemwide Energy Minimization in Real-Time Embedded Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-05">May, 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">B7E847D2044D370E58DEF52968B327A4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditionally, dynamic voltage scaling (DVS) techniques have focused on minimizing the processor power consumption as opposed to the entire system energy. However, the slowdown resulting from DVS can increase the energy consumption of components like memory and network interfaces. Furthermore, leakage power consumption, which is increasing with the scaling device technology, must also be considered. In this paper, we present an algorithm to compute task slowdown factors based on the contribution of the processor leakage and standby energy consumption of the resources in the system. We combine slowdown with procrastination of task executions to extend sleep intervals which significantly reduces the leakage energy consumption. We show that the scheduling approach minimizes the total static and dynamic energy consumption of the systemwide resources. In this work, we consider a real-time system model using the Earliest Deadline First (EDF) policy. Our simulation experiments using randomly generated task sets show on an average 10% energy gains over traditional dynamic voltage scaling. Our procrastination scheme increases the average energy savings to 15%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Power management is of primary importance in the operation of embedded systems, which can be attributed to longer battery life, reliability and packaging costs. There are two primary ways to reduce power consumption in computing systems: (1) resource shutdown, commonly known as dynamic power management (DPM) and (2) resource slowdown, also known as dynamic voltage scaling (DVS). Resources such as memory banks, disk drives, displays and network interfaces possess shutdown capability and DPM techniques have been proposed to minimize the power consumption of these resources <ref type="bibr" target="#b3">[7,</ref><ref type="bibr" target="#b6">11,</ref><ref type="bibr" target="#b20">25]</ref>. Recent processors support slowdown and DVS techniques are known to be more effective in reducing the processor energy consumption <ref type="bibr" target="#b1">[5,</ref><ref type="bibr" target="#b19">24]</ref>. DVS techniques exploit an energy-delay tradeoff that arises due to the quadratic relationship between voltage and power whereas a linear relationship between voltage and delay (frequency). Note that DVS decreases the energy consumption at the cost of increased execution time. The longer execution time while decreasing the dynamic power consumption of the processor, can increase the energy contribution of other components for the following reasons:</p><p>The standby leakage currents are increasing with the advances of CMOS technology and a five fold increase in the leakage power is predicted with each technology generation <ref type="bibr" target="#b2">[6]</ref>. Longer execution time implies more leakage power.</p><p>A minimum power consumption is associated in keeping the processor active. Some of the major contributors are the PLL circuitry, which drives up to 200mA current <ref type="bibr">[10,</ref><ref type="bibr" target="#b22">27]</ref> and the I/O and analog components of the processor. Note that the I/O and analog components require higher voltage levels (2.5V to 3.3V) that are not scaled with DVS. Only the processor core voltage (V dd ) [10] is scaled under DVS.</p><p>If components such as memory and other I/O interfaces need to be active (on state) along with the processor, slowdown can increase the total energy consumption of the system.</p><p>Components such as memory banks, flash drives, co-processor (DSP, FPU, codecs), FPGA components, analog interfaces and wired /wireless communication devices are pervasive in modern embedded systems. Most of these resources support multiple shutdown-states for energy minimization. Due to the energy and delay costs of state transitions, the shutdown decisions have to be judiciously made to meet the system requirements. This results in the device operating in the standby state (on-state but idle) where significant power is consumed. Memory modules are present in almost all computing systems with DRAMs and RDRAMs having standby current in the range of 30mA to 120mA [2, 3]. These devices have operating voltages in the range of 1:8V to 3:3V , and can consume up to 0:36W of power. SRAM modules have still higher standby currents of the order of 150mA to 250mA. The standby power consumption of devices such as flash drives and wireless interfaces is up to 0:5W [1] and 1:4W <ref type="bibr" target="#b0">[4]</ref> respectively. Other components like FPGAs, co-processors and codecs also consume significant power based on their functionality. The resource standby time is related to the program execution and can increase with DVS (slowdown). With compiler assisted DPM techniques <ref type="bibr" target="#b3">[7]</ref>, standby time increases proportionally to the execution time. Thus DVS techniques need to consider the standby power consumption of the peripherals devices in the computation of slowdown factor to reduce the total power consumption of the system.</p><p>Most of the works on DVS consider the energy consumption of the processor in isolation. Earlier works have addressed minimizing the dynamic power consumption of the processor <ref type="bibr" target="#b1">[5,</ref><ref type="bibr" target="#b19">24]</ref>, whereas later works have focussed on leakage to minimize the total static and dynamic power consumption <ref type="bibr" target="#b16">[21,</ref><ref type="bibr" target="#b23">28,</ref><ref type="bibr" target="#b9">14]</ref>. Slowdown tradeoffs in the computation and communication subsystems are considered in <ref type="bibr" target="#b12">[17,</ref><ref type="bibr" target="#b15">20]</ref>. Recent works have also considered the combined processor and memory energy consumption. Fan et al. <ref type="bibr" target="#b4">[8]</ref> consider memory power consumption to show that excess slowdown can increase the total energy consumption. Miyoshi et al. <ref type="bibr" target="#b17">[22]</ref> show that the slowdown decision can differ with different processor families. Various shutdown policies for resources such as memory, disks and wireless cards have been studied <ref type="bibr" target="#b3">[7,</ref><ref type="bibr" target="#b6">11,</ref><ref type="bibr" target="#b20">25]</ref>.</p><p>While most of the work on DVS is focussed on minimizing the processor power consumption, the standby power is usually ignored. It is observed that devices like memory banks are in the active state 30% ,90% of the task execution time <ref type="bibr" target="#b3">[7]</ref>. With the steady increase in the amount of data which is often distributed, the network and disk activity increases and so is the standby time of these devices. We take into account the standby power consumption of the resources used by tasks to compute energy efficient task slowdown factors. Given the resource usage and the resource standby time for the tasks, we propose an algorithm to compute task slowdown factors to minimize the total energy. We enhance our technique with procrastination scheduling which further reduces the processor leakage contribution by extending the processor sleep intervals. Procrastination in real-time systems was first proposed by Lee et al. <ref type="bibr" target="#b11">[16]</ref>, however they assume all tasks are executed at the maximum speed. We have combined slowdown and procrastination scheduling in our earlier works <ref type="bibr" target="#b8">[13]</ref>. We have proposed a better procrastination algorithm that guarantees all deadlines under the EDF scheduling policy. The algorithm has been extended to fixed priority scheduling in <ref type="bibr" target="#b7">[12]</ref>.</p><p>The rest of the paper is organized as follows: Section 2 introduces the system model and formulates the problem. In Section 3, we present the computation of slowdown factors and procrastination intervals under the EDF scheduling policy. The processor power model is discussed in Section 4 and the experimental results are discussed in Section 5. Finally, Section 6 concludes the paper with future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Model</head><p>A task set of n periodic real time tasks is represented as Γ = fτ 1 ; :::; τ n g. A 3-tuple fT i ; D i ; C i g is used to represent each task τ i , where T i is the period of the task, D i is the relative deadline and C i is the worst case execution time (WCET) of the task at the maximum processor speed. In this work, we assume task deadlines are equal to the period (D i = T i ) and the tasks are scheduled by the EDF scheduling policy <ref type="bibr" target="#b13">[18]</ref>. All tasks are assumed to be independent and preemptive. The tasks are to be scheduled on a single processor system based on a preemptive scheduling policy. We say a task is procrastinated (or delayed) if the processor remains idle despite the presence of the task in the processor ready queue. The procrastination interval of a task is the time interval by which a task is procrastinated.</p><p>Similar to recent processors such as Intel XScale [10] and Transmeta Crusoe <ref type="bibr" target="#b22">[27]</ref>, the processor support variable voltage and frequency levels. There are s available frequencies, ff 1 ; :::; f s g in increasing order of frequency and the corresponding voltage levels are fv 1 ; :::; v s g. A slowdown factor (η i ) is defined as the normalized operating frequency i.e. the ratio of the current frequency to the maximum frequency, f s , of the processor. The important point to note is when the frequency is changed to f k , the voltage level is also proportionately set to v k . The power consumption of the processor at a slowdown of η is represented as PCPU; η. Since processors support discrete frequency levels, the slowdown factors are discrete points f 1 f s ; f s f s ; :::; 1 in the range [0,1]. The processor supports shutdown to reduce the leakage power consumption. The processor is said to be idle if it is not executing a task. In the idle state, the processor could in the shutdown state (no leakage) or in the standby state (active + idle) when it consumes leakage power. The slowdown factor assigned to task τ i is represented as η i . When task τ i is assigned a slowdown factor f k f s , the task slowdown factor is represented by η k i to make the assignment explicit when required. We assume that the overhead incurred in changing the processor speed is incorporated in the task execution time. This overhead, similar to the context switch overhead, is constant and can be incorporated in the worst case execution time of a task. We note that the same assumption is made in previous works <ref type="bibr" target="#b1">[5,</ref><ref type="bibr" target="#b19">24]</ref>.</p><p>In addition to the processor, the system has a set of m resources R = fR 1 ; :::; R m g that model the peripheral devices. The resource is said to be in the standby state if it is on (active) but idle. The standby state power consumption of each resource R i is given by PR i and the shutdown power of the resource is assumed to be zero. The power consumed in performing the resource functionality is independent of the task slowdown and not considered in our analysis. Each task τ i uses a subset of the resources in R , represented by R τ i . Despite the use of DPM policies, the resources are in a standby state for a significant portion of time. We assume that the device standby time for each task is expressed in number of processor cycles. Since the device activities are related to the program execution the standby time is expected to be represented in terms of processor cycles. This is particularly true for compiler directed DPM. Though the standby time can potentially vary with slowdown under OS directed DPM, we assume that the number of cycles a resource is in standby state is independent of slowdown. Let C R j i be the number of cycles resource R j is in the standby stand during the execution of τ i . If a task does not use resource R j , then C R j i = 0. We compute the task slowdown factors that minimize the total system energy including the resource standby contribution. Note that we are not proposing DPM policies, but considering the standby energy in computing static slowdown factors. In our work, we consider task level slowdown factors as opposed to intra-task level slowdown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Low power scheduling</head><p>Considering the contribution of the processor leakage power and the resource standby power, the slowest speed need not be the optimal slowdown factor. The energy consumption of a task τ i at speed η is given by :</p><formula xml:id="formula_0">E i η = C i η PCPU; η + ∑ R j 2R τ i C R j i η PR j (1)</formula><p>The slowdown factor for a task that minimizes its total energy consumption is called the critical speed for the task. Based on the the EDF scheduling policy, a task-set of n independent periodic tasks is feasible at a slowdown factor of η i for task τ i if the utilization under slowdown is no more than unity. Thus we have an optimization problem:</p><formula xml:id="formula_1">minimize : n ∑ i=1 1 T i E i η i (2)</formula><p>sub ject to :</p><formula xml:id="formula_2">n ∑ i=1 1 η i C i T i 1 ( 3 ) 8 i : η i 2 f f k f s jk = 1; :::; sg (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Slowdown Algorithm</head><p>While we do not know the time complexity of problem to compute the optimal task slowdown factors, we present a heuristic algorithm to compute energy efficient slowdown factors. The proposed heuristic is motivated by the algorithm in <ref type="bibr" target="#b18">[23]</ref>. The algorithm consists of two phases : (1) computing the critical speed for each task (2) Increasing the task slowdown factors if the task set is not feasible. We compute the energy consumption of each task at each discrete slowdown factors and the critical speed is the slowdown factor that minimizes the task energy. Due to different resource usages of task, the critical speed can differ for each task. In the second step, we present a heuristic to select a task whose speed is increased. The candidate tasks for speedup are the tasks that do not have the maximum speed. Given η k i is the current slowdown of a candidate task τ i , the next higher slowdown factor is represented by η k+1 i . Among all candidate tasks, we increase the slowdown of a task that results in the minimum energy increase per unit time. For each candidate task τ i , we compute the increase in energy consumption, ∆E i , and the time gained by the speedup, ∆t i , where</p><formula xml:id="formula_3">∆E i = E i η k+1 i , E i η k i and ∆t i = C i 1 η k i , 1 η k+1 i .</formula><p>The slowdown factor (speed) of the candidate task with the minimum value of ∆E i ∆t i is increased. The same heuristic is used in <ref type="bibr" target="#b18">[23]</ref> to increase the task slowdown factor. The pseudo-code for the algorithm is given in Figure <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Computing Slowdown Factors</head><p>1: Compute the critical speed for each task; 2: Initialize η i to critical speed of τ i ; 3: while ( not feasible) do 4:</p><p>Let τ m be task satisfying:</p><p>5:</p><p>(a) η m is not the maximum speed;</p><p>6:</p><p>(b) ∆E m ∆t m is minimum;</p><p>7:</p><p>Increase speed of task τ m ; 8: end while 9: return slowdown factors η i ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Procrastination Algorithm</head><p>Task procrastination <ref type="bibr" target="#b11">[16]</ref>  <ref type="bibr" target="#b8">[13]</ref> has been shown to increase the sleep intervals and thereby reduce the energy consumption of idle intervals. Task procrastination is increasingly important as the device leakage currents is rapidly increasing. We use the procrastination algorithm proposed in our earlier work <ref type="bibr" target="#b8">[13]</ref>. A maximum procrastination interval Z i is computed for each task τ i as given by Theorem 1. The procrastination algorithm ensures that no task is procrastinated more than its Z i . Task executions are procrastinated only when the processor is in the sleep state. It is assumed that the power manager that handles task procrastination is implemented as a controller. When the processor enters sleep state, it hands over the control to the power manager (controller), which handles all the interrupts and task arrivals while the processor is in sleep state. The controller has a timer to wake the processor after a specified time period. The procrastination algorithm is shown in Figure <ref type="figure">2</ref>. When the processor is in sleep state and the first task τ i arrives, the timer is set to Z i . The timer counts down every clock cycle. If another task arrives before the timer expires, the timer is adjusted based on the new task arrival. When another task τ j arrives, the timer is updated to the minimum of the current timer value and Z j . This ensures that no task in the system is procrastinated by more than its maximum procrastination interval. When the timer counts down to zero (expires), the processor is woken up and the scheduler dispatches the highest priority task in the system for execution. All tasks are scheduled at their assigned slowdown factor.</p><p>Algorithm 2 Procrastination Algorithm <ref type="bibr" target="#b8">[13]</ref> 1 14: timer --; fCounts down every clock cycleg Theorem 1 Given tasks are ordered in non-decreasing order of their period, the procrastination algorithm guarantees all task deadlines if the procrastination interval Z i of each task τ i satisfies:</p><formula xml:id="formula_4">8i i = 1; :::; n Z i T i + i ∑ k=1 1 η k C k T k 1 ( 5 ) 8 k i Z k Z i (6)</formula><p>The details of the proof are given in the technical report <ref type="bibr" target="#b21">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Processor Power Model</head><p>In this section, we describe the power model used to compute the static and dynamic components of power consumption of CMOS circuits. The dynamic power consumption P AC of CMOS circuits is given by,</p><formula xml:id="formula_5">P AC = C e f f V 2 dd f (7)</formula><p>where V dd is the supply voltage, f is the operating frequency and C e f f is the effective switching capacitance. The major contributors of leakage are the subthreshold leakage and the reverse bias junction current. We use the power model and the technology parameters described by Martin et al. <ref type="bibr" target="#b16">[21]</ref>.</p><p>The subthreshold current I subn , as a function of the supply voltage V dd and the body bias voltage V bs is given below :</p><formula xml:id="formula_6">I subn = K 3 e K 4 V dd e K 5 V bs (<label>8</label></formula><formula xml:id="formula_7">)</formula><p>where K 3 , K 4 and K 5 are constant fitting parameters. The leakage power dissipation per device due to subthreshold leakage I subn and reverse bias junction current I j is given by, P DC = V dd I subn + jV bs jI j <ref type="bibr" target="#b5">(9)</ref> and the total leakage power consumption is L g P DC , where L g is the number of devices in the circuit. The relation of threshold voltage V th and V bs is represented by, V th = V th1 , K 1 V dd , K 2 V bs where K 1 , K 2 and V th1 are technology constants. The cycle time t inv as a function of the V dd and the threshold voltage V th is given by,</p><formula xml:id="formula_8">t inv = L d K 6 V dd ,V th α (10)</formula><p>The technology constants for the 70nm technology given in <ref type="bibr" target="#b16">[21]</ref> are used. The value for C e f f based on the Transmeta Crusoe processor, scaled to 70nm are used. To reduce the leakage substantially, we use V bs = ,0:7V. The static and dynamic power consumption as the supply voltage is varied in the range of 0:5V and 1:0V is shown in Figure <ref type="figure">1</ref>.</p><p>In addition to the gate level leakage, there is an inherent cost in keeping the processor on. This intrinsic cost (power) of keeping the system on is referred to as P on . The power consumption of these components will scale with technology and architectural improvement and we assume a conservative value of P on = 0:1W.</p><p>We define the processor critical speed as the operating point that minimizes the energy consumption per cycle. Figure <ref type="figure">2</ref> shows the energy consumption per cycle for the 70nm technology. It is seen From the power model that the processor critical speed is at V dd = 0:70V . From the voltage frequency relation described in Equation 10, V dd = 0:7V corresponds to a frequency of 1:26 GHz. The maximum frequency at V dd = 1:0V is 3:1 GHz, resulting in a critical slowdown of η crit = 1:26=3:1 = 0:41.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Shutdown Overhead</head><p>In previous work, the overhead of processor shutdown/wakeup has been neglected or considered only as the actual time and energy consumption incurred within the processor. However, a processor shutdown and wakeup has a higher overhead. When switched to the deepest sleep mode, the processor loses its register and cache contents. Thus the cost of shutdown and wakeup includes additional costs as follows : (1) inherent energy delay cost of processor wakeup (2) saving registers to main memory (3) flushing dirty data cache lines to main memory (4) extra misses on a cold start (empty structures) in components such as data / instruction caches, translation look aside buffers (TLBs) and branch target buffers (BTBs), which are empty on wakeup. This results in extra memory accesses and thereby an additional energy overhead.</p><p>We estimate the energy overhead due to shutdown which we use in our simulations. Typical embedded processors such as the Intel PXA family processors have typically cache sizes of 32KB. Assuming 20% P DC is the leakage power, P AC is the dynamic power and P on is the intrinsic power consumption in on state lines of the data cache to be dirty before shutdown results in 6554 memory writes. With an energy cost of 13nJ <ref type="bibr" target="#b10">[15]</ref> per memory write, the cost of flushing the data cache is computed as 85µJ. On wakeup, there is an additional cost due to cache miss. Note that a context switch occurs when a task resumes execution which has its own cache miss penalty. However, shutdown has its own additional cost than a regular context switch due to the fact that these structures are empty. We assume 10% additional misses rate in both the instruction and data cache. Therefore, the total overhead of bringing the processor to active mode is 6554 cache misses. A cost of 15nJ <ref type="bibr" target="#b10">[15]</ref> per memory access, results in 98µJ overhead.</p><p>Adding the cache energy overhead to the energy of charging the circuit logic (300µJ), the total cost is 85 + 98 + 300 = 483µJ . Due to the cost of shutdown, we have to make a decision whether to shutdown or not. An unforeseen shutdown can result in extra energy and/or missing task deadlines. Based on the idle power consumption, we can compute the minimum idle period, referred to as the idle threshold interval t threshold , to break even with the wakeup energy overhead. Since the idle power consumption in our power model is 240mW , and the shutdown energy overhead is 483µJ, t threshold is 2:01ms. We assume a sleep state power of 50µW , which can account for the power consumption in the sleep state and that of the controller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We implemented the different scheduling techniques using a discrete event simulator. To evaluate the effectiveness of our scheduling techniques, we consider several task sets, each containing up to  20 randomly generated tasks. We note that such randomly generated tasks are a common validation methodology in previous works <ref type="bibr" target="#b11">[16,</ref><ref type="bibr" target="#b19">24,</ref><ref type="bibr" target="#b5">9]</ref>. Based on real life task sets <ref type="bibr" target="#b14">[19]</ref>, tasks are assigned a random period in the range [10 ms,120 ms]. An initial utilization u i of each task is uniformly assigned in the range [0.05, 0.5]. The Worst Case Execution Times (WCET) for each task is set to u i T i at the maximum processor speed. The execution time of each task is scaled to ensure a processor utilization less than one, thereby making the task set feasible. The tasks are scheduled on a single processor system. In addition to the processor, the system has three resources with standby power consumption of 0:2W, 0:4W and 1:0W . These are typical standby power consumption for memory, flash drives and 802.11 wireless interfaces and represent these resources. The typical standby time for the resources as a percentage of the task execution time is assumed to be in the range <ref type="bibr" target="#b15">[20,</ref><ref type="bibr">60]</ref>, <ref type="bibr">[10,</ref><ref type="bibr" target="#b20">25]</ref> and <ref type="bibr" target="#b1">[5,</ref><ref type="bibr" target="#b15">20]</ref> respectively. While the usage of network interfaces widely vary based on the applications, we assume conservative standby time. Note that our techniques will result in increased gains with larger resource standby intervals. Each task is assumed to use minimum one (memory) and maximum all resources and the standby time is uniformly assigned in the corresponding ranges. The wireless interface (1.0W) is assigned to a task only if the task uses all resources.</p><p>All tasks are assumed to execute up to their WCET. Experiments were performed on various task sets and the average results are presented. We use the processor power model described in Section 4 to compare the energy consumption of the following techniques :</p><p>No DVS (no-DVS): where all tasks are executed at maximum processor speed.</p><p>Traditional Dynamic Voltage Scaling (DVS) : where tasks are assigned the minimum possible slowdown factor. Critical Speed DVS (CS-DVS): where task slowdown factors are computed based on the algorithm presented in Section 3. Critical Speed DVS with Procrastination (CS-DVS-P): This is the Critical Speed DVS (CS-DVS) slowdown with the procrastination technique under EDF scheduling policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Energy Consumption</head><p>Figure <ref type="figure" target="#fig_1">3</ref> shows the energy consumption of the techniques normalized to no-DVS scheme. We refer the processor utilization at maximum speed as U and is shown along the X-axis with the energy consumption along the Y-axis. With the resource standby time in the specified range, the resources consume around 10% of the total energy in our experimental setup. Traditional DVS scheme does not consider the resource standby time and no-DVS and DVS schemes have similar energy consumption at higher values of U (80% to 100%). With the processor consuming the majority of the energy, DVS leads to energy gains at U drops below 80%. At lower utilization however, traditional DVS scheme results in increased processor leakage as well as longer resource standby time and consumes more energy. As U drops below 40%, the energy consumed by DVS increases and even surpasses no-DVS at very low values of U. CS-DVS computes task slowdown factors considering the resource standby power consumption and saves at least 5% to 10% over the traditional DVS. The CS-DVS technique executes each task no slower than its critical speed and shuts down the system to minimize energy consumption. However if the idle intervals are not sufficient to shutdown, significant energy savings cannot be achieved (over DVS) as seen at utilization of 30% and 40%. It is seen that the procrastination scheme results in more energy saving from this point. As the utilization lowers, executing tasks by the CS-DVS scheme results in idle intervals in the system and the idle energy consumption contributes to a significant portion of the total energy. The procrastination scheme (CS-DVS-P) clusters task executions thereby increasing the sleep intervals and achieves more energy savings. CS-DVS-P minimizes the idle energy consumption to result on an average 15% energy savings over the CS-DVS scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this paper, we have presented a scheduling algorithm that consider the contributions of processor leakage and resource standby energy to minimize the total energy consumption in a system. We show that executing at the maximum or minimum processor speed need not be the optimal operating point. Detailed power models of the resources are important in computing the optimal operating point. Incorporating the resource usage patterns and their power models is increasingly important as systems are getting diverse with more resources contributing to the total energy consumption. Our experimental results show that computing the critical execution speeds for tasks results on an average 10% energy savings. The procrastination scheme increases the average energy savings to 15% by extending the sleep intervals thereby controlling leakage power consumption. Such a scheduling framework will result in an energy efficient operation of the system while meeting all timing requirements. We plan to extend these techniques to scheduling multiple resources with DVS capability and their effects on system wide DPM policies. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Energy consumption normalized to no-DVS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Figure 2. Energy per Cycle for 70nm technology for the Crusoe processor: E AC is the switching energy, E DC is the leakage energy and E on is the intrinsic energy to keep the processor on.</figDesc><table><row><cell>E AC E DC E on E total</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Energy per Cycle</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>.55</cell><cell>0.6</cell><cell>0.65</cell><cell>0.7</cell><cell>0.75</cell><cell>0.8</cell><cell>0.85</cell><cell>0.9</cell><cell>0.95</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>V dd</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Power consumption and energy efficiency comparisons of wlan products</title>
		<ptr target="http://www.atheros.com/pt/papers.html" />
	</analytic>
	<monogr>
		<title level="m">Atheros White Papers</title>
		<imprint>
			<publisher>Atheros Communications</publisher>
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Determining optimal processor speeds for periodic real-time tasks with different power characteristics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Aydin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Melhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mossé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroMicro Conference on Real-Time Systems</title>
		<meeting>EuroMicro Conference on Real-Time Systems</meeting>
		<imprint>
			<date type="published" when="2001-06">Jun. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Design challenges of technology scaling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Micro</title>
		<imprint>
			<date type="published" when="1999-08">Aug 1999</date>
			<biblScope unit="page" from="23" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hardware and software techniques for controlling dram power modes</title>
		<author>
			<persName><forename type="first">V</forename><surname>Delaluz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vijaykrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1154" to="1173" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The synergy between power-aware memory systems and processor voltage</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Power-Aware Computing Systems</title>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Minimizing memory utilization of real-time task sets in single and multi-processor systems-on-a-chip</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lipari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Natale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Real-Time Systems Symposium</title>
		<meeting>IEEE Real-Time Systems Symposium</meeting>
		<imprint>
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Online strategies for dynamic power management in systems with multiple power-saving states</title>
		<author>
			<persName><forename type="first">S</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. on Embedded Computing Sys</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="325" to="346" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Procrastination scheduling in fixed priority real-time systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jejurikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Language Compilers and Tools for Embedded Systems</title>
		<meeting>Language Compilers and Tools for Embedded Systems</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Leakage aware dynamic voltage scaling for real-time embedded systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jejurikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Design Automation Conference</title>
		<meeting>the Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Combined dynamic voltage scaling and adaptive body biasing for heterogeneous distributed real-time embedded systems</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K J L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Aided Design</title>
		<meeting>International Conference on Computer Aided Design</meeting>
		<imprint>
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Energy-aware memory allocation in heterogeneous non-volatile memory systems</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Low Power Electronics and Design</title>
		<meeting>International Symposium on Low Power Electronics and Design</meeting>
		<imprint>
			<date type="published" when="2003-08">Aug. 2003</date>
			<biblScope unit="page" from="420" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scheduling techniques for reducing leakage power in hard real-time systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In EcuroMicro Conf. on Real Time Systems</title>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Communication speed selection for embedded systems with networked voltage-scalable processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bagherzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings pf International Symposium on Hardware/Software Codesign</title>
		<meeting>pf International Symposium on Hardware/Software Codesign</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Real-Time Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W S</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Building a predictable avionics platform in ada: a case study</title>
		<author>
			<persName><forename type="first">C</forename><surname>Locke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mesler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Real-Time Systems Symposium</title>
		<meeting>IEEE Real-Time Systems Symposium</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simultaneous dynamic voltage scaling of processors and communication links in real-time distributed embedded systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Peh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Design Automation and Test in Europe</title>
		<meeting>Design Automation and Test in Europe</meeting>
		<imprint>
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combined dynamic voltage scaling and adaptive body biasing for lower power microprocessors under dynamic workloads</title>
		<author>
			<persName><forename type="first">S</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Flautner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blaauw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Aided Design</title>
		<meeting>International Conference on Computer Aided Design</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Critical power slope: Understanding the runtime effects of frequency scaling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Miyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lefurgy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Hensbergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajamony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Supercomputing</title>
		<meeting>International Conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2002-06">Jun. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Maximizing the system value while satisfying time and energy constraints</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Melhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Real-Time Systems Symposium</title>
		<meeting>IEEE Real-Time Systems Symposium</meeting>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Power optimization of real-time embedded systems on variable speed processors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sakurai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Aided Design</title>
		<meeting>International Conference on Computer Aided Design</meeting>
		<imprint>
			<date type="published" when="2000-11">Nov. 2000</date>
			<biblScope unit="page" from="365" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic power management for portable systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Simunic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Glynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th annual international conference on Mobile computing and networking</title>
		<meeting>the 6th annual international conference on Mobile computing and networking</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Skipped for Blind Review</title>
		<imprint>
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<ptr target="http://www.transmeta.com/technology" />
	</analytic>
	<monogr>
		<title level="j">Transmeta Crusoe Processor. Transmeta Inc</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compiler support for reducing leakage energy consumption</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vijaykrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Design Automation and Test in Europe</title>
		<meeting>Design Automation and Test in Europe</meeting>
		<imprint>
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
