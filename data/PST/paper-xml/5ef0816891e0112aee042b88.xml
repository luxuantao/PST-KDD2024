<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Denoising Diffusion Probabilistic Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
							<email>jonathanho@berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
							<email>ajayj@berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
							<email>pabbeel@cs.berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">U</forename><forename type="middle">C</forename><surname>Berkeley</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">UC Berkeley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Denoising Diffusion Probabilistic Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep generative models of all kinds have recently exhibited high quality samples in a wide variety of data modalities. Generative adversarial networks (GANs), autoregressive models, flows, and variational autoencoders (VAEs) have synthesized striking image and audio samples <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b41">42]</ref>, and there have been remarkable advances in energy-based modeling and score matching that have produced images comparable to those of GANs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b51">52]</ref>.  3 q Y G m r 3 m e M p D a w q s a A m y k p E c t S 0 l h h N l L Z P A i q t 1 Y w M C 2 O W Y m w j i y n N t q 8 w / s 4 X p D B 5 F W V M J i l Q S V a N J i l H o F A B L 4 q Z p g T 4 0 i r Y n t T O i s g M a 0 z A k q C + 0 Q b Y / M q u I f C c Y s s b s B H 1 U N I F U U J g G V e P G f h R 1 q y j 1 Y E T X A a H / S q A n p 8 3 6 / l G f t U f d N c F i q b B T 8 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X V z P 5 0</p><formula xml:id="formula_0">= " &gt; A A A B + H i c b V B N S w M x E J 2 t X 7 V + d N W j l 2 A R P J X d K u i x 6 M V j B f s B 7 V K y a X Y b m k 2 W J K v U 0 l / i x Y M i X v 0 p 3 v w 3 p u 0 e t P X B w O O 9 G W b m h S l n 2 n j e t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / b L 7 s F h S 8 t M E d o k k k v V C b G m n A n a N M x w 2 k k V x U n I a T s c 3 c z 8 9 g N V m k l x b 8 Y p D R I c C x Y x g o 2 V + m 6 5 x 6 W I F Y u H B i s l H / t u x a t 6 c 6 B V 4 u e k A j k a f f e r N 5 A k S 6 g w h G O t u 7 6 X m m C C l W G E 0 2 m p l 2 m a Y j L C M e 1 a K n B C d T C Z H z 5 F p 1 Y Z o E g q W 8 K g u f p 7 Y o I T r c d J a D s T b I Z 6 2 Z u J / 3 n d z E R X w Y S J N D N U k M W i K O P I S D R L A Q 2 Y o s T w s S W Y K G Z v R W S I F S b G Z l W y I f j L L 6 + S V q 3 q n 1 d r d x e V + n U e R x G O 4 Q T O w I d L q M M t N K A J B D J 4 h l d 4 c 5 6 c F + f d + V i 0 F p x 8 5 g j + w P n 8 A X O G k 5 o = &lt; / l a t e x i t &gt; x T ! • • • ! x t ! x t 1 ! • • • ! x 0 &lt; l</formula><formula xml:id="formula_1">L 2 j o u Q d v E 9 i V A o V U y D W O N F a 5 X V Y l J S j</formula><formula xml:id="formula_2">3 G 8 M a 8 L k w k 3 K K G Z c Z J b Z 0 = " &gt; A A A C E n i c b V C 7 S g N B F J 2 N r x h f q 5 Y 2 g 0 F I C s N u F E w Z s L G M Y B 6 Q L M v s Z D Y Z M v t g 5 q 4 Y 1 n y D j b 9 i Y 6 G I r Z W d f + M k 2 S I m H r h w O O d e 7 r 3 H i w V X Y F k / R m 5 t f W N z K 7 9 d 2 N n d 2 z 8 w D 4 9 a K k o k Z U 0 a i U h 2 P K K Y 4 C F r A g f B O r F k J P A E a 3 u j 6 6 n f v m d S 8 S i 8 g 3 H M n I A M Q u 5 z S k B L r l m O 3 R 4 M G Z B S L y A w 9 P z 0 Y e K m c G 5 P 8 C N e k K D s m k W r Y s 2 A V 4 m d k S L K 0 H D N 7 1 4 / o k n A Q q C C K N W 1 r R i c l E j g V L B J o Z c o F h M 6 I g P W 1 T Q k A V N O O n t p g s + 0 0 s d + J H W F g G f q 4 k R K A q X G g a c 7 p 0 e q Z W 8 q / u d 1 E / B r T s r D O A E W 0 v k i P x E Y I j z N B / e 5 Z B T E W B N C J d e 3 Y j o k k l D Q K R Z 0 C P b y y 6 u k V a 3 Y F 5 X q 7 W W x X s v i y K M T d I p K y E Z X q I 5 u U A M 1 E U V P 6 A W 9 o X f j 2 X g 1 P o z P e W v O y G a O 0 R 8 Y X 7 + b C p 4 F &lt; / l a t e x i t &gt; q(x t |x t 1 )</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e A Z 8 7  This paper presents progress in diffusion probabilistic models <ref type="bibr" target="#b49">[50]</ref>. A diffusion probabilistic model (which we will call a "diffusion model" for brevity) is a parameterized Markov chain trained using variational inference to produce samples matching the data after finite time. Transitions of this chain are learned to reverse a diffusion process, which is a Markov chain that gradually adds noise to the data in the opposite direction of sampling until signal is destroyed. When the diffusion consists of small amounts of Gaussian noise, it is sufficient to set the sampling chain transitions to conditional Gaussians too, allowing for a particularly simple neural network parameterization.</p><formula xml:id="formula_3">U u T m A Q o J 4 u 1 9 R G H 5 t A + b C I = " &gt; A A A C C 3 i c b V C 7 T g J B F J 3 1 i f h a t b S Z Q E y w k O y i i Z Q k N p</formula><formula xml:id="formula_4">+ g a H r J Q 8 T B / A j n v s m c G Z P T h 2 z a J W t K f A y s T N S R B n q j v n d 7 Y c 0 9 l k A V B C l O r Y V Q S 8 h E j g V b J L v x o p F h I 7 I g H U 0 D Y j P V C + Z 3 j L B J 1 r p Y y + U + g W A p + p 8 R 0 J 8 p c a + q y v T R d W i l 4 r / e Z 0 Y v G o v 4 U E U A w v o b J A X C w w h T o P B f S 4 Z B T H W h F D J 9 a 6 Y D o k k F H R 8 e R 2 C v X j y M m l W y v Z 5 u X J z U a x V s z h y 6 B g V U A n Z 6 B L V 0 D W q o w a i</formula><p>Diffusion models are straightforward to define and efficient to train, but to the best of our knowledge, there has been no demonstration that they are capable of generating high quality samples. We show that diffusion models actually are capable of generating high quality samples, sometimes better than the published results on other types of generative models (Section 4). In addition, we show that a certain parameterization of diffusion models reveals an equivalence with denoising score matching over multiple noise levels during training and with annealed Langevin dynamics during sampling (Section 3.2) <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b57">58]</ref>. We obtained our best sample quality results using this parameterization (Section 4.2), so we consider this equivalence to be one of our primary contributions.</p><p>Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models (our models do, however, have log likelihoods better than the large estimates annealed importance sampling has been reported to produce for energy based models and score matching <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b51">52]</ref>). We find that the majority of our models' lossless codelengths are consumed to describe imperceptible image details (Section 4.3). We present a more refined analysis of this phenomenon in the language of lossy compression, and we show that the sampling procedure of diffusion models is a type of progressive decoding that resembles autoregressive decoding along a bit ordering that vastly generalizes what is normally possible with autoregressive models.</p><formula xml:id="formula_5">p θ (x t−1 |x t ), p θ (x t−1 |x t ) := N (x t−1 ; µ θ (x t , t), Σ θ (x t , t))<label>(1)</label></formula><p>What distinguishes diffusion models from other types of latent variable models is that the approximate posterior q(x 1:T |x 0 ), called the forward process or diffusion process, is fixed to a Markov chain that gradually adds Gaussian noise to the data according to a variance schedule β 1 , . . . , β T :</p><formula xml:id="formula_6">q(x 1:T |x 0 ) := T t=1 q(x t |x t−1 ), q(x t |x t−1 ) := N (x t ; 1 − β t x t−1 , β t I)<label>(2)</label></formula><p>Training is performed by optimizing the usual variational bound on negative log likelihood:</p><formula xml:id="formula_7">E [− log p θ (x 0 )] ≤ E q − log p θ (x 0:T ) q(x 1:T |x 0 ) = E q − log p(x T ) − t≥1 log p θ (x t−1 |x t ) q(x t |x t−1 ) =: L (3)</formula><p>The forward process variances β t can be learned by reparameterization <ref type="bibr" target="#b30">[31]</ref> or held constant as hyperparameters, and expressiveness of the reverse process is ensured in part by the choice of Gaussian conditionals in p θ (x t−1 |x t ), because both processes have the same functional form when β t are small <ref type="bibr" target="#b49">[50]</ref>. A notable property of the forward process is that it admits sampling x t at an arbitrary timestep t in closed form: using the notation α t := 1 − β t and ᾱt := t s=1 α s , we have</p><formula xml:id="formula_8">q(x t |x 0 ) = N (x t ; √ ᾱt x 0 , (1 − ᾱt )I)<label>(4)</label></formula><p>Efficient training is therefore possible by optimizing random terms of L with stochastic gradient descent. Further improvements come from variance reduction by rewriting L (3) as:</p><formula xml:id="formula_9">E q D KL (q(x T |x 0 ) p(x T )) L T + t&gt;1 D KL (q(x t−1 |x t , x 0 ) p θ (x t−1 |x t )) Lt−1 − log p θ (x 0 |x 1 ) L0<label>(5)</label></formula><p>(See Appendix A for details. The labels on the terms are used in Section 3.) Equation ( <ref type="formula" target="#formula_9">5</ref>) uses KL divergence to directly compare p θ (x t−1 |x t ) against forward process posteriors, which are tractable when conditioned on x 0 :</p><formula xml:id="formula_10">q(x t−1 |x t , x 0 ) = N (x t−1 ; μt (x t , x 0 ), βt I),<label>(6)</label></formula><p>where μt (x t ,</p><formula xml:id="formula_11">x 0 ) := √ ᾱt−1 β t 1 − ᾱt x 0 + √ α t (1 − ᾱt−1 ) 1 − ᾱt x t and βt := 1 − ᾱt−1 1 − ᾱt β t<label>(7)</label></formula><p>Consequently, all KL divergences in Eq. ( <ref type="formula" target="#formula_9">5</ref>) are comparisons between Gaussians, so they can be calculated with closed form expressions instead of high variance Monte Carlo estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Diffusion models and denoising autoencoders</head><p>Diffusion models might appear to be a restricted class of latent variable models, but they allow a large number of degrees of freedom in implementation. One must choose the variances β t of the forward process and the model architecture and Gaussian distribution parameterization of the reverse process. To guide our choices, we establish a new explicit connection between diffusion models and denoising score matching (Section 3.2) that leads to a simplified, weighted variational bound objective for diffusion models (Section 3.4). Ultimately, our model design is justified by simplicity and empirical results (Section 4). Our discussion is categorized by the terms of Eq. ( <ref type="formula" target="#formula_9">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Forward process and L T</head><p>We ignore the fact that the forward process variances β t are learnable by reparameterization and instead fix them to constants (see Section 4 for details). Thus, in our implementation, the approximate posterior q has no learnable parameters, so L T is a constant during training and can be ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reverse process and L 1:T −1</head><p>Now we discuss our choices in p</p><formula xml:id="formula_12">θ (x t−1 |x t ) = N (x t−1 ; µ θ (x t , t), Σ θ (x t , t)) for 1 &lt; t ≤ T . First, we set Σ θ (x t , t) = σ 2 t I to untrained time dependent constants. Experimentally, both σ 2 t = β t and σ 2 t = βt = 1− ᾱt−1 1− ᾱt β t had similar results</formula><p>. The first choice is optimal for x 0 ∼ N (0, I), and the second is optimal for x 0 deterministically set to one point. These are the two extreme choices corresponding to upper and lower bounds on reverse process entropy for data with coordinatewise unit variance <ref type="bibr" target="#b49">[50]</ref>.</p><p>Second, to represent the mean µ θ (x t , t), we propose a specific parameterization motivated by the following analysis of</p><formula xml:id="formula_13">L t . With p θ (x t−1 |x t ) = N (x t−1 ; µ θ (x t , t), σ 2</formula><p>t I), we can write:</p><formula xml:id="formula_14">L t−1 = E q 1 2σ 2 t μt (x t , x 0 ) − µ θ (x t , t) 2 + C (<label>8</label></formula><formula xml:id="formula_15">)</formula><p>where C is a constant that does not depend on θ. So, we see that the most straightforward parameterization of µ θ is a model that predicts μt , the forward process posterior mean. However, we can expand Eq. ( <ref type="formula" target="#formula_14">8</ref>) further using the forward process posterior formula (7):</p><formula xml:id="formula_16">L t−1 − C = E q 1 2σ 2 t √ ᾱt−1 β t 1 − ᾱt x 0 + √ α t (1 − ᾱt−1 ) 1 − ᾱt x t − µ θ (x t , t) 2 (9) = E x0, 1 2σ 2 t 1 √ α t x t (x 0 , ) − β t √ 1 − ᾱt − µ θ (x t (x 0 , ), t) 2<label>(10)</label></formula><p>where x t (x 0 , ) = √ ᾱt x 0 + √ 1 − ᾱt and ∼ N (0, I), due to Eq. ( <ref type="formula" target="#formula_8">4</ref>).</p><formula xml:id="formula_17">Algorithm 1 Training 1: repeat 2: x0 ∼ q(x0) 3: t ∼ Uniform({1, . . . , T }) 4: ∼ N (0, I) 5: Take gradient descent step on ∇ θ − θ ( √ ᾱtx0 + √ 1 − ᾱt , t) 2 6: until converged Algorithm 2 Sampling 1: xT ∼ N (0, I) 2: for t = T, . . . , 1 do 3: z ∼ N (0, I) if t &gt; 1, else z = 0 4: xt−1 = 1 √ α t xt − 1−α t √ 1− ᾱt θ (xt, t) + σtz 5: end for 6: return x0 Equation (10) reveals that µ θ must predict 1 √ αt x t − βt √ 1− ᾱt</formula><p>given x t . Since x t is available as input to the model, we may choose the parameterization</p><formula xml:id="formula_18">µ θ (x t , t) = 1 √ α t x t − β t √ 1 − ᾱt θ (x t , t)<label>(11)</label></formula><p>where θ is a function approximator intended to predict from x t . To sample</p><formula xml:id="formula_19">x t−1 ∼ p θ (x t−1 |x t ) is to compute x t−1 = 1 √ αt x t − βt √ 1− ᾱt θ (x t , t) + σ t z</formula><p>, where z ∼ N (0, I). The complete sampling procedure, Algorithm 2, resembles Langevin dynamics with θ as a learned gradient of the data density. Furthermore, with the parameterization <ref type="bibr" target="#b10">(11)</ref>, Eq. ( <ref type="formula" target="#formula_16">10</ref>) simplifies to:</p><formula xml:id="formula_20">E x0, β 2 t 2σ 2 t α t (1 − ᾱt ) − θ ( √ ᾱt x 0 + √ 1 − ᾱt , t) 2<label>(12)</label></formula><p>which resembles denoising score matching over multiple noise scales indexed by t <ref type="bibr" target="#b51">[52]</ref>. As Eq. ( <ref type="formula" target="#formula_20">12</ref>) is equal to (one term of) the variational bound for the Langevin-like reverse process <ref type="bibr" target="#b10">(11)</ref>, we see that optimizing an objective resembling denoising score matching is equivalent to using variational inference to fit the finite-time marginal of a sampling chain resembling Langevin dynamics.</p><p>To summarize, we can train the reverse process mean function approximator µ θ to predict μt , or by modifying its parameterization, we can train it to predict . (There is also the possibility of predicting x 0 , but we found this to lead to worse sample quality early in our experiments.) We have shown that the -prediction parameterization both resembles Langevin dynamics and simplifies the diffusion model's variational bound to an objective that resembles denoising score matching. Nonetheless, it is just another parameterization of p θ (x t−1 |x t ), so we verify its effectiveness in Section 4 in an ablation where we compare predicting against predicting μt .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data scaling, reverse process decoder, and L 0</head><p>We assume that image data consists of integers in {0, 1, . . . , 255} scaled linearly to [−1, 1]. This ensures that the neural network reverse process operates on consistently scaled inputs starting from the standard normal prior p(x T ). To obtain discrete log likelihoods, we set the last term of the reverse process to an independent discrete decoder derived from the Gaussian N (x 0 ; µ θ (x 1 , 1), σ 2 1 I):</p><formula xml:id="formula_21">p θ (x 0 |x 1 ) = D i=1 δ+(x i 0 ) δ−(x i 0 ) N (x; µ i θ (x 1 , 1), σ 2 1 ) dx δ + (x) = ∞ if x = 1 x + 1 255 if x &lt; 1 δ − (x) = −∞ if x = −1 x − 1 255 if x &gt; −1 (13)</formula><p>where D is the data dimensionality and the i superscript indicates extraction of one coordinate. (It would be straightforward to instead incorporate a more powerful decoder like a conditional autoregressive model, but we leave that to future work.) Similar to the discretized continuous distributions used in VAE decoders and autoregressive models <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b48">49]</ref>, our choice here ensures that the variational bound is a lossless codelength of discrete data, without need of adding noise to the data or incorporating the Jacobian of the scaling operation into the log likelihood. At the end of sampling, we display µ θ (x 1 , 1) noiselessly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Simplified training objective</head><p>With the reverse process and decoder defined above, the variational bound, consisting of terms derived from Eqs. ( <ref type="formula" target="#formula_20">12</ref>) and ( <ref type="formula">13</ref>), is clearly differentiable with respect to θ and is ready to be employed for  training. However, we found it beneficial to sample quality (and simpler to implement) to train on the following variant of the variational bound:</p><formula xml:id="formula_22">L simple (θ) := E t,x0, − θ ( √ ᾱt x 0 + √ 1 − ᾱt , t) 2 (<label>14</label></formula><formula xml:id="formula_23">)</formula><p>where t is uniform between 1 and T . The t = 1 case corresponds to L 0 with the integral in the discrete decoder definition (13) approximated by the Gaussian probability density function times the bin width, ignoring σ 2 1 and edge effects. The t &gt; 1 cases correspond to an unweighted version of Eq. ( <ref type="formula" target="#formula_20">12</ref>), analogous to the loss weighting used by the NCSN denoising score matching model <ref type="bibr" target="#b51">[52]</ref>. (L T does not appear because the forward process variances β t are fixed.) Algorithm 1 displays the complete training procedure with this simplified objective.</p><p>Due to discarding the weighting in Eq. ( <ref type="formula" target="#formula_20">12</ref>), our simplified objective ( <ref type="formula" target="#formula_22">14</ref>) is a weighted variational bound that emphasizes different aspects of reconstructions that θ must perform <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b19">20]</ref>. We will see in our experiments that this reweighting leads to better sample quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We set T = 1000 for all experiments so that the number of neural network evaluations needed during sampling matches previous work <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b51">52]</ref>. We set the forward process variances to constants increasing linearly from β 1 = 10 −4 to β T = 0.02. These constants were chosen to be small relative to data scaled to [−1, 1], ensuring that reverse and forward processes have approximately the same functional form while keeping the signal-to-noise ratio at x T as small as possible (L T = D KL (q(x T |x 0 ) N (0, I)) ≈ 10 −5 bits per dimension in our experiments).</p><p>To represent the reverse process, we use a U-Net backbone similar to an unmasked PixelCNN++ <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b44">45]</ref> with group normalization throughout <ref type="bibr" target="#b61">[62]</ref>. Parameters are shared across time, which is specified to the network using the Transformer sinusoidal position embedding <ref type="bibr" target="#b56">[57]</ref>. We use self-attention at the 16 × 16 feature map resolution <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b56">57]</ref>. Details are in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sample quality</head><p>Table <ref type="table" target="#tab_0">1</ref> shows Inception scores, FID scores, and negative log likelihoods (lossless codelengths) on CIFAR10. Our unconditional model achieves better sample quality than other models, both unconditional and conditional, at the expense of codelengths (see <ref type="bibr">Section 4.3)</ref>. Training on the true variational bound yields better codelengths than training on the simplified objective, as expected, but the latter yields the best sample quality. See Fig. <ref type="figure" target="#fig_0">1</ref> for CIFAR10 and CelebA-HQ 256 × 256 samples, Fig. <ref type="figure">3</ref> and Fig. <ref type="figure">4</ref> for LSUN 256 × 256 samples <ref type="bibr" target="#b62">[63]</ref>, and Appendix C for more. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reverse process parameterization and training objective ablation</head><p>In Table <ref type="table" target="#tab_1">2</ref>, we show the sample quality effects of reverse process parameterizations and training objectives (Section 3.2). We find that the baseline option of predicting μ works well only when trained on the true variational bound instead of our simplified objective <ref type="bibr" target="#b13">(14)</ref>. We also see that learning reverse process variances (by incorporating a parameterized diagonal Σ θ (x t ) into the variational bound) leads to unstable training and poorer sample quality compared to fixed variances. Predicting , as we proposed, performs approximately as well as predicting μ when trained on the variational bound with fixed variances, but much better when trained with our simplified objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Progressive coding</head><p>Table <ref type="table" target="#tab_0">1</ref> also shows the codelengths of our CIFAR10 models. The gap between train and test is at most 0.03 bits per dimension, which is comparable to the gaps reported with other likelihood-based models and indicates that our diffusion model is not overfitting (see Appendix C for nearest neighbor visualizations). Still, while our lossless codelengths are better than the large estimates reported for energy based models and score matching using annealed importance sampling <ref type="bibr" target="#b10">[11]</ref>, they are not competitive with other types of likelihood-based generative models <ref type="bibr" target="#b6">[7]</ref>.</p><p>Since samples are nonetheless of high quality, we conclude that diffusion models have an inductive bias that makes them excellent lossy compressors. Treating the variational bound terms L 1 + • • • + L T as rate and L 0 as distortion, our CIFAR10 model with the highest quality samples has a rate of 1.78 bits/dim and a distortion of 1.97 bits/dim, which amounts to a root mean squared error of 0.95 on a scale from 0 to 255. More than half of the lossless codelength describes imperceptible distortions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Progressive lossy compression</head><p>We can probe further into the rate-distortion behavior of our model by introducing a progressive lossy code that mirrors the form of Eq. ( <ref type="formula" target="#formula_9">5</ref>): see Algorithms 3 and 4, which assume access to a procedure, such as minimal random coding <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, that can transmit a sample x ∼ q(x) using approximately D KL (q(x) p(x)) bits on average for any distributions p and q, for which only p is available to the receiver beforehand. When applied to x 0 ∼ q(x 0 ), Algorithms 3 and 4 transmit x T , . . . , x 0 in sequence using a total expected codelength equal to Eq. ( <ref type="formula" target="#formula_9">5</ref>). The receiver, at any time t, has the partial information x t fully available and can progressively estimate:</p><formula xml:id="formula_24">x 0 ≈ x0 = x t − √ 1 − ᾱt θ (x t ) / √ ᾱt<label>(15)</label></formula><p>due to Eq. ( <ref type="formula" target="#formula_8">4</ref>). (A stochastic reconstruction x 0 ∼ p θ (x 0 |x t ) is also valid, but we do not consider it here because it makes distortion more difficult to evaluate.) Figure <ref type="figure" target="#fig_6">5</ref> shows the root mean squared error distortion of this estimate, x 0 − x0 2 /D, plotted against reverse process time and rate (calculated by the cumulative number of bits received so far at time t) on the CIFAR10 test set. The distortion decreases steeply in the low-rate region of the rate-distortion plot, indicating that the majority of the bits are indeed allocated to imperceptible distortions.  <ref type="table" target="#tab_3">4</ref> for details.</p><p>Progressive generation We also run a progressive unconditional generation process given by progressive decompression from random bits. In other words, we predict the result of the reverse process, x0 , while sampling from the reverse process using Algorithm 2. Figures <ref type="figure" target="#fig_7">6 and 10</ref> show the resulting sample quality of x0 over the course of the reverse process. Large scale image features appear first and details appear last. Figure <ref type="figure" target="#fig_8">7</ref> shows stochastic predictions x 0 ∼ p θ (x 0 |x t ) with x t frozen for various t. When t is small, all but fine details are preserved, and when t is large, only large scale features are preserved. Perhaps these are hints of conceptual compression <ref type="bibr" target="#b15">[16]</ref>.  Connection to autoregressive decoding Note that the variational bound ( <ref type="formula" target="#formula_9">5</ref>) can be rewritten as:</p><formula xml:id="formula_25">L = D KL (q(x T ) p(x T )) + E q t≥1 D KL (q(x t−1 |x t ) p θ (x t−1 |x t )) + H(x 0 )<label>(16)</label></formula><p>(See Appendix A for a derivation.) Now consider setting the diffusion process length T to the dimensionality of the data, defining the forward process so that q(x t |x 0 ) places all probability mass on x 0 with the first t coordinates masked out (i.e. q(x t |x t−1 ) masks out the t th coordinate), setting p(x T ) to place all mass on a blank image, and, for the sake of argument, taking p θ (x t−1 |x t ) to be a fully expressive conditional distribution. With these choices, D KL (q(x T ) p(x T )) = 0, and minimizing D KL (q(x t−1 |x t ) p θ (x t−1 |x t )) forces p θ to copy coordinates t + 1, . . . , T unchanged and trains p θ to predict the t th coordinate given t + 1, . . . , T . Thus, training p θ with this particular diffusion is training an autoregressive model.</p><p>We can therefore interpret the Gaussian diffusion model ( <ref type="formula" target="#formula_6">2</ref>) as a kind of autoregressive model with a generalized bit ordering that cannot be expressed by reordering data coordinates. Prior work has shown that such reorderings introduce inductive biases that have an impact on sample quality <ref type="bibr" target="#b34">[35]</ref>, so we speculate that the Gaussian diffusion serves a similar purpose, perhaps to greater effect since Gaussian noise might be more natural to add to images compared to masking noise. Moreover, the Gaussian diffusion length is not restricted to equal the data dimension; for instance, we use T = 1000, which is less than the dimension of the 32 × 32 × 3 or 256 × 256 × 3 images in our experiments. Gaussian diffusions can be made shorter for fast sampling or longer for model expressiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Interpolation</head><p>We can interpolate source images x 0 , x 0 ∼ q(x 0 ) in latent space using q as a stochastic encoder, x t , x t ∼ q(x t |x 0 ), then decoding the linearly interpolated latent xt = (1 − λ)x 0 + λx 0 into image space by the reverse process, x0 ∼ p(x 0 |x t ). In effect, we use the reverse process to remove artifacts from linearly interpolating corrupted versions of the source images, as depicted in Fig. <ref type="figure" target="#fig_9">8</ref> (left). We fixed the noise for different values of λ so x t and x t remain the same. Fig. <ref type="figure" target="#fig_9">8</ref> (right) shows interpolations and reconstructions of original CelebA-HQ 256 × 256 images (t = 500). The reverse process produces high-quality reconstructions, and plausible interpolations that smoothly vary attributes such as pose, skin tone, hairstyle, expression and background, but not eyewear. Larger t results in coarser and more varied interpolations, with novel samples at t = 1000 (Appendix Fig. <ref type="figure">9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>While diffusion models might resemble flows <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21]</ref> and VAEs <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b33">34]</ref>, diffusion models are designed so that q has no parameters and the top-level latent x T has nearly zero mutual information with the data x 0 . Our -prediction reverse process parameterization establishes a connection between diffusion models and denoising score matching over multiple noise levels with annealed Langevin dynamics <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53]</ref>. Diffusion models, however, admit straightforward log likelihood evaluation, and since the training procedure explicitly trains the Langevin dynamics sampler using variational inference, there is no justified reason to choose a different sampler after training. The connection also has the reverse implication that a certain weighted form of denoising score matching is the same as variational inference to train a Langevin-like sampler. Other methods for learning transition operators of Markov chains include infusion training <ref type="bibr" target="#b1">[2]</ref>, variational walkback <ref type="bibr" target="#b12">[13]</ref>, generative stochastic networks <ref type="bibr" target="#b0">[1]</ref>, and others <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>By the known connection between score matching and energy-based modeling, our work could have implications for other recent work on energy-based models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b7">8]</ref>. Our rate-distortion curves are computed over time in one evaluation of the variational bound, reminiscent of how rate-distortion curves can be computed over distortion penalties in one run of annealed importance sampling <ref type="bibr" target="#b21">[22]</ref>. Our progressive decoding argument can be seen in convolutional DRAW and related models <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37]</ref> and may also lead to more general designs for subscale orderings or future predictions for autoregressive models <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b60">61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented high quality image samples using diffusion models, and we have found connections among diffusion models and variational inference for training Markov chains, denoising score matching and annealed Langevin dynamics (and energy-based models by extension), autoregressive models, and progressive lossy compression. Since diffusion models seem to have excellent inductive biases for image data, we look forward to investigating their utility in other data modalities and as components in other types of generative models and machine learning systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Our work on diffusion models takes on a similar scope as existing work on other types of deep generative models, such as efforts to improve the sample quality of GANs, flows, autoregressive models, and so forth. Our paper represents progress in making diffusion models a generally useful tool in this family of techniques, so it may serve to amplify any impacts that generative models have had (and will have) on the broader world.</p><p>Unfortunately, there are numerous well-known malicious uses of generative models. Sample generation techniques can be employed to produce fake images and videos of high profile figures for political purposes. While fake images were manually created long before software tools were available, generative models such as ours make the process easier. Fortunately, CNN-generated images currently have subtle flaws that allow detection <ref type="bibr" target="#b58">[59]</ref>, but improvements in generative models may make this more difficult. Generative models also reflect the biases in the datasets on which they are trained. As many large datasets are collected from the internet by automated systems, it can be difficult to remove these biases, especially when the images are unlabeled. If samples from generative models trained on these datasets proliferate throughout the internet, then these biases will only be reinforced further.</p><p>On the other hand, diffusion models may be useful for data compression, which, as data becomes higher resolution and as global internet traffic increases, might be crucial to ensure accessibility of the internet to wide audiences. Our work might contribute to representation learning on unlabeled raw data for a large range of downstream tasks, from image classification to reinforcement learning, and diffusion models might also become viable for creative uses in art, photography, and music.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extra information</head><p>LSUN FID scores for LSUN datasets are included in Table <ref type="table" target="#tab_2">3</ref>. Scores marked with * are reported by StyleGAN2 as baselines, and other scores are reported by their respective authors.  <ref type="bibr" target="#b17">[18]</ref>, which is not tractable for high dimensional data. These algorithms serve as a compression interpretation of the variational bound (5) of Sohl-Dickstein et al. <ref type="bibr" target="#b49">[50]</ref>, not yet as a practical compression system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Extended derivations</head><p>Below is a derivation of Eq. ( <ref type="formula" target="#formula_9">5</ref>), the reduced variance variational bound for diffusion models. This material is from Sohl-Dickstein et al. <ref type="bibr" target="#b49">[50]</ref>; we include it here only for completeness.</p><formula xml:id="formula_26">L = E q − log p θ (x 0:T ) q(x 1:T |x 0 ) (17) = E q   − log p(x T ) − t≥1 log p θ (x t−1 |x t ) q(x t |x t−1 )   (18) = E q − log p(x T ) − t&gt;1 log p θ (x t−1 |x t ) q(x t |x t−1 ) − log p θ (x 0 |x 1 ) q(x 1 |x 0 ) (19) = E q − log p(x T ) − t&gt;1 log p θ (x t−1 |x t ) q(x t−1 |x t , x 0 ) • q(x t−1 |x 0 ) q(x t |x 0 ) − log p θ (x 0 |x 1 ) q(x 1 |x 0 ) (20) = E q − log p(x T ) q(x T |x 0 ) − t&gt;1 log p θ (x t−1 |x t ) q(x t−1 |x t , x 0 ) − log p θ (x 0 |x 1 )<label>(21)</label></formula><formula xml:id="formula_27">= E q D KL (q(x T |x 0 ) p(x T )) + t&gt;1 D KL (q(x t−1 |x t , x 0 ) p θ (x t−1 |x t )) − log p θ (x 0 |x 1 )<label>(22)</label></formula><p>The following is an alternate version of L. It is not tractable to estimate, but it is useful for our discussion in Section 4.3.</p><formula xml:id="formula_28">L = E q   − log p(x T ) − t≥1 log p θ (x t−1 |x t ) q(x t |x t−1 )   (23) = E q   − log p(x T ) − t≥1 log p θ (x t−1 |x t ) q(x t−1 |x t ) • q(x t−1 ) q(x t )   (24) = E q   − log p(x T ) q(x T ) − t≥1 log p θ (x t−1 |x t ) q(x t−1 |x t ) − log q(x 0 )   (25) = D KL (q(x T ) p(x T )) + E q   t≥1 D KL (q(x t−1 |x t ) p θ (x t−1 |x t ))   + H(x 0 )<label>(26)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experimental details</head><p>Our neural network architecture follows the backbone of PixelCNN++ <ref type="bibr" target="#b48">[49]</ref>, which is a U-Net <ref type="bibr" target="#b44">[45]</ref> based on a Wide ResNet <ref type="bibr" target="#b63">[64]</ref>. We replaced weight normalization <ref type="bibr" target="#b45">[46]</ref> with group normalization <ref type="bibr" target="#b61">[62]</ref> to make the implementation simpler. Apart from an initial choice of hyperparameters early on to make network size fit within memory constraints, we performed the majority of our hyperparameter search to optimize for CIFAR10 sample quality, then transferred the resulting settings over to the other datasets:</p><p>• We chose the β t schedule from a set of constant, linear, and quadratic schedules, all constrained so that L T ≈ 0. We set T = 1000 without a sweep, and we chose a linear schedule from β 1 = 10 −4 to β T = 0.02.</p><p>• We set the dropout rate on CIFAR10 to 0.1 by sweeping over the values {0.1, 0.2, 0.3, 0.4}. Without dropout on CIFAR10, we obtained poorer samples reminiscent of the overfitting artifacts in an unregularized PixelCNN++ <ref type="bibr" target="#b48">[49]</ref>. We set dropout rate on the other datasets to zero without sweeping.</p><p>• We used random horizontal flips during training for CIFAR10; we tried training both with and without flips, and found flips to improve sample quality slightly. We also used random horizontal flips for all other datasets except LSUN Bedroom.</p><p>• We tried Adam <ref type="bibr" target="#b28">[29]</ref> and RMSProp early on in our experimentation process and chose the former. We left the hyperparameters to their standard values. We set the learning rate to 2 × 10 −4 without any sweeping, and we lowered it to 2 × 10 −5 for the 256 × 256 images, which seemed unstable to train with the larger learning rate.</p><p>• We set the batch size to 128 for CIFAR10 and 64 for larger images. We did not sweep over these values.</p><p>• We used EMA on model parameters with a decay factor of 0.9999. We did not sweep over this value.</p><p>Final experiments were trained once and evaluated throughout training for sample quality. Sample quality scores and log likelihood are reported on the minimum FID value over the course of training. On CIFAR10, we calculated Inception and FID scores on 50000 samples using the original code from the OpenAI <ref type="bibr" target="#b47">[48]</ref> and TTUR <ref type="bibr" target="#b18">[19]</ref> repositories, respectively. On LSUN, we calculated FID scores on 50000 samples using code from the StyleGAN2 <ref type="bibr" target="#b26">[27]</ref> repository. CIFAR10 and CelebA-HQ were loaded as provided by TensorFlow Datasets (https://www.tensorflow.org/datasets), and LSUN was prepared using code from StyleGAN. Dataset splits (or lack thereof) are standard from the papers that introduced their usage in a generative modeling context. We used v3-8 TPUs for all experiments. All details can be found in the source code release.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Samples</head><p>Additional samples <ref type="bibr">Figure 11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">and 19</ref> show uncurated samples from the diffusion models trained on CelebA-HQ, CIFAR10 and LSUN datasets.</p><p>Latent structure and reverse process stochasticity During sampling, both the prior x T ∼ N (0, I) and Langevin dynamics are stochastic. To understand the significance of the second source of noise, we sampled multiple images conditioned on the same intermediate latent for the CelebA 256 × 256 dataset. Figure <ref type="figure" target="#fig_8">7</ref> shows multiple draws from the reverse process x 0 ∼ p θ (x 0 |x t ) that share the latent x t for t ∈ {1000, 750, 500, 250}. To accomplish this, we run a single reverse chain from an initial draw from the prior. At the intermediate timesteps, the chain is split to sample multiple images. When the chain is split after the prior draw at x T =1000 , the samples differ significantly. However, when the chain is split after more steps, samples share high-level attributes like gender, hair color, eyewear, saturation, pose and facial expression. This indicates that intermediate latents like x 750 encode these attributes, despite their imperceptibility.</p><p>Coarse-to-fine interpolation Figure <ref type="figure">9</ref> shows interpolations between a pair of source CelebA 256 × 256 images as we vary the number of diffusion steps prior to latent space interpolation.</p><p>Increasing the number of diffusion steps destroys more structure in the source images, which the model completes during the reverse process. This allows us to interpolate at both fine granularities and coarse granularities. In the limiting case of 0 diffusion steps, the interpolation mixes source images in pixel space. On the other hand, after 1000 diffusion steps, source information is lost and interpolations are novel samples.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Generated samples on CelebA-HQ 256 × 256 (left) and unconditional CIFAR10 (right) Preprint. Under review.</figDesc><graphic url="image-2.png" coords="1,348.83,468.87,309.95,309.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>a t e x i t s h a 1 _ b a s e 6 4 = " l 4 L v S g M 7 P R 7 I / k k u y 5 s oi k K 4 g p U = " &gt; A A A E o X i c t V L d i t N A F E 7 X q G v 9 2 a 5 e e j O Y L e x K L U 0 V F K R Q 9 E Y v h C r b 3 Y U k l O l k 2 g 6 d n z B z Y r c b 8 z K + l U / g a z h J K 6 a t u i B 4 Y O D M + T / n + 8 Y J Z w Y 6 n W + 1 v R v u z Vu 3 9 + / U 7 9 6 7 / + C g c f j w z K h U E z o k i i t 9 M c a G c i b p E B h w e p F o i s W Y 0 / P x / G 3 h P / 9 M t W F K n s I y o Z H A U 8 k m j G C w p l H j e y g w z A j T h N M 4 K z / j S X a Z j 0 5 z F H I l p 5 p N Z 4 C 1 V g s U k l i B 2 T X / o Q L Y C p e / 4 r J w Z h J M 6 N P M J y L P t 9 I M 0 S w B A 0 t O U a V G B s / 8 / J 8 m W V R H 6 e S j h t d p d 0 p B u 4 q / V j x n L Y P R 4 d 7 X M F Y k F V Q C 4 d i Y w O 8 k E G V Y A 7 P 1 8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>e z E P T + B l m C S i V Q g w 6 5 o r 2 v B a E 0 Y 5 z 1 e 4 D / V e B m h s t w J y o 5 C 0 Y e Z 5 3 v d o / z 1 9 l h V j l y 7 1 + K 6 x R b / Z b O / r b L C S 8 H M w m V Z 7 W 9 z e F c 5 6 7 b 9 5 + 3 u x x d e / 8 2 a 3 / v O Y + e J c + z 4 z k u n 7 7 x z B s 7 Q I b U P N V P 7 U s t d z 3 3 v D t x P q 9 C 9 2 j r n k b M h b v A D 8 1 m O b w = = &lt; / l a t e x i t &gt; p ✓ (x t 1 |x t )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>a Y y C M B s p k d Z m H C 7 M O Z u 0 a y 0 t v 4 K z Y W G m P r D 9 j 5 N 8 7 C F g i e Z J I z 5 9 y b e + 9 x I 8 E V W N a P s b K 6 t r 6 x m d v K b + / s 7 u 2 b B 4 d N F c a S s g Y N R S j b L l F M 8 I A 1 g I N g 7 U g y 4 r u C t d z R V e q 3 7 p l U P A x u Y R y x n k 8 G A f c 4 J a A l x y z c l b o</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The directed graphical model considered in this work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :Figure 4 :Algorithm 3 4 1 :</head><label>34341</label><figDesc>Figure 3: LSUN Church samples. FID=7.89</figDesc><graphic url="image-6.png" coords="6,108.00,72.00,194.04,129.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Unconditional CIFAR10 test set rate-distortion vs. time. Distortion is measured in root mean squared error on a [0, 255] scale. See Table4for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Unconditional CIFAR10 progressive generation (x0 over time, from left to right). Extended samples and sample quality metrics over time in the appendix (Figs. 10 and 14).</figDesc><graphic url="image-8.png" coords="7,127.80,333.65,356.40,356.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: When conditioned on the same latent, CelebA-HQ 256 × 256 samples share high-level attributes. Bottom-right quadrants are xt, and other quadrants are samples from p θ (x0|xt).</figDesc><graphic url="image-9.png" coords="7,147.60,439.77,316.77,67.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Interpolations of CelebA-HQ 256x256 images with 500 timesteps of diffusion.</figDesc><graphic url="image-10.png" coords="8,108.00,72.00,396.01,74.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: CelebA-HQ 256 × 256 generated samples</figDesc><graphic url="image-12.png" coords="16,108.00,189.06,395.98,395.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: CelebA-HQ 256 × 256 nearest neighbors, computed on a 100 × 100 crop surrounding the faces. Generated samples are in the leftmost column, and training set nearest neighbors are in the remaining columns.</figDesc><graphic url="image-14.png" coords="17,108.00,376.64,395.98,197.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 :Figure 14 :Figure 15 :</head><label>131415</label><figDesc>Figure 13: Unconditional CIFAR10 generated samples</figDesc><graphic url="image-15.png" coords="18,108.00,189.05,396.01,396.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 17 :Figure 18 :</head><label>1718</label><figDesc>Figure 17: LSUN Bedroom generated samples, large model. FID=4.90</figDesc><graphic url="image-20.png" coords="22,108.00,129.67,395.98,514.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: LSUN Cat generated samples. FID=19.75</figDesc><graphic url="image-22.png" coords="24,108.00,129.67,395.98,514.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-11.png" coords="15,158.06,142.24,344.22,239.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-16.png" coords="19,108.00,189.05,396.01,396.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-17.png" coords="20,127.80,187.49,356.40,177.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-18.png" coords="20,127.80,382.10,356.40,177.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>CIFAR10 results. NLL measured in bits/dim.</figDesc><table><row><cell>Model</cell><cell>IS</cell><cell>FID</cell><cell>NLL Test (Train)</cell></row><row><cell>Conditional</cell><cell></cell><cell></cell><cell></cell></row><row><cell>EBM [11]</cell><cell>8.30</cell><cell>37.9</cell><cell></cell></row><row><cell>JEM [15]</cell><cell>8.76</cell><cell>38.4</cell><cell></cell></row><row><cell>BigGAN [3]</cell><cell>9.22</cell><cell>14.73</cell><cell></cell></row><row><cell>StyleGAN2 + ADA [28]</cell><cell>10.06</cell><cell>2.67</cell><cell></cell></row><row><cell>Unconditional</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Diffusion (original) [50] Gated PixelCNN [56]</cell><cell>4.60</cell><cell>65.93</cell><cell>≤ 5.40 3.03 (2.90)</cell></row><row><cell>Sparse Transformer [7]</cell><cell></cell><cell></cell><cell>2.80</cell></row><row><cell>PixelIQN [40]</cell><cell>5.29</cell><cell>49.46</cell><cell></cell></row><row><cell>EBM [11]</cell><cell>6.78</cell><cell>38.2</cell><cell></cell></row><row><cell>NCSNv2 [53]</cell><cell></cell><cell>31.75</cell><cell></cell></row><row><cell>NCSN [52]</cell><cell>8.87±0.12</cell><cell>25.32</cell><cell></cell></row><row><cell>SNGAN [36]</cell><cell>8.22±0.05</cell><cell>21.7</cell><cell></cell></row><row><cell>SNGAN-DDLS [4]</cell><cell>9.09±0.10</cell><cell>15.42</cell><cell></cell></row><row><cell>StyleGAN2 + ADA [28] Ours (L, fixed isotropic Σ) Ours (L simple )</cell><cell>9.74 ± 0.05 7.67±0.13 9.46±0.11</cell><cell>3.26 13.51 3.17</cell><cell>≤ 3.70 (3.69) ≤ 3.75 (3.72)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Unconditional CIFAR10 reverse process parameterization and training objective ablation. Blank entries were unstable to train and generated poor samples with out-ofrange scores.</figDesc><table><row><cell>Objective</cell><cell>IS</cell><cell>FID</cell></row><row><cell>μ prediction (baseline)</cell><cell></cell><cell></cell></row><row><cell>L (learned diagonal Σ)</cell><cell>7.28±0.10</cell><cell>23.69</cell></row><row><cell>L (fixed isotropic Σ)</cell><cell>8.06±0.09</cell><cell>13.22</cell></row><row><cell>L simple</cell><cell>-</cell><cell>-</cell></row><row><cell>prediction (ours)</cell><cell></cell><cell></cell></row><row><cell>L (learned diagonal Σ)</cell><cell>-</cell><cell>-</cell></row><row><cell>L (fixed isotropic Σ)</cell><cell>7.67±0.13</cell><cell>13.51</cell></row><row><cell>L simple</cell><cell>9.46±0.11</cell><cell>3.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Progressive compression Our lossy compression argument in Section 4.3 is only a proof of concept, because Algorithms 3 and 4 depend on a procedure such as minimal random coding</figDesc><table><row><cell>Model</cell><cell cols="4">: FID scores for LSUN 256 × 256 datasets LSUN Bedroom LSUN Church LSUN Cat</cell></row><row><cell cols="2">ProgressiveGAN [25] StyleGAN [26]</cell><cell>8.34 2.65</cell><cell>6.42 4.21  *</cell><cell>37.52 8.53  *</cell></row><row><cell>StyleGAN2 [27]</cell><cell></cell><cell>-</cell><cell>3.86</cell><cell>6.93</cell></row><row><cell>Ours (L simple )</cell><cell></cell><cell>6.36</cell><cell>7.89</cell><cell>19.75</cell></row><row><cell cols="2">Ours (L simple , large)</cell><cell>4.90</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Unconditional CIFAR10 test set rate-distortion values (accompanies Fig.5) Reverse process time (T − t + 1) Rate (bits/dim) Distortion (RMSE [0, 255])</figDesc><table><row><cell>1000</cell><cell>1.77581</cell><cell>0.95136</cell></row><row><cell>900</cell><cell>0.11994</cell><cell>12.02277</cell></row><row><cell>800</cell><cell>0.05415</cell><cell>18.47482</cell></row><row><cell>700</cell><cell>0.02866</cell><cell>24.43656</cell></row><row><cell>600</cell><cell>0.01507</cell><cell>30.80948</cell></row><row><cell>500</cell><cell>0.00716</cell><cell>38.03236</cell></row><row><cell>400</cell><cell>0.00282</cell><cell>46.12765</cell></row><row><cell>300</cell><cell>0.00081</cell><cell>54.18826</cell></row><row><cell>200</cell><cell>0.00013</cell><cell>60.97170</cell></row><row><cell>100</cell><cell>0.00000</cell><cell>67.60125</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Our 32 × 32 models use four feature map resolutions (32 × 32 to 4 × 4), and our 256 × 256 models use six. All models have two convolutional residual blocks per resolution level and self-attention blocks at the 16 × 16 resolution between the convolutional blocks<ref type="bibr" target="#b5">[6]</ref>. Diffusion time t is specified by adding the Transformer sinusoidal position embedding<ref type="bibr" target="#b56">[57]</ref> into each residual block. Our CIFAR10 model has approximately 30 million parameters, and the other models have 114 million parameters. We also train a larger variant of the LSUN Bedroom model by increasing filter count, with approximately 256 million parameters.</figDesc><table><row><cell>The CIFAR10 models were trained for at most 1.3M steps (approximately 1 day). CelebA-HQ used</cell></row><row><cell>0.5M steps, LSUN Bedroom used 2.4M steps, LSUN Cat used 1.8M steps, and LSUN Church used</cell></row><row><cell>1.2M steps. The larger LSUN Bedroom model used 1.15M steps.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">(a) Pixel space nearest neighbors (b) Inception feature space nearest neighbors</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>This work was supported by ONR PECASE and the NSF Graduate Research Fellowship under grant number DGE-1752814. Computational resources were provided by Google Cloud.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">GSNs: generative stochastic networks. Information and Inference: A</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Thibodeau-Laufer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the IMA</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="249" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to generate samples from noise through infusion training</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sina</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Your GAN is secretly an energy-based model and you should use discriminator driven latent sampling</title>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Paull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.06060</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Qi Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6571" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">PixelSNAIL: An improved autoregressive generative model</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="863" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Residual energy-based models for text generation</title>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11714</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">NICE: Non-linear independent components estimation</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<title level="m">Density estimation using Real NVP</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Implicit generation and modeling with energy based models</title>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3603" to="3613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Variational walkback: Learning a transition operator as a stochastic recurrent net</title>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><forename type="middle">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4392" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">FFJORD: Free-form continuous dynamics for scalable reversible generative models</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Your classifier is secretly an energy based model and you should treat it like one</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joern-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards conceptual compression</title>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3549" to="3557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The communication complexity of correlation</title>
		<author>
			<persName><forename type="first">Prahladh</forename><surname>Harsha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaikumar</forename><surname>Radhakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Second Annual IEEE Conference on Computational Complexity (CCC&apos;07)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="10" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Minimal random code learning: Getting bits back from compressed model parameters</title>
		<author>
			<persName><forename type="first">Marton</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Peharz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">GANs trained by a two time-scale update rule converge to a local Nash equilibrium</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Shakir Mohamed, and Alexander Lerchner. beta-VAE: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Flow++: Improving flow-based generative models with variational dequantization and architecture design</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating lossy compression rates of deep generative models</title>
		<author>
			<persName><forename type="first">Sicong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanshuai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th Workshop on Bayesian Deep Learning</title>
				<imprint>
			<date type="published" when="2019">NeurIPS 2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Video pixel networks</title>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1771" to="1779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient neural audio synthesis</title>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seb</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Casagrande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Stimberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2410" to="2419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Analyzing and improving the image quality of StyleGAN</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Training generative adversarial networks with limited data</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miika</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janne</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06676</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="10215" to="10224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Auto-encoding variational Bayes. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improved variational inference with inverse autoregressive flow</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Diederik P Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4743" to="4751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generalizing Hamiltonian Monte Carlo with neural networks</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BIVA: A very deep hierarchy of latent variables for generative modeling</title>
		<author>
			<persName><forename type="first">Lars</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Liévin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6548" to="6558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Generating high fidelity images with subscale pixel networks and multidimensional upscaling</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.01599</idno>
		<title level="m">VQ-DRAW: A sequential discrete VAE</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">On the anatomy of MCMC-based maximum likelihood learning of energy-based models</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitch</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12370</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning non-convergent non-persistent short-run MCMC toward energy-based model</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitch</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5233" to="5243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Autoregressive quantile networks for generative modeling</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3936" to="3945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">WaveGlow: A flow-based generative network for speech synthesis</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3617" to="3621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generating diverse high-fidelity images with VQ-VAE-2</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="14837" to="14847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><surname>Durk</surname></persName>
		</author>
		<author>
			<persName><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="901" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Markov chain monte carlo and variational inference: Bridging the gap</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1218" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A-NICE-MC: Adversarial training for MCMC</title>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5140" to="5150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11895" to="11907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Improved techniques for training score-based generative models</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09011</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<title level="m">WaveNet: A generative model for raw audio</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pixel recurrent neural networks</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Conditional image generation with PixelCNN decoders</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Cnn-generated images are surprisingly easy to spot...for now</title>
		<author>
			<persName><forename type="first">Sheng-Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Auke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiel</forename><surname>Wiggers</surname></persName>
		</author>
		<author>
			<persName><surname>Hoogeboom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09928</idno>
		<title level="m">Predictive sampling with forecasting autoregressive models</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
				<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<author>
			<persName><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<title level="m">Wide residual networks</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
