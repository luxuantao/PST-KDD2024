<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modelling dialogues using argumentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Leila</forename><surname>Amgoud</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Maudet</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Parsons</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Queen Mary and Westfield College</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of London</orgName>
								<address>
									<postCode>E1 4NS</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">IRIT/ENSEEIHT</orgName>
								<address>
									<addrLine>2 rue C. Camichel</addrLine>
									<postCode>31071</postCode>
									<settlement>Toulouse Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Liverpool</orgName>
								<address>
									<postCode>L69 7ZF</postCode>
									<settlement>Chadwick Building, Liverpool</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modelling dialogues using argumentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E67431AEFCD29613DF5A9E16BE491E4B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A number of authors have suggested the use of argumentation techniques as the basis for negotiation dialogues between agents. In this paper we augment this work by investigating the use of argumentation as the basis for a wider range of types of dialogue. The approach we take is based upon MacKenzie's dialogue game DC, and we show that a translation of this into our system of argumentation can support a subset of the types of dialogue identified by Walton and Krabbe.   </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When building multi-agent systems, we take for granted the fact that the agents which make up the system will need to communicate. They need to communicate in order to resolve differences of opinion and conflicts of interest, work together to resolve dilemmas or find proofs, or simply to inform each other of pertinent facts. Many of these communicate requirements cannot be fulfilled by the exchange of single messages. Instead, the agents concerned need to be able to exchange a sequence of messages which all bear upon the same subject. In other words they need the ability to engage in dialogues.</p><p>As a result of this requirement, there has been much work on providing agents with the ability to hold such dialogues. Typically these focus on one type of dialogue, often negotiation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>. Recently, Reed <ref type="bibr" target="#b16">[17]</ref> has suggested a general approach which can capture a range of dialogue types, grounded on work in argumentation theory. Here we build on Reed's work by showing in detail how it is possible to carry out this range of types of dialogues. We take a system of argumentation developed to handle inconsistent information, use this to build a formal model of dialogue, and then show that the latter is general enough to capture the types of dialogue discussed by Reed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The argumentation model</head><p>In this section we briefly introduce the system of argumentation which forms the backbone of our approach. This is inspired by the work of Dung <ref type="bibr" target="#b6">[7]</ref> but goes further in dealing with preferences between arguments. Further details are available in <ref type="bibr" target="#b0">[1]</ref>. We start with a possibly inconsistent knowledge base with no deductive closure. We assume contains formulas of a propositional langage ¡ . ¢ stands for classical inference and £ for logical equivalence. Definition 1 An argument is a pair ¤ H ¥ h¦ where h is a for- mula of ¡ and H a subset of such that i) H is consistent, ii) H ¢ h and iii) H is minimal, so no subset of H satisfying both i) and ii) exists. H is called the support of the argument and h is its conclusion.</p><p>In general, since is inconsistent, arguments in § ¨¤ ¦ , the set of all arguments which can be made from , will conflict, and we make this idea precise with the notion of undercutting: Definition 2 Let ¤ H© ¥ h© ¦ and ¤ H ¥ h ¦ be two arguments of § ¨¤ ¦ . ¤ H© ¥ h© ¦ undercuts ¤ H ¥ h ¦ iff h H such that h £ h© . In other words, an argument is undercut iff there exists an argument for the negation of an element of its support.</p><p>To capture the fact that some facts are more strongly believed (or desired, or intended, depending on the nature of the facts) we assume that any set of facts has a preference order over it. We suppose that this ordering derives from the fact that the knowledge base is stratified into nonoverlapping sets © ¥ ! " ! !¥ n such that facts in i are all equally preferred and are more preferred than those in j where j # i. The preference level of a nonempty subset H of , level¤ H¦ , is the number of the highest numbered layer which has a member in H. </p><formula xml:id="formula_0">Definition 3 Let ¤ H© ¥ h© ¦ and ¤ H ¥ h "¦ be two arguments in § ¨¤ ¦ . ¤ H© ¥ h© ¦ is preferred to ¤ H ¥ h "¦</formula><formula xml:id="formula_1">¤ © a ¥ a ¦ Pref ¤ © a¥ a b ¥ b¦ .</formula><p>We can now define the argumentation system we will use: Henceforth, C Undercut % Pref will gather all non-undercut ar- guments and arguments defending themselves against all their undercutting arguments. In <ref type="bibr" target="#b1">[2]</ref>, it was shown that the set $ of acceptable arguments of the argumentation system § ¨¤ ¦ ¥ Undercut¥ Pref is the least fixpoint of a function &amp; :</p><formula xml:id="formula_2">Definition 4 An argumentation system (AS) is a triple § ¨¤ ¦ ¥ Undercut¥ Pref such that § ¨¤ ¦ is a set</formula><formula xml:id="formula_3">$ § ¨¤ ¦ &amp; ¤ $ ¦ ¢ © ¤ H ¥ h¦ § ¤ ¦ (' ¤ H ¥ h¦ 0) 21 ¦3 54 76 84 @9 A3 54 B3 DC FE $ Definition 6</formula><p>The set of acceptable arguments for an argu- </p><formula xml:id="formula_4">mentation system § ¨¤ ¦ ¥ Undercut¥ Pref is: $ ¢ G &amp; iH "I ¤ QP ¦ ¢ C Undercut % Pref ¤ SR G &amp; iH © ¤ C Undercut % Pref ¦ UT</formula><formula xml:id="formula_5">Theorem 1 W ¤ H ¥ h¦ $ ¥ $ strictly defends ¤ H ¥ h¦ .</formula><p>The proof of this theorem can be found in <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proof Theory</head><p>In practice we don't need to calculate all the acceptable arguments from some in order to know the status of a given argument. This can be exploited to give a proof theory for the system <ref type="bibr" target="#b0">[1]</ref>. The proof theory takes the form of a game between two players P I and P© . Player P I makes the argument we are interested in and its defenders, and player P© makes the counter-arguments or defeaters.</p><p>The basic idea behind the proof theory is to traverse the sequence &amp; © ¥ " ¥ X&amp; n in reverse. Consider that A occurs for the first time in &amp; n . We start with A, and then for any argu- ment B i which strongly undercuts A, we find an argument A i in &amp; n Y © which defends A. Now, because of Theorem<ref type="foot" target="#foot_0">1</ref>, we are only interested in the strict defenders of an argument, and the strict defenders of A will disqualify the B i . The same process is repeated for each strict defender until there is no strict defender or defeater. This leads to the idea of the argument dialogue:  An argument dialogue tree is a finite tree where each branch is an argument dialogue.</p><formula xml:id="formula_6">Example 3 Let § ¥ R¥ Pref be an AS such that § ¢ © a I ¥ a I © ¥ a I ¥ a© I ¥ a© © ¥ a© , and Undercut ¢ © ¤ a© I ¥ a I ¦ ¥ ¤ a I © ¥ a© I ¦ ¥ ¤ a© ¥ a I ¦ ¥ "¤ a I ¥ a© I ¦ ¥ ¤ a I § ¥ a© © ¦ ¥ "¤ a© © ¥ a I ¦ . Let's suppose a I § Pref a© © Pref a I a I © Pref a© I Pref a I</formula><p>and a© Pref a I Pref a© I We are interested in the status of the argument a I . The cor- responding argument dialogue tree is presented in Figure <ref type="figure">1</ref>.</p><p>The dialogue tree can be considered as an AND/OR tree.</p><p>A node corresponding to player P I is an AND node, and a node corresponding to player P© is an OR node. That distinction between nodes is due to the fact that an argument is acceptable if it is defended against all its defeaters. The edges of a node containing an argument of P I represent de- featers so they all must be defeated. In contrast, the edges of a node containing an argument from P© represent defenders of P I so it is sufficient that one of them defeats the argument of P© .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 9 A player wins an argument dialogue iff he ends the dialogue (he makes the last argument).</head><p>A player who wins a dialogue does not necessarily win in all the sub-trees of the dialogue tree. To formalize the winning of a dialogue tree we use the concept of a solution sub-tree.</p><p>Definition 10 A candidate sub-tree is a sub-tree of an argument dialogue tree containing all the edges of each AND node and exactly one edge of each OR node. A solution subtree is a candidate sub-tree whose branches are all won by P I .</p><p>Thus the dialogue represented in Example 3 has exactly two candidate sub-trees: S© and S in Figure <ref type="figure" target="#fig_1">2</ref>. sponding dialogue tree has a solution sub-tree.</p><p>Thus P I wins the dialogue presented in Figure <ref type="figure">1</ref> because S is a solution sub-tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 12</head><p>An argument A is justified iff there is an argument dialogue tree whose root is A, and which is won by player P I . Thus the argument a I is justified because the player P I won the dialogue tree. The main result from the proof theory is:</p><formula xml:id="formula_7">Theorem 2 Let § ¥ R¥ Pref be an argumentation system. ¡ W x § , if</formula><p>x is justified then each argument made by P I which belongs to the solution sub-tree is in $ , in particular x.</p><formula xml:id="formula_8">¡ W x $ , x is justified.</formula><p>The proof may be found in <ref type="bibr" target="#b0">[1]</ref>.</p><p>In other words, the dialogue process constructs all acceptable arguments, and only constructs acceptable arguments. Thus Theorem 2 is a form of soundness and completeness result for the proof theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Arguments and dialogue games</head><p>Dialogue games are way of formally analysing discourse <ref type="bibr" target="#b5">[6]</ref>. A dialogue between two individuals is seen as a game in which each individual has objectives and a set of legal moves which can be used to obtain those objectives. The moves are illocutions, and the objectives are matters such as persuading the other player of the truth of a proposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dialogues in DC</head><p>One rather influential dialogue game is DC, proposed by MacKenzie <ref type="bibr" target="#b8">[9]</ref> 2 in the course of analysing the fallacy of question-begging. DC provides a set of rules for arguing about the truth of a proposition. Each player has the goal of convincing the other, and can assert or retract facts, challenge the other player's assertions, ask whether something is true or not, and demand that inconsistencies be resolved. Associated with each player is a "commitment store", which holds the statements players have made and the challenges they have issued. There are then rules which define how the commitment stores are updated and whether particular illocutions can be uttered at a particular time.</p><p>While DC is interesting in its own right, what is more interesting from the point of view of this paper is that DC ties in very neatly with the system of argumentation descibed above. As detailed in <ref type="bibr" target="#b2">[3]</ref>, it is possible to formulate the dialogue rules in terms of the arguments that each player can construct. This, gives an operational semantics to the system and, given an implementation of the argumentation system, makes it possible to build systems that can carry out DC-type dialogues. One reason we might want to do this, is to use these DC-style dialogues as the basis of communications between agents in a multi-agent system, and the rest of this paper explores some of the issues in doing so.</p><p>Dialogues are assumed to take place between two agents, P and C, where P is arguing "pro" some proposition, and C argues "con". Each player has a knowledge base, P and C respectively, containing their beliefs. In addition, and as in DC, we suppose that each player has a further knowledge base, accessible to both players, containing commitments made in the dialogue. These commitment stores are denoted CS ¤ P¦ and CS ¤ C¦ respectively. Note that the union of the commitment stores can be viewed as the state of the dialogue at turn t. All the bases described contain propositional formulas and are not closed under deduction, and all are stratified according to degree of belief as discussed above. Here we assume that these degrees of belief are static and that both the players agree on them, though it is possible <ref type="bibr" target="#b3">[4]</ref> to combine different sets of degrees of belief, and it is also possible to have agents modify their beliefs on the basis of the reliability of their acquaintances <ref type="bibr" target="#b12">[13]</ref>.</p><p>Both players are equipped with an argumentation system of the kind discussed above. Each has access to their own private knowledge base and both commitment stores. Thus Player P plays with § ¨¤ P ¤ CS ¤ P¦ ¤ CS ¤ C¦ ¦ ¥ Undercut¥ Pref and player C with § ¨¤ C ¤ CS ¤ C¦ ¤ CS¤ P¦ ¥ Undercut¥ Pref . The two argumentation systems are then used to help players to maintain the coherence of their beliefs <ref type="foot" target="#foot_2">3</ref> , and thus to avoid asserting things which are defeated by other knowledge from CS ¤ P¦ ¤ CS¤ C¦ , and which could thus easily be undercut by the other player. In this sense the argumentation systems help to ensure that players are rational.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The dialogue moves</head><p>With this background, we can present the set of dialogue moves that we will use. These are not an exact facsimile of the moves in DC-we omit those illocutions we have not found useful (in particular the retraction rules) and add a move for explicit acknowledgment. For each move, we give what we call rationality rules, dialogue rules, and update rules. These are based on the rules suggested by <ref type="bibr" target="#b9">[10]</ref>. The rationality rules specify the preconditions for playing the move. The update rules specify how commitment stores are modified by the move. The dialogue rules specify the moves the other player can make next, and so specify the protocol under which the dialogue takes place.</p><p>In the following, player P adresses the move to player C. We start with the assertion of facts: assert(p) where p is a propositional formula. rationality the player uses its AS to check if there is an acceptable argument for the fact p.</p><p>dialogue the other player can respond with:</p><formula xml:id="formula_9">1. accept ¤ p¦ , 2. assert ¤ p¦ , 3. challenge¤ p¦ . update CS i ¤ P¦ ¢ CS iY © ¤ P¦ ¤ © p and CS i ¤ C¦ ¢ CS iY © ¤ C¦ assert(S)</formula><p>where S is a set of formulas representing the support of an argument. Note that in DC, players can only assert one propositional formula.</p><p>rationality the player uses the AS to check if the related argument is acceptable.</p><p>dialogue the other player can play:</p><p>1. accept ¤ S¦ , 2. assert ¤ p¦ , 3. challenge¤ p¦ where p S.</p><p>Informally, this means that the player can accept the whole support or challenge/deny an element of the support.</p><formula xml:id="formula_10">update CS i ¤ P¦ ¢ CS iY © ¤ S and CS i ¤ C¦ ¢ CS iY © ¤ C¦</formula><p>The conditions on assertion only allow agents to assert facts which it believes, on the basis of its private knowledge and all the public knowledge, cannot be challenged. The counterpart of these moves are the acceptance moves: accept(p) p is a propositional formula. This move has no equivalent in DC where acceptance is implicit.</p><p>rationality the player uses the AS to check if there is an acceptable argument for p.</p><p>dialogue the other player can play any allowed moves. </p><formula xml:id="formula_11">update CS i ¤ P¦ ¢ CS iY © ¤ P¦ ¤ © p and CS i ¤ C¦ ¢ CS i Y © ¤ C¦ accept(S)</formula><formula xml:id="formula_12">update CS i ¤ P¦ ¢ CS i Y © ¤ P¦ and CS i ¤ C¦ ¢ CS i Y © ¤ C¦</formula><p>A challenge is a means of making the other player explicitly state the argument supporting a proposition. In contrast, a question can be used to query the other player about any proposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>question(p)</head><p>where p is a propositional formula. rationality P dialogue the other player can:</p><formula xml:id="formula_13">1. assert ¤ p¦ , 2. assert ¤ p¦ , 3. question¤ q¦ . update CS i ¤ P¦ ¢ CS i Y © ¤ P¦ and CS i ¤ C¦ ¢ CS i Y © ¤ C¦</formula><p>We refer to this set of moves as the set ¢¡ ¤£ . These are similar to those discussed in legal reasoning <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">How the moves make a dialogue</head><p>The basic kind of dialogue which this system allows us to model is that in which one agent believes p and the other believes p. The private aim of each agent is then simply to offer arguments in support of their thesis. In our model, this means that one agent has an acceptable argument in favour of p in its argumentation system and the other agent has an acceptable one in favour of p. The agents then exchange arguments (defeaters) in an attempt to find an acceptable argument for whichever of p and p they started believing.</p><p>In this dialogue, P has an acceptable argument ¤ S¥ p¦ in favour of p, which it advances. This argument is built using private information, and, because C does have access to it, C does not have an acceptable argument for p and so cannot accept the proposition. Instead C has an acceptable argument ¤ S¥ ¥ p¦ in favour of p, and it asserts p. P responds to this assertion by challenging p, and C rises to the challenge by asserting its support S¥ for p. This dialogue process is continued, for example by P challenging one of the steps in S¥ , until there are no further arguments relating to p, p, S, and S¥ . This is the case when the two argumentation frameworks:</p><formula xml:id="formula_14">§ ¨¤ P ¤ CS ¤ P¦ ¤ CS¤ C¦ ¦ ¥ Undercut¥ Pref and § ¨¤ C ¤ CS ¤ P¦ ¤ CS ¤ C¦ ¦ ¥ Undercut¥ Pref</formula><p>provide the same acceptable argument and the agents, perforce, agree. Thus the agents have resolved their initial conflict of opinions about the acceptability of p. If the agents do not agree, then they are able to make further arguments and keep the dialogue going.</p><p>As mentioned above, the rationality rules and dialogue rules together provide a form of protocol for carrying out these DC-style dialogues. The rationality rules tie the illocutions which can be made quite closely to the information that the agents have at their disposal. The fact that it is only possible for an agent to assert things for which it has an acceptable argument, and to only accept things for which it has an acceptable argument means that Theorem 2 can be carried forward to ensure the soundness of the dialogue. In particular we can prove: Note that this result does mean that agents have to tell the truth; they can lie as long as their mechanism for generating untruths allows suitable acceptable arguments to be generated. Despite this result, the protocol defined by the dialogue rules will only work under certain assumptions. In fact, without these assumptions it can easily descend into meaningless babble. For example, there is no reason why agents should not, under the protocol, carry out infinite dialogues which consist entirely of "accept" illocutions or repeated challenges of the same proposition. The assumptions that the protocol works under are, broadly speaking, equivalent to the usual Gricean maxim of relevance. We assume that agents have a focus to their dialogue and restrict their illocutions to those which address that focus, engage in one for a concrete reason (for example to persuade one to change its mind about giving up a resource) not simply for the sake of it, and both recognise when they have reached the useful end of a dialogue (even if it is a case where neither has persuaded the other) and stop when this point has been reached. In practice, we see these assumptions being enforced by the fact that agents engaging in these kind of dialogues will be part of some kind of electronic institution <ref type="bibr" target="#b11">[12]</ref> which commits them to certain rules of behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3 Given two players P, with AS P ¢ § ¨¤</head><formula xml:id="formula_15">P ¤ CS¤ P¦ ¤ CS¤ C¦ ¦ ¥ Undercut¥ Pref , and C with AS C ¢ § ¨¤ P ¤ CS¤ P¦ ¤ CS ¤ C¦ ¦ ¥ Undercut¥ Pref ,</formula><p>For now we leave the formalisation of these points for future work. Instead we consider how the basic dialogue moves can be used to capture different types of dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Different types of dialogue</head><p>As mentioned by Parsons et al. <ref type="bibr" target="#b14">[15]</ref> and discussed in detail by Reed <ref type="bibr" target="#b16">[17]</ref>, Walton and Krabbe <ref type="bibr" target="#b20">[21]</ref> have identified a set of types of dialogue, distinguished by initial situation, goal of participants, and goal of dialogue. These are summarised in Table <ref type="table" target="#tab_5">1</ref>. In this section we discuss how these types of dialogue may be captured in our model of DC. We deal first with persuasion, inquiry and information seeking, which can be captured by our model of DC directly.</p><p>A persuasion dialogue, according to Walton and Krabbe, is initiated from a position of conflict in which one agent believes p and the other believes p, and both try to persuade the other to change its mind. The dialogue continues until the dispute is resolved. This is clearly the kind of dialogue discussed in the previous section, and can therefore easily be captured in our system.</p><p>An inquiry dialogue does not start from conflict but from a lack of knowledge. The two agents will try to establish the truth or falsity of some proposition p and the dialogue will end when either this has been acheived or they realise they cannot find a proof. In our model this corresponds to the situation in which neither agent has an acceptable argument for p. In other words, the initial situation is that neither:</p><formula xml:id="formula_16">§ ¨¤ P ¤ CS ¤ P¦ ¤ CS¤ C¦ ¦ ¥ Undercut¥ Pref nor § ¨¤ C ¤ CS ¤ P¦ ¤ CS ¤ C¦ ¦ ¥ Undercut¥ Pref</formula><p>can provide an acceptable argument for p. The agents then engage in a DC dialogue with the aim of determining whether the system § ¤ P ¤ C ¤ CS¤ P¦ ¤ CS ¤ C¦ ¦ ¥ Undercut¥ Pref can provide an acceptable argument for p. The dialogue, during which both agents reveal information by asserting it into their commitment store, will continue until either an acceptable argument for p is found, or it is not possible to make any further arguments which are related to p. This achieves the aim of the inquiry dialogue. Thus, although DC has its roots in adversarial dialogue, the moves ¦¡ ¤£ can be used in a non-adversarial way. Information seeking dialogues are similar to inquiries, but differ in their initial conditions. An information seeking dialogue is initiated when there is an asymmetry between the agents in the sense that one is thought by the other to have more information in regard to p, for instance because one agent is a recognised authority on the subject. In our model this kind of dialogue is initiated with a question move, asking if it is the case that p holds. If the other agent has an argument for or against p it will assert this, and the agents will then argue about its acceptability. However the argument is resolved, this exchange of information achieves the aim of the information seeking dialogue. Table <ref type="table" target="#tab_6">2</ref> summarises the initial conditions for these three types of dialogue in our framework, and highlights the differences between them. This table, and our previous discussion allow us to prove:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4 The set of moves</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¡ ¤£ is sufficient to model persuasion, inquiry and information seeking dialogues.</head><p>The two remaining dialogues are slightly different. As discussed in <ref type="bibr" target="#b14">[15]</ref>, negotiation centres around conflicts between the intentions of agents-it is concerned with what agents intend to achieve. Thus to have a negotiation dialogue in our framework it is first necessary to extend the language in which the dialogue is carried out to distinguish between the beliefs which are the subject of persuasion, information seeking and inquiry dialogues and the intentions which are the subject of negotiations. The change to the language then necessitates some minor changes to the argumentation system (essentially defining which arguments undercut which others). This may be done in exactly the same was as in <ref type="bibr" target="#b14">[15]</ref>, and afterwards negotiation dialogues have exactly the same form as persuasion dialogues but concern intentions rather than beliefs. In other words, they arise from a conflict in intentions, proceed through agents making arguments about intentions, and terminate when the agents agree on an acceptable argument for the intention in question.</p><p>A deliberation dialogue represents the process of forming a plan of action, and thus is also concerned with intentions (since an agent's intentions precisely deal with its plans of action). The joint aim of a deliberation is to reach an agreement on a plan (a joint intention or a pair of individual intentions), and the individual aims are to influence this agreement to their benefit (to ensure that the intentions are in their favour). Thus the joint aims can be considered to be establishing an acceptable argument for the joint or individual intentions <ref type="foot" target="#foot_3">4</ref> , and the individual aims are satisfied by the fact that this is acceptable to both agents. Note that deliberation starts not from a point of conflict but simply from a need for action, in exactly the same way that an inquiry dialogue starts, and, once the underlying language is extended to deal with intentions, precisely the same process can be followed as outlined above for the inquiry dialogue.</p><p>This discussion leads us to believe that ¡ ¤£ will be suitable as a basis for negotiation and deliberation dialogues. However to properly capture such dialogues ¡ ¤£ needs to be augmented, in particular to model compromises, and in <ref type="bibr" target="#b4">[5]</ref> we discuss how to do this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we have presented a model for inter-agent dialogues based on argumentation. We believe that this dialogue model goes further than previous attempts based on argumentation. In particular, it is a more general model than that presented in <ref type="bibr" target="#b14">[15]</ref>, and has a precisely defined protocol for the exchange of arguments which the former lacks (since <ref type="bibr" target="#b14">[15]</ref> concentrates more on the interaction between beliefs and intentions in a specific negotiation/deliberation form of dialogue). Our model also extends the suggestion made by Reed <ref type="bibr" target="#b16">[17]</ref> by making Reed's suggestion more concreteproviding an underlying argumentation system and the illocutions necessary to carry out the kinds of dialogues Reed discusses. Thus this work can be seen as an attempt to bridge the gap between the low level detail of handling beliefs and intentions described in <ref type="bibr" target="#b14">[15]</ref> and the general approach of <ref type="bibr" target="#b16">[17]</ref>. This was certainly our motivation in undertaking this work and, though it should be acknowledged that more work is required to combine the approaches, we feel it makes significant progress towards achieving this aim.</p><p>The most obvious thing we need to do now is to extend the underlying argumentation system to handle mental attitudes, in particular beliefs, desires and intentions. As argued above, this is an important step towards capturing negotiation and deliberation dialogues, though taking the approach of <ref type="bibr" target="#b14">[15]</ref> it should be straightforward. Another obvious thing is to extend the mechanism to deal with multiparty dialogues possibly through the use of agoras <ref type="bibr" target="#b10">[11]</ref>.</p><p>Other important points relate to how this work on dialogue connects with wider issues of agent communication. One such issue is what strategy an agent uses to pick which argument to put forward. One simple idea would be to choose the smallest argument in order to restrict the exposure to defeaters, but there are other aspects which might equally play a part. Another issue is how the argumentation protocol we have discussed connects with the protocol for the communication exchange in which the argumentation is embeddedif we assume that agents use argumentation for part of their communication (as for example in <ref type="bibr" target="#b17">[18]</ref>) then agents need to know when to engage in argumentation and when to stop. Finally, we need to define the kinds of electronic institutions within which agents can engage in argumentative dialogues.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 . An argument dialogue tree 5 .</head><label>15</label><figDesc>Figure 1. An argument dialogue tree 5. If Player i ¢ P© then Arg i attacks Arg i Y © .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Sub-trees</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>according to Pref iff level¤ H© ¦ ¡ level¤ H ¦ . Example 1 Let £¢ © ¥¤ ¦¤ ¨ § with © ¢ © a ¥ ¢ © a¥ a b and § ¢ © b . Now, ¤ © a ¥ a¦ and ¤ © a¥ a b ¥ b¦ are two arguments of § ¨¤ ¦ . The argument ¤ © a ¥ a¦ undercuts ¤ ©</figDesc><table><row><cell>a¥ a b ¥ b¦ . The preference level a¥ a b is 2 whereas the preference level of © a is of ©</cell></row><row><cell>1, and so</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>of the ar- guments built from , Undercut is a binary relation representing defeat relationship between arguments, Undercut § ¨¤ ¦ "! § ¨¤ ¦ , and Pref is a (partial or complete) preorder- ing on § ¨¤ ¦ #! § ¨¤ ¦ .</figDesc><table><row><cell>which</cell></row><row><cell>strongly undercuts every argument B where B under-</cell></row><row><cell>cuts A and A cannot defend itself against B.</cell></row></table><note><p><p><p><p><p>Pref stands for the strict pre-order associated with Pref .</p>The preference order makes it possible to distinguish different types of relation between arguments:</p>Definition 5 Let A, B be two arguments of § ¨¤ ¦ . B strongly undercuts A iff B undercuts A and it is not</p>the case that A Pref B. If B undercuts A then A defends itself against B iff A Pref B. $</p>defends A if there is some argument in $</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>¥ b¦ is undercut by ¤ © a¥ a b ¥ b¦ and does not defend itself. On the contrary, ¤ © a ¥ a¦ un- dercuts ¤ © a¥ a b ¥ b¦ and ¤ © a ¥ a¦ V Pref ¤ © a¥ a b ¥ b¦ . Therefore, C Undercut % Pref defends ¤ © b ¥ b¦ and con- sequently ¤ © b ¥ b¦ $</figDesc><table><row><cell>preferred (according to Pref ) to the unique undercutting ar-gument ¤ © a ¥ a¦ . Consequently, ¤ © a ¥ a¦ is in $ . The argument ¤ © b .</cell></row><row><cell>The set of acceptable arguments mutually defend one an-</cell></row><row><cell>other: Definition 7 Let A, B be two arguments of  § ¨¤ ¦ and $  § ¨¤ ¦ , then A disqualifies B iff A strongly undercuts B and B does not strongly undercut A. $ strictly defends A iff for all B such that B strongly undercuts A, then there is a C $</cell></row><row><cell>such that C disqualifies B.</cell></row><row><cell>An argument is acceptable if it is a member of the accept-</cell></row><row><cell>able set.</cell></row><row><cell>Example 2 (follows Example 1) The argument ¤ © a ¥ a¦ is in C Undercut % Pref because it is</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>S is a set of propositional formulas. P¦ ¢ CS i Y © ¤ P¦ ¤ S and CS i ¤ C¦ ¢ CS i Y © ¤ C¦Thus a player can only accept something if it is not possible to build a stronger argument against it.</figDesc><table><row><cell>rationality the player uses his AS to check if</cell></row><row><cell>each element of S is supported by an accept-</cell></row><row><cell>able argument.</cell></row><row><cell>dialogue the other player can play any allowed</cell></row><row><cell>move.</cell></row><row><cell>update CS i ¤</cell></row></table><note><p><p>challenge(p)</p>where p is a propositional formula. rationality P dialogue the other player can only assert ¤ S¦ where S is an argument supportting p.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 . Walton and Krabbe's classification of dialogues</head><label>1</label><figDesc></figDesc><table><row><cell>which play a</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 . Initial conditions for different types of dialogue about p</head><label>2</label><figDesc>S¥ p¦ A¤P ¤ CS¤ P¦ ¤ CS ¤ C¦ ¦ ¤ S¥ p¦ S C</figDesc><table><row><cell>Dialogue type Agent P Persuasion ¤ S¥ p¦ S P Inquiry c ¤ S¥ p¦ S P Info-seeking c ¤</cell><cell>Agent C ¤ S¥ p¦ S C c ¤ S¥ p¦ S C</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In<ref type="bibr" target="#b0">[1]</ref> this is called simply a "dialogue"; here we use the term "argument dialogue" to dinstinguish these dialogues from those discussed later in the paper. We will omit the term "argument" when it is clear that we mean an argument dialogue.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Though he describes is as a "dialectical system" rather than a dialogue game.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that the players' data is allowed to be inconsistent in the classical sense, since the argumentation system can handle inconsistency.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Thus we agree withReed [17]  that the dialogue in<ref type="bibr" target="#b14">[15]</ref> has elements of deliberation as well as negotiation.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Contribution a l&apos;integration des préferences dans le raisonnement argumentatif</title>
		<author>
			<persName><forename type="first">L</forename><surname>Amgoud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-07">July 1999</date>
			<pubPlace>Toulouse</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Université Paul Sabatier</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the acceptability of arguments in preference-based argumentation framework</title>
		<author>
			<persName><forename type="first">L</forename><surname>Amgoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cayrol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 14th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Towards a dialogue system based on argumentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Amgoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maudet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Department of Electronic Engineering, Queen Mary and Westfield College</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An argumentation framework for merging conflicting knowledge bases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Amgoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parsons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Department of Electronic Engineering, Queen Mary and Westfield College</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Arguments, dialogue, and negotiation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Amgoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maudet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th European Conference on Artificial Intelligence</title>
		<meeting>the 14th European Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Dialogue games: an approach to discourse analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Carlson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>D. Reidel Publishing company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games. Artificial Intelligence</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Dung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="321" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The pleadings game. Artificial Intelligence and Law</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Gordon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="239" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Question-begging in non-cumulative systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mackenzie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of philosophical logic</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="117" to="133" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A generic framework for dialogue game implementation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Maudet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Evrard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Formal Semantics and Pragmatics of Dialogue</title>
		<meeting>the 2nd Workshop on Formal Semantics and Pragmatics of Dialogue<address><addrLine>The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
		</imprint>
		<respStmt>
			<orgName>University of Twente</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Risk agoras: dialectical argumentation for scientific reasoning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mcburney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parsons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 16th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Agent mediated auctions: the fishmarket metaphor</title>
		<author>
			<persName><forename type="first">P</forename><surname>Noriega</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-12">December 1997</date>
		</imprint>
		<respStmt>
			<orgName>Universitat Autònoma de Barcelona, Bellaterra</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An approach to using degrees of belief in BDI agents</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Giorgini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information, Uncertainty, Fusion. Kluwer</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Bouchon-Meunier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Yager</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Negotiation through argumentation-a preliminary report</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Multi Agent Systems</title>
		<meeting>the 2nd International Conference on Multi Agent Systems</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Agents that reason and negotiate by arguing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic and Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="292" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Relating protocols for dynamic dispute with logics for defeasible argumentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Prakken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dialogue frames in agent communication</title>
		<author>
			<persName><forename type="first">C</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Multi Agent Systems</title>
		<meeting>the 3rd International Conference on Multi Agent Systems</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Parsons. A framework for argumentation-based negotiation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Noriega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Agent Theories, Architectures and Languages</title>
		<meeting>the 4th International Workshop on Agent Theories, Architectures and Languages</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="167" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Persuasive argumentation in negotiation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="203" to="242" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Negotiation and defeasible reasons for choice</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tohmé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Stanford Spring Symposium on Qualitative Preferences in Deliberation and Practical Reasoning</title>
		<meeting>the Stanford Spring Symposium on Qualitative Preferences in Deliberation and Practical Reasoning</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Commitment in Dialogue: Basic Concepts of Interpersonal Reasoning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C W</forename><surname>Krabbe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>State University of New York Press</publisher>
			<pubPlace>Albany, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
