<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scaling Genetic Algorithms using MapReduce</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abhishek</forename><surname>Verma</surname></persName>
							<email>verma7@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xavier</forename><surname>Llorà</surname></persName>
							<email>xllora@illinois.edu</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">National Center for Supercomputing Applications (NCSA)</orgName>
								<orgName type="department" key="dep2">Department of Industrial and Enterprise Systems Engineering</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<postCode>61801</postCode>
									<region>IL, US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Roy</forename><forename type="middle">H</forename><surname>Campbell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scaling Genetic Algorithms using MapReduce</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">68260B3A841EF318E9F57530927F8243</idno>
					<idno type="DOI">10.1109/ISDA.2009.181</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Genetic Algorithms</term>
					<term>MapReduce</term>
					<term>Scalability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Genetic algorithms(GAs) are increasingly being applied to large scale problems. The traditional MPI-based parallel GAs require detailed knowledge about machine architecture. On the other hand, MapReduce is a powerful abstraction proposed by Google for making scalable and fault tolerant applications. In this paper, we show how genetic algorithms can be modeled into the MapReduce model. We describe the algorithm design and implementation of GAs on Hadoop, an open source implementation of MapReduce. Our experiments demonstrate the convergence and scalability up to 10 5 variable problems. Adding more resources would enable us to solve even larger problems without any changes in the algorithms and implementation since we do not introduce any performance bottlenecks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The growth of the internet has pushed researchers from all disciplines to deal with volumes of information where the only viable path is to utilize data-intensive frameworks <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Genetic algorithms are increasingly being used for large scale problems like non-linear optimization <ref type="bibr" target="#b6">[7]</ref>, clustering <ref type="bibr" target="#b5">[6]</ref> and job scheduling <ref type="bibr" target="#b23">[24]</ref>. The inherent parallel nature of evolutionary algorithms makes them optimal candidates for parallelization <ref type="bibr" target="#b1">[2]</ref>. Although large bodies of research on parallelizing evolutionary computation algorithms are available <ref type="bibr" target="#b1">[2]</ref>, there has been little work done in exploring the usage of data-intensive computing <ref type="bibr" target="#b18">[19]</ref>.</p><p>The main contributions of the paper are as follows:</p><p>• We demonstrate a transformation of genetic algorithms into the map and reduce primitives • We implement the MapReduce program and demonstrate its scalability to large problem sizes.</p><p>The organization of the paper is as follows: We introduce the MapReduce model and its execution overview in Section II. Then, we discuss how genetic algorithms can be modeled using the MapReduce model in Section III and report our experiments in Section IV. In Section V, we discuss and compare with the related work and finally conclude with Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MAPREDUCE</head><p>Inspired by the map and reduce primitives present in functional languages, Google proposed the MapReduce <ref type="bibr" target="#b2">[3]</ref> abstraction that enables users to easily develop large-scale distributed applications. The associated implementation parallelizes large computations easily as each map function invocation is independent and uses re-execution as the primary mechanism of fault tolerance.</p><p>In this model, the computation inputs a set of key/value pairs, and produces a set of output key/value pairs. The user of the MapReduce library expresses the computation as two functions: Map and Reduce. Map, written by the user, takes an input pair and produces a set of intermediate key/value pairs. The MapReduce framework then groups together all intermediate values associated with the same intermediate key I and passes them to the Reduce function. The Reduce function, also written by the user, accepts an intermediate key I and a set of values for that key. It merges together these values to form a possibly smaller set of values. The intermediate values are supplied to the user's reduce function via an iterator. This allows the model to handle lists of values that are too large to fit in main memory.</p><p>Conceptually, the map and reduce functions supplied by the user have the following types:  partitioning function are specified by the user. Figure <ref type="figure" target="#fig_1">1</ref> shows the high level data flow of a MapReduce operation. Interested readers may refer to <ref type="bibr" target="#b2">[3]</ref> and Hadoop<ref type="foot" target="#foot_0">1</ref> for other implementation details. An accompanying distributed file system like GFS <ref type="bibr" target="#b7">[8]</ref> makes the data management scalable and fault tolerant.</p><formula xml:id="formula_0">map(k 1 , v 1 ) → list(k 2 , v 2 ) reduce(k 2 , list(v 2 )) → list(v 3 ) i.e.,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MAPREDUCING GAS</head><p>In this section, we start with a simple model of genetic algorithms and then transform and implement it using MapReduce along with a discussion of some of the elements that need to be taken into account. We encapsulate each iteration of the GA as a seperate MapReduce job. The client accepts the commandline parameters, creates the population and submits the MapReduce job.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Genetic Algorithms</head><p>Selecto-recombinative genetic algorithms <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, one of the simplest forms of GAs, mainly rely on the use of selection and recombination. We chose to start with them because they present a minimal set of operators that help us illustrate the creation of a data-intensive flow counterpart. The basic algorithm that we target to implement as a dataintensive flow can be summarized as follows:</p><p>1) Initialize the population with random individuals. 2) Evaluate the fitness value of the individuals.</p><p>3) Select good solutions by using s-wise tournament selection without replacement <ref type="bibr" target="#b11">[12]</ref>. 4) Create new individuals by recombining the selected population using uniform crossover<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b27">[28]</ref>. 5) Evaluate the fitness value of all offspring. 6) Repeat steps 3-5 until some convergence criteria are met.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Map</head><p>Evaluation of the fitness function for the population (Steps 2 and 5) matches the MAP function, which has to be computed independent of other instances. As shown in the algorithm in Algorithm 1, the MAP evaluates the fitness of the given individual. Also, it keeps track of the the best individual and finally, writes it to a global file in the Distributed File System (HDFS). The client, which has initiated the job, reads these values from all the mappers at the end of the MapReduce and checks if the convergence criteria has been satisfied. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Partitioner</head><p>If the selection operation in a GA (Step 3) is performed locally on each node, spatial constraints are artificially introduced and reduces the selection pressure <ref type="bibr" target="#b24">[25]</ref> and can lead to increase in the convergence time. Hence, decentralized and distributed selection algorithms <ref type="bibr" target="#b15">[16]</ref> are preferred. The only point in the MapReduce model at which there is a global communication is in the shuffle between the Map and Reduce. At the end of the Map phase, the MapReduce framework shuffles the key/value pairs to the reducers using the partitioner. The partitioner splits the intermediate key/value pairs among the reducers. The function GETPARTITION()  returns the reducer to which the given (key, value) should be sent to. In the default implementation, it uses HASH(key) % numReducers so that all the values corresponding to a given key end up at the same reducer which can then apply the REDUCE function. However, this does not suit the needs of genetic algorithms because of two reasons: Firstly, the HASH function partitions the namespace of the individuals N into r distinct classes : N 0 , N 1 , . . . , N r-1 where N i = {n : HASH(n) = i}. The individuals within each partition are isolated from all other partitions. Thus, the HASHPARTITIONER introduces an artificial spatial constraint based on the lower order bits. Because of this, the convergence of the genetic algorithm may take more iterations or it may never converge at all.</p><p>Secondly, as the genetic algorithm progresses, the same (close to optimal) individual begins to dominate the population. All copies of this individual will be sent to a single reducer which will get overloaded. Thus, the distribution progressively becomes more skewed, deviating from the uniform distribution (that would have maximized the usage of parallel processing). Finally, when the GA converges, all the individuals will be processed by that single reducer. Thus, the parallelism decreases as the GA converges and hence, it will take more iterations.</p><p>For these reasons, we override the default partitioner by providing our own partitioner, which shuffles individuals randomly across the different reducers as shown in Algorithm 2.</p><p>Algorithm 2 Random partitioner for GA int GETPARTITION(key, value, numReducers):</p><p>return RANDOMINT(0, numReducers -1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Reduce</head><p>We implement Tournament selection without replacement <ref type="bibr" target="#b8">[9]</ref>. A tournament is conducted among S randomly chosen individuals and the winner is selected. This process is repeated population number of times. Since randomly selecting individuals is equivalent to randomly shuffling all individuals and then processing them sequentially, our reduce function goes through the individuals sequentially. Initially the individuals are buffered for the last rounds, and when the tournament window is full, SELECTIONAND-CROSSOVER is carried out as shown in the Algorithm 3. When the crossover window is full, we use the Uniform Crossover operator. For our implementation, we set the S to 5 and crossover is performed using two consecutively selected parents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Optimizations</head><p>After initial experimentation, we noticed that for larger problem sizes, the serial initialization of the population takes a long time. According to Amdahl's law, the speedup is bounded because of this serial component. Hence, we create the initial population in a separate MapReduce phase, in which the MAP generates random individuals and the REDUCE is the Identity Reducer 3 . We seed the pseudorandom number generator for each mapper with mapper id• current time. The bits of the variables in the individual are compactly represented in an array of long long ints and we use efficient bit operations for crossover and fitness calculations. Due to the inability of expressing loops in 3 Setting the number of reducers to 0 in Hadoop removes the extra overhead of shuffling and identity reduction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head><p>The ONEMAX Problem <ref type="bibr" target="#b26">[27]</ref> (or BitCounting) is a simple problem consisting in maximizing the number of ones of a bitstring. Formally, this problem can be described as finding an string x = {x 1 , x 2 , . . . , x N }, with x i ∈ {0, 1}, that maximizes the following equation:</p><formula xml:id="formula_1">F ( x) = N i=1 x i (1)</formula><p>We implemented this simple problem on Hadoop (0.19)<ref type="foot" target="#foot_2">4</ref> and ran it on our 416 core (52 nodes) Hadoop cluster. Each  of HDFS is set to 3). A detailed description of the cluster setup can be found elsewhere 5 . Each node can run 5 mappers and 3 reducers in parallel. Some of the nodes, despite being fully functional, may be slowed down due to disk contention, network traffic, or extreme computation loads. Speculative execution is used to run the jobs assigned to these slow nodes, on idle nodes in parallel. Whichever node finishes first, writes the output and the other speculated jobs are killed. For each experiment, the population for the GA is set to n log n where n is the number of variables. We perform the following experiments: 1) Convergence Analysis: In this experiment, we monitor the progress in terms of the number of bits set to 1 by the GA for a 10 4 variable ONEMAX problem. As shown in Figure <ref type="figure" target="#fig_4">2</ref>, the GA converges in 220 iterations taking an average of 149 seconds per iteration. 2) Scalability with constant load per node: In this experiment, we keep the load set to 1,000 variables per mapper. As shown in Figure <ref type="figure" target="#fig_6">3</ref>, the time per iteration increases initially and then stabilizes around 75 seconds. Thus, increasing the problem size as more resources are added does not change the iteration time. Since, each node can run a maximum of 5 mappers, the overall map capacity is 5 • 52(nodes) = 260. Hence, around 250 mappers, the time per iteration increases due to the lack of resources to accommodate so many mappers. 3) Scalability with constant overall load: In this experiment, we keep the problem size fixed to 50,000 variables and increase the number of mappers. As shown in Figure <ref type="figure" target="#fig_7">4</ref>, the time per iteration decreases   Scalability of GA for ONEMAX problem with increasing number of variables as more and more mappers are added. Thus, adding more resources keeping the problem size fixed decreases the time per iteration. Again, saturation of the map capacity causes a slight increase in the time per iteration after 250 mappers. However, the overall speedup gets bounded by Amdahl's law introduced by Hadoop's overhead (around 10s of seconds to initiate and terminate a MapReduce job). However, as seen in the previous experiment, the MapReduce model is extremely useful to process large problems size, where extremely large populations are required. 4) Scalability with increasing the problem size: Here, we utilize the maximum resources and increase the number of variables. As shown in Figure <ref type="figure">5</ref>, our implementation scales to n = 10 5 variables, keeping the population set to n log n. Adding more nodes would enable us to scale to larger problem sizes. The time per iteration increases sharply as the number of variables is increased to n = 10 5 as the population increases super-linearly (n log n), which is more than 16 million individuals.</p><p>V. DISCUSSION OF RELATED WORK Several different models like fine grained <ref type="bibr" target="#b20">[21]</ref>, coarse grained <ref type="bibr" target="#b17">[18]</ref> and distributed models <ref type="bibr" target="#b16">[17]</ref> have been proposed for implementing parallel GAs. Traditionally, Message Passing Interface (MPI) has been used for implementing parallel GAs. However, MPIs do not scale well on commodity clusters where failure is the norm, not the exception. Generally, if a node in an MPI cluster fails, the whole program is restarted. In a large cluster, a machine is likely to fail during the execution of a long running program, and hence efficient fault tolerance is necessary. This forces the user to handle failures by using complex checkpointing techniques.</p><p>MapReduce <ref type="bibr" target="#b2">[3]</ref> is a programming model that enables the users to easily develop large-scale distributed applications. Hadoop is an open source implementation of the MapReduce model. Several different implementations of MapReduce have been developed for other architectures like Phoenix <ref type="bibr" target="#b22">[23]</ref> for multicores and CGL-MapReduce <ref type="bibr" target="#b3">[4]</ref> for streaming applications.</p><p>To the best of our knowledge, MRPGA <ref type="bibr" target="#b14">[15]</ref> is the only attempt at combining MapReduce and GAs. However, they claim that GAs cannot be directly expressed by MapReduce, extend the model to MapReduceReduce and offer their own implementation. We point out several shortcomings: Firstly, the Map function performs the fitness evaluation and the "ReduceReduce" does the local and global selection. However, the bulk of the work -mutation, crossover, evaluation of the convergence criteria and scheduling is carried out by a single co-ordinator. As shown by their results, this approach does not scale above 32 nodes due to the inherent serial component. Secondly, the "extension" that they propose can readily be implemented within the traditional MapReduce model. The local reduce is equivalent to and can be implemented within a Combiner <ref type="bibr" target="#b2">[3]</ref>. Finally, in their mapper, reducer and final reducer functions, they emit "def ault key" and 1 as their values. Thus, they do not use any characteristic of the MapReduce model -the grouping by keys or the shuffling. The Mappers and Reducers might as well be independently executing processes only communicating with the co-ordinator.</p><p>We take a different approach, trying to hammer the GAs to fit into the MapReduce model, rather than change the MapReduce model itself. We implement GAs in Hadoop, which is increasingly becoming the de-facto standard MapReduce implementation and used in several production environments in the industry. Meandre <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b18">[19]</ref> extends beyond some limitations of the MapReduce model while maintaining a data-intensive nature. It shows linear scalability of simple GAs and EDAs on multicore architectures. For very large problems (&gt; 10 9 variables), other models like compact genetic algorithms(cGA) and Extended cGA(eCGA) have been explored <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS AND FUTURE WORK</head><p>In this paper, we have mainly addressed the challenge of using the MapReduce model to scale genetic algorithms. We described the algorithm design and implementation of GAs on Hadoop. The convergence and scalability of the implementation has been investigated. Adding more resources would enable us to solve even larger problems without any changes in the algorithm implementation.</p><p>MapReducing more scalable GA models like compact GAs <ref type="bibr" target="#b13">[14]</ref> and extended compact GAs <ref type="bibr" target="#b12">[13]</ref> will be investigated in future. We also plan to compare the performance with existing MPI-based implementations. General Purpose GPUs are an exciting addition to the heterogenity of clusters. The compute intensive Map phase and the random number generation can be scheduled on the GPUs, which can be performed in parallel with the Reduce on the CPUs. We would also like to demonstrate the importance of scalable GAs in practical applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the input keys and values are drawn from a different domain than the output keys and values. Furthermore, the intermediate keys and values are from the same domain as the output keys and values. The Map invocations are distributed across multiple machines by automatically partitioning the input data into a set of M splits. The input splits can be processed in parallel by different machines. Reduce invocations are distributed by partitioning the intermediate key space into R pieces using a partitioning function, which is hash(key)%R according to the default Hadoop configuration (which we later override for our needs). The number of partitions (R) and the 2009 Ninth International Conference on Intelligent Systems Design and Applications 978-0-7695-3872-3 2009 U.S. Government Work Not Protected by U.S. Copyright DOI 10.1109/ISDA.2009.181</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. MapReduce Data flow overview</figDesc><graphic coords="2,68.32,70.72,214.60,145.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Map phase of each iteration of the GA MAP(key, value): individual ← INDIVIDUALREPRESENTATION(key) fitness ← CALCULATEFITNESS(individual) EMIT (individual, fitness) {Keep track of the current best} if fitness &gt; max then max ← fitness maxInd ← individual end if if all individuals have been processed then Write best individual to global file in DFS end if</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Convergence of GA for 10 4 variable ONEMAX problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>5 http://cloud.cs.illinois.edu</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Scalability of GA with constant load per node for ONEMAX problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Scalability of GA for 50, 000 variable ONEMAX problem with increasing number of mappers</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://hadoop.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We assume a crossover probability pc=1.0.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>http://hadoop.apache.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>We would like to thank the anonymous reviewers for their valuable feedback. This research was funded, in part, by NSF IIS Grant #0841765. The views expressed are those of the authors only.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Design of a framework for data-intensive wide-area applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Beynon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HCW &apos;00: Proceedings of the 9th Heterogeneous Computing Workshop</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Efficient and Accurate Parallel Genetic Algorithms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cantú-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mapreduce: Simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mapreduce for data intensive scientific analyses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ekanayake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pallickara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESCIENCE &apos;08: Proceedings of the 2008 Fourth IEEE International Conference on eScience</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="277" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The virtual data grid: A new model and architecture for data-intensive collaboration</title>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 15 th International Conference on Scientific and Statistical Database Management</title>
		<imprint>
			<biblScope unit="page" from="11" to="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Genetic algorithms for large scale clustering problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Frnti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kivijrvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kaukoranta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nevalainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. J</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="547" to="554" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Genetic algorithms: a powerful tool for large-scale nonlinear optimization problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sambridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Geosci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7-8</biblScope>
			<biblScope unit="page" from="1229" to="1236" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The google file system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gobioff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Messy genetic algorithms: motivation, analysis, and first results</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Korb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="493" to="530" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization, and machine learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The Design of Innovation: Lessons from and for Competent Genetic Algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Messy genetic algorithms: Motivation, analysis, and first results</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Korb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="493" to="530" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Linkage learning via probabilistic modeling in the ecga</title>
		<author>
			<persName><forename type="first">G</forename><surname>Harik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>University of Illinois at Urbana-Champaign)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The compact genetic algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Harik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Evolutionary Computation</title>
		<meeting>the IEEE International Conference on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="523" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mrpga: An extension of mapreduce for parallelizing genetic algorithms. eScience, 2008. eScience &apos;08</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vecchiola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Fourth International Conference on</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On decentralizing selection algorithms</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sarma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Genetic Algorithms</title>
		<meeting>the Sixth International Conference on Genetic Algorithms</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient hierarchical parallel genetic algorithms using grid computing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="658" to="670" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coarse-grain parallel genetic algorithms: Categorization and new approach</title>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Punch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeedings of the Sixth IEEE Symposium on Parallel and Distributed Processing</title>
		<meeting>eeedings of the Sixth IEEE Symposium on Parallel and Distributed essing</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="28" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data-intensive computing for competent genetic algorithms: a pilot study using meandre</title>
		<author>
			<persName><forename type="first">X</forename><surname>Llorà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO &apos;09: Proceedings of the 11th Annual conference on Genetic and evolutionary computation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1387" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Meandre: Semantic-driven data-intensive flows in the clouds</title>
		<author>
			<persName><forename type="first">X</forename><surname>Llorà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ács</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Auvil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Capitanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE International Conference on e-Science</title>
		<meeting>the 4th IEEE International Conference on e-Science</meeting>
		<imprint>
			<publisher>IEEE press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="238" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A fine-grained parallel genetic algorithm for distributed parallel systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Maruyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konagaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Genetic Algorithms</title>
		<meeting>the 5th International Conference on Genetic Algorithms<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="184" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A software architecture-based framework for highly distributed and data intensive scientific applications</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Mattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Medvidovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE &apos;06: Proceedings of the 28th international conference on Software engineering</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="721" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating mapreduce for multi-core and multiprocessor systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raghuraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Penmetsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE 13th International Symposium on High Performance Computer Architecture</title>
		<meeting>the 2007 IEEE 13th International Symposium on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2007-01">Jan 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Application of genetic algorithm to a large-scale scheduling problem for a metal mold assembly process</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sannomiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ashizawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th IEEE Conference on Decision and Control</title>
		<meeting>the 38th IEEE Conference on Decision and Control</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2288" to="2293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Selection pressure and performance in spatially distributed evolutionary</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Jong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Congress on Computatinal Intelligence</title>
		<meeting>the World Congress on Computatinal Intelligence</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="553" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards billionbit optimization via a parallel estimation of distribution algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Llora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO &apos;07: Proceedings of the 9th annual conference on Genetic and evolutionary computation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On Crossover as an Evolutionary Viable Strategy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eshelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Belew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Booker</surname></persName>
		</editor>
		<meeting>the 4th International Conference on Genetic Algorithms</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Uniform crossover in genetic algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sywerda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third international conference on Genetic algorithms</title>
		<meeting>the third international conference on Genetic algorithms<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="2" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A performance prediction framework for data intensive applications on large scale parallel machines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Uysal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Languages, Compilers and Run-time Systems for Scalable Computers</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the Fourth Workshop on Languages, Compilers and Run-time Systems for Scalable Computers</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="243" to="258" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
