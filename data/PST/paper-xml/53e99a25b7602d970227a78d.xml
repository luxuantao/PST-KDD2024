<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Facility Location: Distributed Approximation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Moscibroda</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Roger</forename><surname>Wattenhofer</surname></persName>
							<email>wattenhofer@tik.ee.ethz.ch</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering</orgName>
								<orgName type="laboratory">Networks Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>8092</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering</orgName>
								<orgName type="laboratory">Networks Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>8092</postCode>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<addrLine>Las Vegas</addrLine>
									<postCode>2005</postCode>
									<settlement>Nevada</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Facility Location: Distributed Approximation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">155B89F6516EDCD672A8E41001A88CC4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems-computations on discrete structures</term>
					<term>G.2.2 [Discrete Mathematics]: Graph Theory-graph algorithms</term>
					<term>G.2.2 [Discrete Mathematics]: Graph Theory-network problems Algorithms, Theory facility location, distributed approximation, linear programming, primal-dual algorithms</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we initiate the study of the approximability of the facility location problem in a distributed setting. In particular, we explore a trade-off between the amount of communication and the resulting approximation ratio. We give a distributed algorithm that, for every constant k, achieves an</p><p>communication rounds where message size is bounded to O(log n) bits. The number of facilities and clients are m and n, respectively, and ρ is a coefficient that depends on the cost values of the instance. Our technique is based on a distributed primal-dual approach for approximating a linear program, that does not form a covering or packing program.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>During the last few years, the study of distributed approximation has attracted a lot of attention and has resulted in several fundamental results that shed new light into the possibilities and limitations of distributed computing <ref type="bibr" target="#b5">[6]</ref>. The interest in distributed approximation appears natural considering that it lies on the boundary between two well-established and important areas in computer science: distributed computing and approximability. In the same way as the theory of approximation has lead to an understanding of principles in complexity theory, the study of distributed approximation has the potential of providing a deeper understanding of the underlying distributed models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>In this paper, we investigate the distributed approximability of one of the most studied problems in operations research and the theory of approximation, the facility location problem. In the facility location problem, there is a set of clients (a.k.a. cities or demands) and a set of possible server locations, called facilities. Every client must be connected to a facility that serves the client's demand. Opening a facility i causes opening costs f i and connecting a client j to an opened facility i incurs connection costs c ij . The goal is to open a subset of the facilities and connect each client to an opened facility in such a way that minimizes the sum of connection costs and opening costs.</p><p>The facility location problem captures a large variety of important application scenarios. Traditionally, it has been used to model the problem of finding the best geographic location for the construction of industrial facilities or warehouses. While this classic application can be satisfactorily solved by a centralized algorithm, there are numerous applications that explicitly demand for distributed algorithms. Consider for instance the problem of dynamically setting up servers or placing caches in the Internet for a certain application. Setting up a server at a host in the Internet incurs overhead, traffic, and maintenance costs at that particular host. On the other hand, every client demands to access its data from a server that is as close as possible in order to minimize its delay. The resulting trade-off between the number of servers to be installed and the propagation delay maps precisely to the facility location problem.</p><p>Another example comes from the world of battery powered wireless ad hoc and sensor networks that typically feature tight energy constraints. In this context, structuring the network into energy-efficient clusters plays a key role for prolonging the networks lifetime, e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref>. Only selected cluster-leaders must remain active, while all other nodes can go into an energy-efficient sleep mode thus saving valuable battery power. Again, the trade-off to be optimized follows along the same lines. It is desirable to have as few clusterleaders as possible since this in turn allows more nodes to go into sleep mode. However, having few cluster-heads naturally increases the distance between clusterheads and their associated nodes. This forces nodes to set their transmission power to higher values in order to reach their clusterhead.</p><p>In both of the above examples, centralized algorithms based on maintaining a global view of the network cannot be applied because no node in the network has total knowledge. In large-scale distributed Internet applications or wireless sensor networks, collecting and maintaining a global view of the network would cause a horrendous overhead in terms of both time and message complexity. Hence, nodes must come up with a solution in a distributed way.</p><p>The study of distributed approximation explores the tradeoff between the amount of communication between nodes in the network, and the quality of the global solution they achieve. Specifically, we want to be able to come up with an algorithm that gives a non-trivial approximation ratio for any (even constant!) number of communication rounds k. From a theoretical point of view, having such a complete characterization of the above mentioned trade-off yields a deeper understanding of the nature of the problem. Moreover, algorithms having a constant running time independent of the size of the problem instance are often the only acceptable choice in distributed settings. This is the case if either individual nodes do not know about the size of the entire solution or, as in the case of mobile wireless networks, low bandwidth and high dynamics preclude algorithms with high running time.</p><p>Our algorithm is based on approximating the LP relaxation of the facility location problem in a distributed way. In fact, it follows a kind of distributed primal-dual approach. Starting with a sub-optimal but feasible primal solution and an infeasible dual solution, the nodes successively increase the primal optimality and reduce the dual infeasibility. In a second step, the obtained fractional solution to the LP is then rounded in a distributed way to a feasible integer solution to the original facility location problem.</p><p>Initiated by Papadimitriou and Yannakakis in <ref type="bibr" target="#b22">[23]</ref>, the distributed approximation of linear programs has attracted the interest of researchers for some time, e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b15">16]</ref>. All of these papers consider the special class of covering or packing linear programs. The distributed complexity of more general linear programs has remained a long-standing open problem since <ref type="bibr" target="#b22">[23]</ref>. Moreover, of the above works, only <ref type="bibr" target="#b16">[17]</ref> gives a complete characterization of the communicationquality of the solution trade-off.</p><p>In contrast, in this paper, we take a step towards understanding a more general case of LPs by presenting a characterization for the facility location problem, which does not form a covering or packing pair of LPs. To the best of our knowledge, our paper is the first to provide a result on the distributed approximability of non-positive linear programs in a constant number of communication rounds. Specifically, we consider the classic bounded message size model in which every message is restricted to O(log n) bits and the ID space is assumed to be polynomial in n, e.g. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b19">20]</ref>. We present an algorithm that, for arbitrary positive integers k, in O(k) communication rounds, obtains an approximation ratio of O(</p><formula xml:id="formula_0">√ k(mρ) 1/ √ k log (m + n))</formula><p>, where m and n are the number of facilities and clients, respectively, and ρ is a parameter that depends on the coefficients of the given facility location instance. Furthermore, at the cost of a slightly worse approximation, it is possible to get rid of the dependency on ρ. This result shows that even in a constant number of communication rounds, the facility location problem can be approximated with a non-trivial approximation ratio.</p><p>The remainder of the paper is organized as follows. Section 2 gives an overview over related work and discusses the reasons why existing centralized solutions cannot be easily adapted to serve our needs. In Section 3, we introduce our model of computation and formally define the facility location problem and its linear program relaxation. The distributed approximation algorithm for the LP is presented and analyzed in subsequent Sections 4 and 5. We give a procedure for rounding the fractional LP solution to a feasible integer solution in Section 6. Section 7 generalizes the problem and shows how the dependency on ρ can be avoided. Subsequent Section 8 discusses an extension to the problem before Section 9 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Its wide applicability and appealing simplicity have rendered uncapacitated facility location one of the most wellstudied optimization problems in the literature <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4]</ref>. It has not only occupied a central place in operations research, but has recently attracted a lot of attention from the perspective of approximation theory <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>For the general non-metric case, Hochbaum <ref type="bibr" target="#b10">[11]</ref> showed that the greedy algorithm is an O(log n) approximation. Set cover being a special case of facility location, this is asymptotically optimal unless N P ⊆ DT IM E(n O(log log n) ) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b6">7]</ref>. The filtering technique introduced by Lin and Vitter <ref type="bibr" target="#b17">[18]</ref> yields another O(log n) approximation algorithm. In the metric facility location problem, it is assumed that the connection costs obey the triangle inequality. In that case, the problem remains NP-hard, but constant approximations become possible. The first algorithm achieving a constant approximation ratio was given in <ref type="bibr" target="#b26">[27]</ref>. Ever since, a flurry of research activity has lead to various improvements. Also, numerous variants of facility location have been studied, e.g. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>Considering the vast literature on the facility location problem, surprisingly little is known about the important distributed case. In a seminal paper, Jain and Vazirani <ref type="bibr" target="#b12">[13]</ref> claim that their primal-dual algorithm for the metric case of the facility location problem was also suitable in a distributed setting. However, this is only the case if either message-size is unbounded<ref type="foot" target="#foot_0">1</ref> , or the algorithm's timecomplexity depends on the size of the problem instance. That is, their primal-dual algorithm cannot be applied if the number of communication rounds is restricted to an arbitrary constant.</p><p>It is interesting to relate our work to the wider context of distributed approximation of linear programs. Starting from <ref type="bibr" target="#b22">[23]</ref>, there have been a number of efficient distributed algorithms for approximating covering and packing LPs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b16">17]</ref> and in <ref type="bibr" target="#b15">[16]</ref> a lower bound on the distributed timecomplexity of covering LPs is given. This multiplicity of results on covering and packing problems is in sharp contrast to the case of more general LPs, i.e., non-positive linear programs. For problems such as facility location, the achievable time-approximation trade-off has been an open question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MODEL</head><p>In the formal model, the facility location instance is represented by a complete bipartite graph G = (C ∪ F, E). C and F denote the set of clients and facilities, respectively. Let n = |C| and m = |F | denote the number of clients and facilities, respectively. The non-negative opening costs of facility i ∈ F are denoted by f i . The connection costs between facility i ∈ F and client j ∈ C are denoted by cij. Notice that we do not assume the connection costs cij to form a metric. In particular, c ij may be infinitely large. For ease of presentation, we make the assumption that c ij ≥ 1 and f i ≥ 1 for all i ∈ F, j ∈ C in Sections 4 and 5. We show how to deal with costs less than 1 in Section 7. Each client and facility has a distinct ID of size O(log n) bits.</p><p>We consider a classic message passing model (e.g. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>) in which a node can send a message of size O(log n) bits to each neighbor in every communication step. To simplify the presentation of the algorithm, we assume a synchronous communication model. In this model, the computation is assumed to advance in global rounds. In each round, each client can send a message to each facility, and each facility can send a message to each client. We emphasize that the algorithm works for the asynchronous model by applying an appropriate synchronizer <ref type="bibr" target="#b0">[1]</ref>. The time-complexity of an algorithm is the number of communication rounds needed by the algorithm.</p><p>Notice that even though we consider a complete bipartite graph, solving the facility location problem is not trivial. Due to the restriction in message size, any straightforward centralized approach fails to solve the problem. The most basic idea is to elect a leader v among the facilities and send the entire information about the specific problem instance to v . Using the standard greedy algorithm with an approximation ratio of log |F |, v could solve the instance and inform every facility about its decision. Unfortunately, such a simple centralized solution fails because shipping the entire information on the problem instance (i.e., nm connection costs and m facility costs) inherently requires time linear in the number of facilities, i.e., O(m). Hence, using more sophisticated and distributed techniques is inevitable for designing fast algorithms.</p><p>The facility location can be described as an integer linear program (ILP), where y i indicates if facility i is opened, and x ij indicates if client j is connected to the open facility i <ref type="bibr" target="#b1">[2]</ref>. By relaxing the integer constraints of the variables, we obtain the following integer linear program (LP).</p><formula xml:id="formula_1">min i∈F f i y i + i∈F j∈C c ij x ij i∈F x ij ≥ 1 , ∀j ∈ C y i -x ij ≥ 0 , ∀j ∈ C, i ∈ F xij, yi ∈ {0, 1} , ∀j ∈ C, i ∈ F</formula><p>The first constraint ensures that each client j ∈ C is assigned to some facility i ∈ F . The second constraint guarantees that a client j can be assigned only to an open facility i. As usual, we obtain the LP-relaxation by relaxing the integer constraints to y i ≥ 0 and x ij ≥ 0. The relaxed dual program (DLP) is:</p><formula xml:id="formula_2">max j∈C α j α j -β ij ≤ c ij , ∀j ∈ C, i ∈ F j∈C βij ≤ fi , ∀i ∈ F α j , β ij ≥ 0 , ∀j ∈ C, i ∈ F</formula><p>Notice that this primal and dual pair of LPs have negative coefficients and do not form a covering-packing pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ALGORITHM</head><p>The algorithm consists of two parts. First, the facilities and clients compute an approximate solution to the fractional linear program (LP), essentially following a distributed primal-dual approach. Throughout the algorithm, clients and facilities keep track of the value of their primal variables. Specifically, after O(k) communication rounds, the first phase of the algorithm ends with every facility having opening value y i and every client having connection values x ij to facilities. Note that while these values constitute a feasible solution to (LP), they may be fractional and can therefore not be used as a solution to the original facility location problem. Hence, a distributed randomized rounding method described in Section 6 then rounds these fractional values to values in {0, 1}, increasing the approximation ratio from the fractional solution only by a logarithmic factor. The technique of designing distributed approximation algorithms by first computing a fractional solution and rounding them in a second phase has been inspired by <ref type="bibr" target="#b16">[17]</ref>. Our algorithm combines these techniques with ideas from the centralized primal-dual approach in <ref type="bibr" target="#b12">[13]</ref>.</p><p>At the heart of our algorithm is the distributed primaldual technique which deterministically approximates (LP) within a constant number of communication rounds. Each facility and client executes Algorithm 1 and 2, respectively. The algorithms consist of two nested loops which are both executed h = √ k times. The number of communication rounds in each iteration of the inner loop is constant, yielding the claimed constant time-complexity of O(k). Initially, all primal and dual variables y i , x ij , α j , and β ij are set to zero. Hence, the initial primal solution is infeasible, and the dual solution is feasible, yet far from optimal. During the course of the algorithm, both the primal and dual variables are gradually increased, thereby decreasing the primal infeasibility, and increasing dual optimality. At the end of the h th iteration of the outer loop, the primal variables yi and x ij form a feasible solution to (LP).</p><p>A client j is called uncovered if it is not yet (fractionally) connected to one facility, i.e., i∈F x ij &lt; 1. At any moment throughout the algorithm, the set of uncovered clients is called the uncovered set A, initially A = C. Whenever a client j becomes covered, it sends a message M j to the facilities. That way, the facilities always have a consistent view of the current A (Lines 8 and 9 of the algorithm).</p><p>A star consists of one facility i ∈ F and several uncovered clients j ∈ A. The cost efficiency of a star B is the sum of the connection costs of the clients to facility i plus the facility cost f i divided by the number of clients |B|. The cost efficiency c(i) of a facility i is defined as the minimum star spanned from i, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>c(i) := min</head><formula xml:id="formula_3">B∈2 A f i + j∈B c ij |B| . (<label>1</label></formula><formula xml:id="formula_4">)</formula><p>The basic idea of the outer loop (s-loop) is to increase the y i value of facilities with comparatively good cost efficiency c(i) <ref type="foot" target="#foot_2">2</ref> . More precisely, we call a facility active in a given iteration if its cost efficiency is at most c(i) ≤ ρ s/h . Only active facilities, that is, only facilities with good cost efficiency will execute the code between lines 11 and 22. Particularly, only active facilities will increase their yi value during an iteration. The idea of increasing the yi value of facilities with good cost efficiency is inspired by the centralized greedy algorithm <ref type="bibr" target="#b10">[11]</ref> that iteratively picks the facility with the best cost efficiency. In order to come up with fast (and particularly constant time) algorithms in a distributed setting, this "greedy step" has to be parallelized. However, the greedy step's parallelization must be carefully implemented in order to avoid opening too many facilities at once, thus overly deteriorating the algorithm's performance.</p><p>We call a client j tight to an active facility i in iteration s of the outer loop if c ij ≤ ρ s/h . That is, the tight set T i in line 12 consists of all clients that are connected to i by a connection of cost at most ρ s/h . The significance of the tight set is that the increase of yi in a given iteration results in an identical increase of xij of all clients j being in the tight set T i . Since a client j may concurrently be in the tight set of several facilities, the increase of the different y i must be handled with care. This is the role of the inner loop (tloop), during which the yi are gradually increased (line <ref type="bibr" target="#b18">19)</ref> as long as the facility remains active. Finally, note that 2 communication rounds suffice for every facility to compute the value ρ = max j∈C min i∈F (c ij + f i ) in Line 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ANALYSIS</head><p>In a sense, our algorithm's analysis is based on the method of dual fitting <ref type="bibr" target="#b11">[12]</ref> applied in a distributed setting. The basic idea of this method applied to FL can be described as follows: Using the linear program relaxation (LP) for facility location and its dual (DLP), we interpret our combinatorial algorithm as an algorithm that iteratively makes primal and dual updates in a distributed fashion. Unfortunately, these updates do generally not lead to a feasible dual solution. However, the idea is to show that the objective function of the primal fractional solution computed by the algorithm is bounded by that of the dual. That is, the primal solution is fully paid for by the dual. By the basic laws of LP duality, it then remains to divide all dual values by a suitably large factor α that renders the dual variables feasible. The shrunk dual objective function is then a lower bound on OPT, and α is the algorithm's approximation guarantee. That is, instead of relaxing complementary slackness conditions as done in other primal-dual algorithms (e.g., <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b28">29]</ref>), we relax the feasibility of the dual itself.</p><p>For notational clarity, we denote the increase of ∆y i in a certain iteration of the s and t-loop by ∆y i (s, t) throughout Algorithm 1 Facility i 1: h := √ k ; 2: receive cij from all j ∈ C; 3: ρ := maxj∈C mini∈F (cij + fi); 4: y i := 0; A := C; 5: for s := 1 to h by 1 do 6:</p><p>π s i := 0; 7:</p><p>for t := h -1 to 0 by -1 do 8:</p><p>receive Mj from all j ∈ C; 9: </p><formula xml:id="formula_5">A := A \ {j ∈ C | M j = 1} 10: c(i) := min B∈2 A \{} f i + j∈B c ij |B| ; 11: if c(i) ≤ ρ s/h then 12: T i := {j ∈ A | c ij ≤ ρ s/</formula><formula xml:id="formula_6">forall i ∈ T s i do 25: ∆βij :=    0 , ρ s/h &lt; cij ρ s/h -c ij , ρ s/h ≥ c ij ∧ π s i = 0 Γ s i -c ij , ρ s/h ≥ c ij ∧ π s i = 1 26: βij := βij + ∆βij 27:</formula><p>end for 28: end for Algorithm 2 Client j 1: h := √ k ; 2: send cij to all i ∈ F ; 3: αj := 0; 4: ∀i ∈ F : x ij := 0; 5: for s := 1 to h by 1 do 6:</p><p>for t := h -1 to 0 by -1 do 7:</p><formula xml:id="formula_7">Mj := 0; 8: if i∈F xij ≥ 1 then Mj := 1; 9:</formula><p>send M j to all i ∈ F ; 10:</p><p>receive (∆y i , Γ i ) from all i ∈ T j ; 11:</p><p>forall i ∈ F do ∆x ij := ∆y i ; 12:</p><p>xij := xij + ∆xij; 13: ∆αj := i:j∈T i ∆yiΓi; 14:</p><p>α j := α j + ∆α j ; 15:</p><p>end for 16: end for this section. ∆x ij (s, t), ∆α i (s, t), and ∆β ij (s) are defined analogously.</p><p>We begin the analysis with the observation that the resulting primal solution is feasible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 5.1. Algorithms 1 and 2 produces a feasible primal solution for (LP).</head><p>Proof. The feasibility of the second LP condition, yix ij ≥ 0, ∀j ∈ C, i ∈ F , directly follows from the definition of the algorithm. Specifically, in Line 11 of Algorithm 2, the increase of a connection variable, ∆x ij never exceeds the increase of the corresponding y i .</p><p>As for the first LP condition, assume for contradiction that j is a client which is still uncovered at the end of the algorithm, i.e., i∈F x ij &lt; 1 and j ∈ A. Now, consider the very last iteration of the inner loop (s = h, t = 0). By the definition of ρ, there exists at least one facility i with cost efficiency c(i) ≤ ρ covering client j. Because s = h, facility i will become active and increase its yi value to m -t/h = 1 in Lines 19 and 20. Subsequently, j will set x ij := 1 which contradicts the assumption that j ∈ A at the end of the algorithm.</p><p>If a facility is active in a certain iteration, its cost-efficiency c(i) is, by definition, at most ρ s/h . The tight set T i does not necessarily contain the same clients which constituted the optimal cost-efficiency. Therefore, the cost efficiency of Ti may be larger than c(i), i.e., Γ i ≥ c(i). The next lemma shows that the cost-efficiency of the tight set T i , Γ i , is at most ρ s/h . Lemma 5.2. In every iteration of the t-loop, if c(i) ≤ ρ s/h for a facility i, then</p><formula xml:id="formula_8">Γ i ≤ ρ s/h . Proof. Consider the set B that constituted c(i). First, observe that if c(i) ≤ ρ s/h , and because B minimizes c(i), no client j ∈ B can have connection cost cij &gt; ρ s/h . Let Q := T i \ B be the set of clients j / ∈ B with c ij ≤ ρ s/h . Γ i is upper bounded by Γ i = fi + j∈T i cij |T i | = f i + j∈B c ij + j∈Q c ij |Ti| ≤ c(i) ≤ ρ s/h |B|ρ s/h + |Q|ρ s/h |Ti| = ρ s/h .</formula><p>Bounding the primal objective function by the dual objective function is key to applying the method of dual fitting. The next lemma provides such a bound by showing that throughout the execution of the algorithm, the values of the primal and dual objective functions are equal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 5.3. At the end of each t-loop, it holds that</head><formula xml:id="formula_9">j∈C α j = j∈C,i∈F c ij x ij + i∈F f i y i .</formula><p>(</p><formula xml:id="formula_10">)<label>2</label></formula><p>Proof. We prove the claim by induction over the iterations of the t-loop. At the beginning of the algorithms, both sides of the equation are 0. Assume that the claim is true before starting a new iteration s . If facility i increases its y i during s , all tight clients j ∈ T i increase their corresponding x ij as well. Hence, the right hand side of (2) increases by</p><formula xml:id="formula_11">∆RHS = i∈F ∆y i f i + i∈F j∈T i ∆y i c ij .</formula><p>As for the left hand side of (2), the value j∈C α j increases by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∆LHS = j∈C i:j∈T</head><formula xml:id="formula_12">i ∆y i Γ i = i∈F j∈T i ∆y i Γ i = i∈F ∆y i   j∈T i (f i + j∈T i c ij )/|T i |   = i∈F ∆yi •   fi + j∈T i cij   = ∆RHS.</formula><p>In the next lemma, we characterize the steady increase of a facility i's cost efficiency during the course of the algorithm.</p><p>Lemma 5.4. At the beginning of each iteration of the sloop, it holds for all facilities i ∈ F that c(i) ≥ 1 for s = 1 and c(i) &gt; ρ s-1/h for s &gt; 1.</p><p>Proof. The case s = 1 follows from the assumption that c ij ≥ 1 and f i ≥ 1 (cf. Section 7). Consider iteration s &gt; 1 and let s = s -1. In the last t-loop iteration of the s th iteration, all facilities i with c(i) ≤ ρ s /h set y i to 1. Consequently, all j ∈ Ti become covered. It follows that for such a facility i, ∀j ∈ A : c ij &gt; ρ s /h . The claim now follows from</p><formula xml:id="formula_13">c(i) = min B∈2 A\{} f i + j∈B c ij |B| &gt; f i |B| + |B|ρ s-1/h |B| &gt; ρ s-1/h .</formula><p>A client may be tight with several facilities. If all these facilities increased their y i values, the dual value α j of j may increase too much. Consider an iteration of the s-loop. During the early iterations of the t-loop, the increase in ∆yi of active facilities is small, because t is close to h. Intuitively, it is acceptable if a client is tight to many active facilities in these early iterations. In other words, the higher the increases ∆y i of active facilities, the fewer active facilities a client is allowed to be tight to. The following lemma establishes precisely this relationship. Lemma 5.5. Let Aj := {i | j ∈ Ti} be the active set for an uncovered client j. At the beginning of each iteration of the t-loop,</p><formula xml:id="formula_14">|Aj| ≤ m t+1/h . (<label>3</label></formula><formula xml:id="formula_15">)</formula><p>Proof. From the previous iteration of the loop, we know that for each active facility i ∈ A j , it holds that y i ≥ m -(t+1)/h . Now, assume for contradiction that |A j | &gt; m t+1/h for some j ∈ C. If so, then</p><formula xml:id="formula_16">i∈A j yi ≥ |Aj| • m -(t+1)/h &gt; 1 and consequently i∈F xij &gt; 1.</formula><p>This contradicts the assumption that client j is uncovered. Hence, the claim follows.</p><p>In the next lemma, we bound the amount of ∆α j that each client can receive in one iteration of the s-loop. For that purpose, let ∆αj(s) := h-1 t=0 ∆αj(s, t) be the increase of α j during the s th iteration of the outer loop. Let T i (s, t) be the set of clients that are tight to i in the iterations s and t. Further, we define σj(s) := h t=1 i∈A j (s,t) ∆yi.</p><p>Intuitively, σj(s) is the increase of the yi value at facilities to which client j has been tight during the course of the s th iteration of the outer loop. The following lemma relates α j (s) and σ j (s).</p><p>Lemma 5.6. The sum of the ∆α j values collected in iteration s at a node j is upper bounded by</p><formula xml:id="formula_17">∆α j (s) ≤ σ j (s) • ρ s/h .</formula><p>Proof. Applying Lemma 5.2 and by the definition of ∆α j , we have</p><formula xml:id="formula_18">∆αj(s) ≤ h-1 t=0 ∆αj(s, t) ≤ h-1 t=0 i∈A j (s,t) ∆y i (s, t)Γ i (s, t) ≤ Lemma 5.2 h-1 t=0 i∈A j (s,t) ∆y i (s, t)ρ s/h = σj(s)ρ s/h .</formula><p>Next, we want to find bounds for σ j (s). Assume that client j becomes covered during iteration s * j of the outer loop. Notice that for every client j, there is exactly one iteration s * j . Once covered, j will not be in A and therefore, not in any T i . Consequently, σ j (s ) = 0 for all s &gt; s * j . The other two cases, s &lt; s * j and s = s * j are subject of the following lemma.</p><p>Lemma 5.7. For all iterations of the s-loop, it holds that σj(s</p><formula xml:id="formula_19">) ≤ 1 ∀s = s * j σ j (s) ≤ m 1/h s = s * j</formula><p>Proof. The first case, s &lt; s * j , follows from the definition of σ j (s). If</p><formula xml:id="formula_20">σ j (s ) = h t=1 i∈A j (s,t) ∆y i ≥ 1,</formula><p>then j would have become covered in iteration s and hence, s = s * j . It remains to analyze the iteration during which j becomes covered, i.e., s = s * j . Consider the iterations of the inner loop during iteration s * j of the outer loop. Let t * denote the iteration during which j becomes covered. Clearly, for all t &gt; t * , it holds that i:j∈T i (t ) ∆y i (t ) = 0 because j is already covered. Hence, we only need to analyze the first t * iterations of the inner loop. Summing up all increases, we get</p><formula xml:id="formula_21">σ j (s ) = h-1 t=t * +1 i∈A j (t) ∆y i (t) + i∈A j (t * ) ∆y i (t * ) ≤ 1 + i∈A j (t * ) ∆y i (t * ) ≤ 1 + m -t/h -m -(t+1)/h • |A j (t * )| ≤ 1 + m -t/h -m -(t+1)/h • m t+1/h ≤ 1 + m 1/h -1 = m 1/h .</formula><p>The first inequality follows from the fact that by definition of t * , client j is not covered after the iterations h-1, . . . , t * +1. The third inequality follows from Lemma 5.5.</p><p>For our dual solution to be feasible, the linear program condition imposes that j∈C βij ≤ fi holds for all facilities i ∈ F . Unfortunately, the dual solution produced by our algorithm does not exhibit this feasibility property. However, we can at least show that the degree of infeasibility is bounded. Specifically, it holds that if we only consider the sum of the increases of the β ij in a single iteration of the s-loop, it fulfils the desired property.</p><p>Lemma 5.8. For all i ∈ F and all iterations s of the outer loop, it holds that</p><formula xml:id="formula_22">j∈C ∆β ij (s) ≤ f i .</formula><p>Proof. We distinguish two cases, depending on whether πi(s) equals 0 or 1. In the first case, πi(s) = 0, the facility i's cost efficiency was insufficient to increase its yi value during the s th iteration. We therefore have</p><formula xml:id="formula_23">j∈C ∆β ij (s) = j∈T i (ρ s/h -c ij ) = ρ s/h |T i | - j∈T i c ij</formula><p>Assume for contradiction that j∈C ∆β ij (s) &gt; f i for some facility i and iteration s. It follows that</p><formula xml:id="formula_24">ρ s/h &gt; f i + j∈T i c ij |Ti| ≥ c(i),</formula><p>which in turn implies π i (s) = 1 for B = T i . This establishes the contradiction.</p><p>As for the second case, π i (s) = 1, we have</p><formula xml:id="formula_25">j∈C ∆βij(s) = j∈T i (Γ s i -cij) = |T i | • fi + j∈T i cij |T i | - j∈T i c ij = f i .</formula><p>Therefore, the lemma holds in both cases.</p><p>Having bounded the degree of infeasibility of the first dual constraint, it now remains to do the same for the second one, αj -βji ≤ cij, for all j ∈ C and i ∈ F . Again, we give weaker bounds that do not hold for the entire execution of the algorithm, but merely for a single iteration of the outer loop.</p><p>Lemma 5.9. Let ∆α j (s) be the sum of the ∆α j (t) over all iterations of the t-loop in the s th iteration of the s-loop. For all j ∈ C, i ∈ F , and all iterations s, it holds that</p><formula xml:id="formula_26">∆α j (s) (mρ) 1/h -∆β ij (s) ≤ c ij</formula><p>Proof. We distinguish three cases, depending on how much increase of βij was assigned to the connection between i and j in line 25 of the facility algorithm. Regardless of the specific case, the value ∆α j (s) is bounded by ∆α j (s) ≤ ρ s/h m 1/h by Lemmas 5.6 and 5.7.</p><p>1) In the case ρ s/h ≤ cij, the algorithm sets ∆βij(s) to 0. Therefore</p><formula xml:id="formula_27">∆αj(s) (mρ) 1/h -∆β ij (s) ≤ ρ (s-1)/h ≤ c ij .</formula><p>2) In the second case, the client j is tight to i, i.e., ρ s/h &gt; c ij , but π i (s) = 0. Plugging in the corresponding value for ∆βij(s), we get</p><formula xml:id="formula_28">∆α j (s) (mρ) 1/h -ρ s/h -cij ≤ ρ (s-1)/h -ρ s/h +cij ≤ cij.</formula><p>3) Finally, consider the last case, ρ s/h &gt; cij and πi(s</p><formula xml:id="formula_29">) = 1. Substituting ∆βij(s) by Γ s i -cij yields ∆βij(s) + cij = Γ s i -cij + cij = Γ s i ≥ c(i).</formula><p>For s &gt; 1, we know by Lemma 5.4, that c(i) ≥ ρ (s-1)/h at the beginning of iteration s, hence</p><formula xml:id="formula_30">∆βij(s) + cij ≥ ρ (s-1)/h .</formula><p>Using the above inequality, we obtain</p><formula xml:id="formula_31">∆α j (s) (mρ) 1/h ≤ ρ (s-1)/h ≤ ∆βij(s) + cij.</formula><p>Subtracting ∆β ij (s) concludes the proof for the case s &gt; 1.</p><p>The case s = 1 follows similarly. By Lemma 5.4, we can lower bound c(i) ≥ 1 and therefore ∆βij(s) + cij ≥ 1. The claim now follows from</p><formula xml:id="formula_32">∆αj(s) (mρ) 1/h ≤ ρ (s-1)/h = 1 ≤ ∆β ij (s) + c ij .</formula><p>Having bounded the degree of dual infeasibility in the two previous lemmas, we can now establish the approximation ratio of the algorithm using the laws of LP duality. Specifically, we prove that the dual feasibility is violated only by a factor O(h(mρ) 1/h ) and hence, when dividing αj and βij by suitably large values, we obtain a feasible solution αj and βij . Proof. The runtime follows directly from the definition of the algorithm. For the analysis of the approximation ratio, we define αj and βij as αj := αj h(mρ) 1/h  and βij := βij h , respectively. We show that the variables αj and βij form a feasible solution to the dual LP. The feasibility of the second dual constraint follows directly from Lemma 5.8. Particularly, it holds that j∈C βij(s) ≤ fi for all iterations s and all facilities i. As a consequence, we obtain j∈C βij ≤ h•fi and therefore, j∈C βij ≤ f i . Next, we show the feasibility of the first constraint by bounding αj -βij as</p><formula xml:id="formula_33">αj -βij = h-1 s=0 α j (s) h(mρ) 1/h - h-1 s=0 β ij (s) h = 1 h h-1 s=0 α j (s) (mρ) 1/h -βij(s) .</formula><p>By Lemma 5.9, each term of the sum is bounded by cij. Therefore, we have αj</p><formula xml:id="formula_34">-βij ≤ hc ij /h ≤ c ij .</formula><p>Let OP T and ALG denote the optimal value and the value as computed by the algorithm, respectively. By LP duality, the sum of the αj values is a lower bound for OP T . As for ALG, recall that by Lemma 5.3, we know that the value of the primal and dual objective function is equal at the end of the algorithm. Therefore, we can bound ALG as</p><formula xml:id="formula_35">ALG = i∈F fiyi + i∈F j∈C cijxij = Lemma 5.3 j∈C α j ≤ h(mρ) 1/h j∈C αj ≤ h(mρ) 1/h • OP T.</formula><p>Finally, the theorem follows from h = √ k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RANDOMIZED ROUNDING</head><p>In order to come up with a solution to the integer facility location problem, we round the fractional solutions obtained in the previous section. During this process, we must neither overly increase the total opening costs, nor the total connection costs. Interestingly, this can be achieved with high probability in constant time even in a distributed setting. The idea for the randomized rounding is based on the filtering technique introduced in <ref type="bibr" target="#b17">[18]</ref>. Applications of randomized rounding for a covering LP in a distributed context can be found in <ref type="bibr" target="#b16">[17]</ref>.</p><p>In the following, let xij and ŷi be the fractional values obtained from Algorithms 2 and 1, respectively. The variables x ij and y i denote the rounded integer values. For every client j ∈ C, let C * j := i∈F c ij xij be the weighted cost of j's connections. Further, let the neighborhood V j of a client j be the set of all facilities that are located within a factor of log (n + m) of the weighted connection cost. Formally, for every</p><formula xml:id="formula_36">j ∈ C, V j := {i ∈ F | c ij ≤ log (n + m)•C * j }.</formula><p>The idea is to round the fractional values y i at each facility i in such a way that with high probability, all clients have at least one opened facility in their neighborhood, Nj = ∅. Each such client then simply connects itself to the open facility with the minimum connection cost c ij .   It remains to bound the costs incurred by clients that are not covered, i.e. N j = ∅, and facilities that are opened via a JOIN-MSG message. The probability qj that a client j does not have an open facility in its neighborhood is at most</p><formula xml:id="formula_37">* j := i∈F c ij xij ; 2: V j := {i ∈ F | c ij ≤ ln (n + m) • C * j }; 3: receive yi from all i ∈ F 4: Nj := Vj ∩ {i ∈ F | yi = 1} 5: if N j = ∅</formula><formula xml:id="formula_38">i∈V j ŷi = i∈V j xij ≥ 1 - 1 log (n + m) . (<label>4</label></formula><formula xml:id="formula_39">qj = i∈V j (1 -pi) =   n+m i∈V j (1 -pi)   n+m ≤ i∈V j (1 -pi) n + m n+m ≤ |V j |≤m 1 - ln (n + m) i∈V j ŷi n + m n+m ≤ Eq. (4) 1 - ln (n + m) n + m 1 - 1 ln (n + m) n+m = 1 - ln (n + m) -1 n + m n+m ≤ e -ln (n+m)-1 ≤ 1 e(n + m) . (<label>5</label></formula><formula xml:id="formula_40">)</formula><p>The first inequality follows from the fact that for every sequence of positive numbers, the geometric mean is smaller than or equal to the arithmetic mean of these numbers.</p><p>An uncovered client sends a JOIN-MSG message to the facility i ∈ F that minimizes c ij + f i . Each of these costs is at most j∈C,i∈F c ij xij + i∈F ŷi f i because x and ŷ would not constitute a feasible solution otherwise. Combining this with the above results, the total expected cost µ</p><formula xml:id="formula_41">= E[ALG] is µ ≤ ln (n + m) j∈C,i∈F c ij xij + i∈F ŷi f i + n e(n + m) j∈C,i∈F cij xij + i∈F ŷifi ≤ (ln (n + m) + O(1)) αOP T.</formula><p>This concludes the proof of Theorem 6.1.</p><p>In many distributed systems, obtaining a solution that holds in expectation may not be satisfying. Instead, we are interested in results that hold with high probability. In order to obtain such a high probability result, the above rounding procedure can be adapted as follows.</p><p>Algorithm 3 for the clients remains unchanged. The procedure executed by each facility, however, is changed such that, instead of (probabilistically) selecting a single binary variable y i , a facility determines a series of log n independent random variables y 1 i , . . . , y log n i . Like in Algorithm 4, each y i , = 1, . . . , log n is independently chosen as</p><formula xml:id="formula_42">y i := 1 , with probability pi 0 , with probability 1 -p i for p i = min {1, ŷi • ln (n + m)}.</formula><p>Every facility then wraps all these log n bits in a message and sends it to some leader node (which can be the client with the lowest ID, for instance). The leader node receives these messages (y 1 i . . . y log n i ) from all facilities i ∈ F and computes the index t which minimizes the sum of the opening costs, formally t = arg min i∈F y s i fi, for all s = 1, . . . , log n. The leader then sends to each facility i ∈ F its corresponding binary variable y t i , which facility i subsequently sends to its cities in Line 3 of Algorithm 4. The following Theorem shows that this adapted procedure yields the desired high probability result. Theorem 6.2. Let xij and ŷi for each j ∈ C and i ∈ F be the fractional solution with cost at most α•OP T as derived in Algorithms 1 and 2. In four rounds of communication, the adapted rounding algorithm produces an integer solution xij, yi with cost at most O(log(m + n))αOP T with probability 1 -n -1 .</p><p>Proof. We know that E[X ] = ln (n + m) i∈F ŷifi, where X = i∈F y i fi. By Markov's inequality,</p><formula xml:id="formula_43">P X ≥ 2 ln (n + m) i∈F ŷifi ≤ 1 2</formula><p>for each = 1, . . . , log n. The probability that X t does not exceed this threshold is therefore bounded by</p><formula xml:id="formula_44">P Xt ≤ 2 ln (n + m) i∈F ŷifi ≤ 1 - 1 2 log n = 1 - 1 n .</formula><p>The rest of the proof is identical to the proof of Theorem 6.1. Particularly, we know by Inequality (5) that with high probability, the solution y t i for all i ∈ F constitutes a solution such that, every client j ∈ C has an open facility in its neighborhood. Because all clients can thus connect to open facilities in their neighborhood, the total connection cost is at most ln (n + m) j∈C,i∈F c ij xij . We conclude the proof by observing that the message size remains in O(log n).</p><p>Clearly, this high probability result comes at the cost of a "centralized" program execution, i.e., all information is compiled and processed at one single node. Depending on the specific application scenario, the decentralized approach of Algorithms 3 and 4 may be preferable for various reasons (including fault-tolerance) even at the cost of worse performance guarantees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ARBITRARY COEFFICIENTS</head><p>The algorithm and analysis of Sections 4 and 5 is based on the assumption that cij ≥ 1 and fi ≥ 1 for all j ∈ C, i ∈ F . In this section, we show how to handle the general case in which connection and opening costs can be arbitrary nonnegative values. Furthermore, this technique can be used to get rid of the dependency on ρ in the approximation ratio.</p><p>The idea is to scale all costs such that the above condition holds. The problem is that the straightforward approach of multiplying all costs with the minimum c ij or f i might overly blow up the coefficient ρ, or it may even be infeasible for zero valued costs. For that reason, we need to perform a more subtle scaling that is inspired by a similar technique given in <ref type="bibr" target="#b2">[3]</ref>.</p><p>The parameter ρ is a lower bound for the objective value µOP T of the optimal solution OP T . Because there are n clients, all stars with cost-efficiency smaller than ρ/n can be added to a solution ALG, incurring costs at most µ OP T . This observation motivates the following scaling procedure performed at the beginning of the algorithm. 2. For all j ∈ C and i ∈ F , set c ij := nc ij /ρ and f i := nf i /ρ, respectively. Clients in C \C do not participate in the algorithm further.</p><p>3. Execute Algorithms 1 and 2 with clients and facilities in C and F , the coefficient ρ = n (the new ρ), and costs c ij and f i .</p><p>Notice that the above procedure can be executed in our distributed model in a constant number of communication rounds. The facility location instance resulting from the above transformation fulfils the following useful and simple property.</p><p>Lemma 7.1. Consider a facility location instance derived from the above transformation. Throughout the algorithm and for all i ∈ F , it holds that c(i) ≥ 1.</p><p>Proof. If B is the set of clients constituting c(i), then</p><formula xml:id="formula_45">c(i) = f i + j∈B c ij |B| = n ρ f i + j∈B c ij |B|</formula><p>Assume for contradiction that i ∈ F and c(i) &lt; 1. It follows that</p><formula xml:id="formula_46">f i + j∈B c ij |B| &lt; ρ n .</formula><p>This contradicts the fact that the star B was not selected during the transformation, that is, the clients j ∈ B are in C . Having Lemma 7.1 allows us to use Lemmas 5.4 and 5.9 as in the proof of Section 5. The remainder of the proof in Section 5 remains the same.</p><p>Summarizing, the transformation algorithm runs in O(k 2 ) rounds and yields a solution of cost at most O(k(mn) 1/k ) • µOP T + µOP T for the fractional facility location problem. In combination with randomized rounding, this results in a O(k(mn) 1/k log (n + m)) approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">FAULT-TOLERANCE</head><p>Facility location problems model the tradeoff between the cost of developing resources and the utility accruing from them. In numerous applications, fault-tolerance is of importance in this context <ref type="bibr" target="#b27">[28]</ref>. When considering caching in a network, for instance, the caches should be resistent to failures of nodes and links. This fault-tolerance is modelled by demanding that every client j be assigned to at least r j facilities, r j being the requirement of client j. The special case rj = 1, ∀j ∈ C corresponds to the regular facility location problem. The fault-tolerant facility location problem can be captured by the following LP relaxation.</p><formula xml:id="formula_47">min i∈F fiyi + i∈F j∈C cijxij i∈F xij ≥ rj , ∀j ∈ C yi -xij ≥ 0 , ∀j ∈ C, i ∈ F -x ij ≥ -1 , ∀j ∈ C, i ∈ F xij, yi ≥ 0 , ∀j ∈ C, i ∈ F</formula><p>The additional constraint xij ≤ 1 prevents a client from connecting to the same facility multiple times.</p><p>The algorithm in Section 4 can be adapted for the faulttolerant case. Analogously to the regular case, the coefficient ρ is defined as the minimal cost such that every city can open and connect to k facilities. The algorithm is changed such that, clients remain in the active set A until they are (fractionally) covered by at least r j facilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSIONS</head><p>Many applications of the facility location problem such as caching in the Internet inherently apply to distributed settings. In this paper, we have given a classification of the trade-off between the amount of communication and the quality of the obtained global solution. Our solution technique is based on the distributed approximation of a linear program which is, in contrast to previous work <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b16">17]</ref>, not a covering or packing problem. By thus pushing the boundaries of distributed LP approximation, we hope that our paper is a step towards understanding the nature of more general linear programs in a distributed context.</p><p>Our results give raise to several questions. First, the fact that in the centralized case, the metric facility location problem allows constant approximations <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b12">13]</ref> raises hope for faster approximations algorithms in distributed settings, too. Moreover, our problem setting is a complete bipartite graph. Interestingly, there are virtually no lower bounds for the bounded message size model for graphs with diameter 1 or 2. For instance, all lower bounds for the MST problem apply to graphs with diameter at least 3. Finding lower bounds for this model appears to be an outstanding open problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 5 . 10 .</head><label>510</label><figDesc>For an arbitrary integer k &gt; 0, the algorithm computes a O( √ k(mρ) 1/ √ k ) approximation to the fractional facility location problem in O(k) communication rounds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 6 . 1 .Algorithm 3</head><label>613</label><figDesc>Let xij and ŷi for each j ∈ C and i ∈ F be the fractional solution with cost at most α • OP T as derived in Algorithms 1 and 2. In two rounds of communication, Algorithms 4 and 3 produce an integer solution x ij , y i with cost at most O(log(m + n))αOP T in expectation. Randomized Rounding -Client INPUT: fractional solution xij from Algorithm 2 OUTPUT: integral solution xij to ILP 1: C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>)</head><label></label><figDesc>For each client j having Nj = ∅, the connection costs are at most cij ≤ ln (n + m)C * j by the definition of the neighborhood V j . It follows that these clients account for total connection costs of at most ln (n + m) j∈C,i∈F c ij xij . A facility declares itself open in Line 2 of Algorithm 4 with probability min {1, ŷi • ln (n + m)}. The expected opening costs of facilities opened in Line 2 are thus bounded by the value ln (n + m) i∈F ŷi f i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 .</head><label>1</label><figDesc>For every facility i, choose the largest set B i of clients such that (f i + j∈B i c ij )/|B i | ≤ ρ/n. If such a B i exists, set yi := 1 and xij := 1 for all j ∈ Bi. Let C and F be the set of unconnected clients and unpicked facilities, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>send y i to all clients j ∈ C; 4: if receive JOIN-MSG then y i := 1;Proof. It follows from the definition of C * j and V j that j∈F \V j xij ≤ 1/ log (n + m), for if not, C * j would be larger. Since the construction of Algorithms 2 and 1 guarantees the invariant i∈V j xij = i∈V j ŷi , and i∈F xij ≥ 1 we have</figDesc><table><row><cell></cell><cell></cell><cell>then</cell></row><row><cell cols="3">6: 7: else i := argmin i∈N j c ij ; x i j := 1;</cell></row><row><cell>8: 9:</cell><cell cols="2">i := argmin i∈F (c ij + f i ); x i j := 1; send JOIN-MSG to facility i ;</cell></row><row><cell>10: fi</cell><cell></cell></row><row><cell cols="3">Algorithm 4 Randomized Rounding -Facility</cell></row><row><cell cols="3">INPUT: fractional solution ŷi from Algorithm 1</cell></row><row><cell cols="3">OUTPUT: integral solution y i to ILP</cell></row><row><cell cols="3">1: p i := min {1, ŷi • ln (n + m)};</cell></row><row><cell cols="2">2: yi :=</cell><cell>1 , with probability pi 0 , with probability 1 -pi</cell></row><row><cell>3:</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In a complete bipartite graph,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>communication rounds suffice to inform every client and every facility about the entire problem instance if the message size is unbounded. The problem can then be solved locally using the standard centralized greedy algorithm<ref type="bibr" target="#b10">[11]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>In spite of there being exponentially many sets B ∈ 2 A , the facility can compute its cost efficiency c(i) in polynomial time in Line 10 of Algorithm 1 by considering the clients ordered according to their connection costs c ij .</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">ACKNOWLEDGEMENTS</head><p>We would like to thank the anonymous PODC reviewers for pointing out a simplification in the original version of Lemma 5.9.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Complexity of Network Synchronization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Awerbuch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="804" to="823" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On Finding Integer Solutions to Linear Programs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Balinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IBM Scientific Computing Symposium on Combinatorial Problems</title>
		<meeting>the IBM Scientific Computing Symposium on Combinatorial Problems</meeting>
		<imprint>
			<date type="published" when="1966">1966</date>
			<biblScope unit="page" from="225" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Global Optimization Using Local Information with Applications to Flow Control</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bartal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Byers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 38 th Symposium on Foundations of Computer Science (FOCS)</title>
		<meeting>38 th Symposium on Foundations of Computer Science (FOCS)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="303" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Discrete Location Theory, chapter The Uncapacitated Facility Location Problem</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cornuejols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nemhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolsey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Wiley</publisher>
			<biblScope unit="page" from="119" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An Unconditional Lower Bound on the Hardness of Approximation of Distributed Minimum Spanning Tree Problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36 th annual ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>the 36 th annual ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributed Approximation -A Survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGACT News -Distributed Computing Column</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Threshold of ln n for Approximating Set Cover</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="634" to="652" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A General Approximation Technique for Constrained Forest Problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="296" to="317" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Facility Location Problem with General Cost Functions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Hajiaghayi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Networks</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="47" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Energy-Efficient Communication Protocol for Wireless Microsensor Networks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Heinzelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chandrakasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33 rd Hawaii International Conference on System Sciences (HICSS)</title>
		<meeting>33 rd Hawaii International Conference on System Sciences (HICSS)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">8020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heuristics for the fixed cost median problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Hochbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="148" to="162" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Greedy Facility Location Algorithms analyzed using Dual Fitting with Factor-Revealing LP</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Markakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saberi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="795" to="824" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Primal-Dual Approximation Algorithms for Metric Facility Location and k-Median Problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40 th Symposium on Foundations of Computer Science (FOCS)</title>
		<meeting>the 40 th Symposium on Foundations of Computer Science (FOCS)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Analysis of a Local Search Heuristic for Facility Location Problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Korupolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Plaxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajaraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9 th ACM-SIAM Symposium on Discrete Algorithms (SODA)</title>
		<meeting>the 9 th ACM-SIAM Symposium on Discrete Algorithms (SODA)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Initializing newly deployed ad hoc and sensor networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moscibroda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 10 th Annual International Conference on Mobile Computing and Networking (MOBICOM)</title>
		<meeting>10 th Annual International Conference on Mobile Computing and Networking (MOBICOM)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="260" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">What Cannot be Computed Locally</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moscibroda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23 rd ACM Symposium on the Principles of Distributed Computing (PODC)</title>
		<meeting>the 23 rd ACM Symposium on the Principles of Distributed Computing (PODC)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="300" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Constant-Time Distributed Dominating Set Approximation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22 nd Annual ACM Symp. on Principles of Distributed Computing (PODC)</title>
		<meeting>of the 22 nd Annual ACM Symp. on Principles of Distributed Computing (PODC)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Approximations with Minimum Packing Constraint Violation</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Vitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24 th ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>the 24 th ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="771" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Locality in Distributed Graph Algorithms</title>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="201" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MST Construction in O(log log n) Communication Rounds</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lotker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Patt-Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15 th ACM symposium on Parallel Algorithms and Architectures (SPAA)</title>
		<meeting>the 15 th ACM symposium on Parallel Algorithms and Architectures (SPAA)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="94" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Parallel Approximation Algorithm for Positive Linear Programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nisan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25 th ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>of the 25 th ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="448" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the Hardness of Approximating Minimization Problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Linear Programming Without the Matrix</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25 th ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>the 25 th ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="121" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed Computing: A Locality-Sensitive Approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM Monographs on Discrete Mathematics and Applications</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Near-Tight Lower Bound on the Time Complexity of Distributed Minimum-Weight Spanning Tree Construction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rubinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1427" to="1442" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Primal-Dual RNC Approximation Algorithms for Set Cover and Covering Integer Programs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rajagopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="525" to="540" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Approximation Algorithms for Facility Location Problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Shmoys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29 th Symposium on Theory of Computing (STOC)</title>
		<meeting>29 th Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fault-Tolerant Facility Location</title>
		<author>
			<persName><forename type="first">C</forename><surname>Swamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Shmoys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14 th Symposium on Discrete Algorithms (SODA)</title>
		<meeting>14 th Symposium on Discrete Algorithms (SODA)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="735" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Primal-Dual Approximation Algorithm for Generalized Steiner Network Problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mihail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25 th Symposium on Theory of Computing (STOC)</title>
		<meeting>25 th Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="708" to="717" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
