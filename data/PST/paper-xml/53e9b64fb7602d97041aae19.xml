<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jaihie</forename><forename type="middle">P</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
						</author>
						<author>
							<persName><forename type="first">-K</forename><surname>Shiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
							<email>csdzhang@comp.polyu.edu.hk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technol-ogy</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5DD5919C6D9F20120157BEC4C33608A1</idno>
					<idno type="DOI">10.1109/TIFS.2014.2324277</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I MAGE set based classification has been increasingly employed in face recognition <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b9">[10]</ref> and object categorization <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref> in recent years. Due to the rapid development of digital imaging and communication techniques, now image sets can be easily collected from multi-view images using multiple cameras <ref type="bibr" target="#b10">[11]</ref>, long term observations <ref type="bibr" target="#b6">[7]</ref>, personal albums and news pictures <ref type="bibr" target="#b12">[13]</ref>, etc. Meanwhile, image set based face recognition (ISFR) has shown superior performance to single image based face recognition since the many sample images in the gallery set can convey more within-class variations of the subject <ref type="bibr" target="#b7">[8]</ref>. One special case of ISFR is video based face recognition, which collects face image sets from consecutive video sequences <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Similar to the work in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b7">[8]</ref>, in this paper we focus on the general case of ISFR without considering the temporal relationship of samples in each set.</p><p>The key issues in image set based classification include how to model a set and consequently how to compute the distance/similarity between query and gallery sets. Researchers have proposed parametric and non-parametric approaches for image set modeling. Parametric modeling methods model each set as a parametric distribution, and use Kullback-Leibler divergence to measure the similarity between the distributions <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b6">[7]</ref>. The disadvantage of parametric set modeling lies in the difficulty of parameter estimation, and it may fail when the estimated parametric model does not fit well the real gallery and query sets <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>Many non-parametric set modeling methods have also been proposed, including subspace <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b10">[11]</ref>, manifold <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref>, affine hull <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, convex hull <ref type="bibr" target="#b4">[5]</ref>, and covariance matrix based ones <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. The method in <ref type="bibr" target="#b10">[11]</ref> employs canonical correlation to measure the similarity between two sets. A projection matrix is learned by maximizing the canonical correlations of within-class sets while minimizing the canonical correlations of between-class sets. The methods in <ref type="bibr" target="#b20">[21]</ref> use manifold to model an image set and define a manifold-to-manifold distance (MMD) for set matching. MMD models each image set as a set of local subspaces and the distance between two image sets is defined as a weighted average of pairwise subspace to subspace distance. As MMD is a non-discriminative measure, Manifold Discriminant Analysis (MDA) is proposed to learn an embedding space by maximizing manifold margin <ref type="bibr" target="#b11">[12]</ref>. The performance of subspace and manifold based methods may degrade much when the set has a small sample size but big data variations <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b17">[18]</ref>. In affine hull and convex hull based methods <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, the between-set distance is defined as the distance between the two closest points of the two sets. When convex hull is used, the set to set distance is equivalent to the nearest point problem in SVM <ref type="bibr" target="#b21">[22]</ref>. In <ref type="bibr" target="#b22">[23]</ref>, a method called sparse approximated nearest points (SANP) is proposed to measure the dissimilarity between two image sets. To reduce the model complexity of SANP, a reduced model, which is called regularized nearest points (RNP), is proposed by modeling each image set as a regularized hull <ref type="bibr" target="#b23">[24]</ref>. However, the closest points based methods <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> rely highly on the location of each individual sample in the set, and the model fitting can be heavily deteriorated by outliers <ref type="bibr" target="#b17">[18]</ref>. A collaborative regularized nearest points (CRNP) method is proposed in <ref type="bibr" target="#b25">[26]</ref> to extend RNP.</p><p>To improve the classification performance, the kernel trick can be introduced to map the image sets to high-dimensional subspaces, e.g., kernel mutual subspace method <ref type="bibr" target="#b26">[27]</ref> and kernel discriminant transformation <ref type="bibr" target="#b27">[28]</ref>. In <ref type="bibr" target="#b17">[18]</ref>, an image set is represented by a covariance matrix and a Riemannian kernel function is defined to measure the similarity between two image sets by a mapping from the Riemannian manifold to a Euclidean space. With the kernel function between two image sets, traditional discriminant learning methods, e.g., linear discriminative analysis <ref type="bibr" target="#b28">[29]</ref>, partial least squares <ref type="bibr" target="#b29">[30]</ref>, kernel machines, can be used for image set classification <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. The disadvantages of covariance matrix based methods include the computational complexity of eigen-decomposition of symmetric positive-definite (SPD) matrices and the curse of dimensionality with limited number of training sets.</p><p>No matter how the set is modeled, in almost all the previous works <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b23">[24]</ref> the query set is compared to each of the gallery sets separately, and then classified to the class closest to it. Such a classification scheme does not consider the correlation between gallery sets, like the nearest neighbor or nearest subspace classifier in single image based face recognition. In recent years, the sparse representation based classification (SRC) <ref type="bibr" target="#b30">[31]</ref> has shown interesting results in image based face recognition. SRC represents a query face as a sparse linear combination of samples from all classes, and classifies it to the class which has the minimal representation residual to it. Though SRC emphasizes much on the role of l 1 -norm sparsity of representation coefficients, it has been shown in <ref type="bibr" target="#b31">[32]</ref> that the collaborative representation mechanism (i.e., using samples from all classes to collaboratively represent the query image) is more important to the success of SRC. The so-called collaborative representation based classification (CRC) with l 2 -regularization leads to similar results to SRC but with much lower computational cost <ref type="bibr" target="#b31">[32]</ref>. In <ref type="bibr" target="#b32">[33]</ref>, feature weights are introduced to the representation model to penalize pixels with large error so that the model is robust to outliers. Moreover, a kernel sparse representation model is proposed for face recognition by mapping features to a high dimensional Reproducing Kernel Hilbert Space (RKHS), which further improves the recognition accuracy <ref type="bibr" target="#b33">[34]</ref>. Similarly, a robust kernel representation model is proposed with iteratively reweighted algorithms <ref type="bibr" target="#b34">[35]</ref>.</p><p>One may apply SRC/CRC to ISFR by representing each image of the query set over all the gallery sets, and then using the average or minimal representation residual of the query set images for classification. However, such a scheme does not exploit the correlation and distinctiveness of sample images in the query set. If the average representation residual is used for classification, the discrimination of representation residuals by different classes will be reduced; if the minimal representation residual is used, the classification can suffer from the outlier images in the query set. In addition, there are redundancies in an image set. The redundancies will lead to great storage burden and computational complexity, and deteriorate the recognition performance.</p><p>In this paper, we propose a novel image set based collaborative representation and classification (ISCRC) approach for ISFR, as illustrated in Fig. <ref type="figure" target="#fig_1">1</ref>. The query set, denoted by Y (each column of Y is an image in the set) is modeled as a hull Y a with the sum of coefficients in a being 1. Let X k , k = 1, 2, . . . , K , be a gallery set. We then propose a collaborative representation based set (i.e., Y ) to sets (i.e., X = [X 1 , . . . , X k , . . . , X K ]) distance (CRSSD for short); that is, we represent the hull Y a over the gallery sets X as X b, where b is a coefficient vector. Consequently, we can classify the query set Y by checking which gallery set has the minimal representation residual to the hull Y a. To get a stable solution to CRSSD, regularizations can be imposed on a and b. In the proposed ISCRC, the gallery sets X k can be compressed to a smaller size to remove the redundancy so that the time complexity of ISCRC can be much reduced without sacrificing the recognition rate. Our experiments on three benchmark ISFR databases show that the proposed ISCRC is superior to state-of-the-art methods in terms of both recognition rate and efficiency.</p><p>To better illustrate the motivation of ISCRC, we use an example to explain the superiority of ISCRC over set to set distance based classifiers (e.g., CHISD <ref type="bibr" target="#b4">[5]</ref>, SANP <ref type="bibr" target="#b7">[8]</ref>, RNP <ref type="bibr" target="#b23">[24]</ref>) from a large margin perspective. Large margin principle has been widely used in classifier design (e.g., SVM <ref type="bibr" target="#b21">[22]</ref>, LVQ <ref type="bibr" target="#b35">[36]</ref>), ensemble learning (e.g., AdaBoost <ref type="bibr" target="#b36">[37]</ref>) and metric learning (e.g., MDA <ref type="bibr" target="#b11">[12]</ref>, LMNN <ref type="bibr" target="#b37">[38]</ref>). In classification, large margin can lead to better generalization ability <ref type="bibr" target="#b38">[39]</ref>. In <ref type="bibr" target="#b39">[40]</ref>, SRC is interpreted as a margin classifier and a margin is derived for SRC. Actually, in image set based classification, MDA <ref type="bibr" target="#b11">[12]</ref>, DCC <ref type="bibr" target="#b10">[11]</ref> and CDL <ref type="bibr" target="#b17">[18]</ref> all try to learn a discriminative set to set distance in a large margin manner, i.e., pull the similar image sets together while push the dissimilar image sets away. Similar to sample margin in nearest neighbor classifier, image set margin can be defined. Given a query set Y but multiple gallery sets X k , k = 1, 2, . . . , K , as illustrated in Fig. <ref type="figure" target="#fig_2">2</ref>, the image set margin is defined as</p><formula xml:id="formula_0">margi n Y = d(Y , X nearmiss ) -d(Y , X nearhit ) (1)</formula><p>where   and RNP <ref type="bibr" target="#b23">[24]</ref>), where the Honda/USCD 1 database <ref type="bibr" target="#b13">[14]</ref> is used. Fig. <ref type="figure" target="#fig_3">3(a)</ref> is the comparison between ISCRC and convex hull based image set distance, i.e., CHISD. The image sets marked by pentagram are misclassified by CHISD with negative margin while correctly classified by ISCRC with positive margin. Besides, the margin of the other image sets are all enlarged, which represents better generalization ability in classification. Fig. <ref type="figure" target="#fig_3">3</ref>(b) illustrates the comparison between ISCRC and regularized hull based image set distance, i.e., RNP. Although RNP classifies all the image sets correctly with positive margin, ISCRC results in much larger margin than RNP. Both comparisons show that the proposed ISCRC can lead to larger image set margin compared with set to set distance, indicating that ISCRC would get better generalization performance.</p><formula xml:id="formula_1">X</formula><p>The rest of this paper is organized as follows. Section II discusses in detail the proposed CRSSD and ISCRC methods. Section III presents the regularized hull based ISCRC, 1 http://vision.ucsd.edu/ leekc/HondaUCSDVideoDatabase/HondaUCSD.html TABLE I THE MAIN ABBREVIATIONS USED IN THIS PAPER followed by the convex hull based ISCRC in Section IV. Section V conducts experiments and Section VI gives our conclusions. The main abbreviations used in the development of our method are summarized in Table <ref type="table">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. COLLABORATIVE REPRESENTATION BASED SET TO SETS DISTANCE</head><p>We first introduce the hull based set to set distance in II-A, and then propose the collaborative representation based set to sets distance (CRSSD) in II-B. With CRSSD, the image set based collaborative representation and classification (ISCRC) scheme can be naturally proposed. In II-C and II-D, the convex hull and regularized hull based CRSSD are respectively presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Hull Based Set to Set Distance</head><p>In image set based classification, compared to the parametric modeling of image set, non-parametric modeling does not impose assumptions on the data distribution and inherits many favorable properties <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b17">[18]</ref>. One simple non-parametric set modeling approach is the hull based modeling <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, which models a set as the linear combination of its samples. Given a sample set Y = {y 1 , . . . , y i , . . . , y n a }, y i ∈ d , the hull of set Y is defined as: H (Y ) = { a i y i }. Usually, a i = 1 is required and the coefficients a i are required to be bounded: <ref type="bibr" target="#b21">[22]</ref>. For the convenience of expression, in the following development we call both the cases convex hull.</p><formula xml:id="formula_2">H (Y ) = a i y i | a i = 1, 0 ≤ a i ≤ τ (2) If τ = 1, H (Y ) is a convex hull [41]. If τ &lt; 1, H (Y ) is a reduced convex hull</formula><p>By modeling a set as a convex hull, the distance between set Y = { y 1 , . . . , y i , . . . , y n a } and set Z = {z 1 , . . . , z j , . . . , z n z } can be defined as follows:</p><formula xml:id="formula_3">min a,b a i y i -b j z j 2 2 s.t. a i = 1, 0 ≤ a i ≤ τ b j = 1, 0 ≤ b j ≤ τ (3)</formula><p>When the two sets have no intersection, the set to set distance in Eq. ( <ref type="formula">3</ref>) becomes the distance between the nearest points in the two convex hulls (CHISD <ref type="bibr" target="#b4">[5]</ref>), as illustrated in Fig. <ref type="figure" target="#fig_4">4</ref>. It is not difficult to see that such a distance is equivalent to the distance computed by SVM <ref type="bibr" target="#b21">[22]</ref>. If the discriminative function of SVM is f = wx + b, then w = a i y ib j z j and the margin is 2/ w . If we consider each image set as one class, then maximizing margin between the two classes is equivalent to finding the set to set distance <ref type="bibr" target="#b41">[42]</ref>. In image set based face recognition, there is usually no intersection between image sets of different persons. If there are intersections between two image sets, then τ can be set as below 1 and the resulting problem can be related with soft-margin SVM and υ-SVM <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b42">[43]</ref>. Unfortunately, such a distance relies highly on the location of each individual sample and can be sensitive to outliers <ref type="bibr" target="#b17">[18]</ref>. More detailed discussions about convex/affine hull based classifiers can be found in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Collaborative Representation Based Set to Sets Distance and Classification</head><p>In image set based face recognition (ISFR), we have a query set Y but multiple gallery sets X k , k = 1, 2, . . . , K . One fact in face recognition is that the face images from different people still have much similarity. If we compute the distance between Y and each X k by using methods such as hull based set to set distance (refer to II-A), the correlation between different gallery sets will not be utilized. As we discussed in the Introduction section, inspired by the SRC <ref type="bibr" target="#b30">[31]</ref> and CRC <ref type="bibr" target="#b31">[32]</ref> methods in image based face recognition, here we propose a novel ISFR method, namely image set based collaborative representation and classification (ISCRC).</p><p>The key component of ISCRC is the collaborative representation based set to sets distance (CRSSD) defined as follows. Let X = [X 1 , . . . , X k , . . . , X K ] be the concatenation of all gallery sets. We model each of Y and X as a hull, i.e., Y a and X b, where a and b are coefficient vectors, and then we define the CRSSD between set Y and sets X as:</p><formula xml:id="formula_4">min a,b Y a -X b 2 s.t. a i = 1 (4)</formula><p>where a i is the i th coefficeint in a and we let a i = 1 to avoid the trivial solution a = b = 0. In Eq. ( <ref type="formula">4</ref>), the hull Y a of the query set Y is collaboratively represented over the gallery sets; however, the coefficients in a will make the samples in Y be treated differently in the representation and the subsequent classification process. By minimizing the distance between Y a and X b, the outliers (e.g., one frame with large corruptions/occlusions) in both the query image set Y and the gallery image sets X will be assigned with very small representation coefficients. Therefore, the impact of outliers can be much alleviated. Our experimental results in Section V showed that ISCRC is robust to face variations in different conditions.</p><p>Suppose that the coefficient vectors â and b are obtained by solving Eq. ( <ref type="formula">4</ref>), then we can write b as b = [ b1 ; ...; bk ; ...; bK ], where bk is is the sub-vector of coefficients associated with gallery set X k . Similar to the classification in SRC and CRC, we use the representation residual of hull Y â by each set X k to determine the class label of Y . The classifier in the proposed ISCRC is:</p><formula xml:id="formula_5">I dentity(Y ) = argmi n k {r k }<label>(5)</label></formula><p>where</p><formula xml:id="formula_6">r k = Y â -X k bk 2 2</formula><p>. Clearly, the solutions to a and b in Eq. (4) determine the CRSSD and hence the result of ISCRC. In order to get stable solutions, we could impose reasonable regularizations on a and b. In the following sections II-C and II-D, we discuss the convex hull based CRSSD and regularized hull based CRSSD, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Convex Hull Based CRSSD</head><p>One important instantiation of CRSSD is the convex hull based CRSSD. In this case, both the hulls Y a and X b are required to be convex hulls, and then the distance in Eq. ( <ref type="formula">4</ref>) becomes</p><formula xml:id="formula_7">min a,b Y a -X b 2 s.t. a i = 1, b j = 1, 0 ≤ a i ≤ τ, i = 1, . . . , n a , 0 ≤ b j ≤ τ, j = 1, . . . , n b (6)</formula><p>where a i and b j are the i th and j th coefficients in a and b, respectively, n a and n b are the number of samples in set Y and sets X, respectively, and τ ≤ 1.</p><p>A geometric illustration of convex hull based CRSSD is shown in Fig. <ref type="figure" target="#fig_5">5</ref>. Different from the CHISD method in <ref type="bibr" target="#b4">[5]</ref>, which models each gallery set as a convex hull, here we model all the gallery sets as one big convex hull. Similar to the closest points searching in SVM, convex hull based CRSSD aims to find the closest points in the query set Y and the whole gallery set X in a large margin manner. With convex hull based CRSSD, the corresponding ISCRC method can be viewed as a large margin based classifier in some sense. Nonetheless, the classification rules in SVM and ISCRC are very different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. l p -Norm Regularized Hull Based CRSSD</head><p>The convex hull modeling of a set can be affected much by outlier samples in the set <ref type="bibr" target="#b17">[18]</ref>. To make CRSSD more stable, the l p -norm regularized hull can be used to model Y and X. For the query set Y , we should keep the constraint a i = 1 to avoid the trivial solution, and the l p -norm regularized hull of Y is defined as</p><formula xml:id="formula_8">H (Y ) = { a i y i | a l p &lt; δ} s.t. a i = 1 (7)</formula><p>For the gallery set X, its regularized hull is defined as:</p><formula xml:id="formula_9">H (X) = { b i x i | b l p &lt; δ} (8)</formula><p>Finally, the regularized hull based CRSSD between Y and X is defined as:</p><formula xml:id="formula_10">min a,b Y a -X b 2 2 s.t. a l p &lt; δ 1 , b l p &lt; δ 2 , a i = 1<label>( 9 )</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. REGULARIZED HULL BASED ISCRC</head><p>In Section II, we introduced CRSSD, and presented two important instantiations of it, i.e., convex hull based CRSSD and regularized hull based CRSSD. With either one of them, the ISCRC (refer to Eq. ( <ref type="formula" target="#formula_5">5</ref>)) can be implemented to perform ISFR. In this section, we discuss the minimization of regularized hull based CRSSD model, and the corresponding classification scheme is called regularized hull based ISCRC, denoted by RH-ISCRC. The minimization of convex hull based CRSSD and the corresponding classification scheme will be discussed in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Main Model</head><p>We can re-write the regularized hull based CRSSD model in Eq. ( <ref type="formula" target="#formula_10">9</ref>) as its Lagrangian formulation:</p><formula xml:id="formula_11">min a,b Y a -X b 2 2 + λ 1 a l p + λ 2 b l p s.t. a i = 1 (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where λ 1 and λ 2 are positive constants to balance the representation residual and the regularizer.</p><p>In ISFR, each gallery set X k often has tens to hundreds of sample images so that the whole set X can be very big, making the computational cost to solve Eq. ( <ref type="formula" target="#formula_11">10</ref>) very high. Considering the fact that the images in each set X k have high redundancy, we can compress X k into a much more compact set, denoted by D k , via dictionary learning methods <ref type="bibr" target="#b44">[45]</ref>, such as KSVD <ref type="bibr" target="#b45">[46]</ref> and metaface learning <ref type="bibr" target="#b46">[47]</ref>.</p><formula xml:id="formula_13">Let D = [D 1 , . . . , D k , . . . , D K ].</formula><p>We can then replace X by D in Eq. <ref type="bibr" target="#b9">(10)</ref> to compute the regularized hull based CRSSD</p><formula xml:id="formula_14">( â, β) = arg min a,β Y a -Dβ 2 2 + λ 1 a l p + λ 2 β l p s.t. a i = 1 (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>where β = [β 1 ; ...; β k ; ...; β K ] and β k is the sub-vector of coefficients associated with D k . Based on our experimental results, compressing X k into D k significantly improve the speed with almost the same ISFR rate.</p><p>Either l 1 -norm or l 2 -norm can be used to regularize a and β, while l 1 -regularization will lead to sparser solutions but with more computational cost. Like in l 1 -SVM <ref type="bibr" target="#b47">[48]</ref> and SRC <ref type="bibr" target="#b30">[31]</ref>,</p><p>sparsity can enhance the classification rate if the features are not informative enough. Note that if the query set Y has only one sample, then a = 1 and the proposed model in Eq. ( <ref type="formula" target="#formula_14">11</ref>) will be reduced to the SRC (for l 1 -regularization) or CRC (for l 2 -regularization) scheme. Next, we present the optimization of l 2 -norm and l 1 -norm regularized hull based ISCRC in Section III-B and Section III-C, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. l 2 -Norm Regularized Hull Based ISCRC</head><p>When l 2 -norm is used to regularize a and β, the problem in Eq. ( <ref type="formula" target="#formula_14">11</ref>) has a closed-form solution. The Lagrangian function of Eq. ( <ref type="formula" target="#formula_14">11</ref>) becomes</p><formula xml:id="formula_16">L(a, β, λ 3 ) = Y a-Dβ 2 2 + λ 1 a 2 2 + λ 2 β 2 2 + λ 3 (ea-1) = [Y -D] a β 2 2 + a T β T λ 1 I 0 0 λ 2 I a β + λ 3 ([e 0] a β -1) (<label>12</label></formula><formula xml:id="formula_17">)</formula><p>where e is a row vector whose elements are 1. Let</p><formula xml:id="formula_18">z = a β , A = [Y -D], B = λ 1 I 0 0 λ 2 I</formula><p>and d = [e 0] T . Then Eq. ( <ref type="formula" target="#formula_16">12</ref>) becomes</p><formula xml:id="formula_19">L(z, λ 3 ) = z T A T Az + z T Bz + λ 3 (d T z -1)<label>(13)</label></formula><p>There are</p><formula xml:id="formula_20">∂ L ∂λ 3 = d T z -1 = 0 (14) ∂ L ∂z = A T Az + Bz + λ 3 d = 0<label>(15)</label></formula><p>According to Eq. ( <ref type="formula">14</ref>) and Eq. ( <ref type="formula" target="#formula_20">15</ref>), we get the closed form solution to Eq. ( <ref type="formula" target="#formula_16">12</ref>):</p><formula xml:id="formula_21">ẑ = âβ = z 0 /d T z 0 (<label>16</label></formula><formula xml:id="formula_22">)</formula><p>where</p><formula xml:id="formula_23">z 0 = ( A T A + B) -1 d.</formula><p>After â and β are got, the distance between query set Y and a gallery set X k is calculated as</p><formula xml:id="formula_24">r k = Y â -D k βk | 2</formula><p>2 , and then the class label of Y is determined by Eq. ( <ref type="formula" target="#formula_5">5</ref>). For RH-ISCRC-l 2 , the main time consumption is to solve the inverse of matrix ( A T A + B). Hence, the time complexity of RH-ISCRC-l 2 is O( n a + n β 3 ), where n a is the number of sample images in Y and n β is the number of atoms in D.</p><p>The CRNP method <ref type="bibr" target="#b25">[26]</ref> also collaboratively represents the query set over the gallery sets. The differences between the proposed RH-ISCRC-l 2 and CRNP lie in the optimization procedure and the classification rule. RH-ISCRC-l 2 has a closedform solution while CRNP adopts the same optimization method as RNP <ref type="bibr" target="#b23">[24]</ref>, which iteratively converges to the global optimal solution. Besides, CRNP uses the same classification rule as RNP, which utilizes both the reconstruction error and rank of image set matrix. RH-ISCRC-l 2 only uses the reconstruction error for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. l 1 -Norm Regularized Hull Based ISCRC</head><p>When l 1 -norm regularization is used, we use the alternating minimization method, which is very efficient to solve multiple variable optimization problems <ref type="bibr" target="#b48">[49]</ref>. For Eq. ( <ref type="formula" target="#formula_14">11</ref>), we have the following augmented Lagrangian function:</p><formula xml:id="formula_25">L(a, β, λ) = Y a -Dβ 2 2 + λ 1 a 1 + λ 2 β 1 + λ, ea -1 + γ 2 ea -1 2 2 (<label>17</label></formula><formula xml:id="formula_26">)</formula><p>where λ is the Lagrange multiplier, •, • is the inner product, and γ &gt; 0 is the penalty parameter.</p><p>Then a and β are optimized alternatively with the other one fixed. More specifically, the iterations of minimizing a go as follows:</p><formula xml:id="formula_27">a (t +1) = arg min a L(a, β (t ) , λ (t ) ) = arg min a f (a) + γ 2 ea -1 + λ (t ) /γ 2 2 = arg min a Ỹ a -x 2 2 + λ 1 a 1 (<label>18</label></formula><formula xml:id="formula_28">)</formula><p>where</p><formula xml:id="formula_29">f (a) = Y a -Dβ (t ) 2 2 +λ 1 a l p , Ỹ = [Y ; (γ /2) 1/2 e], x = [Dβ (t ) ; (γ /2) 1/2 (1 -λ (t ) /γ )].</formula><p>The problem in Eq. ( <ref type="formula" target="#formula_27">18</ref>) can be easily solved by some representative l 1 -minimization approaches such as LARS <ref type="bibr" target="#b49">[50]</ref>.</p><p>After a (t +1) is updated, β (t +1) can be obtained by solving another l 1 -regularized optimization problem:</p><formula xml:id="formula_30">β (t +1) = arg min β L(a (t +1) , β, λ t ) = arg min β Y a (t +1) -Dβ 2 2 + λ 2 β 1 (19)</formula><p>Once a (t +1) and β (t +1) are got, λ is updated as follows:</p><formula xml:id="formula_31">λ (t +1) = λ (t ) + γ ea (t +1) -1<label>(20)</label></formula><p>The algorithm of RH-ISCRC-l 1 for ISFR is summarized in Table <ref type="table" target="#tab_2">II</ref> and it converges. The problem in Eq. ( <ref type="formula" target="#formula_25">17</ref>) is convex, and the subproblems in Eq. ( <ref type="formula" target="#formula_27">18</ref>) and Eq. ( <ref type="formula">19</ref>) are convex and can be solved using the LARS algorithm. It had been shown in <ref type="bibr" target="#b50">[51]</ref>, for the general convex problem, the alternating minimization approach would converge to the correct solution. One curve of the objective function value of RH-ISCRC-l 1 versus the iteration number is shown in Fig. <ref type="figure">6</ref>. Honda/USCD database <ref type="bibr" target="#b13">[14]</ref> is also used. The query set Y and each gallery set X k has 200 frames. Note that one image set is acquired from one video clip and there is no intersection between the query set and each gallery set. We compress each set X k into a dictionary D k with 20 atoms by using the metaface learning method <ref type="bibr" target="#b46">[47]</ref>. Since there are 20 gallery sets, the set D = [D 1 , . . . , D k , . . . , D 20 ] has 20 × 20 = 400 atoms. From the figure we can see that RH-ISCRC-l 1 converges after about five iterations.</p><p>Since the complexity of sparse coding is O(m 2 n ε ), where m is the feature dimension, n is the atom number and ε ≥ 1.2 <ref type="bibr" target="#b51">[52]</ref>, we can get that the time complexity of</p><formula xml:id="formula_32">RH-ISCRC-l 1 is O(lm 2 (n a ε + n β ε ))</formula><p>, where n a is the number of samples in Y , n β is the number of atoms in D and l is the iteration number.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Examples and Discussions</head><p>Let's use an example to better illustrate the classification process of RH-ISCRC. We use the Honda/USCD database <ref type="bibr" target="#b13">[14]</ref>. The experiment setting is the same as Fig. <ref type="figure">6</ref>. By Eq. ( <ref type="formula" target="#formula_14">11</ref>), the computed coefficients in a and β are plotted in Fig. <ref type="figure" target="#fig_6">7</ref> (by l 1 -regularization) and Fig. <ref type="figure">8</ref> (by l 2 -regularization), respectively. The highlighted coefficients in the figures are associated with set X 10 , which has the same class label as Y . Clearly, these coefficients are much more significant than the coefficients associated with the other classes. Meanwhile, from Fig. <ref type="figure" target="#fig_6">7</ref> and Fig. <ref type="figure">8</ref> we can see that l 1 -regularized hull based CRSSD leads to sparser a and β, implying that only few samples are dominantly involved in representation and classification.</p><p>In Fig. <ref type="figure" target="#fig_7">9</ref>, we show the reconstructed faces by Y â with l 1 -regularized hull based CRSSD. The distances between Y â and each D k βk , i.e., r k , are also given. We see that r 10 is 0.03, which is the minimal one among all the gallery sets, meaning that ISCRC will make the correct recognition.</p><p>Here the relationships between ISCRC and manifold based methods can be revealed. MMD assumes that an image set can be modeled as a set of local subspaces so that the image set distance is defined as the weighted average distance between any two local subspaces <ref type="bibr" target="#b3">[4]</ref>. The distance between two local subspaces is related to the cluster exemplar and principle angel. Correspondingly, ISCRC seeks for a local subspace (Y â) in the query image set and a local subspace ( D β) in all the gallery sets, as shown in Fig. <ref type="figure" target="#fig_6">7</ref>. In classification, the distance between the query set and the template set of the k th class is the distance between the local subspace (Y â) and the local subspace D k βk .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. KERNELIZED CONVEX HULL BASED ISCRC</head><p>We then focus on how to compute the convex hull based CRSSD in Eq. ( <ref type="formula">6</ref>) and use it for ISCRC. Since there can be many sample images in gallery sets, X can be a fat matrix (note that usually we use a low dimensional feature vector to represent each face image). Even we compress X into a more compact set D, the system can still be under-determined. In Section 3 we imposed the l p -norm regularization on a and b to make the solution stable. When the convex hull is used, however, the constraint may not be strong enough to get a stable solution of Eq. ( <ref type="formula">6</ref>). In addition, if the underlying relationship between the query set and gallery sets is highly nonlinear, it is difficult to approximate the hull of query set as a linear combination of gallery sets.</p><p>One simple solution to solving both the above two problems is the kernel trick; that is, we can map the data into a higher dimensional space where the subjects can be approximately linearly separable. The mapped gallery data matrix in the highdimensional space will be generally over-determined. In such a case, the convex hull constraint will be strong enough for a stable solution. The kernelized convex hull based CRSSD  model is</p><formula xml:id="formula_33">min a,β φ(Y )a -[φ( D 1 ), φ( D 2 ), . . . , φ(D K )] β 2 s.t. a i = 1, β j = 1, 0 ≤ a i ≤ τ, i = 1, . . . , n a , 0 ≤ β j ≤ τ, j = 1, . . . , n β .<label>(21)</label></formula><p>The above minimization can be easily solved by the standard quadratic optimization (QP <ref type="bibr" target="#b52">[53]</ref>) method. The solution exhibits global and quadratic convergence, as proved in <ref type="bibr" target="#b52">[53]</ref>. Different kernel functions can be used, e.g., linear kernel and Gaussian kernel. We call the corresponding method kernelized convex hull based ISCRC, denoted by KCH-ISCRC. The classification rule is the same as RH-ISCRC with</p><formula xml:id="formula_34">r k = φ(Y ) â -φ( D k ) βk 2 2 .</formula><p>As convex hull based CRSSD is to solve a convex QP problem, the time complexity of KCH-ISCRC is O((n β +n a ) 3 ), which is similar to SVM. The algorithm of KCH-ISCRC is given in Table <ref type="table" target="#tab_3">III</ref>. To reduce the computational cost, the kernel matrix k( D, D) can be computed and stored. When a query set Y comes, we only need to calculate k(Y , Y ) and k(Y , D).</p><p>Like in Fig. <ref type="figure" target="#fig_6">7</ref> and Fig. <ref type="figure">8</ref>, in Fig. <ref type="figure" target="#fig_8">10</ref> we show the coefficient vectors â and β solved by Eq. ( <ref type="formula" target="#formula_33">21</ref>). The Gaussian kernel is used and the experimental setting is the same as that in Figs. <ref type="figure" target="#fig_6">7</ref> and<ref type="figure">8</ref> (the only difference is that each compressed gallery set D k has 50 atoms). We can see that the coefficients associated with gallery set D 10 are larger than the other gallery sets, resulting in a smaller representation residual and hence the correct recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL ANALYSIS</head><p>We used the Honda/UCSD <ref type="bibr" target="#b13">[14]</ref>, CMU Mobo <ref type="bibr" target="#b53">[54]</ref>, and Youtube Celebrities <ref type="bibr" target="#b54">[55]</ref> datasets to test the performance of the proposed method. The comparison methods fall into four categories: C1. Subspace and manifold based methods: Mutual Subspace Method (MSM) <ref type="bibr" target="#b0">[1]</ref>, Discriminant Canonical Correlations based Classifier (SRC) <ref type="bibr" target="#b30">[31]</ref>, Collaborative Representation based Classifier (CRC) <ref type="bibr" target="#b31">[32]</ref>. We tested to use the average and minimal representation residual of query set for classification and found that average residual works better. Hence in this paper, the average residual is used in SRC/CRC for classification. C4. Kernel methods: KSRC (Kernel SRC) <ref type="bibr" target="#b55">[56]</ref>, KCRC (Kernel CRC) <ref type="bibr" target="#b34">[35]</ref>, AHISD <ref type="bibr" target="#b4">[5]</ref>, and CHISD <ref type="bibr" target="#b4">[5]</ref>. For KSRC and KCRC, the average residual is used for classification. For the proposed methods, RH-ISCRC is compared with those non-kernel methods and KCH-ISCRC is compared with those kernel methods. The Matlab source code of the proposed ISCRC method can be downloaded at http://www.comp.polyu.edu.hk/∼cslzhang/code/ISCRC.zip.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Setting</head><p>For competing methods, the important parameters were empirically tuned according to the recommendations in the original literature for fair comparison. For DCC <ref type="bibr" target="#b10">[11]</ref>, if there is only one set per class, then the training set is divided into two sets since at least two sets per class are needed in DCC. For MMD, the number of local models is set following the work in <ref type="bibr" target="#b3">[4]</ref>. For MDA, there are three parameters, i.e., the number of local models, the number of between-class NN local models and the subspace dimension. The three parameters are configured according to the work in <ref type="bibr" target="#b11">[12]</ref>. For SANP, we adopted the same parameters as <ref type="bibr" target="#b7">[8]</ref>. For SRC, CRC, KSRC and KCRC, λ that balances the residual and regularization is tuned from [0.01, 0.001, 0.0001]. For AHISD and CHISD, C is set as 100. For all kernel methods, Gaussian kernel (k(x, y) = exp(-xy 2  2 /2δ 2 )) is used, and δ is set as 5. The experiments of 50 frames, 100 frames and 200 frames per set are conducted on the three databases. If the number of samples in the set is less than the given number, then all the samples in the set are used.</p><p>For the proposed RH-ISCRC, we set λ 1 = 0.001, λ 2 = 0.001, λ = 2.5/n a (n a is the number of samples in the query set), γ = λ/2. The number of atoms in the compressed set D k is set as 20 on Honda/UCSD and 10 on CMU MoBo and YouTube. For KCH-ISCRC, τ = 1 and the number of atoms in each D k is set as 50 for all datasets. The sensitivity   of the proposed methods to parameters will be discussed in Section V-F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Honda/UCSD</head><p>The Honda/UCSD dataset consists of 59 video sequences involving 20 different subjects <ref type="bibr" target="#b13">[14]</ref>. The Viola-Jones face detector <ref type="bibr" target="#b56">[57]</ref> is used to detect the faces in each frame and resize the detected faces to 20×20 images. Some examples of Honda/UCSD dataset are shown in Figure <ref type="figure" target="#fig_10">11</ref>. Histogram equalization is utilized to reduce the illumination variations. Our experiment setting is the same as <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b13">[14]</ref>: 20 sequences are set aside for training and the remaining 39 sequences for testing. The intensity is used as the feature.</p><p>The experimental results are listed in Table <ref type="table" target="#tab_5">IV</ref>. We can see that for those non-kernel methods, the proposed RH-ISCRC outperforms much all the other methods. Note that in <ref type="bibr" target="#b4">[5]</ref>, kernel CHISD achieves 100% recognition accuracy when all the frames in one video clip are used. In this paper, following the experiment setting of SANP <ref type="bibr" target="#b7">[8]</ref>, we reported the accuracy using different number of frames per set. When 200 frames per set are used, both RH-ISCRC and KCH-ISCRC achieve 100% accuracy, which shows the superiority to CHISD and AHISD. For the kernel based method, the proposed KCH-ISCRC performs the best except for the case when 100 frames per set are used. We can also see that on this dataset, RH-ISCRC-l 1 and RH-ISCRC-l 2 achieve the same recognition rate, which implies that on this dataset the l 2 -norm regularization is strong enough to yield a good solution to the regularized hull based CRSSD in Eq. <ref type="bibr" target="#b10">(11)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CMU</head><p>The CMU Mobo 8 (Motion of Body) dataset <ref type="bibr" target="#b53">[54]</ref> was originally established for human pose identification and it contains 96 sequences from 24 subjects. Four video sequences are collected per subject, each of which corresponds to a walking pattern. Again, the Viola-Jones face detector <ref type="bibr" target="#b56">[57]</ref> is used to detect the faces and the detected face images are resized to 40 × 40. The LBP feature is used, which is the same as the work in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b7">[8]</ref>.</p><p>One video sequence per subject is selected for training while the rest are used for testing. Ten-fold cross validation experiments are conducted and the average recognition results are shown in Table <ref type="table" target="#tab_6">V</ref>. We can clearly see that the proposed methods outperform the other methods under different frames per set. On this dataset and the Honda/UCSD dataset, the proposed non-kernel RH-ISCRC and the kernel based KCH-ISCRC have similar ISFR rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. YouTube Celebrities</head><p>The YouTube Celebrities 9 is a large scale video dataset collected for face tracking and recognition, consisting of 1,910 video sequences of 47 celebrities from YouTube <ref type="bibr" target="#b54">[55]</ref>. As the videos were captured in unconstrained environments, the recognition task becomes much more challenging due to the larger variations in pose, illumination and expressions. Some examples of YouTube Celebrities dataset are shown in Figure <ref type="figure" target="#fig_11">12</ref>. The face in each frame is also detected by the Viola-Jones face detector and resized to a 30 × 30 gray-scale image. The intensity value is used as feature. The experiment setting is the same as <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Three video sequences per subject are selected for training and six for testing. Five-fold cross validation experiments are conducted.</p><p>The experimental results are shown in   among the kernel based methods, the proposed KCH-ISCRC performs the best. Since this Youtube Celebrities dataset was established under uncontrolled environment, there are significant variations among the query and gallery sets, and therefore the l 1 -regularization is very helpful to improve the stability and discrimination of the solution to Eq. <ref type="bibr" target="#b10">(11)</ref>. As a consequence, RH-ISCRC-l 1 leads to much better results than RH-ISCRC-l 2 on this dataset. On the other hand, the kernel based KCH-ISCRC leads to better results than RH-ISCRC in this experiment. Besides, the number of frames per set also affect the performance of ISCRC. When number of frames is small, the improvement by ISCRC is more significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Time Comparison</head><p>Then let's compare the efficiency of competing methods. The Matlab codes of all competing methods are obtained from the original authors, and we run them on an Intel(R) Core(TM) i7-2600K (3.4GHz) PC. The average running time per set on CMU MoBo (200 frames per set) is listed in Table <ref type="table" target="#tab_9">VII</ref>. We can see that the proposed RH-ISCRC-l 2 is the fastest among all competing methods except for RNP, while RH-ISCRC-l 1 also has a fast speed. Among all the kernel based methods, the proposed KCH-ISCRC is much faster than others. Overall, the proposed RH-ISCRC and KCH-ISCRC methods have not only high ISFR accuracy but also high efficiency than the competing methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Parameter Sensitivity Analysis</head><p>To verify if the proposed methods are sensitive to parameters, in this section we present the recognition accuracies with different parameter values. For RH-ISCRC, there are two parameters, λ 1 and λ 2 in Eq. ( <ref type="formula" target="#formula_25">17</ref>), which need to be set. For KCH-ISCRC, there is only one parameter τ in Eq. ( <ref type="formula" target="#formula_5">5</ref>). We show the recognition accuracies versus the parameters on the CMU MoBo dataset in Fig. <ref type="figure" target="#fig_3">13</ref>, Fig. <ref type="figure" target="#fig_12">14</ref> and Fig. <ref type="figure" target="#fig_13">15</ref>, respectively, for RH-ISCRC-l 1 , RH-ISCRC-l 2 and KCH-ISCRC. The different colors correspond to different accuracies, as shown in the color bar. λ 1 and λ 2 are selected from {0.0005, 0.001, 0.01, 0.05}. In Fig. <ref type="figure" target="#fig_3">13</ref> and Fig. <ref type="figure" target="#fig_12">14</ref>, the top sub-figure is for 50 frames per set, the middle is for 100 frames per set and the bottom corresponds to 200 frames per set. From Fig. <ref type="figure" target="#fig_3">13</ref>, we can see that the accuracy of RH-ISCRC-l 1 is very stable when λ 1 varies from 0.0005 to 0.05 and λ 2 varies from 0.0005 to 0.01. When λ 2 is increased to 0.05, the recognition performance would degrade. Fig. <ref type="figure" target="#fig_12">14</ref> shows that RH-ISCRC-l 2 is insensitive to  the values of λ 1 and λ 2 . For example, in the experiments of 100 and 200 frames per set, the accuracy variation is within 0.5% for different λ 1 and λ 2 . Considering the performance of both RH-ISCRC-l 1 and RH-ISCRC-l 2 , λ 1 and λ 2 can both be set as 0.001. With this parameter setting, the accuracy is very stale in different experiments. For KCH-ISCRC, its recognition accuracies with different values of τ are shown in Fig. <ref type="figure" target="#fig_13">15</ref>. τ is set as {1, 2, 5, 10, 50, 100}. One can see that KCH-ISCRC is insensitive to τ . Hence, we simply set τ as 1.</p><p>The dictionary learning technique is used in our method to compress each image set to reduce the time complexity when representing a query image set. The number of atoms in the dictionary needs to be defined before dictionary learning. If the number of atoms is too small, the representation power of the dictionary will be reduced; if the number of atoms is large, the system tends to be under-determined and thus the solution may be less stable. We tested our algorithm by varying the number of atoms (for each sub-dictionary D k ) from 5 to 50. The recognition accuracies versus the number of atoms on the   CMU MoBo dataset are shown in Figs. <ref type="bibr">16-18.</ref> From Fig. <ref type="figure" target="#fig_14">16</ref> and Fig. <ref type="figure" target="#fig_15">17</ref>, we can see that the recognition accuracies of both RH-ISCRC-l 1 and RH-ISCRC-l 2 vary little if the number of atoms is set within <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20]</ref>. From Fig. <ref type="figure" target="#fig_16">18</ref>, we can see that for KCH-ISCRC the variation of recognition accuracies is within 0.5% under different number of atoms. This is because the feature dimension is relatively high in the kernel space and thus the solution is affected little by the dictionary size. Based on the above observation, in all our experiments we set the number of atoms as 10 or 20 for RH-ISCRC-l 1 and RH-ISCRC-l 2 , and 50 for KCH-ISCRC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We proposed a novel image set based collaborative representation and classification (ISCRC) scheme for image set based face recognition (ISFR). The query set was modeled as a convex or regularized hull, and a collaborative representation based set to sets distance (CRSSD) was defined by representing the hull of query set over all the gallery sets. The CRSSD considers the correlation and distinction of sample images within the query set and the relationship between the gallery sets. With CRSSD, the representation residual of the hull of query set by each gallery set can be computed and used for classification. Experiments on the three benchmark ISFR databases showed that the proposed ISCRC is superior to state-of-the-art ISFR methods in terms of both recognition rates and efficiency.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Abstract-</head><label></label><figDesc>With the rapid development of digital imaging and communication technologies, image set-based face recognition (ISFR) is becoming increasingly important. One key issue of ISFR is how to effectively and efficiently represent the query face image set using the gallery face image sets. The set-to-set distance-based methods ignore the relationship between gallery sets, whereas representing the query set images individually over the gallery sets ignores the correlation between query set images. In this paper, we propose a novel image set-based collaborative representation and classification method for ISFR. By modeling the query set as a convex or regularized hull, we represent this hull collaboratively over all the gallery sets. With the resolved representation coefficients, the distance between the query set and each gallery set can then be calculated for classification. The proposed model naturally and effectively extends the imagebased collaborative representation to an image set based one, and our extensive experiments on benchmark ISFR databases show the superiority of the proposed method to state-of-the-art ISFR methods under different set sizes in terms of both recognition rate and efficiency. Index Terms-Collaborative representation, face recognition, image set, set to sets distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Image set based collaborative representation and classification (ISCRC).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of image set margin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Margin comparison between ISCRC and CHISD (a) and RNP (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Convex hull based set to set distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Convex hull based CRSSD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The coefficient vectors â (of Y ) and β (of D) by l 1 -regularized hull based CRSSD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Reconstructed faces Y â, D β, D k βk (we normalized each D k βk for better visualization). The number over each D k βk is the residual r k = Y â -D k βk 2 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The coefficient vectors â (of Y ) and β (of D) by kernelized convex hull based CRSSD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>(DCC 2 )</head><label>2</label><figDesc><ref type="bibr" target="#b10">[11]</ref>, Manifold-Manifold Distance (MMD 3 ) [4], and Manifold Discriminant Analysis (MDA 4 ) [12]. C2. Affine/convex hull based methods: Affine Hull based Image Set Distance (AHISD 5 ) [5], Convex Hull based Image Set Distance (CHISD 6 ) [5], Sparse Approximated Nearest Points (SANP 7 ) [8], and Regularized Nearest Points (RNP) [24]. C3. Representation based methods: Sparse Representation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Some examples of Honda/UCSD dataset</figDesc><graphic coords="8,381.95,58.61,110.06,78.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Some examples of YouTube Celebrities dataset</figDesc><graphic coords="9,387.95,58.13,99.02,78.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Recognition accuracy of RH-ISCRC-l 2 on CMU MoBo with different λ 1 and λ 2 . Different colors represent different accuracy. Top: 50 frames per set; middle: 100 frames per set; bottom: 200 frames per set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Recognition accuracy of KCH-ISCRC on CMU MoBo with different τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .</head><label>16</label><figDesc>Fig.<ref type="bibr" target="#b15">16</ref>.Recognition accuracy of RH-ISCRC-l 1 on CMU MoBo with different number of atoms per set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17.Recognition accuracy of RH-ISCRC-l 2 on CMU MoBo with different number of atoms per set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Recognition accuracy of KCH-ISCRC on CMU MoBo with different number of atoms per set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Image Set-Based Collaborative Representation for Face Recognition Pengfei Zhu, Student Member, IEEE, Wangmeng Zuo, Member, IEEE, Lei Zhang, Member, IEEE, Simon Chi-Keung Shiu, Member, IEEE, and David Zhang, Fellow, IEEE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II ALGORITHM</head><label>II</label><figDesc>OF RH-ISCRC FOR ISFR Fig.6. of RH-ISCRC-l 1 .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III ALGORITHM</head><label>III</label><figDesc>OF KCH-ISCRC FOR ISFR</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>2 http://www.iis.ee.ic.ac.uk/ tkkim/code.htm 3 http://www.jdl.ac.cn/user/rpwang/research.htm 4 http://www.jdl.ac.cn/user/rpwang/research.htm 5 http://www2.ogu.edu.tr/ mlcv/softwareimageset.html 6 http://www2.ogu.edu.tr/ mlcv/softwareimageset.html 7 https://sites.google.com/site/yiqunhu/cresearch/sanp</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV RECOGNITION</head><label>IV</label><figDesc>RATES ON HONDA/UCSD (%)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V RECOGNITION</head><label>V</label><figDesc>RATES ON CMU MOBO(%)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table VI .</head><label>VI</label><figDesc>It can be seen that among the non-kernel methods, the proposed RH-ISCRC-l 1 achieves the highest recognition rate, while 8 http://www.ri.cmu.edu/publication_ view.html?pub_id=3904</figDesc><table /><note><p><p>9 </p>http://seqam.rutgers.edu/site/index.php?option=com_content&amp;view=article &amp;id = 64&amp;Itemid=80</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VI RECOGNITION</head><label>VI</label><figDesc>RATES ON YOUTUBE (V1 %)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VII AVERAGE</head><label>VII</label><figDesc>RUNNING TIME PER SET ON CMU MoBo (s) Fig. 13. Recognition accuracy of RH-ISCRC-l 1 on CMU MoBo with different λ 1 and λ 2 . Different colors represent different accuracy. Top: 50 frames per set; middle: 100 frames per set; bottom: 200 frames per set.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank T. Kim for sharing the source code of DCC, S. Gao for the source code of KSRC and Y. Hu for the source code of SANP. We thank R. Wang for sharing the source code of MMD and MDA, and the cropped faces of the Honda/UCSD dataset and YouTube Celebrities dataset. We also thank H. Cevikalp for sharing the source code of AHISD/CHISD and providing the LBP features for the Mobo dataset.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the Research Grants Council, Public Policy Research Funding Scheme, Hong Kong, under Grant K-QZ09.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Face recognition using temporal image sequence</title>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-I</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd IEEE Conf. Autom. Face Gesture Recognit</title>
		<meeting>3rd IEEE Conf. Autom. Face Gesture Recognit</meeting>
		<imprint>
			<date type="published" when="1998-04">Apr. 1998</date>
			<biblScope unit="page" from="318" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face recognition with image sets using manifold density divergence</title>
		<author>
			<persName><forename type="first">O</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="page" from="581" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recognizing faces of moving people by hierarchical image-set matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nishiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wakasugi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2007-06">Jun. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Manifold-manifold distance with application to face recognition based on image set</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Face recognition based on image sets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cevikalp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="2567" to="2573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An evaluation of video-to-video face verification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Poh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="781" to="801" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Face recognition in unconstrained videos with matched background similarity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Maoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="529" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sparse approximated nearest points for image set classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image sets alignment for video-based face recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="2626" to="2633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dictionarybased face recognition from video</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="766" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discriminative learning and recognition of image set classes using canonical correlations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1005" to="1018" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Manifold discriminant analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="429" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Face verification using the LARK representation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1275" to="1286" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Video-based face recognition using probabilistic appearance manifolds</title>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
			<biblScope unit="page" from="313" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Video-based face recognition on real-world data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stallkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Ekenel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2007-10">Oct. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">From still image to video-based face recognition: An experimental analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Autom. Face Gesture Recognit</title>
		<meeting>IEEE Conf. Autom. Face Gesture Recognit</meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="page" from="813" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Locally linear models on face appearance manifolds with application to dual-subspace based classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2006-06">Jun. 2006</date>
			<biblScope unit="page" from="1384" to="1390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Covariance discriminative learning: A natural and efficient approach to image set classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="2496" to="2503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rolling Riemannian manifolds to solve the multi-class classification problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kernel methods on the Riemannian manifold of symmetric positive definite matrices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Manifold-manifold distance and its application to face recognition with image sets</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4466" to="4479" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A geometric interpretation of v-svm classifiers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Crisp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="244" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Face recognition using sparse approximated nearest points between image sets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1992" to="2004" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Face recognition based on regularized nearest points between image sets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Autom. Face Gesture Recognit</title>
		<meeting>IEEE Conf. Autom. Face Gesture Recognit</meeting>
		<imprint>
			<date type="published" when="2013-04">Apr. 2013</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Set based discriminative ranking for recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Minoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mukunoki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="497" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Collaboratively regularized nearest points for set based recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Minoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mukunoki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A framework for 3D object recognition using the kernel constrained mutual subspace method</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kernel discriminant transformation for image set-based face recognition</title>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><forename type="middle">J</forename><surname>Lien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1567" to="1580" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Generalized discriminant analysis using a kernel approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Baudat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Anouar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2385" to="2404" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overview and recent advances in partial least squares</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rosipal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krämer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Subspace, Latent Structure and Feature Selection</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="34" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sparse representation or collaborative representation: Which helps face recognition?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Regularized robust coding for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1753" to="1766" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sparse representation with kernels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-T</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="423" to="434" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust kernel representation with statistical local features for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="900" to="912" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Margin analysis of the LVQ algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Navot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="462" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Boosting as a regularized path to a maximum margin classifier</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="941" to="973" />
			<date type="published" when="2004-08">Aug. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1473" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Margin based feature selection-theory and algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Navot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A max-margin perspective on sparse representation-based classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
			<biblScope unit="page" from="1217" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>Princeton, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton Univ. Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Large margin classifiers based on affine hulls</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cevikalp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Küçük</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Küçük</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barkana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="3160" to="3168" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Duality and geometry in SVM classifiers</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Bredensteiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Geometric algorithms to large margin classifier based on affine hulls</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="236" to="246" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dictionary-based face recognition under variable lighting and pose</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="954" to="965" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Efficient implementation of the K-SVD algorithm using batch orthogonal matching pursuit</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<idno>CS-2008-08</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Technion, Haifa, Israel</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Metaface learning for sparse representation based face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICIP</title>
		<meeting>IEEE ICIP</meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
			<biblScope unit="page" from="1601" to="1604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">1-norm support vector machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Convergence theorems for generalized alternating minimization procedures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gunawardana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2049" to="2073" />
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Least angle regression</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="499" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adaptive alternating minimization algorithms</title>
		<author>
			<persName><forename type="first">U</forename><surname>Niesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Wornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1423" to="1429" />
			<date type="published" when="2009-03">Mar. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An interiorpoint method for large-scale l1-regularized least squares</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gorinevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="606" to="617" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A reflective newton method for minimizing a quadratic function subject to bounds on some of the variables</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1040" to="1058" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The CMU motion of body (MoBo) database</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Face tracking and recognition with visual constraints in real-world videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Kernel sparse representation for image classification and face recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-T</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">His research interests are focused on machine learning and computer vision</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pengfei Zhu received the B.S. and M.S. degrees from the Harbin Institute of Technology</title>
		<meeting><address><addrLine>Harbin, China; Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2009 and 2011</date>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="137" to="154" />
		</imprint>
		<respStmt>
			<orgName>Hong Kong Polytechnic University</orgName>
		</respStmt>
	</monogr>
	<note>Robust real-time face detection</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
