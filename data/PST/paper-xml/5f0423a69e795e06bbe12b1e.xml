<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-06-04">4 Jun 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
							<email>zhangjianwei.zjw@alibaba-inc.com</email>
						</author>
						<author>
							<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
							<email>jingren.zhou@alibaba-inc.com</email>
						</author>
						<author>
							<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
							<email>yang.yhx@alibaba-inc.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-06-04">4 Jun 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3447548.3467102</idno>
					<idno type="arXiv">arXiv:2005.12964v9[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender systems</term>
					<term>candidate generation</term>
					<term>bias reduction</term>
					<term>inverse propensity weighting</term>
					<term>contrastive learning</term>
					<term>negative sampling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep candidate generation (DCG) that narrows down the collection of relevant items from billions to hundreds via representation learning has become prevalent in industrial recommender systems. Standard approaches approximate maximum likelihood estimation (MLE) through sampling for better scalability and address the problem of DCG in a way similar to language modeling. However, live recommender systems face severe exposure bias and have a vocabulary several orders of magnitude larger than that of natural language, implying that MLE will preserve and even exacerbate the exposure bias in the long run in order to faithfully fit the observed samples. In this paper, we theoretically prove that a popular choice of contrastive loss is equivalent to reducing the exposure bias via inverse propensity weighting, which provides a new perspective for understanding the effectiveness of contrastive learning. Based on the theoretical discovery, we design CLRec, a Contrastive Learning method to improve DCG in terms of fairness, effectiveness and efficiency in Recommender systems with extremely large candidate size. We further improve upon CLRec and propose Multi-CLRec, for accurate multi-intention aware bias reduction. Our methods have been successfully deployed in Taobao, where at least four-month online A/B tests and offline analyses demonstrate its substantial improvements, including a dramatic reduction in the Matthew effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>‚Ä¢ Information systems ‚Üí Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Large-scale industrial recommender systems usually adopt a multistage pipeline, where the first stage, namely candidate generation, is responsible for retrieving a few hundred relevant entities from a billion scale corpus. Deep candidate generation (DCG) <ref type="bibr" target="#b13">[14]</ref>, a paradigm that learns vector representations of the entities to enable fast k-nearest neighbor retrieval <ref type="bibr" target="#b27">[28]</ref>, has become an essential part of many live industrial systems with its enhanced expressiveness.</p><p>Typical large-scale DCG models <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b60">61]</ref> regard the problem of identifying the most relevant items to the users as estimating a multinomial distribution traversing over all items for each user, conditional on the user's past behaviors. Maximum likelihood estimation (MLE) is the conventional principle for training such models. Apparently, exact computation of the log likelihood, which requires computing softmax looping over a million-or even billion-scale collection of items, is computationally infeasible. Among the various sampling-based approximation strategies, sampled-softmax <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref> usually outperforms the binary-cross-entropy based approximations such as NCE <ref type="bibr" target="#b17">[18]</ref> and negative sampling <ref type="bibr" target="#b37">[38]</ref> at large scale.</p><p>However, the MLE paradigm and the sampling strategies mainly stem from the language modeling community, where the primary goal is to faithfully fit the observed texts. Indeed, live recommender systems are different from natural language texts in several aspects. Firstly, the training data are collected from current undergoing systems that might be sub-optimal and biased towards popular items. In such situations, some high-quality items can be underexplored in the training data, while an algorithm trained via MLE will continue to under-estimate the relevance of the under-explored items in order to faithfully fit the observed data. Secondly, the set of items for recommendation is much larger than the vocabulary of natural languages, e.g. ‚âà 100ùëÄ items in our system compared to ‚âà 100ùëò words, posing great difficulties in learning a set of fairly good representations for the entire candidate set.</p><p>In this paper, we introduce CLRec, a Contrastive Learning framework for debiased DCG in RECommender systems. Contrastive learning, which constructs self-supervised tasks to improve the discriminative ability of a model, has become increasingly popular recently in the pre-training community <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref>. We discover that the contrastive learning paradigm has a debiasing effect that can benefit recommender systems. Specifically, our central contribution is establishing the theoretical connection between contrastive learning and inverse propensity weighting, where the latter is a well-studied technique for bias reduction <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b47">48]</ref>. Our theory complements the previous studies of contrastive learning <ref type="bibr" target="#b38">[39]</ref>.</p><p>Based on the theoretical discovery, an easy-to-implement framework is developed to efficiently reduce the exposure bias of a largescale system. Our implementation maintains a fixed-size first-in first-out (FIFO) queue <ref type="bibr" target="#b18">[19]</ref> to accumulate positive samples and their representations from the previous batches, and use the content of the queue to serve as the negative samples to be discriminated from the positive samples of the next batch. It guarantees that all items will be sampled sometime in an epoch to serve as the negative examples. More importantly, it allows us to reuse the computed results from the previous batches, e.g., saving 90% computation cost when the queue size is 10√ó of the batch size. As a result, we can afford to encode complex features of the negative samples even when the negative sample size, i.e., the queue size, is very large, where the rich features can improve the quality of the learned representations of the under-explored items. The queue-based framework also offers simple yet efficient implementations for complex self-supervised tasks, e.g., discriminating whether two subsequences come from the same user's behaviors <ref type="bibr" target="#b35">[36]</ref>. We further improve upon CLRec and propose Multi-CLRec, which employs a multi-queue design for more accurate user-intention aware bias reduction.</p><p>Our methods have been fully deployed into our live system as the default choice to serve billions of page views each day. We observe that they are capable of recommending high-quality items that are largely neglected by most current ongoing systems, and consistently outperform the previous state-or-art baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">OUR THEORECTICAL RESULTS ON CONTRASTIVE LEARNING IN DCG</head><p>In this section, we will reveal the connection between contrastive learning and inverse propensity weighting (IPW).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>Notations. Given a dataset of user clicks D = {(ùë• ùë¢,ùë° , ùë¶ ùë¢,ùë° ) : ùë¢ = 1, 2, . . . , ùëÅ , ùë° = 1, 2, . . . ,ùëá ùë¢ }, where ùë• ùë¢,ùë° = {ùë¶ ùë¢,1:(ùë° ‚àí1) } represents a user's clicks prior to the ùë°-th click ùë¶ ùë¢,ùë° , and ùëá ùë¢ denotes the number of clicks from the user ùë¢. We will drop the sub-scripts occasionally and write (ùë•, ùë¶) in place of (ùë• ùë¢,ùë° , ùë¶ ùë¢,ùë° ) for conciseness. We use X to refer to the set of all possible click sequences, i.e. ùë• ‚àà X. Each ùë¶ ‚àà Y represents a clicked item, which includes various types of features associated with the item, while Y is the set of all possible items. The features of ùë¶ could be in any form, e.g., the item's unique identifier number, embeddings or raw data of its image and text description. The number of items |Y| can easily reach 100 million.</p><p>Deep Candidate Generation. The deep candidate generation paradigm involves learning a user behavior encoder f ùúÉ (ùë•) ‚àà R ùëë and an item encoder g ùúÉ (ùë¶) ‚àà R ùëë . The set of parameters used by each encoder is a subset of ùúÉ , i.e. the set of all trainable parameters in the system. It then takes {g ùúÉ (ùë¶)} ùë¶ ‚ààY and builds a k-nearest-neighbor search service, e.g., Faiss <ref type="bibr" target="#b27">[28]</ref>. As a result, given an arbitrary user behavior sequence ùë• at serving time, we can instantly retrieve the top ùëò items relevant to the user by finding the top ùëò candidate g ùúÉ (ùë¶) similar to f ùúÉ (ùë•). Most implementations use inner product ùúô ùúÉ (ùë•, ùë¶) = ‚ü®f ùúÉ (ùë•), g ùúÉ (ùë¶)‚ü© or cosine similarity as the similarity score. The typical learning procedure fits the data following the maximum likelihood estimation (MLE) principle:</p><formula xml:id="formula_0">arg min ùúÉ 1 |D| ‚àëÔ∏Å (ùë•,ùë¶) ‚ààD ‚àí log ùëù ùúÉ (ùë¶ | ùë•), where ùëù ùúÉ (ùë¶ | ùë•) = exp ùúô ùúÉ (ùë•, ùë¶) ùë¶ ‚Ä≤ ‚ààY exp ùúô ùúÉ (ùë•, ùë¶ ‚Ä≤ ) . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>The denominator of ùëù ùúÉ (ùë¶ | ùë•) sums over all possible items, which is infeasible in practice and thus requires approximation, e.g., via sampling. However, the observed clicks for training are from the previous version of the recommender system. The training data thus suffer from exposure bias (i.e. missing not at random <ref type="bibr" target="#b41">[42]</ref>) and reflect the users' preference regarding the recommended items rather than all potential items. High-quality items that have few clicks in the training data will likely remain under-recommended by a new algorithm trained via the MLE paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Understanding Contrastive Learning from a Bias-Reduction Perspective</head><p>We now introduce the family of contrastive losses that we are interested in, and reveal their connection with the inverse propensity weighting (IPW) <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b47">48]</ref> techniques for bias reduction.</p><p>Sampled Softmax. The kind of contrastive loss we will investigate is similar to sampled softmax. We thus recap sampled softmax here and will show that the minor difference is crucial. There are many variants of sampeld softmax <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref>, among which the following variant is integrated by TensorFlow <ref type="bibr" target="#b0">[1]</ref> and commonly used:</p><formula xml:id="formula_2">arg min ùúÉ 1 |D| ‚àëÔ∏Å (ùë•,ùë¶) ‚ààD ‚àí log exp (ùúô ùúÉ (ùë•, ùë¶) ‚àí log ùëù ùëõ (ùë¶|ùë•)) exp (ùúô ùúÉ (ùë•, ùë¶) ‚àí log ùëù ùëõ (ùë¶|ùë•)) + ùêø ùëñ=1 exp (ùúô ùúÉ (ùë•, ùë¶ ùëñ ) ‚àí log ùëù ùëõ (ùë¶ ùëñ |ùë•)) ,<label>(2)</label></formula><p>where {ùë¶ ùëñ } ùêø ùëñ=1 are ùêø negative samples drawn from a pre-defined proposal distribution ùëù ùëõ (ùë¶ | ùë•). Subtracting log ùëù ùëõ (ùë¶ | ùë•) is necessary for it to converge to the same solution as the exact loss in Eq. ( <ref type="formula" target="#formula_0">1</ref>). Most implementations assume ùëù ùëõ (ùë¶ | ùë•) = ùëù ùëõ (ùë¶) and set ùëù ùëõ (ùë¶) somehow proportional to the popularity of the items to improve convergence. In practice, we would draw thousands of negative samples to pair with each positive example. Sampled softmax in general outperforms other approximations such as NCE <ref type="bibr" target="#b17">[18]</ref> and negative sampling <ref type="bibr" target="#b37">[38]</ref> when the vocabulary is large <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Contrastive Loss. We study the following type of contrastive loss <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b42">43]</ref> under a negative sampler ùëù ùëõ (ùë¶ | ùë•): where {ùë¶ ùëñ } ùêø ùëñ=1 are again sampled from ùëù ùëõ (ùë¶ | ùë•) for each ùë• to pair with the positive sample. It no longer optimizes the MLE loss in Eq. ( <ref type="formula" target="#formula_0">1</ref>), because it misses ‚àí log ùëù ùëõ (ùë¶ | ùë•) and thus does not correct the bias introduced by sampling. Many efforts on contrastive learning have been focusing on designing a well-performing proposal distribution ùëù ùëõ (ùë¶ | ùë•) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43]</ref>. InfoNCE <ref type="bibr" target="#b38">[39]</ref> demonstrates that this loss maximizes a lower bound of the mutual information between ùë• and ùë¶ if we set the proposal distribution ùëù ùëõ (ùë¶ | ùë•) to be the actual data distribution ùëù data (ùë¶), i.e. if we sample ùë¶ proportional to its frequency in the dataset.</p><formula xml:id="formula_3">arg min ùúÉ 1 |D| ‚àëÔ∏Å (ùë•,ùë¶) ‚ààD ‚àí log exp (ùúô ùúÉ (ùë•, ùë¶)) exp (ùúô ùúÉ (ùë•, ùë¶)) + ùêø ùëñ=1 exp (ùúô ùúÉ (ùë•, ùë¶ ùëñ )) ,<label>(3)</label></formula><p>Contrastive Learning and Exposure Bias Reduction. The contrastive loss as shown above in Eq. (3) has recently achieved remarkable success in various fields <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b38">39]</ref>. Nevertheless, it still remains a question why the loss is effective. We will reveal that the contrastive loss is a sampling-based approximation of an inverse propensity weighted (IPW) loss. The IPW loss<ref type="foot" target="#foot_0">1</ref> has the form:</p><formula xml:id="formula_4">arg min ùúÉ 1 |D| ‚àëÔ∏Å (ùë•,ùë¶) ‚àà D ‚àí 1 ùëû(ùë¶ | ùë•) ‚Ä¢ log ùëù ùúÉ (ùë¶ | ùë•),<label>(4)</label></formula><p>where ùëû(ùë¶ | ùë•) should be the propensity score function, which represents the impression (or exposure) distribution, i.e., the probability that item ùë¶ is recommended to user ùë• in the previous system where we collect the training data D. The idea of IPW is to model missing-not-at-random via the propensity scores in order to correct the exposure bias. We can prove that the IPW loss is optimizing ùëù ùúÉ (ùë¶ | ùë•) to capture the oracle user preference even when there exists exposure bias. A standard implementation of the IPW loss has two steps, where the first step is to use a separate model to serve as ùëû(ùë¶ | ùë•) and optimize it by fitting the exposure history according to the MLE principle, while the second step is to optimize ùëù ùúÉ (ùë¶ | ùë•) according to Eq. (4). However, the two-stage pipeline of IPW, as well as the numerical instability and variance <ref type="bibr" target="#b41">[42]</ref> brought by 1 ùëû (ùë¶ |ùë•) , makes IPW less efficient for large-scale production systems.</p><p>Fortunately, we can prove that the contrastive loss Eq. ( <ref type="formula" target="#formula_3">3</ref>) is in principle optimizing the same objective as Eq. ( <ref type="formula" target="#formula_4">4</ref>). And in Subsection 3 we provide simple implementations that do not require two separate steps and can avoid the instability brought by the division of ùëû(ùë¶ | ùë•). Our key theoretical result is as follows: Theorem 1. The optimal solutions of the contrastive loss (Eq. 3) and the IPW loss (Eq. 4) both minimize the KL divergence from ùëù ùúÉ (ùë¶ | to ease implementation and save computation since impression data is larger than click data by an order of magnitude.</p><formula xml:id="formula_5">ùë•) to ùëü (ùë¶ | ùë•) = ùëù data (ùë¶ |ùë•)/ùëû (ùë¶ |ùë•) ùë¶ ‚Ä≤ ‚ààY ùëù data (ùë¶ ‚Ä≤ |ùë•)/ùëû (ùë¶ ‚Ä≤ |ùë•) , if ùëù ùëõ (ùë¶ | ùë•) is set to be ùëû(ùë¶ | ùë•).</formula><p>Drawbacks of Performing Explicit Sampling. Our analysis above shows that, by simply drawing negative samples according to ùëù ùëëùëéùë°ùëé (ùë¶), the contrastive loss (Eq. 3) can alleviate the selection bias related with the items' impression counts in the history. However, sampling will still incur non-negligible overheads, e.g. communication costs, in a distributed environment <ref type="bibr" target="#b44">[45]</ref>. Sampling also cannot guarantee that every item will be sampled in an epoch. We thus adopt a queue-based design <ref type="bibr" target="#b18">[19]</ref> that avoids explicitly performing sampling, as shown in Figure <ref type="figure" target="#fig_13">1b</ref> and Figure <ref type="figure" target="#fig_13">1c</ref>.</p><p>Designs of Queue-based Contrastive Learning. We maintain a firstin first-out (FIFO) queue Q, which has a fixed capacity and can store |Q| examples. Given a new batch to process, we first enqueue the positive examples ùë¶ (or their representations g ùúÉ (ùë¶)) encountered in the present batch into Q. We then use the examples stored in the queue to serve as {ùë¶} ‚à™ {ùë¶ ùëñ } ùêø ùëñ=1 (the positive example and ùêø negative examples) when computing the denominator of the contrastive loss (Eq. 3) for the present batch. In a distributed setting, each worker maintains its own queue locally to avoid communication costs. When the queue size |Q| is equal to the batch size, our implementation is then equivalent to sampling negative examples from the present batch <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43]</ref> (see Figure <ref type="figure" target="#fig_13">1a</ref>). In general, we need thousands of negative samples to achieve satisfying performance. We thus use a large queue size, but with a small batch size to save memory, e.g. batch size = 256 and queue size = 2, 560.</p><p>Queue-based Caching and its Efficiency in Encoding Complex Features. With the implementation that stores the encoded results g ùúÉ (ùë¶) in the queue (see Figure <ref type="figure" target="#fig_13">1c</ref>), we can no longer back-propagate through the negative examples from the previous batches, though we can still back-propagate through the negative examples from the present batch. As a result, we find that the total training steps required for convergence mildly increase. However, since each training step will take much less time to compute (and less communication costs in a distributed training setting), the total running time can still be greatly reduced if the features of the negative items are expensive to encode, e.g. if the features contain raw images, texts, or even structured data such as a knowledge graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-CLRec: Multiple Disentangled Queues for Intent-Aware Bias Reduction</head><p>There are tens of thousands of categories of items in our system, many of which are long-tail. As a result, approximating ùëû(ùë¶ | ùë•) with ùëû(ùë¶ | the category in which user ùë• is currently interested) can still incur non-negligible variance. Multi-CLRec thus aims to cluster the categories into ùêª intentions and simultaneously learn a de-biased model with negative samples that roughly follow the smoothed propensity scores ùëû(ùë¶ | user ùë•'s current intention is ‚Ñé), ‚Ñé = 1, . . . , ùêª . In particular, Multi-CLRec uses ùêª queues {Q ‚Ñé } ùêª ‚Ñé=1 corresponding to the ùêª intentions. We use ùêª = 64 in our system.</p><p>Disentangled Encoding with Prototype-based Routing. Our model (see Figure <ref type="figure" target="#fig_2">2</ref>) borrows the idea of intention disentanglement <ref type="bibr" target="#b34">[35]</ref>, which has a built-in routing mechanism for clustering. Let ùë• = {ùë¶ 1:(ùëá ‚àí1) } be the sequence of items clicked by user ùë•, and the user's ground-truth next click to predict is ùë¶ ùëá . Let c ùë° ‚àà R ùëë be the embedding corresponding to item ùë¶ ùë° 's category ID. The embedding of item ùë¶ ùë° is generated by the item encoder g ùúÉ : Y ‚Üí R ùëë as follows:</p><formula xml:id="formula_6">g ùúÉ (ùë¶ ùë° ) = MLP 1 ([ embedding of item ùë¶ ùë° 's unique ID;</formula><p>embedding of item ùë¶ ùë° 's category ID, i.e., c ùë° ; embedding of item ùë¶ ùë° 's seller ID; embeddings of ùë¶ ùë° 's tags; . . . ]), <ref type="bibr" target="#b4">(5)</ref> where MLP 1 (‚Ä¢) represents a multilayer perceptron (MLP) whose input is the concatenation of item ùë¶ ùë° 's features. We then use another MLP to model the importance of each clicked item {ùë¶ ùë° } ùëá ‚àí1 ùë° =1 :</p><formula xml:id="formula_7">ùëù ùë° = exp(ùëù ‚Ä≤ ùë° ) ùëá ‚àí1 ùë° ‚Ä≤ =1 exp(ùëù ‚Ä≤ ùë° ‚Ä≤ )</formula><p>, where (6) Our model then uses a set of trainable parameters ùùÅ ‚Ñé ‚àà R ùëë , ‚Ñé = 1, 2, . . . , ùêª , to represent ùêª intention prototypes <ref type="bibr" target="#b34">[35]</ref>, based on which each item ùë¶ ùë° is being routed into intention ‚Ñé with probability ùëù ‚Ñé |ùë° :</p><formula xml:id="formula_8">ùëù ‚Ä≤ ùë° = MLP 2 ([ item</formula><formula xml:id="formula_9">ùëù ‚Ñé |ùë° = exp(ùëù ‚Ä≤ ‚Ñé |ùë° ) ùêª ‚Ñé ‚Ä≤ =1 exp(ùëù ‚Ä≤ ‚Ñé ‚Ä≤ |ùë° )</formula><p>, where</p><formula xml:id="formula_10">ùëù ‚Ä≤ ‚Ñé |ùë° = ‚ü®ùùÅ ‚Ñé , c ùë° ‚ü© ùúå ‚Ä¢ ‚à•ùùÅ ‚Ñé ‚à• ‚Ä¢ ‚à•c ùë° ‚à• .<label>(7)</label></formula><p>The temperature hyper-parameter ùúå is set to ùúå = 0.07 following previous work <ref type="bibr" target="#b18">[19]</ref>, and ‚à• ‚Ä¢ ‚à• stands for the ùëô2-norm of a vector. Based on the importance weights and the routing results, we obtain   ùêª intention vectors {z ‚Ñé } ùêª ‚Ñé=1 for the user:</p><formula xml:id="formula_11">z ‚Ñé = MLP 3 ( [z ‚Ä≤ ‚Ñé ; ùú∑ ‚Ñé ]), z ‚Ä≤ ‚Ñé = ùëá ‚àí1 ‚àëÔ∏Å ùë° =1 ùëù ‚Ñé |ùë° ‚Ä¢ ùëù ùë° ‚Ä¢ g ùúÉ (ùë¶ ùë° ),<label>(8)</label></formula><p>where ùú∑ ‚Ñé ‚àà R ùëë , ‚Ñé = 1, 2, . . . , ùêª , are trainable parameters that represent the bias vectors of the intentions, which are shared by all users. However, not all of the ùêª intention vectors would match the user's current interest, since it is possible to have ùëá ‚àí1 ùë° =1 ùëù ‚Ñé |ùë° ‚Ä¢ ùëù ùë° ‚Üí 0 for some ‚Ñé. We thus use the following attention module to select the intention vector that is most likely to match the user's interest, and set the the user encoder f ùúÉ (‚Ä¢)'s output to be the selected vector z ‚Ñé * :</p><formula xml:id="formula_12">f ùúÉ (ùë•) = z ‚Ñé * , where ‚Ñé * = arg max ‚Ñé ‚àà {1,2,...,ùêª } ùë§ ‚Ñé , ùë§ ‚Ñé = exp( w‚Ñé ) ùêª ‚Ñé ‚Ä≤ =1 exp( w‚Ñé ‚Ä≤ ) , w‚Ñé = ‚ü®m, z ‚Ñé ‚ü© ùúå ‚Ä¢ ‚à•m‚à• ‚Ä¢ ‚à•z ‚Ñé ‚à• , m = MLP 4 ùëá ‚àí1 ‚àëÔ∏Å ùë° =1</formula><p>ùëù ùë° ‚Ä¢ g ùúÉ (ùë¶ ùë° ) .</p><p>(9) We approximate the gradient of argmax via straight-through <ref type="bibr" target="#b4">[5]</ref>. That is, we define</p><formula xml:id="formula_13">ùë§ ‚Ñé = stop_gradient(ùêº [‚Ñé = ‚Ñé * ] ‚àíùë§ ‚Ñé ) +ùë§ ‚Ñé , where ùêº [‚Ñé = ‚Ñé * ] = 1 if ‚Ñé = ‚Ñé * and ùêº [‚Ñé = ‚Ñé * ]</formula><p>= 0 otherwise. We then use ùë§ ‚Ñé instead of ‚Ñé * when computing the loss (see Equation <ref type="formula" target="#formula_18">13</ref>).</p><p>When serving online, we can select the top-ùêæ (1 ‚â§ ùêæ ‚â§ ùêª ) vectors from {z ‚Ñé } ùêª ‚Ñé=1 with maximum values of ùë§ ‚Ñé for item retrieval, which is useful if a diverse recommendation list is preferred.</p><p>Auxiliary Losses for Enhancing Interpretability. The encoder architecture alone cannot guarantee an interpretable routing mechanism in our large-scale setting. We thus introduce three auxiliary losses to enhance the interpretability 2 . The first is to encourage ùëù ‚Ñé |ùë° to be polarized, i.e., ùëù ‚Ñé + |ùëá ‚Üí 1 and ùëù ‚Ñé ‚Ä≤ |ùëá ‚Üí 0 for ‚Ñé ‚Ä≤ ‚â† ‚Ñé + :</p><formula xml:id="formula_14">L aux,1 = ‚àí log ùëù ‚Ñé + |ùëá , where ‚Ñé + = arg max ‚Ñé ‚àà {1,2,...,ùêª } ùëù ‚Ñé |ùëá . (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>The second auxiliary loss is for pushing the correct intention vector z ‚Ñé + closer to the target item ùë¶ ùëá while making the incorrect 2 Empirical results that demonstrate the enhanced interpretability are provided in the Appendix. intention vectors {z ‚Ñé ‚Ä≤ } ‚Ñé ‚Ä≤ :‚Ñé ‚Ä≤ ‚â†‚Ñé + , far away from the target item:</p><formula xml:id="formula_16">L aux,2 = ‚àí log exp(ùë† ‚Ñé + ,ùëá ) ùêª ‚Ñé ‚Ä≤ =1 exp(ùë† ‚Ñé ‚Ä≤ ,ùëá ) , ùë† ‚Ñé,ùëá = ‚ü®z ‚Ñé , g ùúÉ (ùë¶ ùëá )‚ü© ùúå ‚Ä¢ ‚à•z ‚Ñé ‚à• ‚Ä¢ ‚à•g ùúÉ (ùë¶ ùëá ) ‚à• .<label>(11)</label></formula><p>Our third auxiliary loss is for balancing the ùêª intentions, such that each is responsible for a roughly equal number of items:</p><formula xml:id="formula_17">L aux,3 = ùêª ‚àëÔ∏Å ‚Ñé=1 1 ùêª ‚Ä¢ (log 1 ùêª ‚àí log ùúã ‚Ñé ), ùúã ‚Ñé = E B [ùëù ‚Ñé |ùë° ],<label>(12)</label></formula><p>where E B means that the expectation is computed based on the items encountered in the present mini-batch B.</p><p>Multi-Queue Contrastive Loss. The main loss to optimize is:</p><formula xml:id="formula_18">L cl = ‚àí log ùêª ‚àëÔ∏Å ‚Ñé=1 ùë§ ‚Ñé ‚Ä¢ exp {cos(z ‚Ñé , g ùúÉ (ùë¶ ùëá ))/ùúå } ùêª ‚Ñé ‚Ä≤ =1 ùë¶ ‚Ä≤ ‚ààQ 0 ‚à™Q ‚Ñé + exp {cos(z ‚Ñé ‚Ä≤ , g ùúÉ (ùë¶ ‚Ä≤ ))/ùúå } ,<label>(13)</label></formula><p>where cos(ùë•, ùë¶) = ‚ü®a, b‚ü©/(‚à•a‚à• ‚Ä¢ ‚à•b‚à•). Here Q 0 is the main queue, as described in Subsection 3.1, and Q ‚Ñé + is the ‚Ñé + -th secondary queue (one of the ùêª secondary queues) that stores negative samples associated with intention ‚Ñé + = arg max ‚Ñé ùëù ‚Ñé |ùëá . We update the 1+ùêª queues prior to computing the loss at each iteration as follows:</p><p>(1) The positive sample ùë¶ ùëá is enqueued into the main queue Q 0 prior to computing the loss. (2) An item ùë¶ ‚àí just dequeued from the main queue Q 0 is enqueued into the secondary queue Q ‚Ñé ‚àí , where</p><formula xml:id="formula_19">‚Ñé ‚àí = arg max ‚Ñé ùëù ‚Ñé |ùë¶ ‚àí = arg max ‚Ñé ‚ü®ùùÅ ‚Ñé , c ‚àí ‚ü©/(ùúå ‚Ä¢ ‚à•ùùÅ ‚Ñé ‚à• ‚Ä¢ ‚à•c ‚àí ‚à•)</formula><p>and c ‚àí is the category embedding of item ùë¶ ‚àí . (3) Items dequeued from the secondary queues {Q ‚Ñé } ùêª ‚Ñé=1 are discarded. We minimize the total loss L cl +ùúÜ 1 L aux,1 +ùúÜ 2 L aux,2 +ùúÜ 3 L aux,3 . We simply set ùúÜ 1 = ùúÜ 2 = ùúÜ 3 = 1, because we find that our method is robust with respective to a wide range of coefficients.</p><p>Remark 2. We are implicitly performing bias reduction based on a propensity score proportional to ùëû(ùë¶ | user ùë•'s intention is ‚Ñé) + ùõº ‚Ä¢ ùëû(ùë¶) for a certain smoothing factor ùõº &gt; 0, by using the negative samples from a secondary queue Q ‚Ñé and the main queue Q 0 . Figure <ref type="figure">3</ref>: The total number of impressions of the items in a specific degree bucket vs. the logarithm of the corresponding degree. The rightmost bar is not the highest because the number of the extremely popular items is small, even though each item in the bucket has a very high degree.</p><p>Table <ref type="table">2</ref>: CLRec vs. the sampling-based alternatives. We conducted these proof-of-concept live experiments in a smalltraffic scenario, due to the costs of online experiments. The negative sampling baseline has been outdated and removed from our live system before this work starts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT 4.1 Experiments in Production Envrionments</head><p>The online experiments have lasted for at least four months, and our algorithm serves several scenarios with different traffic volumes. Details can be found in the Appendix. The total number of items is around 100 million. We use the queue-based implementation without caching in this subsection, and we will explore settings where encoding is expensive and requires caching in Subsection 4.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1.1</head><p>The Debiasing Effect in Large-Scale Production Environments.</p><p>To examine the debiasing effects of CLRec, we first conduct offline experiments and compare CLRec with sampled softmax. We report the aggregated diversity <ref type="bibr" target="#b1">[2]</ref> in Table <ref type="table" target="#tab_3">1</ref>, and the distributions of the recommended items resulted from the different losses in Figure <ref type="figure">3</ref>.</p><p>Table <ref type="table" target="#tab_3">1</ref> shows that CLRec has an over 2√ó improvement on aggregated diversity. We see from Figure <ref type="figure">3</ref> that, sampled softmax tends to faithfully fit the distribution of the training data. CLRec, however, learns a relatively different distribution, which shifts towards the under-explored items and alleviates the Matthew effect.</p><p>Bias reduction not only leads to a fairer system, but also contributes to a significant improvement regarding the online performance. In Table <ref type="table">2</ref>, we compare CLRec with other sampling alternatives using the same implementation of the encoders. Details of the alternative methods are in the Appendix. We observe that negative sampling <ref type="bibr" target="#b37">[38]</ref>, including its variant <ref type="bibr" target="#b55">[56]</ref> that makes the instances in a batch share the same large set of negative samples, does not perform well in our settings. CLRec's improvement over sampledsoftmax <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref> w.r.t. the offline metric HitRate@50 is negligible. However, CLRec achieves significant improvement regarding the click-through rate (CTR) online, which indicates that there exists discrepancy between the offline metric and the online performance.</p><p>In Table <ref type="table" target="#tab_6">4</ref>, we compare Multi-CLRec against CLRec. We deliberately evaluate the methods in the setting where the training and the test data have different user distributions. Multi-CLRec is more robust compared to CLRec and achieves higher performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">At</head><p>Least Four Months' Large-Scale A/B testing. CLRec has been fully depolyed into several heavy-traffic scenarios since Feb 2020, after the initial proof-of-concept ablation studies shown in Table <ref type="table">2</ref>. Table <ref type="table" target="#tab_5">3</ref> shows our main online results conducted in these heavy-traffic scenarios, with billions of page views each day. During the at least four months' A/B testing, CLRec has been consistently outperforming MIND <ref type="bibr" target="#b31">[32]</ref>, the previous state-or-art baseline, in terms of the fairness metrics such as aggregated diversity and average popularity index, as well as the user engagement metrics such as click-through rate and average dwell time. Compared with MIND <ref type="bibr" target="#b31">[32]</ref>, which is the previous state-of-art DCG baseline deployed in the system, CLRec tends to recommend items with a lower popularity index while being more attractive to the users. This proves CLRec's ability of identifying high-quality items that are rarely explored by the previous systems. We further achieve a +2% relative improvement in the total click number on our platform after ensembling CLRec and MIND, compared to using MIND alone.</p><p>In mid-2020, we upgrade CLRec to Multi-CLRec, and Multi-CLRec brings a 3% relative improvement in terms of total clicks on our platform while maintaining a comparable click-through rate.  <ref type="table" target="#tab_7">5</ref> compares CLRec and sampledsoftmax in terms of training speed and the network traffic required in a distributed setting. CLRec's queue-based implementation is much more efficient than the methods that perform explicit sampling, since CLRec reuses the result computed for a positive sample shortly later when the sample is serving as a negative sample. The version of sampled-softmax that encodes features for the negative items is from <ref type="bibr" target="#b61">[62]</ref>. This proof-of-concept experiment only uses a few features of the items, and we can deduce that the improvement regarding efficiency will be much more substantial with more complex features. Table <ref type="table" target="#tab_8">6</ref> shows that encoding features for the negative samples is beneficial, which justifies the efforts spent on efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Computational Advantages of CLRec</head><p>Table <ref type="table">7</ref>: Task u2i is the regular task where ùë• is a sequence of clicks and ùë¶ is the next click to be predicted. Task u2u <ref type="bibr" target="#b35">[36]</ref> adds an auxiliary loss where ùë• and ùë¶ are both sequences from the same user (before and after a sampled timestamp), which is co-trained with task u2i. HR1@50 and Recall5@50 represent the HitRate and Recall truncated at 50 when predicting the next one and five clicks, respectively.</p><p>Task &amp; Implementation HR1@50 Recall5@50 CLRec-u2i We now demonstrate that CLRec with a queue that caches the computed results can enable more complex pretext tasks that may improve the quality of the learned representations. We consider an auxiliary task where ùë• and ùë¶ are both sequences from the same user (before and after a sampled timestamp). The goal is to identify the correct sequence ùë¶ that belongs to the same user that produces ùë•. This auxiliary task is expensive to implement with sampled-softmax, since the negative samples are sequences and are thus expensive to encode. Fortunately, cached CLRec can implement it efficiently. Table <ref type="table">7</ref> demonstrates that the auxiliary task can improve an algorithm's ability to make long-term prediction. MoCo <ref type="bibr" target="#b18">[19]</ref> proposes momentum update for stabilizing the training loss. We however observe no additional gain with MoCo.</p><p>Table <ref type="table">9</ref>: Results on public benchmarks preprocessed by HPMN <ref type="bibr" target="#b39">[40]</ref>. We follow HPMN <ref type="bibr" target="#b39">[40]</ref> and use AUC as the metric. The clicks in the training and the test set of each benchmark happen before and after a certain timestamp, respectively. There hence exists a distribution drift. The users also have diverse interests, i.e., the probability of a user's two consecutive clicks belonging to the same category is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Amazon UserBehavior DNN 0.7546 0.7460 SVD++ <ref type="bibr" target="#b30">[31]</ref> 0.7155 0.8371 GRU4Rec <ref type="bibr" target="#b20">[21]</ref> 0.7760 0.8471 Caser <ref type="bibr" target="#b46">[47]</ref> 0.7582 0.8745 DIEN <ref type="bibr" target="#b59">[60]</ref> 0.7770 0.8934 RUM <ref type="bibr" target="#b12">[13]</ref> 0.7464 0.8370 LSTM <ref type="bibr" target="#b22">[23]</ref> 0.7765 0.8681 SHAN <ref type="bibr" target="#b54">[55]</ref> 0.7763 0.8828 HPMN <ref type="bibr" target="#b39">[40]</ref> 0   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Reproducible Experiments on Public Data</head><p>In addition to the experiments on large-scale data, we also conduct quantitative experiments on several public benchmarks. The quantitative results are listed in Table <ref type="table" target="#tab_9">8</ref> and Table <ref type="table">9</ref>, respectively. We also conduct the same analyses as in Subsection 4.1.1 to demonstrate the debiasing effects of CLRec on the public benchmarks. We sample a sequence from each user in the training set as the input to the recommenders. Each recommender then retrieves ten items for each sequence. The results are in Table <ref type="table" target="#tab_10">10</ref> and Figure <ref type="figure" target="#fig_5">4</ref>.</p><p>Table <ref type="table" target="#tab_10">10</ref> reports aggregate diversity of the items retrieved by the algorithms, as well as the aggregate diversity of the groundtruth next clicks. CLRec retrieves a more diverse set of items than sampled softmax, i.e., much more items will have a chance to be recommended after we reduce the bias in the training data.</p><p>Figure <ref type="figure" target="#fig_5">4</ref> visualizes the distributions of the items retrieved by each algorithm, as well as the training data's distribution. Sample softmax tends to faithfully fit the training data's distribution, while CLRec tends to explore the previously under-explored items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Deep Candidate Generation. Deep candidate generation methods are widely deployed in industrial systems, e.g., YouTube <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">27]</ref>, Taobao <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b60">61]</ref>, and Pinterest <ref type="bibr" target="#b55">[56]</ref>. The existing methods explicitly sample negative examples from a pre-defined proposal distribution <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b37">38]</ref>. The proposal distribution not only affects convergence, but also has a significant impact on the performance <ref type="bibr" target="#b8">[9]</ref>. Empirically the number of the negative samples need to be large, e.g. a few thousand ones for pairing with a positive example. Consequently, it is computationally expensive to incorporate rich features for the negative samples. The existing systems hence usually choose to not encode features for the negative examples except for simple features such as item IDs <ref type="bibr" target="#b13">[14]</ref>, even though rich features for the negative samples are demonstrated to be beneficial <ref type="bibr" target="#b3">[4]</ref>. CLRec achieves great efficiency when encoding rich features for the negative samples by caching the computed results.</p><p>Bias Reduction and Fairness in Recommender Systems. Recommendation algorithms that directly fits the training data will suffer from selection bias due to the missing-not-at-random phenomenon <ref type="bibr" target="#b41">[42]</ref>, where the previous recommendation algorithms affect the training data collected. The topic of reducing the bias in training and evaluating recommender systems has been explored before <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr">63</ref>]. However, these existing works mostly focus on small-scale offline settings, and rely on techniques less efficient for large-scale DCG. For example, most of them involve an extra stage to train a propensity score estimator. Dividing the propensity scores can also lead to high variance when small propensities exist <ref type="bibr" target="#b41">[42]</ref>. Correcting the bias helps improve P-fairness <ref type="bibr" target="#b7">[8]</ref>, i.e. fairness towards the under-recommended products <ref type="bibr" target="#b6">[7]</ref>.</p><p>Contrastive Learning. Contrastive learning, which aims to learn high-quality representations via self-supervised pretext tasks, recently achieves remarkable success in various domains, e.g., speech processing <ref type="bibr" target="#b38">[39]</ref>, computer vision <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22]</ref>, graph data <ref type="bibr" target="#b49">[50]</ref>, and compositional environments <ref type="bibr" target="#b29">[30]</ref>. The contrastive loss we investigate in this paper is a generalization of the InfoNCE loss <ref type="bibr" target="#b38">[39]</ref>. InfoNCE is previously understood as a bound of the mutual information between two variables <ref type="bibr" target="#b38">[39]</ref>. Our work provides a new perspective on the effectiveness of the contrastive loss, by illustrating its connection with inverse propensity weighting <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>[63] Hao Zou, Peng Cui, Bo Li, Zheyan Shen, Jianxin Ma, Hongxia Yang, and Yue He.</p><p>2020. Counterfactual Prediction for Bundle Treatment. In NeurIPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A EXPERIMENTAL SETTINGS</head><p>Data and Hyper-parameters. We use the data collected from the last four days on our platform as the training data and use the click data recorded in the following day as the test set. We limit the minimum length of a valid sequence to be five in the training set, because requiring the model to predict the next item of an unusually short sequence can easily introduce great noise which harms the recommendation performance. We use seven categorical features of the items, including item ID, coarse-grained and fine-grained category IDs, seller ID, seller category, brand ID, and gender preference, for our live experiments. We use the queue-based implementation without the caching mechanism on the regular tasks where the negative items consist of the seven categorical features, while using the queue-based implementation that caches the processed results when solving the complex pretext tasks due to the high costs of encoding the complex negative examples. The number of negative samples is 2,560 while the batch size is 256. Multi-CLRec use ùêª = 16 on public data and ùêª = 64 on our large-scale data. We train the model for one epoch in total on our large-scale data.</p><p>Training Environment. The training data contain four billion sequences of user behaviors. We train the model in a distributed TensorFlow cluster that consists of 140 workers and 10 parameter servers. Each worker is equipped with a GPU, which is either GTX 1080 Ti or Tesla P100. Each parameter server is allocated 32GB memory while each worker has 16G memory. Training CLRec and Multi-CLRec on our internal four-day data for one epoch costs less than eight hours for task u2i without caching and less than twelve hours for task u2u with caching.</p><p>Online Serving. We pre-compute offline the item representations via the item encoder. We then store and index the item representations using an online vector-based kNN service for fast retrieval of top relevant items at serving time. At serving time, our user encoder will infer a user vector f ùúÉ (ùë•) as the request made by user ùë• arrives and pass the user vector to the kNN service to find a few hundred relevant items ùëÜ. The latency for dealing with the query is around 10 ms. The set of relevant items ùëÜ is then send to be scored by a separate deep ranking model that costs much more computational power and is responsible for constructing the final recommendation list by selecting the top relevant items from ùëÜ.</p><p>Evaluation Metrics. We report the performance in terms of the following offline and online metrics:</p><p>‚Ä¢ HitRate@50 (HR@50) is an offline metric. We sample a subset of users and compute the metric based on the users' click sequences to measure an algorithm's offline performance. We pick the latest one click of a user as the label ùë¶ to predict, and use the user' sequence prior to ùë¶ to serve as the input ùë•. We run the algorithm under evaluation to retrieve top 50 items for each user via kNN searching. If the ground-truth next one click ùë¶ is in the retrieved 50 items, the algorithm receives a score 1 for this user, or score 0 otherwise. The HitRate@50 of the algorithm is then the average score received by the algorithm.</p><p>‚Ä¢ The click-trough rate (CTR) of an algorithm is the percentage of recommendations made by the algorithm that are finally clicked by the users. ‚Ä¢ The average dwell time is the total time spent by the users on reading the details of the items clicked by them, divided by the total number of clicks on our platform. ‚Ä¢ The aggregate diversity <ref type="bibr" target="#b1">[2]</ref>, measured on a sampled subset of users for testing, is the number of distinct items recommended to the subset of users. ‚Ä¢ The popularity index of the items recommended by a candidate generation algorithm ùê¥ is defined as</p><formula xml:id="formula_20">E ùê¥ [ùëù data (ùë¶) ] max ùê¥ ‚Ä≤ E ùê¥ ‚Ä≤ [ùëù data (ùë¶) ] .</formula><p>Here ùëù data (ùë¶) is the number of times our system recommends item ùë¶ to the users in the past few weeks before we deploy CLRec into the system, and E ùê¥ [ùëù data (ùë¶)] = ùë¶ ‚ààY ùëù data (ùë¶)‚Ä¢ ùëù (algorithm ùê¥ recommends item ùë¶) measures how much an algorithm prefers recommending the items that are already popular. The algorithm ùê¥ ‚Ä≤ that has the largest value of E ùê¥ ‚Ä≤ [ùëù data (ùë¶)] in our system is a simple candidate generation method that does not learn vector representations, which is used as a fallback to handle the cases when the deep candidate generation methods, i.e. MIND and CLRec, fail to return the results within a time limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B IMPLEMENTATION DETAILS B.1 Single-Queue CLRec's Encoders</head><p>The encoders of the multi-queue implementation Multi-CLRec is described in Subsection 3.2. However, the single-queue CLRec uses a different set of user and item encoders, which is due to the fact that our large-scale experiments related with the single-queue CLRec were conducted before we invented Multi-CLRec. We thus describe in this subsection the single-queue CLRec's encoders.</p><p>B.1.1 Item Encoder. In the single-queue CLRec, an item's embedding is the sum of several parts, i.e. a base item embedding corresponding to its ID umber, the concatenation of the item features' embeddings, a time bucket embedding, as well as a backward positional embedding. The time bucket embedding and the positional embedding are only added when the item embedding is to be used by the user encoder f ùúÉ (ùë•) for encoding a past click made by user ùë•. The output of the item encoder g ùúÉ (ùë¶) for item ùë¶ is the sum of only the base item embedding and the item features' embeddings, excluding the time and positional embeddings. Notably, Multi-CLRec also use the time and positional embeddings described here for estimating each click's importance weight. Time Bucket Embedding. To encode time intervals between consecutive behaviors, we use the embeddings of bucketized time intervals, which are used by previous work <ref type="bibr" target="#b57">[58]</ref>. To be specific, given the current timestamp ùë° when the user query arrives and the timestamp ùë° ‚Ä≤ when a click was recorded, the time interval ùë° ‚àí ùë° ‚Ä≤ is discretized and put into a bucket that corresponds to a specific range. Each bucket has its own vector representation, i.e. bucket embedding.</p><p>Backward Positional Embedding. We also find that the positional embedding has extra positive impacts even when the time bucket embedding is already in use. There are two ways to add positional embeddings. The forward way is to view the latest click as if it is at the anchor position, i.e. position zero, while the earliest click of the user would then be at a varying position depending on the user's sequence length. The backward way is, on the other hand, to view the earliest click as if it is at position zero, and the latest click would then be at a varying position when the sequence length varies. We find that the backward version of the positional embedding brings extra improvement even after the bucket embedding is used, while the forward positional embedding does not. We thus adopt the backward positional embedding. The time bucket embedding has already highlighted the recent behaviors, and the backward positional embedding may be behaving like the backward direction in a bi-directional LSTM for capturing long-range dependencies.</p><p>B.1.2 User Encoder. For single-queue CLRec, we employ a simplified multi-head attention (MultiAtt) module for capturing a user's diverse interests hidden behind the user's click sequence ùë• = {ùë¶ ùë° } ùëá ‚àí1 ùë° =1 . We then perform weighted head aggregation (WHA) of the multiple heads' outputs, i.e., head embeddings. That is, f ùúÉ (ùë•) = WHA (MultiAtt (X)), where X ‚àà R (ùëá ‚àí1)√óùëë are the ùëá ‚àí 1 clicks' embeddings, whose specification has been described earlier.</p><p>Multi-Head Attention. Multi-head attention <ref type="bibr" target="#b48">[49]</ref> achieves great success in various NLP tasks and is adopted by sequential recommendation models <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b57">58]</ref>. We simplify the multi-head attention <ref type="bibr" target="#b33">[34]</ref> for efficiency's sake and implement the following module:</p><formula xml:id="formula_21">MultiAtt(X) = SoftMax(MLP(X) ‚ä§ , ‚àí1) X,</formula><p>where X ‚àà R (ùëá ‚àí1)√óùëë are the ùëá ‚àí 1 clicks' embeddings. MLP is a two-layer feed forward neural network whose output is of shape R (ùëá ‚àí1)√óùêª , representing the ùêª sets of attention scores for the ùêª attention heads, respectively. The softmax is performed along the last axis of its input, hence the -1. The output of the above module is a set of ùêª ùëë-dimensional embeddings, namely ùêª head embeddings.</p><p>Weighted Heads Aggregation (WHA). After the simplified multihead attention module, there are ùêª head embeddings {z ‚Ñé } ùêª ‚Ñé=1 . We use a WHA module to aggregate the ùêª head embeddings into one single user embedding. WHA first produces a global feature vector m ‚àà R ùëë , based on which another weighted attention is performed to produce the final user embedding f ùúÉ (ùë•) ‚àà R ùëë for user ùë•:</p><formula xml:id="formula_22">m = ùêª ‚Ñé=1 z ‚Ñé ùêª , ùõº ‚Ñé = exp(z ‚ä§ ‚Ñé Am) ùêª ‚Ñé ‚Ä≤ =1 exp(z ‚ä§ ‚Ñé ‚Ä≤ Am) , f ùúÉ (ùë•) = ùêª ‚àëÔ∏Å ‚Ñé=1 ùõº ‚Ñé z ‚Ñé ,</formula><p>where A ‚àà R ùëë√óùëë is a learnable parameter. We find WHA to be more effective than mean-pooling or concatenation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Normalization and Initialization</head><p>WHA and contrastive learning both seem to be sensitive to the similarity metrics used. We thus ùëô2-normalize the head embeddings before sending them into WHA and normalize the output of WHA as well, which empirically improves training convergence and recommendation diversity. We use the cosine similarity with temperature ùúå &gt; 0 for contrastive learning, i.e. ùúô ùúÉ (ùë•, ùë¶) = ‚ü®f ùúÉ (ùë•),g ùúÉ (ùë¶) ‚ü© ùúå ‚à•f ùúÉ (ùë•) ‚à• ‚à•g ùúÉ (ùë¶) ‚à• , where ùúå = 0.07 following previous work <ref type="bibr" target="#b18">[19]</ref>.</p><p>Some efforts <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53]</ref> have been spent on analyzing the cosine similarity related with ùëô2-normalization as well as the positive effects brought by ùëô2-normalization. According to <ref type="bibr" target="#b52">[53]</ref> which assumes a normal distribution, cosine softmax will force the embeddings to form more compact clusters, which makes kNN search more easy.</p><p>The embeddings should use normal initialization <ref type="bibr" target="#b15">[16]</ref> instead of uniform initialization if ùëô2-normalization is in use, so that the initial embeddings are uniformly spread over the hyper-sphere, which prevents the loss from oscillating at the beginning of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Loss Functions and Sampling Strategies</head><p>Negative sampling <ref type="bibr" target="#b37">[38]</ref>. We sample ùêø examples to pair with each positive click from a proposal distribution ùëû(ùë¶). The proposal distribution ùëû(ùë¶) is proportional to the item's degree, i.e., degree(ùë¶) 0.75 as recommended in <ref type="bibr" target="#b37">[38]</ref>. We use a distributed version of the sampling strategy based on the alias method <ref type="bibr" target="#b44">[45]</ref>, which is provided by AliGraph <ref type="bibr" target="#b61">[62]</ref>. We tune ùêø from 8 to 2, 560 and report the best.</p><p>Shared negative sampling <ref type="bibr" target="#b55">[56]</ref>. This variant aims to increase the efficiency of the original implementation of negative sampling. It makes the positive examples in the present batch share the same set of ùêø negative samples, rather than sampling a different set of ùêø negative samples for each positive instance. Sampled softmax, as well as CLRec, similarly let the positive examples in a batch share the same set of negative samples. However, this implementation of negative sampling with sharing still uses the binary cross-entropy loss used by the original negative sampling implementation.</p><p>Sampled softmax <ref type="bibr" target="#b25">[26]</ref>. We use the sampled softmax implemented in Tensorflow <ref type="bibr" target="#b0">[1]</ref>, which subtracts the correction term to make the sampled loss approximately optimize the same objective as the full loss. We set the number of negative examples used by sample softmax per batch to be the same as the queue size of CLRec.</p><p>CLRec &amp; Multi-CLRec. The batch size is 256. The queue size of CLRec is 2,560. The queue size of Multi-CLRec is 1,280, leading to 2,560 negative items in total as it draws samples from both a main queue and an additional secondary queue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Complex Pretext Tasks</head><p>In task u2u <ref type="bibr" target="#b35">[36]</ref>, ùë• and ùë¶ are both sequences from the same user, before and after a sampled timestamp, respectively. Intuitively, pre-training a recommender to solve task u2u may improve a recommender's ability to make long-term prediction. We co-train the same encoders to solve both task u2u and the original u2i task where ùë• and ùë¶ are a sequence and the sequence's next click. Task u2i is still required, since we ultimately need the recommender to recommmend items rather than sequences at serving time. The batch size is 256. We use one separate queue of size 2,560 for each task. We limit the sequence length of ùë¶ in task u2u to be less than ten. We also investigate whether Momentum Contrast (MoCo) <ref type="bibr" target="#b18">[19]</ref> may improve performance, and vary the momentum parameter in the range of {0.9, 0.99, 0.999, 0.9999} and report the best result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C ADDITIONAL EMPIRICAL RESULTS</head><p>In this section, we provide additional empirical results that demonstrate the interpretability of Multi-CLRec and justify some designs of our encoders. (1) Top items retrived by vector 1.</p><p>(2) Top items retrived by vector 2.</p><p>(3) Top items retrived by vector 3.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Results about Multi-CLRec's Encoders</head><p>In Figure <ref type="figure" target="#fig_8">5</ref>, we demonstrate that the top-ùêæ vectors selected by Multi-CLRec's user encoder do represent a user's ùêæ different intentions, which is mostly due to the auxiliary losses for intention disentanglement. We note that the case shown here is not cherry-picked, but a randomly sampled case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Results about CLRec's Encoders</head><p>In this subsection, we provide some interesting empirical findings that motivates the design of our encoders when developing the single-vector CLRec, even though the findings are not strictly related to contrastive learning or bias reduction. Each of the following experiments should be taken as the analysis for each component individually, which are conducted during different time periods. Considering the costs of deployment into a live system, we deploy a model online only if it has at least similar performance with the previous baselines, and mark a method's online performance as "-" in the table if it is not deployed.</p><p>Table <ref type="table" target="#tab_3">11</ref> then demonstrate the usefulness of combining time bucket embedding and backward positional embedding.</p><p>We then illustrate in Table <ref type="table" target="#tab_12">12that</ref> the encoders can benefit from the combination of weighted head aggregation (WHA) and the cosine similarity, where the results show that cosine similarity is indeed needed for reaching a higher HitRate.</p><p>We also find that combining WHA and cosine can endow a single-vector user encoder with the ability to generate a diversified recommendation list that reflects the different intents behind a user's behavior sequence (see Figure <ref type="figure" target="#fig_10">6</ref>). Without WHA, we observe that the retrieved item set can be easily dominated by one single intent, showing limited diversity.</p><p>The previous methods, especially those use dot product instead of cosine similarity, easily lead to a much skewer interest distribution of the top-k retrieved items. These previous methods tend to under-explore items from the less popular interests. Many have also noticed this issue and proposed their solutions, such as using multiple interest vectors <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b34">35]</ref> or multiple interest sub-models <ref type="bibr" target="#b60">[61]</ref>. Our result (Figure <ref type="figure" target="#fig_10">6</ref>), however, indicates that a single-vector model can sometimes be sufficient for generating a diverse recommendation list.</p><p>Table <ref type="table" target="#tab_3">11</ref>: Effects of the forward positional embedding, backward positional embedding, and time bucket embedding (TBE). We conducted these ablation studies about the encoders in a small-traffic scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>HR@50 (Offline) CTR (Online)  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D THEORECTICAL ANALYSES AND PROOFS</head><p>In this section, we provide the derivation of the IPW loss for a multinomial policy, along with the proof of our theorem.  Nevertheless, the single-vector CLRec is not as controllable and reliable as the multi-vector Multi-CLRec when it comes to preserving the multiple intentions in a balanced manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Derivation of Inverse Propensity Weighting for Multinomial Policies</head><p>In this subsection, we derive the IPW loss for DCG, where we represent the recommendation policy as a multinomial distribution. We assume that the recommender system is a sequential recommender system where a user will receive only one recommendation ùë¶ when the user's state becomes ùë•. However, we note that it is easy to verify that our conclusions still hold when user state ùë• receives ùêæ recommendations, where ùêæ ‚â• 1. We will also focus on a single user state ùë• for conciseness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.1</head><p>Training with Unbiased Data. Ideally, we should collect the training data that do not suffer from selection bias. This is equivalent to collect training data under a random recommendation policy ùúã uni that always recommends a random item in a uniform way, i.e., the random policy should not be aware of the value of ùë• and ùë¶.</p><p>Let the oracle user preference be ùëù (click = 1|ùë•, ùë¶), which is a bernoulli distribution and represents how likely user ùë• will click item ùë¶ if we recommend item ùë¶ to the user. Assuming that user ùë• clicks one item recommended by the random policy ùúã uni , the click data collected under ùúã uni will be:</p><formula xml:id="formula_23">ùëù ùúã uni (ùë¶|ùë•) = ùëù (click = 1 | ùë•, ùë¶) ùë¶ ‚Ä≤ ùëù (click = 1 | ùë•, ùë¶ ‚Ä≤ ) ,<label>(14)</label></formula><p>which is the oracle click data distribution for unbiased training, since the uniform random policy ùúã uni does not introduce any selection bias. Note that ùëù ùúã uni (ùë¶|ùë•) is a multinomial distribution rather than a multivariate bernoulli distribution.</p><p>To learn an ubiased recommendation policy, we need to optimize ùëù ùúÉ (ùë¶|ùë•) on the click data collected under the uniform random policy. In other words, the unbiased loss function should be: </p><p>Since ùëÇ and ùê∂ are independent, the expectation of the above loss is The na√Øve estimator is thus not optimizing the ideal loss as described in Eq. ( <ref type="formula">15</ref>). </p><p>Note that ùëù ùúã uni (ùë¶|ùë•) ‚àù ùëù (click = 1 | ùë•, ùë¶) according to Eq. ( <ref type="formula" target="#formula_23">14</ref>). We thus have: We can see that, if we set ùëû(ùë¶|ùë•) to ùëû ùúã (ùë¶|ùë•), the IPW estimator is then an unbiased estimation that minimizes the oracle unbiased loss Eq. ( <ref type="formula">15</ref>). D.1.3 Bernoulli Propensities vs. Multinomial Propensities. We note that our fomulation is different from the existing literature on debiasing a recommender <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b53">54]</ref>. Most of the existing methods assume that the recommendations ùëÇ are drawn from a multivariate bernoulli policy, i.e., ùëÇ ùë¶ follows an independent bernoulli distribution ùëû ùúã (recommend = 1 | ùë•, ùë¶) <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b51">52]</ref>. Here ùëÇ ùë¶ ‚àà {0, 1} denotes whether item ùë¶ is recommended by the policy. We take a different approach and instead assume that ùëÇ is drawn from a multinomial policy ùëû ùúã (ùë¶ | ùë•) rather than a multivariate bernoulli one.</p><p>In other words, the difference lies in whether we should design a candidate generation policy as a multinomial model or as a multivariate bernoulli model. We choose to design the policy as a multinomial one, due to the following reasons:</p><p>‚Ä¢ The multinomial formulation brings superior performance.</p><p>There are many empirical results that report better performance with a multinomial candidate generation method than a multivariate bernoulli one, especially with a large set of items for recommendation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. Our empirical results in Table <ref type="table">2</ref>, where the negative sampling baselines follow the multivariate bernoulli formulation, also verify this finding. Similarly, the natural language processing (NLP) community also report better results with a multinomial classifier, especially when the number of classes increases <ref type="bibr" target="#b36">[37]</ref>. ‚Ä¢ The multinomial formulation is more consistent with the realworld production environments. The multivariate bernoulli formulation implicitly assumes that the number of recommendations requested by a user can be modeled as part of the recommendation policy ùúã, e.g., the expectation of the number of recommendations is ùë¶ ùëû ùúã (recommend = 1 | ùë•, ùë¶) with the multivariate bernoulli formulation. However, this assumption does not hold in many recommender systems, where the number of recommendations received by a user is decided by the user rather than the system. For example, the user can request more recommendations by scrolling down the page or stop receiving any new recommendation by leaving the page. On the contrary, the multinomial policy ùëû ùúã (ùë¶ | ùë•) does not attempt to model the number of recommendations requested by a user. Rather, the multinomial policy ùëû ùúã (ùë¶ | ùë•) only models which one item it should recommend if the user explicitly requests the system to make one recommendation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Three variants of the single-queue CLRec , whose implicit proposal distributions are ùëù ùëõ (ùë¶ | ùë•) = ùëù data (ùë¶). The superscripts +, ‚àí mean positive and negative examples respectively. Variant (a) uses the positive examples of other instances in the present batch as the negative examples. Variant (b) creates a fixed-size FIFO queue to store the positive examples encountered in previously processed batches, and use the examples in the queue to serve as the negative examples for the present batch. Variant (c) differs from variant (b) in that the queue caches computed representations g ùúÉ (ùë¶) rather than raw features of ùë¶.</figDesc><graphic url="image-1.png" coords="3,109.28,83.68,393.44,192.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Click Sequence (The ground-truth click after this sequence is Item T) Prototype-based Routing (H = Number of Prototypes) Attention Module for Selecting Top K Vectors out of the H Vectors (K=1 when training)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Multi-CLRec, a multi-queue implementation of contrastive learning for bias reduction in DCG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>4. 2 . 1</head><label>21</label><figDesc>Training Efficiency. Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The total number of impressions of the items a specific degree bucket vs. the logarithm of the corresponding degree. Sample softmax tends to faithfully fit the training data's distribution, while CLRec reduces the Matthew effect.</figDesc><graphic url="image-3.png" coords="8,58.19,459.89,75.66,56.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( 0 )</head><label>0</label><figDesc>The user's latest eight clicks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>( 4 )</head><label>4</label><figDesc>Top items retrived by vector 4.(5) Top items retrived by vector 5.(6) Top items retrived by vector 6.(7) Top items retrived by vector 7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Multi-CLRec's user encoder can select and output top-ùêæ vectors at serving time. We show here the top-ùêæ vectors (for ùêæ = 7) do represent the user's ùêæ different intentions, owing to the auxiliary losses for intention disentanglement.</figDesc><graphic url="image-36.png" coords="12,168.59,398.13,54.52,61.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) User's behavior sequence. (b) Items retrieved by the concatenation method. (c) Items retrieved by the WHA + cosine method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: It is possible for a single-vector user encoder to generate a diverse recommendation list, as long as the model is properly designed, e.g., if the model combines the weighted head aggregation (WHA) strategy with the cosine similarity.Nevertheless, the single-vector CLRec is not as controllable and reliable as the multi-vector Multi-CLRec when it comes to preserving the multiple intentions in a balanced manner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>ùëÖ(ùúÉ |ùë•) = ‚àí ‚àëÔ∏Å ùë¶ ùëù ùúã uni (ùë¶|ùë•) log ùëù ùúÉ (ùë¶|ùë•). (15) D.1.2 Training with Biased Data: Inverse Propensity Weighting. However, random exploration is expensive in a real-world recommender system. In practice, the click data D ùúã for training a new policy is collected under a biased old recommendation policy ùúã. Let ùëû ùúã (ùë¶ | ùë•) be the probability that the old policy recommends item ùë¶ to a user in state ùë•. Note that ùëû ùúã (ùë¶ | ùë•) is a multinomial distribution, i.e. ùë¶ ‚Ä≤ ùëû ùúã (ùë¶ ‚Ä≤ | ùë•) = 1. The generating process of the biased dataset D ùúã is as follows. Policy ùúã makes a recommendatin, i.e. draws a one-hot impression vector ùëÇ from the multinomial distribution ùëû ùúã (ùë¶ | ùë•), whose ùë¶th element ùëÇ ùë¶ = 1 if the recommendation is item ùë¶, and ùëÇ ùë¶ = 0 otherwise. On the other hand, user ùë• is associated with a multi-hot vector ùê∂ representing the user's preference regarding all the items, whose ùë¶th element ùê∂ ùë¶ is drawn from the bernoulli distribution ùëù (click = 1 | ùë•, ùë¶), ùë¶ = 1, 2, 3, ..., |Y|. Here ùê∂ ùë¶ = 1 if the user will click item ùë¶ after being recommeded item ùë¶, ùê∂ ùë¶ = 0 otherwise. A na√Øve estimator that does not take selection bias into account typically learns a new biased policy ùëù ùúÉ (ùë¶|ùë•) by minimizing the following biased loss: Rnaive (ùúÉ |D ùúã ) = ‚àí ‚àëÔ∏Å ùë¶ ùëÇ ùë¶ ùê∂ ùë¶ log ùëù ùúÉ (ùë¶|ùë•),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>E</head><label></label><figDesc>D ùúã Rnaive (ùúÉ |D ùúã ) = ‚àí ‚àëÔ∏Å ùë¶ E[ùëÇ ùë¶ ]E[ùê∂ ùë¶ ] log ùëù ùúÉ (ùë¶ | ùë•) = ‚àí ‚àëÔ∏Å ùë¶ ùëû ùúã (ùë¶ | ùë•)ùëù (click = 1 | ùë•, ùë¶) log ùëù ùúÉ (ùë¶ | ùë•).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>1 ùëû</head><label>1</label><figDesc>Now let us analyze the IPW estimator, which minimizes the following loss: RIPW (ùúÉ |D ùúã ) = ‚àí ‚àëÔ∏Å ùë¶ (ùë¶ | ùë•) ùëÇ ùë¶ ùê∂ ùë¶ log ùëù ùúÉ (ùë¶ | ùë•).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>E</head><label></label><figDesc>D ùúã RIPW (ùúÉ |D ùúã ) = ‚àí ‚àëÔ∏Å ùë¶ ùëû ùúã (ùë¶ | ùë•) ùëû(ùë¶ | ùë•) ùëù (click = 1 | ùë•, ùë¶) log ùëù ùúÉ (ùë¶ | ùë•) ‚àù ‚àí ‚àëÔ∏Å ùë¶ ùëû ùúã (ùë¶ | ùë•) ùëû(ùë¶ | ùë•) ùëù ùúã uni (ùë¶ | ùë•) log ùëù ùúÉ (ùë¶ | ùë•).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Here ùëù data (ùë¶ | ùë•) is the data distribution, i.e. what is the frequency of ùë¶ apprearing in D given context ùë•.</figDesc><table><row><cell>roughly follows the non-personalized propensity score ùëû(ùë¶), i.e.,</cell><cell></cell></row><row><cell>the probability of item ùë¶ being recommended by the old system</cell><cell></cell></row><row><cell>under which we collect the training data, for reducing the Matthew</cell><cell></cell></row><row><cell>effect. (2) We then improve upon CLRec and propose Multi-CLRec</cell><cell></cell></row><row><cell>(see Figure 2), which involves multiple disentangled queues cor-</cell><cell></cell></row><row><cell>responding to different user intents and performs bias reduction</cell><cell></cell></row><row><cell>based on the more accurate propensity score ùëû(ùë¶ | user ùë•'s intent).</cell><cell></cell></row><row><cell>Our approaches, unlike the IPW methods that require introduc-</cell><cell></cell></row><row><cell>ing an extra model for estimating the propensity score ùëû(ùë¶ | ùë•), are</cell><cell></cell></row><row><cell>free from the variance brought by the extra model and do not need</cell><cell></cell></row><row><cell>to introduce a costly, extra stage for training the extra model.</cell><cell></cell></row><row><cell>3.1 CLRec: Queue-based Contrastive Learning</cell><cell></cell></row><row><cell>for Reducing the Matthew Effect</cell><cell></cell></row><row><cell>The exact propensity score ùëû(ùë¶ | ùë•) is challenging to estimate, be-</cell><cell></cell></row><row><cell>cause industrial systems involve many complicated modules and the</cell><cell></cell></row><row><cell>data are sparse. CLRec thus use ùëû(ùë¶) in place of ùëû(ùë¶ | ùë•), i.e. assum-</cell><cell></cell></row><row><cell>ing ùëû(ùë¶ | ùë•) ‚âà ùëû(ùë¶), to ease estimation and avoid small propensities.</cell><cell></cell></row><row><cell>Secondly, ùëû(ùë¶) (i.e. the exposure probability that item ùë¶ is recom-</cell><cell></cell></row><row><cell>mended to someone) has a high correlation with ùëù ùëëùëéùë°ùëé (ùë¶), i.e. the</cell><cell></cell></row><row><cell>click probability that item ùë¶ is being recommended and clicked by</cell><cell></cell></row><row><cell>someone, because the existing system will mainly recommend items</cell><cell></cell></row><row><cell>that have a high click-through rate if the system is already highly</cell><cell></cell></row><row><cell>optimized. We thus further replace the impression distribution ùëû(ùë¶)</cell><cell></cell></row><row><cell>with the click distribution ùëù</cell><cell></cell></row><row><cell>Proof. See the Appendix.</cell><cell>‚ñ°</cell></row><row><cell cols="2">Remark 1. The implication of Theorem 1 is that the contrastive</cell></row><row><cell cols="2">loss (Eq. 3) can approximately reduce the exposure bias if we set</cell></row><row><cell cols="2">the proposal distribution ùëù ùëõ (ùë¶ | ùë•) to be the propensity score, i.e.</cell></row><row><cell cols="2">the probability that the old systems deliver item ùë¶ to user ùë• when</cell></row><row><cell>we were collecting the training data D.</cell><cell></cell></row><row><cell>3 QUEUE-BASED CONTRASTIVE LEARNING</cell><cell></cell></row><row><cell>FOR BIAS REDUCTION</cell><cell></cell></row><row><cell cols="2">We propose two efficient implementations of contrastive losses for</cell></row><row><cell cols="2">bias reduction in large-scale DCG: (1) We will first present CLRec</cell></row><row><cell cols="2">(see Figure 1), which draws negative samples from a queue that</cell></row></table><note>ùëëùëéùë°ùëé (ùë¶), i.e. assuming ùëû(ùë¶) ‚âà ùëù ùëëùëéùë°ùëé (ùë¶),</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>If item T belongs to Intention N according to Prototype Routing, Main Queue and Secondary Queue N serve as the negative samples. 2. If an item belonging to Intention M is dequeued from Main Queue, the item enters Queue M after being dequeued from Main Queue.</figDesc><table><row><cell cols="9">Weighted Pooling Concat Intention 1's Bias Vector User Vector 1 trainable parameters. A Set of Auxiliary Losses for Disentangling the Intentions 1. The bias vectrors are Weighted Pooling Concat Intention 2's Bias Vector User Vector 2 Weighted Pooling Concat Intention H's Bias Vector User Vector H Multi-Layer Perceptron ‚Ä¶ Contrastive Loss As Query As Positive Main FIFO Queue, following q(Next Item) Item Item Item Item ‚Ä¶ Secondary FIFO Queue 1, following q(Next Item | Intention 1) Item (belong to Intenion M) Item Item Item Item Item ‚Ä¶ As Negative As Negative Dequeue Enqueue</cell></row><row><cell>(This slot is empty, because</cell><cell cols="2">Intention 2 Item 2 weight 2</cell><cell>‚Ä¶</cell><cell cols="2">Intention H Item 1 weight 1</cell><cell>Enqueue</cell><cell cols="2">Secondary FIFO Queue M, following q(Next Item | Intention M) Item Item Item Item Item ‚Ä¶ Dequeue</cell></row><row><cell>the user has no behavior under this intention)</cell><cell>Item T-1</cell><cell>weight T-1</cell><cell></cell><cell>Item 3 Item T-2</cell><cell>weight 3 weight T-2</cell><cell cols="3">Secondary FIFO Queue N, following q(Next Item | Intention N)</cell></row><row><cell>The weights are output by another MLP (not drawn).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Weighted Pooling</cell><cell cols="2">Item</cell><cell>Item</cell><cell>Item</cell><cell>Item</cell><cell>‚Ä¶</cell><cell>Item</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Secondary FIFO Queue H, following q(Next Item | Intention H)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Item</cell><cell>Item</cell><cell>Item</cell><cell>Item</cell><cell>‚Ä¶</cell><cell>Item</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Aggregate diversity<ref type="bibr" target="#b1">[2]</ref>, i.e. the number of distinct items recommended to a randomly sampled subset of users.</figDesc><table><row><cell></cell><cell>Aggregated Diversity</cell></row><row><cell>sampled-softmax</cell><cell>10,780,111</cell></row><row><cell>CLRec</cell><cell>21,905,318</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Main live experiment results conducted in one of the largest scenarios on our platform. CLRec consistently outperforms the baseline for months and has been fully deployed since Feb 2020. A method with a large popularity index tends to recommend popular items while a method with a small index is fairer to the under-exposured items.</figDesc><table><row><cell cols="4">Method CTR Average Dwell Time Popularity Index</cell></row><row><cell>MIND</cell><cell>5.87%</cell><cell>-</cell><cell>0.658</cell></row><row><cell>CLRec</cell><cell>6.30%</cell><cell>+11.9%</cell><cell>0.224</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>The user distribution of our platform usually changes significantly when the weekend arrives. When the user distribution changes significantly, Multi-CLRec has an advantage over single-queue CLRec in terms of the offline evaluation metric HitRate@50. Multi-CLRec replaced CLRec and became the new default in mid-2020, bringing a 3% relative improvement in terms of total clicks on our platform while maintaining a comparable click-through rate.</figDesc><table><row><cell></cell><cell cols="2">Train on Weekdays' Data</cell></row><row><cell>Method</cell><cell cols="2">Test on Weekdays Test on Weekends</cell></row><row><cell>CLRec</cell><cell>17.18%</cell><cell>17.16%</cell></row><row><cell>Multi-CLRec</cell><cell>17.25%</cell><cell>17.68%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Training speed in terms of the number of the positive examples processed per second, and the average network traffic in a distributed environment.</figDesc><table><row><cell>Method</cell><cell cols="2">Samples/Sec NetTraffic (MB/s)</cell></row><row><cell>sampled-softmax w/o feat.</cell><cell>‚âà 280ùëò</cell><cell>‚âà 700</cell></row><row><cell>sampled-softmax with feat.</cell><cell>‚âà 130ùëò</cell><cell>‚âà 1, 100</cell></row><row><cell>CLRec w/o feat.</cell><cell>‚âà 330ùëò</cell><cell>‚âà 500</cell></row><row><cell>CLRec with feat.</cell><cell>‚âà 280ùëò</cell><cell>‚âà 500</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>The benefits of encoding features for the negative samples. Most baselines that employ sampled-softmax do not encode rich features for the negative samples (though they still use features when encoding the users' click sequences), because the number of negative samples is large and brings high costs if the features are complex. Fortunately, CLRec's cached implementation greatly reduces the costs, as demonstrated in Table5.</figDesc><table><row><cell>Method</cell><cell>HR@50</cell></row><row><cell cols="2">CLRec + negatives w/o features 17.4%</cell></row><row><cell cols="2">CLRec + negatives with features 19.4%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Results on public benchmarks preprocessed by SASRec<ref type="bibr" target="#b28">[29]</ref> and BERT4Rec<ref type="bibr" target="#b45">[46]</ref>. We follow BERT4Rec's approach when constructing the test set, which penalizes false positive predictions on popular items. For fair comparision, the IPW implementation and the CLRec implementation in this table use the same Transformer<ref type="bibr" target="#b33">[34]</ref> encoder as SASRec but with a IPW loss and a contrastive loss, respectively.</figDesc><table><row><cell></cell><cell></cell><cell>17.9%</cell><cell></cell><cell>12.1%</cell></row><row><cell cols="2">CLRec-u2u, cached</cell><cell>18.3%</cell><cell></cell><cell>12.7%</cell></row><row><cell cols="3">CLRec-u2u, cached + MoCo 18.2%</cell><cell></cell><cell>12.6%</cell></row><row><cell>Method</cell><cell cols="4">Metric ML-1M Beauty Steam</cell></row><row><cell>SASRec</cell><cell>HR@1</cell><cell>0.2351</cell><cell>0.0906</cell><cell>0.0885</cell></row><row><cell>BERT4Rec</cell><cell></cell><cell>0.2863</cell><cell>0.0953</cell><cell>0.0957</cell></row><row><cell>IPW</cell><cell></cell><cell>0.2934</cell><cell>0.1129</cell><cell>0.1381</cell></row><row><cell>CLRec</cell><cell></cell><cell>0.3013</cell><cell cols="2">0.1147 0.1424</cell></row><row><cell>SASRec</cell><cell>HR@5</cell><cell>0.5434</cell><cell>0.1934</cell><cell>0.2559</cell></row><row><cell>BERT4Rec</cell><cell></cell><cell>0.5876</cell><cell>0.2207</cell><cell>0.2710</cell></row><row><cell>IPW</cell><cell></cell><cell>0.5985</cell><cell>0.2404</cell><cell>0.3539</cell></row><row><cell>CLRec</cell><cell></cell><cell>0.6045</cell><cell cols="2">0.2552 0.3640</cell></row><row><cell>SASRec</cell><cell cols="2">HR@10 0.6629</cell><cell>0.2653</cell><cell>0.3783</cell></row><row><cell>BERT4Rec</cell><cell></cell><cell>0.6970</cell><cell>0.3025</cell><cell>0.4013</cell></row><row><cell>IPW</cell><cell></cell><cell>0.7156</cell><cell>0.3215</cell><cell>0.4924</cell></row><row><cell>CLRec</cell><cell></cell><cell>0.7194</cell><cell cols="2">0.3423 0.5019</cell></row><row><cell cols="5">4.2.2 Complex Pretext Task that Requires the Cached Implementa-</cell></row><row><cell>tion.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Aggregate diversity on public datasets, where each algorithm retrieves ten items for each test user.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>.7809</cell><cell cols="2">0.9240</cell></row><row><cell></cell><cell>CLRec</cell><cell></cell><cell>0.7785</cell><cell cols="2">0.9278</cell></row><row><cell cols="3">IPW Loss + Multi-CLRec's Encoder</cell><cell>0.7888</cell><cell cols="2">0.9319</cell></row><row><cell></cell><cell>Multi-CLRec</cell><cell></cell><cell>0.7993</cell><cell cols="2">0.9353</cell></row><row><cell></cell><cell></cell><cell cols="3">Aggregate Diversity</cell></row><row><cell cols="6">Dataset #Users Ground-Truth Sample-Softmax CLRec</cell></row><row><cell>ML-1M</cell><cell>6,040</cell><cell>1,883</cell><cell></cell><cell>2,348</cell><cell>3,020</cell></row><row><cell>Beauty</cell><cell>40,226</cell><cell>19,820</cell><cell></cell><cell cols="2">24,340 44,408</cell></row><row><cell cols="2">Steam 281,428</cell><cell>10,006</cell><cell></cell><cell cols="2">5,154 10,111</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>Performance of the different head aggregation strategies used by the single-vector CLRec's user encoder.</figDesc><table><row><cell>Method</cell><cell cols="2">HR@50 (Offline) CTR (Online)</cell></row><row><cell>MeanPooling</cell><cell>15.1%</cell><cell>3.10%</cell></row><row><cell>MeanPooling + Cosine</cell><cell>18.1%</cell><cell>-</cell></row><row><cell>MeanPooling + MLP</cell><cell>10.5%</cell><cell>-</cell></row><row><cell>MeanPooling + MLP + Cosine</cell><cell>17.7%</cell><cell>-</cell></row><row><cell>Concatenation + MLP</cell><cell>17.8%</cell><cell>3.15%</cell></row><row><cell>WHA + Cosine</cell><cell>19.7%</cell><cell>3.21%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Our IPW loss is different from the previous works on debiased recommenders<ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b51">52]</ref>. We focus on multinomial propensities, i.e. whether an item is selected and recommended by a recommender out of all possible items. The previous works consider bernoulli propensities related with users' attention, i.e. whether a user notices a recommended item or not, and mostly deal with the position bias in ranking. We give the derivation of this multinomial IPW loss in the Appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1">CONCLUSIONWe established in theory the connection between contrastive learning and IPW, based on which we proposed CLRec and Multi-CLRec for efficient and effective bias reduction in large-scale DCG.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Proof of Theorem 1</head><p>Theorem 2. The optimal solutions of the contrastive loss (Eq. 3) and the IPW loss (Eq. 4) both minimize the KL divergence from ùëù ùúÉ <ref type="bibr">(</ref> ùë¶ ‚Ä≤ ‚ààùê∂ exp(ùúô ùúÉ (ùë•,ùë¶ ‚Ä≤ )) , whose supports are ùê∂ ‚äÇ Y. Since we are minimizing the KL divergence under all possible ùê∂ ‚äÇ Y, the global optima will be the ones that make ùëù ùúÉ (ùë¶ | ùë•) equal to ùëü (ùë¶ | ùë•) for all ùë¶ ‚àà Y if ùúô ùúÉ (ùë•, ùë¶) is expressive enough to fit the target distribution arbitrarily close. Note that ùúô ùúÉ (ùë•, ùë¶) is indeed expressive enough since we implement it as a neural network, due to the universal approximation theorem <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref>. The two losses hence have the same global optima. ‚ñ°</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">Mart√≠n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving aggregate recommendation diversity using ranking-based techniques</title>
		<author>
			<persName><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngok</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unbiased learning to rank with unbiased propensity estimation</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keping</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Personalized Bundle List Recommendation</title>
		<author>
			<persName><forename type="first">Jinze</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junshuai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiting</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Li</surname></persName>
		</author>
		<idno>WWW. 60-71</idno>
		<imprint>
			<date type="published" when="2019">Jun Gao. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>L√©onard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive importance sampling to accelerate training of a neural probabilistic language model</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-S√©bastien</forename><surname>Sen√©cal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="713" to="722" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fairness in Recommendation Ranking through Pairwise Comparisons</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tulsee</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristos</forename><surname>Goodrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00093[cs.CY]</idno>
		<title level="m">Multisided Fairness for Recommendation</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Word2vec applied to recommendation: Hyperparameters matter</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Caselles-Dupr√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Lesaint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimena</forename><surname>Royo-Letelier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="352" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Top-k off-policy correction for a REINFORCE recommender system</title>
		<author>
			<persName><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francois</forename><surname>Belletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="456" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<title level="m">A simple framework for contrastive learning of visual representations</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On sampling strategies for neural network-based collaborative filtering</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequential recommendation with user memory networks</title>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of a sigmoidal function</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Control, Signals and Systems</title>
		<imprint>
			<date type="published" when="1989">1989. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
	<note>In AISTATS</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Real-time personalization using embeddings for search ranking at airbnb</title>
		<author>
			<persName><forename type="first">Mihajlo</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyv√§rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning Stable Graphs from Multiple Environments with Selection Bias</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Bal√°zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06939</idno>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Linas Baltrunas, and Domonkos Tikk</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06670</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J√ºrgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Approximation capabilities of multilayer feedforward networks</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Guido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Imbens</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
		<title level="m">Causal inference in statistics, social, and biomedical sciences</title>
				<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">S√©bastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.2007</idno>
		<title level="m">On using very large target vocabulary for neural machine translation</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Neural input search for large scale recommendation models</title>
		<author>
			<persName><forename type="first">Cong</forename><surname>Manas R Joglekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Khaitan</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04471</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herv√©</forename><surname>J√©gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<title level="m">Billion-scale similarity search with GPUs</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM. IEEE</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elise</forename><surname>Van Der Pol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12247</idno>
		<title level="m">Contrastive Learning of Structured World Models</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-interest network with dynamic routing for recommendation at Tmall</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengmeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pipei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dik</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Variational Autoencoders for Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Jebara</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cicero</forename><surname>Nogueira Dos Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03130</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning disentangled representations for recommendation</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5712" to="5723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Disentangled Self-Supervision in Sequential Recommenders</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A comparison of event models for naive bayes text classification</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-98 workshop on learning for text categorization</title>
				<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Lifelong sequential modeling with personalized memorization for user response prediction</title>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Kan Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="565" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The central role of the propensity score in observational studies for causal effects</title>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="41" to="55" />
			<date type="published" when="1983">1983. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05352</idno>
		<title level="m">Recommendations as treatments: Debiasing learning and evaluation</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multi-class n-pair loss objective</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1857" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Evaluation of recommendations: rating-prediction and ranking</title>
		<author>
			<persName><forename type="first">Harald</forename><surname>Steck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Distributed negative sampling for word embeddings</title>
		<author>
			<persName><forename type="first">Stergios</forename><surname>Stergiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zygimantas</forename><surname>Straznickas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rolina</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kostas</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1441" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Personalized top-n sequential recommendation via convolutional sequence embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><surname>Thompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Attention Is All You Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veliƒçkoviƒá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Li√≤</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Hjelm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10341</idno>
		<title level="m">Deep graph infomax</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingchao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5265" to="5274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning to rank with selection bias in personal search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep cosine metric learning for person re-identification</title>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Wojke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Bewley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV. IEEE</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="748" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sequential recommender system based on hierarchical attention network</title>
		<author>
			<persName><forename type="first">Haochao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guandong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01973</idno>
		<title level="m">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">CauseRec: Counterfactual User Sequence Synthesis for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Shengyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">ATRank: An attention-based user behavior modeling framework for recommendation</title>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinze</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junshuai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengchao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Scalable graph embedding for asymmetric proximity</title>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqiong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deep interest evolution network for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Na</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5941" to="5948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning Tree-based Deep Model for Recommender Systems</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guozheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">AliGraph: a comprehensive graph neural network platform</title>
		<author>
			<persName><forename type="first">Rong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baole</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2094" to="2105" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
