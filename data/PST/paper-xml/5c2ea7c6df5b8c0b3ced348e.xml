<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yue</forename><surname>Wu</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Youzuo</forename><surname>Lin</surname></persName>
							<email>ylin@lanl.gov</email>
						</author>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">Chas</forename><surname>Bolton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ji</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Johnson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><surname>Johnson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Earth and Environmental Sciences Division</orgName>
								<orgName type="institution">Los Alamos National Laboratory</orgName>
								<address>
									<postCode>87544</postCode>
									<settlement>Los Alamos</settlement>
									<region>NM</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Geosciences</orgName>
								<orgName type="institution">Penn State University</orgName>
								<address>
									<postCode>16802</postCode>
									<settlement>University Park</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8030267F2CFD7BDDF94DE329A18F5B64</idno>
					<idno type="DOI">10.1109/TGRS.2018.2852302</idno>
					<note type="submission">received November 11, 2017; revised April 10, 2018; accepted June 11, 2018.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional neural network (CNN)</term>
					<term>event detection</term>
					<term>seismic signals</term>
					<term>time series segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic event detection from time series signals has broad applications. Traditional detection methods detect events primarily by the use of similarity and correlation in data. Those methods can be inefficient and yield low accuracy. In recent years, machine learning techniques have revolutionized many sciences and engineering domains. In particular, the performance of object detection in a 2-D image data has significantly improved due to deep neural networks. In this paper, we develop a deeplearning-based detection method, called "DeepDetect," to detect events from seismic signals. We find that the direct adaptation of similar ideas from 2-D object detection to our problem faces two challenges. The first challenge is that the duration of earthquake event varies significantly; the other is that the proposals generated are temporally correlated. To address these challenges, we propose a novel cascaded region-based convolutional neural network to capture earthquake events in different sizes while incorporating contextual information to enrich features for each proposal. To achieve a better generalization performance, we use densely connected blocks as the backbone of our network. Because some positive events are not correctly annotated, we further formulate the detection problem as a learning-from-noise problem. To verify the performance, we employ the seismic data generated from the Pennsylvania State University Rock and Sediment Mechanics Laboratory, and we acquire labels with the help of experts. We show that our techniques yield high accuracy. Therefore, our novel deep-learning-based detection methods can potentially be powerful tools for identifying events from the time series data in various applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning methods have been successful in object detection to identify patterns. There have been many existing machine learning methods to detect events from time series data sets for various applications, such as epileptic seizure detection from EEG signals and change detection from remotely sensed imagery data sets. Depending on the availability of labeled data sets, these event detection methods for time series data sets can be categorized into supervised <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b4">[5]</ref> and unsupervised methods <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. This paper belongs to the supervised category since we acquire labels for training and evaluation with the help of experts. As for supervised methods, they are all pointwise detection methods meaning that they classify data points at each time stamp. Pointwise detection methods can be limited in their detection performance. In particular, those methods can neither accurately localize events nor obtain the number of events. In this paper, inspired by the object detection in 2-D imagery, we develop a novel eventwise detection method, called "DeepDetect," to capture each complete event. In other words, our DeepDetect captures the beginning and end coordinates to localize each event from the time series data sets.</p><p>Convolutional neural networks (CNNs) has achieved promising results in computer vision, image analysis, and many other domains due to the significantly improved computational power <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b10">[11]</ref>. The state-of-the-art CNN-based object detection models for 2-D imagery primarily consist of two steps <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>: a step to generate the region proposals and a step to identify and localize the events within the proposals. Specifically, segments of the input data that may include targeting patterns are first used to generate region proposals. A classifier is then employed on each proposal to detect targeting patterns, and a regressor is utilized to localize events within the positive proposals. The original proposal generation method for CNN-based detection models is developed in two region-based CNN models, known as R-CNN <ref type="bibr" target="#b13">[14]</ref> and fast R-CNN <ref type="bibr" target="#b12">[13]</ref>, where fixed methods are used to obtain proposals. Faster R-CNN <ref type="bibr" target="#b11">[12]</ref> improves previous models by building region proposal networks on top of the final feature map of CNN backbone. Compared with Girshick <ref type="bibr" target="#b12">[13]</ref> and Girshick et al. <ref type="bibr" target="#b13">[14]</ref>, the faster R-CNN eliminates the additional time spent on proposal generation. To determine whether a proposal is positive or negative, Ren et al. <ref type="bibr" target="#b11">[12]</ref> introduce the concept of anchor to denote the region on the input data that a proposal covers. A proposal is considered positive if its corresponding anchor overlaps the ground truth above a threshold.</p><p>In this paper, we develop a novel deep neural network detection method for time series data sets. Similar to the U.S. Government work not protected by U.S. copyright. previous 2-D detection models, our model also consists of two steps: proposal generation and event localization. However, a direct adaptation of 2-D methods to generate the region proposals does not work well with our 1-D seismic time series data sets because the duration of seismic events varies significantly. Therefore, we develop a novel region proposal method to address this issue. In particular, we develop a cascaded network that generates proposals by including more downsampling layers than regular networks do. Theoretically, events of small size can be captured at shallow layers. As the network becomes deeper, events of large size can be captured due to the increasing size of the receptive field. We add detection branches on feature maps at different depths so that events in various scales can be captured.</p><p>Features are critical to the performance of our detection model. Since the classifier and the regressor in the second step share the same feature vector obtained from the CNN, enriching features for proposals will boost the detection rate and localization accuracy. Another novelty of this paper is the incorporation of contextual information for each individual proposal. Although the importance of contextual information has been emphasized for imagery segmentation <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>, there are surprisingly few detection models taking into account contextual information on the proposal level. As for the time series seismic signals, proposals are temporally correlated. Utilizing each proposal individually generates many falsepositive detections. This is because proposals may be a part of some large events, and our detection method should be able to distinguish small-signal segments from large events. Considering this, we enrich the features of each proposal by incorporating contextual information.</p><p>Because of the cascaded structure, the number of parameters in our model may significantly increase. To obtain the better generalization performance, we build our DeepDetect based on densely connected networks (DenseNets) <ref type="bibr" target="#b7">[8]</ref>. The core idea of DenseNet is to reuse features learned from shallow layers, which enables us to maintain a reasonable number of parameters even if the network becomes substantially deep. Another strategy we use to address overfitting is to share the parameters of the sibling detector and regressor. This is reasonable since we are interested in capturing specific patterns regardless of their size.</p><p>Due to the variation in the event patterns and density, it is impractical for domain experts to accurately annotate all events. Those omitted events may bias the classifier for proposals. To alleviate the impact of mislabeled positive events, we further formulate the proposal classification as a learningfrom-noise problem. Inspired by Natarajan et al. <ref type="bibr" target="#b17">[18]</ref>, we use a label-dependent loss function for the classifier.</p><p>We test our detection models on the seismic time series data and compare the experimental results obtained using the proposed cascaded-contextual R-CNN (CC-RCNN) and the traditional template matching (TM) method. We use AP@[0.5, 0.95] as the evaluation metric. Average precision (AP) calculates the averaged maximum precision at each recall value. We calculate 10 APs with the intersection over union (IoU) of [0.5:0.95:0.05] as the metric to identify true positive detections and then take the average. We also conduct ablation experiments to verify the effect of the multiscale architecture and the incorporation of contextual information. The experiment results demonstrate that our deep-learningbased model achieves AP@[0.5, 0.95] of 63.8%, which significantly outperforms the TM method. The ablation studies further show that the incorporation of contextual information for each individual proposal not only reduces false-positive detections but also significantly increases the event localization accuracy. Also, the utilization of label-dependent loss further boosts the performance of our detection models. To summarize, our contributions can be listed as follows.</p><p>1) Extend R-CNNs to time series scenarios.</p><p>2) Propose a cascaded structure to generate multiscale proposals to efficiently capture events in varying lengths. 3) Incorporate contextual information for each proposal to further boost the detection accuracy. 4) Conduct experiments on the seismic time series data and obtain promising results-achieving AP (AP)@[0.5, 0.95] of 63.8%. This paper is organized as follows. Section II briefly reviews the related works on event detection and object detection. Section III gives background knowledge about our method. The proposed method is elaborated in Section IV. Implementation details of the proposed methods and the counterpart methods are described in Section V. Experiment results are provided in Section VI. Section VII concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Our study is related to both event detection for 1-D time series data sets and object detection for 2-D imagery data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Detection Methods for Time-Series Data</head><p>There are many event detection methods in various applications. In seismology, short time average over long time average (STA/LTA) is the most popular used detection method due to its simplicity <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. STA/LTA computes the ratio of short-term average energy and long-term average energy on multiple receivers. If the ratio exceeds a predefined threshold, a detection is declared. However, STA/LTA fails to detect earthquakes or yields many false detections in challenging situations, such as signal with low signal-to-noise ratio, or overlapping events. Compared with STA/LTA, autocorrelation yields a much higher detection rate <ref type="bibr" target="#b20">[21]</ref>. Autocorrelation is an exhaustive "many-to-many" detection method. It searches for similar waveforms when the desired signal waveform is unknown. The major disadvantage with autocorrelation lies in its notoriously expensive computational cost, which scales quadratically with data duration. TM is a detection method that yields a good balance between accuracy and computational complexity <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. TM is a "one-to-many" detection method. It computes the correlation coefficient of a template waveform with the candidate waveform data. A detection is claimed when the correlation coefficient value is above the user-defined threshold value. TM has been proven to be efficient and successful for different seismic applications: microseismic monitoring in geothermal fields <ref type="bibr" target="#b23">[24]</ref>, oil and gas reservoirs <ref type="bibr" target="#b24">[25]</ref>, nuclear monitoring <ref type="bibr" target="#b25">[26]</ref>, and tectonic tremor <ref type="bibr" target="#b22">[23]</ref>, and so on. However, TM usually performs poorly when events are dissimilar. Yoon et al. <ref type="bibr" target="#b1">[2]</ref> recently developed an event detection approach called the fingerprint and similarity thresholding (FAST) method and applied it to detect earthquakes out of seismic data sets. FAST creates "fingerprints" of waveforms by extracting key discriminative features and then groups similar fingerprints together within a database to facilitate the fast and scalable search for similar fingerprint pairs.</p><p>There are many other event detection methods developed in other application domains. Oehmcke et al. <ref type="bibr" target="#b2">[3]</ref> employed local outlier factor to detect events from the marine time series data. To further improve results, dimensionality reduction methods are employed by the authors to the data sets. In the work of Batal et al. <ref type="bibr" target="#b4">[5]</ref>, an event detection method was developed based on recent temporal patterns. The detection algorithm mines time-interval patterns backward in time, starting from patterns related to the most recent observation. The authors further applied their detection method to health care data of diabetic patients. McKenna et al. <ref type="bibr" target="#b26">[27]</ref> developed a binomial event discriminator (BED) method. BED uses a failure model based on the binomial distribution to determine the probability of an event within a time segment. The effectiveness of their model is demonstrated with the hydrological data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. CNN-Based Detection Methods for Image Data</head><p>Ren et al. <ref type="bibr" target="#b11">[12]</ref> developed the faster RCNN method, of which a window is slid on the final feature map of the fourth stage of ResNet <ref type="bibr" target="#b8">[9]</ref> to generate proposals. The authors use nine different anchors with three various sizes (128, 256, 512) and three ratios of height/width (1:1, 1:2, 2:1) to determine regions that a proposal covers. To make anchors more accurate, Cai et al. <ref type="bibr" target="#b27">[28]</ref> developed the multiscale CNN methods, consisting of a proposal subnetwork to generate multiscale proposals at three stages of VGG <ref type="bibr" target="#b9">[10]</ref> network. The authors then built detectors on top of each proposal branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BACKGROUND AND RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Template Matching</head><p>TM <ref type="bibr" target="#b21">[22]</ref> is widely used in the seismology community. It calculates the similarity of a template with successive windows from continuous waveform data. The commonly used similarity metric is normalized cross correlation (CC)</p><formula xml:id="formula_0">CC(a, b) = a, b a 2 b 2 = i a i b i i a 2 i i b 2 i (1)</formula><p>where a and b are vectorized time series signals. The detection threshold of τ is given as</p><formula xml:id="formula_1">τ = μ • MAD (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where μ is usually chosen as 9 <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. For a univariate set X 1 , X 2 , . . . , X n , median absolute deviation can be calculated as </p><formula xml:id="formula_3">MAD(X) = median(|X i -median(X)|).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Densely Connected Network</head><p>DenseNet <ref type="bibr" target="#b7">[8]</ref> is an improved version of the residual network <ref type="bibr" target="#b8">[9]</ref>. Both ResNet and DenseNet are discussed in this section.</p><p>1) ResNet Block: The major breakthrough of ResNet is the application of skip connections between residual blocks, which can be denoted as</p><formula xml:id="formula_4">x l+1 = x l + W * (σ (B(W * (σ (B(x l )) (4)</formula><p>where x l is the input feature to the lth residual block, W and W are weight matrices, the operator of "*" denotes convolution, B denotes batch normalization (BN) <ref type="bibr" target="#b30">[31]</ref>, and σ (x) = max(0, x) <ref type="bibr" target="#b31">[32]</ref>. Equation ( <ref type="formula">4</ref>) forms a building block in ResNet. Skip connections are implemented by summing up the input of the block and the output of a set of convolution layers. The existence of skip connections weakens the importance of each individual path, so that the model behaves like an ensemble of small networks. Although ResNet immediately topped most of benchmarks, a few drawbacks still need to be addressed. First, the number of parameters becomes extremely large with hundreds layers of convolutions. Second, the network may not benefit from "going deep" due to the gradient vanishing problem, as indicated in Veit et al. <ref type="bibr" target="#b32">[33]</ref>.</p><p>2) DenseNet Block: A DenseNet block is then formulated as</p><formula xml:id="formula_5">x l+1 = H([x 0 , x 1 , . . . , x l ]) (5) H(x) = W * (σ (B(x)))<label>(6)</label></formula><p>where x 0 , x 1 , . . . , x l denote the input of each convolution layer in the block and the bracket "[•]" denotes the concatenation of all outputs of previous layers. A DenseNet block is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Thus, the output of a layer in one DenseNet block is densely connected with outputs of all deeper layers in the same block by means of concatenation. Thus, it fully exploits the advantage of skip connections. Moreover, features from shallow layers are reused by deep layers, which reduces the number of parameters, and the gradient vanishing problem is further alleviated by the concatenation layers.</p><p>The feature dimension d l+1 of x l+1 is calculated as</p><formula xml:id="formula_6">d l+1 = d 0 + k • l (7)</formula><p>where k (a.k.a the growth rate) is the number of filters used for each convolution layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Atrous Convolution</head><p>Atrous convolution convolves input nodes with a dilation rate d, denoting the stride for each convolved location on </p><formula xml:id="formula_7">y i = K k=1 x i+d•k • w k (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>where k is the dimension, x i is the input node, and w ∈ R K is the kernel. The regular convolution can be seen as a special case of atrous convolution with d = 1. Atrous convolution was first proposed in <ref type="bibr" target="#b33">[34]</ref> to address the low-resolution problem caused by downsampling layers (pooling, convolution with stride, and so on). Atrous convolution essentially involves distant information by covering larger regions of input signals while maintaining the same number of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPOSED METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Network Architecture</head><p>As shown in Table <ref type="table" target="#tab_0">I</ref>, our DeepDetect is inspired by DenseNet. All convolution kernels in our network are 1-D because of the input of 1-D time series data. "Conv7, 64, /2" denotes using 64 1 × 7 convolution kernels with stride 2. The same routine applies to max-pool and avg-pool. The brackets denote DenseNet blocks shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Specifically, we use "[conv3, 20] × 6" to denote a DenseNet block, where six convolution layers are applied, each followed by BN and ReLU activation layers. D i and T i denote DenseNet blocks and transition blocks, respectively. All transition blocks have an average pooling layer to downsample the signal by 2, while T 3 -T 9 have an extra 1 × 1 convolution layer to reduce the feature dimension by half. As previously discussed, our model is designed for capturing events with significantly different durations, so we use the output of each D 3 -D 9 , having strides 16, 32, 64, 128, 256, 512, and 1024 on the input signals, as proposals, and then, detection branches (the classification and regression layers) are built on the top of these multiscale proposals. Since small events greatly outnumber large events, we share the detection branches for all scales to make our model robust. To achieve this, We set growth rate k = 12 for D 1 , D 2 , k = 20 for D 3 -D 9 , so that all proposals have the same feature dimension 240.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Anchors</head><p>Anchor is the effective region of the input signals that a proposal is responsible for. In most cases, it is used to decide the label for that proposal. In our time series data, an anchor indicates two coordinates representing the beginning and the end of each proposal. We assign the anchor size 128 to proposals in D 3 , and it doubles for the next scale. Proposals in D 9 have the largest anchor size 8192. These settings are determined by the length distribution of events in our data. It is worthwhile to mention that the amount of shift between adjacent proposals is determined by the stride of that stage on the input signals. Specifically, the stride is 1/8 of the anchor size for each D3-D9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Proposals With Contextual Information</head><p>Features are critical to detection. In time series data, it is important to take into consideration of the temporal correlations among neighboring proposals. Only considering features from each individual proposal will result in many false detections.</p><p>Fig. <ref type="figure" target="#fig_1">2</ref>(a) shows a perfect individual event in the time series data. The signal amplitude remains at a constant level before a major event comes. As the event vanishes, the signal amplitude returns to the background. However, it is possible that the signal amplitude does not decrease monotonically or the major event may last longer than usual. Both cases will lead to the scenario when truncations from a major event are misdetected as several small events. Fig. <ref type="figure" target="#fig_1">2</ref>(b) shows an example of a false detection. The whole segment of signals in Fig. <ref type="figure" target="#fig_1">2</ref>(b) (denoted as "top") is a single event. However, if we only focus on a truncation of that, i.e., the "bottom" part as shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), we may mistakenly consider this truncation as an individual event. Therefore, in order to detect each event as a whole, it is necessary to check the preceding and succeeding patterns for each proposal.  Atrous convolution block. We aim at enriching the features of individual proposals by convolving with preceding and succeeding proposals. In this figure, the target proposal is at the center. Atrous convolutions with different strides are applied to capture contextual information from nearby to further proposals.</p><p>We build atrous convolution blocks on seven proposal layers, D 3 -D 9 . The atrous convolution block is shown in Fig. <ref type="figure" target="#fig_2">3</ref>. The dilation rate in atrous convolution indicates the number of skipped proposals at each convolved location. We set dilation rates to be 4, 8, and 12 for proposals in all scales. These dilation rates are inspired by the amount of shifts of adjacent proposals. Anchors of adjacent proposals shift only a little, and hence, the features of adjacent proposals tend to be similar. In contrast, atrous convolution is capable of incorporating contextual information. For the other extreme, the shifts of anchors should not be too large since the information from far away will be irrelevant to the target proposal. With dilation rates of 4, 8, and 12, the shifts between the target proposal and the contextual proposals are 0.5, 1, and 1.5 of the anchor size. The blocks in red, green, and blue shown in Fig. <ref type="figure" target="#fig_2">3</ref> are the outputs of atrous convolutions with 4, 8, and 12 as dilation rates, followed by BN and activation layers. All convolutions are 1 × 3, with 240 kernels. We generate new proposals with contextual information by concatenating outputs using three dilation rates and the target proposal. The new proposal includes four times as many features as the target proposal. In order to keep the number of features unchanged, we further employ a 1×1 convolution layer. To summarize, we employed atrous convolution with three dilation rates on proposals layers so that the features of each individual proposal are enriched by preceding and succeeding proposals while maintaining its own features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Sibling Branches for Detection and Localization</head><p>We add a classification branch and a regression branch on each proposal. The classification branch is first used to detect whether a proposal includes an event or not. For each positive proposal, we further apply a regressor to localize the event within. We use a joint loss function to optimize the classification and regression branches simultaneously.</p><p>We assign a positive label to a proposal if its anchor has the ratio of IoU above 0.5 with at least one ground-truth event. Proposals are assigned a negative label if the highest IoU of their anchors with the ground truth is below 0.3. Neutral proposals (IoU ∈ [0.3, 0.5]) do not contribute to the loss. To localize the event within a proposal, two offsets, d x and d w , are captured to transform the anchor to real coordinates by</p><formula xml:id="formula_9">G x = P w d x + P x (9)</formula><p>G w = P w exp(d w ) <ref type="bibr" target="#b9">( 10)</ref> where P x and P w are the center and length of an anchor and G x and G w are the center and length of the prediction. Fig. <ref type="figure" target="#fig_3">4</ref> gives an illustration of this process, where three nodes are positive so they also have a localization loss. Another challenge in our time series data is that not all events in the training set are annotated, which is caused by the fact that some patterns are difficult for our annotators to determine. Due to this problem, negative labels are noisy in our task. To address this issue, we employ label-dependent loss function for the classifier.</p><p>The label-dependent loss function was initially proposed in a couple of works <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, known as weighted logistic regression and biased support vector machine, respectively. The core idea of "label-dependent" is to apply separate loss functions for positive and negative sets</p><formula xml:id="formula_10">J (g(x)) = 1 |X| ⎛ ⎝ α x∈X + l(g(x)) + β x∈X - l(g(x)) ⎞ ⎠<label>(11)</label></formula><p>where l can be any 0-1 loss functions, X + and X -denote the observed positive and negative sets, α and β are two hyperparameters, and g is a linear score function.</p><p>To obtain the optimal weight parameters α * and β * , Natarajan et al. <ref type="bibr" target="#b17">[18]</ref> give</p><formula xml:id="formula_11">ρ +1 = P( Ỹ = -1|Y = 1) (12) ρ -1 = P( Ỹ = 1|Y = -1)<label>(13)</label></formula><formula xml:id="formula_12">α * = 1 -ρ +1 + ρ -1 2 (<label>14</label></formula><formula xml:id="formula_13">)</formula><formula xml:id="formula_14">β * = 1 -α *<label>(15)</label></formula><p>where Ỹ denotes the observed label, Y denotes the true label, and the conditional probability P denotes the probability of a sample being wrongly labeled. It can be shown that by employing the optimal parameters of α * and β * , the resulting classifier can make predictions of sign(g(x) -1/2) with noisy data <ref type="bibr" target="#b17">[18]</ref>. We use the similar parameter estimation approach to our data sets by setting ρ +1 = 0, since the noise only exists in negative samples. x , and d (i)  w are the predictions of the i th proposal's class score, center, and length offsets, respectively, t</p><formula xml:id="formula_15">(i) cls , t (i)</formula><p>x , and t (i)   w are the corresponding ground truth of the i th proposal's class score, center, and length offsets, respectively, and λ controls the balance between L cls and L regr .</p><p>The classification loss function L cls is defined as a labeldependent logistic loss</p><formula xml:id="formula_16">L cls (d cls , t cls ) = α1{t cls = 1} log(1 + e -d cls ) +(1 -α)1{t cls = -1} log(1 + e d cls ) (<label>17</label></formula><formula xml:id="formula_17">)</formula><p>where α is the hyperparameter. The regression loss function L regr is defined as the smoothed L 1 loss as proposed in <ref type="bibr" target="#b12">[13]</ref> </p><formula xml:id="formula_18">L regr (d u , t u ) = smooth L 1 (t u -d u ) (<label>18</label></formula><formula xml:id="formula_19">)</formula><p>where d u and t u denote the predicted and target values, and</p><formula xml:id="formula_20">smooth L 1 (x) = 0.5x 2 , if|x| &lt; 1 |x| -0.5, otherwise.</formula><p>According to ( <ref type="formula">9</ref>) and (9), t x and t w can be obtained by</p><formula xml:id="formula_21">t x = (G *</formula><p>x -P x )/P w <ref type="bibr" target="#b18">(19)</ref> t w = ln(G * w /P w ) <ref type="bibr" target="#b19">( 20)</ref> where G * x and G * w are the ground truth of the center and length of the event. 2) Share Weights for Robustness: To capture events with dramatically varying durations, we make multiscale predictions on output layers with different sizes of receptive fields. However, events with different lengths are not equally distributed. In other words, small events greatly outnumber large events. Our model should capture patterns from all events regardless of their durations or amplitudes; hence, we share the weights of contextual atrous convolution layers and sibling classification and regression branches that built on top of D 3 -D 9 . Weight sharing makes our model robust and helps with the optimization because predictions in all scales equally contribute to the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. IMPLEMENTATION DETAILS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Template Matching</head><p>We use events in the training set as templates. For each template, CC is calculated at each sliding location of the time series data. We set the detection threshold μ = 8 in (2), which is determined by the validation set. For multidetections of a single event, the detection with the highest CC is kept, and all other detections are discarded. The beginning and the end of each detection are determined by those of the template.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proposed Model 1) Optimization:</head><p>The proposed model has approximately 3 million parameters. For each mini-batch iteration, we feed a 24 576-timestamp (6 ms) time series segment with 0.5 overlapping rate so that if the endpoint of an event lies outside of the segment, event will be roughly at the center of the next segment. In our data set, large events are rare comparing to small events. To account for this characteristic, we generate fewer proposals from large events than those from small events for training. In particular, Table <ref type="table" target="#tab_2">II</ref> shows how we select the number of proposals from each detection branch.</p><p>To further simplify the optimization, we also make sure that the ratio of positive and negative proposals is 1:1. If positive or negative proposals are insufficient, we use neutral ones as negative proposals. Adam optimizer <ref type="bibr" target="#b36">[37]</ref> is applied with the initial learning rate of 5e-4. The learning rate is multiplied by 0.1 for every 10 epochs. Each of the mini-batch data is subtracted by the mean and divided by the standard deviation before feeding into the network. Our model is implemented with TensorFlow <ref type="bibr" target="#b37">[38]</ref>.</p><p>2) Inference: Similar to the training process, we feed 24 576 timestamp segments with the overlapping rate of 0.5 each time window. Predictions are first generated on all proposals; then, we apply nonmaximum suppression (NMS) to reduce multidetections for a single event. Since events in the time series data are rarely overlapped, we set the IoU threshold of NMS to be 0.05. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data</head><p>The data used for our machine learning model come from a frictional experiment in the Pennsylvania State University Rock and Sediment Mechanics Laboratory. The experiment was conducted using the double-direct shear configuration where two laboratory fault zones are sandwiched between two forcing blocks and sheared simultaneously.</p><p>Acoustical data are recorded from two broadband (0.02-2 MHz) piezoelectric transducers with a central frequency of 500 kHz. The transducers are embedded within a 10×10 (cm 2 ) steel block and placed adjacent to the fault zone <ref type="bibr" target="#b40">[41]</ref>. Acoustical data are sampled continuously at 4 MHz with a 14-bit Verasonics data acquisition system.</p><p>We hand-picked 1000 acoustic emissions (AEs) from the raw time series data between 2368.9-2369.7 s. During this section of the experiment, the normal stress is at 3 MPa. Furthermore, this time corresponds to the first two seconds of the stick-slip cycle. For a single AE, we picked the beginning and end of the event based on the amplitude of the signal, the duration of the signal, and the characteristic shape of the signal. We use 800 events for training, 100 events for validating, and 100 events for testing.</p><p>The length distribution of all events is shown in Fig. <ref type="figure" target="#fig_4">5</ref>. The largest event spans more than 7 000 timestamps (1.7 ms), while the smallest event spans few hundreds. The mean and median lengths of events are both about 1 500 timestamps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Metric</head><p>We use AP to evaluate our models. AP first calculates the precision-recall curve and then averages maximum precisions for each unique recall. For AP@.5, a detection is considered as true positive if it has IoU above 0.5 with a ground-truth event. If there are multiple detections for one event, only one detection is considered true positive, and others are considered false positive. In this paper, we use AP@[.5, .95], which is used in MS COCO object detection data set <ref type="bibr" target="#b41">[42]</ref>. To obtain AP@[.5, .95], we calculate 10 APs using IoUs from 0.5 to 0.95 with stride 0.05 and then take the average of 10 APs. The IoU for two 1-D segments A 0 A 1 , B 0 B 1 is calculated as</p><formula xml:id="formula_22">x a = max(A 0 , B 0 ) y a = min(A 1 , B 1 ) x b = min(A 0 , B 0 ) y b = max(A 1 , B 1 )</formula><formula xml:id="formula_23">IoU(A 0 A 1 , B 0 B 1 ) = max(y a -x a , 0) y b -x b .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Test: Overall Performance</head><p>We provide the detection results in Table <ref type="table" target="#tab_3">III</ref> obtained using the TM (baseline) and our deep-learning-based CC-RCNN. Table <ref type="table" target="#tab_3">III</ref> shows that our CC-RCNN model consistently yields better detection accuracy than the TM method. The average AP value of our method is 63.8% compared with the value of 5.5% obtained by the TM method.</p><p>To visualize the detection results using our method and the TM method, we provide the example detections of these two models in Fig. <ref type="figure" target="#fig_5">6</ref>. The results obtained using our method are denoted by " ," and those obtained by TM are denoted in "•." The ground truth ("×") is also provided. Although TM has the ability to detect some events, it has poor localization performance. For instance, TM only captures the second half of event #6 in Fig. <ref type="figure" target="#fig_5">6(a)</ref>. Also, TM cannot capture event #7 as a whole since each template works separately. The reason for the poor localization is that the lengths of TM detections are simply determined by those of templates, and most events have lengths that no templates can match. On the other hand, the proposed CNN-based method is capable of accurately detecting, as well as localizing multiscale events due to the cascaded design. Capturing events shown in Fig. <ref type="figure" target="#fig_5">6(b</ref>) is more challenging than those in Fig. <ref type="figure" target="#fig_5">6</ref>(a), since some of events in Fig. <ref type="figure" target="#fig_5">6</ref>(b) vary dramatically in length (such as #57 and #58) and yield irregular patterns (such as #60). TM detects #57-#60 as a whole event, while CC-RCNN is able to detect and localize each individual event accurately. ) is more challenging than those in (a) since some of events in (b) vary dramatically in lengths (such as #57 and #58) and yield irregular patterns (such as #60). We compare the results obtained using our method (denoted by " ") to those obtained by using TM ("•"). The ground truth ("×") is also provided. Our detection methods yield much higher accuracy than the TM method. Based on the results shown in Table <ref type="table" target="#tab_3">III</ref> and Fig. <ref type="figure" target="#fig_5">6</ref>, our detection methods yield much higher accuracy than the TM method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Test: Hyperparameters</head><p>Hyperparameters play an important role in our model to achieve high performance. Specifically, the selection of λ value in <ref type="bibr" target="#b15">(16)</ref> and α value in <ref type="bibr" target="#b14">(15)</ref> is critical to the detection accuracy using our label-dependent loss function.</p><p>We provide results in Table <ref type="table" target="#tab_4">IV</ref> to illustrate the performance of our algorithm using different λ values in <ref type="bibr" target="#b15">(16)</ref>. Similar to Ren et al. <ref type="bibr" target="#b11">[12]</ref>, different values of λ ∈ {0.1, 1, 10, 100} are tested. We observe that the performance of our model is impacted notably by using different λ values. The best performance is achieved with λ = 10, which is therefore used for all the tests implemented within this paper.</p><p>To demonstrate the effectiveness of different values of α, we further provide detection results using our label-dependent loss function in <ref type="bibr" target="#b16">(17)</ref>. The performance on different noise parameters, α ∈ {0.45, 0.5, 0.55, 0.6, 0.7}, is reported in Table <ref type="table" target="#tab_5">V</ref>. The best average performance of our CC-RCNN model is achieved when α = 0.55 with the corresponding noise level of 0.1. This is reasonable since the noise only exists in the negative samples, and the noise level is low. The accuracy decreases when either the noise level becomes larger (α = 0.55, 0.6, and 0.7) or assuming that the noise exists in the positive samples (α = 0.45).</p><p>Through these sets of tests on hyperparameter, we obtain the best combination to use for our data set, i.e., λ = 10 and α = 0.55.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Test: Robustness With Respect to Training Data Size</head><p>Although the CNN-based models have superb performance in many applications, they may require a large amount of training data to achieve low generalization errors. Insufficient training data may lead to overfitting since the number of parameters in CNN is remarkably larger than that of other models.    test are shown in Fig. <ref type="figure">7</ref>. We observe that the accuracy benefits from the larger training set in most cases. However, even if we use 450 events out of 1000 to train our model, we still obtain a good accuracy-AP 44.9%. These results suggest that our DeepDetect yields good accuracy without an enormous amount of training data. It has a notable regularization effect achieved by the reuse of features, and they take full advantage of skip connections to make the model robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Test: Ablation Study</head><p>We conduct ablation experiments to verify the effect of the atrous convolution blocks and the multiscale architecture. All ablation experiments are conducted with α = 0.5 and λ = 10. Actually, the classifier gives positive predictions for proposals of event #93. However, the detection of #93 is suppressed by that of event #94 because the predicted beginning of event #94 is inaccurate, which makes the IoU of these two detections above the suppression threshold. Thus, the incorporation of contextual information for individual proposals not only reduces false detections but also increases the localization accuracy.</p><p>2) Multiscale Architecture: To demonstrate the effect of the proposed multiscale architecture, which is designed for capturing various lengths of events, we compare the performance of using D 3 -D 9 (proposed), D 4 -D 8 , D 5 -D 7 , and D 6 to make predictions. The results are shown in Table <ref type="table" target="#tab_7">VII</ref>. The single-scale model (using D 6 only) achieves AP 47.3% and is outperformed by the proposed multiscale model by 14.2 points. Fig. <ref type="figure" target="#fig_7">9</ref> shows the detection results of two segments. Events #69 and #70 in Fig. <ref type="figure" target="#fig_7">9</ref>(a) span about 4 000 timestamps. event #73 in Fig. <ref type="figure" target="#fig_7">9</ref>(b) spans about 3 000 timestamps. They are all poorly captured by the single-scale model since their lengths are outside the range that the anchor covers. Though, it is worthwhile to mention that the performance of the single-scale model is still significantly better than the baseline-TM model. Since we assign positive labels to those anchors having IoU greater than 0.5 with at least one groundtruth event, D 6 is theoretically capable of capturing events with 512-2 048 timestamps. The majority of events in our data set can be captured with this range.</p><p>To further demonstrate the effectiveness of each branch, we plot their probability distributions in Fig.   be captured by multiple detection branches simultaneously. However, our model is capable of suppressing redundant detections because the highest probability is always given by the detection branch with the anchor size closest to that event. More concretely, D 5 gives the highest probability for event #5 since its anchor size is 512. D 7 , with anchor size 2 048, gives the most confident prediction for event #7. For event #6, D 7 and D 8 give similar predictions since the event length is at the middle of the two anchor sizes. To sum up, Fig. <ref type="figure" target="#fig_8">10</ref> verifies that our multiscale architecture can effectively capture the events with dramatically various lengths. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING Fig. <ref type="figure" target="#fig_1">12</ref>. Detection results of three randomly selected segments, (a)-(c). Our algorithm yields promising detections for most of the events, although there are some false-positive events obtained [e.g., one at timestamp of 160 000 of (a)].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Test: Curated and Randomly Selected Detections</head><p>To further illustrate the performance of our CC-RCNN model, we present example detections of five long segments in Figs. <ref type="figure" target="#fig_9">11</ref> and<ref type="figure" target="#fig_1">12</ref>. All detections are plotted on the top of the ground truth. Fig. <ref type="figure" target="#fig_9">11</ref> shows the detection results of two curated time series segments, which are selected because of the impressive detection results. The detections of three randomly selected segments are presented in Fig. <ref type="figure" target="#fig_1">12</ref>. Although they are not curated examples, we found the detection results still promising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>Accurate event detection from the 1-D time series seismic data is not only important but also challenging. In this paper, we develop a novel eventwise detection method, DeepDetect, for 1-D time series signals. Specifically, a cascaded architecture is developed to generate multiscale proposals to detect events with various lengths. To take into account the temporal correlation of the time series data, we use atrous convolutions with different dilation rates to enrich the features of individual proposals. To help with the optimization, we share parameters for branches built on the top of the multiscale proposals. For event detection tasks in 1-D time series signals, our DeepDetect method is state of the art. In our experimental tests, we compare our new CC-RCNN model with a standard method (TM). Our detection accuracy is significantly higher than that obtained using TM, especially when the sizes of events are greatly different from one another. We also demonstrate the robustness of our new model to different sizes of the training data set. To conclude, our new detection model, DeepDetect, yields high performance for the laboratory seismic data set, and therefore, it has great potential for event detection in various seismic applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Densely connected block. Solid lines denote the composite function H and dashed lines denote concatenation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Perfect individual event in time series data (top). Zoomed-in truncation of (a) top (bottom). (b) Segment of time series signals, and the whole segment is labeled as an event (top). Truncation of (b) top (bottom). The green and red boxes indicate the beginning and end of an event, respectively.</figDesc><graphic coords="5,48.47,328.13,251.06,101.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3.Atrous convolution block. We aim at enriching the features of individual proposals by convolving with preceding and succeeding proposals. In this figure, the target proposal is at the center. Atrous convolutions with different strides are applied to capture contextual information from nearby to further proposals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Illustration of multiscale detections. Three proposals (green nodes) are considered positive since they have the IoU with the ground truth above the threshold. Ground truth is indicated at the bottom with green and red dots, which denote beginnings and ends, respectively.</figDesc><graphic coords="5,323.99,58.13,226.94,138.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Length distribution of all events.</figDesc><graphic coords="7,73.67,57.77,201.62,157.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) and (b) Two different examples. Capturing events shown in (b) is more challenging than those in (a) since some of events in (b) vary dramatically in lengths (such as #57 and #58) and yield irregular patterns (such as #60). We compare the results obtained using our method (denoted by " ") to those obtained by using TM ("•"). The ground truth ("×") is also provided. Our detection methods yield much higher accuracy than the TM method.</figDesc><graphic coords="8,323.99,302.45,226.94,168.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Comparison of the performance of C-RCNN with CC-RCNN. (a) and (b) Detections from two segments. Green and red markers denote beginnings and ends, respectively. Our CC-RCNN model outperforms the C-RCNN for both the examples.</figDesc><graphic coords="9,312.47,360.17,250.10,138.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Comparison of detections of a single-scale model using D 6 with our CC-RCNN model using multiscale branches. Green and red markers denote beginnings and ends, respectively. The ground-truth is indicated at the bottom. We show the detection results of two segments, (a) and (b). Both segments show that the single-scale detector cannot capture events with lengths far away from the anchor size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Probability distributions from all detection branches. (a) Input signals and the ground truth. (b)-(h) Probabilities of being an event for each location of the input signal, output by D 3 -D 9 . Signals are denoted in blue light. Probabilities are denoted as solid lines of varying colors and the red dotted lines indicate the detection threshold of 0.5. 1) Contextual Versus Noncontextual: To demonstrate the importance of using atrous convolutions to incorporate contextual information, we build a noncontextual model (C-RCNN) by directly adding detection branches on top of D 3 -D 9 . The improvement of performance is indicated by AP@[.50, .95] in Table VI, where the contextual model outperforms the noncontextual counterpart by 13.9 points. More concrete examples are shown in Fig. 8. event #41 in Fig. 8(a) is the case discussed in Section IV-C. C-RCNN detects event #41 as two individual events due to the second peak in the pattern. In contrast, our contextual model, CC-RCNN, is able of capturing the whole event. Moreover, event #93 in Fig. 8(a) is missed by C-RCNN.Actually, the classifier gives positive predictions for proposals of event #93. However, the detection of #93 is suppressed by that of event #94 because the predicted beginning of event #94 is inaccurate, which makes the IoU of these two detections above the suppression threshold. Thus, the</figDesc><graphic coords="10,106.67,358.49,170.30,127.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Curated examples. The two segments, (a) and (b), are selected because we found the detection results are impressive.</figDesc><graphic coords="11,74.03,279.65,463.82,199.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>10</head><label>10</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>. The signals have been scaled to [0, 1]. A testing segment is shown in Fig. 10(a), with eight events to be captured. The length of each event is shown in Table VIII. Fig. 10(b)-(h) shows the probabilities of being an event output by the classification branch built on D 3 -D 9 . It can be seen that none of the events are captured by D 3 since its anchor size is only 128, and all events are beyond the scope that D 3 is theoretically responsible for. event #5, the smallest one in this segment spanning 502 timestamps, is captured by {D 4 , D 5 , D 6 }. The largest event, #6, spanning 3 058 timestamps, is captured by {D 6 , D 7 , D 8 , D 9 }. These results indicate that an event can</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,93.95,58.13,424.10,182.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,93.95,255.89,423.98,182.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,93.95,453.65,423.98,182.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I CASCADED</head><label>I</label><figDesc>NETWORK ARCHITECTURE OF DEEPDETECT FOR EVENT DETECTION. L DENOTES THE LENGTH OF THE INPUT WAVEFORM. "-" MEANS THAT THE OUTPUT OF THAT STAGE IS NOT USED TO MAKE PREDICTIONS</figDesc><table /><note><p>input nodes. The output node y i of an atrous convolution layer is calculated as</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>We develop a joint loss function L including a classification loss function L cls and a regression loss function L regr L(d cls , d x , d w , t cls , t x , t w ) = L cls (d cls , t cls ) +λ1{t cls = 1}</figDesc><table><row><cell>L regr (d u , t u ) (16)</cell></row><row><cell>u∈{x,w}</cell></row><row><cell>where 1{t cls = 1} is the indicator function indicating only positive proposals that contribute to the regression loss, d (i) cls , d (i)</cell></row></table><note><p>1) Loss Function:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II NUMBER</head><label>II</label><figDesc>OF PROPOSALS SELECTED FROM EACH SCALE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III ACCURACY</head><label>III</label><figDesc>RESULTS OBTAINED USING TM AND OUR CC-RCNN MODEL. WE NOTICE THAT OUR CC-RCNN MODEL CONSISTENTLY YIELDS BETTER DETECTION ACCURACY THAN THE TM METHOD</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV ACCURACY</head><label>IV</label><figDesc>WITH RESPECT TO DIFFERENT VALUES OF λ</figDesc><table /><note><p>IN EQ. (16). WE TEST λ ∈ {0.1, 1, 10, 100}. THE ACCURACY PEAKS WHEN λ = 10</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V ACCURACY</head><label>V</label><figDesc>WITH RESPECT TO DIFFERENT VALUES OF α IN (17). WE TEST α ∈ {0.45, 0.5, 0.55, 0.6, 0.7}. THE ACCURACY PEAKS AT α = 0.55, WHICH HAS THE CORRESPONDING NOISE LEVEL OF 0.1. THEN, THE ACCURACY DECREASES AS α BECOMES LARGER. THE BEST AVERAGE PERFORMANCE OF OUR CC-RCNN MODEL IS ACHIEVED WHEN α = 0.55 Fig. 7. APs achieved by using different training data sizes. The AP peaks when using 800 samples for training. Even with 450 samples, which is less than a half, our model still has a good performance.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI EFFECT</head><label>VI</label><figDesc>OF ATROUS CONVOLUTIONS FOR INCORPORATING CONTEXTUAL INFORMATIONMoreover, it is demanding for human annotators to amplify the training data. Thus, we conduct another sets of experiments to test the robustness of our model with respect to different sizes of the training data.We trained our CC-RCNN model on eight sizes of training data. We split {0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8} of total samples as the training set, and the validation and testing sets evenly split the rest of the samples. The results of robustness</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII PERFORMANCE</head><label>VII</label><figDesc>OF USING DIFFERENT DETECTION BRANCHES. THE SINGLE-SCALE MODEL HAS THE LOWEST ACCURACY. THE ACCURACY GROWS AS MORE EVENTS ARE COVERED BY MULTISCALE ANCHORS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VIII LENGTH</head><label>VIII</label><figDesc>(IN TIMESTAMP) OF EACH EVENT IN FIG. 10(a)</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Center for Space and Earth Science (CSES) at Los Alamos National Laboratory (LANL), in part by the U.S. DOE Office of Fossil Energy through the Carbon Storage Program, and in part by the Institutional Support (LDRD) at Los Alamos.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Yue Wu received the B.S. degree in software engineering from Sichuan University, Sichuan, China, in 2016, and the M.S. degree in computer science from the University of Rochester, Rochester, NY, USA, in 2018.</p><p>He was a Research Assistant with the Geophysics Group, Los Alamos National Laboratory, Los Alamos, NM, USA, from 2017 to 2018. His research interests include rigorous machine learning algorithms and their applications.</p><p>Youzuo Lin received the B.S. degree in information and computational science from the Changchun University of Science and Technology, Changchun, China, and the Ph.D. degree in computational and applied mathematics from Arizona State University, Tempe, AZ, USA.</p><p>He is currently a Staff Scientist at the Los Alamos National Laboratory, Los Alamos, NM, USA. He is a co-inventor on a couple of U.S. patents about ultrasound imaging techniques. He has published over 50 papers in top journals and conferences, including Numerical Linear Algebra with Applications, Applied Energy, Water Resources Research, Geophysical Journal International, Signal Processing, Pure and Applied Geophysics, IEEE International Conference on Image Processing, IEEE International Conference on Data Mining, and Society of Exploration Geophysicists Annual Meeting. His research interests include optimization and numerical methods for ill-posed inverse problems, machine learning, and data-driven methods for physics problems. Specifically, he has involved in the applications, including events detection from time series, seismic inversion/imaging, unmanned aerial vehicle imagery analysis, hydrology inverse modeling, and ultrasound tomography.</p><p>Dr. Lin has also been a reviewer for over 20 scientific journals and proceedings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zheng</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A low complexity algorithm for earthquake detection system</title>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Sheu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCP</title>
		<meeting>ICCP</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Earthquake detection through computationally efficient similarity search</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Adv</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">e1501057</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Event detection in marine time series data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Oehmcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint German/Austrian Conf</title>
		<meeting>Joint German/Austrian Conf</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-sensor event detection using shape histograms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd IKDD Conf. Data Sci</title>
		<meeting>2nd IKDD Conf. Data Sci</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="20" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mining recent temporal patterns for event detection in multivariate time series data</title>
		<author>
			<persName><forename type="first">I</forename><surname>Batal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fradkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Moerchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hauskrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="280" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised realtime anomaly detection for streaming data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Purdy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Agha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">262</biblScope>
			<biblScope unit="page" from="134" to="147" />
			<date type="published" when="2017-11">Nov. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised event characterization and detection in multichannel signals: An EEG application</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dormido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dormido-Canto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">590</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1409.1556" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1706.05587" />
		<imprint>
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large kernel matters-Improve semantic segmentation by global convolutional network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1743" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName><forename type="first">N</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Ravikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1196" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic phase pickers: Their present use and future prospects</title>
		<author>
			<persName><forename type="first">R</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Seismol. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<date type="published" when="1982-12">Dec. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparison of select trigger algorithms for automated global seismic phase and event detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Withers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Seismol. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="106" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An autocorrelation method to detect low frequency earthquakes within tremor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophys. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">L16305</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The detection of low magnitude seismic events using array-based waveform correlation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophys. J. Int</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="149" to="166" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Non-volcanic tremor and low-frequency earthquake swarms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">446</biblScope>
			<biblScope unit="page" from="305" to="307" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Low signal-to-noise event detection based on waveform stacking and cross-correlation: Application to a stimulation experiment</title>
		<author>
			<persName><forename type="first">K</forename><surname>Plenkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R R</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Seismol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="49" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An improved method for hydrofracture-induced microseismic event detection and phase picking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Kuleli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Toksöz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysics</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="47" to="A52" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Perspectives of cross-correlation in seismic monitoring at the international data centre</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bobrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kitov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zerbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pure Appl. Geophys</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="439" to="468" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Event detection from water quality time series</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mckenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Klise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. World Environ</title>
		<meeting>World Environ</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A unified multi-scale deep convolutional neural network for fast object detection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="354" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rapid earthquake detection through GPU-based template matching</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Geosci</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="305" to="314" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Migration of early aftershocks following the 2004 parkfield earthquake</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Geosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="877" to="881" />
			<date type="published" when="2009-11">Nov. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Residual networks behave like ensembles of relatively shallow networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1605.06431" />
		<imprint>
			<date type="published" when="2016-10">Oct. 2016</date>
		</imprint>
	</monogr>
	<note>Online]. Available</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs</title>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1606.00915" />
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning with positive and unlabeled examples using weighted logistic regression</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICDM</title>
		<meeting>ICDM</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Building text classifiers using positive and unlabeled examples</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1603.04467" />
		<imprint>
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Laboratory observations of slow earthquakes and the spectrum of tectonic fault slip modes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Leeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Saffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Scuderi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Commun</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
	<note>Art. no. 11104</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The effect of shear load on frictional healing in simulated fault gouge</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Karner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophys. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="4561" to="4564" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evolution of bvalue during the seismic cycle: Insights from laboratory experiments on simulated faults</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rivière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Earth Planet. Sci. Lett</title>
		<imprint>
			<biblScope unit="volume">482</biblScope>
			<biblScope unit="page" from="407" to="413" />
			<date type="published" when="2018-01">Jan. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1405.0312" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
