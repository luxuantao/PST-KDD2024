<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
							<email>zhangdinghuai@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Tianyuan</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yiping</forename><surname>Lu</surname></persName>
							<email>yplu@stanford.edu</email>
						</author>
						<author>
							<persName><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
							<email>zhanxing.zhu@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Bin</forename><surname>Dong</surname></persName>
							<email>dongbin@math.pku.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">School of Mathematical Sciences</orgName>
								<orgName type="department" key="dep2">Peking University Center for Data Science</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Beijing Institute of Big Data Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Beijing International Center for Mathematical Research</orgName>
								<orgName type="department" key="dep2">Peking University Center for Data Science</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Beijing Institute of Big Data Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">32EAC8F1B8801E546D24FC350483C00F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning achieves state-of-the-art results in many tasks in computer vision and natural language processing. However, recent works have shown that deep networks can be vulnerable to adversarial perturbations, which raised a serious robustness issue of deep networks. Adversarial training, typically formulated as a robust optimization problem, is an effective way of improving the robustness of deep networks. A major drawback of existing adversarial training algorithms is the computational overhead of the generation of adversarial examples, typically far greater than that of the network training. This leads to the unbearable overall computational cost of adversarial training. In this paper, we show that adversarial training can be cast as a discrete time differential game. Through analyzing the Pontryagin's Maximum Principle (PMP) of the problem, we observe that the adversary update is only coupled with the parameters of the first layer of the network. This inspires us to restrict most of the forward and back propagation within the first layer of the network during adversary updates. This effectively reduces the total number of full forward and backward propagation to only one for each group of adversary updates. Therefore, we refer to this algorithm YOPO (You Only Propagate Once). Numerical experiments demonstrate that YOPO can achieve comparable defense accuracy with approximately 1/5 ∼ 1/4 GPU time of the projected gradient descent (PGD) algorithm [15]. 3 * Equal Contribution † Corresponding Authors 3 Our codes are available at https://github.com/a1600012888/YOPO-You-Only-Propagate-Once 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks achieve state-of-the-art performance on many tasks <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b41">42]</ref>. However, recent works show that deep networks are often sensitive to adversarial perturbations <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47]</ref>, i.e., changing the input in a way imperceptible to humans while causing the neural network to output an incorrect prediction. This poses significant concerns when applying deep neural networks to safety-critical problems such as autonomous driving and medical domains. To effectively defend the adversarial attacks, <ref type="bibr" target="#b23">[24]</ref> proposed adversarial training, which can be formulated as a robust optimization <ref type="bibr" target="#b35">[36]</ref>:</p><formula xml:id="formula_0">min θ E (x,y)∼D max η ≤ (θ; x + η, y),<label>(1)</label></formula><p>where θ is the network parameter, η is the adversarial perturbation, and (x, y) is a pair of data and label drawn from a certain distribution D. The magnitude of the adversarial perturbation η is restricted by &gt; 0. For a given pair (x, y), we refer to the value of the inner maximization of (1), i.e. max η ≤ (θ; x + η, y), as the adversarial loss which depends on (x, y).</p><p>A major issue of the current adversarial training methods is their significantly high computational cost.</p><p>In adversarial training, we need to solve the inner loop, which is to obtain the "optimal" adversarial attack to the input in every iteration. Such "optimal" adversary is usually obtained using multi-step gradient decent, and thus the total time for learning a model using standard adversarial training method is much more than that using the standard training. Considering applying 40 inner iterations of projected gradient descent (PGD <ref type="bibr" target="#b14">[15]</ref>) to obtain the adversarial examples, the computation cost of solving the problem (1) is about 40 times that of a regular training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adversary updater</head><p>Adversary updater</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Black box</head><p>Previous Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YOPO</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heavy gradient calculation</head><p>Figure <ref type="figure">1</ref>: Our proposed YOPO expolits the structure of neural network. To alleviate the heavy computation cost, YOPO focuses the calculation of the adversary at the first layer.</p><p>The main objective of this paper is to reduce the computational burden of adversarial training by limiting the number of forward and backward propagation without hurting the performance of the trained network. In this paper, we exploit the structures that the min-max objectives is encountered with deep neural networks. . Furthermore, we apply our algorithm to a recent proposed min max optimization objective "TRADES" <ref type="bibr" target="#b43">[44]</ref> and achieve better clean and robust accuracy within half of the time TRADES need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Works</head><p>Adversarial Defense. To improve the robustness of neural networks to adversarial examples, many defense strategies and models have been proposed, such as adversarial training <ref type="bibr" target="#b23">[24]</ref>, orthogonal regularization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>, Bayesian method <ref type="bibr" target="#b42">[43]</ref>, TRADES <ref type="bibr" target="#b43">[44]</ref>, rejecting adversarial examples <ref type="bibr" target="#b40">[41]</ref>,</p><p>Jacobian regularization <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>, generative model based defense <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b30">31]</ref>, pixel defense <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b22">23]</ref>, ordinary differential equation (ODE) viewpoint <ref type="bibr" target="#b44">[45]</ref>, ensemble via an intriguing stochastic differential equation perspective <ref type="bibr" target="#b36">[37]</ref>, and feature denoising <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b31">32]</ref>, etc. Among all these approaches, adversarial training and its variants tend to be most effective since it largely avoids the the obfuscated gradient problem <ref type="bibr" target="#b1">[2]</ref>. Therefore, in this paper, we choose adversarial training to achieve model robustness.</p><p>Neural ODEs. Recent works have built up the relationship between ordinary differential equations and neural networks <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b29">30]</ref>. Observing that each residual block of ResNet can be written as u n+1 = u n + ∆tf (u n ), one step of forward Euler method approximating the ODE u t = f (u). Thus <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b38">39]</ref> proposed an optimal control framework for deep learning and <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> utilize the adjoint equation and the maximal principle to train a neural network.</p><p>Decouple Training. Training neural networks requires forward and backward propagation in a sequential manner. Different ways have been proposed to decouple the sequential process by parallelization. This includes ADMM <ref type="bibr" target="#b33">[34]</ref>, synthetic gradients <ref type="bibr" target="#b12">[13]</ref>, delayed gradient <ref type="bibr" target="#b10">[11]</ref>, lifted machines <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b8">9]</ref>. Our work can also be understood as a decoupling method based on a splitting technique. However, we do not attempt to decouple the gradient w.r.t. network parameters but the adversary update instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contribution</head><p>• To the best of our knowledge, it is the first attempt to design NN-specific algorithm for adversarial defense. To achieve this, we recast the adversarial training problem as a discrete time differential game. From optimal control theory, we derive the an optimality condition, i.e. the Pontryagin's Maximum Principle, for the differential game. • Through PMP, we observe that the adversarial perturbation is only coupled with the first layer of neural networks. The PMP motivates a new adversarial training algorithm, YOPO. We split the adversary computation and weight updating and the adversary computation is focused on the first layer. Relations between YOPO and original PGD are discussed. • We finally achieve about 4∼ 5 times speed up than the original PGD training with comparable results on MNIST/CIFAR10. Combining YOPO with TRADES <ref type="bibr" target="#b43">[44]</ref>, we achieve both higher clean and robust accuracy within less than half of the time TRADES need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Organization</head><p>This paper is organized as follows. In Section 2, we formulate the robust optimization for neural network adversarial training as a differential game and propose the gradient based YOPO. In Section 3, we derive the PMP of the differential game, study the relationship between the PMP and the backpropagation based gradient descent methods, and propose a general version of YOPO. Finally, all the experimental details and results are given in Section 4.</p><p>2 Differential Game Formulation and Gradient Based YOPO</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Optimal Control Perspective and Differential Game</head><p>Inspired by the link between deep learning and optimal control <ref type="bibr" target="#b19">[20]</ref>, we formulate the robust optimization (1) as a differential game <ref type="bibr" target="#b6">[7]</ref>. A two-player, zero-sum differential game is a game where each player controls a dynamics, and one tries to maximize, the other to minimize, a payoff functional.</p><p>In the context of adversarial training, one player is the neural network, which controls the weights of the network to fit the label, while the other is the adversary that is dedicated to producing a false prediction by modifying the input.</p><p>The robust optimization problem (1) can be written as a differential game as follows,</p><formula xml:id="formula_1">min θ max ηi ∞≤ J(θ, η) := 1 N N i=1 i (x i,T ) + 1 N N i=1 T -1 t=0 R t (x i,t ; θ t ) subject to x i,1 = f 0 (x i,0 + η i , θ 0 ), i = 1, 2, • • • , N x i,t+1 = f t (x i,t , θ t ), t = 1, 2, • • • , T -1<label>(2)</label></formula><p>Here, the dynamics {f t (x t , θ t ), t = 0, 1, . . . , T -1} represent a deep neural network, T denote the number of layers, θ t ∈ Θ t denotes the parameters in layer t (denote θ = {θ t } t ∈ Θ), the function f t : R dt × Θ t → R dt+1 is a nonlinear transformation for one layer of neural network where d t is the dimension of the t th feature map and {x i,0 , i = 1, . . . , N } is the training dataset. The variable η = (η 1 , • • • , η N ) is the adversarial perturbation and we constrain it in an ∞-ball. Function i is a data fitting loss function and R t is the regularization weights θ t such as the L 2 -norm. By casting the problem of adversarial training as a differential game (2), we regard θ and η as two competing players, each trying to minimize/maximize the loss function J(θ, η) respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Gradient Based YOPO</head><p>The Pontryagin's Maximum Principle (PMP) is a fundamental tool in optimal control that characterizes optimal solutions of the corresponding control problem <ref type="bibr" target="#b6">[7]</ref>. PMP is a rather general framework that inspires a variety of optimization algorithms. In this paper, we will derive the PMP of the differential game <ref type="bibr" target="#b1">(2)</ref>, which motivates the proposed YOPO in its most general form. However, to better illustrate the essential idea of YOPO and to better address its relations with existing methods such as PGD, we present a special case of YOPO in this section based on gradient descent/ascent. We postpone the introduction of PMP and the general version of YOPO to Section 3.</p><p>Let us first rewrite the original robust optimization problem (1) (in a mini-batch form) as</p><formula xml:id="formula_2">min θ max ηi ≤ B i=1 (g θ (f 0 (x i + η i , θ 0 )), y i ),</formula><p>where f 0 denotes the first layer,</p><formula xml:id="formula_3">g θ = f θ T -1 T -1 • f θ T -2 T -2 • • • • f θ1</formula><p>1 denotes the network without the first layer and B is the batch size. Here θ is defined as</p><formula xml:id="formula_4">{θ 1 , • • • , θ T -1 }.</formula><p>For simplicity we omit the regularization term R t .</p><p>The simplest way to solve the problem is to perform gradient ascent on the input data and gradient descent on the weights of the neural network as shown below. Such alternating optimization algorithm is essentially the popular PGD adversarial training <ref type="bibr" target="#b23">[24]</ref>. We summarize the PGD-r (for each update on θ) as follows, i.e. performing r iterations of gradient ascent for inner maximization.</p><p>• For s = 0, 1, . . . , r -1, perform</p><formula xml:id="formula_5">η s+1 i = η s i + α 1 ∇ ηi (g θ (f 0 (x i + η s i , θ 0 )), y i ), i = 1, • • • , B</formula><p>, where by the chain rule,</p><formula xml:id="formula_6">∇ ηi (g θ (f 0 (x i + η s i , θ 0 )), y i ) =∇ gθ (g θ (f 0 (x i + η s i , θ 0 )), y i ) • ∇ f0 g θ (f 0 (x i + η s i , θ 0 )) • ∇ ηi f 0 (x i + η s i , θ 0 ).</formula><p>• Perform the SGD weight update (momentum SGD can also be used here)</p><formula xml:id="formula_7">θ ← θ -α 2 ∇ θ B i=1 (g θ (f 0 (x i + η m i , θ 0 )), y i )</formula><p>Note that this method conducts r sweeps of forward and backward propagation for each update of θ. This is the main reason why adversarial training using PGD-type algorithms can be very slow.</p><p>To reduce the total number of forward and backward propagation, we introduce a slack variable</p><formula xml:id="formula_8">p = ∇ gθ (g θ (f 0 (x i + η i , θ 0 )), y i ) • ∇ f0 g θ (f 0 (x i + η i , θ 0 ))</formula><p>and freeze it as a constant within the inner loop of the adversary update. The modified algorithm is given below and we shall refer to it as YOPO-m-n.</p><p>• Initialize {η 1,0 i } for each input</p><formula xml:id="formula_9">x i . For j = 1, 2, • • • , m -Calculate the slack variable p p = ∇ gθ (g θ (f 0 (x i + η j,0 i , θ 0 )), y i ) • ∇ f0 g θ (f 0 (x i + η j,0 i , θ 0 )) ,</formula><p>-Update the adversary for s = 0, 1, . . . , n -1 for fixed p</p><formula xml:id="formula_10">η j,s+1 i = η j,s i + α 1 p • ∇ ηi f 0 (x i + η j,s i , θ 0 ), i = 1, • • • , B -Let η j+1,0 i = η j,n i . • Calculate the weight update U = m j=1 ∇ θ B i=1 (g θ (f 0 (x i + η j,n i , θ 0 )), y i )</formula><p>and update the weight θ ← θ -α 2 U . (Momentum SGD can also be used here.)</p><p>Intuitively, YOPO freezes the values of the derivatives of the network at level 1, 2 . . . , T -1 during the s-loop of the adversary updates. Figure <ref type="figure" target="#fig_0">2</ref> shows the conceptual comprison between YOPO and PGD. YOPO-m-n accesses the data m × n times while only requires m full forward and backward propagation. PGD-r, on the other hand, propagates the data r times for r full forward and backward propagation. As one can see that, YOPO-m-n has the flexibility of increasing n and reducing m to achieve approximately the same level of attack but with much less computation cost. For example, suppose one applies PGD-10 (i.e. 10 steps of gradient ascent for solving the inner maximization) to calculate the adversary. An alternative approach is using YOPO-5-2 which also accesses the data 10 times but the total number of full forward propagation is only 5. Empirically, YOPO-m-n achieves comparable results only requiring setting m × n a litter larger than r.</p><p>Another benefit of YOPO is that we take full advantage of every forward and backward propagation to update the weights, i.e. the intermediate perturbation η j i , j = 1, • • • , m -1 are not wasted like PGD-r. This allows us to perform multiple updates per iteration, which potentially drives YOPO to converge faster in terms of the number of epochs. Combining the two factors together, YOPO significantly could accelerate the standard PGD adversarial training.</p><p>We would like to point out a concurrent paper <ref type="bibr" target="#b27">[28]</ref> that is related to YOPO. Their proposed method, called "Free-m", also can significantly speed up adversarial training. In fact, Free-m is essentially YOPO-m-1, except that YOPO-m-1 delays the weight update after the whole mini-batch is processed in order for a proper usage of momentum<ref type="foot" target="#foot_0">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Pontryagin's Maximum Principle for Adversarial Training</head><p>In this section, we present the PMP of the discrete time differential game <ref type="bibr" target="#b1">(2)</ref>. From the PMP, we can observe that the adversary update and its associated back-propagation process can be decoupled. Furthermore, back-propagation based gradient descent can be understood as an iterative algorithm solving the PMP and with that the version of YOPO presented in the previous section can be viewed as an algorithm solving the PMP. However, the PMP facilitates a much wider class of algorithms than gradient descent algorithms <ref type="bibr" target="#b18">[19]</ref>. Therefore, we will present a general version of YOPO based on the PMP for the discrete differential game.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PMP</head><p>Pontryagin type of maximal principle <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b2">3]</ref> provides necessary conditions for optimality with a layer-wise maximization requirement on the Hamiltonian function. </p><formula xml:id="formula_11">H t : R dt × R dt+1 × Θ t → R as H t (x, p, θ t ) = p • f t (x, θ t ) - 1 B R t (x, θ t ).</formula><p>The PMP for continuous time differential game has been well studied in the literature <ref type="bibr" target="#b6">[7]</ref>. Here, we present the PMP for our discrete time differential game (2). </p><formula xml:id="formula_12">x * i,t+1 = ∇ p H t (x * i,t , p * i,t+1 , θ * t ), x * i,0 = x i,0 + η * i<label>(3)</label></formula><formula xml:id="formula_13">p * i,t = ∇ x H t (x * i,t , p * i,t+1 , θ * t ), p * i,T = - 1 B ∇ i (x * i,T )<label>(4)</label></formula><p>At the same time, the parameters of the first layer θ * 0 ∈ Θ 0 and the optimal adversarial perturbation η * i satisfy</p><formula xml:id="formula_14">B i=1 H 0 (x * i,0 + η i , p * i,1 , θ * 0 ) ≥ B i=1 H 0 (x * i,0 + η * i , p * i,1 , θ * 0 ) ≥ B i=1 H 0 (x * i,0 + η * i , p * i,1 , θ 0 ),<label>(5)</label></formula><formula xml:id="formula_15">∀θ 0 ∈ Θ 0 , η i ∞ ≤<label>(6)</label></formula><p>and the parameters of the other layers θ * t ∈ Θ t , t ∈ [T ] maximize the Hamiltonian functions</p><formula xml:id="formula_16">B i=1 H t (x * i,t , p * i,t+1 , θ * t ) ≥ B i=1 H t (x * i,t , p * i,t+1 , θ t ), ∀θ t ∈ Θ t<label>(7)</label></formula><p>Proof. Proof is in the supplementary materials.</p><p>From the theorem, we can observe that the adversary η is only coupled with the parameters of the first layer θ 0 . This key observation inspires the design of YOPO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PMP and Back-Propagation Based Gradient Descent</head><p>The classical back-propagation based gradient descent algorithm <ref type="bibr" target="#b16">[17]</ref> can be viewed as an algorithm attempting to solve the PMP. Without loss of generality, we can let the regularization term R = 0, since we can simply add an extra dynamic w t to evaluate the regularization term R, i.e.</p><formula xml:id="formula_17">w t+1 = w t + R t (x t , θ t ), w 0 = 0.</formula><p>We append w to x to study the dynamics of a new (d t + 1)-dimension vector and change f t (x, θ t ) to (f t (x, θ t ), w + R t (x, θ t )). The relationship between the PMP and the back-propagation based gradient descent method was first observed by Li et al. <ref type="bibr" target="#b18">[19]</ref>. They showed that the forward dynamical system Eq.( <ref type="formula" target="#formula_12">3</ref>) is the same as the neural network forward propagation. The backward dynamical system Eq.( <ref type="formula" target="#formula_13">4</ref>) is the back-propagation, which is formally described by the following lemma. Lemma 1.</p><formula xml:id="formula_18">p * t = ∇ x H t (x * t , p * t+1 , θ * t ) = ∇ x f (x * t , θ * t ) T p t+1 = (∇ xt x * t+1 ) T •-∇ xt+1 ( (x T )) = -∇ xt ( (x T )).</formula><p>To solve the maximization of the Hamiltonian, a simple way is the gradient ascent:</p><formula xml:id="formula_19">θ 1 t = θ 0 t + α • ∇ θ B i=1 H t (x θ 0 i,t , p θ 0 i,t+1 , θ 0 t ).<label>(8)</label></formula><p>Theorem 2. The update ( <ref type="formula" target="#formula_19">8</ref>) is equivalent to gradient descent method for training networks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">YOPO from PMP's View Point</head><p>Based on the relationship between back-propagation and the Pontryagin's Maximum Principle, in this section, we provide a new understanding of YOPO, i.e. solving the PMP for the differential game.</p><p>Observing that, in the PMP, the adversary η is only coupled with the weight of the first layer θ 0 . Thus we can update the adversary via minimizing the Hamiltonian function instead of directly attacking the loss function, described in Algorithm 1.</p><p>For YOPO-m-n, to approximate the exact minimization of the Hamiltonian, we perform n times gradient descent to update the adversary. Furthermore, in order to make the calculation of the adversary more accurate, we iteratively pass one data point m times. Besides, the network weights are optimized via performing the gradient ascent to Hamiltonian, resulting in the gradient-based YOPO proposed in Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 YOPO (You Only Propagate Once)</head><p>Randomly initialize the network parameters or using a pre-trained network. repeat Randomly select a mini-batch B = {(x 1 , y 1 ), </p><formula xml:id="formula_20">for j = 1 to m do x i,0 = x i + η j i , i = 1, 2, • • • , B for t = 0 to T -1 do x i,t+1 = ∇ p H t (x i,t , p i,t+1 , θ t ), i = 1, 2, • • • , B end for p i,T = -1 B ∇ (x * i,T ), i = 1, 2, • • • , B for t = T -1 to 0 do p i,t = ∇ x H t (x i,t , p i,t+1 , θ t ), i = 1, 2, • • • , B end for η j i = arg min ηi H 0 (x i,0 + η i , p i,0 , θ 0 ), i = 1, 2, • • • , B end for for t = T -1 to 1 do θ t = arg max θt B i=1 H t (x i,t , p i,t+1 , θ t ) end for θ 0 = arg max θ0 1 m m k=1 B i=1 H 0 (x i,0 + η j i , p i,1 , θ 0 ) until Convergence 4 Experiments</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">YOPO for Adversarial Training</head><p>To demonstrate the effectiveness of YOPO, we conduct experiments on MNIST and CIFAR10. We find that models trained with YOPO have comparable performance with that of the PGD adversarial training, but with a much fewer computational cost. We also compare our method with a concurrent method "For Free" <ref type="bibr" target="#b27">[28]</ref>, and the result shows that our algorithm can achieve comparable performance with around 2/3 GPU time of their official implementation.</p><p>MNIST We achieve comparable results with the best in <ref type="bibr" target="#b4">[5]</ref> within 250 seconds, while it takes PGD-40 more than 1250s to reach the same level. The accuracy-time curve is shown in Figuire 3(a). Quantitative results can be seen in supplementary materials. Naively reducing the backprop times of PGD-40 to PGD-10 will harm the robustness, as can be seen in supplementary materials. [24] performs a 7-step PGD to generate adversary while training. As a comparison, we test YOPO-3-5 and YOPO-5-3 with a step size of 2/255. Quantitative results can be seen in Table <ref type="table" target="#tab_3">1</ref> and supplementary materials.</p><p>Under PreAct-Res18, for YOPO-5-3, it achieves comparable robust accuracy with <ref type="bibr" target="#b23">[24]</ref> with around half computation for every epoch. The accuracy-time curve is shown in Figuire 3(b).The quantitative results can be seen in supplementary materials.</p><p>As for Wide ResNet34, YOPO-5-3 still achieves similar acceleration against PGD-10, as shown in Table <ref type="table" target="#tab_3">1</ref>. We also test PGD-3/5 to show that naively reducing backward times for this minmax problem <ref type="bibr" target="#b23">[24]</ref> cannot produce comparable results within the same computation time as YOPO. Meanwhile, YOPO-3-5 can achieve more aggressive speed-up with only a slight drop in robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Methods Clean Data PGD-20 Attack Training Time (mins)</head><p>Natural train 95.03% 0.00% 233 PGD-3 <ref type="bibr" target="#b23">[24]</ref> 90.07% 39.18% 1134 PGD-5 <ref type="bibr" target="#b23">[24]</ref> 89.65% </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we have developed an efficient strategy for accelerating adversarial training. We recast the adversarial training of deep neural networks as a discrete time differential game and derive a Pontryagin's Maximum Principle (PMP) for it. Based on this maximum principle, we discover that the adversary is only coupled with the weights of the first layer. This motivates us to split the adversary updates from the back-propagation gradient calculation. The proposed algorithm, called YOPO, avoids computing full forward and backward propagation for too many times, thus effectively reducing the computational time as supported by our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pipeline of YOPO-m-n described in Algorithm 1. The yellow and olive blocks represent feature maps while the orange blocks represent the gradients of the loss w.r.t. feature maps of each layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance w.r.t. training time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>• • • , (x B , y B )} from training set. Initialize η i , i = 1, 2, • • • , B by sampling from a uniform distribution between [-, ]</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Code from https://github.com/ashafahi/free_adv_train. Results of Wide ResNet34 for CIFAR10.4.2 YOPO for TRADESTRADES<ref type="bibr" target="#b43">[44]</ref> formulated a new min-max objective function of adversarial defense and achieves the state-of-the-art adversarial defense results. The experiment details are in supplementary material and quantitative results are demonstrated in Table2.</figDesc><table><row><cell>43.85%</cell><cell>1574</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Results of training PreAct-Res18 for CIFAR10 with TRADES objective</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>Momentum should be accumulated between mini-batches other than different adversarial examples from one mini-batch, otherwise overfitting will become a serious problem.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Di He and Long Chen for beneficial discussion. Zhanxing Zhu is supported in part by National Natural Science Foundation of China (No.61806009), Beijing Natural Science Foundation (No. 4184090) and Beijing Academy of Artificial Intelligence (BAAI). Bin Dong is supported in part by Beijing Natural Science Foundation (No. Z180001) and Beijing Academy of Artificial Intelligence (BAAI). Dinghuai Zhang is supported by the Elite Undergraduate Training Program of Applied Math of the School of Mathematical Sciences at Peking University.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Armin</forename><surname>Askari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Negiar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Sambharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.01532</idno>
		<title level="m">Lifted neural networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples</title>
		<author>
			<persName><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.00420</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Revaz Valer&apos;yanovich Gamkrelidze, and Lev Semenovich Pontryagin. The theory of optimal processes. i. the maximum principle</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Grigor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'</forename><surname>Boltyanskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TRW SPACE TECHNOLOGY LABS LOS ANGELES CALIF</title>
		<imprint>
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13436</idno>
		<title level="m">Max-mig: an information theoretic approach for joint learning from crowds</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6572" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parseval networks: Improving robustness to adversarial examples</title>
		<author>
			<persName><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="854" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An introduction to mathematical optimal control theory</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Department of Mathematics, Berkeley</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Fangda</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Askari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08039</idno>
		<title level="m">Fenchel lifted networks: A lagrange relaxation of neural network training</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stable architectures for deep neural networks</title>
		<author>
			<persName><forename type="first">Eldad</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Ruthotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Problems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14004</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Zhouyuan</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10574</idno>
		<title level="m">Decoupled parallel backpropagation with convergence guarantee</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajil</forename><surname>Jalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eirini</forename><surname>Asteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantinos</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09196</idno>
		<title level="m">The robust manifold defense: Adversarial training using generative models</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Decoupled neural interfaces using synthetic gradients</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marian</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1627" to="1635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving dnn robustness to adversarial attacks using jacobian regularization</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jakubovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="514" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01236</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A theoretical framework for backpropagation</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Touresky</surname></persName>
		</author>
		<author>
			<persName><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1988 connectionist models summer school</title>
		<meeting>the 1988 connectionist models summer school<address><addrLine>Pittsburgh, Pa</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
		<respStmt>
			<orgName>CMU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01501</idno>
		<title level="m">Lifted proximal operator machines</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Maximum principle based algorithms for deep learning</title>
		<author>
			<persName><forename type="first">Qianxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><surname>Weinan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5998" to="6026" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An optimal control approach to deep learning and applications to discrete-weight neural networks</title>
		<author>
			<persName><forename type="first">Qianxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuji</forename><surname>Hao</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Jennifer</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsmässan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07">Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Defensive quantization: When efficiency meets robustness</title>
		<author>
			<persName><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations</title>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aoxiao</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanzheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10121</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">RANDOM MASK: Towards robust convolutional neural networks</title>
		<author>
			<persName><forename type="first">Tiange</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianle</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengxiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deepfool: a simple and accurate method to fool deep neural networks</title>
		<author>
			<persName><forename type="first">Seyed-Mohsen</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alhussein</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2574" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Mathematical theory of optimal processes</title>
		<author>
			<persName><forename type="first">Lev</forename><surname>Semenovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontryagin</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><surname>Mark N Wegman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.07896</idno>
		<title level="m">L2-nonexpansive neural networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Ali</forename><surname>Shafahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahyar</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12843</idno>
		<title level="m">Adversarial training for free! arXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Pixeldefend: Leveraging generative models to understand and defend against adversarial examples</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10766</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Transport analysis of infinitely deep neural network</title>
		<author>
			<persName><forename type="first">Sho</forename><surname>Sonoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noboru</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="82" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Enhancing the robustness of deep neural networks by boundary conditional gan</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.11029</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Peernets: Exploiting peer wisdom against adversarial attacks</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<title level="m">Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Training neural networks without gradients: A scalable admm approach</title>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Burmeister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2722" to="2731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Van Gennip</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.11741</idno>
		<title level="m">Deep limits of residual neural networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Contributions to the theory of statistical estimation and testing hypotheses</title>
		<author>
			<persName><forename type="first">Abraham</forename><surname>Wald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="299" to="326" />
			<date type="published" when="1939">1939</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Bao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binjie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuoqiang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanley</forename><forename type="middle">J</forename><surname>Osher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.10745</idno>
		<title level="m">Enresnet: Resnet ensemble via the feynman-kac formalism</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A proposal on machine learning via dynamical systems</title>
		<author>
			<persName><surname>Weinan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Mathematics and Statistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A mean-field optimal control formulation of deep learning</title>
		<author>
			<persName><forename type="first">Jiequn</forename><surname>Weinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianxiao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research in the Mathematical Sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Laurens van der Maaten, Alan Yuille, and Kaiming He. Feature denoising for improving adversarial robustness</title>
		<author>
			<persName><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.03411</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Feature squeezing: Detecting adversarial examples in deep neural networks</title>
		<author>
			<persName><forename type="first">Weilin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01155</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>L_Dmi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03388</idno>
		<title level="m">An information-theoretic noise-robust loss function</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Bayesian adversarial learning</title>
		<author>
			<persName><forename type="first">Nanyang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6892" to="6901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaodong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiantao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08573</idno>
		<title level="m">Theoretically principled trade-off between robustness and accuracy</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Jingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Wynter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kian</forename><surname>Hsiang Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10887</idno>
		<title level="m">Towards robust resnet: A small step but a giant leap</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamically unfolding recurrent restorer: A moving endpoint control method for image restoration</title>
		<author>
			<persName><forename type="first">Xiaoshuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
