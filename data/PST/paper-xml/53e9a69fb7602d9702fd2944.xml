<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-03-03">March 3, 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Joshua</forename><surname>Candamo</surname></persName>
							<email>candamo@cse.usf.edu</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Matthew</forename><surname>Shreve</surname></persName>
							<email>mshreve@cse.usf.edu</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Dmitry</forename><forename type="middle">B</forename><surname>Goldgof</surname></persName>
							<email>goldgof@cse.usf.edu</email>
						</author>
						<author>
							<persName><forename type="first">Deborah</forename><forename type="middle">B</forename><surname>Sapper</surname></persName>
							<email>sapper@cutr.usf.edu</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Rangachar</forename><surname>Kasturi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of South Florida</orgName>
								<address>
									<postCode>33620</postCode>
									<settlement>Tampa</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">K9 Bytes, Inc</orgName>
								<address>
									<postCode>33617</postCode>
									<settlement>Tampa</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Com-puter Science and Engineering</orgName>
								<orgName type="institution">University of South Florida</orgName>
								<address>
									<postCode>33620</postCode>
									<settlement>Tampa</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Center for Urban Transportation Research</orgName>
								<orgName type="institution">Univer-sity of South Florida</orgName>
								<address>
									<postCode>33620</postCode>
									<settlement>Tampa</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-03-03">March 3, 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">AC6C6BBA6E0EDDE62FDD61B1AEF2DCCF</idno>
					<idno type="DOI">10.1109/TITS.2009.2030963</idno>
					<note type="submission">received September 18, 2008; revised April 28, 2009 and July 15, 2009. First published October 2, 2009; current version published</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Anomaly detection</term>
					<term>event detection</term>
					<term>human behavior recognition</term>
					<term>smart transit system</term>
					<term>video analytics</term>
					<term>visual surveillance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visual surveillance is an active research topic in image processing. Transit systems are actively seeking new or improved ways to use technology to deter and respond to accidents, crime, suspicious activities, terrorism, and vandalism. Human behavior-recognition algorithms can be used proactively for prevention of incidents or reactively for investigation after the fact. This paper describes the current state-of-the-art image-processing methods for automatic-behavior-recognition techniques, with focus on the surveillance of human activities in the context of transit applications. The main goal of this survey is to provide researchers in the field with a summary of progress achieved to date and to help identify areas where further research is needed. This paper provides a thorough description of the research on relevant human behavior-recognition methods for transit surveillance. Recognition methods include single person (e.g., loitering), multipleperson interactions (e.g., fighting and personal attacks), personvehicle interactions (e.g., vehicle vandalism), and person-facility/ location interactions (e.g., object left behind and trespassing). A list of relevant behavior-recognition papers is presented, including behaviors, data sets, implementation details, and results. In addition, algorithm's weaknesses, potential research directions, and contrast with commercial capabilities as advertised by manufacturers are discussed. This paper also provides a summary of literature surveys and developments of the core technologies (i.e., low-level processing techniques) used in visual surveillance systems, including motion detection, classification of moving objects, and tracking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Understanding Transit Scenes: A Survey on Human Behavior-Recognition Algorithms I. INTRODUCTION M ILITARY, intelligence, and mass-transit agencies are increasingly using video cameras to fight crime and terrorism. Due to hardware and storage improvements during the last decade, a collection of continuous surveillance video is already at our doorstep. However, the means to continuously process it are not.</p><p>To illustrate the scope and scale of large surveillance transit systems, consider the following examples. The New York City Transit System <ref type="bibr" target="#b0">[1]</ref> is the busiest metro system in the U.S. (based on 2006 statistics), with a total of 468 stations and 1.49 billion riders a year, that is, 4.9 million riders a day. Moscow metro <ref type="bibr">[2]</ref> is the busiest metro in Europe and, as of 2007, has 176 stations with 2.52 billion riders annually, that is, 9.55 million daily riders. This ridership represents a 9.53% growth since 1995. Transit systems are spread through hundreds of kilometers and already require several tens of thousands of employees for daily operations. A complete deployment of visual surveillance to cover a system of this magnitude requires thousands of cameras, which makes human-based/dependent surveillance unfeasible for all practical purposes.</p><p>As the volume of video data increases, most existing digital video-surveillance systems provide the infrastructure only to capture, store, and distribute video while exclusively leaving the task of threat detection to human operators. Detecting specific activities in a live feed or searching in video archives (i.e., video analytics) almost completely relies on costly and scarce human resources. Detecting multiple activities in real-time video feeds is currently performed by assigning multiple analysts to simultaneously watch the same video stream. Each analyst is assigned a portion of the video and is given a list of events (behaviors) and objects for which to look. The analyst issues an alert to the proper authorities if any of the given events or objects are spotted. Manual analysis of video is labor intensive, fatiguing, and prone to errors. Additionally, psychophysical research indicates that there are severe limitations in the ability of humans to monitor simultaneous signals <ref type="bibr" target="#b1">[3]</ref>. Thus, it is clear that there is a fundamental contradiction between the current surveillance model and human surveillance capabilities.</p><p>The ability to quickly search large volumes of existing video or monitor real-time footage will provide dramatic capabilities to transit agencies. Software-aided real-time video analytics or forensics would considerably alleviate the human constraints, which currently are the main handicap for analyzing continuous surveillance data. The idea of creating a virtual analyst or software tools for video analytics has become of great importance to the research community. It is our goal to review the state-of-the-art methods for automatic video analytic techniques, with focus on surveillance of human activities in transit systems. Human and vehicle behavior recognition has become one of the most active research topics in image processing and pattern recognition <ref type="bibr" target="#b2">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b92">[93]</ref>, <ref type="bibr" target="#b122">[123]</ref>. Previous surveys have emphasized low-level processing techniques used in visual surveillance (what we will refer to as "core technologies," e.g., motion detection and tracking). In contrast, we focus on human behavior recognition topics, drawing special attention to transit system applications. However, for clarity, a brief review of the state-of-the-art core technologies is offered, and previous surveys in related areas are identified (see Table <ref type="table" target="#tab_0">I</ref>).</p><p>Video analytics gained significant research momentum in 2000, when the Advanced Research and Development Activity (ARDA) started sponsoring detection, recognition, and understanding of moving object events. Research focused on news broadcast video, meeting/conference video, unmanned aerial vehicle (UAV) motion imagery and ground reconnaissance video, and surveillance video. The Video Analysis and Content Extraction (VACE) project focused on automatic video content extraction, multimodal fusion, event recognition, and understanding. The Defense Advanced Research Projection Agency (DARPA) has also supported several large research projects involving visual surveillance and related topics. Projects include Visual Surveillance and Monitoring (VSAM, 1997) <ref type="bibr" target="#b7">[8]</ref> and Human Identification at a Distance <ref type="bibr">(HID, 2000)</ref>. Recently, the Video and Image Retrieval Analysis Tool (VIRAT, 2008) project has been announced. VIRAT's purpose is to develop and demonstrate a system for UAV video data exploitation, which would enable analysts to efficiently provide alerts of events of interest during live operations and retrieve video content of interest from archives.</p><p>Video analytics have increasingly become popular in commercial systems. Later in this survey, a summary of some of the existing commercial systems is provided. The list includes advertised capabilities for human behavior recognition. However, it is unclear how well systems are able to cope with crowds of people, which is typical of mass transit systems. The cost effectiveness of behavior detection systems to transit agencies depends on independent verification. Verification of the systems' performance is based on the tasks deemed most important by the transit agencies for the application. Efforts to create standard evaluation frameworks (methodologies to quantify and qualify performance) have been of increasing interest to the research surveillance community <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Additionally, there are methods for evaluating the performance of the evaluators <ref type="bibr" target="#b17">[18]</ref>. Despite the large number of existing evaluation techniques, a robust study that experimentally compares algorithms for human activity recognition is still lacking.</p><p>In the last decade, there have been many conferences and workshops dedicated to visual surveillance, including the IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS) 2005 challenge, which focused on realtime event detection solutions. The Challenge for Real-time Events Detection Solutions (CREDS) <ref type="bibr" target="#b18">[19]</ref> defined by the needs of the public transportation network of Paris (RATP, the second busiest metro system in Europe) focused on proximity warning, dropping objects on tracks, launching objects across platforms, persons trapped by the door of a moving train, walking on rails, falling on the track, and crossing the rails. Several CREDS proposals can be found in <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b22">[23]</ref>. The Performance Evaluation of Tracking and Surveillance (PETS) <ref type="bibr" target="#b23">[24]</ref> workshops started with the goal of evaluating visual tracking and surveillance algorithms. The initiative provides standard data sets, with available ground truth, to evaluate object tracking and segmentation. Recently, a metric to evaluate surveillance results has also been introduced <ref type="bibr" target="#b24">[25]</ref>. Some PETS data sets contain relevant information closely related to transit systems. Data sets include single-camera outdoor people and vehicle tracking (PETS, 2000); multicamera outdoor people and vehicle tracking (2001); diverse surveillance-related events, including people walking alone, meeting with others, window shopping, fighting, passing out, and leaving a package in a public place (2004); and images containing left-luggage scenarios <ref type="bibr">(2006)</ref>.</p><p>Around the world, large underground metro networks (e.g., France's RATP, the U.K.'s LUL and BAA, and Italy's ATM) have deployed and tested large real-time transit visualsurveillance systems that include human-behavior recognition. There have been several transit surveillance projects that have been funded by the European Union. The Proactive Integrated Systems for Security Management by Technological, Institutional, and Communication Assistance (PRISMATICA) <ref type="bibr" target="#b25">[26]</ref> has deployed video analytic systems in France. The Content Analysis and Retrieval Technologies to Apply Knowledge Extraction to Massive Recording (CARETAKER) <ref type="bibr" target="#b26">[27]</ref> project was deployed in Italy. The Annotated Digital Video for Intelligent Surveillance and Optimized Retrieval (ADVISOR) <ref type="bibr" target="#b27">[28]</ref> was successfully deployed and tested in Spain and Belgium, including previous work from the Crowd Management with Telematic Imaging and Communication Assistance (CROMATICA) project <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Paper Overview</head><p>The main focus of this survey is to offer a comprehensive survey of image-processing human behavior recognition algorithms in the context of transit applications. All the preprocessing steps prior to behavior recognition are referred to in this paper as "core technologies." Human behavior recognition using video starts with the detection of foreground objects, which is commonly achieved through environmental modeling or motion-based segmentation. Subsequently, foreground objects are classified depending on the application as humans or vehicles. Object classification can be shape based, motion based, or based on a particular descriptor suitable for a specific application. Finally, tracking establishes the spatiotemporal relationship between the objects and the scene. The organization of this paper is depicted in Fig. <ref type="figure" target="#fig_0">1</ref>. We begin Section II with a brief glance on the core technologies, to facilitate the understanding of the later sections of this paper. For organization purposes, all pertinent surveys dealing with core technologies are identified and summarized in Table <ref type="table" target="#tab_0">I</ref>. Behavior-recognition strategies are discussed in Section III. Section IV elaborates on many important topics describing the current state-of-the-art strengths, weaknesses, and future research directions. Section V summarizes the contents of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CORE TECHNOLOGIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motion Detection</head><p>Visual surveillance systems for fixed cameras traditionally include some sort of motion detection. Motion detection is used to segment moving objects from the rest of the image. Knowledge about the motion of objects is useful in both the object and behavior recognition processes. A survey on early work in motion detection can be found in <ref type="bibr" target="#b32">[33]</ref>. In transit-surveillance applications, motion detection typically refers to movement of objects as a whole, e.g., movement of pedestrians or vehicles. However, human motion can also be referred to articulated motion of the human body, such as the motion of certain body parts like legs or arms. There are two types of articulated motion: 1) large-scale body movements like movements of the head, arms, torso, and legs <ref type="bibr" target="#b6">[7]</ref>; and 2) small-scale body movements like hand gestures and facial expressions <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. In general, motion detection can be subdivided into environment modeling, motion segmentation, and object classification. All three often overlap during processing. Nearly all current surveillance systems rely on 2-D data for motion processing; thus, the focus of this survey will be on this domain. However, advances in image sensors and evolution of digital computation are leading to creation of new sophisticated methods for capturing, processing, and analyzing 3-D data from dynamic scenes. Recent developments include 3-D environmental modeling reconstructed using the shape-from-motion technique <ref type="bibr" target="#b35">[36]</ref> and 3-D imagery from a moving monocular camera <ref type="bibr" target="#b36">[37]</ref>. Most 3-D approaches require landmarks to be present in the scene <ref type="bibr" target="#b37">[38]</ref> to accurately estimate the required extrinsic parameters of the camera, which sets an additional set of practical constraints for deployment of systems. A survey on emerging perspective time-varying 3-D scene capture technologies can be found in <ref type="bibr" target="#b38">[39]</ref>.</p><p>1) Background Subtraction and Temporal Differencing: A popular object segmentation strategy is background subtraction. Background subtraction compares an image with an estimate of the image as if it contained no objects of interest. It extracts foreground objects from regions where there is a significant difference between the observed and the estimated image. Common algorithms include methods by Heikkila and Silven <ref type="bibr" target="#b39">[40]</ref>, Stauffer and Grimson (adaptive Gaussian mixture model or GMM) <ref type="bibr" target="#b40">[41]</ref>, Halevy and Weinshall <ref type="bibr" target="#b41">[42]</ref>, Cutler and Davis <ref type="bibr" target="#b42">[43]</ref>, and Toyama et al. (Wallflower) <ref type="bibr" target="#b43">[44]</ref>. A detailed general survey of image change algorithms can be found in <ref type="bibr" target="#b44">[45]</ref>. The GMM is one of the most commonly used methods for background subtraction in visual surveillance applications for fixed cameras. A mixture of Gaussians is maintained for each pixel in the image. As time goes on, new pixel values update the mixture of Gaussians using an online K-means approach. The estimation update is used to account for illumination changes, slight sensor movements, and noise. Nevertheless, transit surveillance researchers continue to emphasize the importance of robust background subtraction methods <ref type="bibr" target="#b46">[47]</ref> and online construction and adaptive background models <ref type="bibr" target="#b45">[46]</ref>. A large number of recent background subtraction methods improve on prior existing methods by modeling the statistical behavior of a particular domain or by using a combination of methods. For example, in <ref type="bibr" target="#b46">[47]</ref>, a slow adapting Kalman filter was used to model the background over time in conjunction with statistics based on an elliptical moving object model. Robust background subtraction is typically computationally expensive; thus, methods to improve standard algorithms are becoming increasingly popular <ref type="bibr" target="#b30">[31]</ref>. For example, authors of <ref type="bibr" target="#b37">[38]</ref> state that, for a GMM, speed can be improved by a factor of 8 with an imagesize of 640 × 480 pixels.</p><p>Another common object segmentation method is temporal differencing. In temporal differencing, video frames are separated by a constant time and compared to find regions that have changed. Unlike background subtraction, temporal differencing is based on local events with respect to time and does not use a model of the background to separate motion. Typically, two or three frames are used as separation time intervals, depending on the approach. A small time interval provides robustness to lighting conditions and complex backgrounds, since illumination changes and objects in the scene are more likely to be similar over short periods of time. However, an image-stabilization algorithm is required when there is a significant movement of the camera <ref type="bibr" target="#b47">[48]</ref>. Temporal differencing is usually computationally inexpensive, but it regularly fails at properly extracting the shape of the object in motion and can cause small holes to appear. For these reasons, hybrid approaches <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref> often combine both background subtraction and temporal differencing methods to provide more robust segmentation strategies.</p><p>2) Optical Flow: Optical flow is a vector-based approach that estimates motion in video by matching points on objects over multiple frames. A moderately high frame rate is required for accurate measurements. It should be noted that a real-time implementation of optical flow will often require specialized hardware, due to the complexity of the algorithm. A benefit of using optical flow is that it is robust to multiple and simultaneous camera and object motions, making it ideal for crowd analysis and conditions that contain dense motion. Popular techniques to compute optical flow include methods by Black and Anandan <ref type="bibr" target="#b50">[51]</ref>, Horn and Schunck <ref type="bibr" target="#b51">[52]</ref>, Lucas and Kanade <ref type="bibr" target="#b52">[53]</ref>, and Szeliski and Couglan <ref type="bibr" target="#b53">[54]</ref>. A comparison of methods for calculating optical flow can be found in <ref type="bibr" target="#b54">[55]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Object Classification</head><p>After finding moving regions or objects in an image, the next step in the behavior-recognition process is object classification. For example, a pedestrian crossing a street and a vehicle running a red light can be similar if there is no knowledge of the object causing the motion. Furthermore, object classification could distinguish interesting motion from those caused by moving clouds, specular reflections, swaying trees, or other dynamic occurrences common in transit videos. It is important to note here that there are multiple possible representations of objects before and after classification. Common geometric or topological properties used include height/width ratio, fill ratio, perimeter, area, compactness, convex hull, and histogram projection. For detailed definitions of these properties, see <ref type="bibr" target="#b55">[56]</ref>. Some of these properties are also used in postobject classification to keep track of the object in sequential frames or separate cameras. In general, for object classification in surveillance video, there are shape-based, motion-based, and feature-based classification methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Shape-Based Classification:</head><p>The geometry of the extracted regions (boxes, silhouettes, blobs) containing motion are often used to classify objects in video surveillance. Some common classifications in transit system surveillance are humans, crowds, vehicles, and clutter <ref type="bibr" target="#b7">[8]</ref>. For transit applications, particularly those oriented to human-behavior recognition, appearance features extracted from static images have been proven effective in segmenting pedestrians without the use of motion or tracking <ref type="bibr" target="#b56">[57]</ref>- <ref type="bibr" target="#b58">[59]</ref>. In general, shape-based recognition methods find the best match between comparisons of these properties in association with a priori statistics about the objects of interest. For example, in <ref type="bibr" target="#b59">[60]</ref>, blobs are first extracted and classified based on the calculated human height/width ratio based on data from the National Center for Health Statistics. Shape-based classification is particularly useful in certain transit systems when only certain parts of the objects are fully visible; for instance, in buses and metros, objects will partially be occluded most of the time, in which case, the head <ref type="bibr" target="#b60">[61]</ref> could be the only salient feature in the scene.</p><p>2) Motion-Based Classification: This classification method is based on the idea that object motion characteristics and patterns are unique enough to distinguish between objects. Humans have been shown to have distinct types of motion. Motion can be used to recognize "types" of human movements such as walking, running, or skipping, as well as for human identification. Starting with the HumanID Gait Challenge <ref type="bibr" target="#b61">[62]</ref>, imageprocessing researchers actively proposed gait-based methods <ref type="bibr" target="#b62">[63]</ref> for human identification at a distance. For more information on motion extraction and motion-based classification, see <ref type="bibr" target="#b63">[64]</ref> and <ref type="bibr" target="#b64">[65]</ref>. For an overview of motion estimation and recognition, with focus on optical flow techniques, see <ref type="bibr" target="#b65">[66]</ref>.</p><p>3) Other Classification Methods: Skin color <ref type="bibr" target="#b66">[67]</ref> has proved to be an important feature that can be used for the classification of humans in video, as it is relatively robust to changes in illumination, viewpoint, scale, shading, and occlusion. Skin color has also successfully been combined with other descriptors <ref type="bibr" target="#b67">[68]</ref> for classification purposes. In <ref type="bibr" target="#b59">[60]</ref>, the authors describe a method that consists of three parts: First, a red-green-blue normalization procedure was adopted to get the pure color components. A color transform is then applied, which correlates each pixel to that of its Gaussian distribution of the skin color, higher intensities being closer to the center. Hence, the output shows the region of the image that has closely matched with skin color, indicating human motion. This method has also been extended in <ref type="bibr" target="#b68">[69]</ref> and fused with other methods, including depth analysis using binocular imaging. Fusion of methods has been shown to be very effective when combining shape-and motion-based methods <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Object Tracking</head><p>In the context of transit systems, tracking is defined as the problem of estimating the trajectory of a pedestrian in the image plane while he is in the transit station or vehicle. The increasing need for automated video analysis has motivated researchers to explore tracking techniques, particularly for surveillance applications. Object tracking, in general, is a difficult task. Many problems that come from general object tracking are the same as those for human and vehicle tracking, among them multiple moving objects, noise, occlusions, object complexity, scene illumination variations, and sensor artifacts. For additional information on tracking, the reader is referred to detailed object tracking surveys <ref type="bibr" target="#b71">[72]</ref>, <ref type="bibr" target="#b72">[73]</ref>. Specific issues that arise within the transit domain include dealing with multiple persons in complex scenarios <ref type="bibr" target="#b73">[74]</ref>, tracking across large-scale distributed camera systems <ref type="bibr" target="#b74">[75]</ref>, tracking in highly congested areas with crowds of people <ref type="bibr" target="#b75">[76]</ref> (e.g., near ticket offices, metro, or bus waiting areas at rush hour), or tracking using mobile platforms <ref type="bibr" target="#b76">[77]</ref>. Extremely frequent occlusions are typical; consequently, the traditional localization and tracking of individuals is not sufficiently reliable. Furthermore, surveillance inside transit vehicles often only allows parts of individuals to be captured by the sensors (e.g., common occlusions from seats and other passengers often expose only faces inside buses and metros).</p><p>Tracking systems assign persistent identification tags to tracked pedestrians in different frames of a video. Depending on the application requirements, it is common for the system to also maintain other subject characteristics, such as aspect ratio, area, shape, color information, etc. Selecting good features that can be used for future tracking or identification is a necessity, since the object's appearance in a later frame may vary due to orientation, scale, or other natural changes. In addition, feature uniqueness plays an important role. Some common features used in image-processing applications are color, edges, motion, and texture. In <ref type="bibr" target="#b77">[78]</ref>, researchers describe a system that monitors suspicious human activities around bus stops, in which tracking of pedestrians is performed using a kernel-based method proposed in <ref type="bibr" target="#b78">[79]</ref>. This tracker is based on the color distribution of previously detected targets. The current position is found by searching the neighborhood around the previously found target and computing a Bhattacharyya coefficient, which is used as a correlation score. In <ref type="bibr" target="#b59">[60]</ref>, the shirt color is used as the main feature for tracking purposes, and kernel-based tracking is dropped in favor of blob-based tracking. Blob-based tracking offers a computational advantage over kernel search since the latter has to be first initialized, which would redundantly require blob extraction to be performed. Blob-based methods are extremely popular in the literature; for example, in proposed solutions to the CREDS challenge, <ref type="bibr" target="#b19">[20]</ref> considers the use of a long-memory matching algorithm <ref type="bibr" target="#b79">[80]</ref> using the blob's area, perimeter, and color histogram, and <ref type="bibr" target="#b21">[22]</ref> performs blob-based color histogram tracking. The French project Système d'Analyse de Médias pour une Sécurité Intelligente dans les Transports publics (SAMSIT) focuses on automatic surveillance in public transport vehicles by analyzing human behaviors. Inside metros and buses, faces are the only body part mostly captured by surveillance cameras, whereas the other body parts are occluded, particularly by the seats. Therefore, tracking is performed using faces with a color particle filter <ref type="bibr" target="#b80">[81]</ref> similar to <ref type="bibr" target="#b81">[82]</ref>. Tracking is based on the likelihood from the Bhattacharyya distance between color histograms in the hue-saturation-value color space. Color-based tracking is robust against vibration of the moving vehicles like trains and buses. However, it is sensitive to extreme changes in lighting conditions, such as a train entering a tunnel. Many multisensor approaches <ref type="bibr" target="#b82">[83]</ref>, <ref type="bibr" target="#b83">[84]</ref>, algorithm-fusion techniques <ref type="bibr" target="#b84">[85]</ref>, and integrating features over time <ref type="bibr" target="#b85">[86]</ref> have been proposed to overcome many of the mentioned tracking difficulties and to generate robust tracking performance in transit-surveillance applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. HUMAN-BEHAVIOR RECOGNITION</head><p>In this survey, the terminology and classification strategy for the human behavior is similar to that used by the VIRAT project. VIRAT divides the human behavior into two categories, namely, "events" and "activities." An event refers to a single low-level spatiotemporal entity that cannot be further decomposed (e.g., person standing and person walking). An activity refers to a composition of multiple events (e.g., a person loitering). Across the literature, the term "event" is often interchangeably used to describe "events" or "activities," as defined  by VIRAT. For clarity, we use the term "behavior" to include both "events" and "activities" and do not worry about inconsistencies of technical definitions. For organizational purposes, transit surveillance operationally relevant behaviors are divided into four general groups: 1) single person or no interaction; 2) multiple-person interactions; 3) person-vehicle interactions; and 4) person-facility/location interactions. Next, we provide some examples for each of these groups.</p><p>1) Single person or no interaction (see Fig. <ref type="figure" target="#fig_1">2</ref>) consists of behaviors that can be defined only by considering person(s), which are not interacting with any other person or vehicle. For example, loitering, people (crowd) counting, crowd flow (behavior) analysis, and person talking on a cell phone. 2) Multiple-person interactions (see Fig. <ref type="figure" target="#fig_2">3</ref>) consist of behaviors that involve persons interacting with each other. For example, following, tailgating, meeting, gathering, moving as a group, dispersing, shaking hands, kissing, exchanging objects, and kicking. 3) Person-vehicle interactions (see Fig. <ref type="figure">4</ref>) consist of behaviors that are defined through interactions with persons and vehicles. For example, driving, getting in (out), loading (unloading), opening (closing) trunk, crawling under car, breaking window, dropping off, and picking up. 4) Person-facility/location interactions (see Fig. <ref type="figure">5</ref>) are behaviors defined through interactions with persons and facilities/locations. For example, entering (exiting), standing, waiting at checkpoint, evading checkpoint, passing through gate, object left behind, and vandalism. In surveillance systems, behavior recognition can be ambiguous, depending on the scene context. The same behavior may have several different meanings depending on the environment and task context in which it is performed. Human behavior recognition has been the focus of several workshops such as Visual Surveillance (1998) <ref type="bibr" target="#b86">[87]</ref>, <ref type="bibr" target="#b87">[88]</ref>, Event Mining (2003) <ref type="bibr" target="#b88">[89]</ref>, <ref type="bibr" target="#b89">[90]</ref>, and Event Detection and Recognition (2004) <ref type="bibr" target="#b90">[91]</ref>, <ref type="bibr" target="#b91">[92]</ref>. See <ref type="bibr" target="#b92">[93]</ref>, where a brief background review of advances in intelligent visual surveillance is presented, and <ref type="bibr" target="#b93">[94]</ref> and <ref type="bibr" target="#b94">[95]</ref> for a review on studies of motion of the human body.</p><p>Any reliable behavior recognition strategy must be able to handle uncertainty. Many uncertainty-reasoning models have been proposed by the artificial intelligence and imageunderstanding community and already have been used in visual surveillance applications. The Bayesian approach is perhaps the most common model due its robustness and relatively low computational complexity, as compared with other methods, such as the Dempster-Shafter theory <ref type="bibr" target="#b95">[96]</ref>. Uncertainty handling can 3 Crime solver public video release from Hartford Police Department in Connecticut. 4 Object left behind sample images from PETS 2006 data set <ref type="bibr" target="#b23">[24]</ref>.</p><p>improve visual attention schemes <ref type="bibr" target="#b96">[97]</ref>. Various other models have been used in surveillance-related applications, including classifying human motion and simple human interactions using a small belief network <ref type="bibr" target="#b97">[98]</ref>, human postures using belief networks <ref type="bibr" target="#b98">[99]</ref>, description of traffic scenes using a dynamic Bayes network <ref type="bibr" target="#b99">[100]</ref>, human activity recognition using a hierarchical Bayes network <ref type="bibr" target="#b100">[101]</ref>, and anomalous behavior detection using trajectory learning with hidden Markov models <ref type="bibr" target="#b101">[102]</ref>, <ref type="bibr" target="#b102">[103]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Single Person or No Interaction 1) Loitering:</head><p>Loitering is defined as the presence of an individual in an area for a period of time longer than a given time threshold. Methods for automatically detecting loitering in real time would enable deployed security to investigate suspicious individuals or to target loitering stations for future investigation. Loitering is of special interest to public transit systems since it is a common practice of drug dealers, beggars, muggers, graffiti vandals, among others. In this survey, loitering refers to a behavior that exclusively involves a human. It is not to be confused with stationarity of objects (e.g., object left behind), which in our classification falls under person-facility interaction behaviors. Before a loitering activity is detected, individuals can be engaged in other activities like browsing, entering, leaving, and passing through <ref type="bibr" target="#b103">[104]</ref>.</p><p>In general, the literature for loitering detection in transit system applications mostly consists of tracking using indoor video (see Table <ref type="table" target="#tab_1">II</ref>). However, publications often lack of implementation and technical details <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b104">[105]</ref>, <ref type="bibr" target="#b105">[106]</ref>. The technical literature exclusively to outdoor loitering detection is scarce. In <ref type="bibr" target="#b59">[60]</ref>, outdoor loitering is used as a cue to detect potential drug-dealing operations in bus stations. Often, drug dealers wait for their clients to come by bus, buy drugs, and leave. Consequently, a suspicious activity is defined as individuals loitering, using a time threshold longer than the maximum time that it would typically take to catch a bus. The technique proposed in <ref type="bibr" target="#b59">[60]</ref> uses a refined Gaussian mixture background subtraction algorithm to detect motion blobs in a calibrated scene. Blobs are classified as humans using size and shape descriptors, and a short-term biometric based on the color of clothing is used for tracking purposes. A calibrated scene is used to calculate the effect of distortions in the pedestrian's size due to the perspective projection. However, in transit scenes, it is often impractical to manually measure camera parameters on site and almost impossible when working only with prerecorded examples <ref type="bibr" target="#b106">[107]</ref>.</p><p>2) Crowd Counting: Accurate people detection can increase management efficiency in public transportation by marking areas with high congestion or signaling areas that need more attention. Moreover, estimation of crowds in underground transit systems can be used to give passengers a good estimate of the waiting time in a queue. Multiple solutions to automate the crowd-counting process have been proposed, including solutions from a moving platform (e.g., camera on a bus) <ref type="bibr" target="#b107">[108]</ref> that analyze the optic flow generated from the moving objects and the moving platform.</p><p>Researchers have identified crowd counting to be often highly sensitive to training data <ref type="bibr" target="#b108">[109]</ref>, and in these cases, algorithms or crowd density classifiers <ref type="bibr" target="#b109">[110]</ref> will greatly benefit from having a realistic and robust training data set. However, new techniques for creating human crowd scenes are continuously being developed, particularly due to the growing demand from the motion picture industry <ref type="bibr" target="#b110">[111]</ref>. Simulated crowds have widely been studied in many application domains, including emergency response <ref type="bibr" target="#b111">[112]</ref> and large-scale panic situation modeling <ref type="bibr" target="#b112">[113]</ref>, <ref type="bibr" target="#b113">[114]</ref>; perhaps, simulated crowds <ref type="bibr" target="#b114">[115]</ref> or flow models could also potentially offer visual surveillance researchers a new way to efficiently generate training data. Solutions using fixed cameras that use standard imageprocessing techniques can be separated into two types: The first type uses an overhead camera, which contains "virtual gaits" that count the number of people crossing a predetermined area. Clearly, segmentation of a group of people into individuals is necessary for this purpose <ref type="bibr" target="#b115">[116]</ref>. The second type attempts to count pedestrians using people detection and crowd segmentation algorithms. In the overhead camera scenario, many difficulties that arise with traditional side-view surveillance systems are rarely present. For example, overhead views of crowds are more easily segmented, since there is likely a space between each person, whereas the same scenario from a side-view angle could incorrectly be segmented as one continuous object. When strictly people counting, some surveillance cameras are placed at bottlenecked entrance points, where at most one person at any given time is crossing some predetermined boundary (such as a security checkpoint or an access gate at a subway terminal). However, a potential drawback is that overhead views are prone to tracking errors across several cameras (unless two cameras are operating in stereo) since human descriptors for overhead views are only reliable for a small number of pedestrians <ref type="bibr" target="#b116">[117]</ref>. Hence, using multiple cameras may further complicate crowd counting. In cases where overhead surveillance views are not available, side-view cameras must be used to count people, and the multiple problems associated with this view (e.g., crowd segmentation and occlusion) come into play. In the case of crowd segmentation, some solutions that have been proposed include shape indexing, face detection, skin color, and motion <ref type="bibr" target="#b117">[118]</ref>, <ref type="bibr" target="#b118">[119]</ref>. However, most of these methods heavily rely on image quality and frame rate for accurate results. Shape indexing and skin colors are considered robust to poor video quality, whereas motion and face detection are most dependent on video quality. Occlusion is another problem, since all or part of a person may be hidden from view. Some techniques try to mitigate this issue by detecting only heads <ref type="bibr" target="#b119">[120]</ref> or omegashaped regions formed by heads and shoulders <ref type="bibr" target="#b120">[121]</ref>.</p><p>3) Crowd Behavior: Crowd behavior analysis has drawn significant interest from researchers closely working with the transit domain <ref type="bibr" target="#b121">[122]</ref>. A recent survey <ref type="bibr" target="#b122">[123]</ref> focused on crowd analysis methods employed in image processing. The flow of large human crowds <ref type="bibr" target="#b106">[107]</ref> is a useful cue for human operators in real-time behavior detection, such as diverging crowd flow and obstacles. Flow cues can be used reactively by human operators to efficiently deal with accidents or preventively to timely control situations that potentially could lead to graver incidents. Recent crowd behavior analysis methods include tracking of moving objects <ref type="bibr" target="#b123">[124]</ref>, motion models using optical flow <ref type="bibr" target="#b124">[125]</ref>- <ref type="bibr" target="#b127">[128]</ref>, and crowd-density measurement using back-ground reference images <ref type="bibr" target="#b128">[129]</ref>. A related surveillance problem consists of identifying specific individual events in crowded areas <ref type="bibr" target="#b129">[130]</ref>, in which motion from other objects in the scene will cause significant clutter under which algorithms might fail. Detecting particular behaviors based on crowd analysis (e.g., panic, fighting, and vandalism) is a new research direction for projects like SEcuRization KEeps Threats (SERKET) <ref type="bibr" target="#b130">[131]</ref>, which has recently been funded by the European Union to create methods to analyze crowd behaviors and aid in the fight against terrorism. Common abnormal crowd characteristics that have been researched are fallen person, blocked exit, and escape panic <ref type="bibr" target="#b124">[125]</ref>- <ref type="bibr" target="#b126">[127]</ref>. Behavior classification is often based on the vector fields generated by crowd motion instead of individual person tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Human Pose Estimation (Stance Change):</head><p>In transit surveillance applications, human pose estimation refers to the pose of the entire human body (e.g., going from standing to lying down in a metro is an indication of pedestrian collapse), and not a pose related to a single body part, such as a head pose, that can be used in applications such as driving monitoring <ref type="bibr" target="#b131">[132]</ref>. However, keeping track of multiple body parts is often useful to estimate the global body poses. In fact, there are two main approaches to estimating the body pose. The first approach calculates ratios between the height and the width of the bounding box around a detected human. In <ref type="bibr" target="#b132">[133]</ref>, vertical and horizontal projection templates are used to detect standing, crawling/bending, lying down, and sitting. The second approach attempts to track specific joints and body parts <ref type="bibr" target="#b133">[134]</ref>, <ref type="bibr" target="#b134">[135]</ref>, both because they are useful for indicating the human pose and because, when accurately modeled, they can be used to recover the pose even after occlusion and other common tracking failures <ref type="bibr" target="#b135">[136]</ref>. Due to self-occlusion and background clutter, some approaches also use the motion generated from each body part as a feature for pose change <ref type="bibr" target="#b136">[137]</ref>, since movements from each joint are shown to be interdependent. In <ref type="bibr" target="#b137">[138]</ref>, the observed motion is compared with registered motion exemplars, whereas action models are used to estimate possible future poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multiple-Person Interactions</head><p>Multiple-person interactions have largely been motivated by the growing demand for recognizing suspicious activities in security and surveillance applications. In <ref type="bibr" target="#b138">[139]</ref>, the behavior detection process consists of foreground segmentation, blob detection, and tracking. Semantic descriptions of suspicious human behaviors are defined through groups of low-level blobbased events. For example, fights are defined as many blobs' centroid moving together, merging and splitting, and overall fast changes in the blobs' characteristics. Attacks are defined as one blob getting too close to another blob, with one blob perhaps being initially static, and one blob erratically moving apart. Large projects like Computer-assisted Prescreening of Video Streams or Unusual Activities (BEHAVE) (2004-2007) <ref type="bibr" target="#b139">[140]</ref> and Context Aware Vision using Image-based Active Recognition (2002-2005) <ref type="bibr" target="#b140">[141]</ref> have each produced several publications focusing on multiple-person interactions. Algorithms include the use of a nearest neighbor classifier based on trajectory information <ref type="bibr" target="#b141">[142]</ref> to detect human interactions such as walking together, approaching, ignoring, meeting, splitting, and fighting; Bayesian networks <ref type="bibr" target="#b142">[143]</ref>; and moment-invariant feature descriptions <ref type="bibr" target="#b143">[144]</ref> to detect events, including sitting down, standing up, bending over, getting up, walking, hugging, bending sideways, squatting, rising from a squatting position, falling down, jumping, punching, and kicking. Often, performance relies on the ability to accurately segment and separate multiple human motions. Multiple free-form blobs and course models of the human body were used in a twoperson interaction in <ref type="bibr" target="#b144">[145]</ref>, which used a hierarchical Bayesian network to recognize human behaviors based on body part segmentation and motion. This work was extended <ref type="bibr" target="#b145">[146]</ref> to track multiple body parts of multiple people. Processing at three levels (pixel, blob, and object) was used to distinguish punching, handshaking, pushing, and hugging. A technique that does not use temporal motion information but instead uses pose is discussed in <ref type="bibr" target="#b146">[147]</ref>. By using a string matching method using a K-nearest neighbor approach, the authors were able to classify shaking hands, pointing, standing hand in hand, and the intermediate transitional states between these events.</p><p>Exchanging objects between persons is a common security concern in airports and other transit scenarios. In <ref type="bibr" target="#b147">[148]</ref>, backpack exchanging is detected based on shape analysis of each person. First, a person is detected to be carrying or not carrying a backpack or any other object. Then, the object is segmented and tracked for possible future exchanges between people. The involuntary exchanging of objects such as pickpocketing is discussed in <ref type="bibr" target="#b148">[149]</ref>, and a real-time implementation of this behavior can be found in <ref type="bibr" target="#b149">[150]</ref>. Other methods have extended the concept of "objects left behind" to analyze higher level information <ref type="bibr" target="#b188">[190]</ref> of objects being "switched," i.e., changing hands. A noncontact hand gesture between people such as waiving was studied in <ref type="bibr" target="#b129">[130]</ref>. This event was based on the localization of spatiotemporal patterns of each human motion and uses a shape-and-flow matching algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Person-Vehicle Interactions</head><p>In general, transit systems involve surveillance of motorized vehicles and humans. Spatiotemporal relationships between people and vehicles for situational awareness <ref type="bibr" target="#b150">[151]</ref> are the basis for analysis of "the big picture." However, operationally relevant behavior detection (e.g., human breaking in or vandalizing a car) has yet to be addressed in the research literature. As mentioned before, the focus of interest for this survey is human behavior recognition; however, for completeness, this following section provides a short general overview on vehicle visual surveillance. For a complete review of on-road vehicle detection systems, see <ref type="bibr" target="#b151">[152]</ref>.</p><p>Most existing automated vehicle surveillance systems are based on trajectory analysis. Detected events are abnormal low-frequency ones (e.g., U-turns, sudden brake, and pedestrians trespassing the street) <ref type="bibr" target="#b152">[153]</ref>, <ref type="bibr" target="#b153">[154]</ref> or a small group of predefined events, such as accidents <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b155">[156]</ref>, illegal parking <ref type="bibr" target="#b156">[157]</ref>, congestion status <ref type="bibr" target="#b157">[158]</ref>, illegal turns, or lane driving <ref type="bibr" target="#b158">[159]</ref>. Events of interest are commonly learned using expectation-maximization <ref type="bibr" target="#b159">[160]</ref> or modeled using semantic rules <ref type="bibr" target="#b160">[161]</ref> similar to the human interpretation of such events and validated using existing data. Trajectory-based approaches have been the subject of significant study, particularly in the traffic analysis domain. Common approaches to trajectory analysis are based on Kalman filter <ref type="bibr" target="#b161">[162]</ref>, <ref type="bibr" target="#b162">[163]</ref>, dynamic programming <ref type="bibr" target="#b163">[164]</ref>, and hidden Markov models <ref type="bibr" target="#b159">[160]</ref>. Discrete behavior profiling has been proposed <ref type="bibr" target="#b164">[165]</ref> to avoid tracking difficulties associated with occlusion and noise. There is significant research done in domain-independent anomaly behavior detection <ref type="bibr" target="#b165">[166]</ref>, <ref type="bibr" target="#b166">[167]</ref>, as well as events based on group activities <ref type="bibr" target="#b164">[165]</ref>. Transit surveillance involves many subproblems, including classification of different types of vehicles <ref type="bibr" target="#b167">[168]</ref>- <ref type="bibr" target="#b169">[170]</ref>, vehicle recognition <ref type="bibr" target="#b170">[171]</ref>, or discrimination between vehicles and other frequent objects <ref type="bibr" target="#b171">[172]</ref>, such as pedestrians, bicycles, buses, cars, pickups, trucks, and vans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Person-Facility/Location Interactions 1) Intrusion or Trespassing:</head><p>Intrusion or trespassing is defined as the presence of people in a forbidden area. A forbidden area can also be defined in terms of time (e.g., after hours) or spatial relationships (e.g., a pedestrian walking close to the train platform edge or walking on the rails). A large number of intrusion detection algorithms rely on the use of a digital "trip wire." A trip wire is typically a line drawn over the image, which separates regions into "allow" and "do not allow" areas. In <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, and <ref type="bibr" target="#b22">[23]</ref>, whenever a bottom corner of the bounding rectangle of an object intersects this line (rails in a subway), an intrusion is detected, and a warning is given. The warning stops when both corners of the rectangle come back to the allowed area. Intrusion detection is necessary to detect suicidal behaviors, such as people jumping on the train tracks. To reduce false positives, often, the blob needs to be tracked over time for a given number of frames after intrusion. To mitigate strong illumination changes, edges can be used in the motion extraction process <ref type="bibr" target="#b172">[173]</ref>. Trespasser hiding <ref type="bibr" target="#b138">[139]</ref> can be defined as a blob disappearing in many consecutive frames with the blob's last centroid position not close to an area previously defined as a possible "exit area." Access time and motion trajectory have also been shown to be useful for intrusion violation detection using hidden Markov models <ref type="bibr" target="#b173">[174]</ref>.</p><p>Another security-sensitive activity similar to intrusion is tailgating (i.e., illegal piggyback entry). Tailgating is a topic that has not received much attention in research but has been implemented in many commercial systems. Rather than strictly detecting an intrusion past a trip wire, illegal entry can occur when a human gains access through a door or gate by staying close to the person or car in front of him, sometimes without the knowledge of the authorized person.</p><p>2) Wrong Direction: Wrong direction occurs when an object is moving in a restricted direction. Typical examples of this behavior are people or crowds breaching security checkpoints at airports and subways or cars driving in wrong traffic lanes. In general, algorithms used to detect wrong direction heavily rely on a tracking algorithm, since successful tracking allows the movement of the object to easily be estimated and later compared with acceptable motion vectors <ref type="bibr" target="#b174">[175]</ref>. In some scenarios, the overall crowd characteristics, which do not rely on the tracking of individual objects, may be sufficient <ref type="bibr" target="#b106">[107]</ref>. For instance, the movement of large groups of people in an uncommon direction may indicate panic or danger. To entirely automate the process, motion vectors can be calculated in conjunction with a GMM to learn the correct directional patterns of traffic in the scene <ref type="bibr" target="#b175">[176]</ref>.</p><p>3) Vandalism: Vandalism is defined in <ref type="bibr" target="#b138">[139]</ref> as irregular centroid motion of a blob, combined with detected changes in the background. This definition is also implemented in <ref type="bibr" target="#b176">[177]</ref> when a blob enters a scene and causes changes in the background or predefined "vandalisable" areas. In <ref type="bibr" target="#b177">[178]</ref>, vandalism is detected in unmanned railway environments using a neural net by detecting erratic or strange behaviors of a single person or a group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Object Stationarity (Object Removal and Object Left Behind):</head><p>In this survey, object stationarity exclusively refers to nonanimated objects. In transit surveillance systems, objects left behind usually represent suspicious or potentially dangerous elements (e.g., a suitcase and a backpack). Detection of dangerous objects is a critical task that leads to safety and security of the passengers. In 2004 and 2006, object stationarity was one of the events targeted by PETS. Most algorithms presented a simple background subtraction method to find stationary objects that were not present before. Many other methods have been proposed to deal with objects left behind or removed. In <ref type="bibr" target="#b178">[179]</ref>, an edge matching algorithm is used, which compares the current frame to the background model to detect objects removed or left behind. In <ref type="bibr" target="#b20">[21]</ref>, a block-based matching algorithm is used to detect stationarity. Each video frame is separated into blocks and classified as background or foreground using frame differences with respect to the training phase. If at any given time a foreground block is not moving, it is then considered to be stationary. There is still quite a lack of research in terms of object stationarity in the context of crowded areas, but researchers <ref type="bibr" target="#b179">[180]</ref> have admitted this weakness and mentioned ways to include crowd segmentation algorithms to improve stationarity detection performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. STATE-OF-THE-ART DISCUSSION</head><p>AND FUTURE DEVELOPMENTS Future developments mentioned in the previous survey <ref type="bibr" target="#b2">[4]</ref> include multimodal data fusion, robust occlusion handling, usage of 3-D data, and usage of personal identification. In this section, additional potential directions of work are explored. In addition, an analysis of the current state-of-the-art behavior understanding algorithms is presented. Research weaknesses are identified, and possible solutions are discussed. The surveyed papers in Table <ref type="table" target="#tab_2">III</ref> offer an indication to the level of interest in this research area. As shown in Fig. <ref type="figure" target="#fig_4">6</ref>, it is clear that behavior recognition is an active research topic. In fact, there have been three times as many publications in the last three years than the number of all publications found before 2005.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Core Technology Limitations</head><p>Human behavior algorithms heavily rely on the available core technology. There are many limiting factors to the usability of these core technologies in real transit systems. Implementing analytics on some videos may not be feasible or could be restricted to only a subset of the available algorithms. There are many hardware-related problems such as poor resolution, low frame rates, or insufficient processing hardware. For instance, crowd-monitoring algorithms usually rely on the calculation of optical flow, which requires a moderately high frame rate and significant processing power. In fact, optical flow often requires special hardware if a real-time solution is needed <ref type="bibr" target="#b2">[4]</ref>. In this survey, we separate algorithms in terms of processing speed into two groups, namely, real time and offline processing (see Table <ref type="table" target="#tab_2">III</ref>). Nevertheless, in the last decade, the imageprocessing community in this context agrees that the definition of real time is not clear, although many researchers use it in their systems <ref type="bibr" target="#b6">[7]</ref>. This point brings the biggest concern to create an accurate assessment of core technology limitations: the lack of independent studies that compares behavior detection performance in transit environments with a common set of data set and metrics. For instance, although significant progress has been made in object tracking in the last decade, tracking methods usually rely on assumptions that often overly simplify the real problem. Assumptions such as smoothness of motion, limited occlusion, illumination constancy, and high contrast with respect to background <ref type="bibr" target="#b72">[73]</ref> effectively limit the algorithms' usability in real scenarios within the transit-surveillance domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Framework</head><p>Robust evaluation of automatic computer-vision methods is a complicated task. Standard baseline algorithms are required for comparison purposes. These baseline algorithms are usually well known to computer scientists working in related areas of research. However, there are no accepted baseline algorithms in behavior recognition for transit applications. Surprisingly, a few papers in Table <ref type="table" target="#tab_2">III</ref> formally compare performance against any other related work, making behavior-detection algorithm comparison scarce in the literature. Dealing with new detection tasks that have not previously been studied will clearly require baselines to be developed. In any case, the use of well-known and standard low-level processing techniques is a must. A meaningful study must compare performance with techniques that are likely to work under most circumstances, rather than compare with techniques likely to fail under the scope of interest. Transit data are far from common as are the problems that come along with them. On top of typical problems faced in vision-based surveillance applications, the transit domain faces particularly difficult problems, including poor illumination with drastic lighting changes (e.g., underground stations and tunnels) and heavily crowded scenes. In outdoor transit, weather can also have a significant impact on the quality of the data. A previous study on capturing human motion, which compares over 130 papers, found algorithms to be heavily constrained to assumptions <ref type="bibr" target="#b6">[7]</ref> related to movement, environments, and subjects. Nearly a decade later, algorithms still rely on many of the same assumptions. The problem is that performance under these situations is not well specified in the literature. In transit environments, particular concerns are assumptions of camera motion, camera parameters, field of view, background complexity, landmarks, lighting and weather conditions, crowd density,  number and severity of occlusions, subject initialization or a priori information (e.g., known pose, movement, and tightfitting clothes), and variability of motion patterns. Going back to a point made earlier, there is a lack of independent studies that attempt to describe the effect of these problems in different transit scenarios; therefore, it is unclear how behavior detection algorithms and commonly used low-level processing methods are affected by some of these domain-specific problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Standard Terminology</head><p>It is often assumed that crowds will be evenly distributed across the available space. However, that is not necessarily the case in transit areas such as a metro platform, where people are "competing" for space to ensure they get on the next train. The occupancy capacity of a given area depends on the pertinent licensing authority (e.g., fire or police department and emergency agency). For example, in U.K., the Communities and Local Government regulations set the limit occupancy for a bar [181] to 0.3-0.5 m 2 per person, but the same regulations do not apply to shopping malls. In image processing, to find a common ground for publications and experimental results, sometimes, it is necessary to use standard operational definitions. In <ref type="bibr" target="#b108">[109]</ref> and <ref type="bibr" target="#b180">[182]</ref>, definitions based on current practical safety guidelines are used. For example, very low density is defined as people/m 2 &lt; 0.5, whereas very high density is defined as people/m 2 &gt; 2. Other studies use less mathematically precise definitions such as "Overcrowding occurs when too many people congregate within a certain location. Congestion is a situation where it becomes difficult for an individual to move within a crowded area" <ref type="bibr" target="#b20">[21]</ref>. A common approach is to describe a crowd in terms of the number of individuals in it, like in <ref type="bibr" target="#b31">[32]</ref>, where authors define "very low density (0-15 people), low density (16-30 people), moderate density (31-45 people), high density (46-60 people), and very high density (more than 60 people)." Clearly, comparing related work dealing with "crowds" becomes extremely complicated since there is no widely accepted standard way to define crowd levels in the literature. Additionally, it is hard to identify methods that directly refer to similar data sets in terms of crowd density. Fig. <ref type="figure">7</ref>. Data set description analysis based on 52 transit surveillance-related papers surveyed in this paper. "None" refers to papers that include no reference to the data set used. "Complete" indicates that a full description is included, i.e., quantity and pixel resolution for both training and testing data. "Incomplete" indicates that there is some description but not enough to account for "Complete."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Data Sets</head><p>This survey has found across the literature the tendency to not fully specify the data set used. As shown in Fig. <ref type="figure">7</ref>, most papers, regardless of the review process, chose to not completely disclose the data set description of their work. Clearly, this information is necessary when showing the significance of an algorithm and understanding their results. Moreover, relative improvements over other previously reviewed publications may be hard to quantify since a comparison of the data sets cannot be made. Consequently, it is often unclear what level of empirical validation is behind published techniques. An advantage of using similar or common data sets is that performance scores from different algorithms can directly be compared, as long as the evaluation framework is comparable. However, in general, transit security data are hard to come by, due to the difficulty of gathering an adequate supply of valid video sequences containing operationally relevant events <ref type="bibr" target="#b138">[139]</ref>, and overcome privacy and security concerns <ref type="bibr" target="#b191">[193]</ref>. Initiatives like TREC Video Retrieval Evaluation <ref type="bibr" target="#b181">[183]</ref> encourage research by providing large data set collections and uniform scoring procedures. Efforts like this will be required as organizations become interested in comparing behavior detection reliability and results. Nevertheless, some authors using available data sets report concrete results only on very small portions of the data set but make reference of general testing on the entire data. Other authors refer to algorithms being able to work without any level of detail on performance, which does not offer researchers in the field with any meaningful performance information. In this survey, we found these to be common problems in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Distributed Surveillance</head><p>Distributed surveillance systems are networks of sensors that can be spread over large regions. Often, a single view of a transit scene could be insufficient to determine certain complex human behaviors. Large networks of cameras and other sensors could interact to form a "bigger picture," which can potentially offer a viable solution to complex problems. Many transit systems have large sensor networks (e.g., audio, video, motion sensors, and smoke detectors) already in place. Under such scenarios, multiple sensors can be used to generate more accurate, complete, and dependable data. For example, camera networks can be used to provide multiple views of a scene, which might diminish the number of tracking occlusions <ref type="bibr" target="#b182">[184]</ref>. In addition, sensors can often overcome weaknesses of other sensors; for example, fusing color and infrared video can be used to improve tracking through occlusions <ref type="bibr" target="#b183">[185]</ref>. However, there is not much work reported on the integration of different types of sensors in automated video surveillance systems <ref type="bibr" target="#b4">[5]</ref>. Multimodal fusion, such as audio and video <ref type="bibr" target="#b184">[186]</ref> or infrared and stereovision <ref type="bibr" target="#b185">[187]</ref>, can potentially offer better scene understanding, thereby improving situational awareness and response time. For general distributed surveillance, see a detailed survey in <ref type="bibr" target="#b4">[5]</ref> for more information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Aerial Surveillance</head><p>Moving cameras and mobile surveillance platforms have yet to become an important player in transit surveillance. With much research and commercial interest in UAVs and mobile surveillance platforms, current solutions are not far from being usable as an efficient surveillance platform for transit networks. Early works using surveillance video from UAVs <ref type="bibr" target="#b193">[195]</ref>, <ref type="bibr" target="#b194">[196]</ref> describe behavior analysis algorithms for low-resolution vehicles to monitor roadblock checkpoints (e.g., avoiding, passing through, and getting closer). As aerial surveillance has gained increased interest within the research community, authors have proposed techniques to detect low-resolution vehicles <ref type="bibr" target="#b195">[197]</ref> and buildings <ref type="bibr" target="#b196">[198]</ref> from aerial images. As surveillance techniques using image-processing algorithms are created to be used on aerial platforms, tracking-based methods often used in current transit applications will likely have problems with aerial video. Tracking systems have problems with objects following broken trajectories resulting from limited field of view and occlusion due to terrain features. Recent work is being driven by these problems, leading to solutions for problems such as the study of global motion patterns <ref type="bibr" target="#b197">[199]</ref> from aerial video. As resolution and video quality increases, transit surveillance, including people, vehicles, and behavior analysis, is logically the next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Commercial Systems</head><p>There are many commercial system providers who offer visual surveillance solutions for residential, commercial, government, and law enforcement agencies. Most modern systems now include video analytics software useful for automatic behavior recognition. Moreover, the actual storage of the video is significantly reduced if recording is performed only when an alarm is triggered by one of such behaviors. Customers are also able to specify defining attributes of moving objects, such as shape and speed, to provide means to efficiently search large video databases. Along with a visual cue on a security monitor, other common features include automatic e-mail or text messaging to cell phones or personal display assistants when alarms are triggered. In addition, geocoded mapping tools combined with real-time communication allow key personnel to further investigate the alarms. Table <ref type="table" target="#tab_3">IV</ref> shows a summary of existing commercial systems, including current general behavior detection capabilities. Capabilities are based on information advertised by vendors in their websites as in April 2009. Due to the broad terminology used by different providers, we based behavior labels on the most common names found. In Table <ref type="table" target="#tab_3">IV</ref>, crowd analysis refers to any analytics that targets crowds in general; thus, it would include events like people counting, crowd density, and queue length monitoring.</p><p>As capabilities advertised by commercial providers increase, the necessity for an independent evaluation of such capabilities becomes increasingly more prominent. Currently, there are no published efforts in the literature or independent data that can sustain the providers' claims. Furthermore, it is not clear how typical problematic conditions of mass transit systems, such as heavy traffic, crowded areas, detrimental weather effects, and drastic illumination changes, could affect performance. Additionally, without independent verification studies, there is no way to determine strict technical terminology commonality, and therefore, we could not compare performance across platforms. In other words, we have no idea which system (vendor) will perform better using a given set of requirements. Let us consider detection of the loitering behavior as an example. Looking at Table IV, almost two thirds of vendors advertised loitering detection capabilities. Let us take into account that, as discussed earlier in this paper, we describe that, in <ref type="bibr" target="#b59">[60]</ref>, loitering is detected over long periods of time, including likely situations of subjects leaving the scene or being frequently occluded. However, it is unclear that any of the systems listed in this table can achieve the same results as in <ref type="bibr" target="#b59">[60]</ref>. In fact, based on direct discussions with some vendors, it was made clear that systems, in general, have significant limitations with respect to camera placement, image quality and resolution, lighting conditions, occlusions, object contrast and stationarity, and weather.</p><p>V. CONCLUSION Public transit agencies are under mounting pressure to provide a safe and secure environment for their passengers and staff on their buses, light-rail, subway systems, and transit facilities. Transit agencies are increasingly using video surveillance as a tool to fight crime, prevent terrorism, and increase the personal safety of passengers and staff. Visual surveillance for transit systems is currently a highly active research area in image processing and pattern recognition. The number of research papers published in the last three years outnumbers the rest of the previous related literature threefold. This survey presented an overview of the state-of-the-art developments on behavior recognition algorithms for transit visual surveillance applications. A literature sample of 52 papers was used to study state-of-the-art strengths and weaknesses. Analysis includes behaviors, data sets, and implementation details. A classification strategy is presented that separates these papers by the targeted human behavior. The behavior groups are as follows: 1) single person or no interaction (i.e., behaviors exhibited by a single person that does not interact with any other person or vehicles); 2) multiple-person interactions; 3) person-vehicle interactions; and 4) person-facility/location interactions.</p><p>In this survey, a brief overview of the core technologies (i.e., all preprocessing steps before behavior recognition) has been included. There are many well-known limitations in the core technologies that need to be addressed. Techniques are often sensitivity to poor resolution, frame rate, drastic illumination changes, detrimental weather effects, and frequent occlusions, among other common problems prevalent in transit surveillance systems. Consequently, improved core technology algorithms are needed to increase the reliability of human behavior recognition. Over the last decade, numerous methods for evaluating core technologies have been proposed. However, there are no standard evaluation methods for human behavior recognition. Creating standard evaluation tools includes defining a common set of terminology and generating operationally similar data sets. For example, a bus and a metro can both be "crowded." However, operationally, the "crowds" in both situations are very different. Thus, without a standard precise definition of "crowd," formal comparisons become a very difficult task.</p><p>There are vast amounts of untapped information present in surveillance video footage, which can be exploited for automatic behavior detection. However, there is still a big gap in analytical skills between a typical security guard and stateof-the-art image-processing algorithms. On the other hand, there is a never-ending struggle to increase security personnel effectiveness over long periods of time while reducing labor costs. Many think of computer technology as the only solution that is able to close that gap.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Paper organization flowchart.</figDesc><graphic coords="3,52.44,69.82,230.88,224.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Sample single-person or no interaction behavior. Suspicious person (marked with an ellipse) loitering for a long period of time without leaving in a bus.1   </figDesc><graphic coords="5,307.95,282.82,245.88,89.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Sample multiple-person interaction behavior. Pedestrians on a crosswalk. 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 . 3 Fig. 5 .</head><label>435</label><figDesc>Fig. 4. Sample person-vehicle interaction. Person being run over by a vehicle. 3</figDesc><graphic coords="6,39.73,290.83,246.12,98.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Increasing interest on human behavior recognition research is shown through a comparison of a number of papers published up to 2008.</figDesc><graphic coords="12,44.23,70.30,236.52,143.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="2,41.73,92.90,241.68,224.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="13,95.94,93.41,406.92,258.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I RELATED</head><label>I</label><figDesc>LITERATURE SURVEY SUMMARY</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II EXPERIMENTAL</head><label>II</label><figDesc>RESULTS AS STATED IN THEIR RESPECTIVE PUBLICATIONS (TP: TRUE POSITIVES;</figDesc><table /><note><p>FP: FALSE POSITIVES; ROC: RECEIVER OPERATING CHARACTERISTIC CURVE)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III PUBLICATIONS</head><label>III</label><figDesc>OF BEHAVIOR RECOGNITION ALGORITHMS APPLICABLE TO TRANSIT SURVEILLANCE SYSTEMS (O: DATA SET INCLUDES OUTDOOR DATA SETS; R: MENTIONS A REAL-TIME IMPLEMENTATION; C: DATA SET INCLUDES CROWDED SCENES)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV BEHAVIOR</head><label>IV</label><figDesc>RECOGNITION SUMMARY ADVERTISED BY COMMERCIAL PROVIDERS IN THEIR WEBSITES</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Images courtesy of the Center for Distributed Robotics, University of Minnesota. Images are part of the data set used in<ref type="bibr" target="#b59">[60]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Images courtesy of the Computer Vision Laboratory, ETH Zurich. Images are part of the data set used in<ref type="bibr" target="#b85">[86]</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank D. Kelsey (Hart) and S. Godavarthy and W. Cheng (University of South Florida) for their involvement and support in the completion of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This work was supported in part by the Center of Urban Transportation and Research, University of South Florida, and the Florida Department of Transportation under Grant BD549-49. The Associate Editor for this paper was R. I. Hammoud. J. Candamo was with the</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Matthew Shreve (M'06) received the B.S. degree in computer science and the M.S. degree in mathematics from Youngstown State University, Youngstown, OH, in 2004 and 2006, respectively. He is currently working toward the Ph.D. degree in computer science and engineering with the University of South Florida, Tampa.</p><p>His research interests include computer vision, image processing, pattern recognition, and artificial intelligence applied to facial motion analysis and surveillance applications. Mr. Shreve has served on organizing committees for international conferences on both abstract mathematics and computer science. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.mta.info" />
		<title level="m">Official website for Metropolitan Transportation Authority</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How effective is human video surveillance performance?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sanocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldgof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on visual surveillance of object motion and behaviors</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="334" to="352" />
			<date type="published" when="2004-08">Aug. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intelligent distributed surveillance systems: A review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Inst. Elect. Eng.-Vision, Image Signal Process</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="192" to="204" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computational studies of human motion: Part 1, tracking and motion synthesis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Arikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ikemoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Comput. Graph. Vis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="77" to="254" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey of computer vision-based human motion capture</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Granum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="268" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A system for video surveillance and monitoring</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujiyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duggins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tolliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Enomoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wixson</surname></persName>
		</author>
		<idno>Rep. CMU-RI-TR-00-12</idno>
	</analytic>
	<monogr>
		<title level="j">Carnegie Mellon Univ</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Pittsburgh, PA, Tech</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Framework for performance evaluation of face, text, and vehicle detection and tracking in video: Data, metrics, and protocol</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldgof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garofolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boonstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Korzhova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="336" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Performance evaluation of object tracking algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Perform</title>
		<meeting>IEEE Int. Workshop Perform</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="733" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A novel method for video tracking performance evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rosin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Perform. Anal. Video Surveillance Tracking</title>
		<meeting>IEEE Int. Workshop Perform. Anal. Video Surveillance Tracking</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Performance evaluation metrics for objectbased video segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sankur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. X Eur. Signal Process. Conf</title>
		<meeting>X Eur. Signal ess. Conf</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="917" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Use of an evaluation and diagnosis method to improve tracking performances</title>
		<author>
			<persName><forename type="first">B</forename><surname>Georis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bremond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IASTED Int. Conf. Vis., Imaging Image Process</title>
		<meeting>IASTED Int. Conf. Vis., Imaging Image ess</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="827" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Performance evaluation of object detection algorithms</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Mariano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mihalcik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Drayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="965" to="969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Performance evaluation of surveillance systems under varying conditions</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hampapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Merkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Perform</title>
		<meeting>IEEE Int. Workshop Perform</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tools and techniques for video performances evaluation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mihalcik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="167" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance evaluation of a real time video surveillance system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Muller-Schneiders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Niem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Visual Surveillance Perform</title>
		<meeting>IEEE Int. Workshop Visual Surveillance Perform</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="137" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance evaluating the evaluator</title>
		<author>
			<persName><forename type="first">T</forename><surname>List</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Visual Surveillance Perform</title>
		<meeting>IEEE Int. Workshop Visual Surveillance Perform</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Performance evaluation of event detection solutions: The CREDS experience</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ziliani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marcenaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kelliher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bruneaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic detection of dangerous events for underground surveillance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Spirito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marcenaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A real time surveillance system for metropolitan railways</title>
		<author>
			<persName><forename type="first">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boghossian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Target segmentation and event detection at videorate: The EAGLE project</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schwerdt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bernas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Paul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="183" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Metro railway security algorithms with real world experience adapted to the RATP dataset</title>
		<author>
			<persName><forename type="first">C</forename><surname>Seyve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="177" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Performance Evaluation of Tracking and Surveillance official website</title>
		<ptr target="http://www.cvg.rdg.ac.uk/slides/pets.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluation of motion segmentation quality for aircraft activity surveillance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wildenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thirde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferryman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Visual Surveillance Perform</title>
		<meeting>IEEE Int. Workshop Visual Surveillance Perform</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="293" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PRISMATICA: Toward ambient intelligence in public transport environments</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Boghossian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P L</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Vicencio-Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="164" to="182" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Toward generic intelligent knowledge extraction from video and audio: The EU-funded CARETAKER project</title>
		<author>
			<persName><forename type="first">C</forename><surname>Carincotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Desurmont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ravera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bremond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Odobez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Corbucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cernocky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inst. Eng. Technol. Conf. Crime Security</title>
		<meeting>Inst. Eng. Technol. Conf. Crime Security</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="470" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Advisor-socket and see: Lessons learnt in building a real-time distributed surveillance system</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Attwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Distrib. Surveillance Syst</title>
		<imprint>
			<biblScope unit="page" from="6" to="11" />
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Passengers queue length measurement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Aubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Anal. Process</title>
		<meeting>IEEE Int. Conf. Image Anal. ess</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1132" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Time-scale change detection applied to real-time abnormal stationarity monitoring</title>
		<author>
			<persName><forename type="first">D</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guichard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bouchafa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Imaging</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="22" />
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Project CROMATICA</title>
		<author>
			<persName><forename type="first">L</forename><surname>Khoudour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Deparis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Bruyelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cabestaing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bouchafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Vicencio-Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wherett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Anal. Process</title>
		<meeting>IEEE Int. Conf. Image Anal. ess</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="757" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Estimation of crowd density using image processing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Marana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lotufo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Colloq</title>
		<meeting>IEEE Colloq</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="11" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A survey of motion analysis from moving light displays</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cedras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visual interpretation of hand gestures for human-computer interaction: A review</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="677" to="695" />
			<date type="published" when="1997-07">Jul. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic facial expression analysis: A survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fasel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luettin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="275" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visual modeling with a hand-held camera</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vergauwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Verbiest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="232" />
			<date type="published" when="2004-10">Sep./Oct. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Human tracking by particle filtering using full 3D model of both target and environment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Osawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wakabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yasuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dynamic background subtraction for object extraction using virtual reality based prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dominguez-Caneda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Urdiales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sandoval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MELECON</title>
		<meeting>MELECON</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="466" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">3-D time-varying scene capture technologies-A survey</title>
		<author>
			<persName><forename type="first">E</forename><surname>Stoykova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Alatan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Benzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Grammalidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malassiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ostermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Piekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sainov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thevar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zabulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1568" to="1586" />
			<date type="published" when="2007-11">Nov. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A real-time system for monitoring of cyclists and pedestrians</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heikkila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Silven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Visual Surveillance</title>
		<meeting>IEEE Workshop Visual Surveillance</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adaptive background mixture models for real-time tracking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stauffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="246" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Motion of disturbances: Detection and tracking of multi-body non-rigid motion</title>
		<author>
			<persName><forename type="first">G</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="897" to="902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">View-based detection and analysis of periodic motion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="495" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Wallflower: Principles and practice of background maintenance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krumm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Brumitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Meyers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="255" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Image change detection algorithms: A systematic survey</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Andra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Al-Kofahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roysam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="294" to="307" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Background modeling based on subpixel edges</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mundy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="321" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Robust background subtraction with foreground validation for urban traffic video</title>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kamath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Appl. Signal Process</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2330" to="2340" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Realtime scene stabilization and mosaic construction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Der Wal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Underst. Workshop</title>
		<meeting>DARPA Image Underst. Workshop</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An effective detection algorithm for moving object with complex background</title>
		<author>
			<persName><forename type="first">F.-Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf</title>
		<meeting>IEEE Int. Conf</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="5011" to="5015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Salient motion information detection technique using weighted subtraction image and motion vector</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zaijun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-B</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Hybrid Inf</title>
		<meeting>Hybrid Inf</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="263" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The robust estimation of multiple motions: Parametric and piecewise smooth flow fields</title>
		<author>
			<persName><forename type="first">M</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="104" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="185" to="203" />
			<date type="published" when="1981-08">Aug. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Underst</title>
		<meeting>DARPA Image Underst</meeting>
		<imprint>
			<publisher>Workshop</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Spline-based image registration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coughlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="218" />
			<date type="published" when="1997-04">Mar./Apr. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Performance of optical flow techniques</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Beauchemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Burkitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="236" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Shape based object classification for automated video surveillance with feature selection</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Hota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Venkoparao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajagopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Inf. Technol</title>
		<meeting>IEEE Int. Conf. Inf. Technol</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="97" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pedestrian detection in crowded scenes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Seemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="878" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Fast human detection using a cascade of histograms of oriented gradients</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1491" to="1498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Detection of loitering individuals in public transportation areas</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Papanikolopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Isaacs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="177" />
			<date type="published" when="2005-06">Jun. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Detection and monitoring of passengers on a bus by video surveillance</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Chee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lazarescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Anal. Process</title>
		<meeting>IEEE Int. Conf. Image Anal. ess</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="143" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The HumanID gait challenge problem: Data sets, performances, and analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="162" to="177" />
			<date type="published" when="2005-02">Feb. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">General methods and development actuality of gait recognition</title>
		<author>
			<persName><forename type="first">Y.-B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Wavelet Anal. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Wavelet Anal. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1333" to="1340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The visual analysis of human movement: A survey</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="98" />
			<date type="published" when="1999-01">Jan. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Motion-based recognition, A survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cedras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="155" />
			<date type="published" when="1995-03">Mar. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Human motion estimation and recognition (depth oral report)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. Toronto</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>Toronto, ON, Canada</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Face detection using multi-modal information</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Autom. Face Gesture Recog</title>
		<meeting>IEEE Int. Conf. Autom. Face Gesture Recog</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="14" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Human model for people detection in dynamic scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Harasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bonnaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Desvignes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="335" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">People tracking by integrating multiple features</title>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="929" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Pedestrian detection using boosted features over many frames</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Snow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Human detection using oriented histograms of flow and appearance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="428" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Special issue on: Sequential state estimation: From Kalman filters to particle filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Defreitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="399" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Object tracking: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">People tracking in surveillance applications</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1165" to="1171" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A framework for tracking target in a heterogeneous camera suite</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Control, Autom., Robot. Vis</title>
		<meeting>IEEE Int. Conf. Control, Autom., Robot. Vis</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Homography based multiple camera detection and tracking of people in a dense crowd</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eshel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Moses</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A mobile vision system for robust multi-person tracking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Human activities monitoring at bus stops</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Kernel-based object tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="564" to="577" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Long memory matching of interacting complex objects from real image sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tesei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Teschioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vernazza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Time Varying Image Process. Moving Objects Recog</title>
		<meeting>Conf. Time Varying Image ess. Moving Objects Recog</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="283" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Condensation conditional density propagation for visual tracking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="28" />
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Color-based probabilistic tracking</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vermaak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gangnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="661" to="675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Multi sensor based tracking of pedestrians: A survey of suitable movement models</title>
		<author>
			<persName><forename type="first">U</forename><surname>Scheunert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wanielik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intell. Vehicles Symp</title>
		<meeting>Intell. Vehicles Symp</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="774" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Multisensor Surveillance Systems: The Fusion Perspective</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Foresti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Varshney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Fusion of multiple tracking algorithms for robust people tracking</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Siebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Coupled detection and trajectory estimation for multi-object tracking</title>
		<author>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Statistical models of object interaction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Visual Surveillance</title>
		<meeting>IEEE Workshop Visual Surveillance</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="81" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Robust, real-time people tracking in open environments using integrated stereo, color, and face detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woodfill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Visual Surveillance</title>
		<meeting>IEEE Workshop Visual Surveillance</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Hierarchical language based representation of events in video steams</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hongeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog. Workshop</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog. Workshop</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">ARGMode-Activity recognition using graphical models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Vis. Pattern Recog. Workshop</title>
		<meeting>IEEE Comput. Vis. Pattern Recog. Workshop</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="38" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">An ontology for video event representation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Event Detection Recog</title>
		<meeting>IEEE Workshop Event Detection Recog</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">119</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">View-invariant representation and learning of human action</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Detection Recog. Events Video</title>
		<meeting>IEEE Workshop Detection Recog. Events Video</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Research on intelligent visual surveillance for public security</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACIS Int. Conf. Comput</title>
		<meeting>IEEE/ACIS Int. Conf. Comput</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="824" to="829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Human motion analysis: A review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="428" to="440" />
			<date type="published" when="1999-03">Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Articulated and elastic non-rigid motion: A review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sabata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Motion Non-Rigid Articulated Objects</title>
		<meeting>Workshop Motion Non-Rigid Articulated Objects</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">A Mathematical Theory of Evidence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shaffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Princeton Univ. Press</publisher>
			<pubPlace>Princeton, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Handling uncertainty in video analysis with spatiotemporal visual attention</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rapantzikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kollias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fuzzy Syst</title>
		<meeting>Fuzzy Syst</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="213" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Agent-oriented annotation in model based visual surveillance</title>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="857" to="862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A belief theory-based static posture recognition systems for real-time video surveillance applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Girondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caplier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bonnaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Automatic symbolic traffic scene analysis using belief networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Nat. Conf. Artif. Intell</title>
		<meeting>Nat. Conf. Artif. Intell</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="966" to="972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Deleted interpolation using a hierarchical Bayesian grammar network for recognizing human activity</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sugimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Visual Surveillance Perform</title>
		<meeting>IEEE Int. Workshop Visual Surveillance Perform</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Discovery and segmentation of activities in video</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Kettnaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="844" to="851" />
			<date type="published" when="2000-08">Aug. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">An adaptive scene description for activity analysis in surveillance video</title>
		<author>
			<persName><forename type="first">B</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Segmentation and classification of human activities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Marques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Human Activity Recog. Modeling</title>
		<meeting>Workshop Human Activity Recog. Modeling</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Automatic visual analysis for transportation security</title>
		<author>
			<persName><forename type="first">N</forename><surname>Haering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shafique</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Technol. Homeland Security</title>
		<meeting>IEEE Conf. Technol. Homeland Security</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Video content analysis with effective response</title>
		<author>
			<persName><forename type="first">D</forename><surname>Abrams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcdowall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Technol. Homeland Security</title>
		<meeting>IEEE Conf. Technol. Homeland Security</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="57" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A motionbased image processing system for detecting potentially dangerous situations in underground railway stations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Boghossian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Vicencio-Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. Part C: Emerging Technol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="96" to="113" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Crowd detection in video sequences</title>
		<author>
			<persName><forename type="first">P</forename><surname>Reisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intell. Vehicles Symp</title>
		<meeting>Intell. Vehicles Symp</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">On crowd density estimation for surveillance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rahmalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inst. Eng. Technol. Conf. Crime Security</title>
		<meeting>Inst. Eng. Technol. Conf. Crime Security</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="540" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Crowd density estimation using texture analysis and learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Biometrics</title>
		<meeting>IEEE Int. Conf. Robot. Biometrics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="214" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Implementation of crowd system in Maya</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. SICE-ICASE</title>
		<meeting>Int. Joint Conf. SICE-ICASE</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2713" to="2716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Crowd simulation for emergency response using BDI agent based on virtual reality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shendarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Son</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Winter Simul. Conf</title>
		<meeting>Winter Simul. Conf</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="545" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Emotional ant based modeling of crowd dynamics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Banarjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grosan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Symbolic Numeric Algorithms Sci</title>
		<meeting>Symbolic Numeric Algorithms Sci</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Simulation of large crowds in emergency situations including gaseous phenomena</title>
		<author>
			<persName><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Musse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf</title>
		<meeting>Int. Conf</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="206" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Crowd control with swarm intelligence</title>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3321" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Detecting and counting people in surveillance applications</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krahnstoever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="306" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Vision-based overhead view person recognition</title>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1119" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Fast crowd segmentation using shape indexing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zoghlami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Tracking and segmenting people with occlusions by a sample consensus based method</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="410" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Estimation of number of people in crowded scenes using perspective transformation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="645" to="654" />
			<date type="published" when="2001-11">Nov. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Estimating the number of people in crowded scenes by MID based foreground segmentation and head-shoulder detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Tracking all traffic: Computer vision algorithms for monitoring vehicles, individuals, and crowds</title>
		<author>
			<persName><forename type="first">B</forename><surname>Maurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Mag</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="36" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Crowd analysis: A survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Monekosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Vis. Appl</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5/6</biblScope>
			<biblScope unit="page" from="345" to="357" />
			<date type="published" when="2008-09">Sep. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Counting crowded moving objects</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="705" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Modeling crowd scenes for event detection</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blunsden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="175" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Hidden Markov models for optical flow analysis in crowds</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blunsden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="460" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Detection of emergency events in crowded scenes</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blunsden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inst. Eng. Technol. Conf. Crime Security</title>
		<meeting>Inst. Eng. Technol. Conf. Crime Security</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="528" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Performance analysis of event detection models in crowded scenes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blunsden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Towards Robust Visual Surveillance Techn</title>
		<meeting>Workshop Towards Robust Visual Surveillance Techn</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="427" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Image processing techniques for crowd density estimation using a reference image</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Asian Conf. Comput. Vis</title>
		<meeting>Asian Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="489" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Event detection in crowded videos</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Intelligent environments for problem solving by autonomous systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Antipolis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Institut National de Recherche en Informatique et en Automatique</title>
		<imprint>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2007">2007</date>
			<pubPlace>Rocquencourt, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Head pose estimation for driver monitoring</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fujimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intell. Vehicles Symp</title>
		<meeting>IEEE Intell. Vehicles Symp</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="501" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Shining a light on human pose: On shadows, shading and the estimation of pose and shape</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Haussecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Body part detection for human pose estimation and tracking</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Motion Video Comput</title>
		<meeting>Motion Video Comput</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Dynamic human pose estimation using Markov chain Monte Carlo approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Motion Video Comput</title>
		<meeting>Motion Video Comput</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="168" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Fast human pose estimation using appearance and motion via multi-dimensional boosting regression</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Comput. Vis. Pattern Recog</title>
		<meeting>Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Human pose estimation using motion exemplars</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">An efficient method for contour tracking using active shape models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Motion Non-Rigid Articulated Objects</title>
		<meeting>IEEE Workshop Motion Non-Rigid Articulated Objects</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="194" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Tracking-based event detection for CCTV systems</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="356" to="364" />
			<date type="published" when="2004-12">Dec. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<ptr target="http://homepages.inf.ed.ac.uk/rbf/BEHAVE/" />
		<title level="m">BEHAVE official website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<ptr target="http://groups.inf.ed.ac.uk/vision/CAVIAR/CAVIARDATA1/" />
		<title level="m">CAVIAR Project dataset</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Non parametric classification of human interaction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Blunsden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Iberian Conf. Pattern Recog. Image Anal</title>
		<meeting>3rd Iberian Conf. Pattern Recog. Image Anal</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">A Bayesian approach to human activity recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Visual Surveillance</title>
		<meeting>IEEE Workshop Visual Surveillance</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Moment invariants based human mistrustful and suspicious motion detection, recognition and classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Comput. Modeling Simul</title>
		<meeting>Comput. Modeling Simul</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="734" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Recognition of two-person interactions using a hierarchical Bayesian network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Video Surveillance</title>
		<meeting>Int. Workshop Video Surveillance</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="65" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Simultaneous tracking of multiple body parts of interacting persons</title>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Recognition of human interaction using multiple features in gray scale images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="51" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Backpack: Detection of people carrying objects using silhouettes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Haritaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Group behavior recognition with multiple cameras</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cupillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bremond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="177" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Design and assessment of an intelligent activity monitoring platform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brémond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tornieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Appl. Signal Process</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2359" to="2374" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Homography-based analysis of people and vehicle activities in crowded scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">51</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">On-road vehicle detection: A review</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="694" to="711" />
			<date type="published" when="2006-05">May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Abnormal event detection from surveillance video by dynamic hierarchical clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="145" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Abnormal event detection based on trajectory clustering by 2-depth greedy search</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal ess</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="2129" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Traffic monitoring and accident detection at intersections</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kamijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sakauchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="108" to="118" />
			<date type="published" when="2000-06">Jun. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Incident retrieval in transportation surveillance videos-An interactive framework</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Multimedia Expo</title>
		<meeting>IEEE Int. Conf. Multimedia Expo</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2186" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Real-time detection of illegally parked vehicles using 1-D transformation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="254" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">A real-time vehicle flow-measuring algorithm for complex urban intersection in the daytime</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf</title>
		<meeting>IEEE Int. Conf</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="934" to="938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Minimum-entropy models of scene activity</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kettnaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">A hidden Markov model framework for traffic event detection using video features</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2004">Oct. 24-27, 2004</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2901" to="2904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">An incident detection system based on semantic hierarchy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kamijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sakauchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int</title>
		<meeting>IEEE Int</meeting>
		<imprint>
			<date type="published" when="2004-03-06">Oct. 3-6, 2004</date>
			<biblScope unit="page" from="853" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Switching Kalman filter-based approach for tracking and event detection at traffic intersections</title>
		<author>
			<persName><forename type="first">H</forename><surname>Veeraraghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schrater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intell</title>
		<meeting>Intell</meeting>
		<imprint>
			<date type="published" when="2005">Jun. 27-29, 2005</date>
			<biblScope unit="page" from="1167" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Multiple-target tracking for crossroad traffic utilizing modified probabilistic data association</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal ess</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="921" to="924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Framework for real-time behavior interpretation from traffic video</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Weimin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sengupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="53" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Recognition of group activities using dynamic probabilistic networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="742" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Finding events automatically in continuously sampled data streams via anomaly detection</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Raeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bertke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Nat. Aerosp. Electron. Conf</title>
		<meeting>Nat. Aerosp. Electron. Conf</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Video behavior profiling for anomaly detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="893" to="908" />
			<date type="published" when="2008-05">May 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Commode: An algorithm for video background modeling and object segmentation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Control, Autom., Robot. Vis</title>
		<meeting>IEEE Int. Conf. Control, Autom., Robot. Vis</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1603" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Object tracking with Bayesian estimation of dynamic layer representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="89" />
			<date type="published" when="2002-01">Jan. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Detection and classification of vehicles for urban traffic scenes</title>
		<author>
			<persName><forename type="first">N</forename><surname>Buch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Visual Inf. Eng</title>
		<meeting>Int. Conf. Visual Inf. Eng</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="182" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Vehicle recognition for highway lane survey</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sidla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lypetskyy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Janner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Intell. Transp. Syst</title>
		<meeting>IEEE Int. Conf. Intell. Transp. Syst</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="531" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">High-level traffic-violation detection for embedded traffic analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Vijverberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A H M</forename><surname>De Koning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H N</forename><surname>De With</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cornelissen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="793" to="796" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Intrusion detection using extraction of moving edges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Makarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Vesin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="804" to="807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Time-dependent HMMs for visual intrusion detection</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kettnaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog. Workshop</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recog. Workshop</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Integration of color and shape for detecting and tracking security breaches in airports</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Abidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 38th Annu. Int. Carnahan Conf. Security Technol</title>
		<meeting>38th Annu. Int. Carnahan Conf. Security Technol</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="289" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Wrongway drivers detection based on optical flow</title>
		<author>
			<persName><forename type="first">G</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="141" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Real-time automatic detection of vandalism behavior in video sequences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst., Man, Cybern</title>
		<meeting>IEEE Int. Conf. Syst., Man, Cybern</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1056" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">A neural network-based image processing system for detection of vandal acts in unmanned railway environments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vernazza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Anal. Process</title>
		<meeting>IEEE Int. Conf. Image Anal. ess</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="529" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">An abandoned/removed objects detection algorithm and its evaluation on PETS datasets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spagnolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caroppo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Martiriggiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Orazio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Video Signal Based Surveillance</title>
		<meeting>IEEE Int. Conf. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">A knowledge-based approach for detecting unattended packages in surveillance video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Video Signal Based Surveillance</title>
		<meeting>IEEE Int. Conf. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">110</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<monogr>
		<title level="m" type="main">Crowd dynamics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Still</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Coventry, U.K.</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Math. Dept., Warwick Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<ptr target="http://www-nlpir.nist.gov/projects/trecvid/" />
		<title level="m">TREC Video Retrieval Evaluation official website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Collaborative multi-camera surveillance with automated person detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ahmedali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Can. Conf. Comput. Robot Vis</title>
		<meeting>IEEE Can. Conf. Comput. Robot Vis</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Geodesic active contour based fusion of visible and infrared video for persistent object tracking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bunyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seetharaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Workshop Appl. Comput. Vis</title>
		<imprint>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Fusing visual and audio information in a distributed intelligent surveillance system for public transport systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P L</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Autom. Sin</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="393" to="407" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Person surveillance using visual and infrared imagery</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Krotosky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1096" to="1105" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Detection of thrown objects in indoor and outdoor scenes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ribnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Atev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Voyles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intell. Robots Syst</title>
		<meeting>Intell. Robots Syst</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="979" to="984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Real time, online detection of abandoned objects in public areas</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Atev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Caramelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Autom</title>
		<meeting>IEEE Int. Conf. Robot. Autom</meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="page" from="3775" to="3780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">A new method for real time abandoned object detection and owner tracking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ferrando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3329" to="3332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Real-time detection of camera tampering</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ribnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Atev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Voyles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">A novel method for graffiti detection using change detection algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Angiati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Piva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveillance</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveillance</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="242" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Advanced surveillance: From tracking to event detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Latin America Trans</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="206" to="211" />
			<date type="published" when="2004-09">Sep. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Automatic measurement of crowd density and motion using image processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Vicencio-Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Allsop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Road Traffic Monitoring Control</title>
		<meeting>Int. Conf. Road Traffic Monitoring Control</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="127" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Event detection and analysis from video streams</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IUW</title>
		<meeting>IUW</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Event detection and analysis from video streams</title>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bremond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hongeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="873" to="889" />
			<date type="published" when="2001-08">Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Car detection in low resolution aerial images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="710" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Automatic description of complex buildings from multiple images</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="95" />
			<date type="published" when="2004-10">Oct. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Detecting global motion patterns in complex videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Pattern Recog</title>
		<meeting>Int. Conf. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<ptr target="http://www.agentvi.com/" />
		<title level="m">The official website for AgentVi</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<title level="m" type="main">The official website for Aimetis Corp</title>
		<ptr target="http://www.aimetis.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<title level="m" type="main">The official website for Cernium</title>
		<ptr target="http://www.cernium.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<ptr target="http://www.eptascape.com" />
		<title level="m">The official website for Eptascape</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title level="m" type="main">The official website for Honeywell</title>
		<ptr target="http://www51.honeywell.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<monogr>
		<title level="m" type="main">The official website for Indigo Vision</title>
		<ptr target="http://www.indigovision.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<monogr>
		<title level="m" type="main">The official website for Intelliview</title>
		<ptr target="http://www.intelliview.ca/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<monogr>
		<title level="m" type="main">The official website for Intellivision</title>
		<ptr target="http://www.intelli-vision.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">The official website for Ipsotek</title>
		<ptr target="http://www.ipsotek.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">March</forename><surname>Networks</surname></persName>
		</author>
		<ptr target="http://www.marchnetworks.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">[211] The official website for Object Video</title>
		<ptr target="http://www.objectvideo.com" />
	</analytic>
	<monogr>
		<title level="m">MATE Intelligent Video</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<monogr>
		<title level="m" type="main">The official website for Sightlogix</title>
		<ptr target="http://www.sightlogix.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<monogr>
		<ptr target="http://verint.com" />
		<title level="m">The official website Verint</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<monogr>
		<title level="m" type="main">The official website for Vidient</title>
		<ptr target="http://www.vidient.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<ptr target="http://www.nice.com/products/video/index.php" />
		<title level="m">The official website for Nice</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<monogr>
		<ptr target="http://www.ioimage.com" />
		<title level="m">Joshua Candamo received the Ph.D. degree in computer science from the University of South Florida</title>
		<meeting><address><addrLine>Tampa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>The official website of IoImage. He is currently the Chief Executive Officer of K9</note>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">he has taken the pet care industry to a new level of technology innovation. His main areas of research and technical publications are in the fields of image processing and pattern recognition</title>
		<author>
			<persName><forename type="first">Inc</forename><surname>Bytes</surname></persName>
		</author>
		<author>
			<persName><surname>Tampa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">K9 Bytes</title>
		<imprint/>
	</monogr>
	<note>which is a software solution provider for the pet care industry</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
