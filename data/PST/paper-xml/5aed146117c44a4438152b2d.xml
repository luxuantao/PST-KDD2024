<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">&quot;Accessibility Came by Accident&quot;: Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alisha</forename><surname>Pradhan</surname></persName>
							<email>alisha93@terpmail.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kanika</forename><surname>Mehta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information Studies</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leah</forename><surname>Findlater</surname></persName>
							<email>leahkf@uw.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Human Centered Design and Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">&quot;Accessibility Came by Accident&quot;: Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9B722E8AFB93CA8B5D82046EF077AE39</idno>
					<idno type="DOI">10.1145/3173574.3174033</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Intelligent personal assistants</term>
					<term>conversational interfaces</term>
					<term>speech</term>
					<term>accessibility</term>
					<term>disability H.5.m. Information interfaces and presentation (e.g., HCI) Disability-Related Search Terms Specified in Advance AAC, accessibility, accessible, ALS, Alzheimer, Alzheimer&apos;s, amnesia, amnestic, amputation, amputee, amyotrophic lateral sclerosis, aphasia, apraxia, arthritis, assistive technology, ataxia, augmentative communication, autism, autistic, blind, blindness, caregiver, cochlear implant, congenital amputation, congenital amputee, deaf, dementia, diabetic retinopathy, disabilities, disability, disabled, Down syndrome, dysarthria, dyslexic, dystonia, epilepsy, essential tremor, fibromyalgia, Friedreich ataxia, Friedreich&apos;s ataxia, glaucoma, handicap, handicapped, hard of hearing, hearing aid, hearing device, hearing loss, hemiplegia, hemiplegic, impaired, impairment, impairments, lateral sclerosis, lisp, Lou Gehrig&apos;s, macular degeneration, mobility, multiple sclerosis, muscular dystrophy, muscular rheumatism, myopathy, neurological disorder, neurological vision impairment, neuromuscular disorders, nursing home, paralysis, paralyzed, paraplegia, paraplegic, Parkinson, Parkinson&apos;s disease, Parkinsonism, quadriplegia, quadriplegic, sclerosis, seizure disorder, short term memory, sigmatism, SMA, speaking disorder, special needs, speech impediment, speech therapy, spinal bifida, spinal cord injury, spinal muscular atrophy, stroke, stutter, TBI, traumatic brain injury, tremor, tremors, vision, walker, wheelchair Bedridden, disease, injuries, injury, limited vision, no vision, non-verbal, nonverbal, poor vision, rehab, rehabilitation, surgeries, surgery</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>From an accessibility perspective, voice-controlled, homebased intelligent personal assistants (IPAs) have the potential to greatly expand speech interaction beyond dictation and screen reader output. To examine the accessibility of off-the-shelf IPAs (e.g., Amazon Echo) and to understand how users with disabilities are making use of these devices, we conducted two exploratory studies. The first, broader study is a content analysis of 346 Amazon Echo reviews that include users with disabilities, while the second study more specifically focuses on users with visual impairments, through interviews with 16 current users of home-based IPAs. Findings show that, although some accessibility challenges exist, users with a range of disabilities are using the Amazon Echo, including for unexpected cases such as speech therapy and support for caregivers. Richer voice-based applications and solutions to support discoverability would be particularly useful to users with visual impairments. These findings should inform future work on accessible voice-based IPAs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Voice-controlled intelligent personal assistants (IPAs), such as Amazon Echo and Google Home, have introduced a new interaction paradigm into the mainstream. These devices provide a conversational interface in the home to allow users to ask for and save information (e.g., check weather, add to a shopping list), control smart home appliances, and perform a range of online actions (e.g., shopping, banking).</p><p>From an accessible technology perspective, voicecontrolled IPAs offer the potential to apply speech input and output beyond the traditional confines of text dictation and screen reader software. A person with limited mobility, for example, can control their home's lighting or door locks by voice, while a blind user can ask for the time or weather. Due to their relatively recent introduction, however, researchers have only begun to understand how these devices are being used by the general population (e.g., <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32]</ref>), much less by users with disabilities. As such, our focus is to address exploratory questions such as: To what extent are off-the-shelf IPAs, which were not necessarily designed with accessibility in mind, accessible? How are people with disabilities making use of them? What design opportunities do these devices offer to further support everyday activities for users with disabilities?</p><p>To answer these questions, we conducted two studies. The first study broadly examined use of IPAs by people with disabilities, by collecting and analyzing online customer reviews of the Amazon Echo, a popular IPA, and its offshoots, the Echo Dot and Tap. We identified 346 reviews that described use of the device by a person with a cognitive, sensory, or physical disability, written either from a first-or third-person perspective. We conducted a content analysis of the reviews, qualitatively coding them along dimensions such as overall tone (positive/negative), uses of the device, and accessibility challenges. To complement these findings, we then conducted a second study to offer a more in-depth understanding of one specific subset of users: those with visual impairments. Here, we interviewed 16 participants with visual impairments who owned an Amazon Echo or Google Home device. The interview covered similar themes to the analysis of reviews.</p><p>Findings from both studies show that the new paradigm offered by voice-controlled IPAs offers tremendous potential for inclusive, accessible interaction. Although some accessibility challenges arose, Study 1 shows that users with a broad range of disabilities, even some with hearing loss and speech impairments, are making use of IPAs. Reviews were overwhelmingly positive, mentioning impacts such as ease of use compared to existing technology and the ability to more independently complete everyday tasks. At the same time, the currently limited functionality of the device and unexpected use cases of speech therapy, learning support, and memory support point to potentially fruitful avenues of future work. Study 2 findings confirm many of the conclusions from Study 1, albeit specifically with blind and visually impaired users.</p><p>As well, while smart home appliance adoption was relatively low at the time of study, participants viewed smart home technologies favorably due to the potential to address accessibility issues in the physical world.</p><p>The primary contributions of this paper are: (1) a characterization of how voice-based intelligent personal assistants are being used by people with disabilities; (2) identification of accessibility benefits and barriers; (3) and recommendations for design as well as future work on conversational voice interfaces for users with disabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>We cover work on voice-based accessible technologies and, because a key marketing component of IPAs is smart home control, smart home environments for independent living.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech Interaction as an Accessible Technology</head><p>Speech input and output is commonly used to support accessibility. Traditionally, the two most widely adopted forms of accessible speech interaction have been screen readers, which provide audio output for users with visual impairments (e.g., Apple's Voiceover <ref type="bibr" target="#b43">[44]</ref> or JAWS <ref type="bibr" target="#b44">[45]</ref>), and speech dictation software, which provides a text entry alternative to the keyboard (e.g., Dragon <ref type="bibr" target="#b45">[46]</ref>). Speech input has been helpful for a range of applications for users with motor impairments, including text input on desktops <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b37">38]</ref> and smartphones <ref type="bibr" target="#b27">[28]</ref>, controlling wheelchairs <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34]</ref>, and "free-hand" drawing <ref type="bibr" target="#b19">[20]</ref>. For users with visual impairments, speech input on mobile devices is more common than it is for sighted users <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b41">42]</ref>, due to efficiency for text entry <ref type="bibr" target="#b3">[4]</ref> and browsing <ref type="bibr" target="#b2">[3]</ref>. Speech interaction has also been studied for users with other types of disabilities. For example, computerized speech interaction can be useful for speech practice <ref type="bibr" target="#b17">[18]</ref> and therapy <ref type="bibr" target="#b29">[30]</ref> for people with speech impairments. Derboven et al. <ref type="bibr" target="#b13">[14]</ref> conducted an exploratory study on how people with speech and physical impairments form commands for a speech interface, finding that commands were short, directive statements and were often ambiguous. Speech interaction has also been explored for people with cognitive impairments, for example, to derive design guidelines for spoken dialogue assistants for users with dementia <ref type="bibr" target="#b39">[40]</ref>, and to provide audio prompts that support routine daily living tasks <ref type="bibr" target="#b10">[11]</ref>. In contrast to the above work, our focus is on voice-only conversational interaction with an off-the-shelf, general purpose IPA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Voice-based Intelligent Personal Assistants</head><p>Challenges with smartphone-based conversational assistants (e.g., Siri, Google Now) may also apply to home-based IPAs such as Amazon Echo and Google Home. User expectations for smartphone-based assistants tend to exceed the agents' abilities, with actual use being for simple tasks such as checking the weather or setting reminders <ref type="bibr" target="#b23">[24]</ref>; privacy is also a concern <ref type="bibr" target="#b16">[17]</ref>. At the same time, homebased assistants such as Amazon Echo and Google Home offer different affordances and accessibility opportunities.</p><p>Interaction is remote (e.g., across the room), which lowers the barrier to use in comparison to having to hold/use a device, and home-based assistants can connect to smart home appliances, becoming integrated into the home environment. Home-based assistants are relatively new, and the research literature on their use is accordingly sparse. Purington et al. <ref type="bibr" target="#b31">[32]</ref> studied device personification in Amazon Echo reviews, concluding that users who personified the device were more likely to be satisfied with it. Druga et al. <ref type="bibr" target="#b15">[16]</ref> studied how children perceive intelligent personal assistants (e.g., trust, intelligence level), including Amazon Echo and Google Home, although the focus was not on the children's actual or desired use of the devices. Finally, researchers have begun examining issues of privacy and security with always-on smart home devices, such as concerns arising in multi-user homes <ref type="bibr" target="#b42">[43]</ref>. This body of research is in the early stages and, to our knowledge, no one has examined use of home-based IPAs by users with disabilities-our focus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smart Home Technology and Users with Disabilities</head><p>Smart home technologies have long been touted as useful for users with disabilities (e.g., <ref type="bibr" target="#b14">[15]</ref>), although until recently many solutions have remained as research prototypes or have been too costly for mainstream adoption. More smart home studies have focused on older adults than users with disabilities, showing, for example, that the most desired features are emergency help, health monitoring, and environmental control (e.g., lights, temperature) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27]</ref>. Smart home technologies also introduce challenges such as privacy and security <ref type="bibr" target="#b42">[43]</ref>, cost <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>, and a worry about becoming dependent on the technology <ref type="bibr" target="#b30">[31]</ref>. To do with privacy, specifically, people with disabilities may be more accepting of sharing and recording smart home information than people without disabilities <ref type="bibr" target="#b5">[6]</ref>. Moreover, work with older adults has shown that the location in which the smart home sensors are placed may mitigate this concern <ref type="bibr" target="#b26">[27]</ref>.</p><p>Most relevant to our studies is work on voice-based control of smart homes. Vacher et al. <ref type="bibr" target="#b36">[37]</ref> found that older adults and people with visual impairments were both positive about controlling a smart home using voice. Other studies have shown that users with multiple sclerosis <ref type="bibr" target="#b34">[35]</ref> and older adults <ref type="bibr" target="#b9">[10]</ref>, many of whom had motor impairments, desired voice-based control over the home (e.g., doors, windows), while the latter group also strongly desired communication via phone. Despite these positives, there may be downsides of smart home voice control, such as accessibility issues around speech input (e.g., adults with non-continuous speech due to Alzheimer's disease) <ref type="bibr" target="#b32">[33]</ref>, and a reduction in perceived control compared to manual input <ref type="bibr" target="#b24">[25]</ref>. Compared to this past work our study is timely: because smart home technology has entered the mainstream, we can analyze real-world impacts with a broad range of users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STUDY 1: ANALYZING AMAZON REVIEWS</head><p>To understand the experience of users with disabilities in using voice-controlled intelligent personal assistants, we conducted an exploratory study of online customer reviews of Amazon Echo, Echo Dot, and Tap that mention use by an individual with a disability. Our coding scheme focused on overall experience with the devices, accessibility issues encountered, and suggested improvements. For this first study, we defined disability broadly, including motor, sensory, and cognitive impairments, while in the interview study described later, we focused on the largest user group from the reviews-users with visual impairments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Our approach is inspired by analyses of online content to derive implications for accessible design <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref>, and a study on personification in Amazon Echo reviews <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>We first collected 28,921 Amazon Echo, 27,286 Echo Dot, and 5,370 Tap reviews in June, 2017 from Amazon.com. All reviews were verified reviews, meaning that Amazon confirmed that the customer had purchased the device before reviewing. To identify reviews related to disability, we created a list of keywords related to cognitive, sensory, or physical abilities (following <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref>). As shown in Table <ref type="table" target="#tab_0">1</ref>, the list included 95 keywords identified a priori and 13 emergent keywords identified by reading ~500 reviews.</p><p>Of the full review set, 792 included at least one keyword, but not always in the context of disability. We thus defined a relevant review as one that contained a first-or thirdperson mention of a user with a disability. Two research team members independently evaluated the relevancy of 50 randomly selected reviews, agreeing in 49/50 cases (Cohen's kappa = 0.96). One team member then assessed all remaining reviews. The final dataset included 478 relevant reviews, although as mentioned below, we further eliminated reviews that only hypothetically mentioned a user with a disability, leaving 346 reviews in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Review Analysis</head><p>The reviews were coded along the 26 dimensions shown in Table <ref type="table" target="#tab_1">2</ref>, which include both inductive and deductive codes. Deductive codes were informed by related work (e.g., on smart homes, privacy) and our own experience with IPAs, while inductive codes were added upon reviewing the data. Two research team members built an initial codebook, with one person reading approximately one-third of the reviews in depth, and the second person participating in discussions, reading a smaller subset of the reviews, and helping to add, merge, and delete codes.</p><p>To ensure coding reliability, we used a multi-phase process <ref type="bibr" target="#b20">[21]</ref>. First, one researcher involved in the initial codebook creation and one new team member independently coded 20 randomly selected reviews, discussed disagreements, and refined problematic codes. Second, the same two researchers independently coded 40 new randomly selected reviews. Cohen's kappa calculated on the primary codes (all numbered codes in Table <ref type="table" target="#tab_1">2</ref>) after this second round was on average 0.96 (SD=0.07, Range=0.79-1.00). Four codes that had been present in the first round were by chance not applicable in the second round, and were excluded from these calculations (Indispensable, Privacy, Home automation, and Awkwardness/discomfort with device interaction). We also removed one primary code (Technology comfort) due to sparsity, and added Use in nursing home/rehab center/hospital. Finally, one researcher coded all reviews using the refined codebook. The excerpts  marked with each code were then qualitatively analyzed to obtain richer descriptions to complement the coded data.</p><p>We also computed basic statistics on review length, rating (on a 5-point scale), and age (based on date of posting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Findings</head><p>We report on review and user characteristics, overall experience, device usage, accessibility issues, and emergent themes such as independence and safety. To focus on reviews based on experience with the device, we exclude from this analysis 132 reviews that only mentioned disability or accessibility in a hypothetical sense (under the coding dimension Perspective); for example, from R14: "Alexa could be immensely valuable in helping a person with limited mobility and/or physical disability." Our analysis thus includes 346 of the 478 reviews. We refer throughout to reviews by ID numbers R1-R478.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Review Characteristics</head><p>The reviews were on average 775 characters long (SD=810) and had a rating of 4.5 out of 5 (SD=1.0). As of June 15, 2017, the reviews were 312.2 days old (SD=205.7, Range=0-727). About a third (N=114; 32.9%) were written from the first-person perspective of someone with a disability, whereas 232 (67.1%) were written from a thirdperson perspective. These latter reviews were mainly written by people who had close ties with the user with a disability, such as a son or daughter (in-law) (36.6% of the 232 third-person reviews), spouse (26.7%), parent (16.8%), other family member (11.6%), or friend (4.3%); the remaining 4.3% of reviews did not mention what relationship the author had to the user. One review included purchases for two separate users with disabilities, so percentages sum more than 100%. Ratings from both firstperson and third-person reviews were positive on average, at 4.6 (SD=0.9) and 4.3 (SD=1.2), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Characteristics</head><p>Our dataset included users with a diverse set of disabilities: visual impairment (37.9% of reviews), motor or mobility impairment (30.6%), speech impairment (13.6%), cognitive impairment (11.8%), and hearing loss (4.6%). An additional 18.2% only mentioned disability in general. Some reviews mentioned more than one specific type of disability, so percentages sum to more than 100%. Nineteen (5.5%) of the reviews mentioned that the disability was only shortterm, such as a user recovering from an injury or surgery.</p><p>In terms of age, we looked for mentions of older adults or children, and found that 46 reviews (13.3%) mentioned a user who was 60+ years old or used age-specific keywords (e.g., elderly, old, older), while 16 reviews mentioned that the user was a child (4.6%). While only 145 reviews explicitly mentioned whether the user with a disability lived alone or with others, the vast majority of these mentions were of households with multiple members (138 reviews; 95.2%); the remaining seven mentioned living alone. A small number of reviews (4.0%) mentioned use in a nursing home, rehab center, hospital, or assisted living center.</p><p>Users tended to receive the device as a gift rather than buying it themselves. Of the 202 reviews that mentioned how the device was obtained, 79.2% involved a gift (N=160). Examining this data by user age revealed that older adults were disproportionately represented: 22.5% of gift recipients were older adults, although older adult users were only mentioned in 13.3% of all reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Interface and Interaction</head><p>In terms of overall tone, most reviews were positive (85.6%). Some reviews (N=23; 6.7%) referred to the device as a companion, using terms such as "new best friend", "bff", and "someone to talk to". Eight reviews even mentioned that the device had become an integral part of the user's life. For example, R94 stated: "This has to be the best gift I have gotten in years. I'm so used to it being here that I would be lost without it." In contrast, only 11.9% of the reviews were negative, while 2.6% were coded as neutral. Here, we discuss more specific positive and negative comments about the user interface and interaction.</p><p>Ease of use was commonly brought up as a positive, arising in 23.4% of reviews. The voice-based interaction, which allowed for control from a distance and without the need for visual output was valued. For example: However, 19.1% of reviews mentioned limitations, criticisms, or suggestions. Nineteen reviews (5.5%) mentioned that a desired feature was missing, such as voice calls and messaging, emergency calls, alternative input via a remote, or braille to make the case more accessible. (Note that subsequent releases of the devices have addressed some of these concerns.) Another criticism was that the device offered limited use, which was mentioned in 4.0% of reviews and is a criticism that has been aimed at smartphone-based IPAs as well <ref type="bibr" target="#b23">[24]</ref>. For example, R405 said, "…echo still is not very smart. About 80% of my questions i ask it did not know." Other less common criticisms mentioned in at least five reviews included having to pair the device with a phone, need for wifi, lack of portability, issues with the audio sensing, and issues with specific apps. Finally, a few reviews (2.9%) mentioned that cost was a challenge. Even when the base cost of the device is relatively cheap, additional skills or subscriptions (e.g., Amazon Prime, Audible) are often needed.</p><formula xml:id="formula_0">"I can't</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specific Uses of IPAs</head><p>Over half of the reviews (66.2%) mentioned specific tasks for which the device was used. The most common tasks demonstrated a mix of entertainment and utility-listening to music, looking up information, checking the weather, playing audio books, and home automation. See Table <ref type="table" target="#tab_4">3</ref>.</p><p>Because control over home automation is a primary marketing component of IPAs, we further examined these mentions. Table <ref type="table" target="#tab_5">4</ref> shows that most of the 52 reviews mentioning home automation included a reference to lights, and other smart home devices were much less common (Table <ref type="table" target="#tab_5">4</ref>). The majority of reviews with home automation included users with motor impairments (71.2%; 37 of the 52 reviews). Approximately a third (28.8%; 15 of 52) mentioned an improvement in independence and just over half (53.8%; 28 of 52%) mentioned ease of using the voice for control. For example, R213 discussed how home automation saved effort and could be used to communicate with others in the home: For people with visual impairments, a common theme was the ability to use the device for a range of small tasks without having to depend on someone else for help (48.9% of the 49 reviews), such as listening to music, checking the weather, asking for the time or date, reading books, or listening to the news. For example, R472 said:</p><formula xml:id="formula_1">"If I</formula><p>"My wife who is legally blind and has disabilities due to a stroke […] used to have to depend upon others to assist her with time, weather, making lists, taking care of her calendar, and many other daily chores. Thanks to Alexa she is in control of all of these as well as enjoying music again." (R472)</p><p>Finally, the impacts of independence extended to alleviating the burden on caregivers, reflecting past work on the utility of some new technologies for caregivers (e.g., <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b35">36]</ref>). A few reviews (3.2%) mentioned that the device had reduced some caregiver demands, such as reading books, playing music, controlling the home environment, or answering simple questions. For example, R350 said that instead of frequently having to repeat the time, daily agenda, and so on: "Alexa has been phenomanal with taking some of the pressure off of me. She can answer the time ALL DAY LONG, and never get annoyed, lol."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Safety</head><p>Sixteen reviews (4.6%) mentioned that the device had improved safety, 12 of which included people with motor impairments. Several of these reviews (N=7) commented on an app that sends an emergency alert to a contact. R289 also described using home automation to send messages: Another review (R126) mentioned using their AAC device to give commands to Amazon Echo, a behavior identified in <ref type="bibr" target="#b21">[22]</ref>.</p><formula xml:id="formula_2">"</formula><p>Still, 10 users with speech impairments also or solely mentioned difficulties with speech recognition, such as the need to enunciate clearly and speak loudly. Another issue that arose for users more broadly, beyond those with speech impairments, was the device timing out before the speaker could complete their command (an issue noted for users with Alzheimer's disease <ref type="bibr" target="#b32">[33]</ref>). Speech output challenges also arose in a few reviews. Three users with hearing loss experienced difficulty in understanding the output and could benefit by additional speech settings and paired earphones. R154 said, for example: "…just a bit too much bass for speech (I'm a hard of hearing with typical treble roll-off)... wish there was a music &amp; speech tone setting."</p><p>A second accessibility challenge arose from the paired smartphone app, which is required for device setup, troubleshooting, and detailed help. Six users with visual impairments mentioned accessibility issues with the app, which highlights the need to ensure that the entire device ecosystem-not just the voice interaction-is accessible.</p><p>Memory demands of the voice-based interaction were also an issue. Some reviews (4.9%) mentioned difficulties in remembering voice commands, which could be particularly problematic for older adults or users with cognitive impairments. For example, R81 mentioned that an older user who had difficulty remembering how to wake the device (with the word "Alexa"), while R200 said of his 86year-old father with limited vision: "Unfortunately, he's not making full use of it's potential because he can't quite remember exactly the words needed to [use] some of the skills that are available." At the same time, the ease of the conversational interface offered benefits for some users with memory issues. R91, for example, mentioned a user with dementia who sometimes forgets how to dial a phone, but can use a voice command to call his partner with Alexa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unexpected Uses</head><p>Along with the conventional uses of the device in Table <ref type="table" target="#tab_4">3</ref>, some unexpected use cases arose, including for speech therapy, learning support, and as a memory aid. These use cases offer insight into potentially rich avenues of research.</p><p>In terms of speech therapy, seven reviews (2.0%) described how the device had helped users with speech impairments to talk slowly, clearly, and loudly. The conversational nature of the device was also seen as helpful. For example:</p><p>"Our oldest daughter has a pretty challenging speech impediment and using Alexa has forced her to slow down and enunciate clearly. Not only is Alexa learning how to understand my daughter, my daughter is also slowing down and learning to communicate with Alexa. The huge benefit is she is now slowing down to communicate more clearly with us. This is something her speech therapists have been working on with her for years. Alexa has gotten these results from her in a few months." (R185)</p><p>R329 described how the device was used to measure speech improvement for the reviewer's brother with autism: "He'll speak to Alexa, ask her questions about the weather, and if Alexa responds, my parents know his speech is improving."</p><p>Use of the device to support learning also arose. The voicebased, conversational interaction allowed some users with print disabilities to access information. Specifically, of the five reviews (1.4%) that mentioned a user with dyslexia, four reported that the device was useful for reading audio books or asking questions. For example, R68 said:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"My daughter is dyslexic and struggles with reading, but we load audio books on to our Amazon music account and Alexa plays the books while she is playing, resting, falling asleep. She asks her questions about everything under the sun, and Alexa never tires of answering them." (R68)</head><p>A third unexpected use case was as a memory aid for users who had memory difficulties (mentioned as an issue for 19 of the 41 users with a cognitive impairment). Features like setting reminders, timers, managing a calendar, to-do lists, and shopping lists, and asking for the time, date and weather were seen as most helpful. For example, R190 said:</p><p>"I live alone, and was recently diagnosed with a disease that leaves me confused on details and the passage of time.</p><p>It has been a godsend to be able to ask Alexa the day, date, time, or weather, set wake-up alarms or reminder alarms (for example, turn off the oven in an hour, or take my medicine), add to my to-do list or shopping list, etc."</p><p>Finally, the applicability of the device to a medical setting and for short-term disabilities such as injury or recovery after surgery arose (5.5% of reviews). In some cases, the device was seen as useful for maintaining medication timing (N=5). Nineteen reviews mentioned short-term disabilities and reported benefits similar to those expressed by users with long-term disabilities, such as being able to listen to music or jokes, or query information by voice. For example, R422, who was recovering at home from surgery, said the device, "Takes away my anxiety of being alone while my husband is at work."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>Users with a broad range of disabilities are making use of voice-based intelligent personal assistants in the home. Reviews were overwhelmingly positive, mentioning impacts such as ease of use compared to existing devices and the ability to more independently complete everyday tasks-due both to internet-connected apps as well as smart home appliances. Despite being highly accessible, challenges still arose, particularly for people with speech impairments and for users with hearing loss. Accessibility of the larger device ecosystem (e.g., physical device design, smartphone app, smart home appliances) needs to also be considered. Unexpected use cases of speech therapy, learning support, and memory support point to potentially fruitful avenues of future work. A limitation of this study, however, is that, while the online reviews provided a large sample size, the data itself is sparse and does not allow for an in-depth understanding of individual users' experiences.</p><p>As such, we turn to an interview method in Study 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STUDY 2: INTERVIEW STUDY</head><p>To complement the breadth offered by Study 1, we conducted a second, in-depth study to examine use by one specific subset of users: 16 blind and visually impaired users Amazon Echo or Google home users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 16 participants (11 female, 5 male) with visual impairments who owned an Amazon Echo, Echo Dot, Amazon Tap, or Google Home device; three participants also reported having a mobility impairment. Details are shown in Table <ref type="table" target="#tab_6">5</ref>. Fifteen participants owned a smartphone. Participants were recruited from across the United States through Facebook groups specific to Amazon Echo, Echo Dot and Google Home, participant lists maintained by our research team, and snowball sampling. Participants were each compensated with a $15 Amazon gift card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>We conducted semi-structured interviews over Skype or Google Hangout, or via a regular phone call. Conducting remote interviews provided us the flexibility of reaching a larger number of participants than would have been possible locally. Interviews were designed to last one hour, but ranged from 33-85 minutes long. Interview questions covered the following categories: background and demographics, number of devices owned, when/how device was acquired, device usage (frequency, activities), motivation for buying the device, comparison of expectations beforehand to actual experience, benefits and concerns/challenges/limitations of using the device, speech recognition experience, current use of and desire for home automation, user interface preferences, and suggestions for improvement. All interviews were audio recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Interviews were transcribed and qualitatively coded using a thematic coding approach that included both inductive and deductive codes <ref type="bibr" target="#b6">[7]</ref>. Two researchers worked together to prepare an initial codebook, with one member reading all transcripts and discussing with a second team member to add, merge and delete codes. The first researcher applied this initial codebook to two randomly selected interview transcripts, which were reviewed by the second researcher. The two researchers refined the codebook, and in doing so added one new code (Device Setup). For validation of the refined codebook, we then followed a peer debriefing method <ref type="bibr" target="#b4">[5]</ref>. Here, the first researcher and a third researcher independently coded one interview transcript and discussed disagreements. There were 15 disagreements out of 186 codes applied, which were resolved through consensus; one code definition (General positive) was refined and one subcode removed. The final codebook, which the first researcher then used on all transcripts, contained 20 primary codes, 13 of which had sub-codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Findings</head><p>As shown in Table <ref type="table" target="#tab_6">5</ref>, most participants (13/16) owned multiple Amazon Echo and/or Google Home devices, placing them most often in a living room or bedroom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall Usage Patterns and Perceived Utility</head><p>All participants found the device to be useful, with five participants mentioning that it had become an integral part of their lives-reflecting some of the reviews in Study 1. For example, P10 said, "I cannot imagine life without them [Amazon Echo and Google Home]," while P13 said, "Initially, I heard about it and I thought, 'Who'd ever buy that?' Honestly, I thought, 'Oh, what a waste of money.' And then now it's just become such an integral part of our lives." Most participants (N=14) used the device multiple times a day, while two used it once every few days.</p><p>Participants made use of and valued a range of features. The most commonly reported uses were playing music (N=15) and checking the weather (N=14). Less frequent but still popular tasks included setting timers (N=12), listening to news (N=12), playing games (N=9), online shopping (N=9), looking up information (N=9), checking the time or date (N=8), reading books (N=7), setting an alarm (N=7), playing the radio (N=6), and calling people (N=5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial Purchase and Change in Use Over Time</head><p>Most participants (N=13) had purchased the device themselves, while the others had been given it as a gift. The most common reasons for acquiring the device were expected ease of use of the voice interaction (N=8) and expected utility (N=6). For example, P1 touched on themes of utility and independence:</p><p>"It was the fact that I could do things that sighted people can do, you know, people with vision. It allowed me to do things very easily and not have to use a separate app for each thing I want to do." (P1)</p><p>Uniquely, P12, who had low vision and primarily interacted visually with computers, reported buying the Echo Dot as a more attractive entry into voice and audio-based interaction than she had experienced with screen readers:</p><p>"I do have JAWS and things like that, the screen reader, but for right now it's not pleasing to my ear to be hearing that.</p><p>[…] But I do wanna take control of this [vision loss], so I'm hoping that starting out with Amazon Dot will motivate me to get this other audio help in my life." (P12)</p><p>All but three participants reported being familiar with at least the device's basic capabilities before acquiring it. When asked about their initial use and whether use had changed over time, only two participants reported that their use had dropped off with time, due to frustration with the smartphone app or novelty wearing off. Overall, though, these trends demonstrate persistent utility for most people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strengths and Benefits</head><p>Three main benefits that arose were efficiency, impacts on independence, and an ability to replace a range of other technologies. Toward the theme of efficiency, seven participants mentioned that the device had enabled them to perform tasks faster than before, such as online shopping, checking the weather, listening to news, playing music, and setting timers. For example, P11 said that compared to using a traditional browser, Alexa is "able to accomplish [making a purchase] in seconds versus a few minutes." Four participants also referred to the IPAs as enabling them to multitask in new ways. P15, for example, felt that the voice interface was easier than using a smartphone to set a timer while cooking because it was hands-free: "I think as a blind person, you tend to get your hands messier than perhaps some sighted people do." Another main benefit was to improve on a disparate set of existing technologies (mentioned by N=10 participants).</p><p>Positive comparisons were made against smartphones, computers, tablets, talking clocks, talking calculators, braille timers, and e-book readers. P13 said, "I mean you have to buy adaptive games and they're so prohibitively expensive. And the books... Right now, we don't have to buy machines, for the most part, that are separate.</p><p>[…] between the phones for portable usage and the Echo for home, we can read virtually all our books anywhere." (P13)</p><p>Finally, the theme of independence was mentioned by four participants-that is, enabling tasks that had previously required assistance from others. Tasks mentioned included being able to shop, play games, and control the home environment. For example, P5 said that she could order online without having to ask her brother for help, while P10 described needing less help from her husband:</p><p>"It used to be there were nights I went to bed with the light on until my husband got home from work because I couldn't turn it off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[It also] saves me having to get up and turn on my CPAP [sleep apnea machine]." (P10)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accessibility Challenges and Device Limitations</head><p>Accessibility challenges arose primarily due to the device's ecosystem, that is, elements of the system beyond voicebased interaction. As found in Study 1, half of the participants mentioned problems with the paired smartphone app. Ten participants also reported that device setup was difficult, either on initial purchase or whenever the device got disconnected from the internet. Finally, the physical design caused issues for two participants. P12, who had low vision, had trouble reading the physical controls due to poor color contrast between the symbol and button, while P2 could not see the orange indicator light that comes on with the Echo during setup (note: recent releases also provide audio feedback to address this issue).</p><p>Two other limitations point to the need for richer voice interaction: the difficulty of discovering unknown features, and the limited features of Echo's voice-based apps compared to smartphone apps. P16, for example, compared the implementations of Alexa (Echo) apps for ride sharing (e.g., Uber, Lyft) to comparable smartphone apps, concluding that the voice-based apps were lacking. For discoverability, eight participants either reported difficulty in learning about the existence of features or mentioned that they desired a particular feature that already existeddemonstrating the problem itself. As an example, P14 said: </p><formula xml:id="formula_3">"</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Modalities</head><p>The primary input modality preference was voice, but many people (N=9) also wanted other means such as a remote, smartphone, smartwatch, in-air gestures, or direct touch for controlling the device. Alternative options could deal with noisy environments, not wanting to disturb other people, or wanting to control the device from a distance. For example, P15 mentioned that it could be easier at times to use their watch as a manual remote control than to yell across the room, since "I will almost always have the watch on."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Current and Desired Smart Home Use</head><p>Although only four participants had connected smart home appliances to their IPA, all participants wanted their house to be automated. As shown in Table <ref type="table" target="#tab_6">5</ref>, current smart home appliances included lights, thermostat, TV, and switches.</p><p>For the 12 participants who did not own smart appliances, the most common reasons were policies at their current residence (e.g., a rental unit) (N=5) and cost (N=4).</p><p>The most common desired smart appliances, when posed to all 16 participants, were thermostats (N=14) and lights (N=10). Less common requests included the oven, dishwasher, security system, stove, garage door, washer, dryer, vacuum cleaner, TV, fans, blinds, and refrigerator. For example, P16 felt that voice control would be more accessible than his current thermostat, while P15 mentioned the general need for an accessible alternative to flat touch controls on appliances, "which are very difficult as a blind person". P4 also said: "I often forget to either turn lights on so that people know we're home or turn them off, because I don't need them."</p><p>Some participants' experience points to the need for a wider range of appliances to be smart-enabled. P10, in particular, had a mobility impairment and used a smart switch for her CPAP (sleep apnea machine) and had wanted to do so for her oxygen compressor as well. But, she said:</p><p>"But unfortunately, compressors are, if the electricity dies, it sets off an alarm so the smart switches won't work for something like that. If I turn off my oxygen using it, it just sets off an alarm." (P10)</p><p>When asked to envision an ideal smart home without having to take into account current capabilities, almost everyone wanted all appliances to be automated (N=14). Two participants wanted a personal assistant like Amazon Echo or Google Home to make emergency broadcasts and calls, connect with scales and fitness trackers, and pay bills. One participant also wanted to monitor her pets remotely by audio, as a more accessible alternative to a "pet cam" (P11).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Security and Privacy</head><p>Although security has been called out as an important issue for IPAs <ref type="bibr" target="#b42">[43]</ref>, only four participants raised security concerns, such as cloud-based services being hacked. For privacy concerns, participants were evenly split. Half believed that their conversations were not sensitive enough to cause any harm to them, with one participant even mentioning that the 'always on' feature can be positive:</p><p>"I guess the biggest thing was when there was the murder case which they wanted to subpoena the Echo. And I realized, gee, if somebody's killing me, the smartest thing to do would say, "Alexa, so and so had just stabbed me." Because she would actually record it and the police would be able to get that later on." (P10)</p><p>Of the eight participants who were concerned, however, the two main issues were the device always listening and recording (N=6), and personal information being collected (N=6). Concerns affected device usage for five participants, for example, not using calendars, doing financial transactions or online shopping, or using applications that asked for location details. To avoid conversations being recorded, P16 turned off the microphone during sensitive discussions, while P1 unplugged it. Although not as common, a few people mentioned privacy concerns related to being overheard by other people in the home, or other people controlling their device (e.g., for shopping, banking, for which reason security codes were used).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>This study confirmed many of the findings from Study 1, emphasizing that IPAs have replaced many disparate devices, and improved efficiency and independence for a variety of tasks. Particularly important for blind and visually impaired users, issues related to the device ecosystem arose, along with a desire for more feature-rich voice-enabled applications. Although smart home appliance adoption is currently low, participants expressed enthusiasm about smart home appliances and their potential to address accessibility issues in the physical world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>Our studies demonstrate the immense potential of voicecontrolled IPAs to provide inclusive, accessible interaction for people with a range of disabilities. At the same time, this formative research highlights directions for future work and accessibility issues that should be addressed, such as the limited control over speech output settings for users with hearing loss (Study 1), issues with paired smartphone apps (in Studies 1 and 2), and visual accessibility problems with the physical device design (Study 2). Here, we discuss generalizability of the findings and some of the more promising opportunities we identified for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subpopulations of users.</head><p>Study 1 captured use by users with a broad range of disabilities, but some subpopulations were disproportionately represented. Almost two thirds of the reviews included a user with a visual or motor impairment, which means that our findings may be more likely to apply to these two groups. Study 2 findings are specific to users with visual impairments, although addressing the issues that arose there could be more widely beneficial.</p><p>Perhaps most unexpectedly, Study 1 included adoption by users with speech impairments and hearing loss-two subpopulations for whom voice-based IPAs are not obviously accessible. This finding may be partly due to sampling bias: users with more severe impairments may not have thought to try the device and thus to write a review. Still, most reviews in Study 1 that included users with speech impairments were positive, showing that conversational interaction even supplemented speech therapy for some users. While more formal computerized speech therapy is an active area of research (e.g., <ref type="bibr" target="#b29">[30]</ref>), it will also be important to study the utility of emerging conversational interfaces for these goals.</p><p>Mobile vs. home-based IPAs. Home-based IPAs offer different affordances than smartphone IPAs (e.g., Siri), and, at least at the time of study, offered greater functionality.</p><p>The largely positive findings from our studies contrast work with smartphone-based IPAs, where participants without disabilities considered the IPA to be "entertaining / gimmicky" <ref type="bibr" target="#b23">[24]</ref>. This difference may reflect the differences of home-based devices compared to a purely mobile, smartphone option and/or the preferences of users with disabilities. Further work should explore these possibilities.</p><p>Discoverability. Discoverability of commands is a longstanding problem with voice interaction <ref type="bibr" target="#b40">[41]</ref>. This issue arose in Study 2, where some users with visual impairments found it difficult to discover apps and advanced commands.</p><p>Adaptive and contextualized learning may enhance learnability and discoverability in voice interfaces <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19]</ref>, and has been recently used for voice-based interaction for users with motor impairments <ref type="bibr" target="#b11">[12]</ref>. Typically, however, the voice input is paired with visual output. Improving discoverability for purely non-visual interaction will likely offer benefits not only for blind users but also for others.</p><p>Rich voice-only app design. A related issue found in Study 2 is the limited nature of many voice-based apps compared to mobile or desktop counterparts. While sighted users may not mind switching to a visual interface for in-depth tasks (indeed, Amazon recently released an IPA with a visual display), understanding how to better support rich interaction through a voice-only interface is important for accessibility, particularly for users with visual impairments. While existing auditory interface interaction techniques should prove useful (e.g., Spearcons <ref type="bibr" target="#b38">[39]</ref>), new advances are needed to support complex information access.</p><p>Smart home adoption and perception. Smart home appliance adoption is occurring, with 15% of reviews and 25% of interview participants mentioning at least one smart home appliance. In terms of barriers to adoption, Brush et al. <ref type="bibr" target="#b7">[8]</ref> have identified cost, inflexibility, management overhead, and security. Our visually impaired participants in Study 2 also cited cost, but mentioned policies in housing units, and, for some, worries about the accessibility of purchase and setup; security and privacy were not top concerns. Of course, other subpopulations of users with disabilities may have different concerns. Many of the smart home appliances desired by participants already exist, although there were still new opportunities (e.g., the oxygen compressor). It will be important to revisit adoption rates in a few years to assess how adoption is changing.</p><p>Memory support. Users with memory loss in Study 1 sometimes encountered difficulties in remembering commands. Adaptive interaction may address this problem, for example, by learning a user's usage patterns to efficiently prompt actions. At the same time, we observed broad use of the IPAs for aiding memory: setting reminders, tracking calendars, and other memory-related tasks. As such, IPAs may be a promising platform for extending existing work on memory support (e.g., prompting systems <ref type="bibr" target="#b10">[11]</ref>) and to explore new possibilities for more explicitly supporting independent living for users with memory loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations of the Study Method</head><p>For Study 1, we used verified reviews because they are more credible than otherwise <ref type="bibr" target="#b0">[1]</ref>, but there is still the possibility that some reviews were misleading (e.g., ads for third-party features). Second, the dataset is likely biased toward users who are early adopters, have the resources to purchase an IPA, and are largely able to use the device. Third, the third-person perspective reviews (two thirds of our dataset), may not be as accurate as first-person reviews in reflecting the experience of users with disabilities. Finally, the reviews only include what review authors chose to mention, which means that frequency counts in Study 1 should be considered a minimum. Study 2 addresses this lattermost problem, but only focuses on one user group (users with visual impairments), and participants may have been relatively tech-savvy and socially connected since they were recruited through Facebook. Future work requires similar in-depth studies on IPA usage by other user groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>With the increasing adoption of voice-controlled conversational interfaces and home-based IPAs, including people with disabilities in the design of these technologies is critical. To understand current use, we analyzed 346 Amazon Echo reviews that mentioned a user with a disability and interviewed 16 blind and visually impaired participants who owned a home-based IPA. The first study showed that users with a range of disabilities are using the Amazon Echo, including for unexpected cases such as speech therapy and support for caregivers. Study 2 provided a more in-depth analysis of one specific group-users who are blind or visually impaired-with findings reflecting the first study as well as emphasizing the efficiency of the devices for a variety of tasks, difficulties with discovering new functionality, and the desire for richer voice-only applications. However, accessibility challenges related to speech input and output still exist (Study 1), along with issues with the device ecosystem (both studies). As exploratory research, these findings should inform future work on accessible voice-based IPAs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Disability-related search terms used for extracting reviews, including terms defined a priori and emergent keywords identified through reading a subset of reviews.</head><label>1</label><figDesc></figDesc><table><row><cell>1. Perspective: first person, third person, third person (hypothetical)</cell></row><row><cell>User details</cell></row><row><cell>2. Disability: motor, vision, speech, cognitive, hearing, other, unspecified</cell></row><row><cell>3. Length of disability: short-term, long-term, unspecified.</cell></row><row><cell>4. Age: older adult, child, younger adult or unspecified</cell></row><row><cell>5. Household size: lives alone, other in house, unknown</cell></row><row><cell>6. Use in nursing home/rehab center/hospital: yes, no/unknown</cell></row><row><cell>7. Obtaining the device: was given it, bought it or unknown</cell></row><row><cell>Overall opinion</cell></row><row><cell>8. Overall tone of the review: positive, negative or neutral</cell></row><row><cell>Social aspects</cell></row><row><cell>9. Device as companion</cell></row><row><cell>10. Independence</cell></row><row><cell>11. Indispensable</cell></row><row><cell>12. Helpful for caregiver/family member to support caregiving</cell></row><row><cell>13. Enables digital tech access</cell></row><row><cell>14. Safety</cell></row><row><cell>15. Awkwardness or discomfort with device interaction</cell></row><row><cell>16. Privacy</cell></row><row><cell>17. Security</cell></row><row><cell>18. Other</cell></row><row><cell>19. Limitation (Functional Limitation, Criticism, or Suggestion)</cell></row><row><cell>User interface / interaction</cell></row><row><cell>20. User interface positives</cell></row><row><cell>21. User interface negatives</cell></row><row><cell>Speech recognition</cell></row><row><cell>22. Speech recognition positives</cell></row><row><cell>23. Speech recognition negatives</cell></row><row><cell>24. Device setup</cell></row><row><cell>Device usage</cell></row><row><cell>25. Specific activities performed</cell></row><row><cell>26. Home automation: yes, no</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 . Primary codes used for the reviews in Study 1.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 . Percent of the 346 reviews in Study 1 that mentioned a specific task.</head><label>3</label><figDesc></figDesc><table><row><cell>Activities performed</cell><cell>(%)</cell><cell>Activities performed</cell><cell>(%)</cell><cell>Home automation</cell><cell>(%)</cell><cell>Home automation</cell><cell>(%)</cell></row><row><cell>Listening to music</cell><cell cols="2">34.7 Listening to jokes</cell><cell>7.5</cell><cell>Lights</cell><cell cols="2">82.7 Television</cell><cell>7.7</cell></row><row><cell>Looking up information</cell><cell cols="2">18.5 Setting a timer</cell><cell>6.7</cell><cell>Smart outlets</cell><cell cols="2">21.2 Security system</cell><cell>5.8</cell></row><row><cell>Checking the weather</cell><cell cols="2">17.5 Managing a shopping list</cell><cell>6.1</cell><cell>Thermostats</cell><cell cols="2">19.2 Door locks</cell><cell>5.8</cell></row><row><cell>Playing audio books</cell><cell cols="2">15.6 Managing a calendar</cell><cell>5.2</cell><cell>Switches</cell><cell cols="2">7.7 Other (e.g., fan, sprinkler)</cell><cell>15.4</cell></row><row><cell>Home automation</cell><cell cols="2">15.0 Playing games</cell><cell>5.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Listening to news</cell><cell cols="2">10.1 Third-party skills (e.g., Uber)</cell><cell>4.1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Asking time or date</cell><cell cols="2">9.5 Managing a to-do list</cell><cell>3.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Playing the radio</cell><cell cols="2">8.4 Online shopping</cell><cell>3.5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Setting an alarm</cell><cell cols="2">7.5 Other (e.g., calls, spelling)</cell><cell>13.7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>This was a gift for our son who has ALS. It has been very helpful to him in turning lights on and off where he can't access them and has even brought needed assistance by blinking lights in another room to get someone's attention when help was needed." (R289)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 . Specific types of home automation mentioned, as a percent of the 52 reviews containing home automation.</head><label>4</label><figDesc>Accessibility challenges arose, primarily related to speech interaction, the device ecosystem, and memory demands. Sixty-four reviews mentioned speech recognition accuracy, most of which (59.4%) were positive mentions. However, speech input can be particularly problematic for people with speech impairments. There were 31 reviews that included a user with a speech impairment and comments about speech recognition. Perhaps surprisingly, many of these comments were positive(23/31;  74.2%). For example, R144 stated, "Most humans can not understand me, but Alexia can," while R318 wrote, "Ordinarily voice programs can't understand what I am saying due to my speech impairment, but Alexa responds to my commands without fail."</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 . Demographic and device details of the 16 participants in Study 2. (Note: P3 and P4 were husband and wife.) CHI 2018 Paper CHI 2018, April 21-26, 2018, Montréal, QC, Canada Paper 459</head><label>5</label><figDesc></figDesc><table><row><cell>ID Age Gender</cell><cell>House-hold Size</cell><cell>Self-reported Vision Level and Mobility Aid If Applicable</cell><cell>Devices Owned (Count)</cell><cell>Device Location</cell><cell>First Acquired?</cell><cell>Home Automation</cell></row><row><cell>1 42 M</cell><cell>4</cell><cell>Blind (some usable vision)</cell><cell>Echo (4), Home (1)</cell><cell>Living room, bedroom, office</cell><cell>2.5 years</cell><cell>None</cell></row><row><cell>2 35 F</cell><cell>1</cell><cell>Blind one eye, "little" vision in other</cell><cell>Echo (2), Dot (1)</cell><cell>Living room, bedroom</cell><cell>2 years</cell><cell>None</cell></row><row><cell>3 54 F</cell><cell>3</cell><cell cols="2">Blind (total blindness), uses wheelchair Dot (2)</cell><cell>Living room, bedroom</cell><cell>9 months</cell><cell>None</cell></row><row><cell>4 44 M</cell><cell>3</cell><cell>Blind (total blindness)</cell><cell>Dot (2)</cell><cell>Living room, bedroom</cell><cell>9 months</cell><cell>None</cell></row><row><cell>5 62 F</cell><cell>1</cell><cell>Blind (total blindness)</cell><cell>Echo (1), Dot (1)</cell><cell>Living room, bedroom</cell><cell>1 year</cell><cell>None</cell></row><row><cell>6 48 M</cell><cell>1</cell><cell>Blind (total blindness)</cell><cell>Dot (2)</cell><cell>Living room, bedroom</cell><cell cols="2">10 months None</cell></row><row><cell>7 34 F</cell><cell>4</cell><cell>Blind</cell><cell>Echo (2)</cell><cell>Living room / kitchen, family room,</cell><cell>2 years</cell><cell>TV</cell></row><row><cell>8 61 F</cell><cell>1</cell><cell>Blind (total blindness)</cell><cell>Echo (1), Dot (1)</cell><cell>Living room, bedroom</cell><cell>1.5 years</cell><cell>Lights, stereo</cell></row><row><cell>9 49 M</cell><cell>1</cell><cell>Blind (total blindness)</cell><cell>Echo (1), Dot (1)</cell><cell>Living room, bedroom</cell><cell>2 years</cell><cell>None</cell></row><row><cell>10 57 F</cell><cell>3</cell><cell>Low vision, no peripheral vision, uses</cell><cell>Echo (4), Home (1)</cell><cell>Bedrooms, kitchen, office</cell><cell>7 months</cell><cell>Lights, thermostat,</cell></row><row><cell></cell><cell></cell><cell>walker, cane or wheelchair</cell><cell></cell><cell></cell><cell></cell><cell>switches</cell></row><row><cell>11 65 F</cell><cell>1</cell><cell>Blind (no useful vision)</cell><cell>Echo (2)</cell><cell>Living room, bedroom</cell><cell>1 month</cell><cell>None</cell></row><row><cell>12 57 F</cell><cell>1</cell><cell>Blind (some vision)</cell><cell>Dot (1)</cell><cell>Dining room</cell><cell>7 months</cell><cell>None</cell></row><row><cell>13 54 F</cell><cell>3</cell><cell>Blind (some vision)</cell><cell cols="3">Echo (2), Dot (1), Home (1) Living room, bedroom, office, basement 2.5 years</cell><cell>Lights</cell></row><row><cell>14 62 F</cell><cell>1</cell><cell>Blind (some vision)</cell><cell>Echo (1)</cell><cell>Living room</cell><cell>7 months</cell><cell>None</cell></row><row><cell>15 62 F</cell><cell>2</cell><cell>Blind (light perception)</cell><cell>Echo (1), Dot (2)</cell><cell>Living room, bedroom, kitchen</cell><cell>2 years</cell><cell>None</cell></row><row><cell>16 42 M</cell><cell>1</cell><cell>Blind (total blindness)</cell><cell>Echo (1)</cell><cell>Living room</cell><cell>1 year</cell><cell>None</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>April 21-26, 2018, Montréal, QC, Canada Paper 459</head><label></label><figDesc></figDesc><table><row><cell>CHI 2018 Paper</cell><cell>CHI 2018,</cell></row><row><cell></cell><cell>There are so many skills [Alexa apps] available that I</cell></row><row><cell></cell><cell>know I'm missing out on some things that I would probably</cell></row><row><cell></cell><cell>like to do, but don't even know that's possible." (P14)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Reviews Without a Purchase: Low Ratings, Loyal Customers, and Deception</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">T</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<idno type="DOI">10.1509/jmr.13.0209</idno>
		<ptr target="https://doi.org/10.1509/jmr.13.0209" />
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="249" to="269" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analyzing User-Generated YouTube Videos to Understand Touchscreen Use by People with Motor Impairments</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoojin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leah</forename><surname>Findlater</surname></persName>
		</author>
		<idno type="DOI">10.1145/2470654.2466158</idno>
		<ptr target="https://doi.org/10.1145/2470654.2466158" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;13)</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1223" to="1232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Wizard-of-Oz evaluation of speech-driven web browsing interface for people with vision impairments</title>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Vikas Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Borodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Stoyanchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Puzis</surname></persName>
		</author>
		<author>
			<persName><surname>Ramakrishnan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2596695.2596699</idno>
		<ptr target="https://doi.org/10.1145/2596695.2596699" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Web for All Conference</title>
		<meeting>the 11th Web for All Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploring the use of speech input by blind people on mobile devices</title>
		<author>
			<persName><forename type="first">Shiri</forename><surname>Azenkot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/2513383.2513440</idno>
		<ptr target="https://doi.org/10.1145/2513383.2513440" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS &apos;13)</title>
		<meeting>the 15th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Conscience and Critic : Peer Debriefing Strategies in Grounded Theory Research</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">P</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelley</forename><forename type="middle">K</forename><surname>Walczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Paper presented at the Annual Meeting of the American Educational Research Association</title>
		<meeting><address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-04-13">2009. April 13-17, 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Disability, Age, and Informational Privacy Attitudes in Quality of Life Technology Applications</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Beach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Downs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Seelman</surname></persName>
		</author>
		<idno type="DOI">10.1145/1525840.1525846</idno>
		<ptr target="https://doi.org/10.1145/1525840.1525846" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Accessible Computing (TACCESS)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using Thematic Analysis in Psychology</title>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Qualitative Research in Pyschology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="77" to="101" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Home Automation in the Wild: Challenges and Opportunities</title>
		<author>
			<persName><forename type="first">A J Bernheim</forename><surname>Brush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bongshin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ratul</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharad</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Saroiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Dixon</surname></persName>
		</author>
		<idno type="DOI">10.1145/1978942.1979249</idno>
		<ptr target="https://doi.org/10.1145/1978942.1979249" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human in Computing Systems (CHI &apos;11)</title>
		<meeting>the SIGCHI Conference on Human in Computing Systems (CHI &apos;11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2115" to="2124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sharing is Caring: Assistive Technology Designs on Thingiverse</title>
		<author>
			<persName><forename type="first">Erin</forename><surname>Buehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><surname>Branham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdullah</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><forename type="middle">Kelly</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaun</forename><forename type="middle">K</forename><surname>Kane</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702525</idno>
		<ptr target="https://doi.org/10.1145/2702123.2702525" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI &apos;15)</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="525" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Designing smart home interfaces for the elderly</title>
		<author>
			<persName><forename type="first">Zoraida</forename><surname>Callejas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramón</forename><surname>López-Cózar</surname></persName>
		</author>
		<idno type="DOI">10.1145/1651259.1651261</idno>
		<ptr target="https://doi.org/10.1145/1651259.1651261" />
	</analytic>
	<monogr>
		<title level="j">ACM SIGACCESS Accessibility and Computing</title>
		<imprint>
			<biblScope unit="page" from="10" to="16" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robin: Enabling Independence For Individuals With Cognitive Disabilities Using Voice Assistive Technology</title>
		<author>
			<persName><forename type="first">Clare</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Chiodo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adena</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meg</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayanth</forename><surname>Nidever</surname></persName>
		</author>
		<author>
			<persName><surname>Prathipati</surname></persName>
		</author>
		<idno type="DOI">10.1145/3027063.3049266</idno>
		<ptr target="https://doi.org/10.1145/3027063.3049266" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI &apos;17)</title>
		<meeting>the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">What can I say? Addressing User Experience Challenges of a Mobile Voice User Interface for Accessibility</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Astrid</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.1145/2935334.2935386</idno>
		<ptr target="https://doi.org/10.1145/2935334.2935386" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI &apos;16)</title>
		<meeting>the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI &apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="72" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Older adults&apos; attitudes towards and perceptions of &quot;smart home&quot; technologies: a pilot study</title>
		<author>
			<persName><forename type="first">George</forename><surname>Demiris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marilyn</forename><forename type="middle">J</forename><surname>Rantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myra</forename><forename type="middle">A</forename><surname>Aud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><forename type="middle">D</forename><surname>Marek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harry</forename><forename type="middle">W</forename><surname>Tyrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjorie</forename><surname>Skubic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><forename type="middle">A</forename><surname>Hussam</surname></persName>
		</author>
		<idno type="DOI">10.1080/14639230410001684387</idno>
		<ptr target="https://doi.org/10.1080/14639230410001684387" />
	</analytic>
	<monogr>
		<title level="j">Medical Informatics and the Internet in Medicine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="87" to="94" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Designing voice interaction for people with physical and speech impairments</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Derboven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Huyghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><forename type="middle">De</forename><surname>Grooff</surname></persName>
		</author>
		<idno type="DOI">10.1145/2639189.2639252</idno>
		<ptr target="https://doi.org/10.1145/2639189.2639252" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational (NordiCHI &apos;14)</title>
		<meeting>the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational (NordiCHI &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An overview of the Internet of Things for people with disabilities</title>
		<author>
			<persName><forename type="first">Mari</forename><surname>Carmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domingo</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.jnca.2011.10.015</idno>
		<ptr target="https://doi.org/10.1016/j.jnca.2011.10.015" />
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="584" to="596" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Initial Explorations in Child-Agent Interaction</title>
		<author>
			<persName><forename type="first">Stefania</forename><surname>Druga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randi</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchel</forename><surname>Resnick</surname></persName>
		</author>
		<idno type="DOI">10.1145/3078072.3084330</idno>
		<ptr target="https://doi.org/10.1145/3078072.3084330" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Interaction Design and Children (IDC &apos;17)</title>
		<meeting>the 2017 Conference on Interaction Design and Children (IDC &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="595" to="600" />
		</imprint>
	</monogr>
	<note>Hey Google is it OK if I eat you ?</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Privacy concerns for use of Voice Activated Personal Assistant in the public space</title>
		<author>
			<persName><forename type="first">Aarthi</forename><surname>Easwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moorthy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kim-Phuong L</forename><surname>Vu</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2014.986642</idno>
		<ptr target="https://doi.org/10.1080/10447318.2014.986642" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="307" to="335" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Speech Recognition as a Practice Tool for Dysarthria</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fager</forename></persName>
		</author>
		<idno type="DOI">10.1055/s-0037-1602841</idno>
		<ptr target="https://doi.org/10.1055/s-0037-1602841" />
	</analytic>
	<monogr>
		<title level="j">Seminars in Speech and Language</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="220" to="228" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learnability through Adaptive Discovery Tools in Voice User Interfaces</title>
		<author>
			<persName><forename type="first">Anushay</forename><surname>Furqan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichen</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3027063.3053166</idno>
		<ptr target="https://doi.org/10.1145/3027063.3053166" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI&apos;17)</title>
		<meeting>the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1617" to="1623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Longitudinal study of people learning to use continuous voice-based cursor control</title>
		<author>
			<persName><forename type="first">Susumu</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><forename type="middle">O</forename><surname>Wobbrock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518757</idno>
		<ptr target="https://doi.org/10.1145/1518701.1518757" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;09)</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;09)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="347" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cobb</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erin</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Picone-Decaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><surname>Carey</surname></persName>
		</author>
		<idno type="DOI">10.1177/1525822X04266540</idno>
		<ptr target="https://doi.org/10.1177/1525822X04266540" />
	</analytic>
	<monogr>
		<title level="m">Reliability in Coding Open-Ended Data: Lessons Learned from HIV Behavioral Research</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="307" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">At times avuncular and cantankerous, with the reflexes of a mongoose&quot;: Understanding Self-Expression through Augmentative and Alternative Communication Devices</title>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Shaun K Kane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Paradiso</surname></persName>
		</author>
		<author>
			<persName><surname>Campbell</surname></persName>
		</author>
		<idno type="DOI">10.1145/2998181.2998284</idno>
		<ptr target="https://doi.org/10.1145/2998181.2998284" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing (CSCW &apos;17)</title>
		<meeting>the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing (CSCW &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1166" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lifelogging memory appliance for people with episodic memory impairment</title>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anind</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<idno type="DOI">10.1145/1409635.1409643</idno>
		<ptr target="https://doi.org/10.1145/1409635.1409643" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on Ubiquitous computing -UbiComp &apos;08</title>
		<meeting>the 10th international conference on Ubiquitous computing -UbiComp &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Like Having a Really bad PA&quot;: The Gulf between User Expectation and Experience of Conversational Agents</title>
		<author>
			<persName><forename type="first">Ewa</forename><surname>Lugar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abigail</forename><surname>Sellen</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858288</idno>
		<ptr target="https://doi.org/10.1145/2858036.2858288" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI &apos;16)</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems (CHI &apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="5286" to="5297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Comparing Social Robot, Screen and Voice Interfaces for Smart-Home Control</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Luria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Zuckerman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3025453.3025786</idno>
		<ptr target="https://doi.org/10.1145/3025453.3025786" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI &apos;17)</title>
		<meeting>the 2017 CHI Conference on Human Factors in Computing Systems (CHI &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="580" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Listening Keyboard for Users with Motor Impairments -A Usability Study *</title>
		<author>
			<persName><forename type="first">Bill</forename><surname>Manaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valanne</forename><surname>Macgyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michail</forename><surname>Lagoudakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Speech Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="371" to="388" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The acceptability of home monitoring technology among community-dwelling older adults and baby boomers</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Mihailidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Cockburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Longley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Boger</surname></persName>
		</author>
		<idno type="DOI">10.1080/10400435.2008.10131927</idno>
		<ptr target="https://doi.org/10.1080/10400435.2008.10131927" />
	</analytic>
	<monogr>
		<title level="j">Assistive technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Accessibility in context: understanding the truly mobile experience of smartphone users with motor impairments</title>
		<author>
			<persName><forename type="first">Maia</forename><surname>Naftali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leah</forename><surname>Findlater</surname></persName>
		</author>
		<idno type="DOI">10.1145/2661334.2661372</idno>
		<ptr target="https://doi.org/10.1145/2661334.2661372" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international ACM SIGACCESS conference on Computers and accessibility (ASSETS &apos;14)</title>
		<meeting>the 12th international ACM SIGACCESS conference on Computers and accessibility (ASSETS &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Voice operated intelligent wheelchair -VOIC</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Pačnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Benkič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bojan</forename><surname>Brečko</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISIE.2005.1529099</idno>
		<ptr target="https://doi.org/10.1109/ISIE.2005.1529099" />
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Industrial Electronics (IEEE ISIE &apos;05)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1221" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Addressing the needs of speakers with longstanding dysarthria: computerized and traditional therapy compared</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pam</forename><surname>Enderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hawley</surname></persName>
		</author>
		<idno type="DOI">10.1080/13682820601173296</idno>
		<ptr target="https://doi.org/10.1080/13682820601173296" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Language &amp; Communication Disorders</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="61" to="67" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Design and evaluation of a smart home voice interface for the elderly: Acceptability and objection aspects</title>
		<author>
			<persName><forename type="first">François</forename><surname>Portet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Vacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Golanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camille</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brigitte</forename><surname>Meillon</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00779-011-0470-5</idno>
		<ptr target="https://doi.org/10.1007/s00779-011-0470-5" />
	</analytic>
	<monogr>
		<title level="j">Personal and Ubiquitous Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="127" to="144" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Alexa is my new BFF&quot;: Social Roles, User Satisfaction, and Personification</title>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Purington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessie</forename><forename type="middle">G</forename><surname>Taft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Sannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalya</forename><forename type="middle">N</forename><surname>Bazarova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Hardman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename></persName>
		</author>
		<idno type="DOI">10.1145/3027063.3053246</idno>
		<ptr target="https://doi.org/10.1145/3027063.3053246" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA &apos;17)</title>
		<meeting>the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2853" to="2859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Speech Interaction with Personal Assistive Robots Supporting Aging at Home for Individuals with Alzheimer&apos;s Disease</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Rudzicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosalie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Momotaz</forename><surname>Begum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Mihailidis</surname></persName>
		</author>
		<idno type="DOI">10.1145/2744206</idno>
		<ptr target="https://doi.org/10.1145/2744206" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Accessible Computing (TACCESS)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Voice control of a powered wheelchair</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">C</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">P</forename><surname>Levine</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNSRE.2002.1031981</idno>
		<ptr target="https://doi.org/10.1109/TNSRE.2002.1031981" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="122" to="125" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Maintaining multiple sclerosis patients&apos; quality of life -a case study on environment control assistance in a smart home</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Stahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Laub</surname></persName>
		</author>
		<idno type="DOI">10.1145/3056540.3064943</idno>
		<ptr target="https://doi.org/10.1145/3056540.3064943" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA &apos;17)</title>
		<meeting>the 10th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA &apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="83" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Looking for Respite and Support : Technological Opportunities for Spousal Caregivers</title>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Tixier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myriam</forename><surname>Lewkowicz</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702563</idno>
		<ptr target="https://doi.org/10.1145/2702123.2702563" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI &apos;15)</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1155" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Experimental Evaluation of Speech Recognition Technologies for Voice-based Home Automation Control in a Smart Home</title>
		<author>
			<persName><forename type="first">Michel</forename><surname>Vacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Lecouteux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Istrate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Joubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Portet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Sehili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Chahuara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th Workshop on Speech and Language Processing for Assistive Technologies</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="99" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Programming by voice: a hands-free approach for motorically challenged children</title>
		<author>
			<persName><forename type="first">Amber</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramaraju</forename><surname>Rudraraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasa</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avishek</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Sudame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1145/2212776.2223757</idno>
		<ptr target="https://doi.org/10.1145/2212776.2223757" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts (CHI EA &apos;12)</title>
		<meeting>the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts (CHI EA &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2087" to="2092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spearcons ( Speech-Based Earcons ) Improve Navigation Performance in Advanced Auditory Menus</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Bruce N Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoko</forename><surname>Nance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tilman</forename><surname>Palladino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myounghoon</forename><surname>Dingler</surname></persName>
		</author>
		<author>
			<persName><surname>Jeon</surname></persName>
		</author>
		<idno type="DOI">10.1177/0018720812450587</idno>
		<ptr target="https://doi.org/10.1177/0018720812450587" />
	</analytic>
	<monogr>
		<title level="j">Human Factors</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="157" to="182" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Designing a spoken dialogue interface to an intelligent cognitive assistant for people with dementia</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Klara Wolters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Kilgour</surname></persName>
		</author>
		<idno type="DOI">10.1177/1460458215593329</idno>
		<ptr target="https://doi.org/10.1177/1460458215593329" />
	</analytic>
	<monogr>
		<title level="j">Health informatics journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="854" to="866" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">How Do Users Know What to Say?</title>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Yankelovich</surname></persName>
		</author>
		<idno type="DOI">10.1145/242485.242500</idno>
		<ptr target="https://doi.org/10.1145/242485.242500" />
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="32" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Current and Future Mobile and Wearable Device Use by People With Visual Impairments</title>
		<author>
			<persName><forename type="first">Hanlu</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meethu</forename><surname>Malu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uran</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leah</forename><surname>Findlater</surname></persName>
		</author>
		<idno type="DOI">10.1145/2556288.2557085</idno>
		<ptr target="https://doi.org/10.1145/2556288.2557085" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Factors in Computing Systems (CHI &apos;14)</title>
		<meeting>the SIGCHI Conference on Factors in Computing Systems (CHI &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3123" to="3132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">End User Security &amp; Privacy Concerns with Smart Homes</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shrirang</forename><surname>Mare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franziska</forename><surname>Roesner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Usable Privacy and Security (SOUPS &apos;17)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Mac</forename><surname>Voiceover</surname></persName>
		</author>
		<ptr target="https://support.apple.com/kb/PH22549?locale=en_US" />
		<imprint>
			<date>September 14</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<ptr target="http://www.freedomscientific.com/Products/Blindness/JAWS" />
		<title level="m">JAWS Screen Reader -Best in Class</title>
		<imprint>
			<date>September</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dragon NaturallySpeaking -world&apos;s best-selling speech recognition software | Nuance</title>
		<ptr target="https://www.nuance.com/dragon.html" />
		<imprint>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
