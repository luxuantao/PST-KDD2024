<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AutoMine: Harmonizing High-Level Abstraction and High Performance for Graph Mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Daniel</forename><surname>Mawhirter</surname></persName>
							<email>dmawhirt@mymail.mines.edu</email>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><surname>Automine</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Colorado School of Mines</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Colorado School of Mines</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Harmonizing High-Level Abstraction and High Performance for Graph Mining. In ACM SIGOPS 27th Symposium on Operating Systems Principles (SOSP &apos;19)</orgName>
								<address>
									<addrLine>October 27-30</addrLine>
									<postCode>2019</postCode>
									<settlement>Huntsville, New York</settlement>
									<region>ON, NY</region>
									<country>Canada. ACM, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AutoMine: Harmonizing High-Level Abstraction and High Performance for Graph Mining</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3341301.3359633</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph mining</term>
					<term>graph pattern matching</term>
					<term>compiler</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph mining algorithms that aim at identifying structural patterns of graphs are typically more complex than graph computation algorithms such as breadth first search. Researchers have implemented several systems with high-level and flexible interfaces customized for tackling graph mining problems. However, we find that for triangle counting, one of the simplest graph mining problems, such systems can be several times slower than a single-threaded implementation of a straightforward algorithm.</p><p>In this paper, we reveal the root causes of the severe inefficiencies of state-of-the-art graph mining systems and the challenges to address the performance problems. We build AutoMine, a single-machine system to provide both highlevel interfaces and high performance for large-scale graph mining applications. The novelty of AutoMine comes from 1) a new representation of subgraph patterns and 2) compilation techniques that automatically generate efficient mining code with minimized memory consumption from a highlevel abstraction. We have extensively evaluated AutoMine against 3 graph mining systems on 8 real-world graphs of different scales. Our experimental results show that AutoMine often produces several orders of magnitude better performance and can process very large graphs existing systems cannot handle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS Concepts</head><p>• Computing methodologies → Shared memory algorithms; • Software and its engineering → Compilers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph data, thanks to the flexibility of the structure, is ubiquitous in various domains, ranging from bioinformatics to social networks to web analytics. Efficiently processing largescale graphs has attracted great attention leading to a number of highly optimized systems <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b64">65]</ref>. Most of these systems provide a "think like a vertex" (TLV) or "think like an edge" (TLE) programming paradigm to implement graph computation algorithms. Example applications are breadth-first search (BFS) and PageRank, which can be modeled through iterative sparse matrix vector multiplication <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b45">46]</ref>. In each iteration, the system traverses all active vertices or edges, but the processing of each vertex or edge only involves lightweight computation and generates limited intermediate data. For instance, in BFS an active vertex sends its label to all its unexplored neighbors. As such, the optimization efforts of graph computation problems mainly focus on communication reduction <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, locality improvement <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b64">65]</ref>, and load balancing <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>Graph mining problems, however, are fundamentally differ from graph computation problems, because they involve much more complex algorithms and generate huge amounts of intermediate data. For example, the state-of-the-art algorithm to mine the frequency of size-4 cliques of a graph is O (|E|ΔT max ), where E, Δ, and T max respectively represent the edge set, the maximum degree, and the maximum number of triangles incident to an edge. The algorithm needs to enumerate all the triangles of the input graph, which are subgraphs of the size-4 cliques. The size of generated intermediate data can reach several TB for graphs with multiple million edges. The TLV or TLE based systems only maintain states on vertices or edges, which do not consider the subgraph pattern in graph mining problems. Therefore, neither do such systems provide a friendly interface to write graph mining algorithms, nor are they optimized to handle the large amount of intermediate data.</p><p>To address the mismatch, researchers have recently designed multiple systems that explicitly maintain states for subgraph patterns <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55]</ref>. Arabesque <ref type="bibr" target="#b45">[46]</ref> is the first distributed system that proposes the "think like an embedding" paradigm, where an embedding is an instance of a subgraph pattern. By incrementally appending edges to embeddings, Arabesque can enumerate all the embeddings of any desired subgraph pattern, which are processed by userdefined filter and process functions. But distributed mining systems incur high overhead for small graphs and require enterprise clusters for large graphs. <ref type="bibr">Wang et al. address</ref> this problem by proposing RStream <ref type="bibr" target="#b50">[51]</ref>, a single-machine graph mining system. RStream combines edge streaming for outof-core processing and relational algebra operators for users to compose graph mining applications. Despite using less resource, it outperforms several state-of-the-art distributed mining systems on a variety of graph mining workloads.</p><p>Unfortunately, although Arabesque and RStream are specialized systems for graph mining problems, their performance is far from ideal. To perform triangle counting on a medium-sized graph (i.e., MiCo <ref type="bibr" target="#b13">[14]</ref>) with 1.1 million edges, Arabesque needs 43 seconds on a 10-node cluster <ref type="bibr" target="#b50">[51]</ref>. Our experiments on a 20-core machine show that RStream takes 2.5 seconds to process the same graph, but a single-threaded program based on a simple triangle counting algorithm finishes the execution in 0.97 seconds. To provide the highlevel abstraction, both Arabesque and RStream implement generic yet low-efficiency graph mining algorithms that demand tremendous memory consumption. When facing two conflicting goals of providing a high-level abstraction and high performance, a classical problem in system design, they choose the former over the later.</p><p>In this paper, we present AutoMine, the first large-scale graph mining system to harmonize high-level abstraction and high performance on a single machine. A naive approach to provide the best of both worlds is to manually implement various graph mining algorithms and present easy-to-use interfaces to the user. However, this approach faces extreme difficulties because the topology of the subgraph pattern can take numerous forms and the user may be interested in mining different combinations of subgraph patterns. On the contrary, AutoMine does not explicitly implement any graph mining algorithm. It takes a high-level graph mining program as the input and automatically compiles it into efficient C++ code with low algorithm complexity and minimized memory consumption.</p><p>We face two challenges to implement AutoMine. The first challenge roots from the many possible algorithms to solve the same graph mining problem. AutoMine should automatically explore the algorithm space and properly rank the algorithms to select an optimized one for code generation. We point out that in the data mining community, researchers focus on one subgraph pattern (e.g., triangle counting) at a time and manually design algorithms <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22]</ref>. To the best of our knowledge, there exists no prior work on automatically generating efficient graph mining algorithms.</p><p>The second challenge is how to minimize memory consumption. Existing systems generate large amounts of intermediate data, because graph mining problems have nested dependencies: A subgraph pattern is built upon its own subgraphs. Those systems take an easy approach to meet the dependencies, which enumerates and stores all the embeddings of a simple sub-pattern before moving on to generate embeddings of a more complex one. AutoMine should also respect the dependencies but still find room to dramatically reduce memory consumption in the generated algorithm and code at compile time.</p><p>AutoMine addresses the challenges with three novel ideas. First, it represents an embedding by a vertex composition set (i.e., a set of sets of vertices), which 1) saves space compared to table or graph based representations and 2) provides the foundation for automatic algorithm and code generation. Second, AutoMine's schedule generator models a subgraph pattern mining problem as a graph tournament problem and generates algorithms to produce the composition set as well as encode its meaning. Third, when the user program is interested in multiple subgraph patterns, AutoMine's code generator automatically merges the generated algorithms for these patterns to minimize redundant work and maximize data sharing.</p><p>AutoMine is a flexible system that supports the sophisticated functionality of existing systems. AutoMine can process labeled graphs with a support parameter to filter out subgraph pattern whose frequency does not meet the threshold. Moreover, by leveraging memory mapped I/O, AutoMine can process out-of-core graphs that do not fit in the memory by taking advantage of the locality of the generated mining algorithms.</p><p>The proposed techniques allow AutoMine to be significantly faster than existing systems while still providing high-level interfaces. Our experimental results show that AutoMine often outperforms RStream and Arabesque by several orders of magnitude for 4 graph mining applications running on real-world graphs of different scales. Though AutoMine generates exact graph mining programs, it even outperforms ASAP <ref type="bibr" target="#b22">[23]</ref>, a state-of-the-art approximate graph mining system, by up to 68.8X for size-3 motif counting. We find that RStream's out-of-core processing cannot support triangle counting on a graph of 783 million edges given 2TB SSD space, while AutoMine successfully finishes triangle counting and size-4 clique counting on a much larger graph with 25.7 billion edges.</p><p>This paper makes the following contributions: 1) We present AutoMine, the first single-machine graph mining system to provide both high-level abstraction and high performance for graph mining applications. 2) We propose a space-efficient representation of embeddings that lays the foundation for automatic mining algorithm generation. 3) We propose a set of modeling and optimization techniques to generate efficient graph mining programs in C++ with low complexity and minimized memory consumption. 4) We evaluate AutoMine by comparing it against 3 state-of-the-art graph mining systems on 8 real-world graphs. The results show that AutoMine substantially outperforms all these systems with minimal programming effort from the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Single-threaded Triangle Counting vs.</head><p>State-of-the-art Graph Mining Systems Existing graph mining systems provide a high-level abstraction for users to easily write applications. To understand the performance of such systems, we follow the methodology used by McSherry et al. <ref type="bibr" target="#b31">[32]</ref> and compare RStream, which was the fastest among 4 state-of-the-art mining systems (including Arabesque) <ref type="bibr" target="#b50">[51]</ref>, with a single-threaded program for triangle counting. The program implements a simple triangle counting algorithm used in many prior studies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref> as shown in Algorithm 1. Although the performance of triangle counting can be dramatically improved by locality optimization (e.g., tiling-based data reorganization <ref type="bibr" target="#b61">[62]</ref>), we stick with the unoptimized implementation for a fair comparison, because RStream may not apply similar optimizations.</p><p>Figure <ref type="figure">1</ref> shows the running times with 6 real-world graphs on a 20-core machine (details in Section 8). Observe that even though the single-threaded program only uses 1 core, it always outperforms RStream using 20 cores and produces up to 5.7X speedup. We point out that McSherry et al. <ref type="bibr" target="#b31">[32]</ref> showed that their single-threaded benchmark outperforms the fastest graph computation systems by only up to 1.7X. Our results suggest that the high-level abstraction of the graph mining systems eats up even more performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Root causes and challenges Reason 1: Existing graph mining systems implement generic but low-efficiency mining algorithms.</head><p>The stateof-the-art systems provide a high-level abstraction to implement graph mining applications. They typically implement the bulk synchronous parallel (BSP) model and maintain a list (or lists) of embeddings. In each iteration, they try to append one more edge to each of the current embeddings to generate more complicated ones. The process continues until all the embeddings of the considered subgraph patterns have been enumerated. Figure <ref type="figure">2</ref> shows an example of the iterative process to perform triangle counting in RStream. The initial embeddings are a list of all the edges. To append new edges to generate wedge embeddings, RStream executes a join operation on the edge list. The complexity of the join operation is O (|E|) if the edge list is sorted. In the next iteration, RStream joins the edge list with the list of wedge embeddings, whose worst case size is |V |Δ 2 . The simple triangle counting algorithm has complexity O (|E|Δ). Since |V |Δ is typically much larger than |E|, the triangle counting algorithm is much more efficient in practice, especially for power-law graphs. So the state-of-the-art systems have a serious shortcoming compared to specially designed graph mining algorithms.</p><p>Challenges for the remedy. A strawman approach is to implement the state-of-the-art graph mining algorithms as a library and provide high-level interfaces. Unfortunately, graph mining has a well-known combinatorial explosion problem as we increase the subgraph pattern size. For example, there exist only 6 different size-4 connected subgraph patterns but 21 size-5 connected patterns. Designing and implementing specialized algorithms for even the small subgraph patterns (e.g., size less than 7) is labor-intensive. Ideally, we should automatically generate the efficient mining algorithms, but we face an enormous challenge because they differ dramatically for different subgraph patterns. For instance, Ahmed et al. <ref type="bibr" target="#b3">[4]</ref> propose for all the size-4 subgraph patterns 6 distinct algorithms with varying structures and complexities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reason 2: Existing graph mining systems have high memory consumption.</head><p>To process the Patents graph with 16.5 million edges, RStream consumes more than 22GB memory, while the single-threaded program only needs 158MB memory. RStream has such high memory consumption due to its conservative approach to deal with dependencies. As Figure <ref type="figure">2</ref> shows, RStream needs to generate all the wedge embeddings (indicated by the global synchronization) before moving to the next iteration to generate all the triangle embeddings. It hence has to allocate enormous memory space to store the generated intermediate data. If the required space does not fit in the main memory of one machine, RStream flushes the data into disk.</p><p>Challenges for the remedy. Figure <ref type="figure">2</ref> illustrates a simple idea to minimize memory consumption. To enumerate the triangle embedding (a, b, c), we only need to first generate the wedge embedding (a, b, c) it depends on, instead of all the wedge embeddings. However, it is difficult to generalize the idea to more complex subgraph patterns especially for automatic algorithm generation. Moreover, multiple subgraph patterns may share the same sub-pattern. For example, both the size-4 clique pattern and the chordal cycle pattern (i.e., clique minus a diagonal) have triangles in them. Thus, if the system does not store all the embeddings of the sub-pattern, it may need to re-generate or maintain duplicate embeddings, leading to extra space overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of AutoMine</head><p>In this work, we design the AutoMine system to bridge the gap between high-level abstraction and high performance for graph mining applications. AutoMine does not require the user to understand the mining algorithms or system optimization details, but presents a set of high-level APIs. AutoMine automatically generates highly efficient mining programs with low algorithm complexity and minimized memory consumption. We first present the overall architecture of the system with an end-user example and then the APIs.</p><p>The workflow of the AutoMine system has a compilation phase and an execution phase as shown in Figure <ref type="figure">3</ref>. The compilation phase takes a high-level API (MC(4) in the illustrated example for size-4 motif counting) and generates an optimized graph mining program by invoking three components. The first component is the pattern enumerator. It understands the semantics of the high-level API and enumerates all the non-isomorphic subgraph patterns (6 in total for size-4 motif counting) that are involved in the mining task. The second component, the schedule generator, generates an optimized schedule (i.e., algorithm) to identify each of the subgraph patterns. Each schedule is represented by a colored graph with directions assigned to the edges. The last component is the code generator, which considers data reuse in the generated schedules and produces the final mining program in C++. In the execution phase, the mining program processes input graphs and returns the final results.</p><p>APIs. Figure <ref type="figure">3</ref> shows the major APIs to use AutoMine. The definePattern function defines a pattern with a list of 2-tuples, each representing an undirected edge. For example, to define a triangle pattern, user invokes the function as Pattern p = definePattern([(a,b), (b, c), (c,a)]). Since AutoMine only supports connected patterns, it warns the user if the provided list cannot form one. AutoMine supports two elementary APIs, countPatterns and enumeratePatterns to generate programs to respectively count and enumerate the embeddings of the given list of subgraph patterns. To make AutoMine easy to use, it implements APIs to support 3 popular graph mining applications: Clique Counting (CC), Motif Counting (MC), and Frequent Subgraph Mining (FSM) (details in Section 8). Each of these APIs invokes the pattern enumerator to generate the list of subgraph patterns, which is passed to enumeratePatterns or countPatterns to produce the final mining program.</p><p>We next describe the key techniques in the schedule generator and the code generator. Due to space limit, we omit the detailed description of the pattern enumerator, which is a necessary component but only involves engineering work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Set Based Representation</head><p>Section 2 shows that the simple triangle counting algorithm is much more efficient than the generic algorithm implemented in the state-of-the-art graph mining systems. We make two observations about the algorithm. First, it exploits the local structure of the input graph. In the innermost loop, the algorithm discovers a set of vertices, each forming a triangle with the edge embedding (v 0 , v 1 ). The advantage is that the algorithm can safely discard the edge embedding immediately since all the more complex embeddings (i.e. the triangles) built on it are discovered in the same loop iteration. Second, each vertex of the discovered set corresponds to a distinct triangle incident on (v 0 , v 1 ). The intersection operation performed on the neighbor sets of v 0 and v 1 generates the structure.</p><p>Inspired by this algorithm, we ask three questions: 1) Can we generalize the set based representation for any arbitrary pattern? 2) What operations should we use to compute a set? 3) How can we compose these set operations to discover the set? In this section, we explore the first two questions and consider the last question in the next section.</p><p>Consider a connected pattern P k on k (k &gt; 2) vertices, and a sub-pattern P k−1 . An instance of P k is an embedded subgraph denoted as E P k and composed of vertices (v 0 , ...,v k −1 ). We introduce a function F k (E P k −1 ) which needs to meet two requirements. First, it should return a set V k of all the vertices v k that extend an embedding E P k −1 into an E P k . Second, it must only apply set operations on the neighbor sets of the</p><formula xml:id="formula_0">E P k −1 's vertices.</formula><p>Intuitively, F k exists because a graph is essentially a set of neighbor sets. The neighbor sets of v 0 , ...,v k −1 should have sufficient information for us to discover V k precisely because P k−1 is connected. However, we only have four basic set operations with which to implement F k : union, complement, intersection, and subtraction. Only intersection and subtraction are anti-monotonic, meaning their output is no larger than the size of their largest input. So they are the preferred operations to use. Fortunately, the following lemma shows that these two are always sufficient to implement F k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1. F k can use only set intersection and subtraction to discover V k .</head><p>Proof. In order to construct the function F k , suppose a vertex v k which can form an embedding E P k with the vertices from E P k −1 . We partition v 0 , ...,v k −1 into two sets V T and V F . V T contains all the vertices that are neighbors of v k in P k and V F includes the remaining vertices. Any vertex v k in V k must obey the following properties:</p><formula xml:id="formula_1">v k ∈ N (v) for each vertex v in V T , and v k N (v) for each vertex v in V F .</formula><p>We therefore construct F k as follows:</p><formula xml:id="formula_2">V k = F k (E P k −1 ) = v ∈V T N (v) − v ∈V F N (v) Since P k is connected, V T is not empty. F k first</formula><p>performs a reduction on V T with intersection and then subtracts the neighbor sets of the vertices in V F one by one from the result. V k hence includes the vertices that neighbor all v ∈ V T and none of v ∈ V F , completing F k using only intersection and subtraction.</p><p>The proof introduces an algorithm to discover and represent embeddings of the more complex pattern P k based on any embedding of P k −1 . The base pattern P 1 is a vertex, with P 2 being an edge. Hence, the vertex set V k represents a set of embeddings of the non-trivial pattern P k encoded by the sequence {F 1 , ..., F k }, where F 1 returns the vertex set and F 2 returns the neighbor set of a vertex. We name this sequence a schedule of set operations. In other words, once we have a schedule, we can iteratively apply it to all the edge embeddings to discover a set of sets with all the embeddings for an arbitrary pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Schedule Generation</head><p>In the previous section, we show that once we have the schedule for a particular pattern, we have an algorithm to discover all its embeddings. This section presents the techniques to automatically generate an optimized schedule for any given pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Modeling</head><p>The series of functions defined in Section 4 encodes the relationships among the vertices of a pattern. The functions {F 1 , ..., F k } must be applied in order when computing patterns to respect their dependencies. As explored previously, this also implies an order in the discovery of the vertices v 0 , ...,v k−1 .</p><p>While there is a one-to-one mapping between a series of F k and a vertex order, there can be many possible series' of functions for the same pattern. We next determine how to explore the space of possible schedules.</p><p>Given a pattern, we build a colored complete graph to encode all the neighborhood relationships of the vertices. Specifically, we color all of its present edges black and add red edges for the absent ones. Figure <ref type="figure" target="#fig_2">4</ref> shows an example of a colored complete graph for the chordal cycle pattern. With this complete graph, we need to make two decisions. First, we should assign an order to add vertices while discovering progressively more complex patterns. Second, we should assign directions to the edges. Direction encodes a critical property in this construction, denoting which vertex we should search for in the neighbor set of the other. A symmetric graph has the following important property:</p><formula xml:id="formula_3">v a ∈ N (v b ) ⇐⇒ v b ∈ N (v a )</formula><p>Any pair of vertices which share an edge can therefore be discovered in any order. And the diversity of the space of possible orders gives rise to the diverse schedules for a given pattern.</p><p>The directional edges form a tournament of the complete graph, and each unique tournament identifies a distinct schedule. The tournament's edges define relationships encoded in the series of functions F k . Vertex v k has incoming black edges from the vertices in V T and incoming red edges from the vertices in V F , thus defining the schedule. Chordal cycle, as shown in Figure <ref type="figure" target="#fig_2">4</ref>, has 5 unique acyclic tournaments, two of which are shown. The reason for the choice of acyclic tournaments is described in the following lemma: </p><formula xml:id="formula_4">Proof. Suppose a vertex v is part of a cycle [v 0 , ..., v n−1 ].</formula><p>Assume a valid series of functions F k can be constructed according to this cyclic tournament, and recall that F k is permitted to operate only on the vertices [v 0 , ..., v k −1 ]. Suppose v has an incoming edge from vertex v in and an outgoing edge to v out , both from its cycle, each of which has a defined value of k for its corresponding F k . The edges incident on v demand that k v in &lt; k v &lt; k v out . But the cycle implies that there exists a path from v out to v in through the vertices [v 0 , ..., v n−1 ], demanding that k v out &lt; k v in . This forms a contradiction, and proves that a cyclic tournament cannot have a valid schedule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 3. The proof of Lemma 2 demonstrates that an acyclic tournament gives the vertices a total order, which is the necessary condition for a schedule to exist.</head><p>According to Lemma 2 and Corollary 3, acyclic tournaments and valid schedules have a one-to-one correspondence. We therefore choose to iterate over the possible tournaments in order to search the schedule space. In a k-vertex complete graph, there are k! unique orderings of the vertices, and therefore k! possible acyclic tournaments. The colored edges distinguish between some of these orders, making them nonisomorphic, and worth exploring. Note that cliques are a special case, in which all k! permutations are in fact isomorphic, as there are no red edges to distinguish between them. Since Lemma 1 demonstrates the construction of a schedule from a vertex ordering, the space of all non-isomorphic colored acyclic tournaments defines the scheduling space for a particular pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multiplicity</head><p>We notice from the triangle counting algorithm that the corresponding schedule has a multiplicity problem. Given a triangle embedding, the same schedule (i.e., N (v 0 ) ∩ N (v 1 )) can actually observe it from any of its edges. Each undirected edge is represented symmetrically by two directed edges, so we over-count by a factor of 6. We need to automatically determine the multiplicity for a given schedule.</p><p>Symmetry in a pattern introduces this over-counting in all possible schedules for a pattern. The key point is that the order of vertex discovery for a schedule has a number of possibilities equal to the pattern's multiplicity. Consider the tailed triangle (i.e., a triangle with a dangling edge) with 4 vertices (a, b, c, and d). The three vertices, a, b, and c, form a triangle and d is a neighbor of c only. Now consider two schedules to observe the pattern. The first schedule is:</p><formula xml:id="formula_5">F 2 = N (v 0 ) ∩ N (v 1 ) F 3 = N (v 2 ) − N (v 0 ) − N (v 1 )</formula><p>It first discovers a triangle and then the dangling edge. The schedule can observe the pattern in two orders: (a, b, c, d) and (b, a, c, d) because this pattern has a multiplicity of 2.</p><formula xml:id="formula_6">F 2 = N (v 0 ) − N (v 1 ) F 3 = N (v 0 ) ∩ N (v 2 ) − N (v 1 )</formula><p>This schedule starts from the dangling edge to discover a wedge and then a triangle incident on the second edge of the wedge. The schedule can observe the pattern in two orders again: <ref type="figure">(c, d, a, b) and (c, d, b, a</ref>). Algorithm 2 generalizes this strategy to determine the multiplicity of any pattern by counting the automorphic vertex permutations. A schedule's result count divided by multiplicity yields the number of unique pattern instances in a graph. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Root Symmetry</head><p>Multiplicity introduces a computation redundancy problem, because a schedule may observe the same pattern several times. Root symmetry is a special case of multiplicity that only considers the first edge in the discovery order for a schedule, which we refer to as the root edge. If this edge is root symmetric, then we can halve the multiplicity by considering root edges in only one direction while processing the graph. The method for determining if a schedule is root symmetric is simple given the algorithm for multiplicity. If the two vertices incident on the root edge are interchangeable according to the isomorphism test in its inner loop, then the schedule is root symmetric.</p><p>One perspective to understand the efficiency of the rootsymmetry property is that it prunes half of the directed edges from consideration as root edges in F 2 . Since the pattern is nested, applying the idea to each sub-pattern can further prune edges. We leave the generalization of this idea for arbitrary patterns to future work, but show that it can greatly improve the performance for clique patterns. Cliques have a special case of multiplicity and root-symmetry, in that every edge and vertex is indistinguishable, leading to a very high multiplicity of k! for a k-clique. Even if we apply the basic root-symmetry optimization, the multiplicity is still k ! 2 . Observe that after applying the root symmetry optimization, the root edge becomes directional (i.e., v 0 → v 1 ). If we remove v 0 and its edges from the pattern, the remaining sub-pattern is still a clique which is amenable to a second round of the application of the same technique. So a deep application of the root-symmetry idea at every level of F 2..k eliminates the multiplicity entirely for cliques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Code Generation</head><p>This section crystallizes the scheduling idea into a useful system. We first describe how to generate code for a single pattern with data reuse optimizations, followed by the techniques to merge multiple schedules when having different patterns. We then present the infrastructure to support the generated code to process graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Generating Code for a Single Pattern</head><p>Recall from previous section that given a pattern of size n, its schedule is represented by a series of functions F k (0 ≤ k ≤ n), each depending on the vertices [v 0 , ..., v k −1 ]. Such a pattern naturally lends itself to a nested loop structure. At each loop level k, the loop body traverses the vertex set V k −1 and apply F k to [v 0 , ..., v k −1 ] to create a vertex set V k for the next loop. When the execution reaches the innermost loop, it observes [v 0 , ...,v n ] as an embedding of the pattern. Figure <ref type="figure" target="#fig_2">4</ref> shows two schedules for the chordal cycle pattern as well as their corresponding loops to count the embeddings. The generated loop structure, despite its simplicity, is highly memory efficient. The only mandatory intermediate data for a pattern of size k is the series of vertices [v 0 , ..., v k−1 ] and some indices to track positions in their containing sets. Once the corresponding loop is ready to move to another iteration, it is safe to discard all the vertex sets that store [v k , ..., v n−1 ]. Existing systems do not have this property, because their generic algorithms cannot keep track of the dependencies between embeddings.</p><p>While such an approach minimizes the memory footprint, it incurs redundant computation and data accesses. Because each function F k depends on k − 1 neighbor sets, it must access all of those sets each time it is computed. In the example shown in Figure <ref type="figure" target="#fig_2">4</ref>, the generated code for both schedules accesses N (v 0 ), N (v 1 ), N (v 2 ) in the innermost loop. Observe that N (v 0 ) ∩ N (v 1 ) is loop-invariant, meaning that its result remains the same across iterations of the innermost loop. Ideally, we should store the result ahead of time, paying an up-front computation and data access cost to avoid the redundancy in the future. In the optimized code, we move the operation to the second loop and store the result in a vertex set y0y1. We next describe how to generalize this idea for arbitrary patterns.</p><p>We define a prefix of F k as another function F k p where 2 &lt; p &lt; k, which contain all F k 's operations on only vertices [v 0 , ..., v p−1 ]. If the prefix is pre-computed and its results stored, we only have to access the neighbor sets of [v p , ..., v n−1 ] to complete the computation of F k . For the two schedules of the chordal cycle pattern shown in Figure <ref type="figure" target="#fig_2">4</ref>, N (v 0 ) ∩ N (v 1 ) is a prefix of of the last schedule function computed in the innermost loop. If we precompute N (v 0 ) ∩ N (v 1 ), the only neighbor set accessed in the innermost loop is N (v 2 ).</p><p>During code generation for the loop at level k, we traverse each of [F k , ..., F n ] and try to generate code to compute and store the prefix that depends on [v 0 , ..., v k −1 ]. The code generation always succeeds as long as the corresponding V T set (from Section 5) is non-empty, the same requirement for the use of intersection and subtraction. We aggressively apply this optimization because of two reasons. First, it reduces the computation redundancy as we previously discussed. Second, due to the anti-monotonic property of intersection and subtraction discussed in Section 4, the size of the resultant set of a prefix is typically much smaller than the size of its largest input set, which means the inner loops would access much less data. Parallelism is easy to apply within this model using OpenMP on the outermost loop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Estimating Optimality</head><p>From the space of all possible schedules for a pattern, we will need to select one to use in practice. To achieve this goal, there must be a way to estimate the relative performance of each schedule. It is challenging because of the embedded structure and the complex set compositions used in the schedules. Moreover, the relative cost may even depend on the topology of the input graph. We simplify the problem by leveraging a random graph of n vertices, in which any pair of vertices are neighbors with probability p. Hence, the expected size of a neighbor set is n × p. The expected size of N (v i ) ∩ N (v j ) and N (v i ) − N (v j ) is hence n × p 2 and n ×p × (1 −p), respectively, where v i and v j are two different vertices. With the estimate for the two basic operations, we can further estimate the size of the resultant set of any F k . The estimation works even if the prefix pre-computation optimization is applied, because a prefix also uses only intersection and subtraction operations. Given the estimate of the size of all the sets, we can derive the number of iterations of each loop and thus the number of neighbor set accesses in each loop level. By accumulating these estimates over the nested loop structure, we obtain the complexity for the schedule in n and p. When we compare the complexity of different schedules, n is always canceled out, so we only need to define p to properly rank all the schedules. We empirically choose 10 −5 for p in our system to approximate the density of our chosen datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Multi-Pattern Scheduling</head><p>When preparing a combined schedule for multiple patterns, we take the one for each pattern with the lowest data access complexity according to the prior analysis and combine them to form the merged schedule. Schedules for every pattern start with the same F 1 and F 2 , and may remain the same for levels beyond that. Overlap of prefixes can also contribute to data reuse, so running schedules for multiple patterns at the same time is clearly desirable. Schedules always begin converged, and then diverge at some level k, as soon as F k for the schedules differ. Note that once they diverge, they never re-converge. Even if later functions match again, they cannot be combined again, as the paths they took to get there are different. We refer to this as the identity problem, and it affects the way combined prefix storage is handled. Because divergent paths cannot share data, only the future function to be computed among paths that are still converged should be considered when selecting which prefixes to compute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Supporting Infrastructure</head><p>Graph Data AutoMine stores graphs in the binary compressed sparse row format, in which the vertex array stores offsets into the edge array. A vertex v i can find its sorted neighbor list at edge[vertex[i] : vertex[i + 1]]. We use this format for both the in-memory and on-disk storage of graphs, making the graph data simple to handle, and enabling the option to process memory-resident or disk-resident graphs for out-core-processing.</p><p>Parallelization AutoMine uses OpenMP to parallelize mining tasks. Accesses to the graph are read-only, and inherently thread-safe. Accumulators are protected by OpenMP reduce (+) directives such that each thread accumulates results into thread-local memory until the parallel region ends. This makes the implementations easier to generate, as the parallelism is handled automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory Management</head><p>Two goals should be fulfilled by the memory management. First, graph data should not be copied, as it can be read directly. Second, the scratch space used for intermediate storage should be thread-local and reusable to avoid repeated allocation. We achieve these two goals using a VertexSet class which can either contain a read-only reference to graph data, or a writable reference to a scratch region. The scratch data is allocated at the beginning of execution according to the needs of the program. Since no composition of sets using intersection and subtraction can exceed the size of its largest operand, each region is allocated to hold maximum degree vertices. The regions are returned to the available memory pool when a memory-managed VertexSet goes out of scope.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operators</head><p>The VertexSet class also handles the intersection (∩) and subtraction (-) operations as binary operators which, when called, return a memory-managed VertexSet containing the results. Note that the subtraction operation performs one check beyond its defined set operator scope. Since the edge pair</p><formula xml:id="formula_7">(v 0 , v 1 )(v 1 , v 0 ) is not a wedge, but v 0 ∈ N (v 1 ) − N (v 0 )</formula><p>, we must specifically exclude the vertex itself from subtractions when its neighbor list is a right-hand operand. The modification is trivial, but necessary for correctness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Additional Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Supporting out-of-core processing</head><p>The nested loop structure that AutoMine employs requires little memory on top of the graph representation, while previous work may produce multiple terabytes of intermediate data, stored either in distributed memory or on disk. In the case of the Motif-4 application on the MiCo graph with 1M edges, RStream generates 1.21TB of intermediate data, which it stores to disk. In our system, the graph representation consumes about 9MB of memory (755KB of vertex data, 8.3MB of edge data), and the intermediate data takes up an additional 1.7MB. For many graphs that trigger the out-of-core processing of existing systems, AutoMine can easily fit the entire workload into the main memory of a single machine.</p><p>For very large graphs, we may want to employ out-of-core processing to lighten the load of the graph data in memory, which dominates the memory requirement. In this case, Au-toMine leverages memory-mapped files to support out-coreprocessing. The vertex data file and edge data file can be page faulted into physical memory as needed, and remain on disk when it is not. The key factor that makes this an efficient approach is that the total access costs to a given vertex are super-linear in the degree of the vertex. For triangle counting the cost is quadratic, which continues to grow as the target pattern size increases. These super-linear costs produce large differences in access frequency between large-degree and small-degree vertices. The pages that contain the neighbor set of large-degree vertices become hot pages that occupy most of the available memory. We evaluate the efficiency of the out-of-core processing support in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Supporting labeled graphs</head><p>Frequent Subgraph Mining (FSM) is unique from the other mining tasks that we consider in that it demands a labeled graph. Labeled patterns with the same topology, in this formulation, are different if their labels differ (i.e. the definition of isomorphism is expanded to include labels). Given a labeled pattern, AutoMine first generates a schedule of its unlabeled version and includes a lookup table to distinguish between instances of the labeled patterns. The FSM task also introduces a support parameter, which sets a threshold for the minimum number of embeddings of a labeled pattern to exist before it must be counted. This parameter has more selective power when considering a labeled graph, due to the lower average number of occurrences of each possible pattern.</p><p>In order to leverage this selectivity, however, the algorithm must proceed by growing patterns in the BSP style described in Section 2, which drives huge intermediate data requirements. But failing to maintain the intermediate data would make it impossible to determine if a computation could be avoided due to the support parameter. The implementation of labeled graph processing conceptually performs the nested loop schedule up to the next global synchronization point to generate and store the corresponding vertex sets. These sets are then pruned according to the support parameter, and execution resumes. This global synchronization must occur twice to process size-4 FSM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation</head><p>In this section, we evaluate AutoMine's performance against three graph mining systems: Arabesque, RStream, and ASAP <ref type="bibr" target="#b22">[23]</ref>, specifically how well they scale to large graphs and patterns, as well as the optimization techniques proposed in AutoMine. The highlights of the results are as follows: 1) For 24 different mining workloads on real-world graphs, AutoMine is up to 4 orders of magnitude faster than Arabesque, running on 10 machines, and RStream. 2) ASAP uses approximation techniques to accelerate graph mining. Even when it uses 16 machines and 5% as the error target, ASAP takes on average 12.8X longer time to perform size-3 motif counting on 4 real-world graphs compared to AutoMine. 3) RStream runs out of disk space (2TB) for graphs with millions of edges. AutoMine, thanks to its efficient memory use and out-of-core processing capability, can successfully process a graph with more than 25 billion edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graphs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>#Vertices #Edges Description</head><p>CiteSeer <ref type="bibr" target="#b13">[14]</ref> 3264 4536 Publication citation MiCo <ref type="bibr" target="#b13">[14]</ref> 96638 1080156 Co-authorship Patents <ref type="bibr" target="#b25">[26]</ref> 3.8M 16.5M US Patents LiveJournal-1 <ref type="bibr" target="#b6">[7]</ref> 4.8M 42.9M Social network Orkut <ref type="bibr" target="#b1">[2]</ref> 3.1M 117.2M Social network UK-2005 <ref type="bibr" target="#b8">[9]</ref> 39.5M 783M Web graph Youtube <ref type="bibr" target="#b56">[57]</ref> 1.1M 3M Social network LiveJournal-2 <ref type="bibr" target="#b56">[57]</ref> 4M 34.7M Social network GSH-2015 <ref type="bibr" target="#b7">[8]</ref> 988.5M 25.7B Web graph Table <ref type="table">1</ref>. Graph Datasets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Methodology</head><p>Graph mining applications AutoMine can generate programs to perform graph mining tasks for arbitrary patterns. We use its capability to provide high-level interfaces to run 4 popular graph mining applications on labeled or unlabeled graphs.</p><p>Triangle Counting (TC) is a simple mining task to count all the embeddings of the triangle pattern (i.e., size-3 clique) in an unlabeled graph. Clique Counting (CC) counts all the embeddings of the clique pattern given a specific size in an unlabeled graph. It only involves the 1-hop neighbors of each vertex but may incur heavy workload depending on the size. Motif Counting (MC) counts all the embeddings of each of the connected patterns of a particular size in an unlabeled graph. We consider 3-motifs (wedge and triangle) and 4motifs (6 distinct patterns). Frequent Subgraph Mining (FSM) aims at discovering interesting patterns in a labeled graph. Given the support parameter and the pattern size, it counts embeddings of the patterns whose appearances exceed the threshold. <ref type="table">1</ref> shows the 9 real-world graphs used in the experiments. Wang et al. <ref type="bibr" target="#b50">[51]</ref> used the first 6 graphs to evaluate RStream to demonstrate that it outperforms multiple other mining systems, including Arabesque, by at least 1.7X. We hence also use these graphs to experiment with AutoMine and RStream. Since we do not have access to a private cluster, we use the performance numbers reported by Wang et al. for Arabesque, which was run on a 10-node cluster, each node equipped with a 8-core Intel E5-2640 v3 CPU and 32GB memory <ref type="bibr" target="#b50">[51]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets and settings Table</head><p>The ASAP system is not released, but the authors reported its performance on CiteSeer, MiCo, Youtube, and LiveJournal-2 <ref type="bibr" target="#b22">[23]</ref>. They used a cluster of 16 Amazon EC2 r4.2xlarge instances, each having 8 virtual CPUs and 61GB memory. We also use the 4 graphs to compare AutoMine with ASAP.</p><p>We run experiments with AutoMine and RStream on a single machine with 2 10-core Intel Xeon E5-2630 (v4) CPUs (hyper-threading enabled), 64GB of memory, and 2TB of SSD. The machine runs on Ubuntu 16.04 with Linux kernel version 4.4.0-143. We use the GCC compiler with optimization level O3 to compile RStream and the programs generated by AutoMine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Comparisons with RStream and Arabesque</head><p>We run all 4 mining applications with AutoMine and RStream on CiteSeer, MiCo and Patents, because the RStream paper only shows the timing results on these graphs for Arabesque. Table <ref type="table" target="#tab_0">2</ref> reports the running times of the three systems, which do not include the graph loading time.</p><p>For triangle counting, both RStream and Arabesque scale poorly to larger graphs. Patents is a medium-sized graph with less than 20 million vertices, but RStream takes 9.6 seconds to process it. Arabesque's performance is even worse. Au-toMine's automatically generated triangle counting code produces 68.6X and 820.7X speedup over RStream and Arabesque, respectively. Observe that AutoMine also outperforms the single-threaded implementation by 24.3X on MiCo and by 44.3X on Patents, showing that its high-level abstraction does not sacrifice any performance for this application. Since CiteSeer is a tiny graph, AutoMine's parallelization adds non-trivial overhead and shows worse performance than the single-threaded implementation.</p><p>The same trend continues for motif counting and 5-clique counting. Motif counting is more compute-intensive than triangle counting, so all the systems take much longer time. Though MiCo and Patents can easily fit into the memory, RStream still heavily uses the disk and yields poor performance for 3-motif counting. When performing 4-motif counting, RStream's execution times out after 48 hours on MiCo and runs out of disk space on Patents. Arabesque can only process the smallest graph and runs out of memory with 10 machines for the other two. AutoMine only takes up to 22 seconds to run 4-motif counting on any of the graphs. AutoMine is particularly good at clique counting thanks to its aggressive application of the root-symmetry optimization. It only needs 0.17 seconds to run 5-CC Patents, leading to a speedup of 777X over RStream and 1011X over Arabesque.</p><p>FSM is a special application because of its support parameter. Since support is essentially a threshold to filter out infrequent patterns, the larger support is, the better the performance is for RStream and Arabesque. Because CiteSeer is a tiny graph, with support ≥ 300 most patterns are filtered out, leading to trivial computation overhead. RStream is hence not much slower than AutoMine. For both MiCo and Patents, AutoMine is consistently faster than RStream and Arabesque. Notice that AutoMine does not benefit from the support parameter as much as RStream and Arabesque. A plausible reason is that the support parameter substantially reduces the memory consumption for RStream and Arabesque, but AutoMine has little memory space overhead even with support of 1. Filtering out the size-3 patterns does not affect the number of iterations of the two outermost loops AutoMine needs to execute.  Figure <ref type="figure" target="#fig_4">5</ref> shows the capacity needed by RStream and Au-toMine to fit the entire workload (graph plus intermediates) into the main memory (note that the RStream numbers are a lower bound). When the space need exceeds the available memory, RStream stores the data into disk. Triangle counting, despite its simplicity, incurs on average 520MB space overhead for intermediates. AutoMine reduces the average space overhead to only 8.4KB. The results demonstrate the efficient memory use of the automatically generated schedules, which exploits the local graph structures and optimizes data reuse. We also run AutoMine and RStream on size-4 FSM with different support parameters. Figure <ref type="figure">6</ref> presents the results in log scale. The missing bars for RStream indicate execution failure due to insufficient disk space. "TO" on top of the bars for RStream shows that its execution times out after 48 hours. AutoMine successfully handles all the workloads. RStream needs tremendous disk space and fails to process Patents when support is small (i.e., less filtering). When support is large, most patterns are filtered out, so RStream can fit the data into main memory, producing better performance. Similar to the experiments on 3-FSM, AutoMine does not benefit much from using support except on MiCo with support=5K, which aggressively filters out most size-2 and size-3 patterns.</p><p>We run triangle counting and 3-motif counting on the 3 larger graphs used in the RStream paper as well as LiveJournal-2 and Youtube. RStream runs out of disk space or times out for all the 3-motif counting runs and TC on UK-2005. Figure <ref type="figure">7</ref> hence only shows the triangle counting results for RStream. AutoMine runs at least 140.5X faster than RStream, because it can easily fit the workload into memory even for the largest graph UK-2005, while RStream demands too much disk (e.g., at least 147TB for UK-2005).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Comparisons with ASAP</head><p>ASAP samples edges to produce approximate graph mining results. Though AutoMine always generates exact graph mining programs, we compare AutoMine with ASAP to show that without a high-performance baseline system, the approximation techniques fail to yield satisfactory performance. We point out that the ASAP paper uses 5% as the error target to report their results. This is an aggressive setting, because prior work shows that even with 1% error target, the approximation techniques can produce two orders of magnitude performance improvement <ref type="bibr" target="#b30">[31]</ref>. Figure <ref type="figure">8</ref> shows the performance comparisons for 3-motif counting on 4 graphs used by the ASAP paper. Despite producing the exact counts using a single machine, AutoMine outperforms ASAP, running on 16 machines, by up to 68.8X (on average 12.8X). The reason is that ASAP follows Arabesque's basic approach to enumerate and store embeddings, hence inheriting the major weaknesses of inefficient algorithms and high memory consumption. It is possible to integrate the approximation techniques of ASAP into AutoMine when generating schedules, which has potential to produce much better performance if the user is willing to tolerate some accuracy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Evaluating AutoMine's techniques</head><p>Schedule Selection AutoMine explores the schedule space and may generate many schedules for the same pattern. When there are multiple patterns (e.g., motif counting), the space is even larger with different combinations of the schedules for these patterns. To evaluate the effectiveness of Au-toMine's automatic approach to produce an optimized combined schedule, we enumerate all the 560 possible combined schedules for size-4 motif counting, which operates on 6 patterns. Figure <ref type="figure">9</ref> shows the performance results of the schedules running on Patents. We use 3 parameters to group the schedules for a clear presentation of the data, namely the number of vertex sets, the number of intersection operations, and the number of subtraction operations in the generated static program. Each data point in the figure is represented by a tuple of these parameters. We make three observations. First, the schedules with the same parameters tend to perform similarly. Second, schedules with different parameters (e.g., 12_3_11 and 13_5_9) may also have similar performance. Finally, the optimal schedule is about 2.4X faster than the slowest schedule. AutoMine's greedy approach described in Section 6.3 finds the schedule represented by the star symbol, which is 9.9% slower than the optimal schedule.</p><p>Multi-core Scalability AutoMine automatically generates parallel programs to leverage the multiple cores on the platform. Figure <ref type="figure">10</ref> shows the performance improvement with more threads. From 1 thread to 10 threads, AutoMine enjoys almost linear scalability, which becomes worse beyond 10 threads and further degrade beyond 20 threads. The reason is that the systems has 2 CPUs, each with 10 cores. AutoMine can efficiently utilize 1 CPU but using 2 CPUs triggers the NUMA effect, which is exacerbated by the irregular memory accesses inherent in graph applications. By launching more than 20 threads, AutoMine has to run more than one thread per core with hyper-threading, leading to diminishing returns. With low memory consumption and excellent scalability to physical cores, we would expect AutoMine to perform well in a distributed environment, even with trivial data replication, though such an evaluation is outside the scope of this paper.  As far as we are aware, these are the first 8-node pattern results published for graphs of this scale, which can be seen in Figure <ref type="figure" target="#fig_8">11</ref>. RStream times out at 12 hours for all 6 of the experiments shown, even the ones that take AutoMine less than 1 second to complete. This showcases the real power of AutoMine to enable pattern mining at scales which were not possible with prior systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out-of-core Processing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Related Work</head><p>Graph mining systems and algorithms. Arabesque <ref type="bibr" target="#b45">[46]</ref> built on Giraph <ref type="bibr" target="#b0">[1]</ref> is the first generic distributed graph mining system that spurs much interest in the community. G-thinker <ref type="bibr" target="#b54">[55]</ref> and G-miner <ref type="bibr" target="#b9">[10]</ref> address some of the performance issues of Arabesque with lower-level interfaces. Unfortunately, the current release of the systems does not support frequent subgraph mining and motif counting. Dist-Graph <ref type="bibr" target="#b44">[45]</ref> is a distributed system to focus on FSM. It leverages pruning techniques to reduce the search space and provides optimized graph partitioning and collective communication operations. ScaleMine <ref type="bibr" target="#b2">[3]</ref> is an MPI-based system to perform FSM, which uses approximation to optimize load balancing, prune the search space, and guide intra-task parallelism. ASAP <ref type="bibr" target="#b22">[23]</ref> accelerates graph mining by sampling subgraph patterns but can only produce approximate results. The distributed graph mining systems use expensive clusters and are difficult to debug. To address these issues, Wang et al. propose RStream <ref type="bibr" target="#b50">[51]</ref>, the first single-machine, outof-core mining system. It supports a rich set of relational algebra operators, such as join, for programmers to compose mining applications which are executed by the underlying runtime through data streaming from and to disk. Though RStream efficiently implements out-of-core processing and the relational algebra operators, its abstraction, which is similar to that of Arabesque, leads to inefficient graph mining algorithms and high memory consumption by introducing severe, unnecessary synchronization. In contrast, AutoMine leverages a fundamentally different set-centric abstraction, so neither Arabesque nor RStream can implement our methods.</p><p>Motif counting has attracted significant attention in the data mining community <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b52">53]</ref>. Ahmed et al. carefully consider the combinatorial properties of the motifs to reduce the complexity of the algorithms <ref type="bibr" target="#b3">[4]</ref>. Our automatically generated algorithms are similar to their manually designed ones. Researchers also propose approximate motif counting algorithms <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38]</ref> based on sampling, which may be implemented in AutoMine if exact counting is not required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph computation systems.</head><p>Most distributed graph computation systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b63">64]</ref> implement the vertex-centric or edge-centric programming model. The programmer has to implement low-level functions to run on each vertex or edge, which are difficult to write to identify subgraph patterns. Performance optimization of such systems mainly focuses on data reorganization <ref type="bibr" target="#b63">[64]</ref>, load balancing <ref type="bibr" target="#b10">[11]</ref>, communication reduction <ref type="bibr" target="#b17">[18]</ref>, or graph partitioning <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b63">64]</ref>. AutoMine may implement some of these techniques (e.g., locality optimization) to further improve performance.</p><p>Many single-machine graph computation systems <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref>] assume that the input graph as well as the intermediate data can fit in the main memory. Because modern machines typically have large memory and the graph computation algorithms do not generate much intermediate data, these systems can practically handle most real-world graphs. They heavily optimize locality and scheduling, and achieve great performance for a broad set of graph computation problems.</p><p>Out-of-core graph computation on a single machine has attracted great attention since the introduction of GraphChi <ref type="bibr" target="#b24">[25]</ref>, the first of its kind. The idea is to stream edges and updates from and to disk as partitions if they do not fit in the memory. Many systems <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b64">65]</ref> leverage this idea with different optimizations. X-stream <ref type="bibr" target="#b39">[40]</ref> optimizes away random accesses on vertex data but may stream unuseful edges to the memory. Vora et al. <ref type="bibr" target="#b48">[49]</ref> proposes a runtime to filter out edges that make no contribution to the update of vertices. GraphQ <ref type="bibr" target="#b49">[50]</ref> can figure out the edge partitions that may be needed by the queries and only load these partitions. AutoMine leverages memory-mapped I/O to support out-of-core processing that efficiently exploits the locality of subgraph patterns and the neighbor set of hot vertices. <ref type="bibr" target="#b61">[62]</ref> for graph computations and a compiler to generate efficient code. GraphIt, similar to Halide <ref type="bibr" target="#b26">[27]</ref> for image processing and TVM <ref type="bibr" target="#b11">[12]</ref> for deep learning, separates the algorithm and its schedule. This decomposition enables relatively easy application of a set of compiler optimization techniques, such as edge traversal direction, locality improvement, and kernel fusion. While GraphIt has a sufficiently general programming interface, it cannot express the functional relationships between vertices. So its optimization phases cannot fundamentally restructure the loop ordering to resolve dependencies according to the ideas proposed in this paper. Pai and Pingali <ref type="bibr" target="#b34">[35]</ref> propose a compiler to compile graph computation algorithms for GPUs. The compiler particularly addresses the challenges of optimizing throughput due to the special thread organization, the SIMD execution model, and the complex memory hierarchy of the GPU architecture. The Abelian <ref type="bibr" target="#b15">[16]</ref> compiler takes a graph computation algorithm and generates code to execute on distributed systems with heterogeneous processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compiler optimization for graph computation. Zhang et al. propose a DSL called GraphIt</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion and Future Work</head><p>We proposed a system to produce up to several-order-ofmagnitude higher performance than existing systems for a variety of graph mining tasks on real-world graphs. The system provides high-level interfaces, which assume no knowledge of the user about graph mining algorithms, and automatically generates efficient mining programs. Though the system runs on a single machine, it can process very large graphs with tens of billions of edges that existing systems cannot handle. It is interesting to extend AutoMine for distributed processing when the input graphs cannot even fit into the disk of a single machine. In this case, AutoMine's local exploration complicates graph partitioning and load balancing. It is also critical to implement the basic set operators efficiently in a distributed manner.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1 :begin 2 n ← 0; 3 for v 0 's neighbors 4 for v 1 in N (v 0 ) do 5 s 6 n ← n + |s |; 7 n ← n/ 6 ;Figure 1 .</head><label>1230456761</label><figDesc>Figure 1. Performance comparisons on triangle counting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Embedding enumeration for triangle counting in RStream.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Scheduling for Chordal Cycle</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 2 :begin 2 M ← 0; 3 base_order 4 for 5 Pattern P n ← empty; 6 for 7 P 9 M</head><label>22345679</label><figDesc>Computing Multiplicty for a Pattern input : P n : the Pattern. output : M : the multiplicity of S counting P n . 1 ← range [0..n); order in permutations (base_order ) do Edдe (v a , v b ) in P n do n .add_edдe (order [v a ], order [v b ]); 8 if equal (P n , P n ) then ← M + 1;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Needed space for RStream and AutoMine to fit all the data into memory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Figure 6. Size-4 FSM with different support parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .Figure 9 .</head><label>89</label><figDesc>Figure 8. Results versus ASAP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 Figure 10 .</head><label>110</label><figDesc>Figure 10. Threading scalability</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. AutoMine Performance for Large Patterns</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Comparisons between AutoMine (AM), singlethreaded triangle counting (ST), RStream (RS), and Arabesque (AR) on CiteSeer, MiCo, and Patents. 'T' indicates timeout after 48 hours of execution. 'F' indicates execution failure due to insufficient memory or disk space.</figDesc><table><row><cell></cell><cell></cell><cell cols="8">App. Sys. CiteSeer MiCo Patents</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AM</cell><cell cols="2">0.01</cell><cell></cell><cell>0.04</cell><cell></cell><cell>0.14</cell></row><row><cell></cell><cell></cell><cell>TC</cell><cell>RS</cell><cell cols="2">0.01</cell><cell></cell><cell>2.5</cell><cell></cell><cell>9.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell cols="2">38.1</cell><cell></cell><cell>43.1</cell><cell></cell><cell>114.9</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ST</cell><cell cols="2">0.003</cell><cell></cell><cell>0.97</cell><cell></cell><cell>6.2</cell></row><row><cell></cell><cell></cell><cell>3-MC</cell><cell>AM RS</cell><cell cols="4">0.016 0.13 1666.9 0.12</cell><cell cols="2">0.5 1149.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell cols="2">40.6</cell><cell></cell><cell>51.7</cell><cell></cell><cell>116</cell></row><row><cell></cell><cell></cell><cell>4-MC</cell><cell>AM RS</cell><cell cols="2">0.024 2.2</cell><cell></cell><cell>22.0 T</cell><cell></cell><cell>20.0 F</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell></cell><cell>F</cell><cell></cell><cell>F</cell><cell></cell><cell>F</cell></row><row><cell></cell><cell></cell><cell>5-CC</cell><cell>AM RS</cell><cell cols="2">0.024 0.075</cell><cell></cell><cell>11.4 F</cell><cell></cell><cell>0.17 134.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell cols="2">42.8</cell><cell cols="2">132.0</cell><cell></cell><cell>174.5</cell></row><row><cell></cell><cell></cell><cell>3-FSM</cell><cell>AM</cell><cell cols="2">0.024</cell><cell></cell><cell>0.88</cell><cell></cell><cell>3.9</cell></row><row><cell></cell><cell></cell><cell>300</cell><cell>RS</cell><cell cols="2">0.086</cell><cell cols="2">649.1</cell><cell cols="2">1453.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell></cell><cell>F</cell><cell></cell><cell>F</cell><cell></cell><cell>F</cell></row><row><cell></cell><cell></cell><cell>3-FSM</cell><cell>AM</cell><cell cols="2">0.037</cell><cell></cell><cell>0.88</cell><cell></cell><cell>3.9</cell></row><row><cell></cell><cell></cell><cell>500</cell><cell>RS</cell><cell cols="2">0.088</cell><cell cols="2">182.6</cell><cell cols="2">1002.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell></cell><cell>F</cell><cell></cell><cell>F</cell><cell></cell><cell>F</cell></row><row><cell></cell><cell></cell><cell>3-FSM</cell><cell>AM</cell><cell cols="2">0.033</cell><cell></cell><cell>0.87</cell><cell></cell><cell>4.1</cell></row><row><cell></cell><cell></cell><cell>1K</cell><cell>RS</cell><cell cols="2">0.09</cell><cell></cell><cell>2.5</cell><cell></cell><cell>81.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell cols="4">35.6 5790.1</cell><cell></cell><cell>F</cell></row><row><cell></cell><cell></cell><cell>3-FSM</cell><cell>AM</cell><cell cols="2">0.02</cell><cell cols="2">0.039</cell><cell></cell><cell>3.9</cell></row><row><cell></cell><cell></cell><cell>5K</cell><cell>RS</cell><cell cols="2">0.087</cell><cell></cell><cell>2.54</cell><cell></cell><cell>36.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell>AR</cell><cell cols="2">41.6</cell><cell cols="2">120.8</cell><cell></cell><cell>F</cell></row><row><cell>Space need (bytes)</cell><cell>1E+0 1E+3 1E+6 1E+9 1E+12</cell><cell cols="3">CiteSeer AutoMine Rstream MiCo Patents CiteSeer MiCo</cell><cell>Patents</cell><cell>CiteSeer</cell><cell>MiCo</cell><cell>Patents</cell><cell>CiteSeer</cell><cell>MiCo</cell><cell>Patents</cell></row><row><cell></cell><cell></cell><cell>TC</cell><cell></cell><cell>3-MC</cell><cell></cell><cell></cell><cell>4-MC</cell><cell></cell><cell></cell><cell>5-CC</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Muthian Sivathanu (our shepherd) and the anonymous reviewers for their constructive comments. We also would like to thank Feng Yan for sharing his servers to conduct part of the experiments. This project was supported in part by NSF grant CCF-1823005 and an NSF CAREER Award (CNS-1750760).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Giraph</surname></persName>
		</author>
		<ptr target="http://giraph.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<ptr target="http://snap.stanford.edu/data/com-Orkut.html" />
	</analytic>
	<monogr>
		<title level="j">Orkut social network</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scalemine: scalable parallel frequent subgraph mining in a single large graph</title>
		<author>
			<persName><forename type="first">Ehab</forename><surname>Abdelhamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuhair</forename><surname>Khayyat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuad</forename><surname>Jamour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</title>
				<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis<address><addrLine>SC; Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-13">2016. November 13-18, 2016. 2016</date>
			<biblScope unit="page" from="716" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient graphlet counting for large networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nesreen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><forename type="middle">G</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><surname>Duffield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Data Mining, ICDM 2015</title>
				<meeting><address><addrLine>Atlantic City, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">November 14-17, 2015. 2015</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Squeezing out all the value of loaded data: An out-of-core graph processing system with reduced disk I/O</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weimin</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 USENIX Annual Technical Conference, USENIX ATC 2017</title>
				<meeting><address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">July 12-14, 2017. 2017</date>
			<biblScope unit="page" from="125" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Sublinear-time algorithms for counting star subgraphs with applications to join selectivity estimation</title>
		<author>
			<persName><forename type="first">Maryam</forename><surname>Aliakbarpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amartya</forename><surname>Shankha Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Themitstoklis</forename><surname>Gouleakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronitt</forename><surname>Rubinfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anak</forename><surname>Yodpinyanee</surname></persName>
		</author>
		<idno>CoRR, abs/1601.04233</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Group formation in large social networks: Membership, growth, and evolution</title>
		<author>
			<persName><forename type="first">Lars</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;06</title>
				<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="44" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Layered label propagation: A multiresolution coordinate-free ordering for compressing social networks</title>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastiano</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World Wide Web</title>
				<editor>
			<persName><forename type="first">Sadagopan</forename><surname>Srinivasan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Krithi</forename><surname>Ramamritham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Arun</forename><surname>Kumar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Ravindra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Elisa</forename><surname>Bertino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</editor>
		<meeting>the 20th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="587" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The webgraph framework I: compression techniques</title>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastiano</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on World Wide Web, WWW 2004</title>
				<meeting>the 13th international conference on World Wide Web, WWW 2004<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">May 17-20, 2004. 2004</date>
			<biblScope unit="page" from="595" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">G-miner: an efficient task-oriented graph mining system</title>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunjian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
				<meeting>the Thirteenth EuroSys Conference<address><addrLine>Porto, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-23">2018. April 23-26. 2018. 2018</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Powerlyra: differentiated graph computation and partitioning on skewed graphs</title>
		<author>
			<persName><forename type="first">Rong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanzhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth European Conference on Computer Systems, EuroSys 2015</title>
				<meeting>the Tenth European Conference on Computer Systems, EuroSys 2015<address><addrLine>Bordeaux, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">April 21-24, 2015. 2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TVM: an automated end-to-end optimizing compiler for deep learning</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddie</forename><forename type="middle">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haichen</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meghan</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Ceze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Operating Systems Design and Implementation</title>
				<meeting><address><addrLine>Carlsbad, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-08">2018. October 8-10. 2018. 2018</date>
			<biblScope unit="page" from="578" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Approximately counting triangles in sublinear time</title>
		<author>
			<persName><forename type="first">Talya</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Ron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">GRAMI: frequent subgraph and pattern mining in a single large graph</title>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Elseidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehab</forename><surname>Abdelhamid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spiros Skiadopoulos, and Panos Kalnis</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="517" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Parallelizing sequential graph computations</title>
		<author>
			<persName><forename type="first">Wenfei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2018-12">December 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Abelian: A compiler for graph analytics on distributed, heterogeneous platforms</title>
		<author>
			<persName><forename type="first">Gurbinder</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loc</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lenharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Euro-Par 2018: Parallel Processing -24th International Conference on Parallel and Distributed Computing</title>
				<meeting><address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">August 27-31. 2018. 2018</date>
			<biblScope unit="page" from="249" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A study of partitioning policies for graph analytics on large-scale distributed platforms</title>
		<author>
			<persName><forename type="first">Gurbinder</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loc</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="334" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Powergraph: Distributed graph-parallel computation on natural graphs</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haijie</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th USENIX Symposium on Operating Systems Design and Implementation</title>
				<meeting><address><addrLine>Hollywood, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-10-08">2012. October 8-10, 2012. 2012</date>
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graphx: Graph processing in a distributed dataflow framework</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reynold</forename><forename type="middle">S</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Crankshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 14)</title>
				<meeting><address><addrLine>Broomfield, CO</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="599" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graphie: Large-scale asynchronous graph traversals on just a gpu</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mawhirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Buland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Architectures and Compilation Techniques</title>
				<meeting><address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09">2017. September 9-13, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Turbograph: a fast parallel graph engine handling billion-scale graphs in a single PC</title>
		<author>
			<persName><forename type="first">Wook-Shin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyungyeol</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeong-Hoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Soo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinha</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2013</title>
				<meeting><address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">August 11-14, 2013. 2013</date>
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A combinatorial approach to graphlet counting</title>
		<author>
			<persName><forename type="first">Tomaz</forename><surname>Hocevar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janez</forename><surname>Demsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="559" to="565" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Shivaram Venkataraman, Vladimir Braverman, and Ion Stoica</title>
		<author>
			<persName><forename type="first">Anand Padmanabha</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaoxing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)</title>
				<meeting><address><addrLine>Carlsbad, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="745" to="761" />
		</imprint>
	</monogr>
	<note>ASAP: Fast, approximate graph pattern mining at scale</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mathematical foundations of the graphblas</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Kepner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Aaltonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aydin</forename><surname>Buluç</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><surname>Franchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manoj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lumsdaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henning</forename><surname>Meyerhenke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Zalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">G</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><forename type="middle">E</forename><surname>Moreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE High Performance Extreme Computing Conference, HPEC 2016</title>
				<meeting><address><addrLine>Waltham, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">September 13-15, 2016. 2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Graphchi: Large-scale graph computation on just a pc</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12</title>
				<meeting>the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="31" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graphs over time: densification laws, shrinking diameters and possible explanations</title>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">August 21-24, 2005. 2005</date>
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Differentiable programming for image processing and deep learning in halide</title>
		<author>
			<persName><forename type="first">Tzu-Mao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédo</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ragan-Kelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="139" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed graphlab: A framework for machine learning in the cloud</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="716" to="727" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pregel: A system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Malewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">H</forename><surname>Austern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilan</forename><surname>Dehnert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naty</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Leiser</surname></persName>
		</author>
		<author>
			<persName><surname>Czajkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIG-MOD International Conference on Management of Data, SIGMOD &apos;10</title>
				<meeting>the 2010 ACM SIG-MOD International Conference on Management of Data, SIGMOD &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rage -a rapid graphlet enumerator for large networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shavitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Netw</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="810" to="819" />
			<date type="published" when="2012-02">February 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Approxg: Fast approximate parallel graphlet counting through accuracy control</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mawhirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Ai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</title>
				<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-01">2018. May 1-4, 2018. 2018</date>
			<biblScope unit="page" from="533" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scalability! but at what cost?</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">Gordon</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th Workshop on Hot Topics in Operating Systems, HotOS XV, Kartause Ittingen</title>
				<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 18-20, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Naiad: a timely dataflow system</title>
		<author>
			<persName><forename type="first">Derek</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murray</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Isaacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGOPS 24th Symposium on Operating Systems Principles, SOSP &apos;13</title>
				<meeting><address><addrLine>Farmington, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">November 3-6, 2013. 2013</date>
			<biblScope unit="page" from="439" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A lightweight infrastructure for graph analytics</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lenharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGOPS 24th Symposium on Operating Systems Principles, SOSP &apos;13</title>
				<meeting><address><addrLine>Farmington, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">November 3-6, 2013. 2013</date>
			<biblScope unit="page" from="456" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A compiler for throughput optimization of graph algorithms on gpus</title>
		<author>
			<persName><forename type="first">Sreepathi</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016, part of SPLASH 2016</title>
				<meeting>the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016, part of SPLASH 2016<address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-04">October 30 -November 4, 2016. 2016</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Counting and sampling triangles from a graph stream</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanat</forename><surname>Tangwongsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srikanta</forename><surname>Tirthapura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun-Lung</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1870" to="1881" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graphphi: efficient parallel graph processing on emerging throughputoriented architectures</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tekin</forename><surname>Bicer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Parallel Architectures and Compilation Techniques, PACT 2018</title>
				<meeting>the 27th International Conference on Parallel Architectures and Compilation Techniques, PACT 2018<address><addrLine>Limassol, Cyprus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04">November 01-04. 2018. 2018</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Graft: An approximate graphlet counting algorithm for large graph analysis</title>
		<author>
			<persName><forename type="first">Mahmudur</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mansurul</forename><surname>Bhuiyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM &apos;12</title>
				<meeting>the 21st ACM International Conference on Information and Knowledge Management, CIKM &apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1467" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Chaos: Scale-out graph processing from secondary storage</title>
		<author>
			<persName><forename type="first">Amitabha</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Bindschaedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmina</forename><surname>Malicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles, SOSP &apos;15</title>
				<meeting>the 25th Symposium on Operating Systems Principles, SOSP &apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="410" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">X-stream: Edgecentric graph processing using streaming partitions</title>
		<author>
			<persName><forename type="first">Amitabha</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Mihailovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles, SOSP &apos;13</title>
				<meeting>the Twenty-Fourth ACM Symposium on Operating Systems Principles, SOSP &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="472" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast and concurrent RDF queries with rdma-based distributed graph exploration</title>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youyang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feifei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation</title>
				<meeting><address><addrLine>Savannah, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-02">2016. November 2-4, 2016. 2016</date>
			<biblScope unit="page" from="317" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Ligra: A lightweight graph processing framework for shared memory</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Shun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming, PPoPP &apos;13</title>
				<meeting>the 18th ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming, PPoPP &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multicore triangle computations without tuning</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Shun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanat</forename><surname>Tangwongsan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st IEEE International Conference on Data Engineering, ICDE 2015</title>
				<meeting><address><addrLine>Seoul, South Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">April 13-17, 2015. 2015</date>
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Graphmat: High performance graph analytics made productive</title>
		<author>
			<persName><forename type="first">Narayanan</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadathur</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Mostofa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subramanya</forename><forename type="middle">R</forename><surname>Dulloor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Satya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Vadlamudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><surname>Dubey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
				<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2015-07">July 2015</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A distributed approach for graph mining in massive networks</title>
		<author>
			<persName><forename type="first">Nilothpal</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1024" to="1052" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Arabesque: a system for distributed graph mining</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><forename type="middle">J</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgos</forename><surname>Serafini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Siganos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashraf</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><surname>Aboulnaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles, SOSP 2015</title>
				<meeting>the 25th Symposium on Operating Systems Principles, SOSP 2015<address><addrLine>Monterey, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">October 4-7, 2015. 2015</date>
			<biblScope unit="page" from="425" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Parallel triangle counting and k-truss identification using graph-centric methods</title>
		<author>
			<persName><forename type="first">Chad</forename><surname>Voegele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Shan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreepathi</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE High Performance Extreme Computing Conference</title>
				<meeting><address><addrLine>Waltham, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-12">2017. September 12-14, 2017. 2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Parallel triangle counting and k-truss identification using graph-centric methods</title>
		<author>
			<persName><forename type="first">Chad</forename><surname>Voegele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Shan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreepathi</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE High Performance Extreme Computing Conference</title>
				<meeting><address><addrLine>Waltham, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-12">2017. September 12-14, 2017. 2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Load the edges you need: A generic i/o optimization for disk-based graph processing</title>
		<author>
			<persName><forename type="first">Keval</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 USENIX Annual Technical Conference (USENIX ATC 16)</title>
				<meeting><address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="507" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Graphq: Graph query processing with abstraction refinement -scalable and programmable analytics over very large graphs on a single PC</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><forename type="middle">(</forename><surname>Harry) Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><forename type="middle">David</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 USENIX Annual Technical Conference, USENIX ATC &apos;15</title>
				<meeting><address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-10">July 8-10. 2015</date>
			<biblScope unit="page" from="387" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Rstream: Marrying relational algebra with streaming for efficient graph mining on A single machine</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><forename type="middle">Quang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><forename type="middle">Harry</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Operating Systems Design and Implementation</title>
				<meeting><address><addrLine>Carlsbad, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-08">2018. October 8-10. 2018. 2018</date>
			<biblScope unit="page" from="763" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Gunrock: A high-performance graph processing library on the gpu</title>
		<author>
			<persName><forename type="first">Yangzihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuechao</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuduo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Riffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP 2015</title>
				<meeting>the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP 2015<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="265" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fanmod: A tool for fast network motif detection</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Wernicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Rasche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1152" to="1153" />
			<date type="published" when="2006-05">May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Gram: scaling graph computation to the trillions</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilong</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wencong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youshan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yafei</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth ACM Symposium on Cloud Computing</title>
				<meeting>the Sixth ACM Symposium on Cloud Computing<address><addrLine>SoCC; Kohala Coast, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-08-27">2015. August 27-29, 2015. 2015</date>
			<biblScope unit="page" from="408" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">G-thinker: Big graph mining made easier and faster</title>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Da Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qizhen</forename><surname>Özsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Lui</surname></persName>
		</author>
		<idno>CoRR, abs/1709.03110</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Blogel: A block-centric framework for distributed computation on real-world graphs</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilfred</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1981" to="1992" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Defining and evaluating network communities based on ground-truth</title>
		<author>
			<persName><forename type="first">Jaewon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="181" to="213" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Finepar: Irregularity-aware fine-grained workload partitioning on integrated architectures</title>
		<author>
			<persName><forename type="first">Feng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jidong</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingsheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Symposium on Code Generation and Optimization</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Numa-aware graphstructured analytics</title>
		<author>
			<persName><forename type="first">Kaiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</title>
				<meeting>the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-02-07">2015. February 7-11, 2015. 2015</date>
			<biblScope unit="page" from="183" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Exploring the hidden dimension in graph processing</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weimin</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016</title>
				<meeting><address><addrLine>Savannah, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">November 2-4, 2016. 2016</date>
			<biblScope unit="page" from="285" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Wonderland: A novel abstraction-based outof-core graph processing system</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youwei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengying</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018</title>
				<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2018<address><addrLine>Williamsburg, VA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">March 24-28. 2018. 2018</date>
			<biblScope unit="page" from="608" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Graphit: a high-performance graph DSL</title>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengjiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riyadh</forename><surname>Baghdadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shoaib</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Shun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><forename type="middle">P</forename><surname>Amarasinghe</surname></persName>
		</author>
		<idno>121:1-121:30</idno>
	</analytic>
	<monogr>
		<title level="j">PACMPL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Flashgraph: Processing billion-node graphs on an array of commodity ssds</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Disa</forename><surname>Mhembere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randal</forename><forename type="middle">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">T</forename><surname>Vogelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carey</forename><forename type="middle">E</forename><surname>Priebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Szalay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies, FAST 2015</title>
				<meeting>the 13th USENIX Conference on File and Storage Technologies, FAST 2015<address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">February 16-19, 2015. 2015</date>
			<biblScope unit="page" from="45" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Gemini: A computation-centric distributed graph processing system</title>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weimin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaosong</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</title>
				<meeting><address><addrLine>Savannah, GA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="301" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Gridgraph: Largescale graph processing on a single machine using 2-level hierarchical partitioning</title>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 USENIX Annual Technical Conference (USENIX ATC 15)</title>
				<meeting><address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="375" to="386" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
