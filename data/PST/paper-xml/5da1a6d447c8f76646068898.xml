<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simmani: Runtime Power Modeling for Arbitrary RTL with Automatic Signal Selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
							<email>dgkim@berkeley.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Now at Apple</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jerry</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<address>
									<addrLine>MICRO-52, October 12-16</addrLine>
									<postCode>2019</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Simmani: Runtime Power Modeling for Arbitrary RTL with Automatic Signal Selection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3352460.3358322</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a novel runtime power modeling methodology which automatically identifies key signals for power dissipation of any RTL design. The toggle-pattern matrix is constructed with the VCD dumps from a training set, where each signal is represented as a high-dimensional point. By clustering signals showing similar switching activities, a small number of signals are automatically selected, and then the design-specific but workload-independent activity-based power model is constructed using regression against cycle-accurate power traces obtained from industry-standard CAD tools. We can also automatically instrument an FPGA-accelerated RTL simulation with runtime activity counters to obtain power traces of realistic workloads at speed. Our methodology is demonstrated with a heterogeneous processor composed of an in-order core and a custom vector accelerator, running not only microbenchmarks but also real-world machine-learning applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As power and energy efficiency has been the primary concern for both low-power portable computers and high-end servers, runtime power estimation plays an important role not only in validation of hardware design ideas during the design process but also in effective runtime power, energy, and thermal optimizations and management. As a result, there has been significant prior work on various power-modeling methodologies.</p><p>Microarchitectural analytic power models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b65">66</ref>] are widely used in computer architecture research and early hardware design phases. These models in general rely on microarchitectural performance simulators <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b66">67]</ref> to collect necessary statistics. This approach helps computer architects gain some highlevel intuition before RTL implementation, but are limited to microarchitectures similar to those used to build the abstract model. Moreover, as simulation rate is a bottleneck with this methodology,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>computer architects are forced to sample and examine only a tiny fraction of real-world workloads for their studies. Finally, since power validation requires at least RTL implementation, constructing and validating power models is much more difficult for new types of application-specific accelerators.</p><p>Alternatively, power modeling using performance counters has been widely adopted for runtime power and thermal management in real microprocessors <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b62">63]</ref>. Power models are constructed in terms of statistics from existing performance counters, and calibrated against power measurement from real systems. These power models provide quick power estimates by profiling full execution of applications, which can be used in runtime power and thermal optimizations such as dynamic voltage and frequency scaling (DVFS). However, this method has been only successful for well-known traditional microprocessors with existing real implementations. With a novel hardware design, designers should manually identify microarchitectural activities highly correlated with dynamic power dissipation, which is also extremely difficult for non-traditional hardware designs.</p><p>With the slow down in historical transistor scaling, the only way to sustain performance gain is through specialization with application-specific accelerators. Indeed, RTL implementation has become a standard procedure in computer architecture research to estimate the area, power, and energy for novel design ideas. However, dynamic power dissipation is not one-dimensional and cannot be statically determined as it depends heavily on signal activities that can vary across different workloads. Moreover, runtime power, energy, and thermal-management techniques should be studied for novel hardware designs to improve their energy efficiency. For this reason, a general, accurate, and efficient runtime power modeling methodology is required for future architecture research.</p><p>In this paper, we present Simmani, a novel activity-based runtime power modeling methodology that automatically selects the key signals for power dissipation in any RTL design. Our methodology was inspired by the observation that signals showing similar toggle patterns have similar effect on dynamic power dissipation. In the power modeling flow, the toggle pattern matrix, where each RTL signal is represented as a high-dimensional point, is constructed from VCD dumps generated from RTL simulation of the training set. As similarities of signals are quantified by the Euclidean distances between two points, a small number of signals are selected through clustering with dimensionality reduction. Then, the power model is trained through regression against cycle-accurate power traces from industry-standard CAD tools.</p><p>We also present a technique to automatically instrument the target RTL design with toggle activity counters for FPGA-accelerated RTL simulation, which enables runtime power analysis for nontrivial workloads. By applying compiler passes using the FIRRTL compiler <ref type="bibr" target="#b26">[27]</ref>, Simmani automatically inserts activity counters for the selected signals that can be sampled by the software simulation driver for runtime power estimation.</p><p>The main contributions of this paper are as follows:</p><p>? Simmani is a general and easy-to-use runtime power modeling methodology for any RTL design. From VCD dumps and power traces, Simmani automatically constructs power models by selecting a small number of signals without requiring designers' intuition. ? Simmani trains and validates power models against RTL designs with cycle-accurate power traces from industrystandard CAD tools, which gives a high confidence for the model. Simmani also uses standard statistical methods to minimize modeling errors. ? Simmani enables fast runtime power estimation in FPGAaccelerated simulations by automatically instrumenting any RTL design with activity counters, dramatically reducing designers' manual effort. Fast power simulation also enables various case studies including power/thermal analysis of custom accelerators for emerging applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Microarchitectural Power Modeling</head><p>Analytical power modeling <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b65">66]</ref> combined with microarchitectural software simulators <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b66">67]</ref> is widely-used for computer architecture research. This method enables early architecture-level design-space exploration, helping designers gain high-level intuitions before RTL implementation. However, the power models need to be strictly validated against RTL implementations or real systems, which is difficult when exploring new nontraditional designs. We believe Simmani will help improve pre-RTL power models for novel hardware designs by discovering necessary modeling variables for future accelerator research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Power Model Validation</head><p>Shafi et al. <ref type="bibr" target="#b58">[59]</ref> validate an event-driven power model against the IBM PowerPC 405GP processor. Mesa-Martinez et al. <ref type="bibr" target="#b48">[49]</ref> validate power and thermal models by measuring the temperature of real machines. The authors measure temperature using an infrared camera and translate temperature to power using a genetic algorithm. Xi et al. <ref type="bibr" target="#b68">[69]</ref> validate McPAT against the IBM POWER7 processor and illustrate how inaccuracies can arise without careful tuning and validation. Lee et al. <ref type="bibr" target="#b40">[41]</ref> propose a regression-based calibration of McPAT against existing processors to improve its prediction accuracy. McKeown et al. <ref type="bibr" target="#b46">[47]</ref> characterize power and energy of an open-source 25-core processor from its silicon implementation. However, these methodologies can only be applied using existing machines or proprietary data. Jacobson et al. <ref type="bibr" target="#b27">[28]</ref> suggest a power model from pre-defined microarchitectural events and validate it against RTL simulation. However, the approach relies on designer annotations and microbenchmarks exploiting familiarity with a particular family of processor architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Runtime Power Modeling with Performance Counters</head><p>Power modeling based on performance-monitoring counters is also popular for power estimation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b62">63]</ref>. This method provides a quick power estimate, which is also useful for runtime power/thermal optimizations, by profiling full execution of applications. In addition, LeBeane et al. <ref type="bibr" target="#b36">[37]</ref> show a power modeling technique that maps platform-specific event counters to McPAT's event counts.</p><p>There are also a variety of studies on phase/kernel-based power modeling. Isci et al. <ref type="bibr" target="#b25">[26]</ref> characterize power phases with event counter statistics collected by dynamic binary instrumentation. Zheng et al. <ref type="bibr" target="#b69">[70]</ref> present a cross-platform phase-based power modeling methodology that predicts the target design's power from the host platform's counter statistics. Wu et al. <ref type="bibr" target="#b67">[68]</ref> and Greathouse et al. <ref type="bibr" target="#b19">[20]</ref> develop a GPGPU performance and power modeling methodology that clusters training kernels based on performance scaling behaviors and classifies the group of a new kernel with neural nets based on performance counter values.</p><p>However, these methodologies are limited to well-known microprocessors with existing silicon implementations. For novel hardware designs, computer architects need intuition to define representative microarchitectural events highly correlated with power dissipation, which is extremely difficult without collecting empirical data from multiple costly tape-outs.</p><p>Unlike the previous work on event-based power modeling, Simmani trains high-fidelity runtime power models by automatically selecting a small number of signals for any RTL designs using industrystandard CAD tools. In addition, activity counters collecting signal statistics are automatically inserted in FPGA-accelerated simulations to provide rapid power estimates. We also believe our work can bootstrap various counter/phase-based power modeling efforts, by hinting at what activity counters should be available in novel hardware designs for emerging applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Statistical Performance/Power Modeling</head><p>There is significant previous work on statistical performance/power modeling for uniprocessors <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref> and chip multiprocessors <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b39">40]</ref>. Regression <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref> or neural network <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref> models based on microprocessor microarchitectural parameters are trained from simulations of a small number of configurations to predict performance and power for unseen configurations without detailed simulations.</p><p>However, all these models are constructed in the microprocessor context. For non-traditional hardware designs, high-level microarchitectural parameters must be carefully identified using designers' intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Cycle-Level RTL Power Modeling</head><p>Activity-based cycle-level RTL power modeling was also explored in previous work. Metha et al. <ref type="bibr" target="#b47">[48]</ref> build table-based power models for small-size modules by clustering their input transitions resulting in similar energy dissipation to reduce the number of entries in the table. Our approach is different in that we cluster signals based on their toggle patterns to choose a small number of signals as regression variables. Gupta et al. <ref type="bibr" target="#b20">[21]</ref> construct four-dimensional  Bogliolo et al. <ref type="bibr" target="#b9">[10]</ref> build regression-based RTL power models in terms of input and output signals of combinational macro blocks divided by registers. This approach is not scalable since all switching activities of registers need to be tracked, which is intractable for complex hardware designs. In contrast, Simmani is scalable as it automatically selects a small number of signals from a large-scale design for power-model regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">FPGA-Based Power/Energy Modeling</head><p>There has also been extensive work on accelerating power and energy modeling using FPGAs. Coburn et al. <ref type="bibr" target="#b12">[13]</ref> instrument the target design with power computing units for each RTL library component, which incurs significant FPGA resource overhead for large hardware designs. Ghodrat et al. <ref type="bibr" target="#b18">[19]</ref> improve this methodology to reduce the FPGA resource overhead by splitting the instrumented target design across the FPGA and software, which may significantly slow down the emulation speed without careful partitioning.</p><p>Bhattacharjee et al. <ref type="bibr" target="#b5">[6]</ref> manually instrument event counters to collect statistics from the FPGA for runtime power modeling. Sunwoo et al. <ref type="bibr" target="#b63">[64]</ref> manually instrument cycle-level power models that are trained with manually selected signals. Even though these methodologies are applied to fairly large hardware designs, they do not generalize for any RTL design, require designer intuition and manual effort as 1) microarchitectural events and RTL signals must be manually identified and 2) the target design must be manually instrumented with event counters. In contrast, Simmani automatically identifies the RTL signals most correlated with power dissipation and automatically adds activity counters to collect statistics from FPGA-accelerated simulations.</p><p>Zoni et al. <ref type="bibr" target="#b70">[71]</ref> select signals from input/output signals in the module boundaries of the design hierarchy, construct a linear power model in terms of these signals, and instrument the runtime power model visible by software. In general, input and output signals are not the most correlated with power dissipation of a given module, and thus, a smaller number of internal signals are preferred to a larger number of input and output signals for accurate power modeling.</p><p>Kim et al. <ref type="bibr" target="#b34">[35]</ref> propose sample-based energy modeling using FPGAs. In their methodology, any RTL design is instrumented with scan chains and I/O trace buffers to snapshot the RTL state from FPGAs. By randomly sampling RTL state snapshots from realistic applications running on complex hardware designs and replaying the snapshots on gate-level simulation, the average power and the energy of the whole execution can be accurately computed with the confidence interval. However, this methodology does not provide runtime power estimation, which is crucial for power phase analysis and runtime power optimization techniques. Moreover, the instrumentation overhead is much larger than just adding event counters for a small number of signals. We instead use this framework to provide ground truth for power-model training and validation with non-trivial workloads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">POWER MODEL TRAINING</head><p>In this paper, we present the Simmani framework, which automatically selects signals most correlated with power dissipation and trains power models in terms of the selected signals for any RTL design. The core idea is to cluster signals showing similar toggle patterns to choose distinctive signals, and then, train power models in terms of these selected signals using cycle-accurate power traces. The intuition is that signals showing similar toggle patterns have similar effect on dynamic power dissipation and can be factored to share the same coefficient in the power model, minimizing modeling error. Figure <ref type="figure" target="#fig_0">1</ref>  shows how module-level power models using the selected signals are trained through regression against cycle-accurate power traces. Section 3.7 presents how the window size for the toggle pattern matrix is automatically decided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Power Modeling Background</head><p>CMOS power consumption can be decomposed into three major factors:</p><formula xml:id="formula_0">P t ot al = P dyn +P dp +P l eak = ? f (C L V 2 DD +V DD I peak t s )+V DD I l eak</formula><p>The dynamic power, P dyn , is consumed when the capacitance, C L , is charged or discharged, while the direct-path power, P dp , is consumed during rise/fall times due to short-circuit current, I peak t s , when transistors are switching. Both cause power dissipation when signals toggle, the ratio of which is captured by the activity factor, ?. The leakage power, P l eak , is, on the other hand, consumed due to leakage current, I l eak , even when transistors are not switching.</p><p>We may assume leakage power is constant under the condition that the temperature is well-controlled and the threshold voltage does not change dynamically. In this case, the leakage power can be statically computed by CAD tools. In addition, the direct-path power is minimized by CAD tools, and thus, much smaller than dynamic power. However, dynamic power, a primary factor in power dissipation, is hard to determine statically since the activity factor is highly workload-dependent. For this reason, static block-level dynamic power estimation from CAD tools can easily be pessimistic or optimistic. Therefore, we should collect activity statistics from simulations to estimate the dynamic power dissipation of each workload.</p><p>Dynamic power can be computed by summing signal toggle densities over all CMOS gates <ref type="bibr" target="#b52">[53]</ref>:</p><formula xml:id="formula_1">P dyn = 1 2 V 2 DD ? ? {?at es } C ? D ?</formula><p>where C ? and D ? are the load capacitance and the toggle density of gate ?, respectively. Unfortunately, such toggle densities are only available through extremely detailed gate-level simulation, which is not practical for collecting related statistics from realworld workloads running on complex hardware designs. Therefore, for large-scale designs, we approximate the dynamic power in terms of event statistics associated with their effective capacitances:</p><formula xml:id="formula_2">P dyn ? 1 2 V 2 DD e ? {event s } C e D e</formula><p>where C e and D e are the effective capacitance and the statistics of event e, respectively. Microarchitectural power models such as Wattch <ref type="bibr" target="#b10">[11]</ref> and Mc-PAT <ref type="bibr" target="#b44">[45]</ref> analytically compute capacitances for regular structures <ref type="bibr" target="#b53">[54]</ref> and collect manually identified event statistics from microarchitectural software simulators <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b66">67]</ref> before RTL implementation. Performance-counter-based power modeling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b62">63]</ref> uses existing counters in the system, and finds the effective capacitance of each counter event through regression against power measurement of the real machine. These methodologies have been effective for well-known traditional microarchitectures.</p><p>However, for arbitrary novel designs, these approaches are very challenging as 1) manually selecting important signal/event activities is difficult and 2) finding the effective capacitance is also difficult. In the following sections, we tackle both problems for any RTL design automatically and systematically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Toggle-Pattern Matrix from VCD Dumps</head><p>The first step for power-model training is to construct the togglepattern matrix using VCD dumps from RTL simulations of the training set. For accurate power modeling, we carefully choose small workloads that represent real-world applications. If the training set is too small, the trained model cannot accurately predict power consumption of unseen workloads. If the training set is too large, the model training is bottlenecked by RTL simulation and power analysis tools that need to process a large volume of VCD dumps. In this paper, we choose ISA tests and microbenchmarks and replays of random sample snapshots from long-running applications, as an initial attempt, because these workloads highly utilize processors with a variety of operations. Synthesizing more  representative workloads remains as the future work as discussed in Section 6.</p><p>The toggle-pattern matrix is a collection of toggle-density vectors of all signals in the RTL design. Each element of this matrix is constructed as follows:</p><formula xml:id="formula_3">v i j =</formula><p>total number of toggles of signal i over window j width of signal i ? window size where v i j is the element at row i and column j of the toggle pattern matrix.</p><p>Figure <ref type="figure" target="#fig_3">2</ref> shows a simple example of how the toggle-pattern matrix is constructed from VCD dumps with a window size of two cycles. For single-bit signals, the number of toggles is just the number of value transitions. For example, the total number of value transitions of signal a over window 0 is 2, and thus, v a0 = 2/2 = 1.0. The other elements for signal a and b are computed in the same way.</p><p>For multi-bit busses, the number of toggles is the Hamming distance between the value at the previous cycle and the value at the current cycle. For example, the Hamming distance of signal c at cycle 1 is 2. The reason each matrix element is divided by the width of the signal is we want to group busses of different widths together in the same cluster if they show similar toggle patterns. Hence,</p><formula xml:id="formula_4">v c0 = 2/(2 ? 2) = 0.5.</formula><p>The toggle-pattern matrix is very large for a complex hardware design. But most entries in this matrix are zeros for a typical hardware design, since only a small number of signals tend to be active in a given time slot. Therefore, the toggle-pattern matrix is represented as a sparse matrix using the compressed sparse row (CSR) format.</p><p>The similarity of two signals is measured by the Euclidean distance between two vectors. It is intuitive that two signals having a short distance between them have a similar effect on power dissipation. In this case, the window size plays an important role in quantifying similarities. Determining the window size is discussed in Section 3.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Automatic Signal Selection</head><p>Once the toggle-pattern matrix is constructed, we want to partition signals into a handful of groups, each of which collects signals showing similar toggle patterns. Since the similarity is measured as the Euclidean distance between two signal vectors, this problem is identical to a clustering problem.</p><p>There are several challenges in signal clustering. First, exact clustering is known as an NP-hard problem, and thus, a randomized algorithm such as k-means should be used, where clustering results are different with different initial seeds. Moreover, with a nontrivial hardware design, there are a large number of signals, each of which is represented as a very high-dimensional point, which makes clustering more challenging. Specifically, if we have signal traces of N cycles with window size w, the dimension of each signal is N /w, which can be easily a very large number with a long trace.</p><p>Spectral clustering is a class of algorithms for clustering of highdimensional data points through dimensionality reduction <ref type="bibr" target="#b8">[9]</ref>. In this paper, we reduce the dimension of data by projecting data into principal components from singular vector decomposition (SVD). The algorithm to partition the data set into k clusters is as follows:</p><p>(1) Find the space V spanned by the top k right singular vectors from SVD. (2) Project the data points into V through matrix multiplication.</p><p>(3) Cluster the projected points through k-means++ <ref type="bibr" target="#b0">[1]</ref>, which selects better initial seeds than random initial centroids. (4) Repeat multiple times and select the clustering with the best score. It is also proven that the projection brings the data points closer to their cluster centers 1 . In addition, this algorithm can be efficiently implemented with high-performance linear algebra libraries.</p><p>Once signal clustering is done, the signals that are the closest to the center of each cluster are selected, which will be regression variables in power model training. The rationale is these signals have the smallest variance of similarities to other points in the same cluster, and thus, we expect them to introduce the smallest errors in regression than any other signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Finding the Number of Signals</head><p>The clustering algorithm in Section 3.3 finds the optimal clustering when the number of signals is given, but does not determine the number of clusters. In many cases, it is hard to know in advance how many signals should be selected for power modeling with an arbitrary hardware design. We want to select as many signals as possible for accurate power modeling, but not too many signals to avoid model overfitting and to enable power model instrumentation (Section 4).</p><p>Finding the number of signals is the same as a model selection problem. We want to select the best clustering among candidate models for a given data. The idea is we run the clustering algorithm with different numbers of clusters and find the one having the best objective score.</p><p>For model selection, we use the Bayesian Information Criterion (BIC) <ref type="bibr" target="#b57">[58]</ref>, which is commonly used beyond the hypothesis tests. The BIC is a penalized model-fit statistic as it prefers a model having less parameters to a model having more parameters but only fitting 1 For the theorem and its proof, refer to <ref type="bibr" target="#b8">[9]</ref> marginally better. <ref type="foot" target="#foot_1">2</ref> Formally, for model M j , the BIC is formulated as follows:</p><formula xml:id="formula_5">BIC j = p j ln(n) -2ln(L j )</formula><p>where n is the number of points in the data, and p j and L j are the size and the likelihood of model M j , respectively. The absolute value of the BIC is barely interpretable. However, the difference of values, ?BIC = BIC new -BIC old , is of interest. For example, we determine the new model is very strong compared to the old model if ?BIC &lt; -10<ref type="foot" target="#foot_2">3</ref> .</p><p>For clustering, we use the formula derived by Pelleg and Moore <ref type="bibr" target="#b56">[57]</ref>, assuming underlying distributions are spherical Gaussians. The maximum likelihood estimate for the variance is:</p><formula xml:id="formula_6">? 2 = 1 n -k n i=1 ?x i -?(x i )? 2</formula><p>where k is the number of clusters and ?(x i ) is the cluster center of x i . Intuitively, this quantity explains how far points in each group are scattered away from their cluster center.</p><p>Then, the log likelihood of model M j is the summation of log likelihoods of all clusters:</p><formula xml:id="formula_7">ln(L j ) = - n 2 ln(2? ) - nd 2 ln( ? 2 ) - n -k 2 + k i=1 n i ln( n i n )</formula><p>where d is the dimension of points and n i is the number of points in cluster i. The number of parameters, p j , is (k -1) +dk + 1 for (k -1) cluster probabilities, k centroids of dimension d, and one variance estimate. Intuitively, this quantity expresses how well signals in each group are clustered around their cluster center. This metric is also used by SimPoint <ref type="bibr" target="#b60">[61]</ref> to find the optimal clustering for program phases.</p><p>To select the number of signals, we keep track of ?BIC by increasing the number of clusters, k. To avoid getting stuck at local minima, we employ simulated annealing as follows:</p><p>(1) Run the clustering algorithm with the initial k, and compute the BIC, which is the initial best clustering. (2) Increase k, and run the clustering algorithm and compute the BIC. (3) If ?BIC = BIC cur -BIC best &lt; -10, update the best clustering, and go to 2. (4) Otherwise, decrease the temperature, T, and go to 2 with the probability of exp( ?BI C T ). This algorithm starts with a high temperature, which gradually decreases over iterations. Therefore, this algorithm is not likely to terminate in early iterations even if no better clustering is found, helping escape from local minima. However, with low temperatures, the algorithm has a very high probability to terminate in later iterations as the current best clustering is very likely to be the global optimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Obtaining Cycle-Accurate Power Traces</head><p>For accurate power modeling for RTL designs, cycle-accurate power traces are necessary. We obtain these power traces using commercial CAD tools as shown in Figure <ref type="figure" target="#fig_0">1</ref>. We first obtain the gate-level design from the target RTL using logic synthesis <ref type="foot" target="#foot_3">4</ref> with the target technology library <ref type="foot" target="#foot_4">5</ref> . Clock gating is also automatically inferred during synthesis. Since commercial SRAM compilers were not available, we characterize SRAMs used in the target design with CACTI 6.5 <ref type="bibr" target="#b51">[52]</ref>, and generate library files using commercial library compilers <ref type="foot" target="#foot_5">6</ref> . To obtain accurate estimates for the timing, area, and the floorplan of the final silicon, we also place and route the post-synthesis design <ref type="foot" target="#foot_6">7</ref> .</p><p>After place-and-route, the commercial power analysis tool<ref type="foot" target="#foot_7">8</ref> can compute cycle-accurate power traces from RTL VCD dumps. In this detailed power analysis, RTL signal activities are propagated into gate-level signals and the cycle-by-cycle power for modules in the design is computed. Since the full cycle-by-cycle power traces are generated instead of just the average power, this process tends to be the bottleneck for power modeling.</p><p>Throughout this paper, we assume the cycle-accurate power traces obtained in this section are the true power for training and evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Power-Model Regression</head><p>Once n signals are automatically selected (Section 3.3), we train the power model in terms of these signals against the cycle-accurate power traces from commercial CAD tools (Section 3.5). As discussed in Section 3.1, power-model regression finds the effective capacitances for the signal activities. We are also interested in module-level power modeling for thermal analysis <ref type="bibr" target="#b61">[62]</ref>.</p><p>Formally, for each module k, we want to find a function f k that accurately approximates the actual power dissipation in terms of signal activities:</p><formula xml:id="formula_8">p k j ? f k (x 1j , x 2j , ? ? ? , x nj )</formula><p>for all time window j, where p k j and x i j are the power consumption of module k and the toggle density of signal i in window j, respectively. The total power consumption of the target design in window j is just the sum of power consumptions in window j over all modules.</p><p>Power models need to be as simple as possible to minimize the computation overhead for runtime power and thermal analysis. On the other hand, power models need to be more complex than linear regression since, in general, power dissipation is not a linear function of the activities of the selected signals. To cope with nonlinearity, we use linear regression with interactions and high-order terms. One justification is that, theoretically, a non-linear function can be approximated with its Taylor expansion with polynomial terms. There is also a large amount of empirical evidence that linear regression with polynomial terms of manually selected events and signals is reasonably accurate for microprocessors <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b63">64]</ref>. Lastly, these interactions and high-order terms can be viewed as an approximation to hidden activities that are not solely captured by the selected signals.</p><p>Therefore, we also assume power dissipation is a function of the following form:</p><formula xml:id="formula_9">p k j = ?+? 1 x 1j + ? 2 x 2j + ? ? ? ? n x nj + ? 11 x 2 1j + ? 22 x 2 2j + ? ? ? + ? 12 x 1j x 2j + ? ? ? + ? 123 x 1j x 2j x 3j + ? ? ?</formula><p>where ? and ?'s are parameters to be trained. As there are an infinite number of terms in the Taylor expansion, we limit the order of terms to two. However, the number of terms still grows exponentially with the number of signals. For instance, if 50 signals are selected, there will be 2550 terms in the model. Linear regression with this many terms tends to be unstable and suffers from high variance, losing prediction accuracy.</p><p>Moreover, models with a large number of variables are less interpretable, as well as increasing the compute overhead. From the perspective of activity-based power modeling, each regression variable represents a certain activity in the design and its coefficient is its effective capacitance. However, all these activities are not equally important for power modeling across different modules. Indeed, we want to systematically select most of the single-order terms but only a small number of higher-order terms to correlate between signal activities and power consumption without prior knowledge of these signals.</p><p>The previous two issues can be viewed as a problem of regularization and variable selection in linear regression. Prediction accuracy can be improved by shrinking coefficients through regularization with penalized regression, which reduces the variance of coefficients while trading off the bias. Variable selection can further improve the prediction accuracy, preventing overfitting, as well as the interpretability.</p><p>In this paper, we employ the elastic net <ref type="bibr" target="#b71">[72]</ref> for both regularization and variable selection. The elastic net is penalized regression with a convex combination of the L1 and L2 penalties of coefficients. As a result, the elastic net behaves mostly like LASSO <ref type="bibr" target="#b64">[65]</ref>, while preserving the prediction power of ridge regression.</p><p>We assume the training data is standardized having the zero mean and the unit standard deviation before regression. Then, to find the coefficients ? with given power trace p and toggle densities X, the elastic net solves the following optimization problem:</p><formula xml:id="formula_10">min ? 1 2n ||p -X? || 2 + ? 1 -? 2 ||? || 2 + ?||? || 1<label>(1)</label></formula><p>where ? and ? are determined by K-fold cross-validation, a technique that splits the training data into K groups for both training and validation. We also restrict that all coefficients are nonnegative <ref type="foot" target="#foot_8">9</ref> . This optimization can be efficiently solved by coordinate descent <ref type="bibr" target="#b17">[18]</ref>. Notice that ridge regression and LASSO are special instances of the elastic net when ? = 1 and ? = 0, respectively. When we apply the elastic net for power modeling, many unimportant variables are desirably eliminated as shown in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Finding the Window Size</head><p>As alluded in Section 3.2, the window size plays an important role in quantifying similarities in the toggle-pattern matrix. If the window size is too small, two very similar signals (e.g. the input and the output of shift registers) may have a large distance between them. On the other hand, if the window size is too large, two distinctive signals may appear similar. Therefore, the window size affects the number of selected signals and in turn prediction accuracies.</p><p>The window size is dependent on the target design and the training data set. We also observed that the clustering algorithm tends to select more signals with a larger window size. This is because a shorter window size dramatically increases distances between points, and thus, having more clusters does not help improving the quality of clustering.</p><p>Indeed, manual selection of the window size is another challenge and requires many trials and errors. Instead, we propose automatic signal selection as follows:</p><p>(1) For a given window size, (a) Select signals with clustering (Section 3.3 and 3.4). (b) Train a power model for each submodule (Section 3.6) and compute its BIC. (2) Select the window size that minimizes the total score of power models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note that</head><p>Step 1 can be parallelized for different window sizes to minimize runtime overhead as trainings are independent of one another. For the score of each power model in Step 2, we use the BIC for linear regression:</p><formula xml:id="formula_11">BIC = N i error 2 i ? 2 + ln(N ) ? d f</formula><p>where error i is the error of each data point i, d f is the degree of the freedom of the model, is a function of ? in Equation (1), and N and ? 2 are the size and the variance of data, respectively. Intuitively, the BIC finds the model with small errors as well as a small number of variables.</p><p>Computing exact d f for the elastic net is computationally expensive. However, when ? in Equation ( <ref type="formula" target="#formula_10">1</ref>) is small, which is the case when only a small number of variables are selected, d f is very close to the degree of the freedom of LASSO, which is equal to the number of nonzero coefficients <ref type="bibr" target="#b72">[73]</ref>. Therefore, we approximate d f with the number of nonzero coefficients in the model when we compute the BIC.</p><p>Since we have multiple power models for each submodule in the design, we may want to select the new window over the old window if the geometric mean of all Bayes factors <ref type="bibr" target="#b30">[31]</ref> of each model is greater than 1, which is expressed as follows:</p><formula xml:id="formula_12">K K k =1 exp -?BI C k 2 = exp -K k =1 ?BI C k 2K &gt; 1 ? K k =1 ?BIC k = K k =1 BIC k new -K k =1 BIC k old &lt; 0</formula><p>where K is the number of models and BIC k is the BIC of model k. Therefore, we select the window size that minimizes the sum of all BICs of each model. Section 5.3 presents evaluations on how window sizes affect the number of selected signals and the accuracy of power models.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">POWER MODEL INSTRUMENTATION</head><p>Once the power model is trained as in Section 3, the target RTL needs to be instrumented for runtime power analysis and evaluation. The target RTL design is automatically instrumented with the power model using custom transforms inserted in the FIRRTL compiler as shown in Figure <ref type="figure" target="#fig_5">3</ref>. Section 4.1 overviews the FIRRTL compiler that enables hardware designers to write custom compiler passes for any RTL design. Section 4.2 shows how activity counters collecting the toggle activities of the selected signals are automatically inserted into the target RTL by a custom compiler pass. Section 4.3 shows how runtime power traces are obtained from FPGA-accelerated RTL simulation for various case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The FIRRTL Compiler</head><p>Software compilers like LLVM have their own intermediate representations (IRs) to let software engineers write custom transforms and instrumentation. Likewise, the FIRRTL compiler <ref type="bibr" target="#b26">[27]</ref> provides an IR for hardware designs. By writing custom transforms that operate on any hardware design represented by this IR, hardware designers can avoid design-specific engineering effort. We wrote custom compiler passes applicable to any hardware design to instrument activity counters and transform the target design for runtime power analysis on the FPGA.</p><p>For now, the FIRRTL compiler supports Chisel designs only. However, note that this framework is language-agnostic. Once there is a front-end to translate a HDL to FIRRTL, this framework can be reused for any hardware design in the HDL, significantly improving productivity <ref type="foot" target="#foot_9">10</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Activity Counter Insertion</head><p>As shown in Figure <ref type="figure" target="#fig_5">3</ref>, activity counters are automatically inserted by the compiler pass using the information from the power model. Figure <ref type="figure">4</ref> shows components instrumented by the compiler pass to collect the toggle activities of the selected signals.</p><p>For each selected signal, the HD unit is inserted to compute the Hamming distance between the value at the current cycle and the value at the previous cycle. For a single-bit signal, it is just an XOR gate. For a multi-bit bus, the HD unit computes XORs of individual  bits and counts the number of 1's. If the selected signal is a wire, a shadow register that keeps the value at the previous cycle is also inserted, and then the input and the output of this shadow register are fed into the HD unit. On the other hand, if the selected signal is a register, we do not need a shadow register. Instead, the input and the output of the selected register are connected to the HD unit.</p><p>We also need counters that increment by the Hamming distance on each cycle. For this purpose, a counter register file is instantiated in the top-level module, with the number of write ports equal to the number of selected signals. The HD units in submodules are connected to the counter register file across different module hierarchies, and thus, the compiler pass creates module ports along the connections to the write ports.</p><p>The counter register file has one read port and can be visible as architectural state for software running in the target design. Alternatively, this read port can be directly connected to the toplevel I/O for FPGA-accelerated RTL simulation as explained in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Runtime Power Analysis with FPGAs</head><p>FPGA-accelerated RTL simulation is the only viable way for performance, power, and energy evaluation of complex RTL designs running real-world software before tape-out. The Strober framework <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref> automatically generates FPGA-accelerated RTL simulators from any RTL designs with custom compiler passes. We use this framework to obtain runtime power traces from FPGAs. Once the activity counters are inserted, the instrumented target design is consumed by the following custom transforms for FPGAaccelerated RTL simulation (Figure <ref type="figure" target="#fig_5">3</ref>).</p><p>After the FPGA-accelerated RTL simulator is compiled into the bitstream, it is run on the FPGA along with the software simulation driver. Figure <ref type="figure" target="#fig_6">5</ref> shows how the transformed target design is mapped to the host platform. The processor RTL is mapped into the FPGA while the data for the last-level cache (LLC) and the DRAM are mapped into the FPGA DRAM. For the timing of the memory system, we have an abstract timing model that only keeps the tags of the LLC on the FPGA. The software driver with abstract I/O devices runs on the host CPU. The processor RTL infrequently communicates with the I/O devices through the I/O transport unit on the FPGA only when necessary (e.g. console I/O), minimizing simulation slowdown.</p><p>To obtain power traces, the simulation driver periodically reads the activity counter values through the activity counter unit on the FPGA, which is connected to the read port of the counter register file. When the counter values are read, the simulation is stalled so that it does not change the behavior of the target system. Counter sampling is infrequent, and thus, the simulation driver infrequently polls the counter read unit that only pauses the simulation when the counters are sampled.</p><p>After activity statistics are collected from the FPGA, the software driver, which has the power model information, performs the rest of computations for model-level power and dumps runtime power values to a file. As such, we obtain the power traces over the whole execution of real-world applications at the end of the simulation.</p><p>We also estimate the power dissipation of the LLC and the DRAM with event counters in the memory timing model. For the LLC, we characterize its read and write energy per access as well as its static power with CACTI <ref type="bibr" target="#b51">[52]</ref>, and collect the number of read/write accesses to the LLC. For the DRAM, we assume Micron's LPDDR2 SDRAM S4 <ref type="bibr" target="#b50">[51]</ref> and use the spreadsheet power calculator provided by Micron <ref type="bibr" target="#b49">[50]</ref> with statistics on read/write operations and row activations of the DRAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION 5.1 Experimental Setup</head><p>Most of the power training algorithm (Section 3) is implemented in Python with the SciPy's sparse matrix libraries, while the toggle matrix construction algorithm (Section 3.2) is implemented in C++. We import k-means++ (Section 3.3) and the elastic net solver (Section 3.6) from scikit-learn <ref type="bibr" target="#b55">[56]</ref>.  The Simmani framework is demonstrated with the heterogeneous processor composed of the Rocket in-order core 11 [2] and the Hwacha vector accelerator 12 <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref> (Rocket+Hwacha). Table <ref type="table" target="#tab_2">1</ref> shows its configuration for the evaluation. To best of our knowledge, no activity-based power model is developed for this design. We have abstract timing models for the L2 cache and the DRAM since we do not have corresponding RTL implementations for now. Even though we present only Rocket+Hwacha in this paper, we have also evaluated the BOOM out-of-order processor <ref type="bibr" target="#b11">[12]</ref> as well as Rocket running the SPEC 2006/2017 integer benchmark suites <ref type="bibr" target="#b32">[33]</ref>.</p><p>The cycle time, area, and the floorplan of each processor are obtained from Synopsys Design Compiler (logic synthesis) and Synopsys IC Compiler (place-and-route) with the TSMC 45nm technology. Figure <ref type="figure" target="#fig_7">6</ref> shows the floorplan result of Rocket+Hwacha.</p><p>For power model training, we ran CAD tools for a day and the training algorithm for a half day on a high-performance server 13 .</p><p>For FPGA-based simulation, we use AWS F1 instances. The FPGAbased simulator was synthesized at the frequency of 75 MHz, which took 6 hours, but the simulation rate for the case study was 39.3 MHz on average due to the overhead of counter sampling. For accurate validation, we carefully matched the timing of the memory system and the I/O devices between FPGA-based RTL simulation and software RTL simulation.</p><p>The training data set consists of 1) ISA tests, 2) microbenchmarks with their small input sets, and 3) 200 random sample snapshots from each benchmark of SqueezeNet with two images (dog and mousetrap).</p><p>For power model validation in Section 5.4, we used microbenchmarks with their large input sets. For case study in Section 5.5, we used a different set of 11 images for each benchmark of SqueezeNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Signal and Variable Selection</head><p>Table <ref type="table" target="#tab_4">2</ref> shows the results of automatic signal selection by the algorithm in Section 3.3 with the average power and the standard deviation of each module for the training set. We counted all signals and data busses shown in the VCD dump except intermediate 11 Commit: 50bb13d7887e5f9ca192431234b057ae9d8edb6c 12 Commit: 519ed1642674909d89769eae1bd4fc35fa383e49 13 Intel Xeon 32-core CPU @ 3.2 GHz with 25 MB L3 cache and 256 GB main memory.  At first glance, it was surprising that only one signal was selected for the vector register file even though it dissipates a significant amount of power. If we had selected signals manually, the enable signals for this module would have been our primary choice. However, it turns out that those signals were clustered together with related signals in other modules but are not selected as representative signals. For example, the vector regfile write-enable and mask signals were clustered with a control signal of the floating point multiply-add unit, which was a representative signal of that cluster. Similarly, signals in the vector memory unit were clustered with signals in the load-store units of the vector execution unit, while signals in the FPU were clustered with signals in the Rocket core.</p><p>Table <ref type="table" target="#tab_4">2</ref> also presents the variable selection results from powermodel regression (Section 3.6). Note that some of terms appear across multiple modules, and thus, the total number of terms is smaller than the summation of the number of terms from each submodules. Our power modeling keeps 671 terms in total out of 6,554 candidate terms for training.</p><p>We also notice that cross-order terms can capture events across different modules. For example, our power modeling finds the interaction between a predicate signal in the vector execute unit and a hit signal in the data cache, which has a positive effect on the power dissipation of the vector register file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Automatic Window Size Selection</head><p>Figure <ref type="figure">7</ref> shows how the window size affects the number of selected signals and the geometric mean of the R 2 values, a statistic for how well the model fits the training data, across module-level power models. First of all, more signals are selected as the window size increases. This is because a bigger window size makes data points closer, and therefore, having more clusters improves the quality of clustering. We can also see that this effect diminishes as the window size gets bigger.</p><p>Another trend is selecting more signals does not necessarily result in more accurate models. A model fits the training set well if its R 2 value is closer to 1.0 <ref type="foot" target="#foot_10">14</ref> . As seen in Figure <ref type="figure">7</ref>, the geometric mean of R 2 is the max at the window size of 340 cycles, and the sum of BICs, the score for window size selection in Section 3.7, is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Power Model Validation</head><p>In this validation, we used well-known floating-point microbenchmarks vectorized for Rocket+Hwacha with various precisions. We estimated runtime power by sampling activity counters from the FPGA every 128 cycles, and compared it against power traces from Synopsys PrimeTime PX.</p><p>We computed the normalized mean-squared errors (NMSREs) and the average errors (AVGEs) across benchmarks. For N samples, NRMSEs and AVGEs are calculated as follows:</p><formula xml:id="formula_13">N RMSE = N i (p i -p pr ed i ) 2 /N p av? , AV GE = |p av? -p pr ed av? | p av?</formula><p>The NRMSE accounts for point-by-point errors while the AVGE cares about the average values only. The NRMSE also tends to be bigger than the AVGE.</p><p>Figure <ref type="figure">8</ref> shows both errors are within 9 % and our power modeling is reasonably accurate for these microbenchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Case Study</head><p>In this section, we demonstrate how Simmani can be used for custom accelerators targeting emerging applications in the HW/SW co-design flow. As an example of embedded vision applications, we use SqueezeNet <ref type="bibr" target="#b21">[22]</ref>, a neural network for image classification that achieves AlexNet-level accuracy with very small models. We evaluated three versions of SqueezeNet. In addition to the base variant (SqueezeNet), we evaluated a variant with 8-bit weight quantization (SqueezeNet-8bits), and a variant with both quantization and compressed weight storage (SqueezeNet-Comp).</p><p>We ported and vectorized SqueezeNet so that these three benchmarks can run on Rocket+Hwacha. For FPGA-based simulation, we    made initramfs Linux images that contain SqueezeNet binaries as well as 11 images for inference. To obtain power traces, we sampled counters from the FPGA every 100K cycles. For comparison, we also evaluated unoptimized scalar SqueezeNet benchmarks, which do not utilize the vector unit at all.</p><p>Table <ref type="table" target="#tab_6">3</ref> shows the performance of Rocket+Hwacha for these three benchmarks without and with vectorization. First of all, vectorization significantly improves its performance. Without vectorization, quantization decreases the performance, while with vectorization, it marginally improves the performance. However, in both cases, there is a significant performance improvement with compression on top of vectorization.</p><p>Figure <ref type="figure">9</ref> shows the average power breakdowns for SqueezeNet. For the scalar benchmarks, we assume the vector accelerator is perfectly power-gated. Without vectorization, both quantization and compression reduce power consumption as they require less memory accesses. Surprisingly, Simmani reveals that Rocket+Hwacha consumes almost the same power across the vectorized benchmarks. This is because the vector accelerator is highly utilized during inferences thanks to small model sizes. Figure <ref type="figure" target="#fig_0">10</ref> shows the power prediction errors with the 95 % confidence intervals. To validate the power estimates in Figure <ref type="figure">9</ref>, we took random 50 sample snapshots of 1024 cycles from each benchmark. When each of these random snapshots was taken, its runtime power was estimated by sampling activity counters for this period of 1024 cycles. After the FPGA-based simulation was done, the power estimate of each sample point was obtained from sample replays, which was in turn compared against its runtime power estimate from the FPGA to compute the NRSE for 50 sample points. For the AVGE, we compared the average over the whole power trace against the average power estimate from sample replays, which also provided its confidence interval. From this validation, we can see that our power modeling also achieves good prediction accuracy for SqeeuzeNet.</p><p>Figure <ref type="figure" target="#fig_10">11</ref> shows the energy efficiency for SqueezNet. First of all, we can significantly improve energy efficiency with vectorization, which achieves significant speedups despite the increase in power consumption. Also, with vectorization, both quantization and compression gain energy efficiency as they require the same-level of power consumption.</p><p>Figure <ref type="figure" target="#fig_11">12</ref> shows the entire power trace without L2 and DRAM power for the vectorized SqueezeNet-Comp benchmark, while booting Linux, loading the model weights, and running inferences for 11 images over 20 billion cycle, which took 14 minutes on the FPGA but can take weeks or months with the CAD tools. We can also detect power phase changes over the whole execution of the benchmark, which will improve the effectiveness of runtime power/energy management techniques. We can also observe that power is more variable in the later layers than in the earlier layers for each inference because the later layers are more memory-intensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we presented Simmani, a novel runtime power modeling methodology for any RTL designs by automatically key signals for power dissipation. We also automatically instrumented the target design with activity counters to collect statistics from FPGAs, without requiring manual effort. We demonstrated Simmani's power modeling capabilities for non-traditional RTL designs with a case study of HW/SW co-design for machine-learning applications. Simmani is open-source<ref type="foot" target="#foot_11">15</ref> so that our methodology can be easily integrated into various accelerator research projects.</p><p>This section further discusses Simmani's potential use cases and enhancements.</p><p>Thermal Analysis. As we can obtain module-by-module power traces from FPGA-based simulation as well as floorplans from CAD tools (Figure <ref type="figure" target="#fig_7">6</ref>), we can conduct pre-silicon thermal analysis for novel hardware designs running real-world workloads. HotSpot <ref type="bibr" target="#b61">[62]</ref> is one example framework for thermal analysis. We plan to integrate HotSpot into Simmani for runtime thermal analysis with FPGA-based simulation.</p><p>Dynamic Power/Thermal Optimization. Runtime techniques for power and thermal management have been widely studied in the context of CPUs (e.g. <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref>). As custom accelerators are prevalent in computer systems, it is also important to do research on these techniques in the context of a variety of accelerators. As Simmani is generic for any hardware designs, we believe Simmani will be a useful tool for activity-based runtime power/thermal techniques for custom accelerators.</p><p>Power Model Composition. In this paper, Simmani is demonstrated for a relatively smaller hardware design with a single tile compared to contemporary heterogeneous multi-core SoCs. In heterogeneous multi-core systems, cores(tiles) and uncore are fairly independent blocks, and thus, we will improve Simmani's scalability with power model composition: we will train individual power models for each core(tile) and uncore, and then compose the total power with statistical methods. Lee et al. <ref type="bibr" target="#b39">[40]</ref> also present such a methodology.</p><p>Automatic Training Set Generation. For Simmani, it is crucial to have a good training set for both signal selection and power model regression. In many cases, it is even more challenging to find a good training set that is fully representative for their real-world applications.</p><p>A good training set should have good coverage of valid signal activities. In fact, this challenge is also shared with input generation for simulation-based verification. Our future work will tackle this problem in a general setting for both hardware verification and power modeling. We believe workload generation with coveragebased fuzzing such as <ref type="bibr" target="#b35">[36]</ref> is one promising approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The information, data, or work presented herein was funded in part by the Advanced Research Projects Agency-Energy (ARPA-E), U.S. Department of Energy, under Award Number DE-AR0000849. Research was partially funded by ADEPT Lab industrial sponsors and affiliates Intel, Apple, Futurewei, Google, and Seagate, and by RISE Lab sponsor Amazon Web Services. Donggyu Kim was supported in part by the Kwanjeong Educational Foundation. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Power modeling flow</figDesc><graphic url="image-1.png" coords="3,63.79,134.32,122.54,114.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>describes the overall power modeling flow in the Simmani framework. Section 3.1 introduces the power modeling background. Section 3.2 explains how the toggle patten matrix is constructed from VCD dumps. Section 3.3 describes how important signals for power dissipation are found through clustering. Section 3.4 explains how the number of signals is determined through model selection with simulated annealing. Section 3.5 explains how to obtain detailed cycle-accurate power traces from commercial CAD tools. Section 3.6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Constructing a toggle-pattern matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Tool flow for runtime power analysis with FPGAs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Mapping the target system to the host platform.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Floorplan of Rocket+Hwacha</figDesc><graphic url="image-18.png" coords="9,76.70,83.69,192.19,162.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: The number of selected signals and the geometric mean of R 2 across module-level power models for different window sizes</figDesc><graphic url="image-19.png" coords="10,53.80,83.69,240.24,117.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Figure 9: Power breakdown for SqueezeNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Energy efficiency for SqueezeNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Power trace of Rocket+Hwacha for SqueezeNet-Comp</figDesc><graphic url="image-20.png" coords="11,53.80,84.04,504.28,92.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Parameters for Rocket+Hwacha</figDesc><table><row><cell>Parameter</cell><cell>Rocket+Hwacha</cell></row><row><cell>Processor</cell><cell>Rocket 5-stage in-order processor</cell></row><row><cell cols="2">Accelerator 2048-bit wide vector unit and 64-bit wide scalar unit</cell></row><row><cell>Registers</cell><cell>32(int)/32(fp)/64(scalar)/256(vector)</cell></row><row><cell>L1 I and D $</cell><cell>Capacity: 32 KiB, Associativity: 8 ways</cell></row><row><cell>ITLB &amp; DTLB</cell><cell>Reach: 128 KiB, Associativity: fully-associative</cell></row><row><cell>L2 TLB</cell><cell>Reach: 4 MiB, Associativity: direct-mapped</cell></row><row><cell>Cycle time</cell><cell>1 ns</cell></row><row><cell>Area</cell><cell>1.79 mm x 1.52 mm</cell></row><row><cell></cell><cell>Capacity: 1 MiB, Latency: 23 cycles,</cell></row><row><cell>L2 $</cell><cell>Read energy: 116.1 pJ, Write energy: 95.9 pJ,</cell></row><row><cell></cell><cell>Leakage power: 21.0 mW</cell></row><row><cell>DRAM</cell><cell>Latency: 80 cycles, Number of banks: 8, Number of rows in each bank: 16K, Open-page policy</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Results of automatic signal and variable selection signals generated by the FIRRTL compiler (starting with _GEN_). Our signal clustering algorithm selected 113 signals out of 115,285 signals.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Performance of Rocket+Hwacha for SqueezeNet</figDesc><table><row><cell></cell><cell>300</cell><cell></cell></row><row><cell></cell><cell>250</cell><cell></cell></row><row><cell></cell><cell></cell><cell>DRAM</cell></row><row><cell></cell><cell>200</cell><cell>L2 Cache</cell></row><row><cell>Power(mW)</cell><cell>150</cell><cell>Uncore L1 DCache L1 ICache</cell></row><row><cell></cell><cell>100</cell><cell>VectorUnit</cell></row><row><cell></cell><cell></cell><cell>VectorRegFile</cell></row><row><cell></cell><cell>50</cell><cell>RocketFPU</cell></row><row><cell></cell><cell></cell><cell>RocketCore+Fetch</cell></row><row><cell></cell><cell>0</cell><cell></cell></row><row><cell></cell><cell cols="2">SqueezeNet SqueezeNet-8bits SqueezeNet-Comp SqueezeNet SqueezeNet-8bits SqueezeNet-Comp</cell></row><row><cell></cell><cell>Scalar</cell><cell>Vector</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>MICRO-52, October 12-16, 2019, Columbus, OH, USA Donggyu Kim, Jerry Zhao, Jonathan Bachrach, and Krste Asanovi?</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Compared to the Akaike information criterion (AIC), the BIC assigns more penalties on the number of parameters, having higher chances to reject models with more signals.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The Bayes factor is equal to exp (-?BI C/2)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>We used Synopsys Design Compiler version O-2018.06-SP4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>We used the TSMC 45nm technology</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>We used Synopsys Library Compiler version J-2014.09-SP4 and Synopsys Milkyway version J-2014.09-SP4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>We used Synopsys IC Compiler version O-2018.06-SP4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>We use Synopsys PrimeTimePX version O-2018.06-SP4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>We do not have this constraint on uncore in our example target design, whose power is given by subtracting the sum of power of all other modules from the total power.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>The Verilog frontend is in progress</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_10"><p>However, we do not use R 2 for model selection because a high R 2 may result from overfitting</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_11"><p>https://simmani.github.io</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">K-Means++: the Advantages of Careful Seeding</title>
		<author>
			<persName><forename type="first">David</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
		<idno type="DOI">10.1145/1283383.1283494</idno>
		<idno type="arXiv">arXiv:1212.1121</idno>
		<ptr target="https://doi.org/10.1145/1283383.1283494" />
	</analytic>
	<monogr>
		<title level="m">ACM-SIAM Symposium on Discrete Algorithms</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Rocket Chip Generator</title>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rimas</forename><surname>Avizienis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Celio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Dabbelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Izraelevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsup</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miquel</forename><surname>Moreto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Schmidt</surname></persName>
		</author>
		<idno>UCB/EECS-2016-17</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>Stephen Twigg, Huy Vo, and Andrew Waterman</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analyzing CUDA workloads using a detailed GPU simulator</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bakhoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W L</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISPASS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The benefits of event: driven energy accounting in powersensitive systems</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Bellosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 9th ACM SIGOPS European Workshop</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Systematic Methodology to Generate Decomposable and Responsive Power Models for CMPs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bertran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gonzelez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Martorell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ayguade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1289" to="1302" />
			<date type="published" when="2013-07">2013. Jul 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fullsystem chip multiprocessor power evaluations using FPGA-based emulation</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilberto</forename><surname>Contreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISLPED</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somayeh</forename><surname>Sardashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rathijit</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Korey</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Shoaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nilay</forename><surname>Vaish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradford</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkaprava</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">R</forename><surname>Hower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The gem5 simulator</title>
		<imprint>
			<date type="published" when="2011-08">2011. Aug 2011</date>
			<biblScope unit="volume">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Complete System Power Estimation: A Trickle-Down Approach Based on Performance Events</title>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Lloyd</forename><surname>Bircher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizy</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISPASS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Foundations of data science</title>
		<author>
			<persName><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravindran</forename><surname>Kannan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note>Vorabversion eines Lehrbuchs</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Regressionbased RTL power modeling</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Bogliolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Benini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Wattch: a framework for architectural-level power analysis and optimizations</title>
		<author>
			<persName><forename type="first">David</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BOOMv2: an open-source out-of-order RISC-V core</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Celio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pi-Feng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borivoje</forename><surname>Nikolic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Workshop on Computer Architecture Research with RISC-V (CARRV)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Power emulation: a new paradigm for power estimation</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Coburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srivaths</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pack &amp; Cap: Adaptive DVFS and thread packing under power caps</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cochran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Hankendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayse</forename><surname>Coskun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherief</forename><surname>Reda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="175" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CoScale: Coordinating CPU and memory system DVFS in server systems</title>
		<author>
			<persName><forename type="first">Qingyuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Meisner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Bianchini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MICRO</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Microarchitectural design space exploration using an architecture-centric approach</title>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Dubach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>O'boyle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>In MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A counter architecture for online DVFS profitability estimation</title>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1576" to="1583" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Regularization Paths for Generalized Linear Models via Coordinate Descent</title>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Accelerating system-on-chip power analysis using hybrid power estimation</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ghodrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Machine learning for performance and power modeling of heterogeneous systems</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCAD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Power modeling for high-level power estimation</title>
		<author>
			<persName><forename type="first">Subodh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farid</forename><forename type="middle">N</forename><surname>Najm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="18" to="29" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size</title>
		<author>
			<persName><forename type="first">Forrest</forename><forename type="middle">N</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Moskewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Ashraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1602.07360" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficiently exploring architectural design spaces via predictive modeling</title>
		<author>
			<persName><forename type="first">Engin</forename><surname>?pek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><forename type="middle">A</forename><surname>Mckee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bronis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>De Supinski</surname></persName>
		</author>
		<author>
			<persName><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">An analysis of efficient multi-core global power management policies: Maximizing performance for a given power budget</title>
		<author>
			<persName><forename type="first">Canturk</forename><surname>Isci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alper</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">Yong</forename><surname>Cher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradip</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
		<idno>MICRO. 347-358</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Runtime power monitoring in high-end processors: Methodology and empirical data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Isci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>In MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Phase characterization for power: Evaluating control-flow-based and event-counter-based techniques</title>
		<author>
			<persName><forename type="first">Canturk</forename><surname>Isci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="122" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hardware Reusability is FIRRTL Ground: Hardware Construction Languages, Compiler Frameworks, and Transformations</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Izraelevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chick</forename><surname>Markley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCAD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Abstraction and microarchitecture scaling in early-stage power modeling</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alper</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradip</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emrah</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Eickemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Construction and Use of Linear Regression Models for Processor Performance Analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kapil</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Thazhuthaveetil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A predictive performance model for superscalar processors</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kapil</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Thazhuthaveetil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>In MICRO</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995">1995. 1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Using Predictive Modeling for Cross-Program Design Space Exploration in Multicore Systems</title>
		<author>
			<persName><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Polychronis</forename><surname>Xekalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Cavazos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Cintra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">FPGA-Accelerated Evaluation and Verification of RTL Designs</title>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-57.html" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>EECS Department, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evaluation of RISC-V RTL with FPGA-Accelerated Simulation</title>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Celio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Workshop on Computer Architecture Research with RISC-V (CARRV)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Strober : Fast and Accurate Sample-Based Energy Simulation for Arbitrary RTL</title>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Izraelevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Celio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hokeun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsup</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">RFUZZ: coverage-directed fuzz testing of RTL on FPGAs</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Laeufer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koushik</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">WattWatcher: Fine-Grained Power Estimation for Emerging Workloads</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lebeane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jee</forename><surname>Ho Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reena</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizy</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Accurate and Efficient Regression Modeling for Microarchitectural Performance and Power Prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Illustrative Design Space Studies with Microarchitectural Regression Models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">CPR: Composable performance regression for scalable multiprocessor models</title>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamison</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Brooks</surname></persName>
		</author>
		<editor>MI-CRO</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">PowerTrain: A learning-based calibration of McPAT power models</title>
		<author>
			<persName><forename type="first">Wooseok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngchun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jee</forename><surname>Ho Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Gerstlauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizy K</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE/ACM International Symposium on Low Power Electronics and Design</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>ISLPED</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The Hwacha Microarchitecture Manual, Version 3.8.1</title>
		<author>
			<persName><forename type="first">Yunsup</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
		<idno>UCB/EECS-2015-263</idno>
		<ptr target="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-263.html" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>EECS Department, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The Hwacha Vector-Fetch Architecture Manual, Version 3.8.1</title>
		<author>
			<persName><forename type="first">Yunsup</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Waterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
		<idno>UCB/EECS-2015-262</idno>
		<ptr target="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-262.html" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>EECS Department, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">GPUWattch: enabling energy optimizations in GPGPUs</title>
		<author>
			<persName><forename type="first">Jingwen</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayler</forename><surname>Hetherington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Eltantawy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Gilani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><forename type="middle">Sung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tor</forename><forename type="middle">M</forename><surname>Aamodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">Janapa</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>In MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Run-time modeling and estimation of operating system power consumption</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizy</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Power and Energy Characterization of an Open Source 25-Core Manycore Processor</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Lavrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Shahrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">J</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaosheng</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Balkind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><surname>Wentzlaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Energy characterization based on clustering</title>
		<author>
			<persName><forename type="first">Huzefa</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">Michael</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Jane</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Javier</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Mesa-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Nayfach-Battilana</surname></persName>
		</author>
		<author>
			<persName><surname>Renau</surname></persName>
		</author>
		<title level="m">Power model validation through thermal measurements. ISCA</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Micron Technology</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m">Micron Mobile LPDDR2 SDRAM S4. Datasheet. Micron Technology</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Micron Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Muralimanohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<idno>HPL-2009-85</idno>
		<title level="m">CACTI 6.0 : A Tool to Model Large Caches</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A survey of power estimation techniques in VLSI circuits</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Najm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
		<imprint>
			<date type="published" when="1994-12">1994. dec 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="446" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Complexityeffective superscalar processors</title>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">MARSSx86: A full system simulator for x86 CPUs</title>
		<author>
			<persName><forename type="first">Avadh</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furat</forename><surname>Afram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunfei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">X-means: Extending K-means with efficient estimation of the number of clusters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pelleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Machine Learning</title>
		<meeting>the Seventeenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Estimating the Dimension of a Model</title>
		<author>
			<persName><forename type="first">Gideon</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978-03">mar 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Design and validation of a performance and power simulator for PowerPC systems</title>
		<author>
			<persName><forename type="first">P J</forename><surname>Shafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bohrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C A</forename><surname>Phelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J L</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="641" to="651" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Aladdin: A pre-RTL, power-performance accelerator simulator enabling large design space exploration of customized architectures</title>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Yakun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><surname>Reagen</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erez</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Sivakumar Velusamy, and David Tarjan. 2003. Temperature-aware microarchitecture</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Skadron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mircea</forename><forename type="middle">R</forename><surname>Stan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">PPEP: Online Performance, Power, and Energy Prediction Framework and DVFS Space Exploration</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junli</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiying</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In MICRO</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">PrEsto: An FPGA-accelerated Power Estimation Methodology for Complex Systems</title>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gene</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><forename type="middle">A</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPL</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Energydriven integrated hardware-software optimizations using SimplePower</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vijaykrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">SimFlex: Statistical Sampling of Computer System Simulation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Roland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James C J</forename><forename type="middle">C</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="31" />
			<date type="published" when="2006-07">2006. Jul 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">GPGPU performance and power estimation using machine learning</title>
		<author>
			<persName><forename type="first">Gene</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lyashevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuwan</forename><surname>Jayasena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Quantifying sources of error in McPAT and potential impacts on architectural studies</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>Sam Likun Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradip</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Accurate phase-level cross-platform power and performance estimation</title>
		<author>
			<persName><forename type="first">Xinnian</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Lizy K John</surname></persName>
		</author>
		<author>
			<persName><surname>Gerstlauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">53rd ACM/EDAC/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">PowerProbe : Run-time Power Modeling Through Automatic RTL Instrumentation</title>
		<author>
			<persName><forename type="first">Davide</forename><surname>Zoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Cremona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fornaciari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milano</forename><surname>Dipartimento</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In DATE</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">On the &quot;degrees of freedom&quot; of the lasso</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2173" to="2192" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
