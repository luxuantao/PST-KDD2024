<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Asynchronous Multi-Nets Detailed Routing in VLSI using Multi-Agent Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuhua</forename><surname>Jut</surname></persName>
							<email>xuhuaju07@bupt.end.cn</email>
						</author>
						<author>
							<persName><forename type="first">Konglin</forename><surname>Zhut</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yibo</forename><surname>Lin2</surname></persName>
							<email>yibolin@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Zhang1</surname></persName>
							<email>zhanglin@bupt.end.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IEEE International Conference on Network Intelligence and Digital Content (IC-NIDC</orgName>
								<address>
									<postCode>2021 7th</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">1School of Artificial Intelligence</orgName>
								<orgName type="institution">BUPT</orgName>
								<address>
									<postCode>100876</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">2Computer Science Department</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Asynchronous Multi-Nets Detailed Routing in VLSI using Multi-Agent Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/IC-NIDC54101.2021.9660569</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Detailed Routing</term>
					<term>Reinforcement Learning</term>
					<term>VLSI</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detailed routing is a crucial challenge in modem integrated circuit (IC) design. Due to the continuous increase in design complexity and complicated design rules, avoiding routing conflicts between nets becomes more and more challenging. Conventional routing strategies like the rip-up and re-route scheme may need to spend huge effo rts on avoiding conflicts between nets with overlapping routing areas. To resolve this challenge, in this paper, we propose a detailed router based on multi-agent reinforcement learning for handling conflicting nets. First, we approximate nets of detailed routing as agents and regard the pin-connection task as path planning to achieve the asynchronization of routing. Second, we assign each agent a local field of view to reduce feature size and difficulty in training. Finally, in order to eliminate routing congestion, we set an information storage unit fo r the information communication of each agent. The evaluation results show that the proposed multi-agent reinforcement learning scheme outperforms the baseline learning methods by 11.6%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Agent</head><p>Routing is one of the most time-consuming stages in the Ve ry Large Scale Integration (VLSI) design flow <ref type="bibr" target="#b0">[1]</ref>. Routing involves a large and arbitrary number of nets being routed. Routing in VLSI is usually divided into global routing and detailed routing with different granularities <ref type="bibr" target="#b1">[2]</ref>. Global routing plans the rough routing regions on a coarse-grained 2D grid graph, while detailed routing finishes the actual interconnections on a fi ne-grained 3D grid graph, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. Besides, detailed routing needs to handle complicated design rules and meanwhile fo llows the routing guidance of global routing. With the increasing design complexity and complicated design rules in advanced technology nodes, detailed routing becomes more and more challenging. High performance and efficient routing techniques are urgently desired to achieve design closure .</p><p>Most existing routers fo llow a sequential routing strategy with a rip-up and re-route scheme to resolve routing conflicts between nets <ref type="bibr" target="#b1">[2]</ref> [3] <ref type="bibr" target="#b3">[4]</ref> [5] <ref type="bibr" target="#b8">[9]</ref> [10] <ref type="bibr" target="#b11">[12]</ref>. The performance of such a routing strategy is sensitive to the order of nets to be routed. Although Qu et al. <ref type="bibr" target="#b11">[12]</ref> try to overcome such an issue by searching for the best orders of each design with reinforcement 978-1-6654-0582-9/21/$31.00 ©2021 IEEE 250 learning techniques, it still requires a large number of rip-up and re-route iterations to resolve routing conflicts. To overcome the drawbacks of the sequential routing strategy, we propose an asynchronous detailed router based on multi-agent deep reinforcement learning and leverage asynchronous communication between agents to avoid routing conflicts. In particular, we treat each net as an agent and use the term "agent" and "net" interchangeably in the rest of the paper. Each agent only observes and exchanges a local view of environment information with others. It makes routing decisions asynchronously in the grid graph leveraging the information from the nearby agents. The major contributions can be summarized as fo llows:</p><p>•</p><p>We fo rmulate the traditional detailed routing into a multi-agent path-planning task based on reinforcement learning to achieve the asynchronization of routing. To the best of our knowledge, this is the first work to deal with asynchronous detailed routing problems with multi-agent deep reinfo rcement learning.</p><p>• We restrict each agent to only observe the surrounding area from the starting vertex to reduce the fe ature size and combine observation information with communication information from other agents to predict the next target vertex to reduce conflicts.</p><p>• Experimental results demonstrate that the proposed method outperforms the baseline methods by 11.6%.</p><p>The rest of the paper is organized as fo llows. In Section 2, we discuss the related work of our paper. Section 3 discusses the problem fo rmulation and describes the proposed algorithms to achieve asynchronous routing. Section 4 presents the performance evaluation. Finally, Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>We review the traditional and reinforcement learning based detailed routing methods in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tr aditional detailed routing methods</head><p>TritonRoute <ref type="bibr" target="#b6">[7]</ref> proposed an Integer Linear Programming-based algorithm to achieve intra-layer parallel routing. RDTA <ref type="bibr" target="#b7">[8]</ref> adopted an efficient mutability-driven track assignment algorithm. Dr.CU <ref type="bibr" target="#b8">[9]</ref> [10] discussed an optimal correct-by-construction path search algorithm and a two-level sparse data structure fo r runtime and memory efficiency. Dr.CU won first place in the ISPD 20 19 <ref type="bibr" target="#b5">[6]</ref> contest about detailed routing. However, the fi nal result quality of its routing is closely related to the routing sequence because of the use of sequential routing strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Detailed routing with reinforcement learning</head><p>During the last several years Deep Reinforcement Learning (DRL) proved to be a fruitful approach to many artificial intelligence tasks of diverse domains. Some researches <ref type="bibr">[11] [12]</ref> have also combined detailed routing with DRL.</p><p>Attention router <ref type="bibr" target="#b10">[11]</ref> explored an attention-model-based REINFORCE algorithm to solve the most critical step in routing: sequencing device pairs to be routed. Qu et al. <ref type="bibr" target="#b11">[12]</ref> proposed an asynchronous RL framework to search fo r optimal ordering strategies automatically. The asynchronous RL framework extends Dr. CU and greatly improves the performance of Dr. CU. However, this framework determines the sequential routing strategies rather than asynchronous routing.</p><p>The asynchronous DRL can be found in the path planning domain. PRIMAL <ref type="bibr" target="#b13">[13]</ref> presented a novel framework that combines reinforcement and imitation learning to plan paths online fo r MAPF. Wang et al. <ref type="bibr" target="#b14">[14]</ref> developed a hierarchical path-planning algorithm that combines global guidance and a local RL-based planner. However, they deal with path-planning in a 2D grid world rather than a graph. Niu et al. <ref type="bibr" target="#b15">[15]</ref> discussed a generalized value iteration network (GVIN) to learn and plan on graphs. MARVIN <ref type="bibr" target="#b16">[16]</ref> proposed a graph neural network-based model that is able to perform multi-agent routing based on learned value iteration in a sparsely connected graph with dynamically changing traffic conditions. Inspired by MARVIN, we make use of part of the value iteration network to plan paths in local view.</p><p>In this section, we discuss the problem fo rmulation and describe our proposed approach to solve the detailed routing problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem fo rmulation and overview</head><p>VLSI Routing is on a stack of metal layers. A wire segment on a layer runs either horizontally or vertically <ref type="bibr" target="#b8">[9]</ref> . Each layer has a preferred direction for routing, which benefits manufacturability, mutability, and design rule checking <ref type="bibr" target="#b8">[9]</ref> . Detailed routing decides the actual path of the wires connecting the electronic components . Our method casts the detailed routing into a multi-agent path-planning DRL framework. The pins connection problem of a net in detailed routing is regarded as the path planning problem of an agent to each target. From the starting vertex of the agent in the 3D grid graph, each agent can independently observe the environment and communicate with other agents to get the state, make decisions to get action and reward. Note that the agents in our system cannot pass through the same vertex to avoid conflict. We define the detailed routing problem using the learning method as fo llows.</p><p>Given a set of net N, we train a generalization model fo r all agents to output a path from starting vertex to end vertex. The fo llowing metrics should be optimized to the minimum simultaneously: (1) the total wire length of all nets, (2) the number of conflicts.</p><p>In our work, we use Asynchronous Advantage Actor Critic (A3C) <ref type="bibr" target="#b17">[17]</ref> to train the model. Echoing the three elements of reinfo rcement learning, we will introduce our algorithm from three aspects : state space construction, action decision making, and reward function. Figure <ref type="figure" target="#fig_3">3</ref> presents the overall structure of our method. Multiple agents begin from the starting vertex at the same time. When reaching a vertex, each agent constructs its own state space through its own observation and the information of other agents extracted from the information storage unit. Each agent <ref type="figure">r----------,   r-------------------</ref>  <ref type="figure">----------------------------------------------------------------</ref> inputs the state fe atures into the action decision making module to detennine the next vertex. Finally, agents take action and commit new infonnation to the infonnation storage unit. Given a grid vertex graph. we consider a locally observable graph where each agent can access the state of its surrounding vertices within a lilnited cube area centered around itself. known as observation vertices. As shown in Fig. <ref type="figure">4</ref>. Agent vertex only observes the states of surrounding vertices. Such an operation is applied to reduce the consumption of computation and enhance the learning efficiency compared with fu ll-feature observation. Tab le 1 shows the details of the state. where n represents the number of vertices in the cube area. To generate global guidance. we fi rst use the Dijkstra algoritlnn to generate the shortest connecting wire fo r each net and store the result in an infonnation storage unit.</p><p>252</p><p>Table <ref type="table">1</ref> State for an aaent .</p><p>State Dimension Descri.Qtion</p><formula xml:id="formula_0">5 1 [n. 1]</formula><p>Edge number of each vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">z [n. 1]</head><p>We ight sum of the edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="53">[n. 1]</head><p>The current position of the agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="54">[n. 1]</head><p>The pins position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">s [n. 1]</head><p>The global guidance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="56">[n. 1]</head><p>The vertices passed by other agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="57">[n. 1]</head><p>The set of pin positions of other agents .</p><p>5 s [n. 1]   The current position of other agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="59">[n. 1]</head><p>The global guidance of other agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="510">[n. 1]</head><p>The vertices are passed.</p><p>Besides global guidance. the infonnation storage unit also stores infonnation that can avoid multi-agent conflict. Each agent cmmnits its passed path and goal to the storage unit after every action fo r other agents to get the state 56 . 57 . We carried out a unique fe ature 510 . the vertices are passed. to cope with the repeated path problem in the process of agent travel. For an agent if it wants to reach the target points which must be passed. it needs to pass through them one by one in order. If we do not deal with the duplicate path. the agent may have problems in the two situations mentioned in Figure <ref type="figure" target="#fig_6">5</ref>. There are three pins in the grid graph. Starting from one pin, an agent needs to go through another 6 vertices to complete the task of connecting all pins whether in Figure <ref type="figure" target="#fig_6">5</ref>(a) or Figure <ref type="figure" target="#fig_6">5</ref>(b ). However, since the agent in Figure <ref type="figure" target="#fig_6">5</ref>(b) passes through repeated vertices, the fi nal wire length is less than that in Figure <ref type="figure" target="#fig_6">5</ref>(a). Therefore, our goal is to make the agent take the repeated path as much as possible on the premise of completing the task. We think 510 can promote this target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Action decision making</head><p>We allow agents from the current vertex to another adjacent vertex with which it has a common edge in the grid graph at each timestep. Reflected in the 3D grid graph, the action is one of the directions: up, down, fo rward and backward.</p><p>Decision-making is based on a neural network model which is shown in the action decision-making module in Figure <ref type="figure" target="#fig_3">3</ref>. The output of the model consists of two parts: actor value and critic value since the training method used is A3C [18]. In the actor-network, we fi rst encode the input fe ature s through a linear layer as initial fe ature s X fo r the attention value iteration module of Multi-agent Routing Value Iteration Network (MARVIN). At each planning iteration, t , of the value iteration network, MARVIN performs the fo llowing iterative update through an LSTM with an attention module across neighboring vertices:</p><p>x Ck +l l = X(k) + LSTM (Att(XCkl ,A); HCkl)</p><p>fo r t = {1,2, ... , K} and K is the total number of value iteration steps. H C t lis the hidden state of the LSTM, and</p><p>A is the adj acency matrix. We let the output of the attention value iteration module through a decoding linear layer as the output of the actor network. It represents the probability of reaching a vertex in the local view. We use a mask to set the probability of all vertices except fo r adjacent vertices of current position in the local view as zero. The critic network is composed of two linear layers and a ReLU activation fu nction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reward fu nction</head><p>The environment will provide fe edback when the agent takes an action. There is positive and negative reward.</p><p>To motivate agents to reach their goals quickly, we penalize them at every timestep they are not on goal (rt = -0.3), as is common in most reward fu nctions fo r grid graph. In order to deal with the difference between the two situations in Figure <ref type="figure" target="#fig_6">5</ref>(a) and Figure <ref type="figure" target="#fig_6">5</ref>(b), we reduce the penalty of agents on the passed vertex (rt = -0. 1). Agents are also given a sizeable positive reward upon reaching their goal ( rt = + 5 ). Finally, when multiple agents try to reach a vertex at the same time, or an agent reaches the vertex that other agents have passed, the agent will get a conflict penalty (rt = -3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment setup 253</head><p>We implement the algorithm in Python with PyTorch and conduct experiments on a 64-bit Linux machine with a 4-core Intel Xeon @ 2.80GHz CPU and an NVIDIA GeForce RTX 1080 Ti GPU. We use a 3*7*7 grid graph fo r the experiment. We randomly generated 300 graphs, each containing 2 two-pin nets, as our training set and 100 graphs with a similar number of two-pin nets as our test set. We set the local view size as 3*5*5 and the learning rate as 0.001.</p><p>In the experiment, we evaluate the performance of the model by routing success rate and cost on the dataset. The success rate is defined as the ratio of a graph whose nets connect all their pins to the total number of test graphs. In particular, in order to show the success rates under different scenarios, we use con_suc to represent the success rates of completing the net pin connection task, and complex_suc to represent the success rates of complex scenarios in which no conflict is allowed. Moreover, we define cost as the metric of wire length. It is the sum of vertex cost, conflict cost, and success cost of all graphs in the test set. Ve rtex cost is the number of passed vertices in a graph. If a conflict occurs during routing, we set the conflict cost to 10. And we decide the success cost is 0 or 50 depending on whether the routing is successful or not.</p><p>For the experiment comparison, we borrow the asynchronized methods from path planning to construct the compared methods. In particular, we construct DR_ GVIN, which makes the routing decision using a graph-based value iteration network GVIN <ref type="bibr" target="#b15">[15]</ref>. We also construct DR_ MARVIN_ Att, indicating that the approach employs MARVIN <ref type="bibr" target="#b16">[16]</ref> directly using the attention module without the LSTM layer in the value iteration network module. We compare our proposed method with DR GVIN and DR MARVIN Att to show ---</p><p>the effectiveness of our proposed method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DR GVIN 86% 78% 2170</head><p>Table <ref type="table" target="#tab_0">2</ref> shows the evaluation results of our algorithm and other baselines. We can see that our method is significantly better than DR_ GVIN and DR_ MARVIN_ Att. In particular, the success ratio with conflict is 96% by our algorithm, while DR_ GVIN only has 86%. The success rate of complex scenarios is 96% by our algorithm, and DR_ GVIN only obtain a 78% success rate. Our proposed algorithm outperforms DR_GVIN and DR_MARVIN_Att by 11.6%. Furthermore, the cost of our algorithm is 1829, while the cost of DR_GVIN is up to 2170. Our proposed algorithm saves 15.7% of cost, suggesting the efficiency of the proposed algorithm.</p><p>Figure <ref type="figure" target="#fig_7">6</ref> shows the performance results of our proposed algorithm in terms of different graph sizes. The x-axis is the vertex number of a single layer, and we have three layers. It shows that the success rate of the proposed algorithm achieves almost 100% in the simple version of the routing. Meanwhile, even in the version that conflict is not allowed, the success rate is also over 80% as the increasing of graph size. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a detailed routing framework based on multi-agent reinforcement learning to connect pins fo r all nets simultaneously. In this framework, agents planned paths based on local information and communication thus reduced the computation cost and communication cost. Experimental results showed that the proposed algorithm enhanced the success rate of detailed routing by 96% and at the same time reduced the cost by 15.7%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•Figure 1</head><label>1</label><figDesc>Figure1The grid graphs of global and detailed routing .</figDesc><graphic url="image-1.png" coords="1,317.69,249.37,213.43,190.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 The conflict between net A and B.</figDesc><graphic url="image-2.png" coords="2,340.73,333.37,167.11,85.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>--� V . . . � �-.;J : :::: :. . . v _::: :--I Commit and get mformatiOn 1'1 n r; -------_I I_-------------------</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure3The overall structme of om method.</figDesc><graphic url="image-4.png" coords="3,56.33,155.71,482.23,85.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3. 2 Figure 4 A</head><label>24</label><figDesc>Figure 4 A locally observable cube area .</figDesc><graphic url="image-5.png" coords="3,63.29,337.45,215.35,119.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 1 and 5 2</head><label>2</label><figDesc>provides the vertex connection relationship in the limited observation graph to the agent. 53 indicates the location of the agent. And 54 means the location of pins that the agent must pass through. In a multi -agent enviromnent it is not enough to have only a starting vertex. an ending vertex. and a graph structure . Because the observation area is lilnited. it is difficult fo r the agent to obtain the direction infonnation when the pins are not in the observable graph. For this reason. we add 55 that named global guidance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5</head><label>5</label><figDesc>Figure 5 Two situations of a net's wires.</figDesc><graphic url="image-6.png" coords="3,312.65,559.45,223.27,102.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6</head><label>6</label><figDesc>Figure 6 Success rate on graphs with different graph sizes.</figDesc><graphic url="image-7.png" coords="5,56.57,145.75,228.79,142.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc>Performance com p arison.</figDesc><table><row><cell></cell><cell cols="3">Con sue Compl ex sue Cost</cell></row><row><cell>Ours</cell><cell>96%</cell><cell>96%</cell><cell>1829</cell></row><row><cell>DR MARVIN Att --</cell><cell>87%</cell><cell>84%</cell><cell>1934</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 06:55:28 UTC from IEEE Xplore. Restrictions apply.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1">Proceedings of NID C2 021</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Detailed routing based on Multi-Agent Reinforcement Learning</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by Hunan province sc1ence and technology proj ect funds(2018TP1036).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Multithreaded Initial Detailed Routing Algorithm Considering Global Routing Guides</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3240765.3240777</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Computer-Aided Design (ICCAD)</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">NCTU-GR 2.0: Multithreaded collision-aware global routing with bounded-length maze routing</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-Y</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TCAD</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">High-performance routing at the nanometer scale</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Markov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TCAD</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1066" to="1077" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">FastRoute 4.0: global router with efficient via minimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASPDAC</title>
				<meeting>ASPDAC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="576" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BoxRouter 2.0: A hybrid and robust global router with layer assignment for mutability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TODAES</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">I spd 2019 initial detailed routing contest and benchmark with advanced routing rules</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mantik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farshidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Passer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Symposium on Physical Design</title>
				<meeting>the 2019 International Symposium on Physical Design</meeting>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="147" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">TritonRoute: an initial detailed router for advanced VLSI technologies</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20 18 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rdta: An efficient mutability-driven track assignment algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 on Great Lakes Symposium on VLSI</title>
				<meeting>the 2019 on Great Lakes Symposium on VLSI</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dr. CU: Detailed Routing by Sparse Grid Graph and Minimum Area-Captured Path Search</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Pui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dr. CU 2.0: A Scalable Detailed Routing Framework with Correct-by-Construction Design Rule Satisfaction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F Y</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20 19 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)</title>
				<meeting><address><addrLine>Westminster, CO, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11">Nov. 2019</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Attention Routing : track-assignment detailed routing using attention-based reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kara</surname></persName>
		</author>
		<idno>ArXiv, abs/2004.09473</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Asynchronous Reinforcement Learning Framework for Net Order Exploration in Detailed Routing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">202 1. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><surname>Design</surname></persName>
		</author>
		<title level="m">Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</title>
				<imprint>
			<biblScope unit="page" from="1815" to="1820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PRIMAL : Pathfinding via Reinforcement and Imitation Multi Agent Learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sartoretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Satish Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Choset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2378" to="2385" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Mobile Robot Path Planning in Dynamic Environments through Globally Guided Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Prorok</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05420</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalized value iteration networks: Life beyond lattices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Targonski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kovacevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty Second Conference on Artificial Intelligence, AAAI</title>
				<meeting>the Thirty Second Conference on Artificial Intelligence, AAAI</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multi-Agent Routing Value Iteration Network</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Sykora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.05096</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1602.01783</idno>
		<title level="m">Asynchronous Methods fo r Deep Reinforcement Learning</title>
				<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
