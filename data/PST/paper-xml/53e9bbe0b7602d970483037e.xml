<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Record Linkage using Seeded Nearest Neighbour and Support Vector Machine Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Peter</forename><surname>Christen</surname></persName>
							<email>peter.christen@anu.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<postCode>ACT 0200</postCode>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<addrLine>Las Vegas</addrLine>
									<postCode>2008</postCode>
									<settlement>Nevada</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Record Linkage using Seeded Nearest Neighbour and Support Vector Machine Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">93BA10DA85E239978C236292A915A82C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.2.6 [Artificial Intelligence]: Learning; H.2.8 [Database Management]: Database applications-Data mining Algorithms</term>
					<term>Experimentation</term>
					<term>Performance Data matching</term>
					<term>data linkage</term>
					<term>deduplication</term>
					<term>entity resolution</term>
					<term>nearest neighbour</term>
					<term>support vector machine</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The task of linking databases is an important step in an increasing number of data mining projects, because linked data can contain information that is not available otherwise, or that would require time-consuming and expensive collection of specific data. The aim of linking is to match and aggregate all records that refer to the same entity. One of the major challenges when linking large databases is the efficient and accurate classification of record pairs into matches and non-matches. While traditionally classification was based on manually-set thresholds or on statistical procedures, many of the more recently developed classification methods are based on supervised learning techniques. They therefore require training data, which is often not available in real world situations or has to be prepared manually, an expensive, cumbersome and time-consuming process.</p><p>The author has previously presented a novel two-step approach to automatic record pair classification <ref type="bibr" target="#b6">[6,</ref> 7]. In the first step of this approach, training examples of high quality are automatically selected from the compared record pairs, and used in the second step to train a support vector machine (SVM) classifier. Initial experiments showed the feasibility of the approach, achieving results that outperformed k-means clustering. In this paper, two variations of this approach are presented. The first is based on a nearestneighbour classifier, while the second improves a SVM classifier by iteratively adding more examples into the training sets. Experimental results show that this two-step approach can achieve better classification results than other unsupervised approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>As increasingly large amounts of data are being collected by many organisations, techniques that enable efficient mining of massive databases have in recent years attracted interest from both academia and industry. Sharing of large databases between organisations is also of growing importance in many data mining projects, as data from various sources often has to be linked and aggregated in order to improve data quality, or to enrich existing data with additional information <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b24">24]</ref>. Similarly, detecting duplicate records that relate to the same entity within one database is commonly required in the data preparation step of many data mining projects <ref type="bibr" target="#b14">[14]</ref>. The aim of such linkages and deduplications is to match all records that relate to the same entity. These entities can be, for example, patients, customers, businesses, product descriptions, or publications.</p><p>Traditionally, record linkage has been employed in the health sector and within statistical agencies <ref type="bibr" target="#b24">[24]</ref>. Today, many public and private sector organisations use deduplication and linkage techniques to improve the quality of their databases. Government agencies use record linkage to, for example, identify people who register for assistance multiple times, or who collect unemployment benefits despite being employed. National security, and crime and fraud detection, are other areas where record linkage is increasingly being employed. Security agencies often require fast access to files of a particular individual in order to solve crimes or to prevent terror through early intervention <ref type="bibr" target="#b18">[18]</ref>.</p><p>If all databases to be linked contain common entity identifiers (or keys), then the problem of linking at the entity level can be solved by a standard database join. In most situations, however, no such entity identifiers are available, and therefore more sophisticated linkage techniques have to be applied. Broadly, these techniques can be classified into deterministic, probabilistic, and modern approaches <ref type="bibr" target="#b9">[9]</ref>.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> outlines the general record linkage process. An important initial step for successful linkage is data cleaning and standardisation, as in most real-world databases noisy, incomplete and incorrect information is common <ref type="bibr" target="#b10">[10]</ref>. A lack of high quality data can be one of the biggest obstacles to successful record linkage. The main tasks of data cleaning and standardisation are the conversion of the raw input data into well defined, consistent forms, and the resolution of inconsistencies in the way information is represented. When linking two databases, A and B, potentially each record in A should be compared with all records in B. Therefore, the total number of potential record pair comparisons equals |A| × |B|, with | • | denoting the number of records in a database. Similarly, when deduplicating a database, A, the total number of potential record pair comparisons is |A| × (|A| -1)/2, as each record potentially has to be compared to all others. However, as the performance bottleneck in a record linkage or deduplication system is normally the expensive detailed comparison of field (or attribute) values between records <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b9">9]</ref>, it is impossible to compare all pairs when the databases are large. Additionally, assuming there are no duplicate records in the databases to be linked (i.e. one record in A can only be a true match to one record in B, and vice versa), then the maximum number of true matches corresponds to min(|A|, |B|). Thus, when linking larger databases the computational efforts potentially increase quadratically while the maximum number of true matches only increases linearly. This also holds for deduplication, where the number of true duplicate records is always less than the number of records in a database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cleaning and standardisation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cleaning and standardisation</head><note type="other">Database</note><p>To reduce the potentially very large number of comparisons to be conducted between pairs of records, some form of indexing or filtering technique, collectively known as blocking <ref type="bibr" target="#b1">[1]</ref>, is employed by most record linkage systems. A single record attribute, or a combination of attributes, often called the blocking key, is used to split the databases into blocks. All records that have the same value in the blocking key will be inserted into the same block, and candidate record pairs are only generated from records within the same block. Even though blocking will remove many of the record pairs that are obvious non-matches, some true matches will likely also be removed in the blocking process, because of errors or typographical variations in record attribute values <ref type="bibr" target="#b9">[9]</ref>.</p><p>The two records in a candidate pair are compared using similarity functions applied to selected record attributes (fields). These functions can be as simple as an exact string or a numerical comparison, can take typographical variations into account <ref type="bibr" target="#b11">[11]</ref>, can be specialised for example for date or time values, or they can be as complex as a distance comparison based on look-up tables of geographic locations (longitudes and latitudes). There are also various approaches to learn such similarity functions from training data <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b11">11]</ref>. Each similarity function returns a numerical WV(R1,R2): [0.9, 1.0, 1.0, 1.0, 0.9] WV(R1,R3): [0.0, 0.0, 0.0, 0.0, 0.0] WV(R1,R4): [0.0, 0.0, 0.5, 0.0, 0.0] WV(R2,R3): [0.0, 0.0, 0.0, 0.0, 0.0] WV(R2,R4): [0.0, 0.0, 0.5, 0.0, 0.0] WV(R3,R4): [0.7, 0.3, 0.5, 0.7, 0.9] matching weight that is usually normalised, such that 1.0 corresponds to exact similarity and 0.0 to total dissimilarity, with attribute values that are somewhat similar having a matching weight somewhere in between 0 and 1.</p><p>As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, for each compared record pair a weight vector is formed that contains the matching weights calculated for that pair. Using these weight vectors, candidate pairs are classified into matches, non-matches, and possible matches, depending upon the decision model used <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b17">17]</ref>. Pairs of records that are not compared due to the blocking process are implicitly assumed to be non-matches. Assuming there are no duplicate records in the databases to be linked, then the majority of candidate pairs are likely non-matches, because the maximum possible number of true matches corresponds to the number of records in the smaller of the databases that are linked. Classifying record pairs is therefore often a very imbalanced problem <ref type="bibr" target="#b9">[9]</ref>.</p><p>Two records that have equal or very similar values in all their attributes will likely refer to the same entity, as it is unlikely that two entities have very similar values (or even the same value) in all their record attributes. All matching weights calculated when comparing such a pair of records will be 1, or close to 1. On the other hand, weight vectors that contain matching weights of only 0, or weights close to 0, were with high likelihood calculated when two records that refer to two different entities were compared, as it is unlikely that two records that refer to the same entity have totally different values in all their attributes. For example, when somebody moves, most of that person's address details will change, while the person's name, gender and date of birth will stay the same. Therefore, there would be several record attributes that keep their values.</p><p>Based on these observations, it is often easy to accurately classify record pairs as matches when their weight vectors contain only matching weights close to or equal to 1, and as non-matches when their weights are all close to or equal to 0. On the other hand, it is more difficult to correctly classify record pairs that have some similar and some dissimilar attribute values. In Figure <ref type="figure" target="#fig_1">2</ref>, for example, records R1 and R2 are very similar to each other, with only two small differences in their given name and street type attributes, and thus very likely refer to the same person. On the other hand, records R3 and R4 are more different from each other, and it is not obvious if they refer to the same person or not.</p><p>It follows that it is possible to automatically select training examples (weight vectors) from the set of all weight vectors that with high likelihood correspond to true matches or true non-matches, and to then train a supervised binary classifier using these training examples as 'seeds'. For example, of the weight vectors shown in Figure <ref type="figure" target="#fig_1">2</ref>, WV(R1,R2) can be selected as a match training example, while WV(R1,R3) and WV(R2,R3), possibly even WV(R1,R4) and WV(R2,R4), can be used as non-match training examples.</p><p>This two-step approach to automated record pair classification has first been proposed by the author in <ref type="bibr" target="#b6">[6]</ref>, with initial experiments indicating its feasibility. The contribution of this paper is the evaluation of two improved classification methods to be used in the second step of the approach. The first method is based on nearest-neighbour classification, and the second improves SVM classification by iteratively adding more weight vectors into the training sets.</p><p>The remainder of this paper is structured as follows. An overview of related work is given next. Then, the proposed two-step approach to record pair classification is presented in detail in Section 3, with the new classification methods discussed in Section 3.2. These two methods are then evaluated experimentally in Section 4 using both real and synthetic data sets, and the paper is concluded in Section 5 with an outlook to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>The classic probabilistic record linkage approach, as formalised in the 1960s by <ref type="bibr" target="#b15">[15]</ref>, has in recent years been improved by applying the expectation-maximisation (EM) algorithm for better parameter estimation in record pair classification <ref type="bibr" target="#b23">[23]</ref>, and by using approximate string comparisons to calculate partial agreement weights when record attribute (field) values have typographical variations <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b14">14]</ref>.</p><p>Since the mid 1990s, researchers have investigated a variety of approaches to record linkage, originating from artificial intelligence, database technology, information retrieval, machine learning, and data mining <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b14">14]</ref>, with the aims of improving the linkage quality and the scalability of the linkage process. Many of these approaches are based on supervised learning techniques and require training data (record pairs with known true match or true non-match status).</p><p>Such training examples, however, are often not available in real world situations, or they have to be prepared manually. This is a laborious process, and often the training data generated is not 100% accurate, as even humans are not always able to clearly determine weather two records are a true match or not, without having access to further information.</p><p>One supervised approach is to learn similarity measures for approximate string comparisons, such as the costs for edit-distance operations <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b11">11]</ref>, with the aim to adapt similarity calculations to a particular data domain. Decision tree induction <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b22">22]</ref> and support vector machines <ref type="bibr" target="#b19">[19]</ref> are two popular supervised machine learning techniques that have been employed successfully for record pair classification. As expected, these techniques usually achieve better linkage quality compared to unsupervised approaches.</p><p>Three methods for record pair classification have been implemented in TAILOR <ref type="bibr" target="#b13">[13]</ref>: the first is based on supervised decision tree induction, the second is using unsupervised kmeans clustering (with three clusters, one each for matches, possible matches and non-matches), and the third is a hybrid approach that combines the first two to overcome the problem of lack of training data. It first clusters a sub-set of the weight vectors (again into matches, possible matches and non-matches), and then uses the match and non-match clusters to train a supervised decision tree classifier. Both the fully supervised and hybrid approach outperformed k-means clustering in experimental studies. In Section 4, a variation of the hybrid TAILOR approach (employing a SVM instead of a decision tree classifier) will be compared experimentally to the proposed two-step classification approach.</p><p>Active learning is an approach that aims to overcome the problem of lack of training data. A system that presents a difficult to classify record pair to a user for manual classification is discussed in <ref type="bibr" target="#b21">[21]</ref>. After such a pair has been manually classified, it is added to the training data and the classifier is re-trained. This process is repeated until all record pairs are successfully classified. Using this approach, manually classifying less than 100 training pairs provided better results than a fully supervised approach that required 7,000 randomly selected examples. A similar approach is presented in <ref type="bibr" target="#b22">[22]</ref>, where a committee of decision trees is used to learn a set of rules that describe linkages.</p><p>Unsupervised clustering techniques have been investigated both to improve blocking <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b12">12]</ref> and for automatic record pair classification <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b17">17]</ref>. The clustering techniques kmeans and farthest-first were compared in <ref type="bibr" target="#b16">[16]</ref> with supervised decision tree induction using both synthetic and real data. Surprisingly, farthest-first clustering outperformed kmeans and achieved results comparable to decision trees. In <ref type="bibr" target="#b17">[17]</ref>, the k-means clustering algorithm has been employed to group weight vectors into matches and non-matches. In this approach, a user can also identify a 'fuzzy' region halfway in between the two cluster centroids where the difficult to classify record pairs are located. These pairs will then be handed to the user for manual clerical review. Using synthetic data, it was shown that this approach can significantly reduce the number of record pairs that have to be reviewed manually, while keeping high linkage quality.</p><p>Recently, unsupervised techniques based on relational clustering <ref type="bibr" target="#b2">[2]</ref> have been explored for entity resolution of relational data. While traditional record linkage techniques assume that only similarities between attribute values are available, in relational data the entities have additional relational information that can be used to improve the quality of entity resolution. Relational information is present, for example, in census databases that include a family relationship attribute (with values like 'married to', 'dependent of', or 'parent of'); or in bibliographic data where, besides the name of a paper, a publication record also contains a list of one or more authors that can indicate co-author relationships. Experimental results <ref type="bibr" target="#b2">[2]</ref> showed that relational entity resolution outperforms traditional record linkage based only on record attribute similarities. However, non-relational data is still available in many real world applications, such as in databases that contain hospital patient or customer information, and this paper concentrates on improving unsupervised classification of such non-relational data.</p><p>The two-step classification approach presented in this paper has been inspired by similar methods for text classification, where commonly only a limited number of positive labeled examples, besides many unlabeled examples, are available for training. In such situations the aim is to learn a classifier from these positive and unlabeled examples. In <ref type="bibr" target="#b25">[25]</ref>, the TC-WON approach is described, which iteratively trains a SVM using the positive and a selected set  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TWO-STEP CLASSIFICATION</head><p>The idea of seeded record pair classification is based on the following two assumptions. First, weight vectors that contain exact or high similarity values in all their matching weights were with high likelihood generated when two records that refer to the same entity were compared. Second, weight vectors that contain mostly low similarity values were with high likelihood generated when two records that refer to different entities were compared. As a result, selecting such weight vectors in a first step as seeds for generating training data, and training a classifier using these seed training examples in a second step, should enable automatic, efficient and accurate record pair classification.</p><p>Previously, in <ref type="bibr" target="#b6">[6]</ref> and <ref type="bibr">[7]</ref>, the author has shown the feasibility of this proposed approach, and investigated several variations of how to select the initial seed training examples. This paper concentrates on the second step of the approach, which will be discussed in detail in Section 3.2. First, an overview of the first step of the approach is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Step 1: Selection of Training Examples</head><p>Let W be the set of weight vectors that were generated in the comparison step (after blocking has been applied to reduce the total number of detailed record pair comparisons). The aim of the first step of the proposed approach is to select weight vectors from W that with very high likelihood correspond to true matches and true non-matches. The selected weight vectors are inserted into the match seed training examples set, WM , and the non-match seed training examples set, WN , respectively (with WM ∩WN = ∅). There are two main approaches to selecting training examples, either using distance thresholds or nearest-based <ref type="bibr" target="#b6">[6]</ref>.</p><p>The threshold based approach selects weight vectors that have all their matching weights within a certain distance threshold to the exact similarity or total dissimilarity values, respectively. For example, using the weight vectors from Figure <ref type="figure" target="#fig_1">2</ref> and a distance threshold of 0.2, only WV(R1,R2) will be selected into WM , and WV(R1,R3) and WV(R2,R3) into WN . The remaining three weight vectors will not be selected, as at least one of their matching weights is further than the 0.2 distance threshold away from 0 or 1.</p><p>In the nearest based approach, on the other hand, weight vectors are sorted according to their distances (using, for example, Manhattan or Euclidean distance) from the vectors containing only exact similarities and only total dissimilarities, respectively, and the respectively nearest vectors are se-lected into the training sets. In Figure <ref type="figure" target="#fig_1">2</ref>, WV(R1,R2) is closest to the exact similarities vector ([1.0, 1.0, 1.0, 1.0, 1.0]), followed by WV(R3,R4); while WV(R1,R3) and WV(R2,R3) only contain total dissimilarity values, and WV(R1,R4) and WV(R2,R4) are the next vectors closest to them.</p><p>Experiments <ref type="bibr" target="#b6">[6]</ref> showed that the nearest based approach generally outperforms threshold based selection. One reason is that nearest based selection allows explicit specification of the number of weight vectors to be included into WM and WN . Because weight vector classification is often a very imbalanced problem, the number of true non-matches in W is commonly much larger than the number of true matches <ref type="bibr" target="#b9">[9]</ref>, and thus more weight vectors should be selected into WN than into WM . An estimation, r, of the ratio of true matches to true non-matches can be calculated using the number of records in the two databases to be linked, A and B, and the number of weight vectors in W:</p><formula xml:id="formula_0">r = min(|A|, |B|) |W| -min(|A|, |B|) ,<label>(1)</label></formula><p>with | • | denoting the number of elements in a set or a database. The problem with balanced training set sizes is that weight vectors that likely do not correspond to true matches will be selected into WM <ref type="bibr" target="#b6">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Step 2: Classification of Record Pairs</head><p>Once the seed training example sets for matches, WM , and non-matches, WN , have been generated, they can be used to train any binary classifier. In the following two sections, a nearest-neighbour based classifier and an iterative SVM classifier are presented. The set of weight vectors not selected into the seed training example sets will be denoted with WU , with WU = W \ (WM ∪ WN ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Nearest-Neighbour Classification</head><p>The basic idea of this classifier is to iteratively add unclassified weight vectors from WU into the training sets until all weight vectors are classified. In each iteration, the unclassified weight vector closest to k already classified weight vectors is classified according to a majority vote of its classified neighbours (i.e. if the majority is either matches or non-matches). Using the seed training example sets, this nearest-neighbour based classifier can be implemented efficiently as illustrated in Figure <ref type="figure" target="#fig_3">3</ref> and detailed in Algorithm 1.  In Algorithm 1, the number of nearest weight vectors to be considered when nearest neighbours are selected is denoted with k (with k ≥ 1). The function dist calculates the distance between two weight vectors, and can be any distance function such as Euclidean, Manhattan, Canberra, or Cosine distance. In the first line of the algorithm, the output sets of classified match and non-match weight vectors, ZM and ZN , are initialised to the seed training example sets. Next, in line 2, the set WT of all seed training examples and the set WU of all unclassified weight vectors are generated. An empty heap data structure, H, is then initialised next. A heap has the property that its first element is always the smallest element. It will be used in the second phase of the algorithm to iteratively get the next unclassified weight vector that has the smallest distance to the training sets. In line 4, three lists, M, N and U, are initialised that will be used to store nearest weight vectors as detailed below.</p><p>Lines 5 to 15 constitute the first phase of Algorithm 1. In lines 5 and 6, for each weight vector in the match seed training set WM , the closest (k + 1) not classified weight vectors from WU are stored in the list M. The same is done in lines 8 and 9 for the weight vectors in the nonmatch seed training set WN , with nearest neighbours from WU stored in list N. These (k + 1) nearest neighbours (in M and N) are represented in Figure <ref type="figure" target="#fig_3">3</ref> using dashed arrowed lines. In lines 11 and 12, for each unclassified weight vector in WU , the closest (k + 1) weight vectors from the overall seed training set WT are stored in the list U. These nearest neighbours (in U) are represented in Figure <ref type="figure" target="#fig_3">3</ref> using black arrowed lines (with the nearest neighbour indicated using a bold black line). Additionally, in lines 13 and 14, the sum of the distances, s, of the k closest training set neighbours for each wu in Wu are calculated and inserted into the heap H. Therefore, at the end of this first phase of the algorithm, the first element of H will be the weight vector from WU with the smallest distance sum to vectors from WT .</p><p>Phase two of Algorithm 1 (line 16 onwards) iterates until all weight vectors in WU are classified. In line 17, the first element in H, i.e. the weight vector with the smallest sum of distances to classified weight vectors, is taken from H and removed from WU in line 18. Depending upon if the majority of neighbours of wt are matches or non-matches, it is added to the set of classified matches, ZM , or classified non-matches, ZN , respectively (lines 19 to 22).</p><p>In line 24, the set U[wt] of nearest training set weight vectors of wt is used to create the set Xu of nearest unclassified weight vectors. Xu is retrieved via the corresponding nearest sets in the lists M and N. Line 25 then loops over each of the unclassified weight vectors wu in Xu that are nearest to the newly classified weight vector wt. In line 26, the distance d from wu to wt is calculated, and the list of nearest classified weight vectors for wu, U[wu], is updated with this new distance d in line 28 if d is one of the (k + 1) smallest distances. In this case, the heap element for wu also needs to be updated in H with the newly calculated distance sum s (lines 29 and 30). Finally, depending upon if wt was classified as a match or a non-match, the set of nearest unclassified weight vectors for wt is updated in the corresponding list M or N in lines 33 to 36.</p><p>This process is illustrated in Figures <ref type="figure" target="#fig_3">3 (b</ref>) and (c). The middle upper, unclassified weight vector is classified as a match, because its nearest neighbour is a match. Its list of nearest matches (solid lines) is used to get its nearest classified neighbours (the two seed matches in the top right), which in turn have lists of their nearest unclassified neighbours (dotted lines). The union of these lists becomes the new list of unclassified nearest neighbours, represented in Figure <ref type="figure" target="#fig_3">3</ref> (c) with the new dotted lines that point from the newly classified match to its two unclassified neighbours.</p><p>Naïve nearest-neighbour based classification would involve calculating the distances between all pairs of weight vectors, and thus have complexity O(|W| 2 ). This could be improved significantly by employing data reduction or fast searching and indexing techniques for nearest-neighbour classification <ref type="bibr" target="#b20">[20]</ref>, work that is left for future improvements.</p><p>The seeded training sets also allow a reduction of distance calculations to be done through the use of the nearest lists M, N and U. In the first phase of Algorithm 1, distances are only calculated between the weight vectors in the overall training example set WT and those in WU . If a fraction of t (t &lt; 1) of all weight vectors is included in WT , then the number of distance calculations in the first phase of the algorithm is |W| 2 ×(t-t 2 ). The maximum number of distance calculations will have to be done if half the weight vectors are in WT and half are in WU , i.e. t = 0.5: |W| 2 × 0.25; while with t = 0.1, for example, the number of distance calculations to be done is only |W| 2 × 0.09. The second phase of the algorithm involves calculating a maximum of (k + 1) × k distances for each of the weight vectors in WU , as for each of the k nearest training set weight vectors the (k + 1) nearest vectors will have to be checked for closeness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Iterative SVM Classification</head><p>The iterative SVM classifier is similar to the TC-WON <ref type="bibr" target="#b25">[25]</ref> approach for text and Web page classification based on only positive labeled training examples. The basic idea is to train an initial SVM using the seed training example sets WM and WN , and to then iteratively add the strongest positive and negative classified weight vectors from WU into the training sets of subsequent SVMs.</p><p>Algorithm 2 details the steps involved in this approach. The input parameter ip determines what percentage of unclassified weight vectors will be added into the training sets in each iteration, and tp determines the total percentage of weight vectors that will be added into the training sets. For example, if tp = 100% then all weight vectors from W will be used in the last iteration to train the final SVM.</p><p>The algorithm starts with initialising the training sets TM for matches and TN for non-matches, and by creating the set WU of all unclassified weight vectors. The initial SVM svm0 is trained in line 3 using TM and TN . The main loop then starts in line 5 and iterates until tp percent of all weight vectors have been included into the training sets.</p><p>Each iteration starts in line 6 by classifying the weight vectors in WU using the previously trained SVM svmi. The function svm classif y returns two sets, XM and XN , that contain the weight vectors from WU classified as matches and non-matches, respectively. These classified weight vectors are sorted in line 7 according to how far away they are from the SVM decision boundary, and in lines 8 and 9 the strongest positive and negative weight vectors are extracted into the sets YM of new matches, and YN of new non-matches. The size of these sets is determined by the increment percentage parameter ip.  The final SVM is then used in line 16 to classify the weight vectors in WU that have not been classified so far (this step is not required if tp = 100%), and in line 17 the final two sets of matches and non-matches, ZM and ZN , are created.</p><p>Assuming that training a SVM is of quadratic complexity in the number of training examples <ref type="bibr" target="#b25">[25]</ref>, then the overall complexity of Algorithm 2 is O(|W| * i), with i being the number of times a SVM is trained. The value of i depends upon the ip and tp parameter values. For example, if ip = 50% and tp = 100% then i = log2(|WU |), while if ip = 25% and tp = 50% then i = 3, as in each step 25% of weight vectors from WU will be added to the training sets. Training of SVMs will become increasingly time consuming as more weight vectors are added into the training sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL EVALUATION</head><p>The two record pair classifiers presented above were evaluated and compared with two other classification methods. The first is a fully supervised SVM that has access to the true match status of all weight vectors. Nine parameter variations were evaluated: three kernel methods (linear, polynomial and RBF), and three values for the cost parameter, C [4] (0.1, 1, 10). The second method is based on the hybrid approach implemented in the TAILOR <ref type="bibr" target="#b13">[13]</ref> toolbox. It first employs k-means (with one cluster each for matches, possible matches and non-matches), and then uses the match and non-match clusters to train a SVM (in <ref type="bibr" target="#b13">[13]</ref> a decision tree classifier has been used instead). Two distance functions (Manhattan and Euclidean) were evaluated for the k-means step, while for the SVM classifier step the same nine parameter variations as for the supervised SVM were used.   For the two-step classification approach, the imbalanced nearest based selection method <ref type="bibr" target="#b6">[6]</ref> was used, with the number of seed training examples in WN selected as 5% or 10% of all weight vectors in W, respectively, and the number of training examples in WM calculated according to the ratio r as given in Equation <ref type="bibr" target="#b1">(1)</ref>. For the nearest-neighbour based two-step classifier (as described in Section 3.2.1), again Manhattan and Euclidean distances were evaluated in combination with k set to 3 and 9. For the iterative SVM based two-step classifier (described in Section 3.2.2), the same nine parameter variations as for the supervised SVM were evaluated, and the parameters ip and tp were set to the pairs (0,0) (no iterative refinement), <ref type="bibr" target="#b25">(25,</ref><ref type="bibr" target="#b25">25)</ref>, <ref type="bibr" target="#b25">(25,</ref><ref type="bibr">50)</ref>, and (50,100).</p><p>The experiments for the supervised SVM and TAILOR classifiers were conducted using 10-fold cross validation (90% used for training and 10% for testing), while this was not possible for the two-step classifier, because the selection of seed training examples requires all weight vectors in W.</p><p>All classifiers are implemented in the Febrl <ref type="bibr" target="#b8">[8]</ref> record linkage system, which is written in Python. The libsvm library was used for the SVM classifier <ref type="bibr" target="#b4">[4]</ref>. All experiments were run on a 2.13 GHz dual-core CPU with 2 GBytes of main memory, running Linux 2.6.20 and using Python 2.5.1.</p><p>Experiments were conducted using both real and synthetic data, as summarised in Table <ref type="table" target="#tab_2">1</ref>. Three real data sets from the SecondString toolkit 1 were used, while four synthetic data sets of various sizes were created using the Febrl data set generator <ref type="bibr" target="#b5">[5]</ref>. This synthetic data contains name and address attributes that are based on real-world frequency tables, and includes 60% original and 40% duplicate records. The duplicates were randomly created through modification of record attributes (like inserting, deleting or substituting characters, and swapping, removing, inserting, splitting or merging words), again according to real-world error characteristics. Up to nine duplicates were generated for one original record, with a maximum of three modifications per attribute and a maximum ten modifications per record.</p><p>1 http://secondstring.sourceforge.net Standard blocking <ref type="bibr" target="#b1">[1]</ref> was applied in all experiments to reduce the number of detailed record pair comparisons, with the blocking keys being combinations of name, address and postcode values. In the record pair comparison step, the Winkler <ref type="bibr" target="#b24">[24]</ref> approximate string comparator (commonly used in record linkage) was employed for name, address, paper title and conference name attribute (field) comparisons. Additionally, character difference comparisons <ref type="bibr" target="#b8">[8]</ref> were used on attributes such as postcode, street number, and publication year. Figure <ref type="figure" target="#fig_8">4</ref> shows histograms based on the summed weight vectors that were generated in the comparison step. The imbalance between the number of matches and nonmatches can be seen clearly, especially for the 'Restaurant' data set. The ratios of matches to non-matches (both calculated according to Equation (1) and based on the data itself) are shown in the last column of Table <ref type="table" target="#tab_2">1</ref>.</p><p>The quality of the compared record pairs is shown in Table 1 using the pairs completeness measure (which is the number of true matched record pairs generated by blocking divided by the total number of true matched record pairs), and the complexity of the record pair comparison step is shown using the reduction ratio measure (which is one minus the number of record pairs generated by blocking divided by the total possible number of record pairs) <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b13">13]</ref>.</p><p>Due to the imbalanced distribution of matches and nonmatches in the weight vector set W, the accuracy measure commonly used for evaluating classifier performance is not suitable for assessing the quality of record pair classification <ref type="bibr" target="#b9">[9]</ref>: the large number of non-matches would dominate accuracy, and show results that are too optimistic. Instead, the F-measure, F , the harmonic mean of precision, P , and recall, R, is used for measuring classifier quality: F = 2(P × R)/(P + R), with P = T P/(T P + F P ) and R = T P/(T P + F N ). T P is the number of true positives (true matched record pairs classified as matches), F N the number of false negatives (true matched record pairs classified as non-matches), and F P the number of false positives (true non-matched record pairs classified as matches).  <ref type="table" target="#tab_3">2</ref> shows the quality of the seed training example sets generated in the first step of the proposed two-step classification approach (as described in Section 3.1), given as the percentage of correctly selected weight vectors in these sets, i.e. (100 × |true matches in WM |/|WM |) and 100 × |true non-matches in WN |/|WN |). For the second step, Figure <ref type="figure">5</ref> shows the average F-measure results, together with the minimum and maximum F-measure results over all parameter variations discussed above (i.e. 9 supervised SVMs, 18 TAI-LOR classifiers, 8 nearest-neighbour based two-step classifiers, and 72 iterative two-step SVM classifiers -18 each for the four variations of the (ip,tp) parameter pairs). These average results, rather than the 'best' results using a certain parameter setting, are presented as they provide a more realistic picture of the overall performance of a classifier (which likely depends upon the characteristics of a data set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results and Discussion</head><p>As can be seen in Table <ref type="table" target="#tab_3">2</ref>, the seed training example sets selected in the first step of the proposed two-step classification approach are mostly of very high quality, with the match training example set WM only containing true matches in all but one case (10% seed size for the 'Restaurant' data set). While overall the 1% training set selection contains the highest quality seed training data, the size of these sets (especially WM ) is very small, and the resulting classifiers based on these 1% seeds generated in the second step were much worse in most experiments compared to the classifiers generated based on 5% or 10% seed sizes. Therefore, the classifiers based on 1% seed size were not used further and are not included in the results presented.</p><p>Figure <ref type="figure">5</ref> shows the F-measure results for all data sets, with the results for the four synthetic data sets averaged (as they all had very similar F-measure results). As can be seen, there is a large variety of F-measure result values for certain classifiers, and very different F-measure result values for the same classifier on the different data sets.</p><p>As expected, the supervised SVM (which can be seen as an 'oracle' as it knows the true match status of all record pairs) performs best on all data sets. For the 'Census' and 'Restaurant' data sets, there are, however, parameter settings that lead to SVM classifiers that perform worse than the best two-step classifier using the iterative SVM approach. The TAILOR hybrid classifier approach has the lowest performance on most data sets. Only on 'Cora' did it achieve better results than most two-step classifier variations.</p><p>The nearest-neighbour based two-step classifier performs better than all iterative SVM variations for all synthetic data sets, while for the real data sets the iterative SVM generally achieves better classification results. Looking at the different values of the parameter pairs (ip,tp), a noticeable improvement when including more weight vectors into the training sets is only visible for 'Cora', while the improvements are very small for the synthetic data sets, and mixed for the 'Census' data. For the 'Restaurant' data set, the results are getting worse when more training data is added.</p><p>The results for the 'Restaurant' data set are very low for all unsupervised classifiers compared to the supervised SVM. One reason for this is that for this data set the weight vector set W only contains 112 matches (duplicates), but 106,763 non-matches (a ratio of 1 to 953), making it very difficult to extract true match examples. Another reason is that the attributes in this data set contain addresses with a large proportion of either abbreviations or completely different values (such as 'Los Angeles' versus 'Beverly Hills') for the same restaurant. Therefore, the weight vectors generated when such attribute values were compared have a very overlapped distribution of matches and non-matches (as can be seen in Figure <ref type="figure" target="#fig_8">4</ref>), that are hard to classify without knowing the true match status of these weight vectors. This can also be seen in Table <ref type="table" target="#tab_3">2</ref>, where with the 10% seed size the match training set WM already contains more than 9% non-matches.</p><p>The experiments presented in this paper show that the proposed two-step classification approach can achieve results that outperform other unsupervised record pair classification techniques, such as the hybrid TAILOR approach which previously has shown to be better than k-means clustering <ref type="bibr" target="#b13">[13]</ref>. On the other hand, these experiments also showed the limitations of unsupervised classification based on only pair-wise record attribute similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS AND FUTURE WORK</head><p>This paper presented a novel unsupervised two-step approach to record pair classification that is aimed at automating the record linkage process. This approach combines automatic selection of seed training examples with training of a binary classifier. The two two-step classifiers discussed achieve improved record pair classification results compared to other unsupervised classifiers, such a the hybrid TAI-LOR <ref type="bibr" target="#b13">[13]</ref> approach. Thus, the proposed approach can be used in situations where no training data is available.</p><p>Future work will include to conduct more experiments using different data sets, including run-time tests on data sets of various sizes in order to experimentally get scalability results. Related to this is the implementation of data reduction and fast searching and indexing techniques for the nearest-neighbour based classifier <ref type="bibr" target="#b20">[20]</ref>, and similar approaches for the iterative SVM, with the aim to reduce training times while keeping a high record pair classification quality. Another area of research will be to investigate active learning techniques <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22]</ref> and combine them with the seeded training example selection approach presented here. Active learning can, for example, be used in the iterative two-step SVM classifier to select the hardest to classify examples and hand them to a user for manual classification (assuming additional information might be available).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The general record linkage process. The output of the blocking step are candidate record pairs, while the field (attribute) comparison step generates weight vectors with matching weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Four example records (made of given name and surname; and street number, name and type) and the corresponding weight vectors (WV) resulting from the comparisons of these records.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>of strong negative examples. Additional unlabeled examples are included into the training sets as the trained classifier becomes more accurate, until all unlabeled examples are classified.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of the seeded nearest-neighbour classification process with 2-dimensional weight vectors and k = 1. Weight vectors classified as matches are shown with a ⊕, non-matches with a ⊖, and unclassified weight vectors with a circled question mark. The seed training examples are shown as bold circles. In each step, the unclassified weight vector closest to k already classified neighbours is added to one of the training sets. Details of this process are described in Section 3.2.1 and Algorithm 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 :</head><label>1</label><figDesc>Seeded k-NN classification Input: -Set of weight vectors generated in comparison step: W -Seed training examples match set: WM -Seed training examples non-match set: WN -Distance function: dist -Number of nearest-neighbours to consider: k Output: -Weight vectors classified as matches: ZM -Weight vectors classified as non-matches: ZN 1: ZM := WM and ZN := WN 2: WT := (WM ∪ WN ) and WU := W \ WT 3: Initialise empty heap H 4: M := [ ], N := [ ], U := [ ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>For example, if ip = 50%, then in each iteration half of the weight vectors in XM are inserted into YM and half of XN into YN . In lines 10 and 11, the new training examples in YM and YN are added to the training sets TM and TN , and a new SVM svmi is trained next in line 13 using these expanded training sets. Finally, in the last step within the iteration, in line 14, the new training examples from YM and YN are removed from the set WU of unclassified weight vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 2 :</head><label>2</label><figDesc>Seeded iterative SVM classification Input: -Set of weight vectors generated in comparison step: W -Seed training examples match set: WM -Seed training examples non-match set: WN -Increment percentage: ip -Total training percentage: tp Output: -Weight vectors classified as matches: ZM -Weight vectors classified as non-matches: ZN 1: TM := WM and TN := WN 2: WU := W \ (WM ∪ WN ) 3: svm0 := train svm(TM , TN ) 4: i := 0 5: while (|TM | + |TN |) &lt; (|W| * tp/100): 6: XM , XN := svm classif iy(svmi, WU ) 7: Sort XM and XN according to distance from svmi decision boundary (hyperplane) 8: YM := |XM | * (ip/100) vectors from XM furthest away from decision boundary 9: YN := |XN | * (ip/100) vectors from XN furthest away from decision boundary 10: TM := TM ∪ YM 11: TN := TN ∪ YN 12: i := i + 1 13: svmi := train svm(TM , TN ) 14: WU := WU \ (YM ∪ YN ) 15: end while 16: XM , XN := svm classif iy(svmi, WU ) 17: ZM := TM ∪ XM and ZN := TN ∪ XN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Weight vector histograms. Only one is shown for the synthetic data sets as they all are very similar.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Data sets used in experiments. See Section 4 for more details.</figDesc><table><row><cell>Data set</cell><cell>Number of</cell><cell>Task</cell><cell>Pairs</cell><cell cols="4">Reduction Number of weight Ratio r as in Equation (1)</cell></row><row><cell></cell><cell>records</cell><cell></cell><cell>completeness</cell><cell>ratio</cell><cell>vectors (i.e. |W|)</cell><cell cols="2">and true ratio from data</cell></row><row><cell>Census</cell><cell>449 + 392</cell><cell>Linkage</cell><cell>1.000</cell><cell>0.988</cell><cell>2,093</cell><cell>1 / 4.34</cell><cell>1 / 5.40</cell></row><row><cell>Restaurant</cell><cell>864</cell><cell>Deduplication</cell><cell>1.000</cell><cell>0.713</cell><cell>106,875</cell><cell>1 / 122.7</cell><cell>1 / 953.2</cell></row><row><cell>Cora</cell><cell>1,295</cell><cell>Deduplication</cell><cell>0.924</cell><cell>0.793</cell><cell>173,769</cell><cell>1 / 133.2</cell><cell>1 / 9.94</cell></row><row><cell>DS-Gen-A</cell><cell>1,000</cell><cell>Deduplication</cell><cell>0.957</cell><cell>0.995</cell><cell>2,475</cell><cell>1 / 1.48</cell><cell>1.13 / 1</cell></row><row><cell>DS-Gen-B</cell><cell>2,500</cell><cell>Deduplication</cell><cell>0.940</cell><cell>0.997</cell><cell>9,878</cell><cell>1 / 2.95</cell><cell>1 / 2.06</cell></row><row><cell>DS-Gen-C</cell><cell>5,000</cell><cell>Deduplication</cell><cell>0.953</cell><cell>0.997</cell><cell>35,491</cell><cell>1 / 6.10</cell><cell>1 / 4.48</cell></row><row><cell>DS-Gen-D</cell><cell>10,000</cell><cell>Deduplication</cell><cell>0.948</cell><cell>0.997</cell><cell>132,532</cell><cell>1 / 12.25</cell><cell>1 / 9.32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Quality of nearest-based seed training example selection as described in Section 3.1. Each pair of values shows the quality of WM / WN as percentage of correctly selected training examples. The seed size gives the percentage of weight vectors from W selected into WN .</figDesc><table><row><cell>Seed size</cell><cell>Census</cell><cell>Restaurant</cell><cell>Cora</cell><cell>DS-Gen-A</cell><cell>DS-Gen-B</cell><cell>DS-Gen-C</cell><cell>DS-Gen-D</cell></row><row><cell>1%</cell><cell cols="3">100%/100% 100%/100% 100%/96.8%</cell><cell cols="3">100%/100% 100%/99.0% 100%/100%</cell><cell>100%/100%</cell></row><row><cell>5%</cell><cell cols="7">100%/100% 100%/100% 100%/98.0% 100%/96.7% 100%/98.4% 100%/99.8% 100%/99.8%</cell></row><row><cell>10%</cell><cell cols="7">100%/100% 90.8%/100% 100%/97.6% 100%/95.5% 100%/98.3% 100%/99.5% 100%/99.7%</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGEMENTS</head><p>This work is supported by an Australian Research Council (ARC) Linkage Grant LP0453463 and partially funded by the New South Wales Department of Health, Sydney.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comparison of fast blocking methods for record linkage</title>
		<author>
			<persName><forename type="first">R</forename><surname>Baxter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Churches</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD&apos;03 workshop on Data Cleaning, Record Linkage and Object Consolidation</title>
		<meeting><address><addrLine>Washington DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="25" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Collective entity resolution in relational data</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive duplicate detection using learnable string similarity measures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD&apos;03</title>
		<meeting><address><addrLine>Washington DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">LIBSVM: A library for support vector machines. Manual</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/∼cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, National Taiwan University</orgName>
		</respStmt>
	</monogr>
	<note>Software available at</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic data generation for deduplication and data linkage</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IDEAL&apos;05</title>
		<meeting><address><addrLine>Brisbane</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3578</biblScope>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A two-step classification approach to unsupervised record linkage</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AusDM&apos;07, CRPIT</title>
		<meeting><address><addrLine>Gold Coast, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="111" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic training example selection for scalable unsupervised record linkage</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAKDD&apos;08</title>
		<meeting><address><addrLine>Osaka</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5012</biblScope>
			<biblScope unit="page" from="511" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Febrl -A freely available record linkage system with a graphical user interface</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HDKM&apos;08, CRPIT</title>
		<meeting><address><addrLine>Wollongong, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">80</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quality and complexity measures for data linkage and deduplication</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quality Measures in Data Mining</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Guillet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Hamilton</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Preparation of name and address data for record linkage using hidden Markov models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Churches</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed Central Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A comparison of string distance metrics for name-matching tasks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fienberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;03 workshop on Information Integration on the Web (IIWeb-03)</title>
		<meeting><address><addrLine>Acapulco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to match and cluster large high-dimensional data sets for data integration</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Richman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD&apos;02</title>
		<meeting><address><addrLine>Edmonton</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="475" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">TAILOR: A record linkage toolbox</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elfeky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Verykios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmagarmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE&apos;02</title>
		<meeting><address><addrLine>San Jose</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="17" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Duplicate record detection: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Verykios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A theory for record linkage</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fellegi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Society</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">328</biblScope>
			<biblScope unit="page" from="1183" to="1210" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards automated record linkage</title>
		<author>
			<persName><forename type="first">K</forename><surname>Goiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AusDM&apos;06, CRPIT</title>
		<meeting><address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="23" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Decision models for record linkage</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Selected Papers from AusDM</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3755</biblScope>
			<biblScope unit="page" from="146" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective counterterrorism and the limited role of predictive data mining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jonas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Policy Analysis</title>
		<imprint>
			<biblScope unit="issue">584</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Two approaches to handling noisy variation in text mining</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">Y</forename><surname>Nahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TextML&apos;02</title>
		<meeting><address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient nearest neighbor classification with data reduction and fast search algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Sotoca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Systems, Man and Cybernetics</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4757" to="4762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive deduplication using active learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhamidipaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD&apos;02</title>
		<meeting><address><addrLine>Edmonton</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="269" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning domain-independent string transformation weights for high accuracy object identification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tejada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Minton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD&apos;02</title>
		<meeting><address><addrLine>Edmonton</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="350" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Using the EM algorithm for weight computation in the Fellegi-Sunter model of record linkage</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Winkler</surname></persName>
		</author>
		<idno>RR2000/05</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>US Bureau of the Census</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Methods for evaluating and creating data quality</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Winkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Elsevier Information Systems</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="531" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Text classification from positive and unlabeled documents</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;03</title>
		<meeting><address><addrLine>New Orleans</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="232" to="239" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
