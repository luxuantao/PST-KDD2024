<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4352D94687FDA885390ABDA5E5BB795F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discontinuity Preserving Regularization of Inverse Visual Problems</head><p>Robert L. Stevenson, Member, ZEEE, Barbara E. Schmitz, and Edward J. Delp, Senior Member, ZEEE Abstruct-The method of Tikhonov regularization has been widely used to form well-posed inverse problems in low-level vision. The application of this technique usually results in a least squares approximation or a spline fitting of the parameter of interest. This is often adequate for estimating smooth parameter fields. However, when the parameter of interest has discontinuities the estimate formed by this technique will smooth over the discontinuities. Several techniques have been introduced to modify the regularization process to incorporate discontinuities. Many of these approaches however, will themselves be ill-posed or ill-conditioned.</p><p>This paper presents a technique for incorporating discontinuities into the reconstruction problem while maintaining a well-posed and well-conditioned problem statement.</p><p>The resulting computational problem is a convex functional minimization problem. This method will be compared to previous approaches and examples will be presented for the problems of reconstructing curves and surfaces with discontinuities and for estimating image data. Computational issues arising in both analog and digital implementations will also be discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>N THIS PAPER we address the problem of estimating a I discontinuous parameter field, r from sparse and noisy data S. We are interested in techniques that are capable of reliably estimating the parameter field given the fact that there are discontinuities in the parameter field, or in one or more of the derivatives of the parameter field. Such estimation problems naturally arise in many low-level computer vision problems <ref type="bibr" target="#b33">[34]</ref>. For the problem of visual surface reconstruction, the sparse data is obtained from such low-level vision processes as shape-from-stereo, shape-from-shading, etc. <ref type="bibr" target="#b33">[34]</ref>. From this data we wish to estimate the surface depth over a dense mesh of grid points. The surface depth will have depth discontinuities at the edges of objects and will have discontinuities in the first derivative at the comers of objects. In the problem of estimating the optical-flow field of a sequence of images we wish to estimate the two-dimensional vector field of object motion. This vector field will be discontinuous on the boundary of objects moving in front of a static background.</p><p>The basis of many classical parameter estimation schemes is the assumption that the parameter field varies smoothly <ref type="bibr" target="#b33">[34]</ref>. Therefore, these classical techniques are not appropriate for estimating the piecewise smooth parameter fields that arise in Manuscript received <ref type="bibr">March 13, 1992</ref>; revised April 6, 1993. R. L. <ref type="bibr">Stevenson</ref>  low-level vision problems, although they are still often used.</p><p>In order to form reliable estimates we must incorporate the a priori knowledge that the parameter fields of interest may have discontinuities. The regularizing technique proposed by Tikhonov introduces a priori information into the problem statement through the use of a stabilizing functional. The stabilizing functional measures the consistency of a particular field r* with the a priori assumptions relative to the form of the field. Therefore, one of the important issues to address is an appropriate form for the stabilizing functional. The Tikhonov regularization technique uses the stabilizing functional to form a functional minimization problem, which is then solved to form the estimated parameter field. If the chosen stabilizing functional is nonconvex, then the resulting computational problem of minimizing a nonconvex functional is itself an ill-posed problem. The nonconvex minimization problem is ill-posed because the solution will no longer vary continuously with a change of the input; i.e., a small change in the input can result in a drastic difference in the output. Because of this ill-posedness the stability of the output may also be affected by the implementation and by quantization noise. Another problem is that although techniques to exist for minimizing such functionals the computational complexity of these algorithms is very high. Thus when considering a possible stabilizing functional it is important to examine the resulting minimization problem in terms of both its stability and computational requirements. For this reason a convex stabilizing functional is highly desirable.</p><p>Early approaches to dealing with discontinuities proposed various nonconvex stabilizing functionals and novel methods for dealing with the resulting computational problems <ref type="bibr" target="#b12">[4]</ref>, [l 11,  [121, [261, [271, [30], <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b38">[39]</ref>. Unfortunately, the resulting algorithms are ill-posed and yield unstable results. This paper examines a class of convex stabilizing functionals which yield desirable results when the parameter fields or their derivatives have discontinuities. Section I1 introduces the necessary background from regularization theory that is needed. Section 111 discusses several previous approaches to defining a stabilizing functional which incorporates the a priori knowledge of the existence of discontinuities and characterizes the problems of such algorithms. Section IV introduces a class of convex stabilizing functionals that are useful and characterizes the form of the resulting estimates. Section V discusses some of the computational aspects of minimizing these convex but nonquadratic functionals. Section VI compares the convex regularization kemels with previously proposed nonconvex regularization kernels. It is shown that better reconstructions 0018-9472/94$04.00 0 1994 IEEE can be obtained with the convex stabilizers in terms of mean absolute and mean squared errors. Computational comparisons and reconstructions using real data are also addressed. Finally Section VII draws some conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. REGULARIZATION THEORY</head><p>Low-level image analysis problems, because of their inherent structure, are generally inverse problems and like most physical inverse problems the mathematical formulation of the problem statement is ill-posed [l], <ref type="bibr" target="#b32">[33]</ref>. The general inverse problem can be stated by the following: find the parameter field r from the observed finite collection of data S = { G } + ~. For the problem to be well-posed in the sense of Hadamard [14] the solution must exist, be unique, and depend continuously on the data, In image analysis problems the observed data S is generally sparse andor noisy and will not uniquely determine a solution r, hence the problem is ill-posed <ref type="bibr" target="#b33">[34]</ref>.</p><p>To obtain a unique and stable solution from the data, supplementary information must be used so that the problem becomes well-posed <ref type="bibr" target="#b52">[52]</ref>, <ref type="bibr" target="#b53">[53]</ref>. The basic principle common to all methods to use a priori knowledge of the properties of the inverse problem to resolve conflicts in the estimates, and to restrict the space of possible solutions so that the data uniquely determine a stable estimate. Two techniques that are often used to form a well-posed problem for many ill-posed inverse problems are the methods of Tikhonov regularization [52], <ref type="bibr" target="#b53">[53]</ref> and stochastic regularization [29], <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. likhonov Regularization</head><p>To make the problem well-posed, a continuous operator, known as a regularizing operator, is defined which approximates the inverse operator. To construct a regularizing operator, R(., .), Tikhonov and Arsenin <ref type="bibr" target="#b52">[52]</ref> introduce a stabilizing functional, R <ref type="bibr">[ +]</ref> . This stabilizing functional provides a measure of the consistency of a particular solution based on the apriori assumptions. The stabilizing functional is used to define the functional</p><formula xml:id="formula_0">M'[~*,s] = n[r*] + Xil\Ar* -till<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C,ES</head><p>where )I 11 is a norm and denotes the process of acquiring the ith data point and is assumed to be linear. This norm measures the distance between a possible solution and the observed data. This term will be large for solutions that are not near the observed data. Let X denote the collection of {&amp;}El. Then, for certain values of A, the minimization of this functional is a regularizing operator,</p><formula xml:id="formula_1">rx = R ( S , X ) = argminM'[r*,S].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>r'</head><p>This regularized solution, r', will be used as the solution estimate which will be denoted as e. Note that the regularizing operator for a particular problem is in general not unique; there may exist many operators which stabilize the ill-posed problem. The choice of the particular operator and the value of the regularization parameter X is based on supplementary information pertaining to the problem.</p><p>In summary, to find a regularized solution to an ill-posed problem, a stabilizing functional, Cl[-], must be specified based on a priori information. Then an appropriate X must be found such that the minimization of M'[r*, SI is a regularizing operator. The choice of X will be based on the choice of the stabilizer, the chosen norm, and supplementary information pertaining to noise in the data. Once this information is obtained, the regularized solution, r', to the ill-posed problem is determined by minimizing the functional M A [r*, S I The hardest task is to find a stabilizer which not only yields a unique and stable solution to the inverse problem, but also accurately measures the consistency of the estimate with respect to the true solution.</p><p>If a[-] is chosen so that it is quadratic then it can be shown that the solution space is convex and a unique solution exists <ref type="bibr" target="#b52">[52]</ref>. Most applications will therefore define 0[.] to be some norm or semi-norm on the solution space. When this is not the case then the functional may be nonconvex. This makes finding the optimal solution more difficult and ill-posed since there may exist many suboptimal local minimum.</p><p>For univariate regularization of scalar functions, Tikhonov proposed a general stabilizer based on the mth-order weighted Sobolev norm. Letflx) be some scalar univariate function, then a general stabilizing functional can be written as where the wp(x)'s are nonegative and possibly discontinuous weighting functions <ref type="bibr" target="#b52">[52]</ref> and m determines the degree of smoothing. Using such a stabilizer makes the problem wellposed by restricting the space of admissible solutions to the Sobolev space of smooth functions. For multivariate vectorvalued functions Tikhonov's suggestion can be generalized for the n-dimensional case to where p = (p1,p2,..-,pn), IP( = PI + p z + . * * + p n and x = ( X I , 22, . , xn). This multivariate weighted Sobolev norm is the basis on many of the stabilizing norms used in low-level image analysis <ref type="bibr" target="#b33">[34]</ref>. Stabilizing functionals of this form measure function smoothness will be lead to algorithms which smooth discontinuities. This functional is also quadratic, thus applications which utilize such stabilizers result in convex optimization problems. In this paper we will examine a more general stabilizing functional with the form where p(.) is some scalar function. In this paper we will be examining several possible functions which can be used for p ( -) . We will show that p ( . ) can be chosen so that the resulting regularizing functional has the two desirable properties of being convex and allowing discontinuities. Conditions for a stabilizer of the form <ref type="bibr" target="#b13">(5)</ref> to be convex are given by the following theorem (the proof is in the Appendix).</p><p>Theorem 1: The stabilizer in equation ( <ref type="formula">5</ref>) is convex if and only if the scalar function p ( . ) is convex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Stochastic Regularization</head><p>The stochastic solution to ill-posed problems is a straight forward application of Bayesian estimation [ 1 I]. The Tikhonov method makes the problem well-posed by restricting the space of possible solutions to a dense subspace so that a stable and unique solution can be found. The manner in which this restriction is made is based on apriori information. In contrast, a stochastic approach use a priori information relative to the likelihood of a function, r*, being a solution to define a probability distribution, Pr* . A priori information about the observation noise process is used to determine a conditional probability distribution, Using these distributions, the posterior probability distributions can be obtained by which represents the likelihood of a solution, r*, given that the data, S, was observed. An estimate, r, can then be found with either a MAP estimator or by defining a loss functional and computing a Bayesian estimate. The MAP estimate is found by simply maximizing the probability distribution <ref type="bibr" target="#b14">(6)</ref> or the log of the distribution to find the function, e, which is the most likely solution given the data, S, i.e., i. = argmax[ln r* PSI.* +In Pr*]. <ref type="bibr" target="#b15">(7)</ref> In summary, to make the problem well-posed, a probabilistic model on the space of possible solutions must be specified based on a priori information. The quality of the solution will depend largely on the quality of the model chosen; thus it is critical that the model accurately reflect the true space of surfaces. The estimated solution is then found by maximizing (or minimizing) a functional. If the measurement process is modeled as having additive Gaussian noise then where X i = 1/20? and g' is the variance associated with the ith data point. By choosing a prior with the form p,. E x ,-n[r*l <ref type="bibr" target="#b17">(9)</ref> the techniques of Tikhonov and stochastic regularization results in the same functional minimization problem. Using the Sobolev seminorm, (4), for n[.] and by making appropriate discrete approximations, this can be shown to be equivalent to assuming a Markov Random Field (MRF) model for the prior 1471, 1481, where the order of the derivative is equivalent to the order of the MRF. This connection can be used to examine Tikhonov regularization in the context of a probability space P31.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">MODIFICATIONS TO THE STABILIZING FUNCTIONALS TO INCORPORATE DISCONTINUITIES</head><p>In order to incorporate the a priori knowledge that discontinuities exist into the reconstruction process we either examine modifications of the stabilizing function in Tikhonov regularization or the prior distribution function in stochastic regularization. In this section we examine several previously proposed modifications to these functions and the resulting characteristics of the reconstruction algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Controlled-Continuity Stabilizers</head><p>If the location and type of discontinuity is known, this information can be easily incorporated into the stabilizing functional through the use of the weight terms, wp(z), in the Sobolev seminorm, (4). For an mth order discontinuity (m = 0 is a jump discontinuity, m = 1 is a discontinuity in the first derivative, etc.) that occurs at the location (x'), set wp(x') = 0 , for J p J 2 m and for all other locations set the weight term to one. This controls the order of the continuity at discontinuities <ref type="bibr" target="#b49">[49]</ref>- <ref type="bibr" target="#b51">[51]</ref>. When used in this fashion, the weight term, wp(x), is referred to as a line process since it indicates where lines (Le., edges) exist in the parameter field. The weight term can also be used for other things such as estimating parameter fields which are rotationally invariant 1401, <ref type="bibr" target="#b42">[43]</ref>, 1441. Since the knowledge of the location and type of discontinuity is rarely known in most applications, the weight term cannot usually be set prior to computing the estimate. Therefore, the weighting function must also be estimated. Approaches based on estimating the weighting function and the reconstructed parameter field separately have been proposed 1131, <ref type="bibr">[181,[251, [261, 1371, 1381, 1391</ref> as well as approaches based on estimating both the weight function and the parameter field together <ref type="bibr" target="#b10">[2]</ref>- <ref type="bibr" target="#b13">[5]</ref>, [51].</p><p>The techniques proposed in <ref type="bibr" target="#b21">[13]</ref>, <ref type="bibr" target="#b1">[18]</ref>, <ref type="bibr" target="#b8">[25]</ref>, and <ref type="bibr" target="#b25">[26]</ref> make hard decisions about the value of the weight function, Le., wp is set either to 1 or 0. This preprocessing step is essentially performing discontinuity detection on sometimes sparse and noisy data. Since this type of preprocessing requires a decision, these techniques will be prone to unstable reconstructions. This occurs since small perturbations of the data when the decision parameter is near the threshold can result in a different decision being made, and consequently a drastically different parameter field being estimated. A slightly more robust technique was proposed by Sinha and Schunck <ref type="bibr" target="#b36">[37]</ref>- <ref type="bibr" target="#b38">[39]</ref>. Their method allowed the weighting function to take on any value greater than 0. They perform an initial fit without any discontinuities and then set the weight term to be inversely proportional to the first derivative of the initial estimate. This has the effect of creating a region where the weight term is small near discontinuities and large in regions where the parameter field is smooth. This type of soft decisionmaking will result in a more stable estimate than making a hard decision. The tradeoff is that near discontinuities, where the weight term is small, the noise removal properties of the spline fitting will be defeated. That is, the estimating procedure will produce noisy estimates of the parameter field near the discontinuities. To overcome this problem they introduce another parameter which can be used to make the decision harder, i.e., to make the region where the weight term is near zero smaller. Of course, making a harder decision will result in a more unstable estimate.</p><p>To form estimates for wp(x) in conjugation with r(x) we cannot simply minimize (1) with respect to wp and r(x) when using the Sobolev seminorm, (4). Doing this would result in the trivial solution wp(x) = 0 and r(x) being only uniquely determined at points where these are constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Estimating the Line Process</head><p>In order to estimate wp(x) in conjugation with r(x) we need to augment our prior information with some knowledge about the form of wp(x) <ref type="bibr" target="#b51">[51]</ref>. This can be done by adding a term to a <ref type="bibr">[.]</ref> which measures the consistency of a given wp(x) <ref type="bibr" target="#b51">[51]</ref>. That is we minimize a functional of the form The functional E ( . , .) will have a form such as in (4) and I)(.)</p><p>will measure the consistency of the line process. Unfortunately even for simple D(.) the functional minimization problem becomes nonconvex. This is a problem not only because of the increased computation required for a solution but also because the mathematical problem is no longer well-posed.</p><p>Blake and Zisserman proposed a I)(.) which counted the number of discontinuities for a particular wP(x) and used a stabilizer of the norm of (4) for E(., e). They showed that this was equivalent to a using standard Tikhonov regularizing functional with a stabilizer of the form of (5) with wp(x) = l , V x and p ( -) of the form (see Fig. <ref type="figure">l(a)</ref>)</p><p>This choice for the regularization function will be referred to as the neighborhood interaction function. This choice for p(.) For this stabilizer notice that once a threshold is exceeded this term exerts no further influence on the solution. Similar schemes for estimating he line process were proposed by Geman and Geman [ll] and by Marroquin [29], <ref type="bibr" target="#b29">[30]</ref>. Their approach also results in a nonconvex and ill-posed functional minimization problems. Several novel techniques have been proposed to overcome some of the computational complexity associated with such an approach [lo], <ref type="bibr" target="#b4">[21]</ref>. While the accuracy of signal estimators based on nonconvex optimization may be adequate, the stability of such an approach will be poor. Small noise in the data can dramatically change the result. Even for the same input data and the same functional to minimize, different optimization algorithms can compute very different results. This will be shown in Section VI-B.</p><formula xml:id="formula_2">is</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">T T *</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONVEX AND STABLE APPROACHES</head><p>As was discussed in the last section, in order for the regularization problem to be well-posed the stabilizing function must be convex. The question then becomes can a convex stabilizing functional be devised such that discontinuities in the parameter field can be accurately reconstructed. In this section we will examine using a stabilizer functional of the form of (5) with some convex p(-). The weight terms will be set to some constant value throughout the entire field, that is wp(x) = wp. Since the class of convex functional is very large, we will begin by first discussing other desirable characteristics (besides convexity) which are desirable for the functional p(.).</p><p>Besides being convex the functional should be symmetric since the sign of a particular term should not change the importance of its magnitude. The most important characteristic of course is that discontinuities should be allowed to form. In the previous section the weight term, wp, was used to allow discontinuities, the weight was changed to deemphasize regions where the derivative is large (i.e., regions of discontinuities). Regions of discontinuities can also be deemphasized by modifying p(.) so that it is less than the squared term, i.e., p(z) &lt; z2 for large values of z. Finally, we would like a parameter, T, which controls the degree of smoothness of the reconstruction, we will denote the parameterization of p(.) by p T ( -) . That is, as a parameter T varies from some Tl to T2, the estimated parameter field varies from a smooth reconstruction to a reconstruction that allows more discontinuities. Mathematically this is equivalent to the condition that pT ( ) decreases monotonically as T varies from T I , to T2 for all z. To better understand this condition recall that the stabilizer a[.] measures the consistency of a particular function with our a priori information. If we want a parameter which controls the degree to which discontinuities are allowed (or conversely the degree of smoothness imposed), then for any particular function rl(x) if the parameter T is varied to allow more discontinuities then the consistency measure should decrease. If the pT (.) functional does not decrease monotonically as T is varied then it is easy to devise a function for which the consistency measure will increase as the degree of allowed discontinuities is increased. The desirable properties of p T ( . ) can be summarized 2) symmetric, p T ( x ) = pT(-x),</p><p>3) allows regions of discontinuities, p T ( x ) &lt; x 2 , for 1x1 4) has a parameter which can consistently vary the degree of discontinuities allowed, pT (x) decreases monotonically for all x as a function of T .</p><p>To examine some of the characteristics of the functionals that we are going to discuss, we will apply this technique to the problem of approximating piecewise smooth curves from noisy data. The curves will be estimated on a grid on 100 points. There is a discontinuity in the curve near grid point 23, a discontinuity in the first derivative of the curve near grid point 50, and the curve varies smoothly in the region between 55 and 100. Two sets of data will be examined, a set of noisy dense data, Fig. <ref type="figure">2</ref>(a), and a set of noisy sparse data, Fig. <ref type="figure">2(b</ref>). The dense data was obtained by sampling at every point and adding Gaussian noise with standard deviation of 0.02. To obtain the sparse data the curve was sampled at every fifth location and Gaussian noise with standard deviation of 0.02 was added to the signal. Let y(x) denote the curve we wish to estimate, then the acquisition process can be modeled by d;g(z) = y(x;). The Stabilizer used in the reconstruction is</p><formula xml:id="formula_3">x , y E R , a E [O, 11, large, x E R,</formula><p>In this paper we will examine the class of convex stabilizers which can be characterized by the functional (see Fig. <ref type="figure">3</ref>) where p , q 2 1, and generally q 5 p. This choice is based on varying the degree of smoothness imposed at different scales. Below some threshold T one weighting function is used while above that threshold a weighting function that increases less rapidly (Le., less smoothness imposed) is used. By choosing /I 1 T X 1 p &gt; q we smooth small scale noise while retaining large scale discontinuities in the parameter field. The constants in (14) are chosen so that the weight function is convex and continuous and so that the influence function is continuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. A Scale-Invariant Stabilizer</head><p>Bouman and Sauer <ref type="bibr" target="#b14">[6]</ref>, <ref type="bibr" target="#b15">[7]</ref> and Harris <ref type="bibr" target="#b4">[21]</ref> examine the case where 1.0 5 p 5 2.0 and T = m, which is the special case of (14) when</p><formula xml:id="formula_4">P ; ( 4 = 1zIP. (<label>15</label></formula><formula xml:id="formula_5">)</formula><p>This form of the regularization kernel will be referred to as the generalized absolute form. When p = 2.0 the regularizing functional will be the standard Tikhonov regularizer with a quadratic stabilizer and thus estimate smooth parameter fields. For p = 1.0 the corresponding estimator is the sample median and will allow discontinuities. To control the degree that discontinuities are allowed they used the parameter p .</p><p>This choice for &amp;(.) satisfies the first three of our desirable characteristics but not the fourth. Therefore this choice for a stabilizing functional will not allow consistent adjustment of the degree that discontinuities will be allowed. This inconsistency can be shown when estimating the curve given the dense data set. Figure <ref type="figure">4</ref>(a) shows the dense data set curves reconstructed with p = 2.0, 1.6, and 1.2. Notice that the curve estimated with p = 1.6 is visibly smoother than the curve estimated with p = 2.0. When the data is sparse the estimate formed with this stabilizer also appears to be very sensitive to the selection of the discontinuity parameter. Figure <ref type="figure">4</ref>(b) shows the curves reconstructed from the sparse data. Notice the drastic difference in the estimate when the discontinuity parameter is adjusted by less than 0.001%. This occurs because it is not possible with the single parameter to provide sufficient smoothness necessary for interpolation while retaining discontinuities in the estimate. In the application in which Bouman and Sauer are interested, the data is dense and they chose the discontinuity parameter to be between 1.0 and 1.2. In this case we computed satisfactory estimates of the curve. Thus, while in general this may not be a good stabilizer, in some applications it may work satisfactorily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Huber Minimax Functional</head><p>The second special case that we will examine was motivated by work done by Huber in robust statistics <ref type="bibr" target="#b2">[19]</ref>, <ref type="bibr" target="#b3">[20]</ref>. He was interested in computing smooth estimates when outliers existed in the data set. He proposed to weight the outliers in the data with a functional of the form where T varies from +oo to 0. This is the special case for when p = 2.0 and q = 1.0. This function varies as a square for values below the threshold and it varies linearly above the threshold. Thus small scale noise is smoothed with a least squares smoother while large scale discontinuities are weighted less by the linear part of the functional. For T = oo we get a smooth estimate and as T approaches zero more discontinuous regions are allewed. This functional has been applied by <ref type="bibr">Stevenson and</ref> Delp to the problems of curve <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> and surface <ref type="bibr" target="#b44">[45]</ref> reconstruction and by Shulman and Herve <ref type="bibr" target="#b35">[36]</ref> for the problem of estimating discontinuous optical flow fields. Using the dense data set the set of curves in Fig. <ref type="figure">5(a)</ref> were estimated with this stabilizer. The curves reconstructed from the sparse data set are given in Fig. <ref type="figure">5(b)</ref>. Notice that in both cases the curves are estimated with increasing degrees of discontinuity as the parameter T is varied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. General Case</head><p>There is of course an infinite number of variations on the choice of p and q that can be examined. The correct choice will depend on the particular application and the a priori information that is known. If a good quality reconstruction is available or can be modeled, then p and q can be chosen sta-tistically by fitting the statistical model in (9) to the available reconstruction. In most cases p should be chosen to be near 2.0 to provide least squares type smoothing of the noise and q chosen to be around 1.0 to reconstruct the discontinuities as sharply as possible with a convex stabilizer. The threshold T will depend on the scale at which discontinuities are present. Since there is a smooth transition in the weight function at the threshold, the quality of the estimate is not very sensitive to the selection of T and the smaller the quantity Ipq( is the less sensitive the estimate will be to this parameter. written as a matrix multiplication, that is, where the matrix Ai,p depends on the location in the mesh and the order of the discontinuity. Most of the terms in A i , p are zero, the only nonzero terms being given by the difference equation which approximate the derivatives, e.g., (17), <ref type="bibr" target="#b1">(18)</ref>, and (1 9). Using these approximations the generalized stabilizer function <ref type="bibr" target="#b13">( 5 )</ref>   technique for estimating parameter fields with discontinuities. The technique results in a convex but nonquadratic fUnCtional minimization problem. This section examines several computational issues of the resulting mathematical problem statement. The mathematical problem will first be discretized, Since the acquisition process, ~~~( ~1 , the assumed to be linear, the process can be also written as a matrix multiplication, which we will write as .Aird. The resulting discrete regularization functional can be written as then both digital and analog computational techniques will be</p><formula xml:id="formula_6">N N</formula><p>examined. m i ( r d , s ) = . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P(WpAi,prd) I p l &lt; m i l = l i , = l</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Discrete Problem Statement</head><p>The finite element method is utilized to discretize the continuous mathematical problem. The function to be estimated, r(x), is discretized on a regular fine-grid mesh. That is r(x) is sampled uniformly along each of its variables. Assume that N samples are taken along each of the variables. This sampling process results in a finite set of nodal variables which will be represented by .(xi) where xi represents the indexed vector quantity ( ~1 , ~~ ~ ~2 . ~~.</p><p>. . , x , , , ~) and each of the indices, z, vary in the range of 1 to N . Using a triangular conforming element for the first order terms gives the discrete approximation to a first order derivative as -t-</p><formula xml:id="formula_7">X i l l d i r d -Ci1l2 (22) cp E S</formula><p>where p ( . ) wp, Ai,p, 11 . 11, X and A are based on our a priori information about the application and S is the collection of data. To form the discrete parameter field estimate, this functional is minimized with respect to the nodal variables r d .</p><p>In the next two subsections, we will examine both digital and analog techniques for minimizing this discrete functional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Digital Descent Methods</head><p>The most prevalent class of algorithms for digital convex functional minimization are based on iterative techniques,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>dr(xi) -</head><p>where the update at each iteration monotonically decreases the functional value. Let r$ denote the function value at the i3r"</p><p>r ( q 2 , 1 ' ' . 9 TJ,Z,+l% . ' . <ref type="figure">G,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">)</ref> " J (17) lcth iteration. At each iteration the function is updated by r ( q z l 3 . . . , J j , 1 7 , . . . rn.zn ).</p><p>For higher order terms a nonconforming rectangular element can be used. For example for a second order terms the discrete approximation is and r$+l = r: + a'pk <ref type="bibr" target="#b6">(23)</ref> where the vector p k is the direction of the update and the scalar ak determines the size of the step taken in the direction. Since our function is convex any of the descent based methods will converge to the optimal solution given any starting vector rz. However overall computational time will depend on the initial guess rz, and the scheme for choosing the update vector p k and step size a'. For a particular application computational time can be dramatically reduced if there exists some quick technique for forming an rough estimate to be used as the initial guess [16], [MI. For example, in the curve reconstruction problem an initial estimate can be formed quickly by fitting a piecewise linear estimate to the data. Similarly, for the surface reconstruction problem a piecewise planar surface can provide an initial guess. Forming this initial estimate is especially helpful when the data is sparse. In applications where the data is sparse and when it is not possible to quickly form an initial estimate, multigrid techniques can be used to improve the computational time <ref type="bibr">[17]</ref>.</p><p>There are many methods for choosing the update vector pk, the conceptually simplest minimization methods choose pk from among the coordinate vectors e l , . . . , e ". This results in univariate relaxation where at each iteration only one component of r$ changes. Another intuitive choice for the update vector is the direction of steepest descent, that is the direction for which the functional will decrease the fastest. The direction of steepest descent is the direction for which takes on its minimum value as a function of p. If the Z2-norm is used for I I . I I then the direction of steepest descent will be the negative of the gradient vector, i.e., pk = -vM,X[~',SS]. <ref type="bibr" target="#b8">(25)</ref> The choices for pk discussed thus far are not guaranteed to converge to a solution in a fixed number of iterations. For linear systems of equations (quadratic optimization problems) the conjugate gradient method has been shown to converge in a bounded number of steps <ref type="bibr" target="#b23">[15]</ref>. This minimization method computes a conjugate basis for the linear systems which are used for the update vectors. With this choice for the update vectors, the iterative process can be shown to converge in one cycle through the basis set. For nonquadratic functional optimization problems, conjugate gradient algorithms have been proposed by Daniel [SI and Fletcher and Reeves <ref type="bibr" target="#b17">[9]</ref>.</p><p>Once an update vector is chosen, the next step is to compute the size of the step, a k , which will be taken in that direction. The maximal decrease for a given pk occurs when ak is chosen so as to minimize the functional along that direction, ak = argminM,X[r; + a p ' , ~] .</p><formula xml:id="formula_8">a E R</formula><p>This results in a univariate nonquadratic minimization problem. In many applications, including the examples presented here, this one-dimensional minimization problem can be approximated by minimization of the osculating parabola.</p><p>In this case ak is well-defined and given by For the applications presented in the previous section, the solutions were computed by first approximating the solution with a piecewise linear approximation, then by using the steepest descent criterion for the update vector and by computing the step size by minimizing the osculating parabola. One of the advantages of these methods is in the inherent parallelism associated with these algorithms. This can be exploited by a mesh of computational nodes which can greatly reduce the total computational times <ref type="bibr" target="#b46">[46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analog Computational Networks</head><p>Variational principles, such as the functional minimization problem arising from regularization theory, have also been solved using analog networks. These networks can be either chemical, electrical or mechanical. This section examines solving the discontinuity preserving regularization functional that has been studied in this paper using analog electrical networks. The class of variational principles which can be solved by an analog electrical network is dictated by Tellegen's Theorem <ref type="bibr" target="#b31">[32]</ref>. Basically the properties of convexity and wellposedness will ensure that the resulting network will compute the correct solution. For quadratic variational principles the resulting analog network can be made with linear components, however, for the nonquadratic variational principles presented here the resulting networks will have nonlinear components.</p><p>To ease the notational jumble we will only study the construction of a network which will solve the curve reconstruction problem discussed in Section IV. Extensions to other applications should be clear. For curve reconstruction the resulting continuous variational principle is c,ES By taking the derivative of this functional with respect to ~(zi) and setting the equation to zero, the following N nonlinear equations are obtained:</p><formula xml:id="formula_9">0 = $(Y(Zi+2) -2Y(Zi+l) + Y ( Z i ) ) -2.lll(Y(G+l) -2Y(Zi) + Y(G-1)) + $(Y(G) -2Y(Zi-l) + Y b i -2 ) ) + $J(Y(Zi) -Y(Zi-1)) -$J(Y(Xi+l) -Y($i)) + 2Xi(Y(Zi) -ci)2 (31)</formula><p>where the last term is only present if there exists a constraint on the value of ~( x c ; ) .</p><p>The equations at the boundaries are slightly different. Now examine the network in Fig. <ref type="figure">6</ref>. The two terminal passive device, c, and the three terminal device, A, can be characterized by their voltage-current relationship as given in Fig. <ref type="figure">7</ref>. For this network, we can write the following N equations at each node using Kirchhoff s current law:</p><formula xml:id="formula_10">1 0 = R{$J(Yi+2 -2Yi+l + Yi) -2$J(Yi+l -2% + Yi-1) 2xi -$J(Yi+1 -Yi)} + R ( Y i -C d 2 .</formula><p>This has the same form as <ref type="bibr" target="#b30">(31)</ref>, therefore by exciting the network with the constraint controlled voltage sources, the node voltages, y1, yz, . . . , Y N , will represent the solution to the variational principle. Theoretically this solution will be obtained instantaneously, however capacitance in any real implementation will cause transients when the constraints are applied. One the network has settled, the solution to the variational principle can be obtained by measuring the node voltages.</p><p>The passive elements E and A depend on the form of $(.)</p><p>that is being implemented. The case of a quadratic functional minimization problem, where $( .) is linear, has been examined</p><p>[22], <ref type="bibr" target="#b7">[24]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, and at least one working VLSI chip has been designed and tested <ref type="bibr">[22]</ref>. Analog networks have also been proposed for solving some of the nonconvex functionals that arise when incorporating discontinuities information via the methods discussed in Section III [22], <ref type="bibr" target="#b55">[55]</ref>. Figure <ref type="figure">8</ref> shows the passive devices which can be used to solve the quadratic variational principle. These devices can be modified to be nonlinear through the use of nonlinear devices such as diodes, zener diodes and through the used of active devices such as operational amplifiers <ref type="bibr" target="#b4">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. COMPARISONS AND EXAMPLES</head><p>This section will compare the three main regularization kernels described in this paper, the neighborhood interaction form, the generalized absolute form, and the Huber minimax form. The non-discontinuity preserving quadratic form will also be included in the comparisons to provide a base for comparison. The Huber minimax, generalized absolute and quadratic forms are convex and the digital computational techniques described in the previous section are used for computing the signal estimate. For the neighborhood interaction function a continuation method is used to form the estimate <ref type="bibr" target="#b12">[4]</ref>. The technique uses a family of p ( . ) varying from a convex form to the final nonconvex form. For each member of the family a steepest descent technique is used to reach a local minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Reconstruction Quality</head><p>In order to fairly compare the possible reconstruction quality fairly a good set of parameters ( T , p , q , A ) needs to be computed for each regularization kernel. For some of the models some these parameters are specified (e.g., for the Huber based model p = 2, q = 1). Cross-validation [54] is a standard technique and was used to pick the value of A. Crossvalidation, however, is not a good technique for picking the discontinuity-preserving parameter, T. It always tends to favor using a value of T which makes the p function quadratic. This is not surprising since it uses an error criterion based on the mean squared error. A more useful heuristic is to select a value of T which will not cause significant overshoot or undershoot at discontinuity boundaries. This was done by selecting a T for which the combination of both overshoot and understood was less than 5% of the discontinuity height. Once T was selected, A was chosen using cross-validation [%I. The values for T and A for the models of interest are given in Table <ref type="table" target="#tab_1">I</ref>.</p><p>In order to compare reconstruction qualities both the mean absolute error (MAE) and the mean squared error (MSE) will be computed for each reconstruction. A synthetic data set was created with both smooth regions and regions containing discontinuities.Various amounts of noise was added to this known signal and reconstructions were formed using the different reconstruction kernels. The reconstructions were compared with the original data and the MAE and MSE were computed. The MAE and MSE were averaged for over 200 different noise contaminations. The formulas for these error metrics are given by <ref type="bibr" target="#b32">(33)</ref> The results are shown in Table <ref type="table" target="#tab_1">II</ref>.</p><p>Due to the presence of discontinuities in the signal the quadratic signal model performs the worse, as expected. The discontinuity-preserving models all do better then the quadratic, with the Huber model performing the best overall. It should be noted that for some of the individual data sets, both the neighborhood interaction function and the generalized absolute did perform better. This indicates that while all of the discontinuity-preserving signal models are capable of computing high quality reconstructions, the Huber based function will on average perform better. This is due primarily to the robustness of the signal estimate with respection to the selection of the model parameters (T,p, q, A) for the Huber model. Small changes in the model parameters for both the neighborhood interaction function and the generalized absolute can cause large changes in the quality of the reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Stability Issues</head><p>Another issue to be considered when choosing a good regularizer is the stability of the estimator. An estimator for which the reconstruction changes dramatically with small changes in the input signal provides unreliable signal estimates. In Section IV-A. the generalized absolute was shown to compute unstable signal estimates in terms of the regularizer parameters. Small changes in the p parameter can cause large changes in the output estimate in the case of sparse constraints. Note however that small changes in the input constraints will not cause this behavior, that is it stable with respect to the signal noise. This is also true for the entire class of convex stabilizers since small changes in the constraint set does not effect the location of the functional minimum significantly. For nonconvex stabilizers the output of the estimator can change with small changes in the input signal. This was shown by <ref type="bibr" target="#b27">[28]</ref> and can be demonstrated with the following simple example. Consider the noisy signal sets in Fig. <ref type="figure">9</ref>. One data set is marked with x and the second is marked with 0. Notice that the two data sets are identical except for the 63rd data point which is different by about only 15%. The signal reconstructions for the two data sets using the neighborhood interaction function is shown in Fig. <ref type="figure">10</ref>. Notice that both the syntactical and statistical properties of the output signal changes significantly. The edge location is no longer clearly defined and the obtained reconstruction is much smoother. Such instability is a very undesirable property of the entire class of nonconvex stabilizers. For any of the convex stabilizers, the difference between the reconstructions for two such similar data sets is very small. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Computational Comparison</head><p>An issue that should not be neglected when comparing reconstruction techniques is computation time. It is the goal of many image processing systems to operate in real time which puts the limits on the computational complexity of any of the parts of these systems. The time needed to reconstruct a set of constraints using a given signal model varies depending both on the parameters used and the level of sparsity of the data constraints. Table <ref type="table" target="#tab_1">I11</ref> shows the average computation time for the four main types of regularization kernels considered in this paper. The averages where computed for over 600 curve reconstruction examples where the sparsity of the data points varied from 10% to 100%.</p><p>The quadratic regularizing function offers the faster performance, but of course does not preserve discontinuities. The Huber function cost only slightly more since the main difference from the quadratic function is an extra comparison operation, which can be performed very quickly. The generalized absolute function takes much longer to reach the minimum since the operation of raising a term to a fractional power is a very computationally expensive operation. For the neighborhood interaction function, while the function costs about the same to evaluate as the Huber form, the number of iterations to reach convergence is much longer since it is necessary to minimize each functional in a family of functionals.</p><p>Of the discontinuity-preserving regularizing functions the Huber functions does by far the best in terms of computational complexity. This is due to a combination of it being a convex functional and thus generally requiring fewer iterations to reach the minimum and because each evaluation of the Huber function is a computationally fast operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Example Reconstructions from Real Data</head><p>This section details two applications of the discontinuitypreserving regularization kernels proposed in this paper using real data. The first address the problem of three-dimensional surface reconstruction and the second that of image interpolation.</p><p>Three-Dimensional Suiface Reconstruction As example application the three-dimensional surface in Fig. <ref type="figure" target="#fig_8">11</ref> was approximated with several stabilizers. Let z ( x , y) denote the surface we wish to approximate and the data acquisition is modeled by A,z(x. y) = z(x,, yz, ). The approximated surfaces were obtained by using the stabilizer   The surface in Fig. <ref type="figure" target="#fig_9">12</ref> was estimated by using X = 1.0 and T = oa, this corresponds to the normal quadratic surface fitting, notice how the discontinuities in the surface are smoothed. In Figs. <ref type="bibr" target="#b21">13</ref>, 14, and 15 the parameter T was set to 0.1, 1.0, and 2.0, respectively. Notice how the degree to which discontinuities are included is controlled by the parameter T . As an example with some real data the sparse three-dimensional data in Fig. <ref type="figure">16</ref> was approximated by a dense grid of points. the data was produced by a Technical Arts lOOX scanner (White scanner) at Michigan State University's Pattern Recognition and Image Processing Lab. The approximate surface obtained using A = 1.0 and T = 0.1 is shown in Fig. <ref type="figure">17</ref>; notice that both jump and orientation discontinuities are accurately estimated.</p><p>Image Filtering Various filtering techniques have been developed to suppress the noise in image signals in order to improve the overall quality of the picture. For images, linear filtering operations do not perform well because images  usually contain many sharp edges and thin structures that tend to be smeared or lost in the filtering processing. Non-linear filters based on rank-order operations such as the median and morphological filters do well at preserving edge and image structure, but perform poorly when filtering Gaussian noise out of the image.</p><p>Figure <ref type="figure" target="#fig_15">18</ref> shows a segment of a noisy image and the results of filtering with several different nonlinear filters. Figure <ref type="figure" target="#fig_15">18(a)</ref> shows the original noisy image data. Figure <ref type="figure" target="#fig_15">18</ref>(b) shows the image filtered with an a-trimmed mean (7 x 7 cross window, a = 3). Figure <ref type="figure" target="#fig_15">18</ref>(c) shows the image filtered with a median filter (7x7 cross window). Notice that the discontinuity-preserving regularization kernel (Fig. <ref type="figure" target="#fig_15">18(d</ref>)) produces the most visually pleasing reconstruction since the discontinuities in the original data are better preserved and the data is well smoothed.</p><p>VII. CONCLUSION This paper has presented a mathematically well-posed method for estimating parameter fields with discontinuities. The proposed method is based on regularization theory where the consistency measure is nonquadratic, but convex. The convexity of the functional is important from both a mathematical and computational viewpoint. It was shown that the class of convex regularizing functions can provide as higher quality (or higher) signal reconstructions without the stability problems or computational problems of the nonconvex forms. The applications of reconstructing piecewise curves/surfaces and of fitting images data were used to demonstrate the usefulness of the proposed method. Finally, some computational issues were discussed and both analog and digital networks were proposed for solving the variational principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VnI. APPENDIX: PROOF OF THEOFEM 1</head><p>In this appendix we prove the following theorem:  Proofi Since the differential operators and multiplying by a fixed w,(x) are linear operators, and since a sum of convex functionals is convex, we can examine without loss of generality the convexity of the functional R[SI = An p(s(x))dx. + (1 -a)R[t(x)] <ref type="bibr" target="#b37">(38)</ref> for all possible functions S(X) and t(x) and for all possible (+) If R[.]is convex then condition <ref type="bibr" target="#b37">(38)</ref> is true. If we assume that p(.) is not convex that means that there exists scalars a E [0, 11. which implies that R is nonconvex since there exists a s(x), t(x) and a such that condition <ref type="bibr" target="#b37">(38)</ref> does not hold, this is a contradiction, therefore p(,) is convex. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>XillAr* -ci112 (10) M'[~*,W~*,S] = fiw[r*,wp*] + c, ES where a,[., e] has the form aW[r*, wp*] = €(r*, wp*) + z)(wP*). (1 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>nonconvex and thus results in a nonconvex and ill-posed functional minimization problem. Figure l(b) is a plot of the influence functional (the first derivative of p(-)), it indicates the amount of influence imposed as the derivative term gets larger.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>, pT[ax + (1 -a)y] 5 apT(z)+ (1 -a ) p T ( y ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>WEE-Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. (a) Reconstruction for dense data set using p z ( . ) . e) Reconstruction for sparse data set using p 2 ( . ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Two noisy signal sets with step edge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Original three-dimensional surface data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Surface approximated with quadratic stabilizer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Surface approximated with discontinuity preserving stabilizer, T = 0.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Surface approximated with discontinuity preserving stabilize T = 1.0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 15 . 2 Fig. 16 .</head><label>15216</label><figDesc>Fig. 15. Surface approximated with discontinuity preserving stabilizer, T = 2.0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Figure 18(d)  shows the image filtered with the proposed regularization technique, with following discontinuity preserving regularization kernel:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Theorem</head><label></label><figDesc>is convex with respect to the function r(x) and fixed wp(x) if and only if the function p ( . ) is convex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Image filtering (a) Noisy image. (b) Filtered using a-trimmed mean. (c) Filtered using median. (d) Filtered using discontinuity-preserving regularization kemel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>( 37 )</head><label>37</label><figDesc>A functional is convex if and only if O[as(x) + (1 -a)t(x)] 5 ~O [ S ( X ) ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Nov. 30-m. 2, 1987, pp. 225-227. holds. Then fl[as(x) + (1a)t(x)] = + (1a)t(x))dx ap(s(x)) + (1a)p(t(x))dx p ~. 93-98. McGraw-Hill, 1958. Therefore O[.] is convex. = &amp;[s(x) + (1a)R[t(x)]. (42) 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and B. E. Schmitz are with the Laboratory of Image and Signal Analysis, Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN 46556. E. J. Delp is with the Computer Vision and Image Processing Laboratory,</figDesc><table><row><cell>School of Electrical Engineering, Purdue University, West Lafayette, IN</cell></row><row><cell>47907.</cell></row><row><cell>IEEE Log Number 9214600.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I MODEL PARAMETERS USED FOR RECONSTRUCTIONS Signal Model x T Quadratic 5 .oo -</head><label>I</label><figDesc></figDesc><table><row><cell>Generalized Absolute</cell><cell>0.20</cell><cell>1.10</cell></row><row><cell>Neighborhood Interaction</cell><cell>0.20</cell><cell>1 .00</cell></row><row><cell>Huber</cell><cell>0.05</cell><cell>0.05</cell></row><row><cell>TABLE II</cell><cell></cell><cell></cell></row><row><cell cols="2">AVERAGE RECONSTRUCTION ERRORS</cell><cell></cell></row><row><cell>Signal Model</cell><cell>MAE</cell><cell>MSE</cell></row><row><cell>Quadratic</cell><cell>0.006783</cell><cell>0.000264</cell></row><row><cell>Generalized Absolute</cell><cell>0.005624</cell><cell>0.000252</cell></row><row><cell>Neighborhood Interaction</cell><cell>0.004172</cell><cell>0.000062</cell></row><row><cell>Huber</cell><cell>0.003687</cell><cell>O.ooOo26</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The author would like to thank Professors C. Bouman and K. Sauer for their many useful discussions and Professors P. Flynn and A. Jain for use of their data.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Convex then for dl functions S(X) and t(X) [17] W. Hackbusch, Multi-Grid Methods and Applications</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Edge detection through twoand for all scalars (L: E [O, 1 1 the inequality ~ dimensional regularization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Computer Vision</title>
		<meeting>Workshop on Computer Vision</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust Smoothing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robustness in Statistics</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Launer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Wilkinson</surname></persName>
		</editor>
		<imprint>
			<publisher>New York John Wiley &amp; Sons</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<title level="m">Robust Statistics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Analog models for early vision</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Califomia Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computing motion using analog and binary resistive networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="page" from="52" to="62" />
			<date type="published" when="1988-03">Mar. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Variations on Regularization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th Int. Cant on Pattern Recognition</title>
		<meeting>10th Int. Cant on Pattern Recognition<address><addrLine>Atlantic City, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">June 16-21, 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Analog circuits: Solutions offieldproblem</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Karplus</surname></persName>
		</author>
		<imprint>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">One-dimensional regularization with disconti</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">p(as</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ill-posed problems in early vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artgcial Intelligence Laboratory Memo</title>
		<imprint>
			<biblScope unit="issue">924</biblScope>
			<date type="published" when="1986">1986</date>
			<publisher>MIT</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Invariant surface reconstruction using weak continuity constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><surname>Zissennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">P m . Computer b i o n and Pattern Recognition Cant</title>
		<meeting><address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">June 22-26, 1986</date>
			<biblScope unit="page" from="62" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Some properties of weak continuity constraints and the GNC algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">P m . Computer vision and Pattern Recognition Con$</title>
		<meeting><address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">June 22-26, 1986</date>
			<biblScope unit="page" from="656" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">visual Reconstruction, Cambridge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>M A MlT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Localizing discontinuities using weak continuity constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattem Recog. Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An edge-preserving method for image reconstruction from integral projections</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Information Sciences and Systems</title>
		<meeting><address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">Mar. 20-22, 1991</date>
		</imprint>
		<respStmt>
			<orgName>The Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A generalized Gaussian image model for edge-preserving MAP estimation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="296" to="310" />
			<date type="published" when="1993-07">July 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The conjugate gradient method for linear and nonlinear operator equations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numerical Anal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="10" to="26" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Function minimization by conjugate gradients</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Reeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer J</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="149" to="154" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parallel and deterministic algorithms for MRFs: Surface reconstruction and integration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Girosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">401412</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEETruns. Pattem Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984-11">Nov. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Constrained restoration and the recovery of discontinuities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="367" to="383" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discontinuity detection for visual surface reconstruction</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics and I m g e Processing</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="316" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hadamard</surname></persName>
		</author>
		<title level="m">Lectures on the Cauchy Problem in Linear Partial Differential Equations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Methods of conjugate gradients for solving h e a r systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stiefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Res. National Bureau of Standards</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">409427</biblScope>
			<date type="published" when="1952-12">Dec. 1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improved initial approximation and intensityguided discontinuity detection in visible-surface reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<idno>1923. nuities</idno>
	</analytic>
	<monogr>
		<title level="m">Graphics and Imuge Processing</title>
		<meeting><address><addrLine>New Haven, CT; London, England</addrLine></address></meeting>
		<imprint>
			<publisher>Yale University Press</publisher>
			<date type="published" when="1987">Sept. 1989. June 8-11, 1987</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="572" to="577" />
		</imprint>
	</monogr>
	<note>Computer vision</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">One-dimensional regularization with discontinuities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="822" to="829" />
			<date type="published" when="1988-11">Nov. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reconstruction without discontinuities</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">2</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Int. Cor$ on Computer vision</title>
		<meeting>Third Int. Cor$ on Computer vision<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-04-07">Dec. 4-7, 1990</date>
			<biblScope unit="page" from="709" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Nonlinear analog networks for image smoothing and segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lumsdaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Elfadel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. VLSI Signal Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="53" to="68" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Probabilistic Solution of Inverse Problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Marrquin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Probabilistic solution of illposed problems in computational vision</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Marrquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mitter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">397</biblScope>
			<biblScope unit="page">7689</biblScope>
			<date type="published" when="1987-03">Mar. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimal approximations of piecewise smooth functions and associated variational problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Communications in Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="577" to="685" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Telkgen&apos;s Theorem and Electrical Networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Penfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duinker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Cambridge, M A MlT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Ill-posed problems and regularization analysis in early vision</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Laboratory Memo</title>
		<imprint>
			<biblScope unit="issue">773</biblScope>
			<date type="published" when="1984">1984</date>
			<pubPlace>Cambridge, MA. MIT</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Computational vision and regulmization theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">317</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page" from="314" to="319" />
			<date type="published" when="1985-09">Sept. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Early vision: From computational structure to algorithms and parallel hardware</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human and Machine Vision</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="190" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Regularization of discontinuous flow fields</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Hervd</surname></persName>
		</author>
		<imprint>
			<date>Mar</date>
			<pubPlace>M e , CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Discontinuity preserving surface reconstruction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Con$ on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Con$ on Computer Vision and Pattern Recognition<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">June 4-8, 1989</date>
			<biblScope unit="page" from="229" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A robust method for surface reconstruction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop on Robust Computer Vision</title>
		<meeting>Int. Workshop on Robust Computer Vision<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Surface approximation using weighted splines</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Lahaina, Maui, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">June 3-6, 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Invariant recovery of surfaces in mdimensional space from sparse data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. SOC. Amer. A</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="490" />
			<date type="published" when="1990-03">Mar. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Invariant reconstruction of curves and surfaces with applications in computer vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Purdue University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fitting curves with discontinuities</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Workshop on Robust Computer Vision</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date>Oct 1-3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Viewpoint invariant recovery of visual surfaces from sparse data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Third Int. Con&amp; on Computer Vision</title>
		<meeting>IEEE Third Int. Con&amp; on Computer Vision<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-04-07">Dec. 4-7, 1990</date>
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Viewpoint invariant recovery of visual surfaces from sparse data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="897" to="909" />
			<date type="published" when="1992-09">Sept. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Surface reconstruction with discontinuities</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conference on Computer Vision and Graphics II</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">Nov. 1991. 20-22, 1989</date>
			<biblScope unit="page" from="81" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName><surname>Wa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990-01-03">Oct. 1-3, 1990. 1990</date>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Parallel implementation for iterative image restorahon algonthms on a parallel DSP machine</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. VLSI Signal Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3 3</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note>both in electrical engineering</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Regularization uses fractal pnors</title>
		<author>
			<persName><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth Nat. Con$ on Art$cial Intelligence</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">July 13-17, 1987</date>
			<biblScope unit="page" from="749" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<title level="m">Bayesian Modeling of Uncertamty in Low-Level Vision</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academc</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The role of constraints and discontmuities in visiblesurface reconstruction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Joint Con$ on Artikial Intelligence</title>
		<meeting>8th Int. Joint Con$ on Artikial Intelligence<address><addrLine>Karlsruhe, West Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983-08-12">Aug. 8-12, 1983</date>
			<biblScope unit="page" from="1073" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Controlled-smoothness stabilizers for the regulariza-Image Understanding Workshop</title>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1934-10">Oct. 3 4 , 1984</date>
			<pubPlace>New Orleans, LA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Regulanzation of inverse visual problems involving discontinuities</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattem Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">413424</biblScope>
			<date type="published" when="1986-07">July 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Solutions of Ill-Posed Problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Arsenin</surname></persName>
		</author>
		<editor>V. H. Winston &amp; Sons</editor>
		<imprint>
			<date type="published" when="1977">1977</date>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Ill-Posed Problems in the Barbara E. Schmitz received the B.S degree in 1989 from Marquette University and the M.S. degree in 1993 from the University of Notre Dame, From 1986 to the present she has been periodically employed with the Naval Research Laboratory in Washington, DC, working on mihtary identification systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Goncharsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">She is currently working toward the Ph</title>
		<meeting><address><addrLine>Moscow</addrLine></address></meeting>
		<imprint>
			<publisher>MIR Publishers</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="225" to="229" />
		</imprint>
	</monogr>
	<note>Her research tion of Ill-posed problems lnvo~vlng discontinuities,&quot; in proc. interests are in the Of vision and image processing&apos; Ms. Schmitz is a member of Tau Beta Pi and Eta Kappa Nu</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Spline base, regularization, and generalized cross validation for solving approximation problems with large quantities of noisy data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wahba ; George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lorentz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approximarion Theory Ill: Proc.eedings of a Conference Honoring Professor</title>
		<imprint>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Energy functions for early vision and analog networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybem</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="115" to="123" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Parameter estimation for the curve recovery schedule</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Ann. Allerton ConJ on Communications, Control, and Computing</title>
		<meeting>31st Ann. Allerton ConJ on Communications, Control, and Computing<address><addrLine>Monticello, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1980">1993. 1980</date>
			<biblScope unit="page" from="485494" to="485905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">From 1980-1984, he was with the Department of Electrical and Computer Engineering at the University of Michigan. Since 1984, he has been with the School of Electrical Engineering at Purdue University, where he is a Professor of Electrical Engineering. His research interests include ill-posed inverse problems in computational vision, nonlinear filtering using mathematical morphology, image coding, and medical imaging. He has also consulted for various companies and government agencies in the areas of signal and image processing, robot vision, pattem recognition, and secure communications. Dr. Delp is a member of Tau Beta Pi</title>
		<author>
			<persName><forename type="first">L</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SM&apos;86) received the B.S.E.E. (cum laude) and M.S. degrees from the University of Cincinnati, OH, and the Ph.D. degree from Purdue University</title>
		<editor>
			<persName><forename type="first">Eta</forename><surname>Kappa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nu</forename><surname>Edward</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Delp</surname></persName>
		</editor>
		<meeting><address><addrLine>West Lafayette, IN; Sigma Xi; Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Optical Society of America</publisher>
		</imprint>
		<respStmt>
			<orgName>Eta Kappa Nu, Phi Kappa Phi</orgName>
		</respStmt>
	</monogr>
	<note>He is also co-editor of the book Digital Cardiac Imaging. In 1990 he received the Honeywell Award and in 1992 the D. D. Ewing Award, both for excellence in teaching. In 1990 he received a Fulbnght Fellowship to teach and perform research at the Universitat Politecnica de Catalunya in</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
