<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Anomaly Detection on Attributed Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kaize</forename><surname>Ding</surname></persName>
							<email>kding9@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State Uni-versity</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
							<email>jundongl@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State Uni-versity</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rohit</forename><surname>Bhanushali</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State Uni-versity</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
							<email>huan.liu@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Arizona State Uni-versity</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Anomaly Detection on Attributed Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Anomaly Detection</term>
					<term>Attributed Networks</term>
					<term>Graph Convolutional Network</term>
					<term>Deep Autoencoder</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Attributed networks are ubiquitous and form a critical component of modern information infrastructure, where additional node attributes complement the raw network structure in knowledge discovery. Recently, detecting anomalous nodes on attributed networks has attracted an increasing amount of research attention, with broad applications in various high-impact domains, such as cybersecurity, finance, and healthcare. Most of the existing attempts, however, tackle the problem with shallow learning mechanisms by ego-network or community analysis, or through subspace selection. Undoubtedly, these models cannot fully address the computational challenges on attributed networks. For example, they often suffer from the network sparsity and data nonlinearity issues, and fail to capture the complex interactions between different information modalities, thus negatively impact the performance of anomaly detection. To tackle the aforementioned problems, in this paper, we study the anomaly detection problem on attributed networks by developing a novel deep model. In particular, our proposed deep model: (1) explicitly models the topological structure and nodal attributes seamlessly for node embedding learning with the prevalent graph convolutional network (GCN); and ( <ref type="formula">2</ref>) is customized to address the anomaly detection problem by virtue of deep autoencoder that leverages the learned embeddings to reconstruct the original data. The synergy between GCN and autoencoder enables us to spot anomalies by measuring the reconstruction errors of nodes from both the structure and the attribute perspectives. Extensive experiments on real-world attributed network datasets demonstrate the efficacy of our proposed algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Attributed networks provide a potent tool to handle the data heterogeneity that we are often confronted with in vast amounts of information systems. Apart from traditional plain networks in which only node-to-node interactions are observed, attributed networks also encode a rich set of features for each node <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18]</ref>. They are increasingly used to model a wide range of complex systems, such as social media networks, critical infrastructure networks, and gene regulatory networks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">26]</ref>. For example, in social networks, users not only are connected with each other by performing various social activities but also are affiliated with rich profile information; in critical infrastructure networks, different power stations form grids, and are also asso-ciated with additional attribute information (e.g., electricity capacity); in gene regulatory networks, genes interact with each other to control specific cell functions in addition to the rich gene sequence expressions. Studies from social science have shown that data often exhibits correlation among the attributes of connected individuals <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29]</ref>, and such insights are helpful in distilling actionable knowledge from such networks.</p><p>Detecting anomalies from data (e.g., attribute-value data, networked data) is a vital research problem of pressing societal concerns, with significant implications in many security-related applications, ranging from social spam detection, financial fraud detection to network intrusion detection <ref type="bibr" target="#b0">[1]</ref>. Due to the strong modeling power of attributed networks in unifying information of different modalities, there is a surge of research interests in detecting anomalous nodes whose patterns deviate significantly from other majority nodes on attributed networks. Generally, the abnormality of nodes on attributed networks is not only determined by their mutual interactions with others (w.r.t.topological structure), but also is measured by their content dissonance (w.r.t. nodal attributes).</p><p>Due to the prohibitive cost for accessing the ground truth anomalies, existing efforts are mostly unsupervised. Among them, one family of methods study the problem at the mesoscope with ego-network <ref type="bibr" target="#b23">[24]</ref> or community analysis <ref type="bibr" target="#b9">[10]</ref> and then identify anomalies by measuring the abnormality of ego-networks or comparing the current node with other nodes within the same community. Another family of methods heavily rely on subspace selection and attempt to find anomalies in a node feature subspace <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>. Recently, residual analysis has emerged as another way to find anomalous nodes <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23]</ref>, where anomalies are defined as the nodes that cannot be approximated from others. Despite their empirical success, the following challenges remain for anomaly detection on attributed networks: (1) Network sparsity -the network structure could be very sparse on real-world attributed networks; thus egonetwork or community analysis is difficult to perform as they highly depend on the observed node interactions.</p><p>(2) Data nonlinearity -the node interactions and nodal attributes are highly non-linear in nature while existing subspace selection based anomaly detectors mainly model the attributed networks with linear mechanisms.</p><p>(3) Complex modality interactions -attributed networks are notoriously difficult to tackle due to the bewildering combination of two information sources, which necessitates a unified feature space to capture their complex interactions for anomaly detection.</p><p>To address the challenges above, we propose to model the attributed networks with graph convolutional network (GCN) <ref type="bibr" target="#b15">[16]</ref>. GCN, which takes the topological structure and nodal attributes as input, is able to learn discriminative node embeddings by stacking multiple layers of linear units and non-linear activation functions. Even though GCN emerges to be a principled tool to model attributed networks and achieves the state-ofthe-art performance in the semi-supervised node classification task, it remains unclear how its power can be shifted to the anomaly detection problem. To bridge the gap, we propose a novel graph convolutional autoencoder framework called Dominant (Deep Anomaly Detection on Attributed Networks) to support anomaly detection on attributed networks. Specifically, Dominant first compresses the input attributed network to succinct low-dimensional embedding representations using graph convolutional network as an encoder function; then we aim to reconstruct both the topological structure and nodal attributes with corresponding decoder functions. The reconstruction errors of nodes following the encoder and decoder phases are then leveraged for spotting anomalous nodes on attributed networks. The main contributions of this paper are as follow:</p><p>‚Ä¢ We systematically analyze the limitations of existing shallow anomaly detection methods and show the significance of developing a novel deep architectured anomaly detector on attributed networks.</p><p>‚Ä¢ We develop a principled graph convolutional autoencoder Dominant which seamlessly models the attributed network and conducts anomaly detection in a joint framework. In particular, the proposed model can spot anomalies by analyzing the reconstruction errors of nodes from both the structure and the attribute perspectives.</p><p>‚Ä¢ We evaluate our proposed model on various attributed networks from different domains. Empirical experimental results demonstrate the superior performance of our proposed framework. The remaining of the paper is organized as follows. We formally introduce the problem definition in Section 2. In Section 3, we present the details of the proposed deep anomaly detection model. Experimental evaluations on multiple real-world datasets are shown in Section 4. Section 5 reviews the related work and Section 6 concludes the whole paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>Following the commonly used notations, in this paper, we use calligraphic fonts to denote sets (e.g., V), bold lowercase letters (e.g., x) to denote vectors and bold uppercase letters for matrices (e.g., X). The i th row of a matrix X is denoted by x i and the (i, j) th element of matrix X is denoted by X i,j . Besides, we represent the identity matrix as I, and the transpose of a matrix X is represented as X T . The 2 -norm of a vector is denoted by ||‚Ä¢|| 2 . The Frobenius norm of a matrix is represented by || ‚Ä¢ || F . Accordingly, we define the attributed network as follows: Definition 1. Attributed Networks: An attributed network G = (V, E, X) consists of: (1) the set of nodes V = {v 1 , v 2 , ..., v n }, where |V| = n; (2) the set of edges E, where |E| = m; and (3) the node attributes X ‚àà R n√ód , where the i th row vector x i ‚àà R d (i = 1, ..., n) is the attribute<ref type="foot" target="#foot_1">1</ref> information for the i th node.</p><p>The topological structure of attributed network G can be represented by an adjacency matrix A, where A i,j = 1 if there is a link between node v i and node v j . Otherwise, A i,j = 0. We follow the setting of <ref type="bibr" target="#b16">[17]</ref> to obtain the adjacency matrix A = max(A, A T ) for directed networks. To make the results more interpretable, we formulate the task of anomaly detection on attributed networks as a ranking problem: Problem 1. Anomaly Ranking on Attributed Networks: Given an attributed network G, with the adjacency matrix A and attribute information matrix X of n node instances, the task is to rank all the nodes according to the degree of abnormality, such that the nodes that differ singularly from the majority reference nodes should be ranked on high positions.</p><p>Next, we will introduce our proposed deep framework which models network topological structure and nodal attributes coherently for detecting anomalies on attributed networks in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Model -Dominant</head><p>In this section, we present the proposed framework of Dominant in detail. The architecture of the deep model is illustrated in Figure <ref type="figure" target="#fig_2">1</ref>. As can be observed, the fundamental building block of Dominant is the deep autoencoder <ref type="bibr" target="#b10">[11]</ref> and it consists of three essential components: (i) attributed network encoder -which models network structure and nodal attributes seamlessly in a joint framework for node embedding representation learning with GCN; (ii) structure reconstruction </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attributed Network Encoder</head><p>Attribute Reconstruction Decoder</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structure Reconstruction Decoder</head><p>Anomaly Ranking List</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Embedding Vectors</head><p>Hidden Layer 1  decoder -which aims to reconstruct the original network topology with the learned node embeddings; and (iii) attribute reconstruction decoder -which attempts to reconstruct the observed nodal attributes with the obtained node embeddings. Afterwards, the reconstruction errors of nodes are then leveraged to flag anomalies on attributed networks.</p><formula xml:id="formula_0">! " ! # ! $ ! % ! &amp; ! ' ùë£ * ùë£ + ùë£ , !" !# !$ !% !&amp; !' !" !# !$ !% !&amp; !' ! " ! # ! $ ! % ! &amp; ! ' ReLU<label>1</label></formula><formula xml:id="formula_1">‚Ä¶ !" !# !$ !% !&amp; '( ') '* '+ ', '- !" !# !$ !% !&amp; !" !# !$ !% !&amp; !" !# !$ !% !&amp; !" !# !$ !% !&amp; !" !# !$ !% !&amp;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ùêó (</head><note type="other">Hidden</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary -Deep Autoencoder</head><p>As suggested by <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b16">17]</ref>, the disparity between the original data and the estimated data (i.e., reconstruction errors) is a strong indicator to show the abnormality of instances in a dataset. Specifically, the data instances with large reconstruction errors are more likely to be considered as anomalies, since their patterns deviate significantly from the majority and cannot be accurately reconstructed from the observed data. Among various reconstruction based anomaly detection methods, deep autoencoder achieves state-of-the-art performance. Deep autoencoder is a type of deep neural network that is used to learn latent representations of data in an unsupervised manner by stacking multiple layers of encoding and decoding functions together. It has achieved promising learning performance in various domains, such as computer vision, natural language processing, and speech recognition <ref type="bibr" target="#b10">[11]</ref>.</p><p>Given an input dataset X, the encoder Enc(‚Ä¢) is first applied to map the data into a latent lowdimensional feature space, and then the decoder Dec(‚Ä¢) tries to recover the original data based on the latent representations. The learning process can be described as minimizing a cost function described below:</p><formula xml:id="formula_2">(3.1) min E[dist(X, Dec(Enc(X))],</formula><p>where dist(‚Ä¢, ‚Ä¢) is a predefined distance metric. In practice, we often choose the 2 -norm distance to measure the reconstruction errors. It also should be noted that deep autoencoder is able to capture the highly non-linear information from high-dimensional input by applying multiple layers of linear units and nonlinear activation functions in the encoder and decoder phases, which is advantageous compared to conventional shallow learning models. Subsequently, in this study, we propose to solve the problem of anomaly detection on attributed networks in a deep autoencoder architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Attributed Network Encoder</head><p>As a rich network representation, attributed networks encode not only the network structure but also abundant nodal attributes. However, conventional deep autoencoders can only handle i.i.d. attribute-value data <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b34">35]</ref>, which cannot be directly applied to our scenario. How to design an effective encoder to capture the underlying properties of attributed networks remains a daunting task as we need to address the three challenges (i.e., network sparsity, data nonlinearity, and complex modality interactions) simultaneously. To this end, we propose a new type of attributed network encoder inspired by the graph convolutional network (GCN) model <ref type="bibr" target="#b15">[16]</ref>. Specifically, GCN considers the high-order node proximity when learning the embedding representations, thus it mitigates the network sparsity issue beyond the observed links among nodes. Meanwhile, through multiple layers of nonlinear transformations, it captures the nonlinearity of data and the complex interactions of two information modalities on attributed networks. Mathematically, GCN extends the operation of convolution to networked data in the spectral domain and learns a layer-wise new latent representation by a spectral convolution function:</p><formula xml:id="formula_3">(3.2) H (l+1) = f (H (l) , A|W (l) ),</formula><p>where H (l) is the input for the convolution layer l, and H (l+1) is the output after the convolution layer. We take the attribute matrix X ‚àà R n√ód as the input of first layer, which is equivalent to H (0) . W (l) is a layer-specific trainable weight matrix we need to learn in the neural network. Each layer of the graph convolutional network can be expressed with the function f (H (l) , A|W (l) ) as follows:</p><formula xml:id="formula_4">(3.3) f (H (l) , A|W (l) ) = œÉ( D ‚àí 1 2 A D ‚àí 1 2 H (l) W (l) ),</formula><p>where A = A + I and D is the diagonal matrix of A with the diagonal element as D i,i = j A i,j . Thus we can directly compute D ‚àí 1 2 A D ‚àí 1 2 as a preprocessing step. Note that œÉ(‚Ä¢) is a non-linear activation function, such as Relu(x) = max(0, x). It is worth noting that the filter or feature map parameters W l are shared for all nodes on the attributed network. Given the attribute matrix X as input, the k th -hop neighborhood of each node can be effectively captured by successively stacking a number of k convolutional layers. Therefore, the embeddings Z not only encode the attribute information of each node but also involve the k th -order node proximity information. In this work, we propose to use three convolutional layers for constructing the attributed network encoder, but it should be noted that more layers can also be stacked for building a deeper network. The attributed network encoder can be formulated as:</p><formula xml:id="formula_5">H (1) = f Relu (X, A|W (0) ) (3.4)</formula><p>H (2) = f Relu (H (1) , A|W (1) ) (3.5) (2) , A|W (2) ). <ref type="bibr">(3.6)</ref> Here, W (0) ‚àà R n√óh1 is an input-to-hidden layer with h 1 feature maps. Similarly, W (1) ‚àà R h1√óh2 and W (3) ‚àà R h2√óh3 are two hidden-to-hidden weight matrices. After applying three layers of convolution, the input attributed network can be transferred to the h 3dimensional latent representations Z, which can capture the high non-linearity in the topological network structure and nodal attributes.</p><formula xml:id="formula_6">Z = H (3) = f Relu (H</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Structure Reconstruction Decoder</head><p>In this subsection, we will discuss how to reconstruct the original network structure with the learned latent representations Z, which is from the aforementioned encoder module. Let A denote the estimated adjacency matrix, then the structure reconstruction error R S = A‚àí A can be exploited to determine structural anomalies on the network. Specifically, for a certain node, if its structure information can be approximated through the structure reconstruction decoder, thus it is of low probability to be anomalous. On the opposite side, if the connectivity patterns cannot be well reconstructed, it implies that its structure information does not conform to the patterns of majority normal nodes. Therefore, a larger norm of R S (i, :) indicates that the i th node on the attributed network has a higher probability of being an anomaly from the network structure aspect. Specifically, the decoder takes the latent representations as input and predicts whether there is a link between each pair of two nodes:</p><p>(3.7) p( A i,j = 1|z i , z j ) = sigmoid(z i , z T j ). Accordingly, we train a link prediction layer based on the output of attributed network encoder Z, which can be presented as follows:</p><p>(3.8)</p><p>A = sigmoid(ZZ T ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Attribute Reconstruction Decoder</head><p>Similarly, to compute the reconstruction errors of nodal attributes, we propose an attribute reconstruction decoder that approximates the nodal attributes information from the encoded latent representations Z. Specifically, the attribute reconstruction decoder leverages another graph convolutional layer to predict the original nodal attributes as follows:</p><formula xml:id="formula_7">X = f Relu (Z, A|W<label>(3)</label></formula><p>). (3.9)</p><p>With the computed reconstruction errors R A = X ‚àí X, we can spot anomalies on the attributed networks from the attribute perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Anomaly Detection</head><p>Until now, we have introduced how to reconstruct the topological network structure, and nodal attributes using structure reconstruction decoder and attribute reconstruction decoder, respectively. To jointly learn the reconstruction errors, the objective function of our proposed deep graph convolutional autoencoder can be formulated as:</p><formula xml:id="formula_8">(3.10) L = (1 ‚àí Œ±)R S + Œ±R A = (1 ‚àí Œ±)||A ‚àí A|| 2 F , +Œ±||X ‚àí X|| 2 F</formula><p>, where Œ± is an important controlling parameter which balances the impacts of structure reconstruction and attribute reconstruction.</p><p>By minimizing the above objective function, our proposed deep graph convolutional autoencoder can iteratively approximate the input attributed network based on the encoded latent representations until the objective function converges. The final reconstruction errors are then employed to assess the abnormality of nodes. Note that the weight matrices of the deep graph convolutional autoencoder are trained using gradient descent on the objective function. After a certain number of iterations, we can compute the anomaly score of each node v i according to: Specifically, instances with larger scores are more likely to be considered as anomalies; thus we can compute the ranking of anomalies according to the corresponding anomaly scores.</p><formula xml:id="formula_9">(3.11) score(v i ) = (1 ‚àí Œ±)||a ‚àí a i || 2 + Œ±||x i ‚àí x i || 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Complexity Analysis</head><p>Graph convolutional network is a computationally efficient model whose complexity is linear to the number of edges on the network.</p><p>For a particular layer, the convolution operation is D ‚àí 1 2 A D ‚àí 1 2 XW, and its complexity is O(mdh) <ref type="bibr" target="#b15">[16]</ref> as AX can be efficiently implemented using sparse-dense matrix multiplications, where m is the number of non-zero elements in matrix A and d is the number feature dimensions on the attributed network, and h is the number of feature maps of the weight matrix. In addition to the convolutional layers, there is another link prediction layer in our model to reconstruct the original topological structure; thus the overall complexity is O(mdH + n 2 ), where H is the summation of all feature maps across different layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we perform empirical evaluations on realworld attributed networks to verify the effectiveness of the proposed Dominant framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>In order to have a comprehensive evaluation, we adopt three real-world attributed network datasets that have been widely used in previous research <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b7">8]</ref> in our experiments:</p><p>‚Ä¢ BlogCatalog: BlogCatalog is a blog sharing website. The bloggers in blogcatalog can follow each other forming a social network. Users are associated with a list of tags to describe themselves and their blogs, which are regarded as node attributes.</p><p>‚Ä¢ Flickr: Flickr is an image hosting and sharing website. Similar to BlogCatalog, users can follow each other and form a social network. Node attributes of users are defined by their specified tags that reflect their interests.</p><p>‚Ä¢ ACM: ACM is another attributed network from academic field. It is a citation network where each paper is regarded as a node on the network, and the links are the citation relations among different papers. The attributes of each paper are generated from the paper abstract.</p><p>As there is no ground truth of anomalies in the above datasets, thus we need to inject anomalies into the attributed networks for our empirical evaluation. In particular, we refer to two anomaly injection methods that has been used in previous research <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31]</ref> to generate a combined set of anomalies for each dataset by perturbing topological structure and nodal attributes, respectively. On one hand, to perturb the topological structure of an attributed network, we adopt the method introduced by <ref type="bibr" target="#b7">[8]</ref> to generate some small cliques. The intuition behind this method is that in many realworld scenarios, small clique is a typical anomalous substructure in which a small set of nodes are much more closely linked to each other than average <ref type="bibr" target="#b29">[30]</ref>. Therefore, after we specify the clique size as m, we randomly select m nodes from the network and then make those nodes fully connected, and then all the m nodes in the clique are regarded as anomalies. We iteratively repeat this process until a number of n cliques are generated and the total number of structral anomalies is m √ó n. In our experiments, we fix the clique size m to 15 and set n to 10, 15 and 20 for BlogCatalog, Flickr and ACM, respectively. In addition to the injection of structural anomalies, we adopt another attribute perturbation schema introduced by <ref type="bibr" target="#b30">[31]</ref> to generate anomalies from attribute perspective. To guarantee an equal number of anomalies from structural perspective and attribute perspective will be injected into the attributed network, we first randomly select another m √ó n nodes as the attribute perturbation candidates. For each selected node i, we randomly pick another k nodes from the data and select the node j whose attributes deviate the most from node i among the k nodes by maximizing the Euclidean distance ||x i ‚àí x j || 2 . Afterwards, we then change the attributes x i of node i to x j . In our experiments, we set the value of k to 50. The details of these three attributed network datasets are shown in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>In this section, we introduce the detailed experimental settings, including the compared baseline methods and evaluation metrics. Compared Methods. We compare the proposed Dominant framework with the following popular anomaly detection methods:</p><p>‚Ä¢ LOF <ref type="bibr" target="#b3">[4]</ref> detects anomalies at the contextual level and only considers nodal attributes.</p><p>‚Ä¢ SCAN <ref type="bibr" target="#b33">[34]</ref> is a structure based detection method</p><p>‚Ä¢ Radar <ref type="bibr" target="#b16">[17]</ref> is the state-of-the-art unsupervised anomaly detection framework for attributed networks. It detects anomalies whose behaviors are singularly different from the majority by characterizing the residuals of attribute information and its coherence with network information.</p><p>‚Ä¢ ANOMALOUS <ref type="bibr" target="#b22">[23]</ref> performs joint anomaly detection and attribute selection to detect anomalies on attributed networks based on the CUR decomposition and residual analysis.</p><p>Evaluation Metrics In the experiments, two evaluation metrics are used to measure the performance of different anomaly detection algorithms:</p><p>‚Ä¢ ROC-AUC: As a widely used evaluation metric in previous anomaly detection methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23]</ref>, the ROC curve is a plot of true positive rate (an anomaly is recognized as an anomaly) against false positive rate (a normal node is recognized as an anomaly) according to the ground truth and the detection results. AUC value is the area under the ROC curve, representing the probability that a randomly chosen abnormal node is ranked higher than a normal node. If the AUC value approaches 1, the method is of high quality.</p><p>‚Ä¢ Precision@K: As each anomaly detection method outputs a ranking list according to the anomalous scores of different nodes, we use Precision@K to measure the proportion of true anomalies that a specific detection method discovered in its top K ranked nodes.</p><p>‚Ä¢ Recall@K: This metric measures the proportion of true anomalies that a specific detection method discovered in the total number of ground truth anomalies.</p><p>Parameter Settings In the experiments on different datasets, we propose to optimize the loss function with Adam <ref type="bibr" target="#b14">[15]</ref> algorithm and train the proposed model for 300 epochs for the performance evaluation. We set the learning rate to 0.005. In addition, the attributed network encoder is built with three convolutional layers (64-neuron, 32-neuron and 16-neuron, respectively).</p><p>For the other baselines, we retain to the settings described in the corresponding papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>In the experiments, we evaluate the performance of our proposed model Dominant by comparing it with the aforementioned baselines. We first present the experimental results in terms of ROC-AUC on the three datasets in Figure <ref type="figure">2</ref>. Then we present the results w.r.t. Precision@K and Recall@K for other methods on all the attributed networks in Table <ref type="table" target="#tab_1">2</ref>. Note that we do not include the results of SCAN and AMEN in Table <ref type="table" target="#tab_1">2</ref> as only limited number of ground truth anomalies can be detected on the top in our experiments. From the evaluation results, we make the following observations:</p><p>‚Ä¢ The proposed deep model Dominant outperforms other baseline methods on all the three attributed networks. It verifies the effectiveness of performing anomaly detection on attributed networks by deep architecture.</p><p>‚Ä¢ anomalous neighborhoods rather than nodes, which also result in relatively poor performance.</p><p>‚Ä¢ The residual analysis based models (Radar and Anomalous) are superior to the conventional anomaly detection methods (LOF, SCAN and AMEN). However, these models are still limited by their shallow mechanisms to handle the network sparsity, data nonlinearity, and complex modality interactions issues.</p><p>‚Ä¢ Dominant shows a stronger ability to rank anomalies on higher positions according to the results of precision@K and recall@K. It can achieve better detection performance when the objective is to find more true anomalies within the ranking list of limited length.</p><p>4.4 Parameter Analysis Next, we investigate the impact of the controlling parameter Œ± in our proposed Dominant framework and report the performance variance results in Figure <ref type="figure">3</ref>. Here we present the AUC values on the three attributed network datasets. The controlling parameter Œ± balances the impact of attribute reconstruction errors and structure reconstruction errors on model training and anomaly scores computation. In two extreme cases, Dominant will only consider the structure reconstruction errors when Œ± is set to 1 while merely consider the attribute reconstruction errors when Œ± is set 0. The results indicate that it is necessary to find a balance between the structure reconstruction errors and attribute reconstruction errors for achieving a better performance. The reasonable choice of Œ± is around 0.4 to 0.7 for BlogCatalog and Flickr datasets, and 0.5 to 0.8 for ACM dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>In this section, we briefly review related work in two aspects: (1) anomaly detection on attributed networks; and (2) deep learning on network data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Anomaly Detection on Attributed Networks</head><p>As attributed networks are increasingly used to model a wide range of complex systems, the studies of anomaly detection on attributed networks have attracted a lot of attention. Generally, the existing methodologies can be divided into three categories: the first category of anomaly detection methods aims to spot anomalies with community or ego-network analysis. For instance, CODA attempts to simultaneously find communities as well as spot community anomalies within a unified probabilistic model <ref type="bibr" target="#b9">[10]</ref>. AMEN <ref type="bibr" target="#b23">[24]</ref> considers the ego-network information for each node and discovers anomalous neighborhoods on attributed networks. Besides that, another family of methods is focused on spotting abnormal nodes in a node feature subspace <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b20">21]</ref>. For example, GOutRank <ref type="bibr" target="#b20">[21]</ref> conducts anomaly ranking on attributed networks based on subspace cluster analysis. ConSub <ref type="bibr" target="#b27">[28]</ref> takes subspace selection algorithm as a pre-processing step before anomaly detection. FocusCO <ref type="bibr" target="#b24">[25]</ref> focuses on community anomalies on a predefined subspace from user preferences. In addition to the methods mentioned above, residual analysis has emerged as another common way to measure the abnormality of nodes on attributed networks. In particular, Radar <ref type="bibr" target="#b16">[17]</ref> characterizes the residuals of attribute information and its coherence with network information for anomaly detection. ANOMALOUS <ref type="bibr" target="#b22">[23]</ref> further incorporates CUR decomposition into the residual analysis to alleviate the adverse impacts of noisy features for anomaly detection. Despite their fruitful progress, these models are limited by their shallow mechanisms and are incapable of han- dling the critical issues of attributed networks, such as network sparsity, data nonlinearity and complex modality interactions among different information sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Deep Learning on Networked Data</head><p>With the growing research interests on deep learning, tremendous efforts have been devoted to developing deep neural networks on networked data for various learning tasks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b2">3]</ref>. As one of the first attempts, HNE <ref type="bibr" target="#b5">[6]</ref> develops a heterogeneous deep model to embed heterogeneous network data into a unified latent feature space. Afterward, a surge of deep autoencoder based models <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9]</ref> have been proposed for network representation learning, and render state-of-theart performance by their strong capability in capturing highly non-linear properties of data. Among them, SDNE <ref type="bibr" target="#b32">[33]</ref> exploits the first and second order node proximity by extending the traditional autoencoder framework. TriDNR <ref type="bibr" target="#b21">[22]</ref> captures the inherent correlations between structure, node content and label information via a tri-party autoencoder architecture. Meanwhile, recent research advances on graph convolutional network (GCN) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12]</ref> demonstrate superior learning performance by considering neighbors of nodes that are multiple hops away. In particular, GCN <ref type="bibr" target="#b15">[16]</ref> takes the structure and attribute information as input, and extends the operation of convolution on network data in the spectral domain for embedding representation learning. GraphSAGE <ref type="bibr" target="#b11">[12]</ref> enables inductive representation learning on graph structured data by learning a function that generates embeddings by sampling and aggregating features from a nodes local neighborhood. Nevertheless, all these methods focus on learning embedded representations of nodes, it is still not clear how to perform anomaly detection on top of the deep neural networks. Even though the recently proposed NetWalk <ref type="bibr" target="#b34">[35]</ref> combines network representation learning and anomaly detection in a joint framework, it is proposed to solve the problem of anomaly detection on dynamic networks, which cannot be directly applied to our attributed network scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we make the first investigation on the research problem of anomaly detection on attributed networks by developing a carefully designed deep learning model. Specifically, we address the limitations of existing methods and model the attributed networks with graph convolutional network (GCN). As GCN handles the high-order node interactions with multiple layers of nonlinear transformations, it alleviates the network sparsity issue and can capture the nonlinearity of data as well as the complex interactions between two sources of information on attributed networks. To further enable the detection of anomalous nodes, we introduce a deep autoencoder framework to reconstruct the original attributed network with the learned node embeddings from GCN. The reconstruction errors of nodes are then employed to flag anomalies. The experimental results demonstrate the superiority of the proposed deep model over the state-of-the-art methods. Future work can be focused on two aspects: first we will investigate if the proposed deep model is vulnerable to data poisoning attacks as intelligent attackers can inject malicious samples to avoid the anomalies being detected; second, we will study how to develop robust anomaly detectors in the presence of adversarial attacks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overall framework of our proposed Dominant for deep anomaly detection on attributed networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Downloaded 08/04/19 to 146.185.205.150. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Details of the three attributed network datasets with injected anomalies</figDesc><table><row><cell></cell><cell>BlogCatalog</cell><cell>Flickr</cell><cell>ACM</cell></row><row><cell># nodes</cell><cell>5,196</cell><cell>7,575</cell><cell>16,484</cell></row><row><cell># edges</cell><cell>171,743</cell><cell cols="2">239,738 71,980</cell></row><row><cell># attributes</cell><cell>8,189</cell><cell>12,047</cell><cell>8,337</cell></row><row><cell># anomalies</cell><cell>300</cell><cell>450</cell><cell>600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>LOF and SCAN cannot achieve satisfying results in our experiments as they merely consider the nodal attributes or topological structure. Even though AMEN is designed for anomaly detection on attributed networks, it centers around finding Downloaded 08/04/19 to 146.185.205.150. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Performance of different anomaly detection methods w.r.t. precision@K and recall@K.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Precision@K</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">BlogCatalog</cell><cell></cell><cell></cell><cell cols="2">Flickr</cell><cell></cell><cell></cell><cell cols="2">ACM</cell><cell></cell></row><row><cell>K</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell></row><row><cell>LOF</cell><cell>0.300</cell><cell>0.220</cell><cell>0.180</cell><cell>0.183</cell><cell>0.420</cell><cell>0.380</cell><cell>0.270</cell><cell>0.237</cell><cell>0.060</cell><cell>0.060</cell><cell>0.045</cell><cell>0.037</cell></row><row><cell>Radar</cell><cell>0.660</cell><cell>0.670</cell><cell>0.550</cell><cell>0.416</cell><cell>0.740</cell><cell>0.700</cell><cell>0.635</cell><cell>0.503</cell><cell>0.560</cell><cell>0.580</cell><cell>0.520</cell><cell>0.430</cell></row><row><cell>Anomalous</cell><cell>0.640</cell><cell>0.650</cell><cell>0.515</cell><cell>0.417</cell><cell cols="2">0.790 0.710</cell><cell>0.650</cell><cell>0.510</cell><cell>0.600</cell><cell>0.570</cell><cell>0.510</cell><cell>0.410</cell></row><row><cell>Dominant</cell><cell cols="4">0.760 0.710 0.590 0.470</cell><cell cols="8">0.770 0.730 0.685 0.593 0.620 0.590 0.540 0.497</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Recall@K</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">BlogCatalog</cell><cell></cell><cell></cell><cell cols="2">Flickr</cell><cell></cell><cell></cell><cell cols="2">ACM</cell><cell></cell></row><row><cell>K</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>300</cell></row><row><cell>LOF</cell><cell>0.050</cell><cell>0.073</cell><cell>0.120</cell><cell>0.183</cell><cell>0.047</cell><cell>0.084</cell><cell>0.120</cell><cell>0.158</cell><cell>0.005</cell><cell>0.010</cell><cell>0.015</cell><cell>0.018</cell></row><row><cell>Radar</cell><cell>0.110</cell><cell>0.223</cell><cell>0.367</cell><cell>0.416</cell><cell>0.082</cell><cell>0.156</cell><cell>0.282</cell><cell>0.336</cell><cell>0.047</cell><cell>0.097</cell><cell>0.173</cell><cell>0.215</cell></row><row><cell>Anomalous</cell><cell>0.107</cell><cell>0.217</cell><cell>0.343</cell><cell>0.417</cell><cell cols="2">0.087 0.158</cell><cell>0.289</cell><cell>0.340</cell><cell>0.050</cell><cell>0.095</cell><cell>0.170</cell><cell>0.205</cell></row><row><cell>Dominant</cell><cell cols="4">0.127 0.237 0.393 0.470</cell><cell cols="8">0.084 0.162 0.304 0.396 0.052 0.098 0.180 0.248</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Downloaded 08/04/19 to 146.185.205.150. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">In this paper, we use attribute and feature interchangeably.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>This material is based upon work supported by, or in part by, the Nation Science Foundation (NSF) grant 1614576, and the Office of Naval Research (ONR) grant N00014-16-1-2257.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>which detects anomalies at the structural level.</p><p>‚Ä¢ AMEN <ref type="bibr" target="#b23">[24]</ref> uses both attribute and network structure information to detect anomalous neighborhoods. Specifically, it analyzes the abnormality of each node from the ego-network point of view.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graph based anomaly detection and description: A survey</title>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DMKD</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="688" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pics: Parameter-free identification of cohesive subgroups in large attributed graphs</title>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Meeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="439" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Relational inductive biases, deep learning, and graph networks</title>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Peter W Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Redistribution subject to SIAM license or copyright</title>
		<author>
			<persName><forename type="first">Markus</forename><forename type="middle">M</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J√∂rg</forename><surname>Sander</surname></persName>
		</author>
		<idno>08/04/19 to 146.185.205.150</idno>
		<ptr target="http://www.siam.org/journals/ojsa.php" />
	</analytic>
	<monogr>
		<title level="m">ACM Sigmod Record</title>
				<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
	<note>local outliers</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep neural networks for learning graph representations</title>
		<author>
			<persName><forename type="first">Shaosheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiongkai</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1145" to="1152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Heterogeneous network embedding via deep architectures</title>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charu</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">Micha√´l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Interactive anomaly detection on attributed networks</title>
		<author>
			<persName><forename type="first">Kaize</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep attributed network embedding</title>
		<author>
			<persName><forename type="first">Hongchang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3364" to="3370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On community outliers and their efficient detection in information networks</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Deep learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Label informed attributed network embedding</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploring expert cognition for attributed network embedding</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingquan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Radar: Residual analysis for anomaly detection in attributed networks</title>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Dani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2152" to="2158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attributed network embedding for learning in a dynamic environment</title>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Dani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised streaming feature selection in social media</title>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1041" to="1050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Birds of a feather: Homophily in social networks</title>
		<author>
			<persName><forename type="first">Lynn</forename><surname>Miller Mcpherson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Smith-Lovin</surname></persName>
		</author>
		<author>
			<persName><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Sociology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="415" to="444" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ranking outlier nodes in subspaces of attributed graphs</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><forename type="middle">Iglesias</forename><surname>S√°nchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvonne</forename><surname>Mulle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klemens</forename><surname>Bohm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE Workshop</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="216" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tri-party deep network representation</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Anomalous: A joint modeling approach for anomaly detection on attributed networks</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minnan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghua</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3513" to="3519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scalable anomaly ranking of attributed neighborhoods</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="207" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Patricia Iglesias S√°nchez, and Emmanuel M√ºller. Focused clustering and outlier detection in large attributed graphs</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1346" to="1355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attributed graph models: Modeling network structure with correlated attributes</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">La</forename><surname>Fond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="831" to="842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Local context selection for outlier ranking in graphs with multiple numeric node attributes</title>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Iglesias S√°nchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oretta</forename><surname>Irmler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klemens</forename><surname>B√∂hm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistical selection of congruent subspaces for mining attributed graphs</title>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Iglesias S√°nchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Laforet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klemens</forename><surname>Bohm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="647" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Homophily and contagion are generically confounded in observational social network studies</title>
		<author>
			<persName><forename type="first">Rohilla</forename><surname>Cosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">C</forename><surname>Shalizi</surname></persName>
		</author>
		<author>
			<persName><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="239" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Detecting anomalies in graphs</title>
		<author>
			<persName><surname>David B Skillicorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISI</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Conditional anomaly detection</title>
		<author>
			<persName><forename type="first">Xiuyao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Jermaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ranka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="631" to="645" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Non-negative residual matrix factorization with application to graph anomaly detection</title>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ching-Yung</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="143" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Structural deep network embedding</title>
		<author>
			<persName><forename type="first">Daixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Scan: A structural clustering algorithm for networks</title>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nurcan</forename><surname>Yuruk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhidan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">Aj</forename><surname>Schweiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="824" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Netwalk: A flexible deep embedding approach for anomaly detection in dynamic networks</title>
		<author>
			<persName><forename type="first">Wenchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2672" to="2681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Anrl: Attributed network representation learning via deep neural networks</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinggang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3155" to="3161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Anomaly detection with robust deep autoencoders</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randy</forename><forename type="middle">C</forename><surname>Paffenroth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
