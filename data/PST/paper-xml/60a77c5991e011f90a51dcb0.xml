<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generative Adversarial Neural Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-05-19">19 May 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seyed</forename><surname>Saeed</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Changiz</forename><surname>Rezaei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fred</forename><forename type="middle">X</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Di</forename><surname>Niu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Salameh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Keith</forename><surname>Mills</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuo</forename><surname>Lian</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Kirin Solutions</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shangling</forename><surname>Jui</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Kirin Solutions</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huawei</forename><forename type="middle">Hisilicon</forename><surname>Lab</surname></persName>
						</author>
						<title level="a" type="main">Generative Adversarial Neural Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-05-19">19 May 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2105.09356v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the empirical success of neural architecture search (NAS) in deep learning applications, the optimality, reproducibility and cost of NAS schemes remain hard to assess. In this paper, we propose Generative Adversarial NAS (GA-NAS) with theoretically provable convergence guarantees, promoting stability and reproducibility in neural architecture search. Inspired by importance sampling, GA-NAS iteratively fits a generator to previously discovered top architectures, thus increasingly focusing on important parts of a large search space. Furthermore, we propose an efficient adversarial learning approach, where the generator is trained by reinforcement learning based on rewards provided by a discriminator, thus being able to explore the search space without evaluating a large number of architectures. Extensive experiments show that GA-NAS beats the best published results under several cases on three public NAS benchmarks. In the meantime, GA-NAS can handle ad-hoc search constraints and search spaces. We show that GA-NAS can be used to improve already optimized baselines found by other NAS methods, including EfficientNet and ProxylessNAS, in terms of ImageNet accuracy or the number of parameters, in their original search space.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural architecture search (NAS) improves neural network model design by replacing the manual trial-and-error process with an automatic search procedure, and has achieved state-ofthe-art performance on many computer vision tasks <ref type="bibr">[Elsken et al., 2018]</ref>. Since the underlying search space of architectures grows exponentially as a function of the architecture size, searching for an optimum neural architecture is like looking for a needle in a haystack. A variety of search algorithms have been proposed for NAS, including random search (RS) <ref type="bibr">[Li and Talwalkar, 2020]</ref>, differentiable architecture search (DARTS) <ref type="bibr">[Liu et al., 2018]</ref>, Bayesian optimization (BO) <ref type="bibr">[Kandasamy et al., 2018]</ref>, evolutionary algorithm (EA) <ref type="bibr">[Dai et al., 2020]</ref>, and reinforcement learning (RL) <ref type="bibr">[Pham et al., 2018]</ref>.</p><p>Despite a proliferation of NAS methods proposed, their sensitivity to random seeds and reproducibility issues concern the community <ref type="bibr">[Li and Talwalkar, 2020]</ref>, <ref type="bibr">[Yu et al., 2019]</ref>, <ref type="bibr">[Yang et al., 2019]</ref>. Comparisons between different search algorithms, such as EA, BO, and RL, etc., are particularly hard, as there is no shared search space or experimental protocol followed by all these NAS approaches. To promote fair comparisons among methods, multiple NAS benchmarks have recently emerged, including NAS-Bench-101 <ref type="bibr">[Ying et al., 2019]</ref>, <ref type="bibr">NAS-Bench-201 [Dong and Yang, 2020]</ref>, and NAS-Bench-301 <ref type="bibr">[Siems et al., 2020]</ref>, which contain collections of architectures with their associated performance. This has provided an opportunity for researchers to fairly benchmark search algorithms (regardless of the search space in which they are performed) by evaluating how many queries to architectures an algorithm needs to make in order to discover a top-ranked architecture in the benchmark set <ref type="bibr">[Luo et al., 2020;</ref><ref type="bibr">Siems et al., 2020]</ref>. The number of queries converts to an indicator of how many architectures need be evaluated in reality, which often forms the bottleneck of NAS.</p><p>In this paper, we propose Generative Adversarial NAS (GA-NAS), a provably converging and efficient search algorithm to be used in NAS based on adversarial learning. Our method is first inspired by the Cross Entropy (CE) method <ref type="bibr">[Rubinstein and Kroese, 2013]</ref> in importance sampling, which iteratively retrains an architecture generator to fit to the distribution of winning architectures generated in previous iterations so that the generator will increasingly sample from more important regions in an extremely large search space. However, such a generator cannot be efficiently trained through back-propagation, as performance measurements can only be obtained for discretized architectures and thus the model is not differentiable. To overcome this issue, GA-NAS uses RL to train an architecture generator network based on RNN and GNN. Yet unlike other RL-based NAS schemes, GA-NAS does not obtain rewards by evaluating generated architectures, which is a costly procedure if a large number of architectures are to be explored. Rather, it learns a discriminator to distinguish the winning architectures from randomly generated ones in each iteration. This enables the generator to be efficiently trained based on the rewards provided by the discriminator, without many true evaluations. We further establish the convergence of GA-NAS in a finite number of steps, by connecting GA-NAS to an importance sampling method with a symmetric Jensen-Shannon (JS) divergence loss.</p><p>Extensive experiments have been performed to evaluate GA-NAS in terms of its convergence speed, reproducibility and stability in the presence of random seeds, scalability, flexibility of handling constrained search, and its ability to improve already optimized baselines. We show that GA-NAS outperforms a wide range of existing NAS algorithms, including EA, RL, BO, DARTS, etc., and state-of-the-art results reported on three representative NAS benchmark sets, including NAS-Bench-101, NAS-Bench-201, and NAS-Bench-301-it consistently finds top ranked architectures within a lower number of queries to architecture performance. We also demonstrate the flexibility of GA-NAS by showing its ability to incorporate ad-hoc hard constraints and its ability to further improve existing strong architectures found by other NAS methods. Through experiments on ImageNet, we show that GA-NAS can enhance EfficientNet-B0 [Tan and <ref type="bibr">Le, 2019]</ref> and <ref type="bibr">Proxy-lessNAS [Cai et al., 2018]</ref> in their respective search spaces, resulting in architectures with higher accuracy and/or smaller model sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A typical NAS method includes a search phase and an evaluation phase. This paper is concerned with the search phase, of which the most important performance criteria are robustness, reproducibility and search cost. DARTS <ref type="bibr">[Liu et al., 2018]</ref> has given rise to numerous optimization schemes for NAS <ref type="bibr">[Xie et al., 2018]</ref>. While the objectives of these algorithms may vary, they all operate in the same or similar search space. However, <ref type="bibr">[Yu et al., 2019]</ref> demonstrates that DARTS performs similarly to a random search and its results heavily dependent on the initial seed. In contrast, GA-NAS has a convergence guarantee under certain assumptions and its results are reproducible. <ref type="bibr">NAS-Bench-301 [Siems et al., 2020]</ref> provides a formal benchmark for all 10 18 architectures in the DARTS search space. Preceding NAS-Bench-301 are NAS-Bench-101 <ref type="bibr">[Ying et al., 2019]</ref> and <ref type="bibr">NAS-Bench-201 [Dong and Yang, 2020]</ref>. Both of these benchmarks perform a fully exhaustive evaluation on all architectures in their search spaces. Besides the cell-based searches, GA-NAS also applies to macro-search <ref type="bibr">[Cai et al., 2018;</ref><ref type="bibr">Tan et al., 2019]</ref>, which searches for an ordering of a predefined set of blocks.</p><p>On the other hand, several RL-based NAS methods have been proposed. ENAS <ref type="bibr">[Pham et al., 2018]</ref> is the first Reinforcement Learning scheme in weight-sharing NAS. TuNAS <ref type="bibr">[Bender et al., 2020]</ref> shows that guided policies decisively exceed the performance of random search on vast search spaces. In comparison, GA-NAS proves to be a highly efficient RL solution to NAS, since the rewards used to train the actor come from the discriminator instead of from costly evaluations.</p><p>Hardware-friendly NAS algorithms take constraints such as model size, FLOPS, and inference time into account <ref type="bibr">[Cai et al., 2018;</ref><ref type="bibr">Tan et al., 2019]</ref>, usually by introducing regularizers into the loss functions. Contrary to these methods, GA-NAS can support ad-hoc search tasks, by enforcing customized hard constraints in importance sampling instead of resorting to approximate penalty terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Method</head><p>In this section, we present Generative Adversarial NAS (GA-NAS) as a search algorithm to discover top architectures in an extremely large search space. GA-NAS is theoretically inspired by the importance sampling approach and implemented by a generative adversarial learning framework to promote efficiency.</p><p>We can view a NAS problem as a combinatorial optimization problem. For example, suppose that x is a Directed Acyclic Graph (DAG) connecting a certain number of operations, each chosen from a predefined operation set. Let S(x) be a real-valued function representing the performance, e.g., accuracy, of x. In NAS, we optimize S(x) subject to x ∈ X , where X denotes the underlying search space of neural architectures.</p><p>One approach to solving a combinatorial optimization problem, especially the NP-hard ones, is to view the problem in the framework of importance sampling and rare event simulation <ref type="bibr">[Rubinstein and Kroese, 2013]</ref>. In this approach we consider a family of probability densities {p(.; θ)} θ∈Θ on the set X , with the goal of finding a density p(.; θ * ) that assigns higher probabilities to optimal solutions to the problem. Then, with high probability, the sampled solution from the density p(.; θ * ) will be an optimal solution. This approach for importance sampling is called the Cross-Entropy method and is explained in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generative Adversarial NAS</head><p>GA-NAS is presented in Algorithm 1, where a discriminator D and a generator G are learned over iterations. In each iteration of GA-NAS, the generator G will generate a new set of architectures X t , which gets combined with previously generated architectures. A set of top performing architectures T , which we also call true set of architectures, is updated by selecting top k from already generated architectures and gets improved over time.</p><p>Following the GAN framework, originally proposed by <ref type="bibr">[Goodfellow et al., 2014]</ref>, the discriminator D and the generator G are trained by playing a two-player minimax game whose corresponding parameters φ t and θ t are optimized by Step 4 of Algorithm 1. After Step 4, G learns to generate architectures to fit to the distribution of T , the true set of architectures.</p><p>Specifically, after Step 4 in the t-th iteration, the generator G(.; θ t ) parameterized by θ t learns to generate architectures from a family of probability densities {p(.; θ)} θ∈Θ such that p(.; θ t ) will approximate p T , the architecture distribution in true set T , while T also gets improved for the next iteration by reselecting top k from generated architectures.</p><p>We have the following theorem which provides a theoretical convergence guarantee for GA-NAS under mild conditions. Theorem 3.1. Let α &gt; 0 be any real number that indicates the performance target, such that max x∈X S(x) ≥ α. Define γ t as a level parameter in iteration t (t = 0, . . . , T ), such that the following holds for all the architectures x t ∈ X t generated by the generator G(.; θ t ) in the t-th iteration:</p><formula xml:id="formula_0">S(x t ) ≥ γ t , ∀x t ∈ X t .</formula><p>Choose k, |X t |, and the γ t defined above such that γ 0 &lt; α, and γ t ≥ min(α, γ t−1 + δ), for some δ &gt; 0, ∀ t ∈ {1, . . . , T }.</p><p>Then, GA-NAS Algorithm can find an architecture x with S(x) ≥ α in a finite number of iterations T .</p><p>Proof. Refer to Appendix for a proof of the theorem.</p><p>Remark. This theorem indicates that as long as there exists an architecture in X with performance above α, GA-NAS is guaranteed to find an architecture with S(x) ≥ α in a finite number of iterations. From <ref type="bibr">[Goodfellow et al., 2014]</ref>, the minimax game of Step 4 of Algorithm 1 is equivalent to minimizing the Jensen-Shannon (JS)-divergence between the distribution p T of the currently top performing architectures T and the distribution p(x; θ t ) of the newly generated architectures. Therefore, our proof involves replacing the arguments around the Cross-Entropy framework in importance sampling <ref type="bibr">[Rubinstein and Kroese, 2013]</ref> with minimizing the JS divergence, as shown in the Appendix.</p><p>Algorithm 1 GA-NAS Algorithm 1: Input: An initial set of architectures X 0 ; Discriminator D; Generator G(x; θ 0 ); A positive integer k; 2: for t = 1, 2, . . . , T do 3:</p><p>T ← top k architectures of t−1 i=0 X i according to the performance evaluator S(.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Train G and D to obtain their parameters</p><formula xml:id="formula_1">(θ t , φ t ) ←− arg min θt max φt V (G θt , D φt ) = E x∼p T [log D φt (x)] + E x∼p(x;θt) [log (1 − D φt (x))] .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Let G(x; θ t ) generate a new set of architectures X t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Evaluate the performance S(x) of every x ∈ X t . 7: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Models and Training Procedure</head><p>We now describe different components in GA-NAS, followed by their training procedures. Although GA-NAS can operate on any search space, here we describe the implementation of the Discriminator and Generator in the context of cell search. We evaluate GA-NAS for both cell search and macro search in experiments. A cell architecture C is a Directed Acyclic Graph (DAG) consisting of multiple nodes and directed edges. Each intermediate node represents an operator, such as convolution or pooling, from a predefined set of operators. Each directed edge represents the information flow between nodes. We assume that a cell has at least one input node and only one output node.</p><p>Architecture Generator. Here we generate architectures in the discrete search space of DAGs. Particularly, we generate architectures in an autoregressive fashion, which is a frequent technique in neural architecture generation such as The decoder consists of an MLP that outputs the operator probability distribution and a Gated Recurrent Unit (GRU) that recursively determines the edge connections to previous nodes.</p><p>Pairwise Architecture Discriminator. In Algorithm 1, T contains a limited number of architectures. To facilitate a more efficient use of T , we adopt a relativistic discriminator <ref type="bibr">[Jolicoeur-Martineau, 2018</ref>] D that follows a Siamese scheme.D takes in a pair of architectures where one is from T , and determines whether the second one is from the same distribution. The discriminator is implemented by encoding both cells in the pair with a shared k-GNN followed by an MLP classifier with details provided in the Appendix.</p><p>Training Procedure. Generally speaking, in order to solve the minimax problem in Step 4 of Algorithm 1, one can follow the minibatch stochastic gradient descent (SGD) training procedure for training GANs as originally proposed in <ref type="bibr">[Goodfellow et al., 2014]</ref>. However, this SGD approach is not applicable to our case, since the architectures (DAGs) generated by G are discrete samples, and their performance signals cannot be directly back-propagated to update θ t , the parameters of G. Therefore, to approximate the JS-divergence minimization between the distribution of top k architectures T , i.e., p T , and the generator distribution p(x; θ t ) in iteration t, we replace</p><p>Step 4 of Algorithm 1 by alternately training D and G using a procedure outlined in Algorithm 2. Figure <ref type="figure" target="#fig_0">1</ref>  Let G(x; θ t−1 ) generate k random architectures to form the set F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Train discriminator D with T being positive samples and F being negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Using the output of D(x) as the main reward signal, train G(x; θ t ) with Reinforcement Learning. 6: end for We first train the GNN-based discriminator using pairs of architectures sampled from T and F based on supervised learning. Then, we use Reinforcement Learning (RL) to train G with the reward defined in a similar way as in <ref type="bibr">[You et al., 2018]</ref>, including a step reward that reflects the validity of an architecture during each step of generation and a final reward that mainly comes from the discriminator prediction D. When the architecture generation terminates, a final reward R f inal penalizes the generated architecture x according to the total number of violations of validity or rewards it with a score from the discriminator D(x) that indicates how similar it is to the current true set T . Both rewards together ensure that G generates valid cells that are structurally similar to top cells from the previous time step. We adopt Proximal Policy Optimization (PPO), a policy gradient algorithm with generalized advantage estimation to train the policy, which is also used for NAS in <ref type="bibr">[Tan et al., 2019]</ref>.</p><p>Remark. The proposed learning procedure has several benefits. First, since the generator must sample a discrete architecture x to obtain its discriminator prediction D(x), the entire generator-discriminator pipeline is not end-to-end differentiable and cannot be trained by SGD as in the original GAN. Training G with PPO solves this differentiability issue. Second, in PPO there is an entropy loss term that encourages variations in the generated actions. By tuning the multiplier for the entropy loss, we can control the extent to which we explore a large search space of architectures. Third, using the discriminator outputs as the reward can significantly reduce the number of architecture evaluations compared to a conventional scheme where the fully evaluated network accuracy is used as the reward. Ablation studies in Section 4 verifies this claim. Also refer to the Appendix for a detailed discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We evaluate the performance of GA-NAS as a search algorithm by comparing it with a wide range of existing NAS algorithms in terms of convergence speed and stability on NAS benchmarks. We also show the capability of GA-NAS to improve a given network, including already optimized strong baselines such as EfficientNet and ProxylessNAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results on NAS Benchmarks with or without</head><p>Weight Sharing We provide the results on two setups. In the first setup, we set</p><formula xml:id="formula_2">|X 0 | = 50, |X t | = |X t−1 | + 50, t ≥ 1, and k = 25, In the second setup, we set |X 0 | = 100, |X t | = |X t−1 | + 100, t ≥ 1,</formula><p>and k = 50. For both setups, the initial set X 0 is picked to be a random set, and the number of iterations T is 10. We run each setup with 10 random seeds and the search cost for a run is 8 GPU hours on GeForce GTX 1080 Ti. Table <ref type="table" target="#tab_0">1</ref> compares GA-NAS to other methods for the best cell that can be found by querying NAS-Bench-101, in terms of the accuracy and the rank of this cell in NAS-Bench-101, along with the number of queries required to find that cell. Table 2 shows the average performance of GA-NAS in the same experiment over multiple random seeds. Note that Table <ref type="table" target="#tab_0">1</ref> does not list the average performance of other methods except Random Search, since all the other methods in Table <ref type="table" target="#tab_0">1</ref> only reported their single-run performance on NAS-Bench-101 in their respective experiments.</p><p>In both tables, we find that GA-NAS can reach a higher accuracy in fewer number of queries, and beats the best published results, i.e., <ref type="bibr">BANANAS [White et al., 2019]</ref> and Semi-NAS <ref type="bibr">[Luo et al., 2020]</ref> by an obvious margin. Note that 94.22 is the 3rd best cell while 94.23 is the 2nd best cell in NAS-Bench-101. From Table <ref type="table" target="#tab_1">2</ref>, we observe that GA-NAS achieves superior stability and reproducibility: GA-NAS-setup1 consistently finds the 3rd best in 9 runs and the 2nd best in 1 run out of 10 runs; GA-NAS-setup2 finds the 2nd best in 5 runs and the 3rd best in the other 5 runs.</p><p>To evaluate GA-NAS when true accuracy is not available, we train a weight-sharing supernet on the search space of NAS-Bench-101 (with details provided in Appendix) and report the true test accuracies of architectures found by GA-NAS. We use the supernet to evaluate the accuracy of a cell on a validation set of 10k instances of CIFAR10 (see Appendix). Search time including supernet training is around 2 GPU days.</p><p>We report results of 10 runs in Table <ref type="table" target="#tab_2">3</ref>, in comparison to other weight-sharing NAS schemes reported in <ref type="bibr">[Yu et al., 2019]</ref>. We observe that using a supernet degrades the search performance in general as compared to true evaluation, because weight-sharing often cannot provide a completely reliable performance for the candidate architectures. Nevertheless, GA-NAS outperforms other approaches. NAS-Bench-201 contains 15,625 evaluated cells. The search space consists of 6 searchable edges and 5 candidate operations. We test GA-NAS on NAS-Bench-201 by conducting 20 runs for CIFAR-10, CIFAR-100, and ImageNet-16-120 using the true test accuracy. We compare against the baselines from the original NAS-Bench-201 paper [Dong and <ref type="bibr">Yang, 2020]</ref> that are also directly querying the benchmark data. Since no information on the rank achieved and the number of queries is reported for these baselines, we also compare GA-NAS to Random Search (RS-500), which evaluates 500 unique cells in each run. Table <ref type="table" target="#tab_3">4</ref> presents the results. We observe that GA-NAS outperforms a wide range of baselines, including Evolutionary Algorithm (REA), Reinforcement Learning (RE-INFORCE), and Bayesian Optimization (BOHB), on the task of finding the most accurate cell with much lower variance. Notably, on ImageNet-16-120, GA-NAS outperforms REA by nearly 1.3% on average.</p><p>Compared to RS-500, GA-NAS finds cells that are higher ranked while only exploring less than 3.2% of the search space in each run. It is also worth mentioning that in the 20 runs on all three datasets, GA-NAS can find the best cell in the entire benchmark more than once. Specifically for CIFAR-10, it found the best cell in 9 out of 20 runs.</p><p>NAS-Bench-301 is another recently proposed benchmark based on the same search space as DARTS. Relying on surrogate performance models, NAS-Bench-301 reports the accuracy of 10 18 unique cells. We are especially interested in how the number of queries (#Q) needed to find an architecture with high accuracy scales in a large search space. We run GA-NAS on NAS-Bench-301 v0.9. We compare with Random (RS) and Evolutionary (EA) search baselines. Figure <ref type="figure" target="#fig_2">2</ref> plots the average best accuracy along with the accuracy standard deviations versus the number of queries incurred under the three methods. We observe that GA-NAS outperforms RS at all query budgets and outperforms EA when the number of queries exceeds 3k. The results on NAS-Bench-301 confirm that for GA-NAS, the number of queries (#Q) required to find a good performing cell scales well as the size of the search space increases. For example, on NAS-Bench-101, GA-NAS usually needs around 500 queries to find the 3rd best cell, with an accuracy ≈ 94% among 423k candidates, while on the huge search space of NAS-Bench-301 with up to 10 18 candidates, it only needs around 6k queries to find an architecture with accuracy approximately equal to 95%.</p><p>In contrast to GA-NAS, EA search is less stable and does not improve much as the number of queries increases over 3000. GA-NAS surpasses EA for #Q ≥ 3000 in Figure <ref type="figure" target="#fig_2">2</ref>. What is more important is that the variance of GA-NAS is much lower than the variance of the EA solution over all ranges of #Q. Even though for #Q &lt; 3000, GA-NAS and EA are close in terms of average performance, EA suffers from a huge variance.</p><p>Ablation Studies. A key question one might raise about GA-NAS is how much the discriminator contributes to the superior search performance. Therefore, we perform an ablation study on NAS-Bench-101 by creating an RL-NAS algorithm for comparison. RL-NAS removes the discriminator in GA-NAS and directly queries the accuracy of a generated cell from NAS-Bench-101 as the reward for training. We test the performance of RL-NAS under two setups that differ in the total number of queries made to NAS-Bench-101. Table <ref type="table" target="#tab_4">5</ref> reports the results.</p><p>Compared to GA-NAS-Setup2, RL-NAS-1 makes 3× more queries to NAS-Bench-101, yet cannot outperform either of the GA-NAS setups. If we instead limits the number of queries as in RL-NAS-2 then the search performance deteriorates significantly. Therefore, we conclude that the discriminator in GA-NAS is crucial for reducing the number of queries, which converts to the number of evaluations in real-world problems, as well as for finding architectures with better performance. Interested readers are referred to Appendix for more ablation studies as well as the Pareto Front search results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Improving Existing Neural Architectures</head><p>We now demonstrate that GA-NAS can improve existing neural architectures, including ResNet and Inception cells in NAS-Bench-101, EfficientNet-B0 under hard constraints, and ProxylessNAS-GPU <ref type="bibr">[Cai et al., 2018]</ref> in unconstrained search.</p><p>For ResNet and Inception cells, we use GA-NAS to find better cells from NAS-Bench-101 under a lower or equal training time and number of weights. This can be achieved by enforcing a hard constraint in choosing the truth set T in each iteration. Table <ref type="table" target="#tab_5">6</ref> shows that GA-NAS can find new, dominating cells for both cells, showing that it can enforce ad-hoc constraints in search, a property not enforceable by regularizers in prior work. We also test Random Search under a similar number of queries to the benchmark under the same constraints, which is unable to outperform GA-NAS. We now consider well-known architectures found on Ima-geNet i.e., EfficientNet-B0 and ProxylessNAS-GPU, which are already optimized strong baselines found by other NAS methods. We show that GA-NAS can be used to improve a given architecture in practice by searching in its original search space. For EfficientNet-B0, we set the constraint that the found networks all have an equal or lower number of parameters than EfficientNet-B0. For the ProxylessNAS-GPU model, we simply put it in the starting truth set and run an unconstrained search to further improve its top-1 validation accuracy. More details are provided in the Appendix. Table <ref type="table" target="#tab_6">7</ref> presents the improvements made by GA-NAS over both existing models. Compared to EfficientNet-B0, GA-NAS can find new single-path networks that achieve comparable or better top-1 accuracy on ImageNet with an equal or lower number of trainable weights. We report the accuracy of EfficientNet-B0 and the GA-NAS variants without data augmentation. Total search time including supernet training is around 680 GPU hours on Tesla V100 GPUs. It is worth noting that the original EfficientNet-B0 is found using the MNasNet <ref type="bibr">[Tan et al., 2019]</ref> with a search cost over 40,000 GPU hours.</p><p>For ProxylessNAS experiments, we train a supernet on ImageNet and conduct an unconstrained search using GA-NAS for 38 hours on 8 Tesla V100 GPUs, a major portion of which, i.e., 29 hours is spent on querying the supernet for architecture performance. Compared to ProxylessNAS-GPU, GA-NAS can find an architecture with a comparable number of parameters and a better top-1 accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose Generative Adversarial NAS (GA-NAS), a provably converging search strategy for NAS problems, based on generative adversarial learning and the importance sampling framework. Based on extensive search experiments performed on NAS-Bench-101, 201, and 301 benchmarks, we demonstrate the superiority of GA-NAS as compared to a wide range of existing NAS methods, in terms of the best architectures discovered, convergence speed, scalability to a large search space, and more importantly, the stability and insensitivity to random seeds. We also show the capability of GA-NAS to improve a given practical architecture, including already optimized ones either manually designed or found by other NAS methods, and its ability to search under ad-hoc constraints. GA-NAS improves EfficientNet-B0 by generating architectures with higher accuracy or lower numbers of parameters, and improves ProxylessNAS-GPU with enhanced accuracies. These results demonstrate the competence of GA-NAS as a stable and reproducible search algorithm for NAS. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Importance Sampling and the Cross-Entropy Method</head><p>Assume X is a random variable, taking values in X and has a prior probability density function (pdf) p(.; λ) for fixed λ ∈ Θ.</p><p>Let S(X) be the objective function to be maximized, and α be a level parameter. Note that the event E := {S(X) ≥ α} is a rare event for an α that is equal to or close to the optimal value of S(X). The goal of rare-event probability estimation is to estimate</p><formula xml:id="formula_3">l(α) := Pλ (S(X) ≥ α) = Eλ I S(X)≥α = I S(x)≥α p(x; λ)dx,</formula><p>where I x∈E is an indicator function that is equal to 1 if x ∈ E and 0 otherwise. In fact, l(α) is called the rare-event probability (or expectation) which is very small, e.g., less than 10 −4 . The general idea of importance sampling is to estimate the above rare-event probability l by drawing samples x from important regions of the search space with both a large density p(x; λ) and a large I S(x)≥α , i.e., I S(x)≥α = 1. In other words, we aim to find x such that S(x) ≥ α with high probability.</p><p>Importance sampling estimates l by sampling x from a distribution q * (x, α; λ) that should be proportional to I S(x)≥α p(x; λ). Specifically, define the proposal sampling density q(x) as a function such that q(x) = 0 implies I S(x)≥α p(x; λ) = 0 for every x. Then we have l(α) = I S(x)≥α p(x; λ) q(x) q(x)dx = E q I S(X)≥α p(X; λ) q(X) .</p><p>(1) [Rubinstein and <ref type="bibr">Kroese, 2013]</ref> shows that the optimal importance sampling probability density q which minimizes the variance of the empirical estimator of l(α) is the density of X conditional on the event S(X) ≥ α, that is q * (x, α; λ) = p(x; λ)I S(x)≥α I S(x)≥α p(x; λ)dx .</p><p>(2) However, noting that the denominator of ( <ref type="formula">2</ref>) is the quantity l(α) that we aim to estimate in the first place, we cannot obtain an explicit form of q * (.) directly. To overcome this issue, the CE method <ref type="bibr">[Homem-de Mello and Rubinstein, 2002]</ref> aims to choose the sampling probability density q(.) from the parametric families of densities {p(.; θ)} such that the Kullback-Leibler (KL)-divergence between the optimal importance sampling probability density q * (., α; λ), given by (2), and p(.; θ) is minimized.</p><p>The CE-Optimal solution θ * is given by</p><formula xml:id="formula_4">θ * = arg min θ KL q * (., α; λ)||p(.; θ) = arg max θ Eλ I S(X)≥α ln p(X; θ) = arg max θ E θ I S(X)≥α ln p(X; θ) p(X; λ) p(X; θ) ,<label>(3)</label></formula><p>given any prior sampling distribution parameter θ ∈ Θ. Let x 1 , . . . , x N be i.i.d samples from p(.; θ). Then an empirical estimate of θ * is given by</p><formula xml:id="formula_5">θ * = arg max θ 1 N N k=1 I S(x k )≥α p(x k ; λ) p(x k ; θ) ln p(x k ; θ). (4)</formula><p>In the case of rare events, where l(α) ≤ 10 −6 , solving the optimization problem (4) does not help us estimate the probability of the rare event (see <ref type="bibr">[Homem-de Mello and Rubinstein, 2002]</ref>). Algorithm 3 presents the multi-stage CE approach proposed in <ref type="bibr">[Homem-de Mello and Rubinstein, 2002]</ref> to overcome this problem. This iterative CE algorithm essentially creates a sequence of sampling probability densities p(.; θ 1 ), p(, ; θ 2 ), . . . that are steered toward the direction of the theoretically optimal density q * (., α; λ) in an iterative manner.</p><p>Algorithm 3 CE Method for rare-event estimation 1: Input: Level parameter α &gt; 0, some fixed parameter δ &gt; 0, and initial parameters λ and ρ.</p><formula xml:id="formula_6">2: t ← 1, ρ 0 ← ρ, θ 0 ← λ 3: while γ(θ t−1 , ρ t−1 ) &lt; α do 4: γ t−1 ← min(α, γ(θ t−1 , ρ t−1 )) 5: θ t ∈ arg max θ∈Θ Eλ I S(X)≥γt−1 ln p(X; θ) = arg min θ∈Θ KL(q * (., γ t−1 ; λ)||p(.; θ)) 6:</formula><p>Set ρ t such that γ(θ t , ρ t ) ≥ min(α, γ(θ t−1 , ρ t−1 ) + δ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>t ← t + 1. 8: end while More precisely, in Algorithm 3, we denote the threshold sequence by γ t for t ≥ 0, and sampling distribution parameters by θ t for t ≥ 0. Initially, choose ρ and γ( λ, ρ) so that γ( λ, ρ) is the (1 − ρ)-quantile of S(X) under the density p(.; λ), and generally, let γ(θ t , ρ t ) be the (1 − ρ t )-quantile of S(X) under the sampling density p(x; θ t ) of iteration t. Furthermore, the a priori sampling density parameter θ introduced in (3) and ( <ref type="formula">4</ref>) is replaced by the optimum parameter obtained in iteration t − 1, i.e., θ t−1 .</p><p>From (3), we notice that Step 4 in Algorithm 3 is equivalent to minimizing the KL-divergence between the following two densities, q(x, γ t−1 ; λ) = c −1 I S(x)≥γt−1 p(x; λ) and p(x; θ), where c = I S(x)≥γt−1 p(x; λ)dx, γ t−1 = min(α, γ(θ t−1 , ρ t−1 )). One can always choose a small δ in Step 5, which will determine the number of times the while loop is executed.</p><p>The following theorem which was first proved by <ref type="bibr">[Homemde Mello and Rubinstein, 2002]</ref> asserts that Algorithm 3 terminates. We provide a proof of Theorem A.1 as follows.</p><p>Theorem A.1. Assume that l(α) &gt; 0. Then, Algorithm 3 converges to a CE-optimal solution in a finite number of iterations.</p><p>Proof. Let t be an arbitrary iteration of the algorithm, and let ρ α := P (S(X) ≥ α; θ t ). It can be shown by induction that ρ α &gt; 0. Note that this is also true if p(x; θ) &gt; 0 for all θ, x. Next, we show that for every ρ t ∈ (0, ρ α ), γ(θ t , ρ t ) ≥ α. By the definition of γ, we have</p><formula xml:id="formula_7">P (S(X) ≥ γ(θ t , ρ t ); θ) ≥ ρ t , P (S(X) ≤ γ(θ t , ρ t ); θ) ≥ 1 − ρ t &gt; 1 − ρ α . (5)</formula><p>Suppose by contradiction, that γ(θ t , ρ t ) &lt; α. Then, we get P (S(X) ≤ γ(θ t , ρ t ); θ * ) ≤ P (S(X) ≤ α; θ t ) = 1 − ρ α , which contradicts (5). Thus, γ(θ t , ρ t ) ≥ α. This implies that</p><p>Step 5 can always be carried out for any δ &gt; 0. Consequently, Algorithm 3 terminates after T iterations with T ≤ α/δ . Thus at time T , we have θ T ∈ arg max θ∈Θ Eλ I S(X)≥α ln P (X; θ) , which implies that θ T is a CE-Optimal solution. Therefore, Algorithm 3 converges to a CE-Optimal solution in a finite number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proof of Theorem 3.1</head><p>Proof of Theorem 3.1. Let p(x; λ) be the initial sampling distribution over the initial set of architectures X 0 . We can consider γ 0 to be the (1 − ρ)-quantile under p(x; λ). Then, we can consider ρ, δ &gt; 0 and λ to be the inputs to Algorithm 3 of Section A.1. Furthermore, by having γ t &gt;= min(α, γ t−1 + δ), we can view γ t as the (1 − ρ t )-quantile under the sampling density p(x; θ t ) provided by the generator G(.; θ t ) at the t-th iteration, for all t ∈ {1, . . . , T }.</p><p>We now modify Algorithm 3 of Section A.1 by replacing the KL-divergence minimization of Step 5 of Algorithm 3 with minimizing the Jensen-Shannon (JS)-divergence to obtain Algorithm 4 for JS-divergence minimization for rare event simulation. Note that Step 4 of Algorithm 4 is equivalent to</p><p>Step 4 of Algorithm 1. Furthermore, the distribution of architectures in T , i.e., the distribution of top architectures in prior iteration in Algorithm 1, corresponds to q(x, γ t−1 ; λ) in Algorithm 4. By choosing k such that k = ρ t × | t−1 i=0 X i | and the above argument, we note that Algorithm 4 and Algorithm 1 are equivalent. Therefore, by showing that Algorithm 4 converges in a finite number of iterations, we imply that Algorithm 1 converges in a finite number of iterations.</p><p>Using the convergence result of Algorithm 3, we now show that Algorithm 4 converges in a finite number of iterations.</p><p>Consider the JS divergence between q(x, γ t−1 ; λ) = c −1 I S(x)≥γt−1 p(x; λ) and p(x; θ), where c =</p><formula xml:id="formula_8">I S(x)≥γt−1 p(x; λ)dx, γ t−1 = min(α, γ(θ t−1 , ρ t−1 )), which is JS(q(x, γ t−1 ; λ)||p(x; θ)) = 1 2 KL(c −1 p(x; λ)I S(X)≥γt−1 1 2 c −1 p(x; λ)I S(X)≥γt−1 + p(x; θ)) + 1 2 KL(p(x; θ) 1 2 (c −1 p(x; λ)I S(X)≥γt−1 + p(x; θ))).<label>(6)</label></formula><p>We say θ * is a JS-optimal solution, if θ * ∈ arg min θ∈Θ JS(q(x, γ t−1 ; λ)||p(x; θ)). ( <ref type="formula">7</ref>)</p><p>Algorithm 4 JS-divergence minimization for rare-event estimation 1: Input: Level parameter α &gt; 0, some fixed parameter δ &gt; 0, and initial parameters λ and ρ.</p><formula xml:id="formula_9">2: t ← 1, ρ 0 ← ρ, θ 0 ← λ 3: while γ(θ t−1 , ρ t−1 ) &lt; α do 4:</formula><p>θ t ∈ arg min θ∈Θ JS(q(x, γ t−1 ; λ)||p(x; θ)), where γ t−1 = min(α, γ(θ t−1 , ρ t−1 )) and q(x, γ t−1 ; λ) = I S(x)≥γt−1 p(x; λ) I S(x)≥γt−1 p(x; λ)dx .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Set ρ t such that γ(θ t , ρ t ) ≥ min(α, γ(θ t−1 , ρ t−1 ) + δ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>t ← t + 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7: end while</head><p>The assumption that max x∈X S(x) ≥ α, for some α &gt; 0, implies the assumption of Theorem A.1, i.e., l(α) &gt; 0. Then, following the same arguments as in the proof of Theorem A.1, the assertion of Theorem A.1 still holds for the case of JSdivergence minimization of Algorithm 4, and consequently, Algorithm 1 converges to a JS-optimal solution in a finite number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Model Details</head><p>Pairwise Architecture Discriminator Consider the case where we search for a cell architecture C, the input to D is a pair of cells (C true , C ), where C true denotes a cell from the current truth data, while C is a cell from either the truth data or the generator's learned distribution. We transform each cell in the pair into a graph embedding vector using a shared k-GNN model. The graph embedding vectors of the input cells are then concatenated and passed to an MLP for classification. We train D in a supervised fashion and minimize the cross-entropy loss between the target labels and the predictions. To create the training data for D, we first sample T unique cells from the current truth data. We create positive training samples by pairing each truth cell against every other truth cell. We then let the generator generate |T | unique and valid cells as fake data and pair each truth cell against all the generated cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Architecture Generator</head><p>A complete architecture is constructed in an auto-regressive fashion. We define the state at the t-th time step as C t , which is a partially constructed graph. Given the state C t−1 , the actor inserts a new node. The action a t is composed of an operator type for this new node selected from a predefined operation space and its connections to previous nodes. We define an episode by a trajectory τ of length N as the state transitions from C 0 to C N −1 , i.e., τ = {C 0 , C 1 , . . . , C N −1 }, where N is an upper bound that limits the number of steps allowed in graph construction. The actor model follows an Training Procedure of the Architecture Generator The state transition is captured by a policy π θ (a t |C t ), where the action a t includes predictions on a new node type and its connections to previous nodes. To learn π θ (a t |C t ) in this discrete action space, we adopt the Proximal Policy Optimization (PPO) algorithm with generalized advantage estimation. The actor is trained by maximizing the cumulative expected reward of the trajectory. For a trajectory τ with a maximum allowed length of N , this objective translates to max</p><formula xml:id="formula_10">E[R(τ )] = max E[R step (τ )] + E[R f inal (τ )] s.t. |τ | ≤ N,<label>(8)</label></formula><p>where R step and R f inal correspond the per-step reward and the final reward, respectively, which will be described in the following.</p><p>In the context of cell-based micro search, there is a step reward R step , which is given to the actor after each action, and a final reward R f inal , which is only assigned at the end of a multi-step generation episode. For R step , we assign the generator a step reward of 0 if a t is valid. Otherwise, we assign −0.1 and terminate the episode immediately.</p><p>R f inal consists of two parts. The first part is a validity score R v . For a completed cell C gen , if it is a valid DAG and contains exactly one output node, and there is at least one path from every other node to the output, then the actor receives a validity score of R v (C gen ) = 0. Otherwise, the validity score will be −0.1 multiplied by the number of validity violations. In our search space, we define four possible violations: 1) There is no output node; 2) There is a node with no incoming edges; 3) There is a node with no outgoing edges; 4) There is a node with no incoming or outgoing edges. The second part of R f inal is R D (C gen ), which represents the probability that the discriminator classifies C gen as a cell from the truth data distribution p data (x). In order to receive R D (C gen ) from the discriminator, C gen must have a validity score of 0 and C gen cannot be one of the current truth cells {C j true |j = 1, 2, ...K}.</p><p>Formally, we express the final reward R f inal for a generated architecture C gen as</p><formula xml:id="formula_11">R f inal = R v (C gen ) if I(C gen ), R v (C gen ) + R D (C gen ) otherwise. (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>And I(C gen ) = R v (C gen ) &lt; 0 or C gen ∈ {C j true |j = 1, 2, ...K}. We compute R D (C gen ) by conducting pairwise comparisons against the current truth cells, then take the maximum probability that the discriminator will predict a 1, i.e., R D = max j P (C gen ∈ p data (x)|C gen , C j true ; D), for j = 1, 2, ...K, as the discriminator reward.</p><p>Maintaining the right balance of exploration/exploitation is crucial for a NAS algorithm. In GA-NAS, the architecture generator and discriminator provide an efficient way to utilize learned knowledge, i.e., exploitation. For exploration, we make sure that the generator always have some uncertainties in its actions by tuning the multiplier for the entropy loss in the PPO learning objective. The entropy loss determines the amount of randomness, hence, variations in the generated actions. Increasing its multiplier would increase the impact of the entropy loss term, which results in more exploration. In our experiments, we have tuned this multiplier extensively and found that a value of 0.1 works well for the tested search spaces.</p><p>Last but not least, it is worth mentioning that the above formulation of the reward function also works for the single-path macro search scenario, such as EfficientNet and Proxyless-NAS search spaces, in which we just need to modify R step and R D (C gen ) according to the definitions of the new search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Experimentation</head><p>In this section, we present ablation studies and the results of additional experiments. We also provide more details on our experimental setup. We implement GA-NAS using Py-Torch 1.3. We also use the PyTorch Geometric library for the implementation of k-GNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>More Ablation Studies</head><p>We report the results of ablation studies to show the effect of different components of GA-NAS on its performance.</p><p>Standard versus Pairwise Discriminator: In order to investigate the effect of pairwise discriminator in GA-NAS explained in section 3, we perform the same experiments as in Table <ref type="table" target="#tab_1">2</ref>, with the standard discriminator where each architecture ∈ T is compared against a generated architecture ∈ F. The results presented in Table <ref type="table" target="#tab_9">8</ref> indicate that using pairwise discriminator leads to a better performance compared to using standard discriminator.</p><p>Uniform versus linear sample size increase with fixed number of evaluation budget: Once the generator in Algorithm 1 is trained, we sample |X t | architectures X t . Intuitively, as the algorithm progresses, G becomes more and more accurate, thus, increasing the size of X t over the iterations should prove advantageous. We provide some evidence that this is the case. More precisely, we perform the same experiments as in Table <ref type="table" target="#tab_1">2</ref>; however, keeping the total number of generated cell architectures during the 10 iterations of the algorithm the same as that in the setup of Table <ref type="table" target="#tab_1">2</ref>, we generate a constant number of cell architectures of 225 and 450 in each iteration of the algorithm in setup1 and setup2, respectively. The results presented in Table <ref type="table" target="#tab_10">9</ref> indicate that a linear increase in the size of generated cell architectures leads to a better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pareto Front Search Results on NAS-Bench-101</head><p>In addition to constrained search, we search through Pareto frontiers to further illustrate our algorithm's ability to learn any given truth set. We consider test accuracy vs. normalized training time and found that the truth Pareto front of NAS-Bench-101 contains 41 cells. To reduce variance, we always initialize with the worst 50% of cells in terms of accuracy and training time, which amounts to 82,329 cells. We modify GA-NAS to take a Pareto neighborhood of size 4 in each iteration, which is defined as iteratively removing the cells in the current Pareto front and finding a new front using the remaining cells, until we have collected cells from 4 Pareto fronts. We run GA-NAS for 10 iterations and compare with a random search baseline. GA-NAS issued 2,869 unique queries (#Q) to the benchmark, so we set the #Q for random search to 3,000 for a fair comparison. Figure <ref type="figure" target="#fig_5">4</ref> showcases the effectiveness of GA-NAS in uncovering the Pareto front. While random search also finds a Pareto front that is close to the truth, a small gap is still visible. In comparison, GA-NAS discovers a better Pareto front with a smaller number of queries. GA-NAS finds 10 of the 41 cells on the truth Pareto front, and random search only finds 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameter Setup</head><p>Table <ref type="table" target="#tab_8">10</ref> reports the key hyper-parameters used in our NAS-Bench-101, 201 and 301 experiments, which includes (1) bestaccuracy search by querying the true accuracy (Acc), (2) bestaccuracy search using the supernet (Acc-WS), (3) constrained best-accuracy search (Acc-Cons), and (4) Pareto front search (Pareto).</p><p>Here, we include a brief description for some parameters in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supernet Training and Usage</head><p>To train a supernet for NAS-Bench-101, we first set up a macro-network in the same way as the evaluation network of NAS-Bench-101. Our supernet has 3 stacks with 3 supercells per stack. A downsampling layer consisting of a Maxpooling 2-by-2 and a Convolution 1-by-1 is inserted after the first and second stack to halve the input width/height and double the channels. Each supercell contains 5 searchable nodes. In a NAS-Bench-101 cell, the output node performs concatenation of the input features. However, this is not easy to handle in a supercell. Therefore, we replace the concatenation with summation and do not split channels between different nodes in a cell.</p><p>We train the supernet on 40,000 randomly sampled CIFAR-10 training data and leave the other 10,000 as validation data. We set an initial channel size of 64 and a training batch size of 128. We adopt a uniformly random strategy for training, i.e., for every batch of training data, we first uniformly sample an edge topology, then, we uniformly sample one operator type for every searchable node in the topology. Following this strategy, we train for 500 epochs using the Adam optimizer and an initial learning rate of 0.001. We change the learning rate to 0.0001 when the training accuracy do not improve for 50 consecutive epochs.</p><p>During search, after we acquire the set of cells (X ) to evaluate, we first fine-tune the current supernet for another 50 epochs. The main difference here compared to training a supernet from scratch is that for a batch of training data, we randomly sample a cell from X instead of from the complete search space. We use the Adam optimizer with a learning rate of 0.0001. Then, we get the accuracy of every cell in X by testing on the validation data and by inheriting the corresponding weights of the supernet. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ResNet and Inception Cells in NAS-Bench-101</head><p>Figure <ref type="figure">5</ref> illustrates the structures of the ResNet and Inception cells used in our constrained best-acc search. Note that both cells are taken from the NAS-Bench-101 database as is, there might be small differences in their structures compared to the original definitions. Table <ref type="table" target="#tab_5">6</ref> reports that the ResNet cell has a lot more weights than the inception cell, even though it contains fewer operators. This is because NAS-Bench-101 performs channel splitting so that each operator in a branched path will have a much fewer number of trainable weights.</p><p>We then present the two best cell structures found by GA-NAS that are better than the ResNet and Inception cells, respectively, in Figure <ref type="figure" target="#fig_7">6</ref>. Both cells are also in the NAS-Bench-101 database. Observe that both cells contain multiple branches coming from the input node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>More on NAS-Bench-101 and NAS-Bench-201</head><p>We summarize essential statistical information about NAS-Bench-101 and NAS-Bench-201 in Table <ref type="table" target="#tab_12">11</ref>. The purpose is to establish a common ground for comparisons. Future NAS works who wish to compare to our experimental results directly can check Table <ref type="table" target="#tab_12">11 to</ref>  We want the re-emphasize that for each cell in NAS-Bench-101, we take the average of the final test accuracy at epoch 108 over 3 runs as its true test accuracy. For NAS-Bench-201, we take the labeled accuracy on the test sets. Since there is a single edge topology for all cells in NAS-Bench-201, there is no need to predict the edge connections; hence, we remove the GRU in the decoder and only predict the node types of 6 searchable nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clarification on Cell Ranking</head><p>We would like to clarify that all ranking results reported in the paper are based on the un-rounded true accuracy. In addition, if two cells have the same accuracy, we randomly rank one before the other, i.e. no two cells will have the same ranking.</p><p>Conversion from DARTS-like Cells to the NAS-Bench-101 Format DARTS-like cells, where an edge represents a searchable operator, and a node represents a feature map that is the sum of    multiple edge operations, can be transformed into the format of NAS-Bench-101 cells, where nodes represent searchable operators and edges determine data flow. For a unique, discrete cell, we assume that each edge in a DARTS-like cell can adopt a single unique operator. We achieve this transformation by first converting each edge in a DARTS-like cell to a NAS-Bench-101 node. Next, we construct the dependency between NAS-Bench-101 nodes from the DARTS nodes, which enables us to complete the edge topology in a new NAS-Bench-101 cell. Figure <ref type="figure" target="#fig_8">7</ref> shows a DARTS-like cell defined by NAS-Bench-201 and the transformed NAS-Bench-101 cell. This transformation is a necessary first step to make GA-NAS compatible with NAS-Bench-201 and NAS-Bench-301. Notice that every DARTS-like cell has the same edge topology in the NAS-Bench-101 format, which alleviates the need for a dedicated edge predictor in the decoder of G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EfficientNet and ProxylessNAS Search Space</head><p>For EfficientNet experiment, we take the EfficientNet-B0 network structure as the backbone and define 7 searchable locations, as indicated by the TBS symbol in Table <ref type="table" target="#tab_13">12</ref>. We run GA-NAS to select a type of mobile inverted bottleneck MBConv block. We search for different expansion ratios {1, 3 ,6} and kernel size {3, 5} combinations, which results in 6 candidate MBConv blocks per TBS location. We conduct 2 GA-NAS searches with different performance estimation methods. In setup 1 we estimate the performance of a candidate network by training it on CIFAR-10 for 20 epochs then compute the test accuracy. In setup 2 we first train a weight-sharing Supernet that has the same structure as the backbone in Table <ref type="table" target="#tab_13">12</ref>, for 500 epochs, and using a ImageNet-224-120 dataset that is subsampled the same way as NAS-Bench-201. The estimated performance in this case is the validation accuracy a candidate network could achieve on ImageNet-224-120 by inheriting weights from the Supernet. For setup 2, training the supernet takes about 20 GPU days on Tesla V100 GPUs, and search takes another GPU day, making a total of 21 GPU days. Figure <ref type="figure" target="#fig_9">8</ref> presents a visualization on the three single-path networks found by GA-NAS on the EfficientNet search space. Compared to EfficientNet-B0, GA-NAS-ENet-1 significantly reduces the number of trainable weights while maintaining an acceptable accuracy. GA-NAS-ENet-2 improves the accuracy while also reducing the model size. GA-NAS-ENet-3 improves the accuracy further.</p><p>For ProxylessNAS experiment, we take the ProxylessNAS network structure as the backbone and define 21 searchable locations, as indicated by the TBS symbol in Table <ref type="table" target="#tab_14">13</ref>. We run GA-NAS to search for MBConv blocks with different expansion ratios {3 ,6} and kernel size {3, 5, 7} combinations, which results in 6 candidate MBConv blocks per TBS location. We train a supernet on ImageNet for 160 epochs (which is the same number of epochs performed by ProxylessNAS weight-sharing search <ref type="bibr">[Cai et al., 2018]</ref>) for around 20 GPU days, and conduct an unconstrained search using GA-NAS for around 38 hours on 8 Tesla V100 GPUs in the search space of ProxylessNAS <ref type="bibr">[Cai et al., 2018]</ref>, a major portion out of which, i.e., 29 hours is spent on querying the supernet for architecture performance. Figure <ref type="figure" target="#fig_10">9</ref> presents a visualization of the best architecture found by GA-NAS-ProxylessNAS with better top-1 accuracy and a comparable the number of trainable weights compared to ProxylessNAS-GPU.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The flow of the proposed GA-NAS algorithm.</figDesc><graphic url="image-1.png" coords="3,321.30,54.00,230.39,85.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>illustrates the overall training flow of GA-NAS. Algorithm 2 Training Discriminator D and the Generator G 1: Input: Discriminator D; Generator G(x; θ t−1 ); Data set T . 2: for t = 1, 2, . . . , T do 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: NAS-Bench-301 results comparing the means/standard deviations of the best accuracy found at various total query limits.</figDesc><graphic url="image-2.png" coords="5,323.10,138.66,226.79,179.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The structure of a GNN architecture generator for cell-based micro search.</figDesc><graphic url="image-3.png" coords="10,108.00,54.00,395.98,142.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>ensure a matching benchmark setting. There are 3 candidate operators for NAS-Bench-101, (1) A sequence of convolution 3-by-3, batch normalization (BN), and ReLU activation (Conv3×3-BN-ReLU), (2) Conv1×1-BN-ReLU, (3) Maxpool3×3. NAS-Bench-201 defines 5 operator choices: (1) zeroize, (2) skip connection, (3) ReLU-Conv1×1-BN, (4) ReLU-Conv3×3-BN, (5) Averagepool3×3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Pareto Front search on NAS-Bench-101. Observe that GA-NAS nearly recovers the truth Pareto Front while Random Search (RS) only discovers one close to the truth. #Q represents the total number of unique queries made to the benchmark. Each marker represents a cell on the Pareto front.</figDesc><graphic url="image-4.png" coords="12,62.84,470.50,241.92,180.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 5: Structures of the ResNet and Inception cells, which are considered hand-crafted architectures in our constrained best-accuracy search.</figDesc><graphic url="image-6.png" coords="13,65.36,118.81,100.80,157.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The structures of the best two cells found by GA-NAS that are better than the ResNet and Inception cells in terms of test accuracy, training time and number of weights.</figDesc><graphic url="image-8.png" coords="13,65.36,460.85,251.99,130.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Illustration of how to transform a DARTS-like cell (top) in NAS-Bench-201 to the NAS-Bench-101 format (bottom).</figDesc><graphic url="image-10.png" coords="15,162.00,54.00,288.00,238.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Structures of the single-path networks found by GA-NAS on the EfficientNet search space. In each MBConv block, e denotes expansion ratio and k stands for kernel size.</figDesc><graphic url="image-11.png" coords="16,162.00,58.74,288.00,201.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Structures of the single-path networks found by GA-NAS on the ProxylessNAS search space.</figDesc><graphic url="image-12.png" coords="16,108.00,307.32,395.99,63.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Siems et al., 2020]. The goal is to discover the highest ranked cell with as few queries as possible. The number of queries to the NAS benchmark is used as a reliable measure for search cost in recent NAS literature[Luo et al., 2020; Siems et al., 2020], because each query to the NAS benchmark corresponds to training and evaluating a candidate architecture from scratch, which constitutes the major bottleneck in the overall cost of NAS. By checking the rank an algorithm can reach in a given number of queries, one can also evaluate the convergence speed of a search algorithm. The best accuracy values found by different search algorithms on NAS-Bench-101 without weight sharing. Note that 94.23% and 94.22% are the accuracies of the 2nd and 3rd best cells. †: taken from [Luo et al., 2020] on NAS-Bench-101 and compare GA-NAS with a range of NAS schemes based on weight sharing. NAS-Bench-101 is the first publicly available benchmark for evaluating NAS algorithms. It consists of 423,624 DAG-style cell-based architectures, each trained and evaluated for 3 times. Metrics for each run include training time and accuracy. Querying NAS-Bench-101 corresponds to evaluating a cell in reality.</figDesc><table><row><cell>To evaluate search algorithm and decouple it from the impact</cell></row><row><cell>of search spaces, we query three NAS benchmarks: NAS-</cell></row><row><cell>Bench-101 [Ying et al., 2019], NAS-Bench-201 [Dong and</cell></row><row><cell>Yang, 2020], and NAS-Bench-301 [</cell></row></table><note>More queries made to the benchmark would indicate a longer evaluation time or higher search cost in a real-world problem.To further evaluate our algorithm when the true architecture accuracies are unknown, we train a weight-sharing supernet</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Setup1 94.22 ± 4.45e-5 2.90 647.50 ± 433.43 GA-NAS-Setup2 94.23 ± 7.43e-5 2.50 1561.80 ± 802.13</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Mean Acc (%)</cell><cell>Mean Rank</cell><cell>Average #Q</cell></row><row><cell></cell><cell cols="2">Random Search</cell><cell>93.84 ± 0.13</cell><cell>498.80</cell><cell>648</cell></row><row><cell></cell><cell cols="2">Random Search</cell><cell>93.92 ± 0.11</cell><cell>211.50</cell><cell>1562</cell></row><row><cell cols="4">GA-NAS-Algorithm Mean Acc Best Acc Best Rank</cell></row><row><cell>DARTS  †</cell><cell>92.21 ± 0.61</cell><cell>93.02</cell><cell>57079</cell></row><row><cell>NAO  †</cell><cell>92.59 ± 0.59</cell><cell>93.33</cell><cell>19552</cell></row><row><cell>ENAS  †</cell><cell>91.83 ± 0.42</cell><cell>92.54</cell><cell>96939</cell></row><row><cell>GA-NAS</cell><cell>92.80 ± 0.54</cell><cell>93.46</cell><cell>5386</cell></row></table><note>The average statistics of the best cells found on NAS-Bench-101 without weight sharing, averaged over 10 runs (with std shown). Note that we set the number of queries (#Q) for Random Search to be the same as the average number of queries incurred by GA-NAS.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Searching on NAS-Bench-101 with weight-sharing, with the mean test accuracy of the best cells from 10 runs, and the best accuracy/rank found by a single run. †: taken from[Yu et al., 2019]    </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Searching on NAS-Bench-201 without weight sharing, with the mean accuracy and rank of the best cell found reported. #Q represents the average number of queries per run. We conduct 20 runs for GA-NAS.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell cols="2">CIFAR-100</cell><cell></cell><cell cols="2">ImageNet-16-120</cell></row><row><cell cols="2">Algorithm</cell><cell cols="2">Mean Acc</cell><cell cols="2">Rank #Q</cell><cell>Mean Acc</cell><cell cols="2">Rank #Q</cell><cell>Mean Acc</cell><cell>Rank #Q</cell></row><row><cell cols="2">REA  †</cell><cell cols="2">93.92 ± 0.30</cell><cell>-</cell><cell>-</cell><cell>71.84 ± 0.99</cell><cell>-</cell><cell>-</cell><cell>45.54 ± 1.03</cell><cell>-</cell><cell>-</cell></row><row><cell>RS  †</cell><cell></cell><cell cols="2">93.70 ± 0.36</cell><cell>-</cell><cell>-</cell><cell>71.04 ± 1.07</cell><cell>-</cell><cell>-</cell><cell>44.57 ± 1.25</cell><cell>-</cell><cell>-</cell></row><row><cell cols="4">REINFORCE  † 93.85 ± 0.37</cell><cell>-</cell><cell>-</cell><cell>71.71 ± 1.09</cell><cell>-</cell><cell>-</cell><cell>45.24 ± 1.18</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">BOHB  †</cell><cell cols="2">93.61 ± 0.52</cell><cell>-</cell><cell>-</cell><cell>70.85 ± 1.28</cell><cell>-</cell><cell>-</cell><cell>44.42 ± 1.49</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">RS-500</cell><cell cols="4">94.11 ± 0.16 30.81 500</cell><cell cols="3">72.54 ± 0.54 30.89 500</cell><cell cols="2">46.34 ± 0.41 34.18 500</cell></row><row><cell cols="2">GA-NAS</cell><cell cols="2">94.34 ± 0.05</cell><cell>4.05</cell><cell>444</cell><cell>73.28 ± 0.17</cell><cell>3.25</cell><cell>444</cell><cell>46.80 ± 0.29</cell><cell>7.40</cell><cell>445</cell></row><row><cell cols="9">† The results are taken directly from NAS-Bench-201 [Dong and Yang, 2020].</cell><cell></cell></row><row><cell>Algorithm</cell><cell cols="2">Avg. Acc</cell><cell cols="2">Avg. Rank</cell><cell cols="2">Avg. #Q</cell><cell></cell><cell></cell><cell></cell></row><row><cell>RL-NAS-1</cell><cell cols="2">94.14 ± 0.10</cell><cell>20.8</cell><cell></cell><cell cols="2">7093 ± 3904</cell><cell></cell><cell></cell><cell></cell></row><row><cell>RL-NAS-2</cell><cell cols="2">93.78 ± 0.14</cell><cell>919.0</cell><cell></cell><cell cols="2">314 ± 300</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">GA-NAS-Setup1 94.22± 4.5e-5</cell><cell>2.9</cell><cell></cell><cell cols="2">648 ± 433</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">GA-NAS-Setup2 94.23± 7.4e-5</cell><cell>2.5</cell><cell></cell><cell cols="2">1562 ± 802</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Results of ablation study on NAS-Bench-101 by removing the discriminator and directly queries the benchmark for reward.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Constrained search results on NAS-Bench-101. GA-NAS can find cells that are superior to the ResNet and Inception cells in terms of test accuracy, training time, and the number of weights.</figDesc><table><row><cell></cell><cell></cell><cell>ResNet</cell><cell></cell></row><row><cell>Algorithm</cell><cell cols="3">Best Acc Train Seconds #Weights (M)</cell></row><row><cell>Hand-crafted</cell><cell>93.18</cell><cell>2251.6</cell><cell>20.35</cell></row><row><cell>Random Search</cell><cell>93.84</cell><cell>1836.0</cell><cell>10.62</cell></row><row><cell>GA-NAS</cell><cell>93.96</cell><cell>1993.6</cell><cell>11.06</cell></row><row><cell></cell><cell></cell><cell>Inception</cell><cell></cell></row><row><cell>Algorithm</cell><cell cols="3">Best Acc Train Seconds #Weights (M)</cell></row><row><cell>Hand-crafted</cell><cell>93.09</cell><cell>1156.0</cell><cell>2.69</cell></row><row><cell>Random Search</cell><cell>93.14</cell><cell>1080.4</cell><cell>2.18</cell></row><row><cell>GA-NAS</cell><cell>93.28</cell><cell>1085.0</cell><cell>2.69</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Results on the EfficientNet and ProxylessNAS spaces.</figDesc><table><row><cell>Network</cell><cell cols="2">#Params Top-1 Acc</cell></row><row><cell>EfficientNet-B0 (no augment)</cell><cell>5.3M</cell><cell>76.7</cell></row><row><cell>GA-NAS-ENet-1</cell><cell>4.6M</cell><cell>76.5</cell></row><row><cell>GA-NAS-ENet-2</cell><cell>5.2M</cell><cell>76.8</cell></row><row><cell>GA-NAS-ENet-3</cell><cell>5.3M</cell><cell>76.9</cell></row><row><cell>ProxylessNAS-GPU</cell><cell>4.4M</cell><cell>75.1</cell></row><row><cell>GA-NAS-ProxylessNAS</cell><cell>4.9M</cell><cell>75.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>[Bender et al., 2020]  Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang Cheng, Pieter-Jan Kindermans, and Quoc V Le. Can weight sharing outperform random architecture search? an investigation with tunas. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14323-14332, 2020. [Cai et al., 2018] Han Cai, Ligeng Zhu, and Song Han. Proxylessnas: Direct neural architecture search on target task and hardware. arXiv preprint arXiv:1812.00332, 2018. [Dai et al., 2020] Xiaoliang Dai, Alvin Wan, Peizhao Zhang, Bichen Wu, Zijian He, Zhen Wei, Kan Chen, Yuandong Tian, Matthew Yu, Peter Vajda, et al. Fbnetv3: Joint architecture-recipe search using neural acquisition function. arXiv preprint arXiv:2006.02049, 2020. [Dong and Yang, 2020] Xuanyi Dong and Yi Yang. Nasbench-201: Extending the scope of reproducible neural architecture search. In International Conference on Learning Representations, 2020. [Elsken et al., 2018] Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. arXiv preprint arXiv:1808.05377, 2018. [Goodfellow et al., 2014] Ian Goodfellow, Jean Pouget-</figDesc><table><row><cell></cell><cell></cell><cell>[Morris et al., 2019] Christopher Morris, Martin Ritzert,</cell></row><row><cell></cell><cell></cell><cell>Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gau-</cell></row><row><cell></cell><cell></cell><cell>rav Rattan, and Martin Grohe. Weisfeiler and leman go neu-</cell></row><row><cell></cell><cell></cell><cell>ral: Higher-order graph neural networks. In Proceedings of</cell></row><row><cell></cell><cell></cell><cell>the AAAI Conference on Artificial Intelligence, volume 33,</cell></row><row><cell></cell><cell></cell><cell>pages 4602-4609, 2019.</cell></row><row><cell></cell><cell></cell><cell>[Pham et al., 2018] Hieu Pham, Melody Y Guan, Barret</cell></row><row><cell></cell><cell></cell><cell>Zoph, Quoc V Le, and Jeff Dean. Efficient neural ar-</cell></row><row><cell></cell><cell></cell><cell>chitecture search via parameter sharing. arXiv preprint</cell></row><row><cell></cell><cell></cell><cell>arXiv:1802.03268, 2018.</cell></row><row><cell></cell><cell></cell><cell>[Rubinstein and Kroese, 2013] Reuven Y Rubinstein and</cell></row><row><cell></cell><cell></cell><cell>Dirk P Kroese. The cross-entropy method: a unified ap-</cell></row><row><cell></cell><cell></cell><cell>proach to combinatorial optimization, Monte-Carlo simu-</cell></row><row><cell></cell><cell></cell><cell>lation and machine learning. Springer Science &amp; Business</cell></row><row><cell></cell><cell></cell><cell>Media, 2013.</cell></row><row><cell></cell><cell></cell><cell>[Siems et al., 2020] Julien Siems, Lucas Zimmer, Arber Zela,</cell></row><row><cell></cell><cell></cell><cell>Jovita Lukasik, Margret Keuper, and Frank Hutter. Nas-</cell></row><row><cell></cell><cell></cell><cell>bench-301 and the case for surrogate benchmarks for neu-</cell></row><row><cell></cell><cell></cell><cell>ral architecture search. arXiv preprint arXiv:2008.09777,</cell></row><row><cell></cell><cell></cell><cell>2020.</cell></row><row><cell></cell><cell></cell><cell>[Tan and Le, 2019] Mingxing Tan and Quoc V Le. Efficient-</cell></row><row><cell></cell><cell></cell><cell>net: Rethinking model scaling for convolutional neural</cell></row><row><cell></cell><cell></cell><cell>networks. arXiv preprint arXiv:1905.11946, 2019.</cell></row><row><cell></cell><cell></cell><cell>[Tan et al., 2019] Mingxing Tan, Bo Chen, Ruoming Pang,</cell></row><row><cell></cell><cell></cell><cell>Vijay Vasudevan, Mark Sandler, Andrew Howard, and</cell></row><row><cell></cell><cell></cell><cell>Quoc V Le. Mnasnet: Platform-aware neural architecture</cell></row><row><cell></cell><cell></cell><cell>search for mobile. In Proceedings of the IEEE Confer-</cell></row><row><cell></cell><cell></cell><cell>ence on Computer Vision and Pattern Recognition, pages</cell></row><row><cell></cell><cell></cell><cell>2820-2828, 2019.</cell></row><row><cell cols="2">Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sher-</cell><cell>[White et al., 2019] Colin White, Willie Neiswanger, and</cell></row><row><cell cols="2">jil Ozair, Aaron Courville, and Yoshua Bengio. Generative</cell><cell>Yash Savani. Bananas: Bayesian optimization with neural</cell></row><row><cell cols="2">adversarial nets. In Advances in neural information pro-</cell><cell>architectures for neural architecture search. arXiv preprint</cell></row><row><cell cols="2">cessing systems, pages 2672-2680, 2014.</cell><cell>arXiv:1910.11858, 2019.</cell></row><row><cell cols="2">[Homem-de Mello and Rubinstein, 2002] Tito Homem-de</cell><cell>[Xie et al., 2018] Sirui Xie, Hehui Zheng, Chunxiao Liu, and</cell></row><row><cell cols="2">Mello and Reuven Y Rubinstein. Rare event estimation for</cell><cell>Liang Lin. Snas: stochastic neural architecture search.</cell></row><row><cell cols="2">static models via cross-entropy and importance sampling.</cell><cell>arXiv preprint arXiv:1812.09926, 2018.</cell></row><row><cell>2002.</cell><cell></cell><cell>[Yang et al., 2019] Antoine Yang, Pedro M Esperança, and</cell></row><row><cell>[Jolicoeur-Martineau, 2018] Alexia</cell><cell>Jolicoeur-Martineau.</cell><cell>Fabio M Carlucci. Nas evaluation is frustratingly hard.</cell></row><row><cell cols="2">The relativistic discriminator: a key element missing from</cell><cell>arXiv preprint arXiv:1912.12522, 2019.</cell></row><row><cell cols="2">standard gan. arXiv preprint arXiv:1807.00734, 2018.</cell><cell>[Ying et al., 2019] Chris Ying, Aaron Klein, Eric Chris-</cell></row><row><cell cols="2">[Kandasamy et al., 2018] Kirthevasan Kandasamy, Willie</cell><cell>tiansen, Esteban Real, Kevin Murphy, and Frank Hutter.</cell></row><row><cell cols="2">Neiswanger, Jeff Schneider, Barnabas Poczos, and Eric P</cell><cell>Nas-bench-101: Towards reproducible neural architecture</cell></row><row><cell cols="2">Xing. Neural architecture search with bayesian optimisation</cell><cell>search. In International Conference on Machine Learning,</cell></row><row><cell cols="2">and optimal transport. In Advances in neural information</cell><cell>pages 7105-7114, 2019.</cell></row><row><cell cols="2">processing systems, pages 2016-2025, 2018.</cell><cell>[You et al., 2018] Jiaxuan You, Bowen Liu, Zhitao Ying, Vi-</cell></row><row><cell cols="2">[Li and Talwalkar, 2020] Liam Li and Ameet Talwalkar. Ran-</cell><cell>jay Pande, and Jure Leskovec. Graph convolutional policy</cell></row><row><cell cols="2">dom search and reproducibility for neural architecture</cell><cell>network for goal-directed molecular graph generation. In</cell></row><row><cell cols="2">search. In Uncertainty in Artificial Intelligence, pages</cell><cell>Advances in neural information processing systems, pages</cell></row><row><cell>367-377. PMLR, 2020.</cell><cell></cell><cell>6410-6421, 2018.</cell></row><row><cell cols="2">[Liu et al., 2018] Hanxiao Liu, Karen Simonyan, and Yiming</cell><cell>[Yu et al., 2019] Kaicheng Yu, Christian Sciuto, Martin Jaggi,</cell></row><row><cell cols="2">Yang. Darts: Differentiable architecture search. arXiv</cell><cell>Claudiu Musat, and Mathieu Salzmann. Evaluating the</cell></row><row><cell>preprint arXiv:1806.09055, 2018.</cell><cell></cell><cell>search phase of neural architecture search. arXiv preprint</cell></row><row><cell></cell><cell></cell><cell>arXiv:1902.08142, 2019.</cell></row></table><note>[Luo et al., 2020]  Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Enhong Chen, and Tie-Yan Liu. Semi-supervised neural architecture search. arXiv preprint arXiv:2002.10389, 2020.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 .</head><label>10</label><figDesc>• # Eval base (|X 1 |) is the number of unique, valid cells to be generated by G after the first iteration of D and G training, i.e., last step of an iteration of Algorithm. 1.• # Eval inc (|X t | − |X t−1 |)is the increment to the number of generated cells after completing an iteration. From the CE method and importance sampling described in Sec. A.1, the early generator distribution is not close enough to the well-performing cell architecture. To lower the number of queries to the benchmark without sacrificing the performance, we propose an incremental increase in the number of generated cell architectures at each iteration. • Init method describes how to choose the initial set of cells, from which we create the initial truth set. For most experiments, we randomly choose |X 0 | number of cells as the initial set. For the Pareto front search, we initialize with cells that rank in the lower 50% in terms of both test accuracy and training time (which constitutes 82,329 cells in NAS-Bench-101). • Truth set size (T ) controls the number of truth cells for training D. For best-accuracy searches, we take the top most accurate cells found so far. For Pareto front searches, we iteratively collect the cells on the current Pareto front, then remove them from the current pool, then find a new Pareto front, until we visit the desired number of Pareto fronts. For the complete set of hyper-parameters, please check out our code.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>The mean accuracy and rank, and average number of queries over 10 runs.</figDesc><table><row><cell>Algorithm</cell><cell>Mean Acc</cell><cell>Mean Rank</cell><cell>Average #Q</cell></row><row><cell>GA-NAS-Setup1 with pairwise discriminator</cell><cell>94.221± 4.45e-5</cell><cell>2.9</cell><cell>647.5 ± 433.43</cell></row><row><cell>GA-NAS-Setup1 without pairwise discriminator</cell><cell>94.22± 0.0</cell><cell>3</cell><cell>771.8 ± 427.51</cell></row><row><cell>GA-NAS-Setup2 with pairwise discriminator</cell><cell>94.227± 7.43e-5</cell><cell>2.5</cell><cell>1561.8 ± 802.13</cell></row><row><cell>GA-NAS-Setup2 without pairwise discriminator</cell><cell>94.22± 0.0</cell><cell>3</cell><cell>897 ± 465.20</cell></row><row><cell>Algorithm</cell><cell>Mean Acc</cell><cell>Mean Rank</cell><cell>Average #Q</cell></row><row><cell cols="2">GA-NAS-Setup1 (|Xt| = |Xt−1| + 50, ∀t ≥ 2) 94.221 ± 4.45e-5</cell><cell>2.9</cell><cell>647.5 ± 433.43</cell></row><row><cell>GA-NAS-Setup1 (|Xt| = 225, ∀t ≥ 2)</cell><cell>94.21± 0.000262</cell><cell>3.4</cell><cell>987.7 ± 394.79</cell></row><row><cell cols="2">GA-NAS-Setup2 (|Xt| = |Xt−1| + 50, ∀t ≥ 2) 94.227± 7.43e-5</cell><cell>2.5</cell><cell>1561.8 ± 802.13</cell></row><row><cell>GA-NAS-Setup2 (|Xt| = 450, ∀t ≥ 2)</cell><cell>94.22± 0.0</cell><cell>3</cell><cell>1127.6 ± 363.75</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>The mean accuracy and rank, and average number of queries over 10 runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Key hyper-parameters used by our NAS-Bench-101, 201 and 301 experiments. Among multiple runs of an experiment, the same hyper-parameters are used and only the random seed differs.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">NAS-Bench-101</cell><cell></cell><cell>NAS-Bench-201</cell><cell>NAS-Bench-301</cell></row><row><cell>Parameter</cell><cell cols="3">Acc (2 setups) Acc-WS Acc-Cons</cell><cell>Pareto</cell><cell>Acc (3 datasets)</cell><cell>Acc</cell></row><row><cell>G optimizer</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>G learn rate</cell><cell>0.0001</cell><cell>0.0001</cell><cell>0.0001</cell><cell>0.0001</cell><cell>0.0001</cell><cell>0.0001</cell></row><row><cell>D optimizer</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>D learn rate</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell></row><row><cell># GNN layers</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell>Iterations (T )</cell><cell>10</cell><cell>5</cell><cell>5</cell><cell>10</cell><cell>5</cell><cell>10</cell></row><row><cell># Eval base (|X1|)</cell><cell>100</cell><cell>100</cell><cell>200</cell><cell>500</cell><cell>60</cell><cell>50</cell></row><row><cell># Eval inc (|Xt| − |Xt−1|)</cell><cell>50, 100</cell><cell>100</cell><cell>200</cell><cell>100</cell><cell>10</cell><cell>50</cell></row><row><cell>Init method</cell><cell>Random</cell><cell>Random</cell><cell>Random</cell><cell>Worst 50%</cell><cell>Random</cell><cell>Random</cell></row><row><cell>Init size (|X0|)</cell><cell>50; 100</cell><cell>100</cell><cell>100</cell><cell>82329</cell><cell>60</cell><cell>100</cell></row><row><cell>Truth set size (|T |)</cell><cell>25; 50</cell><cell>50</cell><cell>50</cell><cell>4 fronts</cell><cell>40</cell><cell>50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Key information about the NAS-Bench-101 and NAS-Bench-201 benchmarks used in our experiments.</figDesc><table><row><cell></cell><cell>NAS-Bench-101</cell><cell></cell><cell>NAS-Bench-201</cell><cell></cell></row><row><cell>Dataset</cell><cell>CIFAR-10</cell><cell cols="3">CIFAR-10 CIFAR-100 ImageNet-16-120</cell></row><row><cell># Cells</cell><cell>423,624</cell><cell>15,625</cell><cell>15,625</cell><cell>15,625</cell></row><row><cell>Highest test acc</cell><cell>94.32</cell><cell>94.37</cell><cell>73.51</cell><cell>47.31</cell></row><row><cell>Lowest test acc</cell><cell>9.98</cell><cell>10.0</cell><cell>1.0</cell><cell>0.83</cell></row><row><cell>Mean test acc</cell><cell>89.68</cell><cell>87.06</cell><cell>61.39</cell><cell>33.57</cell></row><row><cell># Operator choices</cell><cell>3</cell><cell>5</cell><cell>5</cell><cell>5</cell></row><row><cell># Searchable nodes per cell</cell><cell>5</cell><cell>6</cell><cell>6</cell><cell>6</cell></row><row><cell>Max # edges per cell</cell><cell>9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Macro search backbone network for our EfficientNet experiment. TBS denotes a cell position to be searched, which can be a type of MBConv block. Output denotes a Conv1x1 &amp; Pooling &amp; Fully-connected layer.</figDesc><table><row><cell>Operator</cell><cell>Resolution</cell><cell>#C</cell><cell>#Layers</cell></row><row><cell>Conv3x3</cell><cell>224 × 224</cell><cell>32</cell><cell>1</cell></row><row><cell>TBS</cell><cell>112 × 112</cell><cell>16</cell><cell>1</cell></row><row><cell>TBS</cell><cell>112 × 112</cell><cell>24</cell><cell>2</cell></row><row><cell>TBS</cell><cell>56 × 56</cell><cell>40</cell><cell>2</cell></row><row><cell>TBS</cell><cell>28 × 28</cell><cell>80</cell><cell>3</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>112</cell><cell>3</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>192</cell><cell>4</cell></row><row><cell>TBS</cell><cell>7 × 7</cell><cell>320</cell><cell>1</cell></row><row><cell>Conv1x1 &amp; Pooling &amp; FC</cell><cell>7 × 7</cell><cell>1280</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13 :</head><label>13</label><figDesc>Macro search backbone network for our ProxyLessNAS experiment. TBS denotes a cell position to be searched, which can be a type of MBConv block. Identity denotes if an identity shortcut is enabled.</figDesc><table><row><cell>Operator</cell><cell>Resolution</cell><cell>#C</cell><cell>Identity</cell></row><row><cell>Conv3x3</cell><cell>224 × 224</cell><cell>32</cell><cell>No</cell></row><row><cell cols="2">MBConv-e1-k3 112 × 112</cell><cell>16</cell><cell>No</cell></row><row><cell>TBS</cell><cell>112 × 112</cell><cell>24</cell><cell>No</cell></row><row><cell>TBS</cell><cell>56 × 56</cell><cell>24</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>56 × 56</cell><cell>24</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>56 × 56</cell><cell>24</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>56 × 56</cell><cell>40</cell><cell>No</cell></row><row><cell>TBS</cell><cell>28 × 28</cell><cell>40</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>28 × 28</cell><cell>40</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>28 × 28</cell><cell>40</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>28 × 28</cell><cell>80</cell><cell>No</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>80</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>80</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>80</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>96</cell><cell>No</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>96</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>96</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>96</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>14 × 14</cell><cell>192</cell><cell>No</cell></row><row><cell>TBS</cell><cell>7 × 7</cell><cell>192</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>7 × 7</cell><cell>192</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>7 × 7</cell><cell>192</cell><cell>Yes</cell></row><row><cell>TBS</cell><cell>7 × 7</cell><cell>320</cell><cell>Yes</cell></row><row><cell>Avg. Pooling</cell><cell>7 × 7</cell><cell>1280</cell><cell>1</cell></row><row><cell>FC</cell><cell>1 × 1</cell><cell>1000</cell><cell>1</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
