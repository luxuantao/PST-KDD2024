<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Clemson University</orgName>
								<address>
									<postCode>29634</postCode>
									<settlement>Clemson</settlement>
									<region>SC</region>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5792276452219B1F2E1E8E5CD545935A</idno>
					<note type="submission">received February 1, 1991; revised July 3, 1991.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Index Tem-Multiprocessor architecture, neural network design, nonlinear optimization, parallel processing, resource allocation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUC~ON RTIFICIAL neural networks (ANN'S) are motivated by</head><p>A biological nervous systems. Modem computers and algorithmic computations are good at well-defined tasks. Biological brains, on the other hand, easily solve speech and vision problems under a wide range of conditions-tasks that no digital computer has solved adequately. This inadequacy has prompted researchers to study biological neural systems in an attempt to design computational systems with brain-like capabilities. At the same time, modem analog and digital integrated circuit technology is offering the potential for implementing massively parallel networks of simple processing elements. Neurocomputing will enable us to take advantage of these advances in VLSI by providing the computational model necessary to program and coordinate the behavior of thousands of processing elements. Manuscript</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization Using Neural Networks</head><p>Gene A. Tagliarini, Member, IEEE, J. Fury Christ, and Edward W. Page, Member, IEEE Abstract-Artificial neural networks can achieve high computation rates by employing a massive number of simple processing elements with a high degree of connectivity between the elements. Neural networks with feedback connections provide a computing model capable of exploiting fine-grained parallelism to solve a rich class of optimization problems. Network parameters are explicitly computed, based upon problem specifications, to cause the network to converge to an equilibrium that represents a solution. This paper presents a systematic approach to designing neural networks for optimization applications. It reviews the theoretical basis for applying neural networks to optimization and presents a design rule that facilitates the construction of time evolution equations describing a network's behavior. The design rule is employed to specify the connection strengths and external inputs that enforce constraints expressed as equalities as well as constraints expressed as inequalities. The approach is demonstrated by designing a network that finds good solutions to a complex, nonlinear resource allocation problem-the problem of allocating weapons to counter offensive threats. The neural solution, which employs more than 46OOO neural elements and more than 49 million connections, has been simulated on a highspeed parallel processor. This network has produced excellent solutions to a realistic threat scenario. The results demonstrate that it is possible to employ a systematic approach in designing neural networks for optimization problems and that large-scale neural networks are capable of yielding high-quality solutions to complex problems. Artificial neural networks have been studied for more than 30 years. There has been a major resurgence of interest in neural networks in recent years, primarily because of improved leaming algorithms, due to the work of <ref type="bibr">Werbos [35]</ref>, <ref type="bibr">Le Cun [20]</ref>, Parker <ref type="bibr" target="#b21">[28]</ref>, and Rumelhart, Hinton, and Williams <ref type="bibr" target="#b22">[29]</ref>; improved theoretical foundations due to such pioneers as <ref type="bibr">Grossberg [8]</ref>, Amari <ref type="bibr">[l]</ref>, <ref type="bibr">Fukushima [6]</ref>, and <ref type="bibr">Kohonen [19]</ref>; greatly improved computer systems for simulation studies; and improved implementation technologies <ref type="bibr">[lo]</ref>, <ref type="bibr">[13]</ref>, <ref type="bibr" target="#b16">[23]</ref>, <ref type="bibr" target="#b17">[24]</ref>. Excellent reviews of the historical developments in neural computing may be found in the recent paper by Widrow and  Lehr [36] and the book by .</p><p>Neural network models are providing new approaches to problem solving. Neural networks can be simulated on special purpose, neural hardware accelerators as well as conventional machines. For maximum processing speed they may even be realized using optical implementations or silicon VLSI. The key to the utility of ANN'S is that they provide a computational model that can be used to systematize the process of programming an ultra-fine-grained parallel computer with a massive number of simple processors.</p><p>This paper focuses upon the design of feedback (or recurrent) neural networks to produce good solutions to complex optimization problems. First, the theoretical basis for applying neural networks to optimization problems is reviewed. Then a design rule that serves as a primitive for constructing a wide class of constraints is introduced. Finally, the use of the design rule is illustrated by developing a neural network for producing high-quality solutions to a probabilistic resource allocation task. The resulting neural network has been simulated on a high-performance parallel processor that has been optimized for neural network simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">ARTIFICIAL NEURAL NETWORKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Neuron Model</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> shows the neuron model for the ANN'S considered in this paper. The adjustable, multiplicative weights correspond to biological synapses. For the purpose of analytical modeling, it is often convenient to allow a positive weight to represent an excitatory connection and a negative weight an inhibitory connection. A weight of zero is used when no connection between a pair of neurons is to be made. The input transmitted to a neuron through these weights may come from other neurons or from external sources.</p><p>The weighted inputs to a neuron are accumulated and then passed to an activation function which determines the neuron's response. Commonly, a continuously varying, sigmoidal activation function is used to model the frequency modulated, action potential output of a biological neuron. The output of the model neuron ranges between limits, such as 0 and 1, that are analogous to a biological neuron's minimum and maximum firing rates. When an artificial neuron's output is 0, the model neuron is said to be "off" (or in state 0); the neuron is said to be "on" (or in state 1) if its output is 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network Models</head><p>Networks may be distinguished on the basis of the directions in which signals flow. Basically, there are two types of networks: feedforward and feedback. A network in which signals propagate in only one direction from an input stage through intermediate neurons to an output stage is called a feedforward network. Feedback networks, on the other hand, are networks in which signals may propagate from the output of any neuron to the input of any neuron.</p><p>Feedforward Networks: Fig. <ref type="figure">2</ref> illustrates a feedforward network. The first layer serves only to distribute a weighted version of the input vector to the neurons in the inner layer. Neurons in the inner layer, called hidden neurons, respond to the accumulated effects of their inputs and propagate their response signals to neurons in the output layer. Neurons in the output layer also accumulate the effects of the signals they receive and collectively produce an output vector of signals which represents the response of the network to the input vector. There are several powerful algorithms available for adapting the strengths of the interconnections between neurons in feedforward networks so that the network learns to map input patterns into desired output patterns. Feedforward networks have been applied successfully to a number of problem areas including sonar signal processing [7], speech recognition Feedback Networks: Fig. <ref type="figure">3</ref> shows a feedback network with five neurons (represented by open disks). Each black dot represents a set of feedback connections that are analogous to biological synapses. Because the output of a neuron may be fed back into the network as an input to other neurons, a neuron may influence its own future state. Neural models that permit feedback have been employed to develop networks capable of unsupervised learning [9], self-organization [ 191, retrieving stored memory patterns [14], and computing solutions to a variety of optimization problems [16], [17], <ref type="bibr" target="#b23">[30]</ref>. The neural solution to each of these problems involves interpreting the state of the network after it stabilizes. It is therefore necessary to state criteria for the design of stable neural networks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Cohen-Grossberg Stability Results</head><p>Grossberg [8] developed a mathematical model which encompasses a variety of neural network models as well as models from population biology and macro-molecular evolution. The analysis of this model by Cohen and Grossberg [3] yielded conditions under which the systems of differential equations used to characterize a number of popular neural network models will converge to stable states. The model which they analyzed is a dynamical system of mutually interdependent differential equations of the form They showed the existence of a Lyapunov function for a system of such equations if the matrix <ref type="bibr">[Cij]</ref> and the functions ai, bi, and g; meet three conditions:</p><p>1) The matrix <ref type="bibr">[Cij]</ref> must be symmetric (i.e., C i j = Cji).</p><p>2) The functions ai and b; must be continuous with ai</p><p>3) The functions g; must be nondecreasing. A Lyapunov function for a dynamical system places constraints on the collective behavior of the equations comprising the system. The central idea is that the system always evolves in a manner that does not increase the value of the Lyapunov function. The existence of a Lyapunov function for a system of interdependent differential equations of the form of (1) therefore guarantees that the system will follow a trajectory to a stable state, regardless of the initial state, providing the above conditions hold. The Cohen- In Hopfield's continuous model, the behavior of a neuron is characterized by its activation level U; which is governed by the differential equation where -2 is a passive decay term, Tij is the strength of the interconnection between neuron j and neuron i, g j ( u j ) is the activation function for neuron j, and I; is the external input to neuron i. The activation level U; is a continuous variable that corresponds to the membrane potential in biological neurons. In the absence of an external input and inputs from other neurons, the passive decay term -Ifr causes u i to decay toward o at a rate proportional to 71;. f i e output of neuron i can be described by its mean firing rate V, corresponding to the activation level U;. The output vi is continuous over its range and is related to u i by the activation function V, = g;(u;). The activation function is typically a smooth sigmoid as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. A frequent choice for g(u) is g(u) = 0.5[1 + tanh(gain. U ) ] .</p><p>(3) As long as g(u) is nondecreaing, it meets the Cohen-Grossberg requirements for stability [3]. Thus, if the external inputs are maintained at a constant value, a network of neurons modeled by (2) will eventually equilibrate, regardless of the starting state.</p><p>Hopfield [15] discovered a Lyapunov function for a network of n neurons characterized by (2) which can be expressed as when the gain of the activation function is sufficiently high. This expression, which Hopfield refers to as the network's "computational energy" or just "energy function," is derivable [9] from the Lyapunov function discovered earlier by Cohen and Grossberg [3]. The term "energy function" stems from an analogy between the network's behavior and that of certain physical systems. Just as physical systems may evolve toward an equilibrium state, a network of neurons will always evolve toward a minimum of the energy function. The stable states of a network of neurons therefore correspond to the local minima of the energy function. <ref type="bibr">Hopfield and Tank [16]</ref> had a key insight when they recognized that it was possible to use the energy function to perform computations. Because a network of neurons will seek to minimize the energy function, one may design a neural network for function minimization by associating variables in an optimization problem with variables in the energy function. Developing a neural network to seek solutions to an optimization problem becomes the task of selecting appropriate values for the connection strengths T;j and the external inputs I; so that the desired network behavior results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OFTIMUATION USING NEURAL NETWORKS</head><p>The energy function given by (4) forms the theoretical basis for function optimization using neural networks. Consider an objective function F(X1 , Xp, . . . , Xn) that is to be minimized subject to a set of constraints where X1,X2,.-.,Xn are integer valued decision variables. Suppose that the constraints can be expressed as nonnegative penalty functions Notice that ( <ref type="formula">8</ref>) is expressed in the form of the energy function. Thus, if an objective function and the individual constraints can be expressed in the form of the energy function, there exists another energy function that corresponds to the equivalent unconstrained optimization problem. Furthermore, the energy function specifies both the connection strengths and the external inputs necessary to cause a network of neurons to seek the desired minima.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ci(X1,X2,...,Xn)</head><formula xml:id="formula_0">such that C ~( X 1 , X p 1 ~~~, X n ) = 0 for k = 1, ...</formula><p>According to (8), we can determine the connection strengths for the network by summing the connection strengths arising independently from the objective function and the constraints. In a similar manner, the external input for a given neuron is the sum of the inputs arising from the objective function and the constraints to which it is subjected. This observation significantly reduces the effort required to determine the connection strengths and external inputs needed to design a network corresponding to a particular optimization problem. Because certain types of constraints arise frequently, the corresponding neural network structures that enforce these constraints can be developed and used as primitives in the design of more complex networks.</p><p>The system of differential equations for which ( <ref type="formula">8</ref>) is a Lyapunov function is given by II Since the temporal behavior of the network is captured by (9), it can be numerically integrated in order to find the system's equilibria and hence, the minima being sought. Notice that the effects of the constraints and the objective function combine additively and reflect the neuron connections and inputs that were given in (8).</p><p>There is a significant difference between neural and digital computation. Because neural computation does not employ any notion of step-by-step sequencing of activity, it is not algorithmic in the formal sense. Nevertheless, networks which meet the Cohen-Grossberg requirements for stability do equilibrate and are therefore analogous to programs that terminate for all inputs. The evolution of a network from its initial state toward an equilibrium is determined by the strength of the connections between neurons as well as the external inputs. Instead of constructing a sequential program for a problem of interest, the connection strengths as well as the external inputs are specified through a design process so that the network "flows" to an equilibrium which represents a solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v. THE k-OUT-OF-n NETWORK DESIGN RULE</head><p>Many problems can be represented as a two-or threedimensional array of neurons in which each neuron represents a hypothesis that may be either true or false. If a neuron is on (i.e., in state 1) when the network equilibrates, its corresponding hypothesis is true. Otherwise, the hypothesis it represents is false. Although the neurons in networks used for optimization problems are typically designed to equilibrate in digital states, a neuron's output may assume values over the continuous range from 0 to 1 as the network evolves.</p><p>Optimization problems in which the solution variables are restricted to binary values are known as zero-one programming problems. Such problems often have constraints that are expressed as</p><formula xml:id="formula_1">n i= 1 or n i = l</formula><p>where the Xi's are binary decision variables, k and n are positive integers and k 5 n. Since such constraints arise frequently in the design of neural networks for optimization problems, Page and Tagliarini <ref type="bibr" target="#b20">[27]</ref> introduced the k-out-ofn design rule which facilitates the construction of energy functions for multiple constraints that can be expressed as ( <ref type="formula">10</ref>) or ( <ref type="formula">11</ref>). The remainder of this section presents a derivation of the k-out-of-n rule and illustrates its use as a network design primitive to enforce constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Constraints Expressed as Equalities</head><p>When hypotheses are represented by neurons, (10) requires that exactly k (0 5 k 5 n) of an ensemble of n neurons be on when the network converges to a stable state. If exactly k neurons are to be in state 1 when the network equilibrates, we must have</p><formula xml:id="formula_2">" C V , = k i = l</formula><p>where the binary decision variables X i in (10) are represented by neuron outputs V,. The energy function n E = (k -cV.)z i=l will be minimal when exactly k of the n neurons are in state 1.</p><p>Equation ( <ref type="formula">13</ref>) does not guarantee, however, that the T/'s will assume digital values. Addition of the term n CKCl-V,) (14) i=l to (13) will cause the energy function to favor states in which each neuron has a digital value, since the added term is</p><formula xml:id="formula_3">' 0 -2 -2 -2 0 0 - -2 0 -2 -2 0 0 -2 -2 0 -4 -2 -2 -2 -2 -4 0 -2 -2 0 0 -2 -2 0 -2</formula><p>. o 0 -2 -2 -2 0 -1351 minimal when each V; is either 0 or 1. The resulting energy function is</p><formula xml:id="formula_4">n n E = (k - V,)2 + vi( 1 -K). (<label>15</label></formula><formula xml:id="formula_5">) i=l i = l</formula><p>After some algebraic manipulation and the deletion of a constant which does not influence the locations of the minima, (15) can be written in the form of the energy function (4) as <ref type="formula">16</ref>)</p><formula xml:id="formula_6">n n n 1 ' --- E = --E C(-Z)KV, -E K ( 2 k -I). (</formula><formula xml:id="formula_7">Z=l j = 1 i=l 3 f '</formula><p>Equation ( <ref type="formula">16</ref>) specifies both the connection strengths and the inputs required to realize an n-neuron network having stable states with exactly k neurons on. Matching the terms in ( <ref type="formula">16</ref>)</p><p>and the energy function yields otherwise ( <ref type="formula">17</ref>)</p><p>and</p><formula xml:id="formula_8">Ii = 2k -1 for all i. (<label>18</label></formula><formula xml:id="formula_9">)</formula><p>According to ( <ref type="formula">17</ref>) and (18), a network of n neurons should settle into a stable state with k neurons on and nk neurons off if two conditions are met: 1) Each neuron exerts an inhibitory influence of strength 2</p><p>2) Each neuron receives an external excitatory input of</p><p>The above values represent the relative magnitudes of connection strengths and external inputs required for convergence to a state having exactly k of n neurons on. For the purpose of analysis or digital simulation, one may simply use the values given by ( <ref type="formula">17</ref>) and ( <ref type="formula" target="#formula_8">18</ref>) without regard to practical considerations related to any particular implementation technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example I :</head><p>The three neurons illustrated in Fig. <ref type="figure" target="#fig_5">4</ref> are interconnected so that exactly k will emerge in state 1 as determined by the magnitude of the input. If k = 1, the input to all neurons will be 2k -1 = 1. This will cause the network to settle into a stable state with exactly one of the three neurons on. The particular neuron that emerges in state 1 depends upon the initial states of the neurons when the input is applied and the order in which they are allowed to update.</p><p>The collection of neurons corresponding to the decision variables that are subject to a given constraint [such as <ref type="bibr">(10)</ref> or (ll)] form a set that may be referred to as a constraint set. When multiple constraints are to be satisfied simultaneously, it is likely that some neurons will be members of more than one constraint set. As shown by Page and Tagliarini <ref type="bibr" target="#b20">[27]</ref>, k-outof-n rules can be superimposed to yield an energy function having global minima at those points that simultaneously satisfy multiple constraints.</p><p>Example 2: Consider a network consisting of six neurons that is to simultaneously enforce the constraints on the other n -1 neurons. magnitude 2k -1. and 6</p><formula xml:id="formula_10">E X i = 2. i=3</formula><p>Representing decision variables by neurons, we see that the constraints create two constraint sets as illustrated in Fig. <ref type="figure" target="#fig_6">5</ref>. We can determine the required connection strengths as well as the external inputs by independently developing an energy function for each constraint and then simply combining the energy functions according to (8). Applying a k-out-of-n rule with k = 1 to neurons n l , n2, n3, and n4 in the first constraint set yields connection strength Tij = -2 that is required among all pairs of neurons in the first constraint set. The external input li for neurons in the first constraint set should be 1. Applying a k-out-of-n rule with k = 2 to neurons 7x3, 7~4,715, and n g in the second constraint set yields connection strength Tij = -2 that is required among all pairs of neurons in the set and an external input li = 3 for neurons in the set. The complete connection matrix and the required external inputs are and Notice that the connection strength between neurons n3 and n4 is -4 since they are subject to both constraints. Likewise, the external inputs to neurons n3 and n4 receive contributions from both constraints. Combining multiple k-out-of-n rules as described above assures that the global energy minima will be situated exactly at the system equilibria which satisfy all of the constraints. However, there may be stable equilibria elsewhere <ref type="bibr">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Constraints Expressed as Inequalities</head><p>A constraint represented by an inequality as in (11) translates into the requirement that no more than k neurons in an ensemble of n neurons can be on when the network equilibrates. The results given by ( <ref type="formula">17</ref>) and ( <ref type="formula" target="#formula_8">18</ref>) can be extended to yield a network of n neurons having k or fewer neurons in -neurons representing decision slack neurons variables XI, X2. XJ and X4.</p><p>state 1 when it converges. To see this, consider an ensemble of n neurons that represent hypotheses in a problem formulation. Now add k neurons to the ensemble to give a total of n + k neurons. The k additional neurons, however, are "hidden" in the sense that they do not correspond to hypotheses in the network representation of the problem.</p><p>According to ( <ref type="formula">17</ref>) and ( <ref type="formula" target="#formula_8">18</ref>), we can cause the system to settle into a state with exactly k neurons on if the connection strengths between all pairs of neurons is -2 and the external input to each neuron is 2k-1. If exactly k neurons are on when the network equilibrates, then no more than k of the n neurons representing hypotheses in the problem representation can be on. Thus, by adding neurons to the hypothesis representation neurons, we can enforce inequality constraints. The extra neurons are analogous to slack variables that are sometimes used to solve optimization problems in operations research; therefore, they are referred to as slack neurons.</p><p>Example 3: Suppose we wish to design a network that enforces the constraint 4 c x i I 3. i=l Four neurons n1) . . . , n4 are necessary to represent the binary decision variables XI ) . . . , X4. The constraint, however, will allow no more than three of the neurons to be in state 1 when the network equilibrates. By adding k slack neurons to an n-neuron network, the k-out-of-n rule will yield the necessary connection strengths and external inputs to assure that k or fewer of the n neurons representing decision variables can achieve state 1. In this case, n = 4 and k = 3. Thus, as illustrated in Fig. <ref type="figure" target="#fig_7">6</ref>, three slack neurons n5,n6, and 127 are needed. According to (17), each neuron must exert an inhibitory influence of magnitude 2 on the other six neurons. Additionally, as specified by ( <ref type="formula" target="#formula_8">18</ref>), each neuron must receive an external input of magnitude 2k -1, which in this case is 5. The final network state will have exactly three of the seven neurons on; however, confining one's attention to the neurons representing decision variables, no more than three of them can be on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. A DESIGN EXAMPLE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Weapon-to-Target Assignment Problem</head><p>The weapon-to-target assignment problem (WTAF') is a resource allocation task that arises when defensive weapons must be assigned to counteract offensive threats. In the version of the WTAP considered in this paper, it is assumed that N targets are to be countered by W weapons in T time periods. Each weapon is assumed to have a known likelihood of successfully countering each target in each of the time periods in which it could be fired. It is further assumed that each target has an associated worth which is a measure of the value of successfully neutralizing it. The objective is to assign weapons to targets in a manner that maximizes the total value of the targets neutralized. It is significant to realize that the WTAP is NP-complete <ref type="bibr">[22]</ref>. Consequently, short of enumerating all possible solutions to the problem (which is totally infeasible for all but the smallest problem instances), all algorithmic solution methods employ heuristics to find good assignments.</p><p>The WTAP may be formally expressed as a constrained nonlinear optimization problem. The assignment procedure attempts to maximize EV, the expected value of targets countered, where Here,</p><formula xml:id="formula_11">i = 1,. -, W is the weapon index; j = 1, ' . . , N is the target index; t = l , . . . , ~</formula><p>is the time index; w j = the value of target j ; M = the overall shot limit; Xijt = { 0, otherwise; pijt = the probability that a shot from weapon i at time t destroys target j. The constraint expressed in (20) limits each weapon to firing no more than once. Further, the constraint in (21) imposes a limit M on the total number of shots fired in order to reserve W -M weapons for future use.</p><p>1, if weapon i fires at target j at time t For illustrative purposes, we assume that all targets have equal value with wj = 1 for j = 1 , ... , N . The objective function then becomes</p><formula xml:id="formula_12">1 2 targets I 3 EV = N - n n(1 -p i j t X ; j t ) . (22) j i t</formula><p>Maximizing EV is equivalent to minimizing E L V , the expected number of targets that leak through the defensive system where</p><p>We will develop a neural network that seeks to minimize E L V . However, in order to compare our results with other published work, we will express results in terms of (22).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Neural Representation</head><p>We have chosen to represent the neural network for the WTAP using a three-dimensional array of neurons as illustrated in Fig. <ref type="figure">7</ref>. Each neuron in the array represents the hypothesis that a particular defensive weapon should be launched at a given time to counter a specific offensive threat. We will use the notation X i j t to refer to the neuron in position (2, j , t) of the array and to represent the hypotheses that weapon i should be fired at target j at time t. In addition to i, j , and t, the indexes i ' , j ' , and t' will also be used as needed to denote values from the weapon, target, and time index sets, respectively. When the network equilibrates, the fact that a given neuron is on means that a weapon should be launched toward a specific target at the indicated time. Thus, for example, the shaded neuron X w z l in Fig. <ref type="figure">7</ref> represents the hypothesis that weapon W should be fired at target 2 during the initial time step. In addition to the neurons that represent shot hypotheses, there is a slack neuron associated with each weapon. Each slack neuron Si (i = 1 , . . . , W) represents the hypothesis that the associated weapon is not fired.</p><p>The architecture of the neural network must reflect both the constraints and the objective function. Consequently, the input to each shot hypothesis neuron and the connections among pairs of shot hypothesis neurons will have components resulting from both the constraints and the objective function. Slack neurons are used only to assure that problem constraints are satisfied; hence, neither their input nor their connections depend upon the objective function. The slack neurons, however, are subject to multiple constraints and will therefore have inputs and connections that arise from the influences of those constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Mapping the Objective Function onto the Energy Function</head><p>The connection strength between pairs of neurons as well as the external input to each neuron is determined by establishing a correspondence between (23) and the energy function, (4). Since the energy function is of quadratic order and (23) has higher order terms, the energy function can only approximate the objective function. Fortunately, since the factors of the terms in the objective function are probabilities, the higher order terms are progressively less significant. As shown in Fig. <ref type="figure">8</ref>, the neurons in target plane j represent all possible combinations of weapons and time periods considered by the network for countering target j. By expanding the product in ( <ref type="formula">23</ref>) for target j, we will discover the connection strengths and the external inputs for neurons in target plane j arising from the objective function. The contribution to ELV in (23) for the jth target is</p><formula xml:id="formula_13">W r i = l t=l W r W r i = l t = l i'=l t'=l</formula><p>+ higher order terms.</p><p>(</p><formula xml:id="formula_14">)<label>24</label></formula><p>The constant 1 does not contribute to the location of the minima of (24) and can be removed. Neglecting the higher order terms in (24) and placing the linear and quadratic terms in correspondence with the energy function yields an approximation of ELVj given by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>l W T W T E L V = --( -2 ) p ; j t p i i j t t X ; j t X ; l j t , i = l t=l i'=l t'=1 W r i=l t = l</head><p>Even though the approximation of (24), as expressed by (25), is only of quadratic order, minimizing E L T over all targets j has produced good results for complex battle scenarios. The cubic and higher order terms omitted from (24) appear only if more than two shots are actually assigned to target j. Otherwise, (24) is at most quadratic in which case the minima of E L T and ELVj coincide. Thus, a more conservative shot allocation strategy results in a better approximation of E LVj by E L T . For a pair of neurons X i j t and X i / j t / representing different weapon and time options for countering target j, the connection strength dictated by the objective function is Notice that the objective function specifies connections only within the jth target plane. For a neuron X i j t in the jth target plane, the required component of external input resulting from the objective function is</p><formula xml:id="formula_15">I;;t = P i j t . (<label>27</label></formula><formula xml:id="formula_16">)</formula><p>Because the choice of j was arbitrary, (26) and ( <ref type="formula" target="#formula_15">27</ref>) hold for all j E { 1 , . . . , N } .</p><p>The connections and external inputs arising from (25) have a rational physical interpretation. Equation ( <ref type="formula" target="#formula_15">27</ref>) specifies that the external input, due to the objective function, for each neuron X i j t is p i j t , the single-shot probability of kill. Note that the larger the single-shot probability of kill for a given shot hypothesis, the larger the input to the corresponding neuron and hence the better chance that neuron has of being on when the network equilibrates. Neurons that represent good shots are more likely to come on, thereby eventually representing a scenario in which good shots are being taken. As specified by (26), each pair of neurons in layer j is connected with a connection strength that is -2 times the product of the singleshot probabilities of kill associated with the pair. Thus, the larger the individual single-shot kill probabilities for a given pair of weapons, the larger is their product. Since the product contributes to an inhibitory connection between the neurons representing the shot options for a particular target, it is less likely the network will propose that multiple shots be fired at a given target when the probability of kill with any one shot is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Mapping Constraints onto the Energy Function</head><p>In the WTAP considered, only two constraints are present. These constraints may be enforced in a network by superimposing the structures prescribed by appropriate k-out-of-n rules.</p><p>Weapon Firing Constraint: The constraint expressed in (20), which limits a given weapon to firing no more than once, can be enforced by applying a k-out-of-n rule with k = 1 to each weapon plane (including the slack neuron). The ith weapon plane and the associated slack neuron Si form a weapon constraint set as illustrated in Fig. <ref type="figure">9</ref>. Applying a k-out-of-n rule with k = 1 will encourage exactly one neuron to come on in each weapon constraint set. If Si is on when the network equilibrates, it indicates that weapon i should not be fired. Otherwise, a shot hypothesis neuron X i j t in weapon plane i must be on. The k-out-of-n rule specifies that all neurons in the constraint set must receive an external input of 2k -1, and that mutually inhibitory connections of magnitude 2 must exist among the neurons in the constraint set. Thus, the component of external input due to the weapon plane constraint for shot hypothesis neurons X i j t is</p><formula xml:id="formula_17">= (2k -1) = 1.</formula><p>Likewise, the component of external input for slack neurons Si due to the weapon plane constraint is</p><formula xml:id="formula_18">Is",' = (2k -1) = 1.<label>(29)</label></formula><p>The connection strength between neurons X , j t and Xijttj resulting from the application of a k-out-of-n rule to each weapon constraint set is</p><p>The slack neuron Si is connected to the shot-hypothesis neurons X i j t in weapon constraint set i with strength Shot Limit Constraint: The constraint expressed in (21), which limits the total number of weapons fired to no more than M , is an inequality. In order to compare our results with those previously published, we chose to enforce the constraint that exactly M weapons be fired. This tactic is reasonable so long as M 5 W and there are at least M shots with nonzero single-shot probability of kill. To assure that exactly M shots are taken, one may apply the k-out-of-n rule to the entire set of neurons representing shot hypotheses, but this requires a massive number of interconnections. Alternatively, we can enforce the shot limit constraint indirectly by applying a kout-of-n rule to the slack neurons. Requiring W -M of the slack neurons to be on means that W -M weapons will be not be fired. We can therefore require exactly M shots to be taken by requiring W -M of the slack neurons to be on. Applying the k-out-of-n rule with k = (W -M) to the slack neuron array dictates that each of the slack neurons should receive the external input 1;: = 2(W -M) -1 (32) resulting from the shot limit constraint, and that the connections between each pair of distinct slack neurons Si and Sit must be Equations ( <ref type="formula">26</ref>)-( <ref type="formula">33</ref>) define the architecture of the network in terms of connection strengths and external inputs. Based upon these results and (9), we can now develop the differential equations that describe the behavior of both shot-hypothesis and slack neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Accumulating the Effects of the Objective Function and the Constraints</head><p>This section presents the differential equations which describe the evolution of the activation function for both shot hypothesis and slack neurons as given by (9). The constant a in (9) was chosen to be 1 in order to weight the constraints and the objective function equally. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shot-Hypothesis</head><p>Substituting problem-specific values we have</p><formula xml:id="formula_20">j ' t'</formula><p>which reduces to</p><formula xml:id="formula_21">j l t'</formula><p>Slack Neurons: The equation for the rate of change of the activation for slack neurons S; can be developed similarly. Each slack neuron is connected with strength T?x,,t to all neurons in weapon plane i <ref type="bibr" target="#b24">(31)</ref> and to all other slack neurons S,I with strength Tgf,,, <ref type="bibr" target="#b25">(33)</ref>. Slack neurons receive an external input IT resulting from the weapon constraint set (29) and an external input I.$ resulting from the shot limit constraint (32). The rate of change of the activation for a slack neuron S; can therefore be written as (39) Equations ( <ref type="formula">36</ref>) and (39) characterize the behavior of shothypothesis neurons and slack neurons, respectively. The WTAP network can be simulated by integrating this system of equations. The value of 71 depends upon the choice of gain for the neuron transfer function. It must be sufficiently large to assure that g(ui) approaches either 0 or 1 for all i as the network reaches equilibrium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. SIMULATING THE NETWORK ON A PARALLEL PROCESSOR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Accelerator Architecture</head><p>The neural network designed for the WTAP was simulated on a parallel processor developed specifically for neural network simulation by the Space Information Systems Division of Loral Corporation. As illustrated in Fig. <ref type="figure" target="#fig_0">10</ref>, the architecture exploits multiple digital signal processor (DSP) chips and a high-speed global bus to achieve the high computation rates needed for timely simulation of neural networks. The Loral system consists of two board types: a P-board and an Mboard. A P-board contains 4 Texas Instruments TMS320C30 DSP's, each having 4 megabytes of local memory. The DSP's on a P-board function as a 4-processor MIMD machine and perform the bulk of the computation needed for network simulation. The M-board contains a DSP, 16 megabytes of common memory as well as 32 kilobytes of EPROM that is used to initialize the DSP's on the P-boards. The M-board also manages the flow of information between the host and the P-boards. The DSP's communicate over a high-speed 32bit data bus that allows one processor to broadcast to all others simultaneously. The system host, a Compaq 386/20, provides the user interface, program development utilities, disk storage, and graphical display capabilities. A complete system consists of a microcomputer host, a single M-board, and a single Pboard. The system may be expanded by adding up to 16 P-boards to increase processing power and up to 16 M-boards to increase system memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Mapping the Neural Network onto the Parallel Processor</head><p>Mapping the network onto the architecture of the Loral system requires partitioning the network across multiple DSP's on the P-boards in a manner that maximizes parallelism. Referring to (36), the system equation describing the time evolution for shot-hypothesis neurons, we see that each neuron is connected to every other neuron in its target plane as well as every other neuron in its weapon constraint set. The contribution to (36) from within the jth target plane is and the contribution from the ith weapon constraint set is</p><formula xml:id="formula_22">j ' t'</formula><p>Notice that the connections between neurons in the same weapon constraint set are all of strength -2. Thus, only the sum of the neuron outputs in each weapon constraint set is needed in order to compute the weapon plane contribution to (36). If the single-shot probabilities of kill for a particular target plane are maintained in the local memory of a P-board processor, the state of each neuron in the target plane can be updated once the influence of each weapon constraint set is determined. A natural decomposition, then, is to associate one or more target planes with a processor. If the number of targets does not exceed the number of processors available, each target plane could be assigned to a separate processor. Alternatively, multiple target planes may be assigned to a single processor as illustrated in Fig. <ref type="figure" target="#fig_0">11</ref>. By binding an entire target plane to a single processor, that processor can compute (40) without requiring data from another processor. This method of partitioning distributes each weapon constraint set across all processors. As indicated by the shaded weapon constraint set in Fig. <ref type="figure" target="#fig_0">11</ref>, a given processor will have access to only a portion of the neuron outputs necessary to compute (41). Interprocessor communication is therefore required to distribute the partial sums necessary to compute the total influence of each weapon constraint set (41) which, in turn, becomes incorporated into (36). Notice that one of the processors in Fig. <ref type="figure" target="#fig_0">11</ref> is assigned to handle the slack array in addition to one or more target planes. Except for the processor that must maintain the states of the neurons in the slack array, all processors perform identical tasks. After initializing the processors with the necessary programs and data, each processor accumulates the partial sum of the neuron outputs in that portion of each weapon constraint set accessible to it. Each processor must transmit its partial sums to all other processors and likewise, must receive the partial sums accumulated by all other processors. At this point, the activity of the processors is synchronized. Each processor, in turn, is granted the right to transmit on the global bus while all others receive. A 32-bit word can be transmitted from one processor to all others in a single bus cycle. Upon receipt of the partial sums accumulated by the other processors, all processors compute the sum of the neuron outputs in each weapon constraint set and begin a new cycle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Network Performance</head><p>The network was tested with a realistic scenario consisting of 86 threats, 90 weapons, and 6 time periods. The total number of weapons fired was limited to no more than 86. Thus, a total of 86 x 90 x 6 = 46440 neurons were required to represent the shot hypotheses. An additional 90 slack neurons were used to represent the hypotheses that the associated weapons are not fired. In excess of 49 million network connections were required.</p><p>Table <ref type="table" target="#tab_3">I</ref> compares the quality of the neural network solution with two alternative algorithms: a greedy approach and a linear programing technique. The three methods were compared using the identical test scenario. Since the original objective was to maximize EV, larger values of EV indicate better performance. The greedy algorithm begins with no shots assigned and then searches all admissible shots for one that provides maximum marginal improvement in EV. The linear programming result, generated by Metier and Preston <ref type="bibr" target="#b18">[25]</ref>, represents the application of the Karmarkar linear programming technique and a set of heuristics to a linear approximation of the WTAP. Both the greedy algorithm and the linear programming approach are deterministic. The greedy algorithm was run on a 6 MIPS machine while the linear programming method was executed on a parallel processor that is capable of 40 MIPS when performing the Karmarkar algorithm. The neural network results were obtained using the Loral system (with two P-boards) that was previously described. As indicated in Table <ref type="table" target="#tab_3">I</ref>, the neural network produced the best solution for the test scenario. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J</head><p>While Table <ref type="table" target="#tab_3">I</ref> summarizes the best outcomes produced by each of the various methods, the histogram in Fig. <ref type="figure" target="#fig_0">12</ref> indicates the general quality of the solutions produced by the neural network for more than 100 trials using the same threat scenario but a variety of initial states. Each trial converged to a feasible solution. Note that all but a small fraction of the solutions are better than greedy and several surpassed the linear programming method. Even the average performance of the network is close to the linear programming result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>This paper has begun to formalize the process of designing neural networks for optimization applications. It reviews the theoretical basis for applying neural networks to optimization and presents the k-out-of-n design rule that facilitates the construction of time evolution equations that describe a network's behavior. The k-out-of-n rule is employed to specify the connection strengths and external inputs that enforce constraints expressed as equalities. Together with the notion of a slack neuron, the k-out-of-n rule also enables the determination of connection strengths and external inputs to enforce constraints expressed as inequalities. An approach to designing neural networks for optimization was illustrated by designing a network for a complex resource allocation task-the problem of assigning weapons to counter threats in an optimal manner. The network we designed for this application employs more than 46 000 neural elements and more than 49 million connections. The network was simulated on a high-performance parallel accelerator from Loral Corporation that was designed specifically for neural network applications. This network has produced excellent results for a realistic test scenario. The results demonstrate that it is possible to employ a systematic approach in designing neural networks for optimization problems and that large-scale neural networks are capable of yielding high-quality solutions to complex problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Key elements of an artificial neuron model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>[</head><label></label><figDesc>ll], stock market prediction [MI, image compression [4], and adaptive process control [26].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig. 3. A feedback network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Hopfield and Tank illustrated the use of the energy function to configure networks for several optimization applications including the traveling salesperson problem [ 161, a signal processing problem [34], and a linear programming problem [34]. Inspired by their results, a number of researchers have applied feedback networks to such diverse problems as object recognition [21], graph planarization [33], graph coloring [5], nonthreatening queen placement [31], detecting graph isomorphism [31], and concentrator assignment [30].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, m only when the decision variables XI, Xz, e , X, represent feasible solutions. By additively combining the penalty functions with F, the original constrained optimization problem may be reformulated [2] as an unconstrained problem in which the goal is to minimize the quantity m k=l When a(&gt; 0) is a sufficiently large scaling factor for the penalty terms, minimizing F* yields a minimal, feasible solution to the original problem. Furthermore, if F* can be written in the form of the energy function given in (4), there is a corresponding neural network whose equilibria represent solutions to the problem. Suppose an objective function F can be expressed in the form of the energy function as constraints ck (k = 1,2, . . . , m ) can also be expressed in the form of the energy function as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Network for selecting IC of 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. ' h o intersecting sets of neurons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Network that permits up to 3 of 4 neurons to be in state 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig. 7. The network model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Fig. 8. Highlighted target plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Fig. 9. Highlighted weapon constraint set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Fig. 10. Hardware accelerator architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Fig. 11. Mapping the network onto the architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Neurons: A shot hypothesis neuron XaJt</figDesc><table><row><cell cols="4">is connected to all neurons in its target plane with strength</cell></row><row><cell cols="4">(26), to all shot hypothesis neurons in its weapon TXt,tX,'),' obi</cell></row><row><cell cols="4">plane with strength TXWP,,x,,,,, (30), and to the slack neuron</cell></row><row><cell cols="4">in its weapon constraint set with strength Ts",%,,, (31). The</cell></row><row><cell cols="4">external input to a shot hypothesis neuron consists of two</cell></row><row><cell>components:</cell><cell cols="2">(27) and</cell><cell>(28). The rate of change of</cell></row><row><cell cols="4">the activation for neuron XaJt is therefore:</cell></row><row><cell></cell><cell>j '</cell><cell>t'</cell></row></table><note><p><p>+</p>+ I;:,.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE I EXPECTED</head><label>I</label><figDesc>VALUE OF TARGETS COUNTERED urai Net Expected Value I 35.89 I</figDesc><table><row><cell>I</cell><cell>Time (s)</cell><cell>I 0.41 I</cell><cell>37.55 14.24</cell><cell>[ I</cell><cell>39.01 &lt;8</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors express thanks to J. Chester and J. Engvall of the Space Information Systems Division of Loral Corporation for providing us the opportunity to execute our simulations on the b r a 1 parallel neural network accelerator. Special thanks are due to G. McIntire and M. Hanson of b r a 1 Corporation for assisting us in partitioning the network for efficient execution on the b r a 1 architecture.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the U.S. Army Strategic Defense Command.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image compression by backpropagation: An example of extensional programming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICs Rep. 8702, Univ. of California at San Diego</title>
		<imprint>
			<date type="published" when="1967-10">1967. Sept./Oct. 1983. Feb. 1987</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="815" to="826" />
		</imprint>
	</monogr>
	<note>A theory of adaptive pattern classifiers</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural network algorithm for an NP-complete problem: Map and graph coloring</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st. Int. Conj Neural Networks</title>
		<meeting>1st. Int. Conj Neural Networks<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="11S" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cognitron: A self-organizing multilayered neural network</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="121" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis of hidden units in a layered network trained to classify sonar targets</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="89" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Studies of Mind and Brain: Neural Principles of Learning, Perception, Development, Cognition, and Motor Control</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Reidel</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonlinear neural networks: Principles, mechanisms, and architectures</title>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">l</biblScope>
			<biblScope unit="issue">l</biblScope>
			<biblScope unit="page" from="17" to="61" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A novel objective function for improved phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hammerstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Hampshire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN&apos;W</title>
		<meeting>IJCNN&apos;W<address><addrLine>San Diego, CA; Neurocompuring. Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1990-06">June. June 1990. 1990</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="216" to="228" />
		</imprint>
	</monogr>
	<note>A VLSI architecture for high-performance, low-cost, on-chip learning</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An electrically trainable artificial neural network (ETA&quot;) with 10240 &apos;floating gate&apos; synapses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Holler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf Neural Networks</title>
		<meeting>Int. Joint Conf Neural Networks<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982-06">June. 1982</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
		</imprint>
	</monogr>
	<note>Neural networks and physical systems with emergent collective computational abilities</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neurons with graded response have collective computational properties like those of two-state neurons</title>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="3088" to="3092" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural&apos; composition of decisions optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Tank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="141" to="152" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Computing with neural circuits: A model</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">233</biblScope>
			<biblScope unit="page" from="625" to="633" />
			<date type="published" when="1986-08">Aug. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stock market prediction system with modular neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asakawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN&apos;W</title>
		<meeting>IJCNN&apos;W</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An introduction to neural computing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning process in an asymmetric threshold network</title>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Disordered Systems and Biological Organization</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Bienenstwk</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A hierarchical multiple-view approach to three-dimensional object recognition</title>
		<author>
			<persName><forename type="first">W-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F-Y.</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-K</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lmgutla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="84" to="92" />
			<date type="published" when="1991-01">Jan. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weapon allocation is NPcomplete</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Witsenhausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1986 Summer Comput</title>
		<meeting>1986 Summer Comput<address><addrLine>Reno, NV; Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1979">1986. 1979. 17-21, 1990. 1989</date>
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Analog VLSI and Neural Systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Mead</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neuromorphic electronic systems</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-10">Oct. 1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1629" to="1636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Solutions to a probabilistic resource allocation problem</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Metler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Preston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th IEEE Conj Decision and Contr</title>
		<meeting>28th IEEE Conj Decision and Contr<address><addrLine>Tampa, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-12">Dec. 1989</date>
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identilication and control of dynamical systems using neural networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="27" />
			<date type="published" when="1990-03">Mar. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithm development for neural networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Tagliarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Symp. Innovative Sci. and Technol</title>
		<meeting>SPIE Symp. Innovative Sci. and Technol<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">880</biblScope>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning logic: Casting the cortex of the human brain in silicon</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Parker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TR-47, M.I.T. Center for Computational Research in Economics and Management Science</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-02">Feb. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Bradford</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
		<respStmt>
			<orgName>PDP Research Group</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A neural-network solution to the concentrator assignment problem</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Tagliarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conj Neural Information Processing Systems -Natural and Synthetic</title>
		<meeting>IEEE Conj Neural Information essing Systems -Natural and Synthetic<address><addrLine>Denver, CO, IEEEIAIP</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Undesirable equilibria in systematically designed neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Tagliarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ist. Int. Conj Neural Networks</title>
		<meeting>Ist. Int. Conj Neural Networks<address><addrLine>San Diego, CA; Columbia, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-04">1987. Apr. 1989</date>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="63" to="67" />
		</imprint>
	</monogr>
	<note>Proc. IEEE SOUTHEASTCON&apos;89</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A near optimum parallel planarization algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Takefuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">245</biblScope>
			<biblScope unit="page" from="1221" to="1223" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple &apos;neural&apos; organization networks: An A/D converter, signal decision circuit and a linear programming circuit</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Tank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Sw</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="741" to="748" />
			<date type="published" when="1987-05">May 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Beyond regression: New tools for predicting and analysis in the behavioral sciences</title>
		<author>
			<persName><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
		</imprint>
		<respStmt>
			<orgName>Harvard Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">30 years of adaptive neural networks: Perceptron, madeline, and backpropagation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-09">Sept. 1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1415" to="1442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">After studying biblical languages and theology at Southwestern Baptist Theological Seminary, he taught in the Department of Mathematics at Montreat-Anderson College and in the Department of Computer Science at the University of North Carolina at Asheville. Currently, he is a research associate and Assistant Professor in the Department of Computer Science at Clemson University. His research focuses on developing design primitives that can be combined to produce complex neural neworks for solving nonlinear optimization problems. He is also interested in expert systems, genetic algorithms, and hybrids of the two which may be used for neural network design. J. Fury Christ was born in Washington, DC. He received the B.S. and M.S. degrees in electrical and computer engineering from Clemson University in 1978 and 1981, respectively. Between 1981 and 1987 he worked in industry as an electrical engineer</title>
		<author>
			<persName><forename type="first">Gene</forename><forename type="middle">A</forename><surname>Tagliarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">degrees in mathematics from the University of South Florida in 1970 and 1971, respectively, and the Ph</title>
		<meeting><address><addrLine>Clemson, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>D. in computer science from Clemson University</orgName>
		</respStmt>
	</monogr>
	<note>Presently, he is a Ph.D. candidate at Clemson University and an independent consultant. His research interests are in nondeterministic optimization techniques and special purpose computer architectures</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">He also has government experience with the US. Army Missile Command, Redstone Arsenal, AL. Prior to joining Clemson University in 1975, he was on the electrical engineering faculty at Rice University. His research interests include computer architecture, telecommunications, and biologically inspired computing. He has served as a consultant to a number of government and industry organizations including the Congressional Office of Technology</title>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">W</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">(s'</forename><surname>Wm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Clemson University in 1965, the M.S. degree from the University of Alabama, Huntsville, in 1968, and the Ph</title>
		<meeting><address><addrLine>Huntsville, AL, and Research Triangle Institute, Research Triangle Park, NC</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>He is a Professor of Computer Science at Clemson University. He has industrial experience with Teledyne Brown. Assessment where he served as chairman of a panel on telecommunication technology</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
