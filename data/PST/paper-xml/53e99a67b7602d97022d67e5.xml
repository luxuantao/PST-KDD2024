<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Merging Partial Behavioural Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Uchitel</surname></persName>
							<email>s.uchitel@doc.ic.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Imperial College 180 Queen&apos;s Gate London</orgName>
								<address>
									<postCode>SW7 2RH</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marsha</forename><surname>Chechik</surname></persName>
							<email>chechik@cs.toronto.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<addrLine>40 St. George Street</addrLine>
									<postCode>M5S 2E4</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Merging Partial Behavioural Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A79C88E627B0922856889D328E51BF2F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.2.1 [Software Engineering]: Requirements/Specifications Design MTS</term>
					<term>Merge</term>
					<term>Partial Behaviour Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Constructing comprehensive operational models of intended system behaviour is a complex and costly task. Consequently, practitioners have adopted techniques that support incremental elaboration of partial behaviour descriptions. A noteworthy example is the wide adoption of scenario-based notations such as message sequence charts. Scenario-based specifications are partial descriptions that can be incrementally elaborated to cover the system behaviour that is of interest. However, how should partial behavioural models described by different stakeholders with different viewpoints covering different aspects of behaviour be composed? How should partial models of component instances of the same type be put together?</p><p>In this paper, we propose model merging as a general solution to these questions. We formally define model merging based on observational refinement and show that merging consistent models is a process that should result in a minimal common refinement. Because minimal common refinements are not guaranteed to be unique, we argue that the modeller should participate in the process of elaborating such a model. We also discuss the role of the least common refinement and the greatest lower bound of all minimal common refinements in this elaboration process. In addition, we provide algorithms for i) checking consistency between two models; ii) constructing their least common refinement if one exists; iii) supporting the construction of a minimal common refinement if there is no least common refinement.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>State-based behaviour modeling and analysis has been shown to be successful in uncovering subtle design errors <ref type="bibr" target="#b3">[3]</ref>. However, the adoption of such technologies by practitioners has been slow. Partly, this is due to the difficulty of constructing behavioural models -this task requires considerable expertise in modeling notations that developers often lack. In addition, and perhaps more importantly, the benefits of the analysis appear after comprehensive behavioural models have been built: classical state-based modeling approaches are generally not suited for providing early feedback, when system descriptions are still partial.</p><p>In contrast, interaction-based specifications, such as message sequence charts <ref type="bibr" target="#b11">[11]</ref>, are becoming increasingly popular. These scenario-based notations are partial behavioural descriptions that promote incremental elaboration of system behaviour.</p><p>Lately, there has been interest in developing an understanding and exploiting the relation between interactionbased and state-based modeling techniques <ref type="bibr" target="#b20">[20]</ref>. In particular, several approaches to the synthesis of state-based models from scenarios-based specifications (e.g. <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b14">14]</ref>) have been developed. These approaches aim to combine the benefits of the incremental elaboration in interaction-based specifications with the behavioural analysis in state-based models.</p><p>A current limitation of synthesis approaches is that the models being synthesized, e.g., labeled transition systems (LTSs) <ref type="bibr" target="#b13">[13]</ref>, are assumed to be complete descriptions of the system behaviour up to some level of abstraction, i.e., the state machine is assumed to completely describe the system behaviour with respect to a fixed alphabet of actions. This completeness assumption is limiting, considering that interaction-based specifications are inherently partial.</p><p>A more appropriate type of state-based model to synthesize is the one in which currently unknown aspects of behaviour can be explicitly modelled. Hence, these models can distinguish between positive, negative and unknown behaviours. Positive behaviour refers to the behaviour the system is expected to exhibit; negative behaviour refers to the behaviour the system is expected to never exhibit; unknown behaviour could become positive or negative, but the choice has not yet been made. State-based models that distinguish between these kinds of behaviour are referred to as partial behavioural models, e.g., Partial Labelled Transition Systems (PLTSs) <ref type="bibr" target="#b22">[22]</ref>, multi-valued state machines <ref type="bibr" target="#b6">[6]</ref>, Modal Transition Systems (MTSs) <ref type="bibr" target="#b15">[15]</ref>, Mixed Transition Systems <ref type="bibr" target="#b5">[5]</ref> and multi-valued Kripke structures <ref type="bibr" target="#b2">[2]</ref>.</p><p>Although synthesis of partial behavioural models can provide substantial benefits <ref type="bibr" target="#b22">[22]</ref>, we have found that such models lack a specific concept that is particularly helpful in the context of behavioural model elaboration, namely, model merging. Scenarios are typically provided by different stake-holders with different viewpoints <ref type="bibr" target="#b9">[9]</ref>, describing different, yet overlapping aspects <ref type="bibr" target="#b4">[4]</ref> of the same system. How should these partial models be put together? Alternatively, consider combining behavioural models of component instances of the same type. Typically, several instances of the same component may appear in a given scenario, e.g., several instances of a client component that concurrently access a server. Standard approaches to synthesis produce a separate behavioural model for each client instance (e.g. <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b14">14]</ref>). However, it is reasonable to integrate all models of all client instances into a model for the client component type because all clients should share the same characteristics. How can these partial models be composed?</p><p>Composition of behavioural models is an old idea <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b8">8]</ref>; however, its main focus has been on parallel composition which describes how two different components work together. In the context of model elaboration, what we are interested in is composing two partial descriptions of the same component to obtain a more elaborate version of both original partial descriptions. We call this operation a merge.</p><p>In this paper, we introduce the notion of merging in the context of an adaptation of MTSs <ref type="bibr" target="#b15">[15]</ref>. We argue that the core concept underlying model merging is that of common observational refinement and define consistency as the existence of a common observational refinement. We show that merging consistent models is a process that should result in a minimal common observational refinement and discuss the role of the least common observational refinement and the greatest lower bound of all minimal common observational refinements in this process. We also provide algorithms that under a determinacy condition automatically check consistency, construct the least common observational refinement if there is one, and support the construction of a minimal common observational refinement otherwise.</p><p>The rest of this paper is organized as follows. In Section 2, we define MTSs and observational refinement. Section 3 describes merging MTSs. Section 4 presents the algorithms associated with the merging. We review related work in Section 5 and conclude the paper with a discussion, summary and directions for future research. Due to space restrictions, this paper does not include a more complex example to illustrate our approach; however, one can be found online <ref type="bibr" target="#b21">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>In this section, we define, exemplify and discuss labelled transition systems, modal transition systems and refinement.</p><p>We start with the familiar concept of labeled transition systems (LTSs) <ref type="bibr" target="#b13">[13]</ref> which are widely used for modelling and analyzing the behaviour of concurrent and distributed systems <ref type="bibr" target="#b3">[3]</ref>. An LTS is a state transition system where transitions are labelled with actions. The set of actions of an LTS is called its communicating alphabet and constitutes the interactions that the modelled system can have with its environment. In addition, LTSs can have transitions labelled with τ , representing actions that are not observable by the environment. Examples of a graphical representation of LTSs are models A and B, given in Figure <ref type="figure" target="#fig_9">1</ref>. In this paper, the state labelled 0 is assumed to be the initial state of the transition system, unless stated otherwise. Definition 1. (Labeled Transition Systems) Let States be a universal set of states, Act be a universal set of observable action labels, and let Actτ = Act ∪ {τ }. A labeled transition system (LTS) is a tuple P = (S, L, ∆, s0), where S ⊆ States is a finite set of states, L ⊆ Actτ is a set of labels, ∆ ⊆ (S × L × S) is a transition relation between states, and s0 ∈ S is the initial state. We use αP = L \ {τ } to denote the communicating alphabet of P .</p><p>Existing semantics for LTSs assume that an LTS gives a complete behavioural description with respect to its alphabet. Consider the LTS A which models a read lock. Starting in state 0, this model allows sequences of alternating acquireReadLock and releaseReadLock actions, and, by the completeness assumption, does not allow two acquire-ReadLocks actions without having a releaseReadLock action in between. LTS A is modelling a lock that can be held by at most one reader at any time. Model B, on the other hand, allows two readers to hold the lock simultaneously. A and B are not considered to be equivalent under any of the standard equivalence relations such as strong bisimulation, trace, observational, or failure equivalence <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b18">18]</ref>.</p><p>Modal transition systems (MTSs) allow explicit modelling of what is not known about the behaviour of a system. MTSs extend LTSs with an additional set of transitions that model the interactions with the environment that the system cannot be guaranteed to provide, but equally cannot be guaranteed to prohibit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2. (Modal Transition Systems</head><formula xml:id="formula_0">) A modal transition system (MTS) M is a structure (S, L, ∆ r , ∆ p , s0), where ∆ r ⊆ ∆ p , (S, L, ∆ r , s0</formula><p>) is an LTS representing required transitions of the system and (S, L, ∆ p , s0) is an LTS representing possible (but not necessarily required) transitions of the system. We use αM = L \ {τ } to denote the communicating alphabet of M .</p><p>Figure <ref type="figure" target="#fig_9">1</ref> shows a graphical representation of some MTSs. For example, the MTS C models a partial policy for a read lock that can be acquired by at least one reader at any time, but does not rule out concurrent readers. Transition labels that have a question mark are those in ∆ p -∆ r . We refer to these as "maybe" transitions, to distinguish them from required transitions (those in ∆ r ). Note that LTSs are a special type of MTSs that do not have maybe transitions; thus, models A and B can be considered MTSs as well.</p><p>Given an MTS M = (S, L, ∆ r , ∆ p , s0), we say M transitions on through a required transition (denoted M -→r M ) if M = (S, L, ∆ r , ∆ p , s 0 ) and (s0, , s 0 ) ∈ ∆ r . Similarly, we say M transitions on through a maybe transition</p><formula xml:id="formula_1">(M -→m M ) if (s0, , s 0 ) ∈ ∆ p -∆ r . M -→p M refers</formula><p>to possible transitions ((s0, , s 0 ) ∈ ∆ p ). We write M -→p to mean ∃M • M -→p M . We say that M proscribes (M -→) if M cannot transit on through maybe or required transitions. Finally, for an MTS M = (S, L, ∆ r , ∆ p , s0) and a state n ∈ S, we denote changing the initial state of M from s0 to n as Mn. For example, some transitions of the MTS C, shown in Figure <ref type="figure" target="#fig_9">1</ref>, are C0 acquireReadLock -→r C1 (between states 0 and 1), and C1 releaseReadLock -→m C1 (self-loop in state 1). In this presentation, we associate each MTS with its communicating alphabet, extending the presentation of <ref type="bibr" target="#b15">[15]</ref>. The communicating alphabet is the set of events that are relevant to the model, i.e., the scope of a partial description. Allowing models to have different scopes is fundamental for merging descriptions of different concerns and viewpoints. In addition, our choice is in line with process algebra semantics such as FSP <ref type="bibr" target="#b17">[17]</ref>.</p><p>Refinement of MTSs captures the notion of elaboration of a partial description into a more comprehensive one, in which some knowledge over the maybe behaviour has been gained. It can be seen as being a "more defined than" relation between two partial models. Intuitively, refinement in MTSs is about converting maybe transitions into required transitions or removing them altogether: an MTS N refines M if N preserves all of the required and all of the proscribed behaviours of M . Alternatively, an MTS N refines M if N can simulate the required behaviour of M , and M can simulate the possible behaviour of N . Definition 3. (Refinement) Let ℘ be the universe of all MTSs. N is a refinement of M , written M N , when αM = αN and (M, N) is contained in some refinement relation R ⊆ ℘ × ℘ for which the following holds for all ∈ Actτ :</p><formula xml:id="formula_2">1. (M -→r M ) ⇒ (∃N • N -→r N ∧ (M , N ) ∈ R) 2. (N -→p N ) ⇒ (∃M • M -→p M ∧ (M , N ) ∈ R)</formula><p>Note that the second condition guarantees that if N has a required transition, M has a maybe or a required transition, whereas if N has a maybe transition, then M has a maybe transition -otherwise, the first condition is violated. Consider the MTSs shown in Figure <ref type="figure" target="#fig_9">1</ref>. The MTS C is refined by the LTS A (C A), incorporating the new knowledge that the maybe self-loop at state C1 should be removed. The refinement relation between these models is R = {(C0, A0), (C1, A1)}. The LTS B refines C (C B), with the refinement relation R = {(C0, B0), (C1, B1), (C1, B2)}. Finally, the MTS D refines C via the relation R = {(C0, D0), (C1, D1), (C1, D2)}.</p><p>Although refinement captures the notion of model elaboration, it requires the alphabets of the processes being compared to be equal. In practice, model elaboration can lead to augmenting the alphabet of the system model to describe behavioural aspects that previously had not been taken into account. To capture this aspect of model elaboration, we introduce two concepts: hiding and observational refinement.   Hiding is an operation that makes a set of actions of a model unobservable to its environment by reducing the alphabet of the model and replacing transitions labelled with an action in the hiding set by τ , as shown in Figure <ref type="figure" target="#fig_0">2</ref>. Definition 4. (Hiding) Let M = (S, L, ∆ r , ∆ p , s0) be an MTS and X ⊆ Act be a set of observable actions. M with the actions of X hidden, denoted M \X, is an MTS (S, L\X, ∆ r , ∆ p , s0), where ∆ r and ∆ p are the smallest relations that satisfy the rules in Figure <ref type="figure" target="#fig_0">2</ref>. We use M @αX to denote M \(Act\X).</p><formula xml:id="formula_3">M -→γ M (M \X) -→γ (M \X) ∈ X, γ ∈ {r, m} M -→γ M (M \X) τ -→γ (M \X) ∈ X, γ ∈ {r, m}</formula><formula xml:id="formula_4">a) E@X H@X G@X F @X C A D B H @X ✻ ❏ ❏ ❏  ✒ ✻ y y y y y (b) F G E H H ✡ ✡ ✡ ✣ ✻ ✻ ✼</formula><p>Let w = w1, . . . , w k be a word over Actτ . Then M w -→r N means that there exist M0, . . . , M k such that M0 = M , M k = N , and Mi</p><formula xml:id="formula_5">w i+1 -→r Mi+1 for 0 ≤ i &lt; k. We use M =⇒r M to denote M τ * τ * -→r M . On the other hand, M w -→m N means that there exist M0, . . . , M k such that M0 = M , M k = N , Mi w i+1 -→p Mi+1, for 0 ≤ i &lt; k, and ∃j • 0 ≤ j ≤ k • Mj w j+1</formula><p>-→m Mj+1, i.e., there is at least one maybe transition on some letter of w. We use</p><formula xml:id="formula_6">M =⇒m M to denote ∃M •M τ * -→m M and M τ *</formula><p>-→r M , i.e., the maybe transition precedes on the path from M to M . Finally, for γ ∈ {r, m, p}, we extend =⇒γ to words in the same way as we do for -→γ.</p><p>To compare a model with another one with an augmented alphabet, we must hide the additional actions in the second model and then use observational refinement -effectively, refinement that ignores differences in τ transitions.</p><formula xml:id="formula_7">Definition 5. (Observational Refinement) N is an ob- servational refinement of M , written M O N , if αM = αN and (M, N) is contained in some refinement relation R ⊆ ℘ × ℘</formula><p>for which the following holds for all ∈ Act:</p><formula xml:id="formula_8">1. (M =⇒r M ) ⇒ (∃N • N =⇒r N ∧ (M , N ) ∈ R) 2. (N =⇒p N ) ⇒ (∃M • M =⇒p M ∧ (M , N ) ∈ R)</formula><p>These conditions exclude the case in which N has a required transition on , whereas M has a maybe transition.</p><p>Consider again the MTSs shown in Figure <ref type="figure" target="#fig_9">1</ref>. In model E , if a process acquires the write lock, then the read lock cannot be acquired until the write lock is released. Note that this model does not indicate that processes are actually allowed to acquire the write lock, as these transitions are maybe. Hiding the actions acquireWriteLock and releaseWriteLock, results in an MTS just like E but with labels acquireWriteLock? and releaseWriteLock? changed to τ ?. Furthermore, the resulting model is observationally refined by the MTS D:</p><formula xml:id="formula_9">E = E \ {acquireWriteLock, releaseWriteLock} O D</formula><p>where the refinement relation is:</p><formula xml:id="formula_10">R = {(E 0 , D0), (E 1 , D1), (E 2 , D2), (E 3 , D0)}</formula><p>In fact, E is also a refinement of D via the inverse of R. We say that E and D are observationally equivalent, written E ≡O D.</p><p>Figure <ref type="figure" target="#fig_10">3</ref> depicts observational refinements that hold between models in Figure <ref type="figure" target="#fig_9">1</ref>. Each graph relates models with the same alphabet: X = {acquireReadLock, releaseRead-Lock} in Figure <ref type="figure" target="#fig_10">3</ref>(a) and Y = X ∪ {acquireWriteLock, releaseWriteLock} in Figure <ref type="figure" target="#fig_10">3(b)</ref>. Nodes with multiple labels indicate models that are observationally equivalent. Note that models A, B, C, and D have the alphabet X. Consequently, they cannot be related through observational refinement to models with an augmented alphabet Y , i.e. E , F, G, H, and H . For this reason, A through D do not appear in Figure <ref type="figure" target="#fig_10">3(b)</ref>. However, these models can be related through observational refinement to E , F, G, H, and H if the latter have their alphabets restricted to X, and are depicted in Figure <ref type="figure" target="#fig_10">3(a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MERGING MODELS</head><p>In this section, we introduce the notion of merging modal transition systems. Figure <ref type="figure" target="#fig_3">4</ref> provides an abstract summary of the concepts discussed in this section. In this figure, arrows depict observational refinements (i.e., an edge from P to Q indicates that Q is a refinement of P ). All models are assumed to have the same alphabet, and transitive relations are not depicted.</p><p>The intuition we wish to capture by merging is that of augmenting the knowledge we have of the behaviour of a system by taking what we know from the two partial descriptions of the system. Clearly, the notion of refinement underlies this intuition as it captures the "more defined than" relation between two partial models. Hence, merging two models of the same system is about finding a common refinement for these models, i.e., finding a model that is more defined than both.</p><p>It is possible that the models being merged have different alphabets. Merging these models results in a model whose alphabet is a superset of the original ones. Hence, the merge of two partial behavioural models should be an observational refinement of each with appropriately restricted alphabets. Definition 6. (Common Observational Refinement) A modal transition system P is a common refinement of modal transition systems M and N if αP ⊇ (αM ∪ αN ), M O P @αM and N O P @αN .</p><p>From this point on, when we refer to common refinement, we always mean observational refinement.</p><p>Refer to Figure <ref type="figure" target="#fig_9">1</ref> for the following example. The MTS F specifies the writers policy for acquiring a read-write lock: i) readers exclude writers, ii) writers exclude readers, iii) at most one writer can have the lock at any given time, iv) the number of concurrent readers allowed is not known. We can merge F with the MTS D that states that there can be at least two concurrent readers. Model H is a common refinement of these models. Note that D O H\{ acquireWriteLock, releaseWriteLock} holds via the relation R = {(D0, H0), (D1, H1), (D2, H2), (D0, H3)} and F O H holds via the relation</p><formula xml:id="formula_11">R = {(F0, H0), (F1, H3), (F2, H2), (F2, H1)}</formula><p>H is a refinement of D and F and thus can simulate the required behavior of D and F. For example, like D, H allows up to two readers to access the lock concurrently, e.g., the trace acquireReadLock, acquireReadLock, releaseReadLock, releaseReadLock, . . . Like F, H allows one writer to access the lock (e.g., the trace acquireWriteLock, releaseWriteLock, . . .). On the other hand, F and D can simulate the possible behaviour of H, i.e. H cannot introduce behaviour that is proscribed in F or D. If H had (possible) traces allowing concurrent access to the lock by readers and writers, e.g., acquireWriteLock, acquireReadLock, . . ., H would not be a refinement of F nor D, as these are not possible in F or D. Note that common refinement allows H to proscribe traces that were possible in F or D. In other words, H may not be able to simulate the possible behaviour of D and F. For example, the trace acquireReadLock, acquireReadLock, acquireReadLock, . . . that allows three or more concurrent readers, is a possible trace of F and D, but is proscribed in H.</p><p>Consequently, the merged model H introduces knowledge that neither of the original models has, e.g., proscribing three or more concurrent readers. Instead, we prefer a less refined model H that does not make such restrictions. H is called the least common refinement of D and F. Definition 7. (Least Common Refinement) A modal transition system P is the least common refinement of modal transition systems M and N if P is a common refinement of M and N , αP = αM ∪αN , and for any common refinement Q of M and N , P Q@αP .</p><p>The merge of modal transition systems cannot be defined as their least common refinement for two reasons. Firstly, it is possible that there is no common refinement at all. Secondly, it is possible that a common refinement exists, but there is no least one. We discuss these possibilities below.</p><p>Consider again the models in Figure <ref type="figure" target="#fig_9">1</ref>. Models A and B do not have a common refinement: suppose some model P is a common refinement of A and B, with αP = αA = αB, and w = acquireReadlock, acquireReadlock. We know that B w =⇒r B2, and because B O P , then ∃P such that P w =⇒r P . Since A O P , trace w should be possible in A, which is a contradiction. In fact, model A is inconsistent with all models that give concurrent read access to more than one process, namely B, D, E , H and H , as shown in Figure <ref type="figure" target="#fig_10">3</ref> It is not possible to find common refinements of I and J which are less refined than K and L. For example, P is less refined than both but is not a refinement of J . Hence, we refer to K and L as the minimal common refinements of I and J . Note that models M and N are incorrect attempts of building minimal common refinements of I and J . These are not refinements of I because they both can transit on c from the initial state through (a sequence of) required transitions, while I cannot do so from its initial state. Definition 9. (Minimal Common Refinement) An MTS P is a minimal common refinement of MTSs M and N if P is a common refinement of M and N , αP = αM ∪ αN ; and there is no MTSs Q ≡ P such that Q is a common refinement of M and N and Q@αP P .</p><p>Remark 1. If P is the least common refinement of M and N , it is also a minimal common refinement. In addition, if P is the only minimal common refinement of M and N , then it is also their least common refinement. Finally, if M and N are consistent, then they have a minimal common refinement.</p><p>If two models are consistent but have no least common refinement, then their merge could result in any of their minimal common refinements. However, any choice of minimal common refinement rules out the others! Hence, it is helpful to find a model that characterizes the point in which incompatible decisions must be made in order to merge two models and produce a minimal common refinement. This model is the greatest lower bound (glb) of all minimal common refinements. The glb is the most refined model from which we can arrive through refinement to any of the minimal common refinements. The glb always exists and is always unique with respect to observational equivalence. Note that the glb itself may not be a common refinement of the models being merged.</p><p>For example, the glb of the minimal common refinements of the models I and J (see Figure <ref type="figure" target="#fig_4">5</ref>) is the model P. Note that this model is not a refinement of J , but could be refined to become one. Further, any refinement of this model rules out the possibility of arriving at one of the minimal refinements (K or L).</p><p>The relationship between modes I through N is shown in Figure <ref type="figure" target="#fig_5">6</ref>. As in Figure <ref type="figure" target="#fig_10">3</ref>, each graph relates models with the same alphabets. Since J does not have a or b in its alphabet, it cannot be compared to the other models unless these have their alphabets restricted to αJ . Hence, J does not appear in Figure <ref type="figure" target="#fig_5">6(b)</ref>, where arrows depict observational refinement between models over the alphabet {a, b, c}. However, J does appear in Figure <ref type="figure" target="#fig_5">6(a)</ref>, where the compared models have the alphabet {c}. Definition 10. (Greatest lower bound) Let M and N be consistent modal transition systems. We say that an MTS Q is a lower bound of all minimal common refinements of M and N if αQ = αM ∪ αN and for any minimal common refinement P of M and N , it holds that Q P . We say that a lower bound of all minimal common refinements of M and N is the greatest lower bound (glb) if for any other lower bound Q , it holds that Q Q.</p><p>Remark 2. If P is the least common refinement of M and N , then, by Remark 1, P is also the glb of all minimal common refinements of M and N .</p><p>In conclusion, what should the result of merging two consistent modal transition systems M and N be? If M and N have the least common refinement, then this is the desired result of the merge. However, if M and N are consistent but do not have the least common refinement, then the merge process should result in one of the minimal common refinements of M and N . Model merging should support the modeller in choosing which minimal common refinement is the most appropriate. This can be done by producing the glb of all minimal common refinements of M and N and supporting its elaboration to produce a minimal common refinement. This would allow the modeller to choose, possibly after validating with stakeholders, which is the appropriate way of combining two different descriptions of the behaviour of the same system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MERGE ALGORITHMS</head><p>In this section, we present several algorithms for computing the merge of two MTSs. The basis of our algorithms is the +u operator. We discuss the use of this operator for checking consistency and its limitations for building the least and the minimal common refinements. We also present the + l operator and show how it can be used to build the least common refinement or a lower bound to all minimal common refinements. In the latter case, we show how to support the elaboration to obtain a minimal common refinement.</p><formula xml:id="formula_12">TD M -→r M M +uN -→r M +uN ∈ αN DT N -→r N M +uN -→r M +uN ∈ αM TM M -→r M , N -→mN M +uN -→r M +uN = τ MT M -→mM , N -→r N M +uN -→r M +uN = τ MD M -→mM M +uN -→r M +uN ∈ αN DM N -→mN M +uN -→r M +uN ∈ αM TT M -→r M , N -→r N M +uN -→r M +uN = τ MM M -→mM , N -→mN M +uN -→mM +uN = τ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Building a Common Refinement</head><p>We first introduce the +u operator and then show that assuming consistency and the determinacy condition, M +u N is a common refinement of M and N and also an upper bound to all minimal common refinements of M and N . </p><formula xml:id="formula_13">= (SM , LM , ∆ r M , ∆ p M , s0 M ), N = (SN , LN , ∆ r N , ∆ p N , s0 N ). M +u N is an MTS (SM ×SN , LM ∪LN , ∆ r , ∆ p , (s0 M , s0 N ))</formula><p>, where ∆ r and ∆ p are the smallest relations that satisfy the rules given in Figure <ref type="figure" target="#fig_6">7</ref>.</p><p>We explain the rules of Figure <ref type="figure" target="#fig_6">7</ref> below. Intuitively, the models being merged are run in parallel, synchronizing on shared actions and producing transitions in the merged model that amount to merging knowledge from both models. This means that maybe transitions in one model can be overridden by transitions that are known to be required or proscribed in the other. For instance, if M can transit on through a maybe transition, and N can do so via a required transition, then M +u N can transit on through a required transition as well, as indicated by rules TM and MT in Figure <ref type="figure" target="#fig_6">7</ref>. If M can transit on through a maybe transition and N cannot transit on , then M +u N cannot transit on .</p><p>For cases in which there is an agreement between both models, the rules are as expected. If both M and N can transit on over required transitions, then M +u N can do so as well, as indicated by the rule TT in Figure <ref type="figure" target="#fig_6">7</ref>. Maybe transitions in both models are treated similarly (see rule MM), and if neither models can transit on , then the composition cannot either.</p><p>The rules discussed so far create a composition that is a refinement of the original models: all required transitions are clearly preserved in the composition; furthermore, maybe transitions are introduced into the composition only if one of the original models has a maybe transition. We now address the problem of handling states in which the models disagree on whether the action is allowed or proscribed. Such states are disagreement states, formally defined below. -→m, then (I +u J )@αI is not a refinement of I. Instead, (I +u J ) should not have a transition on c. However, we must guarantee that (I +u J )@αJ is a refinement of J . Hence, because J c -→r J1, (I +u J )@αJ should be able to transit through required τ transitions to a state in which it can then make a required transition on c ((I +u J )@αJ c =⇒r). Special care needs to be taken when merging models with different alphabets. If a label does not belong to the alphabet of one of the models, this means that this model is not concerned with . Hence, if one of the models can transit on through a required transition, then the composition can do so too, but the state of the other model is unchanged, as is out of the scope. This is captured by TD and DT rules in Figure <ref type="figure" target="#fig_6">7</ref> ("D" stands for "do not care"). Similarly, if one model does not care about and the other cannot transit on it, then the composition should not either.</p><p>A similar reasoning could be applied to explain rules MD and DM in Figure <ref type="figure" target="#fig_6">7</ref>; however, note that these rules state that if M can transit on through a maybe transition and is not in N 's alphabet, then M +uN can transit on through a required transition rather than a maybe. For example, applying the +u operator to the models I and J in Figure <ref type="figure" target="#fig_4">5</ref>, results in the model O, which is their common refinement.</p><p>To prove that +u builds common refinements, we need to ensure that the models are consistent (see Section 4.2). We also must limit non-determinism in the models being composed. Consider the modal transition system X shown in Figure <ref type="figure" target="#fig_4">5</ref>. Composing this model with itself should yield X , whereas computing Y = X +u X yields a model which is not a refinement of X . The problem here is with the nondeterministic behaviour of X . From state 0, X can transition on a to either state 1 or state 2, and transitions enabled and proscribed in these states are different. Our +u operator cannot cope with such non-deterministic choices, so for the remainder of this paper, we assume that the models being composed satisfy the determinacy condition, i.e. they do not produce a composite state where there is a non-deterministic choice on some label that leads to states that are not observationally equivalent. Definition 13. (Determinacy Condition) Let M = (SM , LM , ∆ r M , ∆ p M , s0 M ) be an MTS. We say that Ms is nondeterministic on if there are states q and r in M such that Ms -→p Mq, Ms -→p Mr, and Mq ≡ Mr.</p><p>Let N = (SN , LN , ∆ r N , ∆ p N , s0 N ) be an MTS. We say that the determinacy condition holds for a composition C = (SM ×SN , LC , ∆ r C , ∆ p C , (s0 M , s0 N )) if for all reachable states (m, n) of C and all labels ∈ LM ∩ LN , it is not the case that Mm and Nn are non-deterministic on .</p><p>It is important to note that the determinacy condition is weaker than simply requiring MTSs to be deterministic. For example, in Figure <ref type="figure" target="#fig_9">1</ref>, state 3 of E has a non-deterministic choice over label releaseWriteLock. However, in E +u F, this state is reached when F is in state 1, which is deterministic on releaseWriteLock. The same happens with state 2 of F which is non-deterministic on releaseReadLock, but in E +u F, this state is reached when E is in states 1 or 2, both of which are deterministic on releaseReadLock. Thus, E +u F satisfies the determinacy condition, so the merge is possible. On the other hand, X +u X does not satisfy it in state (0, 0), and so the merge cannot be performed. Proof. The proof proceeds by showing that the rules TT, MM, MT, TM, DM, DT, MD, and DM in Figure <ref type="figure" target="#fig_6">7</ref> make the composition preserve required transitions of M and N , while the fact that no other rules are present ensures that M and N preserve the maybe transitions of the composition. There are two main points that the proof addresses: non-deterministic choice and disagreement states. Non-deterministic choice is handled the same way as proving that the parallel composition of deterministic processes can simulate the composed processes <ref type="bibr" target="#b18">[18]</ref>. The proof that disagreement states still result in a common refinement even though no transitions are produced in this case by the rules in Figure <ref type="figure" target="#fig_6">7</ref>, follows from consistency of M and N . Consistency guarantees that if a reachable state (m, n) has a disagreement on and Mm -→, then M must be able to transit through maybe transitions on actions that are unobservable to N and reach a state from which it can transit on , i.e., ∃w ∈ (Actτ \ αN ) * and ∃m such that Mm</p><formula xml:id="formula_14">w =⇒p M m</formula><p>and M m -→r. The MD rule converts maybe transitions that are unobservable to N into required transitions in the composite model, guaranteeing that (Mm +u Nn) -→r.</p><p>Finally, we address the precision of the +u operator: this operator does not build minimal common refinements. For example, I+uJ = O, whereas minimal common refinements of I and J are K and L (see Figure <ref type="figure" target="#fig_4">5</ref>). In fact, +u produces an overapproximation, or an upper bound with respect to the refinement ordering, of all minimal common refinements of the composed models, which is reflected in its name: "u" in +u stands for upper bound. We address this problem in Section 4.3.</p><p>Theorem 2. (+u is an upper bound of all minimal common refinements) If M and N are consistent and M +u N satisfies the determinacy condition, then for every Q that is a minimal common refinement of M and N , it holds that Q@α(M +u N ) 0 M +u N .</p><p>Proof. Any minimal common refinement Q of models M and N differs from M +u N only from the result of applying MD and MD rules: some required transitions of M +u N can be maybe transitions in Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Checking Consistency</head><p>We now present an algorithm for checking consistency of two MTSs under the assumption of the determinacy condition.</p><p>To check consistency of two MTSs M and N , we use the +u operator to build a composite model of M and N and meanwhile check what happens when a disagreement state is reached. The algorithm is shown in Figure <ref type="figure" target="#fig_11">8</ref>. Proof. The proof of the ⇐ direction follows directly from Theorem 1. The proof of the ⇒ direction is based on the similar reasoning as the proof of Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. (Consistency Check)</head><p>Input: MTSs M and N . Output: if M and N are consistent, return null; otherwise, return a disagreement state.</p><p>1: Build M +u N , marking each disagreement state 2: For each marked state (m, n)</p><formula xml:id="formula_15">3: If Nn -→ 4: If Nn w.</formula><p>-→ for some w ∈ (Actτ \αM ) * 5:</p><p>Return (m, n)</p><formula xml:id="formula_16">6: If Mm -→ 7: If Mm w.</formula><p>-→ for some w ∈ (Actτ \αN ) * 8:</p><p>Return (m, n) 9: Return null  Refer to MTSs in Figure <ref type="figure" target="#fig_9">1</ref>. Algorithm 1, applied to inconsistent models A and B, would return the pair (1, 2) signaling that this disagreement state (in which A proscribes the occurrence of acquireReadLock in state 1 while B has a required transition on the same label in state 2) is a source of inconsistency. If the algorithm is applied to models G and B, then the pair (2, 1) would be returned, signaling an inconsistency based on the fact that G constrains the number of readers to 1, while B allows two readers. Similarly, the algorithm would detect the inconsistencies between pairs (G and D) and (G and E ).</p><formula xml:id="formula_17">M + l N -→mM + l N ∈ αM MD M -→mM M + l N -→mM + l N ∈ αN</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Building a Lower Bound of the Merge</head><p>As we noted earlier, the operator +u computes a common refinement of consistent models M and N , but this refinement may not necessarily be minimal. Instead, we wish to provide an algorithm for constructing the least common refinement of M and N , if there is one, or the set of minimal common refinements otherwise. Here we present the + l operator and show that under the assumption of determinacy, it is a lower bound to all minimal common refinements. In Section 4.4, we discuss how to elaborate this model to become a minimal common refinement.</p><p>Recall that +u introduces imprecision through DM and MD rules, making the corresponding transition in M +u N required. Operator + l , defined below, relaxes these restrictions.</p><p>Definition 14. (The + l Operator) The + l operator is defined as +u, but replacing MD and DM rules of Figure <ref type="figure" target="#fig_6">7</ref> with those in Figure <ref type="figure" target="#fig_12">9</ref>.</p><p>Computing I + l J for the models shown in Figure <ref type="figure" target="#fig_4">5</ref> yields P, but as we discussed in Section 3, this model is not a refinement of J . Neither of the maybe transitions on a or on b in J have been converted to required transitions. + l computes an underapproximation, or the lower bound (thus the meaning of "l" in its name) of all minimal refinements of the models being merged, as stated below.</p><p>Theorem 4. (+ l is a lower bound of all minimal common refinements) If M and N are consistent and M + l N satisfies the determinacy condition, then for any minimal common refinement Q of M and N , M + l N 0 Q@α(M + l N ). Thus, M + l N approximates the greatest lower bound of M and N from below, and it would be reasonable to expect that our merge algorithms compute it and then help the modeller refine it into the minimal common refinement of his/her choice. Unfortunately, + l does not necessarily compute the actual glb. Consider merging the models J and V (see Figure <ref type="figure" target="#fig_4">5</ref>). Their least common refinement is W. However, V + l J results in V which is not a refinement of J . The point is that DM and MD rules for the merge operator should convert some maybe transitions into required transitions. But which transitions should be converted? If all are, as in the computation of +u, then minimality is lost. The right rules for computing glb for all minimal common refinements are somewhere between the MD and DM rules of +u and + l . The choice of which transitions should be converted is discussed in Section 4.4.</p><p>Clearly, if the DM and MD rules are never applied, then M +u N = M + l N . Further, both operators produce the least common refinement of M and N , if one exists and the determinacy condition holds. In particular, when models being merged have the same alphabet and no maybe τ transitions, then DM and MD rules are not applied.</p><p>Theorem 5. (Sufficient condition for + l to be the least common refinement) M + l N is the least common refinement of M and N if M and N are consistent, the determinacy condition holds for M + l N , and MD and DM rules have not been used.</p><p>In practice, we have found that the + l operator produces the least common refinement in many model merging contexts. In particular, it suffices for the readers and writers policies of Figure <ref type="figure" target="#fig_9">1</ref> and for the example in <ref type="bibr" target="#b21">[21]</ref>.</p><p>When none of the sufficient conditions of Theorem 5 hold, then the + l operator produces a model that can be refined into a minimal common refinement of both models by choosing an appropriate subset of maybe transitions generated by MD and DM rules and converting them into required transitions, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Elaboration</head><p>The goal of merging two consistent models is to arrive at their minimal common refinement. We now show how to refine a lower bound of all minimal common refinements, obtained via + l , into a minimal common refinement.</p><p>The reason why + l operator builds a lower bound to all minimal common refinements and may not even be a common refinement itself is that DM and MD rules result in maybe transitions, whereas sometimes required transitions should be produced instead. Suppose M +N Q is being constructed and disagreement state (m, n) is reached. Without loss of generality, assume that Mm -→r N n whereas Nn -→. Since M and N are assumed to be consistent, there exists w ∈ (αN \αM ) * and states n and n of N such that Nn we need to obtain (Mm + l Nn)\αM =⇒r (M m + l N n )\αM . In cases where the least common refinement exists, only one w can be produced, and this transformation can be fully automated. In cases where more than one w satisfies the above condition, several minimal common refinements are possible. To obtain one, we need to pick a w from the above set and transform (Mm + l Nn) w =⇒m (Mm + l N n ) into (Mm + l Nn) w =⇒r (Mm + l N n ). Further, different w traces can be used to give feedback to the user to support him/her in choosing the minimal common refinement that is most appropriate for the problem being modelled. The elaboration algorithm is shown in Figure <ref type="figure" target="#fig_13">10</ref>.</p><p>Note that we have to be careful in step 5 of the algorithm: potentially, there can be an infinite number of w traces from which a modeller could choose if there are maybe loops in N . An implementation of this elaboration process needs to provide a subset of such traces, in particular, by putting a bound on the number of times a maybe loop is taken. In fact, it is likely that once a disagreement state with several refinement options has been identified, the modeller would want to evaluate the options by inspecting or animating the models. Hence, step 5 could be simplified to checking whether the disagreement state has more than one refinement option, rather than computing all the options, and then requesting the user to convert one maybe transition to a required one.</p><p>An execution of the algorithm for models I and J of Figure <ref type="figure" target="#fig_4">5</ref> identifies the pair (0, 0) as a disagreement state on action c, and displays a? and b? as the options for refining the composition to achieve a minimal common refinement. Depending on the choice, either model K or L would be reached.</p><p>We now look at complexity of our algorithms for merging models M and N with SM and SN states and TM and TN transitions (Ti is O(Si × Li)). The potential size of the state space of a minimal common refinement of M and N is S = O(|SM | × |SN |). Checking whether M and N are con-sistent is very similar to checking weak bisimulation, and takes O(L + S × T ) <ref type="bibr" target="#b1">[1]</ref>, where T is the number of transitions and L = |LM ∪ LN | is the total number of actions in the merged model. Computing +u and + l does not increase this complexity. Finally, we analyze complexity of the elaboration algorithm. Step 5 of the algorithm can produce an exponential number of w, even if the number of times each maybe loop is N traversed a finite number of times. In fact, since these words are to be displayed to the user, it does not make sense to compute more than a few different w's. In this case, step 5 can be done by breadth-first search in the τ -graph of N , taking O(TN ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION AND RELATED WORK</head><p>Although our work discusses merging of MTSs <ref type="bibr" target="#b15">[15]</ref>, this notion is applicable to other partial behavioural models such as Partial Labelled Transition Systems (PLTS) <ref type="bibr" target="#b22">[22]</ref>, multivalued state machines <ref type="bibr" target="#b6">[6]</ref>, and Mixed Transition Systems <ref type="bibr" target="#b5">[5]</ref>. The underlying principle of all of these should be common observational refinement, although the exact definition of merge operators will differ according to the specific characteristics of each formalism.</p><p>To the best of our knowledge, there is no prior work specifically on merging models that describe the observable behaviour of a system. On the other hand, merging operational specifications in which system states are explicitly described is frequently done (e.g. <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b10">10]</ref>). In <ref type="bibr" target="#b24">[24]</ref>, states are modelled as valuations of state propositions, and states with compatible valuations can be merged. In <ref type="bibr">[7]</ref>, states can be merged only if they have the same label. <ref type="bibr" target="#b19">[19]</ref> proposes a more general approach, but the emphasis of this work is on preserving model structure (i.e., the states and the accessibility relation between them) rather than preserving behavioural properties. Our approach differs from the work on computing least common generalizations from examples, as merge preserves simulation (which is stronger than trace inclusion) on required transitions and (in the opposite direction) on possible transitions. Hussain and Huth <ref type="bibr" target="#b10">[10]</ref> also study the problem of finding a common refinement between multiple MTSs, focusing on the complexity of the relevant model-checking decision procedures. Instead, we address the more general problem of supporting engineering activities in model elaboration; we see merging as the process of selecting the most appropriate common refinement. In addition, we consider merging models with different alphabets. The goal of the work by Larsen et al. <ref type="bibr" target="#b16">[16]</ref> is to decompose a complete specification into several partial ones to enable compositional proofs. In doing so, they define a sufficient condition for constructing common refinements in MTSs with the same alphabet. Their condition is more restrictive than our determinacy condition.</p><p>Our work focuses on operational descriptions. However, an alternative approach is to specify observable behaviour declaratively <ref type="bibr" target="#b12">[12]</ref>. Declarative specifications based on classical logics are partial, yet they do not need to describe the unknown properties explicitly: such properties are those for which neither truth nor falsity can be inferred from the rest of the specification. Merging declarative behavioural specifications comes naturally as the conjunction of the corresponding theories; however, understanding which behaviours are possible is fairly difficult. Further, as in the case of operational descriptions, not all pairs of models have the least common refinement. Thus, some support for constructing an approximation of minimal common refinements and elaborating it into a desired minimal refinement is needed. To the best of our knowledge, there are no approaches that provide such support.</p><p>Larsen and Thomsen <ref type="bibr" target="#b15">[15]</ref> define a parallel composition operator over MTSs. Its intent is different from the ones presented in this paper. Parallel composition assumes that models being composed describe different systems, whereas merging treats those as different models of the same system. Note the difference between the TM and MT rules for parallel composition, shown in Figure <ref type="figure" target="#fig_7">11</ref>, with those for +u and + l : the combined model has a maybe transition in the former case and a required transition in the latter.</p><p>It is also important to note that our approach does not address ontological issues regarding the labels used in models being merged. Here we assume that labels have been used consistently according to one common ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SUMMARY AND FUTURE WORK</head><p>The motivation for the work presented in this paper comes from the need to support the elaboration of partial behaviour models. In particular, our work has been motivated by existing limitations of scenario-based model synthesis techniques, hence the focus on observable behaviour rather than on the model structure. However, our work could also be applicable in the context of composing models that cover different viewpoints <ref type="bibr" target="#b9">[9]</ref> or aspects <ref type="bibr" target="#b4">[4]</ref>.</p><p>We have argued that observational refinement is the formal underlying principle of model merging of partial behavioural models and that merging is a process that should produce a minimal common observational refinement of two consistent models. Modulo the determinacy condition, we have presented an algorithm for checking model consistency and algorithms for supporting the merge process. For the case in which there is only one minimal common refinement (i.e. the least common refinement exists), we have presented an algorithm that can build it automatically. For the other case, we have presented an algorithm that computes the lower bound of all minimal common refinements, which can then be elaborated by the modeller into the desired minimal common refinement.</p><p>In the near future, we expect to work on the efficiency of the algorithms presented in this paper and produce implementations for them. Experimentation using model merging remains to be done, and we aim to apply the algorithms in the context which has motivated our work, namely, scenariobased model synthesis and elaboration. We also intend to work on ways in which the determinacy condition for merging behavioural models can be weakened.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Rules for the hiding operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3: Observational refinements (without transitive relations) between models in Figure 1: (a): over the alphabet X = {acquireReadLock, releaseReadLock}; (b): over the alphabet X ∪ {acquireWriteLock, releaseWriteLock}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Building common refinement for models M and N : (a) M and N have the least common refinement; (b) M and N have no least common refinement.the same system is about finding a common refinement for these models, i.e., finding a model that is more defined than both.It is possible that the models being merged have different alphabets. Merging these models results in a model whose alphabet is a superset of the original ones. Hence, the merge of two partial behavioural models should be an observational refinement of each with appropriately restricted alphabets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example MTS I and J ; their minimal common refinements K and L; models M and N which are not common refinements of I and J ; O: the least upper bound of I and J ; P: the greatest lower bound of minimal refinements of I and J . W: a minimal common refinement of V and J . X : a non-deterministic MTS and Y: composition of X with itself that is not a refinement of X .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Relationships between some MTSs in Figure 5: (a) with respect to the alphabet {c}; (b) with respect to the alphabet {a, b, c}.must refine I into I so that (I \ {a, b}) c =⇒r. Hence, we must transform the maybe transition on c in I to a required transition and also transform one of the maybe transitions on a or b. If we transform all three transitions, we obtain the model O. If we choose not to transform the transition either on a or on b, then we obtain the models K and L. Note that these common refinements are not comparable (neither is a refinement of the other) because of the different choices made on which maybe transition to make required.It is not possible to find common refinements of I and J which are less refined than K and L. For example, P is less refined than both but is not a refinement of J . Hence, we refer to K and L as the minimal common refinements of I and J . Note that models M and N are incorrect attempts of building minimal common refinements of I and J . These are not refinements of I because they both can transit on c from the initial state through (a sequence of) required transitions, while I cannot do so from its initial state.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Rules for the +u operator.common refinement or a lower bound to all minimal common refinements. In the latter case, we show how to support the elaboration to obtain a minimal common refinement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Definition 11 .</head><label>11</label><figDesc>(The +u Operator) Let M and N be MTSs where M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Definition 12 .</head><label>12</label><figDesc>(Disagreement States) Let M and N be MTSs where M = (SM , LM , ∆ r M , ∆ p M , s0 M ) and N = (SN , LN , ∆ r N , ∆ p N , s0 N ). We say that (m, n) ∈ (SM × SN ) is a disagreement state if there exists a label ∈ (αM ∩ αN ) for which (1) Mm -→r and Nn -→ or (2) Mm -→ and Nn -→r. Consider the models I and J of Figure 5. We have that J c -→r J1 but that I c -→. If we allow I +u J to transition on c, i.e., (I +u J ) c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Theorem 1 .</head><label>1</label><figDesc>(+u builds a common observational refinement) If M and N are consistent modal transition systems and M +u N satisfies the determinacy condition, then M +u N is a common observational refinement of M and N .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Theorem 3 .</head><label>3</label><figDesc>(Consistency check algorithm is sound) If M +u N satisfies the determinacy condition, Algorithm 1 called with parameters M and N returns null if and only if M and N are consistent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Consistency checking algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Two rules for the + l operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>wFigure 10 :</head><label>10</label><figDesc>Figure 10: An Elaboration Algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>MTMFigure 11 :</head><label>11</label><figDesc>Figure 11: Rules for parallel composition operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Figure 1: LTSs and MTSs: A: at most one reader can acquire the lock; B: at most two readers can hold the lock concurrently. C: at least one reader can access the lock; D: at least two readers can hold the lock concurrently; E : readers cannot acquire the lock if it is held by writers; F: at most one writer can access the lock but not while readers hold it; G: at most one reader and writer and can access the lock but not concurrently; H: maximum two concurrent readers and one writer, readers and writers exclude each other. H : at least two concurrent readers and maximum one writer, readers and writers exclude each other.</head><label></label><figDesc></figDesc><table><row><cell cols="3">acquireReadLock</cell><cell></cell><cell cols="2">acquireReadLock</cell><cell>acquireReadLock</cell><cell></cell><cell></cell><cell cols="3">acquireReadLock</cell><cell></cell><cell>acquireReadLock</cell><cell>acquireReadLock</cell></row><row><cell>A: 0</cell><cell></cell><cell>1</cell><cell cols="2">B: 0</cell><cell>1</cell><cell cols="2">2</cell><cell cols="2">C: 0</cell><cell cols="2">1</cell><cell cols="2">acquireReadLock? releaseReadLock?</cell><cell>D: 0</cell><cell>1</cell><cell>2</cell><cell>acquireReadLock? releaseReadLock?</cell></row><row><cell cols="3">releaseReadLock</cell><cell></cell><cell cols="2">releaseReadLock</cell><cell>releaseReadLock</cell><cell></cell><cell></cell><cell cols="3">releaseReadLock?</cell><cell></cell><cell>releaseReadLock</cell><cell>releaseReadLock</cell></row><row><cell></cell><cell></cell><cell cols="2">releaseW riteLock?</cell><cell cols="2">acquireReadLock</cell><cell cols="2">acquireReadLock</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>releaseReadLock?</cell><cell>acquireW riteLock</cell><cell>releaseReadLock?</cell><cell>acquireW riteLock</cell></row><row><cell>E :</cell><cell></cell><cell>3</cell><cell>0</cell><cell></cell><cell>1</cell><cell></cell><cell cols="2">2</cell><cell></cell><cell>F :</cell><cell></cell><cell></cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>G :</cell><cell>2</cell><cell>0</cell><cell>1</cell></row><row><cell cols="2">releaseW riteLock? acquireW riteLock?</cell><cell cols="2">acquireW riteLock?</cell><cell cols="2">releaseReadLock</cell><cell cols="2">releaseReadLock</cell><cell cols="2">releaseReadLock? acquireReadLock?</cell><cell cols="3">releaseReadLock? acquireReadLock?</cell><cell>acquireReadLock?</cell><cell>releaseW riteLock</cell><cell>acquireReadLock?</cell><cell>releaseW riteLock</cell></row><row><cell></cell><cell cols="2">releaseW riteLock</cell><cell cols="2">acquireReadLock</cell><cell cols="2">acquireReadLock</cell><cell></cell><cell></cell><cell cols="2">releaseW riteLock</cell><cell cols="3">acquireReadLock</cell><cell>acquireReadLock</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>acquireReadLock?</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>releaseReadLock?</cell></row><row><cell>H:</cell><cell>3</cell><cell cols="2">0</cell><cell>1</cell><cell></cell><cell>2</cell><cell cols="2">H :</cell><cell>3</cell><cell>0</cell><cell></cell><cell></cell><cell>1</cell><cell>2</cell></row><row><cell></cell><cell cols="2">acquireW riteLock</cell><cell cols="2">releaseReadLock</cell><cell cols="2">releaseReadLock</cell><cell></cell><cell></cell><cell cols="2">acquireW riteLock</cell><cell cols="3">releaseReadLock</cell><cell>releaseReadLock</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Arie Gurfinkel and Shiva Nejati for their comments on an earlier draft of this paper and Michael Huth for many interesting discussions. We acknowledge EPSRC grant READS GR/S03270/01 and NSERC for partially funding this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Symbolic Bisimulation Minimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>De Simone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CAV&apos;92</title>
		<meeting>CAV&apos;92</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="96" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-Valued Symbolic Model-Checking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Devereux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Easterbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gurfinkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOSEM</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Formal Methods: State of the Art and Future Directions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="626" to="643" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Composition Patterns: An approach to Designing Reusable Aspects</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSE&apos;01</title>
		<meeting>ICSE&apos;01</meeting>
		<imprint>
			<date type="published" when="2001-05">May 2001</date>
			<biblScope unit="page" from="5" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Abstract Interpretation and Partition Refinement for Model Checking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Eindhoven University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reusing Verification Information of Incomplete Specifications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Diaz-Redondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pazos-Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fernandez-Vilas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Component-Based SE</title>
		<meeting>the Workshop on Component-Based SE</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Framework for Multi-Valued Reasoning over Inconsistent Viewpoints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Easterbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSE&apos;01</title>
		<meeting>ICSE&apos;01</meeting>
		<imprint>
			<date type="published" when="2001-05">May 2001</date>
			<biblScope unit="page" from="411" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A R</forename><surname>Hoare</surname></persName>
		</author>
		<title level="m">Communicating Sequential Processes</title>
		<meeting><address><addrLine>Englewood Cliffs, New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Managing Inconsistent Specifications: Reasoning, Analysis and Action</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nuseibeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOSEM</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="367" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">On Model Checking Multiple Hybrid Views</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-07">2004. July 2004</date>
			<publisher>Department of Computing</publisher>
			<pubPlace>Imperial College London</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Message Sequence Charts</title>
		<author>
			<persName><surname>Itu</surname></persName>
		</author>
		<idno>Recommendation Z.120</idno>
	</analytic>
	<monogr>
		<title level="m">International Telecommunications Union. Telecommunication Standardisation Sector</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Alloy: a Lightweight Object Modelling Notation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOSEM</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="256" to="290" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Formal Verification of Parallel Programs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="371" to="384" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Distributed and Parallel Embedded Systems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broy</surname></persName>
		</author>
		<editor>F. J. Rammig</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
	<note>From MSCs to Statecharts</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Modal Process Logic</title>
		<author>
			<persName><forename type="first">K</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LICS&apos;88</title>
		<meeting>LICS&apos;88</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Constraint Oriented Proof Methodology based on Modal Transition Systems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steffen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TACAS&apos;95</title>
		<meeting>TACAS&apos;95</meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
			<biblScope unit="page" from="13" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Magee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
		<title level="m">Concurrency: State Models and Java Programs</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons Ltd</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Milner</surname></persName>
		</author>
		<title level="m">Communication and Concurrency</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Analysis of Inconsistency in Graph-Based Viewpoints: A Category-Theoretic Approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sabetzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Easterbrook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ASE&apos;03</title>
		<meeting>ASE&apos;03</meeting>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m">ICSE Workshop on Scenarios and State Machines: Model, Algorithms and Tools (SCESM)</title>
		<imprint>
			<biblScope unit="page" from="2002" to="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Merging MTSs for a B2B E-Commerce Site</title>
		<author>
			<persName><forename type="first">S</forename><surname>Uchitel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chechik</surname></persName>
		</author>
		<ptr target="http://www.doc.ic.ac.uk/~su2/merge/examples" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Behaviour Model Elaboration using Partial Labelled Transition Systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Uchitel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ESEC/FSE&apos;03</title>
		<meeting>ESEC/FSE&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Synthesis of Behavioural Models from Scenarios</title>
		<author>
			<persName><forename type="first">S</forename><surname>Uchitel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TSE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="115" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Generating Statechart Designs from Scenarios</title>
		<author>
			<persName><forename type="first">J</forename><surname>Whittle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ICSE&apos;00</title>
		<meeting>ICSE&apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="314" to="323" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
