<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DieHard: Probabilistic Memory Safety for Unsafe Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Emery</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst Amherst</orgName>
								<address>
									<postCode>01003</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Benjamin</forename><forename type="middle">G</forename><surname>Zorn</surname></persName>
							<email>zorn@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<postCode>98052</postCode>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DieHard: Probabilistic Memory Safety for Unsafe Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1F870F0BFB8DBDB4A23C3C71B6EEB4C8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Applications written in unsafe languages like C and C++ are vulnerable to memory errors such as buffer overflows, dangling pointers, and reads of uninitialized data. Such errors can lead to program crashes, security vulnerabilities, and unpredictable behavior. We present DieHard, a runtime system that tolerates these errors while probabilistically maintaining soundness. DieHard uses randomization and replication to achieve probabilistic memory safety through the illusion of an infinite-sized heap. DieHard's memory manager randomizes the location of objects in a heap that is at least twice as large as required. This algorithm not only prevents heap corruption but also provides a probabilistic guarantee of avoiding memory errors. For additional safety, DieHard can operate in a replicated mode where multiple replicas of the same application are run simultaneously. By initializing each replica with a different random seed and requiring agreement on output, the replicated version of DieHard increases the likelihood of correct execution because errors are unlikely to have the same effect across all replicas. We present analytical and experimental results that show DieHard's resilience to a wide range of memory errors, including a heap-based buffer overflow in an actual application.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>While safe languages are now in wide use, the bulk of existing software applications are written in C and C++, two unsafe languages. These languages let programmers maximize performance but are error-prone. Memory management errors, which dominate recent security vulnerabilities reported by CERT <ref type="bibr" target="#b36">[37]</ref>, are especially pernicious. These errors fall into the following categories:</p><p>Dangling pointers: If a live object is freed, the allocator may overwrite its contents with a new object or heap metadata.</p><p>Buffer overflows: Out-of-bound writes can corrupt the contents of live objects on the heap.</p><p>Heap metadata overwrites: If heap metadata is stored near heap objects, it can be corrupted by overflows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uninitialized reads:</head><p>Reading values from newly-allocated or unallocated memory leads to undefined behavior.</p><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. University of Massachusetts Amherst Computer Science Technical Report 05-65 Copyright c 2005 ACM . . . $5.00.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Invalid frees:</head><p>Passing illegal addresses to free can corrupt the heap or lead to undefined behavior.</p><p>Double frees: Repeated calls to free of objects that have already been freed undermine the integrity of freelist-based allocators.</p><p>Tools like Purify <ref type="bibr" target="#b16">[17]</ref> and Valgrind <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34]</ref> allow programmers to pinpoint the exact location of these memory errors (at the cost of a 2-25X performance penalty), but only reveal those bugs found during testing. Deployed programs thus remain vulnerable to crashes or attack. Conservative garbage collectors can, at the cost of increased runtime and additional memory <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20]</ref>, disable calls to free and so eliminate three of the above errors (invalid frees, double frees, and dangling pointers). Assuming source code is available, a programmer can also compile the code with a safe C compiler that inserts dynamic checks for the remaining errors, further increasing running time <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref>. As soon as an error is detected, the inserted code aborts the program. While this fail-stop approach is safe, aborting a computation is often undesirable -users are rarely happy to see their programs suddenly stop. Recognizing this, some systems sacrifice soundness in order to prolong execution in the face of memory errors <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>. For example, failure-oblivious computing builds on a safe C compiler but drops illegal writes and manufactures values for invalid reads. Unfortunately, these systems provide no assurance to programmers that their programs are executing correctly.</p><p>We make the following contributions in this paper:</p><p>1. We introduce the notion of probabilistic memory safety, a probabilistic guarantee of avoiding memory errors.</p><p>2. We present DieHard, a runtime system that provides probabilistic memory safety. We show analytically and empirically that DieHard eliminates or avoids all of the memory errors described above with high probability.</p><p>The next section provides an overview of our approach and an outline of the rest of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Overview</head><p>DieHard provides two modes of operation: a stand-alone mode that replaces the default memory manager, and a replicated mode that runs several replicas simultaneously. Both rely on a novel randomized memory manager that allows the exact probabilities of detecting or avoiding memory errors to be computed.</p><p>The DieHard memory manager places objects randomly across a heap whose size is a multiple of the maximum required (Figure <ref type="figure">1</ref> shows an example heap layout). The resulting spacing between objects makes it likely that buffer overflows end up overwriting only empty space. Randomized allocation also makes it unlikely that a newly-freed object will soon be overwritten by a subsequent allocation, thus avoiding dangling pointer errors. It also improves app-Error GNU libc <ref type="bibr" target="#b24">[25]</ref> BDW GC <ref type="bibr" target="#b7">[8]</ref> CCured <ref type="bibr" target="#b26">[27]</ref> Rx <ref type="bibr" target="#b29">[30]</ref> Failure-oblivious <ref type="bibr" target="#b30">[31]</ref>  lication robustness by segregating all heap metadata from the heap (avoiding most heap metadata overwrites) and ignoring attempts to free already-freed or invalid objects. Despite its degradation of spatial locality, we show that the DieHard memory manager's impact on performance is small for many applications (average 8% across the SPECint2000 benchmark suite), and can actually improve application performance when running on Windows XP.</p><p>While the stand-alone version of DieHard provides substantial protection against memory errors, the replicated version both increases the protection and detects errors caused by illegal reads. In this mode of operation, DieHard executes multiple replicas of the same program simultaneously, each with different seeds to their respective randomized allocators. Errors like buffer overflows are thus likely to overwrite different areas of memory in the different replicas, and if overwritten, dangling pointers will likely be overwritten by different objects. DieHard intercepts output from all of the various replicas and compares the contents of each before transmitting any output. With high probability, whenever any two programs agree on their output, they executed safely. In other words, in any agreeing replicas, any buffer overflows only overwrote dead data, and dangling pointers were never overwritten. If an application's output depends on uninitialized data, these data will be different across the replicas, and thus will be detected by DieHard.</p><p>Since replacing the heap with DieHard significantly improves reliability, we believe that it is suitable for broad deployment, especially in scenarios where increased reliability is worth the space cost. For example, a buggy version of the Squid web caching server crashes on ill-formed inputs when linked with both the default GNU libc allocator and the Boehm-Demers-Weiser garbage collector, but runs correctly with DieHard. Using additional replicas can further increase reliability. While these would naturally increase execution time on uniprocessor platforms, we believe that the natural setting for using replication is on systems with multiple processors. It has proven difficult to rewrite applications to take advantage of multiple CPUs in order to make them run faster. DieHard can in- stead use the multiple cores on newer processors to make legacy programs run more reliably.</p><formula xml:id="formula_0">H = max heap size, class i L = max live size ≤ H/2 F = free = H-L object size = 2 i+1 object size = 2 i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Outline</head><p>The rest of this paper is organized as follows. Section 3 formalizes the notions of probabilistic memory safety and infinite-heap semantics, which probabilistic memory safety approximates. Section 4 then presents DieHard's fast, randomized memory allocator that forms the heart of the stand-alone and replicated versions. Section 5 describes DieHard's replicated variant. Section 6 presents analytical results for both versions, and Section 7 provides empirical results, measuring overhead and demonstrating DieHard's ability to avoid memory errors. Sections 8 discusses related work, and Section 9 concludes with a discussion of future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Probabilistic Memory Safety</head><p>For the purposes of this paper, we define a program as being fully memory safe if it satisifies the following criteria:</p><p>1. Never reads uninitialized memory, 2. Performs no illegal operations on the heap (no invalid/double frees), and 3. Doesn't access freed memory (no dangling pointer errors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Infinite-heap semantics</head><p>By aborting a computation that might violate one of these conditions, a safe C compiler provides full memory safety. However, we would ideally like an execution environment that would allow such programs to continue to execute correctly (soundly) in the face of these errors.</p><p>We can define such an idealized, but unrealizable, runtime system. We call this runtime system an infinite-heap memory manager, and say that it provides infinite-heap semantics. In such a system, the heap area is infinitely large, so there is no risk of heap exhaustion. Objects are never deallocated, and all objects are allocated infinitely far apart from each other. This heap semantics is the same as that assumed by the SLAM toolkit <ref type="bibr" target="#b3">[4]</ref> and the BLAST software model checker <ref type="bibr" target="#b18">[19]</ref>. <ref type="foot" target="#foot_0">1</ref>From the standpoint of a correct C program, there is no way to tell whether it is running with an ordinary heap implementation or an infinite heap. However, infinite-heap semantics allows programs to execute safely that would be rejected by a safe C compiler. Because every object is infinitely far from every other object, heap buffer overflows are benign -they never overwrite live data. The problems of heap corruption and dangling pointers also vanish because frees are ignored and allocated objects are never overwritten. However, uninitialized reads to the heap remain undefined. Unlike Java, the contents of newly-allocated C and C++ objects are not necessarily defined. 2 To ensure soundness, uninitialized reads require program termination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approximating infinite heaps</head><p>While an infinite-heap memory manager is unimplementable, we can probabilistically approximate its behavior. We replace the infinite heap with one that is M times larger than the maximum required to obtain an M-approximation to infinite-heap semantics. By placing objects uniformly at random across the heap, we get a minimum expected separation of E[minimum separation] = M -1 objects, making overflows smaller than M -1 objects benign. Finally, by randomizing the choice of freed objects to reclaim, recentlyfreed objects are highly unlikely to be overwritten.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Detecting uninitialized reads</head><p>Notice that this memory manager approximates most aspects of infinite-heap semantics as M approaches infinity. However, it does not quite capture infinite-heap semantics, because it does not detect uninitialized reads. In order to detect these, we require that the infinite heap and every allocated object be filled with random values. We can then detect uninitialized reads by simultaneously executing at least two replicas with different randomized allocators and comparing their outputs. An uninitialized read will return different results across the replicas, and if this read affects the computation, the outputs of the replicas will differ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Randomized Memory Management</head><p>This section describes the randomized memory management algorithm that approximates the infinite heap semantics given above. We first describe the algorithm's initialization phase, and then describe the allocation and deallocation algorithms. For purposes of exposition, we refer to these as DieHardMalloc and DieHardFree, but in the actual implementation, these are simply called malloc and free. We use interposition to replace the calls in the target application; see Section 5.1 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Initialization</head><p>The initialization step first obtains free memory from the system using mmap. The heap size is a parameter to the allocator, corresponding to the M factor described above. For the replicated version only, DieHard then uses its random number generator to fill the heap with random values. Each replica's random number generator is seeded with a true random number. For example, the Linux version reads from /dev/urandom, a source of true randomness. The random number generator itself is an inlined version of Marsaglia's multiply-with-carry random number generation algorithm, which is a fast, high-quality source of pseudo-random numbers <ref type="bibr" target="#b25">[26]</ref>.</p><p>The heap is logically partitioned into twelve regions, one for each power-of-two size class from 8 bytes to 16 kilobytes. Each region is allowed to become at most 1/M full. DieHard allocates larger objects directly using mmap and places guard pages without read or write access on either end of these regions. Object requests are rounded up to the nearest power of two. Using powers of two significantly speeds allocation by allowing expensive division and modulus operations to be replaced with bit-shifting.</p><p>Separate regions are crucial to making the allocation algorithm practical. If instead objects were randomly spread across the entire heap area, significant fragmentation would be a certainty, because small objects would be scattered across all of the pages. Restricting each size class to its own region eliminates this external fragmentation. We discuss DieHard's memory efficiency in Section 4.4.</p><p>Another vital aspect of the algorithm is its total separation of heap metadata from heap objects. Many allocators, including the    Lea allocator that forms the basis of the GNU libc allocator, store heap metadata in areas immediately adjacent to allocated objects ("boundary tags"). A buffer overflow of just one byte past an allocated space can corrupt the heap, leading to program crashes, unpredictable behavior, or security vulnerabilities <ref type="bibr" target="#b22">[23]</ref>. Other al-locators place such metadata at the beginning of a page, reducing but not eliminating the likelihood of corruption. Keeping all of the heap metadata separate from the heap protects it from buffer overflows.</p><p>The heap metadata includes a bitmap for each heap region, where one bit always stands for one object. All bits are initially zero, indicating that every object is free. Additionally, DieHard tracks the number of objects allocated to each region (inUse); this number is used to ensure that the number of objects does not exceed the threshold factor of 1/M in the partition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Object Allocation</head><p>When an application requests memory from DieHardMalloc, the allocator first checks to see whether the request is to a large object (larger than 16K); if so, it uses allocateLargeObject to satisfy the request, which uses mmap and stores the address in a table for validity checking by DieHardFree. Otherwise, it converts the size request into a size class ( log 2 of the request, minus 3). As long as the corresponding region is not already full, it then looks for space.</p><p>Allocation then proceeds much like probing into a hash table. The allocator picks a random number and checks to see if the slot in the appropriate partition is available. The fact that the heap can only become 1/M full bounds the expected time to search for an unused slot to 1 1-(1/M) . For example, for M = 2, the expected number of probes is two.</p><p>Finally, after finding an available slot, the allocator marks the object as allocated, increments the allocated count, and, for the replicated version, fills the object with randomized values. DieHard relies on this randomization to detect uninitialized reads, as we describe in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Object Deallocation</head><p>To defend against erroneous programs, DieHardFree takes several steps to ensure that any object given to it is in fact valid. First, it checks to see if the address to be freed is inside the heap area, indicating it may be a large object. Because all large objects are mmaped on demand, they lie outside of the main heap. The function freeLargeObject checks the table to ensure that this object was indeed returned by a previous call to allocateLargeObject. If so, it munmaps the object; otherwise, it ignores the request.</p><p>If the address is inside the heap, DieHard checks it for validity to prevent double and invalid frees. First, the offset of the address from the start of its region (for the given size class) must be a multiple of the object size. Second, the object must be currently marked as allocated. If both of these conditions hold, DieHard finally resets the bit corresponding to the object location in the bitmap and decrements the count of allocated objects for this region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion</head><p>The design of DieHard's allocation algorithm departs significantly from previous memory allocators. In particular, it makes no effort to improve locality and can increase space consumption. We address these concerns here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Locality</head><p>Many allocators attempt to increase spatial locality by placing objects that are allocated at the same time near each other in memory <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b37">38</ref>]. DieHard's random allocation algorithm instead makes it likely that such objects will be distant. This spreading out of objects has little impact on L1 locality because typical heap objects are near or larger than the L1 cache line size (32 bytes on the x86). However, randomized allocation leads to a large number of TLB misses in one application (see Section 7.2.1), and leads to higher resident set sizes because it can induce poor page-level locality. To maintain performance, DieHard thus requires that the entire heap fit into physical RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Space Consumption</head><p>DieHard's memory management policies tend to consume more memory than conventional memory allocators. This increase in memory is caused by two factors: rounding up objects to the next power of two, and requiring that the heap be M times larger than necessary.</p><p>The rounding up of objects to the next power of two can, in the worst-case, increase memory consumption by up to a factor of two. Wilson et al. present empirical results suggesting that this policy can lead to significant fragmentation <ref type="bibr" target="#b37">[38]</ref>. Nonetheless, such an allocator is used in real systems, FreeBSD's PHKmalloc <ref type="bibr" target="#b23">[24]</ref>, and is both time and space-efficient in practice <ref type="bibr" target="#b11">[12]</ref>.</p><p>Any increase in memory consumption caused by rounding is balanced by two DieHard features that reduce memory consumption. First, unlike most conventional allocators including the GNU libc allocator, DieHard's allocator has no per-object headers. These headers typically consume eight bytes, but DieHard's per-object overhead is just one bit in the allocation bitmap. Second, while coarse size classes can increase internal fragmentation, DieHard's use of segregated regions completely eliminates external fragmentation. The Lea allocator's external fragmentation plus perobject overhead increases memory consumption by approximately 20% <ref type="bibr" target="#b11">[12]</ref>.</p><p>A more serious concern is the requirement of a factor of M additional space for each of the twelve size classes, and the use of replicas. In the worst case, a program using DieHard could request objects of just one size and so require up to 12M more memory than needed. We could reduce this overhead using profile information to reserve only M times the maximum needed for each size class. However, Robson showed that this factor (a logarithm of the ratio of the largest size to the smallest) is the worst case for all memory allocators <ref type="bibr" target="#b32">[33]</ref>. Approaches like conservative garbage collection can impose an additional space overhead of 3X-5X over malloc/free <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">41]</ref>. Finally, memory that is reserved by DieHard but not used does not consume any virtual memory; the actual implementation of DieHard lazily initializes heap partitions. Nonetheless, DieHard's approach reduces the available address space, which may make it unsuitable for applications with large heap footprints running on 32-bit systems. We expect this will become less of an issue as 64-bit processors become commonplace. We also believe that DieHard's space-reliability tradeoff will be acceptable for many purposes, especially long-running applications with modest-sized heaps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Replication</head><p>While replacing an application's allocator with DieHard reduces the likelihood of memory errors, this stand-alone approach cannot detect uninitialized reads. To catch these errors, and to further increase the likelihood of correct execution, we have built a version of DieHard (currently for UNIX platforms only) that executes several replicas simultaneously. Figure <ref type="figure" target="#fig_5">3</ref> depicts the architecture, instantiated with three replicas.</p><p>The diehard command takes three arguments: the path to the replicated variant of the DieHard memory allocator (a dynamicallyloadable library), the number of replicas to create, and the application name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Replicas and Input</head><p>DieHard spawns each replica in a separate process, each with the LD PRELOAD environment variable pointing to the DieHard memory management library libdiehard.so. This library interposition redirects all calls to malloc and free in the application to DieHard's memory manager. Because the memory manager picks a different random number generation seed on every invocation, all replicas execute with different sequences of random numbers.</p><p>DieHard uses both pipes and shared memory to communicate with the replicas. Each replica receives its standard input from Die-Hard via a pipe. Each replica then writes its standard output into a memory-mapped region shared between DieHard and the replica. After all I/O redirection is established, each replica begins execution, receiving copies of standard input from the main DieHard process.</p><p>While the stand-alone version of DieHard works for any program, the replicated DieHard architecture does not apply to programs whose output is inherently non-deterministic. The current implementation is targeted at standard UNIX-style commands that read from standard input and write to standard output. Also, while we intend to support programs that modify the filesystem or perform network I/O, these are not supported by the current version of the replicated system. We leave the use of DieHard replication with interactive applications as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Voting</head><p>DieHard manages output from the replicas by periodically synchronizing at barriers. Whenever all currently-live replicas terminate or fill their output buffers (currently 4K each, the unit of transfer of a pipe), the voter compares the contents of each replica's output buffer. If all agree, then the contents of one of the buffers is sent to standard output, and execution proceeds as normal.</p><p>However, if not all of the buffers agree, it means that at least one of the replicas has an error. The voter then chooses an output buffer agreed upon by at least two replicas and sends that to standard out. Two replicas suffice, because the odds are slim that two randomized replicas with memory errors would return the same result.</p><p>Any non-agreeing replicas have either exited abnormally before filling their output buffers, or produced different output. Whenever a replica crashes, DieHard receives a signal and decrements the number of currently-live replicas. A replica that has generated anomalous output is no longer useful since it has entered into an undefined state. Our current implementation kills such failed replicas and decreases the currently-live replica count. To further improve availability, we plan to replace failed replicas with a copy of one of the "good" replicas with its random number generation seed set to a different value. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Discussion</head><p>Executing actual applications simultaneously on the same system while both providing reasonable performance and preserving application semantics is a challenge. We address these issues here.</p><p>In order to make correct replicas output-equivalent to the extent possible, we intercept certain system calls that could produce different results. In particular, we redirect functions that access the date and system clock so that all replicas return the same value.</p><p>While it may appear that voting on all output might be expensive, it is amortized because this processing occurs in 4K chunks. More importantly, voting is only triggered by I/O, which is already expensive, and does not interfere with computation.</p><p>A disadvantage of the barrier synchronization employed here is that an erroneous replica could theoretically enter an infinite loop, which would cause the entire program to hang because barrier synchronization would never occur. There are two approaches that one can take: use a timer to kill replicas that take too long to arrive at the barrier, or ignore the problem, the approach we take. Establishing an appropriate waiting time would solve the problem of consensus in the presence of Byzantine failures, which is undecidable <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Analysis</head><p>While DieHard is immune from heap corruption caused by double frees, invalid frees, and heap metadata overwrites, its immunity from other memory errors is probabilistic. In this section, we quantify the probabilistic memory safety provided by both the standalone and replicated versions of DieHard. We derive equations that provide lower bounds on the likelihood of avoiding buffer overflow and dangling pointer errors, and detecting uninitialized reads.</p><p>We use the following notation throughout the analyses. Recall that M denotes the constant factor by which the heap is multiplied the maximum live size of the application. We use k to denote the number of replicas, H the maximum heap size, L the maximum live size (L ≤ H/M), and F the remaining free space (H -L). Figure <ref type="figure">1</ref> depicts these variables graphically. When analyzing buffer overflows, we use O to stand for the number of objects' worth of bytes overflowed (e.g., a 16-byte overflow could overwrite O = 2 8-byte objects). For dangling pointer errors, we use A to denote the number of allocations that have taken place after a premature call to free.</p><p>We make a simplifying and conservative assumption in these analyses that all object requests are for a specific size class. This approach is conservative because the separation of different size classes improves the odds of avoiding memory errors.</p><p>Note that the analyses below quantify the probability of avoiding a single error of a given type. One can calculate the probability of avoiding multiple errors by multiplying the probabilities of each error, but this depends on an assumption of independence that may not hold. Also, these results only hold for objects smaller than 16K in size, because larger objects are managed separately as described in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Masking Buffer Overflows</head><p>In this section, we derive the probability of masking buffer overflows. While buffer overflows are generally writes just beyond an allocated object, for our analysis, we model a buffer overflow as a write to any location in the heap. If a buffer overflow does not overwrite any live data in at least one replica's heap, we say that the buffer overflow has been successfully masked. The following formula gives the probability of successfully masking a buffer overflow.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1. Let OverflowedObjects be the number of live objects overwritten by a buffer overflow. Then the probability of masking a buffer overflow is P(OverflowedObjects</head><formula xml:id="formula_1">= 0) = 1 -1 -F H O k .</formula><p>Proof. The odds of O objects overwriting at least one live object are 1 minus the odds of them overwriting no live objects, or 1 -( F H ) O . Masking the buffer overflow requires that at least one of the k replicas not overwrite any live objects, which is the same as 1 minus all of them overwriting at least one live object = 1 -(1 -</p><formula xml:id="formula_2">( F H ) O ) k .</formula><p>Probabilistic memory safety provides good protection against modest buffer overflows. Whenever the heap is large relative to the maximum amount of live memory, the likelihood of masking an error increases. For example, when the heap is no more than 1/8 full, DieHard in stand-alone mode provides an 87.5% chance of masking a single-object overflow, while three replicas avoids such errors with greater than 99% probability. Figure <ref type="figure" target="#fig_6">4(a)</ref> shows the probability of protecting against overflows for different numbers of replicas and degrees of heap fullness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Masking Dangling Pointers</head><p>A dangling pointer error occurs when an object is freed prematurely and its contents are overwritten by another object. Suppose that the object should have been freed A allocations later than it was; that is, the call to free should have happened at some point after the next A calls to malloc but before the A + 1th call. Avoiding a dangling pointer error is thus the likelihood that the object's contents are not overwritten after A intervening allocations:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2. Let Overwrites be the number of times that a particular freed object of size S gets overwritten by one of the next A allocations. Then the probability of this object being intact after A allocations, assuming A ≤ F/S, is:</head><formula xml:id="formula_3">P(Overwrites = 0) ≥ 1 - A F/S k .</formula><p>Proof. The prematurely freed object is indexed by one of the Q = F/S bits in the allocation bitmap for its size class. The odds of a new allocation not overwriting that object are thus (Q -1)/Q. Assume that after each allocation, we do not free an object: this is the worst case. After the second allocation, the odds are</p><formula xml:id="formula_4">(Q -1)/Q * (Q -2)/(Q -1) = (Q -2)/Q.</formula><p>In general, after A allocations, the probability of not having overwritten a particular slot is</p><formula xml:id="formula_5">(Q -A)/Q.</formula><p>The probability that no replica has overwritten a particular object after A allocations is then one minus the odds of all of the replicas overwriting that object, or 1</p><formula xml:id="formula_6">-(1 -(Q -A)/Q) k = 1 - (A/(F/S)) k .</formula><p>This result shows that DieHard is robust against dangling pointer errors, especially for small objects. Using the default configuration, the stand-alone version of DieHard has greater than a 99.5% chance of masking an 8-byte object that was freed 10,000 allocations too soon. Figure <ref type="figure" target="#fig_6">4(b)</ref> shows the probabilities of avoiding dangling pointer errors for different object sizes and numbers of intervening allocations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Detecting uninitialized reads</head><p>We say that DieHard detects an uninitialized read when it causes all of the replicas to differ on their output, leading to termination. An uninitialized read is a use of memory obtained from an allocation before it has been initialized. If an application relies on values read from this memory, then its behavior will eventually reflect this use. We assume that uninitialized memory reads are either benign or propagate to output.</p><p>The odds of detecting such a read thus depend both on how much use the application makes of the uninitialized memory, and its resulting impact on the output. An application could widen the uninitialized data arbitarily, outputting the data in an infinite loop. On the other end of the spectrum, an application might narrow the data by outputting just one bit based on the contents of the entire uninitialized region. For example, it could output an 'A' if the first bit in the region was a 0, and 'a' if it was 1.</p><p>If we assume that the application generates just one bit of output based on every bit in the uninitialized area of memory, we get the following result: Theorem 3. The probability of detecting an uninitialized read of B bits in k replicas in a non-narrowing, non-widening computation is:</p><formula xml:id="formula_7">P(Detect uninitialized read) = 2 B ! (2 B -k)!2 Bk .</formula><p>Proof. For DieHard to detect an uninitialized read, all replicas must disagree on the result stemming from the read. In other words, all replicas must have filled in the uninitialized region of length B with a different B-bit number. There are 2 B numbers of length B, and k replicas yields 2 Bk possible combinations of these numbers. There are (2 B )!/(2 B -k)! ways of selecting different B-bit numbers across the replicas (assuming 2 B &gt; k). We thus have a likelihood of detecting an uninitalized read of</p><formula xml:id="formula_8">(2 B !)/(2 B -k)!2 Bk .</formula><p>Interestingly, in this case, replicas slightly lower the likelihood of memory safety. For example, the probability of detecting an uninitialized read of one byte across two replicas is 87.5%, while for three replicas, it drops to 65.6%. However, this has little practical impact for reads of more data. The odds of not detecting an uninitialized read of 32 bits drops from one in ten billion for two replicas to one in one hundred million for three replicas.</p><p>DieHard's effectiveness at finding uninitialized reads makes it useful as an error-detecting tool during development. During experiments for this paper, we discovered uninitialized reads in several benchmarks. The replicated version of DieHard typically terminated in several seconds. We verified these uninitalized read errors with Valgrind, which ran approximately two orders of magnitude slower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experimental Results</head><p>We first measure the runtime impact of the DieHard memory manager on a suite of benchmark applications. We then empirically evaluate its effectiveness at avoiding both injected faults and actual bugs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Benchmarks</head><p>We evaluate DieHard's performance with both the full SPECint2000 suite <ref type="bibr" target="#b35">[36]</ref> running reference workloads, as well as a suite of allocation-intensive benchmarks. These benchmarks perform between 100,000 and 1,700,000 memory operations per second (see <ref type="bibr">Berger,</ref><ref type="bibr">Zorn and McKinley [6]</ref> for a detailed description). We include these benchmarks both because they are widely used in memory management studies (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22]</ref>) and because their unusually high allocation-intensity stresses memory management performance.</p><p>In all of our experiments, we set the default heap size for DieHard to 384MB. This is larger than necessary for nearly all of the applications we measure here, but ensures consistency in our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Overhead</head><p>We run our benchmarks on three different platforms: Linux, Windows XP, and Solaris. The Linux platform is a dual-processor Intel Xeon system with each 3.06GHz processor (hyperthreading active) equipped with 512K L2 caches and with 3 gigabytes of RAM. All code on Linux is compiled with g++ version 4.0.2. The Windows XP platform is a Pentium 4 system running at 3.20GHz with a 512K L2 cache and 2 gigabytes of RAM. All code on Windows is compiled using Visual Studio 7. The Solaris platform is a Sun SunFire 6800 server, with 16 900MHz UltraSparc v9 processors and 16 gigabytes of RAM; code there is compiled with g++ 3.2. All code is compiled at the highest optimization level on all platforms. Timings are performed while the systems are quiescent. We report the average of five runs after one warm-up run; observed variances are below 1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Linux</head><p>On Linux, we compare both DieHard and the Boehm-Demers-Weiser collector to the default GNU libc allocator, a variant of the Lea allocator <ref type="bibr" target="#b24">[25]</ref>. The Boehm-Demers-Weiser collector is used for comparison because it represents an alternative trade-off in the design space between space, execution time, and safety guarantees. Figure <ref type="figure" target="#fig_8">5</ref>(a) shows that, for the allocation-intensive benchmarks, DieHard suffers a performance penalty ranging from 16.5% to 63% (geometric mean: 40%). Its overhead is thus comparable to that suffered by the Boehm-Demers-Weiser collector (2% to 59.7%, geometric mean 25.8%).</p><p>However, DieHard's runtime overhead is substantially lower for most of the SPECint2000 benchmarks. The geometric mean of Die-Hard's overhead is 12%. DieHard degrades performance substantially for two applications: 253.perlbmk (48.8%) and 300.twolf (109%). The 253.perlbmk benchmark is allocation-intensive, spending around 12.5% of its execution doing memory operations, and this highlights both DieHard's and Boehm-Demers-Weiser's runtime overhead (13.4%). However, the 300.twolf overhead is due not to the cost of allocation but to TLB misses. 300.twolf uses a wide range of object sizes, so in DieHard, accesses to these objects are spread over many size class partitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Windows</head><p>To evaluate the effect of different default allocators and compilers on DieHard's overhead, we ran the allocation-intensive benchmarks on Windows XP. Figure <ref type="figure" target="#fig_8">5</ref>(b) presents execution time results for these benchmarks.</p><p>The results on Windows XP are far different than for Linux: the geometric mean of performance for these allocation-intensive benchmarks with DieHard is effectively the same as with the default allocator. DieHard improves runtime performance for roboop by 19%, espresso by 8.2%, and cfrac by 6.4%. Only lindsay and p2c perform slower, by 13.6% and 22.5% respectively.</p><p>We attribute these results to two factors: first, the default Windows XP allocator is substantially slower than the Lea allocator. Second, Visual Studio produces much faster code for DieHard than g++ does. DieHard is written in modular C++ code with many small methods, and Visual Studio's better inlining heuristics and backend code generator combine to substantially improve Die-Hard's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">Solaris: Replicated Experiments</head><p>To quantify the overhead of the replicated framework and verify its scalability, we measure running time with sixteen replicas on a 16-way Sun server. We ran these experiments with the allocation-intensive benchmark suite, except for lindsay, which has an uninitialized read error detected by DieHard. Due to lack of space, we summarize the results: running 16 replicas simultaneously increases runtime by approximately 50% versus running a single replica with the replicated version of the runtime (libdiehard r.so). Part of this cost is due to process creation, which longer-running benchmarks would amortize. This result shows that while voting and interprocess communication impose some overhead, the replicated framework scales to a large number of processors.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runtime on</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Error Avoidance</head><p>We evaluate DieHard's effectiveness at avoiding both artificiallyinjected bugs and actual bugs in a real application, the Squid web caching server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Fault Injection</head><p>In this section, we use two libraries we have developed that allow us to inject memory errors into unaltered applications running on UNIX platforms. We can thus explore the resilience of different runtime systems to memory errors including buffer overflows and dangling pointers.</p><p>We first run the application with a tracing allocator that generates an allocation log. Whenever an object is freed, the library outputs a pair, indicating when the object was allocated and when it was freed (both in allocation time). We then sort the log by allocation time and use a fault-injection library that sits between the application and the memory allocator. The fault injector triggers errors probabistically, based on the requested frequencies. To trigger an underflow, it requests less memory from the underlying allocator than was requested by the application. To trigger a dangling pointer error, it uses the log to invoke free on an object before it is actually freed by the application, and ignores the subsequent (actual) call to free this object. The fault injector only inserts dangling pointer errors for small object requests (&lt; 16K).</p><p>We verified DieHard's resilience by injecting errors in the espresso benchmark, and running it ten times with the default allocator and with DieHard. We first introduced dangling pointers of frequency of 50% with distance 10: that is, one out of every two objects is freed ten allocations too early. This high error rate prevents espresso from running to completion with the default allocator in any of our runs. However, even in the face of such errors, DieHard allowed espresso to run correctly in 9 out of 10 runs.</p><p>We then injected buffer overflow errors at a 1% rate (1 out of every 100 allocations), under-allocating object requests of 32 bytes or more by 4 bytes. With the default allocator, espresso crashes in 9 out of 10 runs and enters an infinite loop in the tenth. With DieHard, it runs successfully in all 10 of 10 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real Faults</head><p>We also tested DieHard on an actual buggy application. Version 2.3s5 of the Squid web cache server has a buffer overflow error that can be triggered by an ill-formed input. When faced with this input and running with either the GNU libc allocator or the Boehm-Demers-Weiser collector, Squid crashes with a segmentation fault. Using DieHard in stand-alone mode, the overflow has no effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Related Work</head><p>This section describes related work in software engineering, memory management, approaches to address security vulnerabilities, failure masking, fail-stop, debugging and testing.</p><p>Our approach is inspired by N-version programming, in which independent programmers produce variants of a desired program <ref type="bibr" target="#b1">[2]</ref>. Whereas N-version programming relies on a conjecture of independence across programmers to reduce the likelihood of errors, DieHard provides hard analytical guarantees.</p><p>Memory management approaches: Typical runtime systems sacrific robustness in favor of providing fast allocation with low fragmentation. Most implementations of malloc, including the widely-used Lea allocator included in the GNU C library <ref type="bibr" target="#b24">[25]</ref>, are susceptible to both double frees and heap corruption caused by buffer overflows. However, some explicit memory managers and conservative garbage collectors do employ techniques to improve application robustness <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b31">32]</ref>. Garbage collection requires a significant amount of space to achieve reasonable performance (3X-5X more than malloc/free) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">41]</ref>. DieHard ignores double and invalid frees and segregates metadata from the heap to avoid overwrites, but unlike the Boehm-Demers-Weiser collector, its avoidance of dangling pointers is probabilistic rather than absolute. Unlike previous memory managers, DieHard provides protection of heap data (not just metadata) from buffer overflows, and can detect uninitialized reads.</p><p>The technique of avoiding per-object headers is sometimes referred to as a BIBOP-style organization ("Big Bag of Pages" <ref type="bibr" target="#b15">[16]</ref>) and has been employed by many memory managers, including the Boehm-Demers-Weiser conservative garbage collector <ref type="bibr" target="#b7">[8]</ref> and the Hoard multiprocessor memory allocator <ref type="bibr" target="#b4">[5]</ref>.</p><p>Security vulnerabilities: Previous efforts to reduce vulnerability to heap-based security attacks randomize the base address of the heap, a technique known somewhat misleadingly as address space randomization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b28">29]</ref>. This randomization provides little protection from heap-based attacks on 32-bit platforms <ref type="bibr" target="#b34">[35]</ref>. Although protection from security vulnerabilities is not its intended goal, DieHard makes it difficult for an attacker to predict the layout or adjacency of objects in any replica.</p><p>Failure masking: Several researchers have proposed unsound techniques that can prevent programs from crashing <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. Automatic pool allocation segregates objects into pools of the same type, thus ensuring that dangling pointers are always overwritten only by objects of the same type <ref type="bibr" target="#b10">[11]</ref>. While this approach yields type safety, the resulting program behavior is unpredictable. Failure-oblivious computing allows programs to continue to run by ignoring illegal writes and manufacturing values for reads of uninitialized areas <ref type="bibr" target="#b30">[31]</ref>. These actions impose as high as 8X performance overhead and can lead to incorrect program execution. Rx uses checkpointing and logging in conjunction with a versioning file system to recover from detectable errors, especially crashes. After a crash, Rx rolls back the application and restarts with an allocator that selectively ignores double frees, zero-fills buffers, pads object requests, and defers frees <ref type="bibr" target="#b29">[30]</ref>. Because Rx relies on checkpointing and rollback-based recovery, it is not suitable for applications whose effects cannot be rolled back. It is also unsound: Rx cannot detect latent errors that lead to incorrect program execution rather than crashes.</p><p>Fail-stop approaches: A number of approaches that attempt to provide type and memory safety for C (or C-like) programs are fail-stop, aborting program execution upon detecting an error <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref>. We discuss two representative examples: Cyclone and CCured. Cyclone augments C with an advanced type system that allows programmers direct but safe control over memory <ref type="bibr" target="#b20">[21]</ref>. CCured instruments code with runtime checks that dynamically ensure memory safety and uses static analysis to remove checks from places where memory errors cannot occur <ref type="bibr" target="#b26">[27]</ref>. While Cyclone uses region-based memory management <ref type="bibr" target="#b13">[14]</ref>, CCured relies on the BDW garbage collector to protect against double frees and dangling pointers. Unlike DieHard, which works with binaries and supports any language using explicit allocation, both Cyclone and CCured operate on an extended version of C source code that typically requires manual programmer intervention. Both abort program execution when detecting buffer overflows or other errors, while DieHard can often avoid them.</p><p>Debugging and testing: Tools like Purify <ref type="bibr" target="#b16">[17]</ref> and Valgrind <ref type="bibr" target="#b27">[28]</ref> use binary rewriting or emulation to dynamically detect memory errors in unaltered programs. However, these often impose prohibitive runtime overheads (2-25X) and space costs (around 10X) and are thus only suitable during testing. SWAT <ref type="bibr" target="#b17">[18]</ref> uses sampling to detect memory leaks at runtime with little overhead (around 5%), and could be employed in conjunction with DieHard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion</head><p>DieHard is a runtime system that effectively tolerates memory errors and provides probabilistic memory safety. DieHard uses randomized allocation to give the application an approximation of an infinite-sized heap, and uses replication to further increase error tolerance and detect uninitialized memory reads that propagate to program output. DieHard allows an explicit trade-off between memory usage and error tolerance, and is useful for programs in which memory footprint is less important that reliability and security. We show that on Linux DieHard, adds little CPU overhead to many of the SPECint2000 benchmark programs, while the CPU overhead in allocation-intensive programs is larger. On Windows, the overhead of DieHard is reduced, and programs with DieHard occasionally run faster than when running with the default allocator.</p><p>We show analytically that DieHard increases error tolerance, and reaffirm our analytic results by demonstrating that DieHard significantly increases the error tolerance of an application in which faults are artifically injected. We also describe an experiment in which DieHard successfully masks a known buffer-overflow error in the Squid web cache server, an application used in other program correctness studies. The DieHard runtime system tolerates heap errors but does not prevent safety errors based on stack corruption. We believe that with compiler support, the ideas proven successful in DieHard could be used to improve error tolerance on the stack and also in object field references. We plan to investigate the effectiveness of this approach in future work.</p><p>The current implementation of DieHard has limitations that we believe future work can overcome. The DieHard algorithm as implemented initializes the heap based on the maximum size the heap will eventually grow to. We plan to investigate an adaptive version of DieHard that grows memory regions dynamically as objects are allocated. Other ways of reducing the memory requirements of Die-Hard include selectively applying the technique to particular size classes, allocation pools, object types, and/or object instances.</p><p>One limitation of the replicated form of DieHard is its inability to work with programs that generate non-deterministic output or output related to environmental factors (e.g., time-of-day, performance counters, interactive events, etc.) In the future, we hope to better characterize program output so that these kinds of irreproducible results can be recognized and factored.</p><p>Beyond error tolerance, DieHard also can be used to debug memory corruption. By differencing the heaps of correct and incorrect executions of applications, it may be possible to pinpoint the exact locations of memory errors and report these as part of a crash dump (in our case, without the crash).</p><p>Improving the security and reliability of programs written in C and C++ is recognized by the research community as an important priority and many approaches have been suggested. In this paper, we present a unique and effective approach to soundly tolerating memory errors in unsafe programs without requiring the programs be rewritten or even recompiled. Like garbage collection, DieHard represents a new and interesting alternative in the broad design space that trades off CPU performance, memory utilization, and program correctness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 Figure 1 .</head><label>21</label><figDesc>Figure 1. DieHard's heap layout. The heap is divided into separate per-size class regions, within which objects are laid out randomly. Notice the different layouts across replicas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 1 void 2 // Initialize the random number generator 3 /</head><label>123</label><figDesc>ISO C++ Standard 5.3.4, paragraph 14A. DieHardInitHeap (int MaxHeapSize) { / with a truly random number.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>11 /</head><label>11</label><figDesc>/ Get the heap memory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>12 heap 15 ( 16 } 1 void</head><label>1215161</label><figDesc>= mmap (NULL, MaxHeapSize); 13 // REPLICATED: fill with random values 14 for (i = 0; i &lt; MaxHeapSize; i += 4) (long * ) heap)[i] = rng.next(); * DieHardMalloc (size_t sz) { 2 if (sz &gt; MaxObjectSize) 3 return allocateLargeObject(sz);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4 c 12 // Found one. 13 / 20 ( 21 return ptr; 22 } 23 } 1 void 13 }Figure 2 .</head><label>41213202122231132</label><figDesc>Figure 2. Pseudocode for DieHard heap initialization, object allocation and deallocation routines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The replicated DieHard architecture. Input is broadcast to multiple replicas, each equipped with a different, fullyrandomized memory manager. Output is only committed when at least two replicas agree on the result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Probabilities of avoiding buffer overflows and dangling pointer errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Linux: Performance of the default malloc, the Boehm-Demers-Weiser garbage collector, and DieHard (stand-alone version), across a range of allocation-intensive and general-purpose benchmark applications. (b) Windows XP: Performance of the default malloc and DieHard (stand-alone version), across a range of allocation-intensive benchmark applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Runtime performance on Linux and Windows XP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>This table compares how various systems handle memory safety errors: denotes correct execution, undefined denotes an undefined result, and abort means the program terminates abnormally. See Section 8 for a detailed explanation of each system. The DieHard results for the last three errors (marked with asterisks) are probabilistic; see Section 6 for exact formulae. Note that abort is the only sound response to uninitialized reads.</figDesc><table><row><cell>DieHard</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Personal communication, Dan Grossman and Ranjit Jhala.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Mike Barnett, Mike Bond, Mark Corner, Trishul Chilimbi, Mike Hicks, Daniel Jiménez, David Jensen, Scott Kaplan, Brian Levine, Andrew McCallum, David Notkin, and Gene Novark for their helpful comments. Thanks also to Shan Lu and Yuanyuan Zhou for providing us the buggy inputs for Squid.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient detection of all pointer and array access errors</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Breach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;94: Proceedings of the ACM SIGPLAN 1994 conference on Programming language design and implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="290" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The N-version approach to fault-tolerant systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avizienis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1491" to="1501" />
			<date type="published" when="1985-12">Dec. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving software security with a C pointer analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Avots</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Livshits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE &apos;05: Proceedings of the 27th international conference on Software engineering</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="332" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The slam toolkit</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Rajamani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAV &apos;01: Proceedings of the 13th International Conference on Computer Aided Verification</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="260" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hoard: A scalable memory allocator for multithreaded applications</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS-IX: Ninth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-11">Nov. 2000</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Composing highperformance memory allocators</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Zorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the 2001 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)<address><addrLine>Snowbird, Utah</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Address obfuscation: An efficient approach to combat a broad range of memory error exploits</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Duvarney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Security Symposium</title>
		<meeting>the 12th USENIX Security Symposium</meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2003-08">Aug. 2003</date>
			<biblScope unit="page" from="105" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Garbage collection in an uncooperative environment</title>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="807" to="820" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cache-conscious structure layout</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Chilimbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGPLAN&apos;99 Conference on Programming Languages Design and Implementation</title>
		<meeting>SIGPLAN&apos;99 Conference on Programming Languages Design and Implementation<address><addrLine>Atlanta</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999-05">May 1999</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Empirical evidence for using garbage collection in C and C++ programs</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Detlefs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA/ECOOP &apos;93 Workshop on Garbage Collection in Object-Oriented Systems</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Moss</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Zorn</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1993-10">Oct. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Memory safety without runtime checks or garbage collection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dhurjati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kowshik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lattner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGPLAN 2003 Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES&apos;2003)</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A locality-improving dynamic memory allocator</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 2005 Workshop on Memory System Performance (MSP)</title>
		<meeting>the ACM SIGPLAN 2005 Workshop on Memory System Performance (MSP)<address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Impossibility of distributed consensus with one faulty process</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Paterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="374" to="382" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Region-based memory management in Cyclone</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Morrisett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;02: Proceedings of the ACM SIGPLAN 2002 Conference on Programming language design and implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="282" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving the cache locality of memory allocation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGPLAN&apos;93 Conference on Programming Languages Design and Implementation</title>
		<meeting>SIGPLAN&apos;93 Conference on Programming Languages Design and Implementation<address><addrLine>Albuquerque, NM</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A portable storage management system for the Icon programming language</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="489" to="500" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Purify: Fast detection of memory leaks and access errors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Joyce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Winter 1992 USENIX Conference</title>
		<meeting>of the Winter 1992 USENIX Conference<address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="125" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Low-overhead memory leak detection using adaptive statistical profiling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Chilimbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS-XI: Proceedings of the 11th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="156" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lazy abstraction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sutre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual Symposium on Principles of Programming Languages</title>
		<meeting>the 29th Annual Symposium on Principles of Programming Languages</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="58" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Quantifying the performance of garbage collection vs. explicit memory management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications</title>
		<meeting>the Conference on Object-Oriented Programming Systems, Languages, and Applications<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cyclone: A safe dialect of C</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Morrisett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the General Track: 2002 USENIX Annual Technical Conference</title>
		<meeting>the General Track: 2002 USENIX Annual Technical Conference<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="275" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The memory fragmentation problem: Solved?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Johnstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA &apos;97 Workshop on Garbage Collection and Memory Management</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Dickman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1997-10">Oct. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Kaempf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vudo malloc tricks. Phrack Magazine</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2001-08">Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Malloc(3) revisited</title>
		<author>
			<persName><forename type="first">P.-H</forename><surname>Kamp</surname></persName>
		</author>
		<ptr target="http://phk.freebsd.dk/pubs/malloc.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Lea</surname></persName>
		</author>
		<ptr target="http://gee.cs.oswego.edu/dl/html/malloc.html" />
		<title level="m">A memory allocator</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">yet another rng. posted to the electronic bulletin board sci.stat.math</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marsaglia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-08">Aug. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ccured: type-safe retrofitting of legacy code</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcpeak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL &apos;02: Proceedings of the 29th ACM SIGPLAN-SIGACT symposium on Principles of programming languages</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="128" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bounds-checking entire programs without recompiling</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nethercote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fitzhardinge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPACE 2004</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-01">Jan. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<orgName type="collaboration">PaX Team</orgName>
		</author>
		<ptr target="http://pax.grsecurity.net/docs/aslr.txt" />
		<title level="m">PaX address space layout randomization (ASLR)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Treating bugs as allergies: A safe method to survive software failures</title>
		<author>
			<persName><forename type="first">F</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tucek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sundaresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><surname>Rx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth Symposium on Operating Systems Principles</title>
		<meeting>the Twentieth Symposium on Operating Systems Principles<address><addrLine>Brighton, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005-10">Oct. 2005</date>
			<biblScope unit="volume">XX</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Enhancing server availability and security through failureoblivious computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rinard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cadar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dumitran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><surname>Beebee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth Symposium on Operating Systems Design and Implementation</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2004-12">Dec. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Run-time detection of heap-based overflows</title>
		<author>
			<persName><forename type="first">W</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kruegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Valeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LISA &apos;03: Proceedings of the 17th Large Installation Systems Administration Conference</title>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bounds for some functions concerning dynamic storage allocation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="419" to="499" />
			<date type="published" when="1974-07">July 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Using Valgrind to detect undefined value errors with bit-precision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Seward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nethercote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX&apos;05 Annual Technical Conference</title>
		<meeting>the USENIX&apos;05 Annual Technical Conference<address><addrLine>Anaheim, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the effectiveness of address-space randomization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Modadugu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;04: Proceedings of the 11th ACM conference on Computer and Communications Security</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="298" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Standard Performance Evaluation Corporation. SPEC</title>
		<ptr target="http://www.spec.org" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">US-CERT vulnerability notes</title>
		<author>
			<persName><surname>Us-Cert</surname></persName>
		</author>
		<ptr target="http://www.kb.cert.org/vuls/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dynamic storage allocation: A survey and critical review</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Johnstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Memory Management</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the International Workshop on Memory Management<address><addrLine>Kinross, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995-09">Sept. 1995</date>
			<biblScope unit="volume">986</biblScope>
			<biblScope unit="page" from="1" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An efficient and backwardscompatible transformation to ensure memory safety of C programs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Duvarney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sekar</surname></persName>
		</author>
		<idno>SIGSOFT &apos;04/FSE-12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGSOFT twelfth international symposium on Foundations of software engineering</title>
		<meeting>the 12th ACM SIGSOFT twelfth international symposium on Foundations of software engineering<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Protecting C programs from attacks via invalid pointer dereferences</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Horwitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESEC/FSE-11: 11th ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="307" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The measured cost of conservative garbage collection. Software Practice and Experience</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zorn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="733" to="756" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
