<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">X-Cache : A Modular Architecture for Domain-Specific Caches</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ali</forename><surname>Sedaghati</surname></persName>
							<email>asedagha@cs.sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Sciences</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Milad</forename><surname>Hakimi</surname></persName>
							<email>milad_hakimi@cs.sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Sciences</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Reza</forename><surname>Hojabr</surname></persName>
							<email>shojabro@cs.sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Sciences</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arrvindh</forename><surname>Shriraman</surname></persName>
							<email>ashriram@cs.sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Sciences</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">X-Cache : A Modular Architecture for Domain-Specific Caches</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3470496.3527380</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Domain-specific Architectures</term>
					<term>Caches</term>
					<term>Coroutines</term>
					<term>Dataflow architectures</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With Dennard scaling ending, architects are turning to domainspecific accelerators (DSAs). State-of-the-art DSAs work with sparse data <ref type="bibr" target="#b36">[37]</ref> and indirectly-indexed data structures <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b29">30]</ref>. They introduce non-affine and dynamic memory accesses <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b34">35]</ref>, and require domain-specific caches. Unfortunately, cache controllers are notorious for being difficult to architect; domain-specialization compounds the problem. DSA caches need to support custom tags, data-structure walks, multiple refills, and preloading. Prior DSAs include ad-hoc cache structures, and do not implement the cache controller. We propose X-Cache, a reusable caching idiom for DSAs. We will be open-sourcing a toolchain for both generating the RTL and programming X-Cache. There are three key ideas: i) DSA-specific Tags (Meta-tag): The designer can use any combination of fields from the DSA-metadata as the tag. Meta-tags eliminate the overhead of walking and translating metadata to global addresses. This saves energy, and improves load-to-use latency. ii) DSA-programmable walkers (X-Actions): We find that a common set of microcode actions can be used to implement the DSA-specific walking, data block, and tag management. We develop a programmable microcode engine that can efficiently realize the data orchestration. iii) DSA-portable controller (X-Routines): We use a portable abstraction, coroutines, to let the designer express walking and orchestration. Coroutines capture the block-level parallelism, remain lightweight, and minimize controller occupancy. We create caches for four different DSA families: Sparse GEMM <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b36">37]</ref>, GraphPulse <ref type="bibr" target="#b29">[30]</ref>, DASX <ref type="bibr" target="#b21">[22]</ref>, and Widx <ref type="bibr" target="#b17">[18]</ref>. X-Cache outperforms address-based caches by 1.7× and remains competitive with hardwired DSAs (even 50% improvement in one case). We demonstrate that meta-tags save 26-79% energy compared to address-tags. In X-Cache, meta-tags consume 1.5-6.5% of data RAM energy and the programmable microcode adds a further 7%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS Concepts</head><p>• Computer systems organization → Architectures; • Hardware → Hardware-software codesign.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dally et al. <ref type="bibr" target="#b7">[8]</ref> and Hennessy-Patterson <ref type="bibr" target="#b13">[14]</ref> note that while parallelism and arithmetic intensity are essential, the key to energy efficiency is exploiting extreme locality, making fewer DRAM accesses, and maximizing bandwidth utilization. Thus, most of the resources in current DSAs are dedicated to walking data structures, packing them in SRAMs, and orchestrating data movement and computation. Existing DSAs <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref> predominantly work with dense data and organize them into scratchpads with explicit DMA.</p><p>Emerging DSAs target a broad set of applications characterized by: i) Non-affine data structures: DSAs typically organize data in DRAM with a minimal footprint. Hence, they employ sparse data structures <ref type="bibr" target="#b36">[37]</ref>, indirect-indexes <ref type="bibr" target="#b29">[30]</ref>, and hash tables <ref type="bibr" target="#b17">[18]</ref>. Getting an element's global address requires data structure traversal. ii) Dynamic accesses: Both the data structure and loop pattern cause emerging DSAs to have dynamic (i.e., indirectly addressed) and irregular non-linear accesses. A cache is necessary to capture the reuse. <ref type="bibr" target="#b34">[35]</ref> iii) Walkers: Since data is stored in non-linear data structures, a walker is required to traverse <ref type="bibr" target="#b4">[5]</ref> and preload the cache. A single miss could trigger multiple nested preloads <ref type="bibr" target="#b36">[37]</ref>. iv) Explicit orchestration: Finally, DSAs need to explicitly orchestrate cache replacement and refill with the computational datapaths. In this paper, we introduce an architectural template for domain-specific caches and provide a toolflow to achieve DSA-specialization through the cache controllers. Some prior DSAs include cache-like structures <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref> that are inextricably tied to the underlying DSA. They do not implement the cache controller.</p><p>Figure <ref type="figure">1</ref> illustrates the challenges of incorporating an addressbased cache in a sparse matrix DSA: i) Metadata to address translation (Wasted energy): The sparse GEMM DSA works with row/col indices, while the cache is based on the addresses. Logic would be required to convert row/col indices; in sparse matrices, this would require processing CSR/CSC metadata. ii) Address tags (High loadto-use latency): Conventional caches are tagged by blocks' address, i.e. even if the required row/col is cached, we cannot determine a hit until we find out the address corresponding to the row/col. This would lead to some extra access to the cache or even the DRAM. iii) Walker logic (High NRE): Finally, significant design effort is required for creating custom walkers for each DSA. Walkers would need to handle parallel refills, nested walks, and pipelining.</p><p>X-Cache removes the memory layout and address-generation concerns from the DSA. It dispenses with the flat address space, and DSAs are not required to manipulate raw addresses. X-Cache's architecture includes multiple novel ideas: DSA-specific tags (Metatags): X-Cache permits any combination of metadata fields to serve as cache tags. For example, in sparse GEMM, the Row,Col in CSR/CSC representations will serve as the meta-tag. The computational datapath uses meta loads/stores, and we implicitly locate the data on-chip; X-Cache uses global addresses only on misses. While prior DSAs <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref> include fields that mirror the functionality of meta-tags, we are the first to define and generalize the concept. DSA-programmable walking (X-Routine): On a miss, X-Cache implicitly walks and finds the relevant data. In X-Cache, each DSA can specify a custom walker. Our insight is that the walker can be implemented using a common set of microcode actions for data and tag management. DSA-agnostic controller architecture: X-Cache's controller implements the walkers and data orchestration as coroutines. Coroutines cooperatively yield on long-latency events, in contrast to prior work that used blocking threads <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Coroutines conveniently capture the underlying parallelism across meta-tags, minimize occupancy, and multiplex walkers for memory parallelism.</p><p>We evaluate X-Cache by creating domain-specific caches for five different DSAs, SpArch <ref type="bibr" target="#b36">[37]</ref>, GraphPulse <ref type="bibr" target="#b29">[30]</ref>, Widx <ref type="bibr" target="#b17">[18]</ref>, DASX <ref type="bibr" target="#b21">[22]</ref>, and Gamma <ref type="bibr" target="#b34">[35]</ref>. Both SpArch and Gamma can use the same X-Cache microarchitecture i.e., we only had to reprogram the controller. We demonstrate that we can auto-generate the meta-tags across different DSA families, vertex ids (GraphPulse), database keys (Widx), data structure indices (DASX), Compressed-matrices (SpArch and Gamma). Overall, our performance was comparable to the hard-coded caches in existing DSAs. In the case of Widx, we even improved performance by 50% by reducing the load-to-use latency. Compared to the best-performing address-based cache for each DSA, we improved performance by 1.7×. Between 66-89% of X-Cache's energy was spent on data; only 1.5-6.6% required for tags. The energy penalty of a programmable controller is less than 7%, i.e., a minimal penalty for being reusable compared to a hardwired design. Our contributions:</p><p>• We propose a reusable caching idiom that supports dynamic access patterns and irregular data structures in DSAs. • We generalize the concept of domain-specific tags (meta-tags) and create a high-performance programmable cache controller.</p><p>We demonstrate that walkers can be expressed as a common set of microcode actions.  Figure <ref type="figure" target="#fig_2">3</ref> illustrates the state-of-the-art scratchpads. We first consider Scratchpad+DMA. There has been a long history of work on decoupled engines for shuttling dense tensors from DRAM onto onchip SRAMs. This includes scatter/gather engines <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b30">31]</ref>, memory controllers <ref type="bibr" target="#b3">[4]</ref>, and tiled DMAs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b27">28]</ref>. All designs introduce additional address spaces, either local <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28]</ref>, carved from the physical <ref type="bibr" target="#b30">[31]</ref> or virtual <ref type="bibr" target="#b3">[4]</ref> addresses. Thus, DSAs that include unordered and dynamic accesses would need to implement addresstranslation from meta-tags to these local addresses <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b36">37]</ref>. Further, they can only support access patterns driven by affine loops and    There have also been works on augmenting scratchpads in GPUs <ref type="bibr" target="#b20">[21]</ref> and FPGAs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Scratchpad-AE targets DSAs, which can split into coarse-grain access-execute regions. The access patterns have to be regular, i.e., the order of accesses has to be known statically upfront and cannot be conditional. They are also heavyweight since the access engine is mapped to an FPGA kernel or GPU threads. They target tile-granularity reuse (e.g., dense GEMM) and cannot support fine-grain misses and refills. Since the access engine iterates over elements in a specific order, they cannot accommodate dynamic input-dependent reuse behaviour (e.g., indirect indexes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Summary: X-Cache vs Other Idioms</head><p>Figure <ref type="figure" target="#fig_2">3</ref> and Table <ref type="table">1</ref> qualitatively compare X-Cache against the other popular storage idioms, scratchpads with decoupled DMAs, scratchpads with user-managed access engines, and FIFOs. We use the following taxonomy: i) Implicit vs. explicit The walking and orchestration tasks are broken down into sub-tasks (e.g., miss refill, eviction). Each of these sub-tasks can be implicitly triggered by memory accesses or may be explicitly invoked by the datapath. ii) Coupled vs. decoupled: Coupled lacks domain-awareness and refills only a single data element. Decoupled models have domainawareness and preload multiple data elements. Prior works support decoupled fetches for static access patterns. However, emerging DSAs require support for dynamic-decoupled accesses. iii) Dynamic vs. Static. The data access order is fixed in DSAs with static access patterns, and the addresses can be calculated using affine functions. Emerging DSAs exhibit dynamic data-dependent access pattern; the access order of global addresses are determined by the input pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Deconstructing DSA Caches</head><p>Our thesis is that we should facilitate the adoption of domainspecific caches by deconstructing them into modular components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Choice 1: Address Tags vs. Meta Tags</head><p>We propose that DSAs should issue meta loads/stores that directly reference the elements of the data structure. X-Cache is responsible for implicitly figuring out the addresses and moving the data between DRAM and on-chip. Once the data is brought on-chip, X-Cache tags the data with actual DSA-specific metadata fields so that subsequent accesses can directly reference the on-chip data. Figure <ref type="figure" target="#fig_4">4</ref> plots the load-to-use latency using a domain-specific meta-tag vs. addressbased tag. Meta-tags notably improve the load-to-use latency. In some sense, domain-specific tags are similar to TLB tags; they short  circuit the metadata-to-address translation and eliminate the nested data-structure walks. In contrast, the address-tags require many more access for walking, even when the required element is cache resident. Multiple DSAs in the same family will employ the same type of meta-tags, e.g., sparse GEMM accelerators <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Choice 2: Fixed vs. Programmable Walker</head><p>A central design consideration is whether to make the walkers fixedfunction. To understand this, we consider two DSAs from the same family, sparse GEMM: inner-product and Gustavson product <ref type="bibr" target="#b34">[35]</ref> (Figure <ref type="figure">5</ref>). Both DSAs work with the same data structures (CSR/CSC compressed matrices) and use the same meta-tag, but require different walker logic. In both DSAs, the multiplicand, matrix A, is streamed in. However, matrix B requires a walker, and this varies between the DSAs due to the loop order. In the Gustavson DSA , <ref type="bibr" target="#b34">[35]</ref> we perform an outer product between elements of matrix A and the corresponding row of matrix B, e.g., here we multiply A[0,0]:m by B[0,:]. The walker preloads all the non-zeros in B[0,:]. There is only local reuse within a tile. Within a tile, accesses could be unordered and dynamic, but tile order is known upfront. In contrast with innerproduct the elements in matrix B are dynamically determined, e.g., for element A[0,0] walker refills B[0,0]:a and B[2,0]:c. The reuse pattern is entirely dependent on the pattern on non-zeros in matrix A's rows, e.g., B[0,0]: a brought in first for A[0,0], reused by A <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">0]</ref>. A programmable cache controller will enable design reuse and portability across these DSAs. We can retain the same physical structures while varying the logic based on the GEMM algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Choice 3 -Threads vs. Coroutines</head><p>Here we consider the question of how to decouple the walkers and run multiple in parallel. Past approaches have explored the use of threads for static access patterns <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18]</ref>. Each walker is assigned to a hardware pipeline and fetches a tile into an on-chip buffer. The main problems are caused by the data-dependent branches (MATCH, IDX), indirect memory operations (META), and DRAM accesses (FILL). (see Figure <ref type="figure">5</ref> and Figure <ref type="figure">6</ref>). These lock up the pipeline and reduce the number of active walkers, and minimize memory parallelism. Norm. Occupancy ×10 4  Coroutine Thread This paper expresses the walkers as a coroutine and multiplexes them on a pipeline. (see FSM shown in Figure <ref type="figure">5</ref>). Coroutine breaks up a sequential program into regions and enables multitasking. Here, we break up the walker logic into stages/states and yield the thread at annotated long-latency operations, e.g., memory accesses (FILL), dependence chains (AGEN), and data-dependent branches (MATCH). When the long latency event completes, the walker is rescheduled from where it has been left off. Multiple benefits with coroutines: i) we can have multiple walkers and consequently refills from DRAM active, and ii) we can minimize pipeline stalls, and lockups require less hardware. Figure <ref type="figure" target="#fig_6">7</ref> compares the occupancy of controller when walker implemented with coroutine vs. threads. Occupancy is measured as #active-reg × sizebytes × li f etimecycles. With threads, we experience 1000× more occupancy since resources are allocated/freed at a coarse granularity. As the fraction of data residing off-chip increases, long latency transactions increase, and thread occupancy increases.   1 Meta-Tag It is created by our Chisel generator based on the parameters set by the DSA architect. The architect defines the metadata fields that the controller should write explicitly to the tag entry when a refill is completed. These fields will be used for tag matches and determining hits. We also maintain a bitmap to track the active meta-tags, i.e., metadata for which a walker is already active. This helps to continue the execution of a transaction from the stalled point (e.g., on receipt of the DRAM response). y 2 Meta-tag State and Event Triggers The fetch or starting point of the pipeline is the message queues at the controller. The trigger table provides a mapping from the incoming set of messages to events in the protocol. Also, in a conventional cache controller, states are for maintaining coherence. However, in X-Cache the states represent the status of blocks in the walker. And, pairing it with the incoming event leads to sequencing through the walking logic. So, the current state of an entry is maintained along with the meta-tags. The default is the starting state for misses, i.e., no entry in the meta-tag array. The combination of the input event and the current state triggers a routine, determined by the Routine Table <ref type="table">.</ref>    <ref type="table">Similar</ref> to cache coherence protocols <ref type="bibr" target="#b31">[32]</ref>, we have developed a table-based specification. The table encodes the walker logic's states, events, and transitions. Each cell is a pointer to a routine in the microcode RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta</head><p>There are multiple benefits: i) it supports highly parallel pipelines since X-Cache can process the routines of different meta-tags in parallel. ii) it naturally eliminates structural hazards since routines are not triggered until all the hazard conditions are eliminated. So, it simplifies the pipeline implementation. y 4 Routines and µ-coded RAM X-Cache compiles the actual procedures implementing the walking and orchestration down to a microcode binary and stores it in the routine µ-code RAM. The RAM is partitioned into multiple routine handlers. Each routine would be programmed as a sequence of microcode actions finalized with an update to the state. Based on the sequence of the actions, routines can support multiple tasks, i.e., walking the DSA metadata in memory, arbitrating among accesses to the data, calculating addresses and updating the meta-tag arrays. y 5 Actions The controller can only invoke a predefined set of memory and communication primitives. Actions are low-level microcode that specifies the control signals of each internal structure. An important consideration, what is the "proper" granularity for the actions. We adopt actions that can be implemented atomically in hardware with fixed latency in 1 cycle. There are five different categories of actions targeting each hardware module: address generation, message queue, Meta-tag, control flow, and data RAMs. The table in Figure <ref type="figure" target="#fig_8">8</ref> summarizes the list of actions. An action's operands can be explicit (e.g. immediate operand for add or shift), implicit (e.g., queuing request to DRAM), or DSA-specific (e.g., data size). y 6 Data RAMs The data RAM is physically banked based on the number of words supplied to the compute datapaths. Logically, the data RAM is organized as fixed-granularity sectors. Each data element can occupy multiple sectors depending on the size (e.g., number of non-zeros in a row). The meta-tag organization is completely decoupled from the data RAM. Meta-tag only serves to determine whether the data is in the cache or not, i.e., a miss map. Each meta-tag entry includes explicit pointers to start and end sectors within the data RAM (like decoupled sector-caches). On a hit, we use the pointers to retrieve the sectors and pipeline them through a crossbar switch to the datapath. Since the miss walkers are programmable, they copy the DRAM response sector-by-sector into the data RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Execution Model: Coroutines + Decoupled</head><p>We illustrate using an example. X-Cache walks over a hash-table bucket maintained as a linked list. On a meta access, X-Cache first checks the meta-tags for a hit. On a hit, X-Cache short-circuits the search and returns the data from the cache. The meta-tag hit is handled by a dedicated read port in the data RAMs; it's fully pipelined and supports a 3-cycle load-to-use latency. On a miss, X-Cache needs to trigger the walker. First, we consider the programmer's view (Figure <ref type="figure" target="#fig_11">9</ref>) of the walker.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Programmer's view</head><p>In the walker's C code, there is one potentially expensive memory operation, specifically, on the first access to current.key, the condition that checks to see if the key at the current node matches the meta key. Once the cache-block corresponding to this node is loaded, the subsequent access to current.next and current.payload are accessed with minimal latency. We break the C code into a series of coroutines at the long-latency events (see Figure <ref type="figure" target="#fig_11">9</ref>:FSM). The main purpose of this step is to convert stalling events into yields. Yields release the controller pipeline, enabling us to multiplex multiple walkers cooperatively. We provide a table-driven template to help the programmer develop walkers. Each line in the coroutine description specifies a transition. It includes the current phase/state of the walker, the event that triggers the transition, the set of actions that need to be executed, and the next phase/state of the walker. The action sequence is run in program order (left-to-right). We compile this specification to a routine table and microcode RAM. The routine table is a two-dimensional array (see Figure <ref type="figure" target="#fig_11">9</ref>:Execution Model).</p><p>The rows of the routine table correspond to the coroutine states; the columns correspond to the events that can occur. Each entry is a pointer to a routine in the microcode RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Execution sequence</head><p>From the programmer's view, each meta access is driven by a logically separate walker, and within each walker, the execution is event-driven. All walkers are physically multiplexed on a single hardware pipeline. The hardware pipeline (see Figure <ref type="figure" target="#fig_8">8</ref>:Pipeline) consists of two parts. The front-end serves as the event loop. It monitors the message buffers (internal and external) for events and wakes up one active walker per cycle. The current state of the walker is held by a combination of structures: the meta-tag array and the X-registers (a set of temporaries allocated for the duration of the walker).</p><p>The back-end serves as the routine execution pipeline; it is a conventional in-order pipeline. On wakeup the [state,event] pair index into the routine table, and retrieve a pointer to microcode RAM. Each routine, once triggered, will run in a non-blocking fashion. It starts execution from the pointer provided by the routine table, the logical "PC". It runs each action in order and terminates with an update to the next state in meta-tag or X-register.</p><p>We now describe the execution step-by-step. y 1 As it is a miss, we kickstart from the default state. The MISS routine allocates an entry in the meta-tag and the data RAMs for the data element, enqueues a Ptr (calculate pointer) event, and transitions to the Agen state. In this state y 2 the walker is ready to check if the current node contains the key. However, the required access to current-&gt;key will be expensive (might be a cache miss). The step, therefore, issues a DRAM fill on current and yields a hardware pipeline. To track intermediary state while dormant, routines allocate temporary X-register to store the access key and the address of the DRAM refill being waited on. Active walkers, on other meta elements, can proceed to use the hardware pipeline. In y 3 , when Current block arrives from the DRAM, the walker peeks and extracts the block's key. In y 4 , the match checks the block's key against the meta-tag in X-register. If the key matches, the walker copies the block into the data RAM, releases the X-register's entry, and terminates. Otherwise, updates current and continues. Note that the match condition determines the next state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DSA Walker Examples</head><p>This section provides an overview of integrating X-Cache in DSAs. Table <ref type="table" target="#tab_6">2</ref> summarizes the features of X-Cache that are most relevant to each DSA.</p><p>This section presents the details for the walkers of two families: i) Widx <ref type="bibr" target="#b17">[18]</ref>: a DSA for relation-database hash indices. And ii) SpArch <ref type="bibr" target="#b36">[37]</ref>: a DSA for outer-product sparse GEMM. We walk through their data orchestration pipeline and discuss their access patterns. We then describe their walkers in X-Cache. We intend X-Cache to augment (not replace) scratchpads and streams in DSAs. X-Cache targets access patterns that currently do not have a scratchpad/stream solution. The DSAs described below partition the data and use streams for one of the data structures, while employing X-Cache for the other. This is the efficient and performance-approach, as the meta-tags are not required for dense affine accesses. Our primary focus is to demonstrate that X-Cache is reusable and portable across the dynamic access patterns included in multiple DSAs. Widx: Meet the Walkers <ref type="bibr" target="#b17">[18]</ref> The data structure that X-Cache has to walk is a hash-index in the database. In hash-indexes, each bucket is a chained list. The original Widx paper did not employ a domain-specific cache; it relied on an address-based cache and, hence, always walked. X-Cache makes a key improvement over Widx (see X-Cache in Figure <ref type="figure" target="#fig_12">10a</ref>) -it caches the actual nodes in the hash table and tags them with the hash keys. The DSA datapath interfaces with X-Cache by issuing meta-loads and stores the keys in the hash table. On a hit, X-Cache eliminates the hashing (which could be up to 60 cycles in some TPC-H queries) and short circuits the walking. On a miss, the walker uses the address of the hash table (table) and a key to search for the Rid (row id). Note that X-Cache itself is caching the actual hash-index entries (not the row in the database). We break down the walker into multiple coroutines: i) In the first state walker hashes the key to obtain the index of the bucket (IDX). With the index and table of bucket root nodes, it uses a simple function to access the bucket root(META). Then it iterates over its nodes and loads them (AREF, state: DATA) to find the matching record (MATCH).</p><p>Representing the walker as a state machine has two benefits i) each state explicitly indicates the type of hardware module required (e.g., IDX and AGEN require ALUs, while META and AREF RAM ports). This helps schedule away port conflicts within the controller, ii) we can improve memory-level parallelism with multiple keys actively walked independently.</p><p>SpArch: Outer-product sparse GEMM <ref type="bibr" target="#b36">[37]</ref> [37] implements an outer-product-based matrix-matrix multiplication between two sparse matrices (A×B). In each multiplication round, SpArch streams in a subset of columns of the multiplier matrix, A, stored in the CSC format. The multiply phase consists of a set of cross products on the pairs of columns (from A) and rows (from B). In SpArch, the data path uses the row index of an element in the multiplier matrix to index and fetch the corresponding row of the Matrix B, stored in the CSR format, from memory. As the  non-zero pattern in matrix A varies, the rows of B required to be kept on-chip also varies. Thus, SpArch needs a preload walker that runs ahead in decoupled fashion and caches the required rows. X-Cache caches a variable number of rows based on the number of non-zeros in the matrix A's column. The walker logic is quite similar to tiled DMAs, except the tile size varies based on the number of non-zeros in the required row. We initially read the row_ptr metadata of corresponding row (META) and set up a tiled refill. The walker generates addresses (AG) and fetches the consecutive elements from DRAM (DATA), and stores them in cache blocks. The meta-tag, in this case, is row ids of matrix B. There are certain key differences with Widx's walker i) The data fill (DATA) fetches an entire row of matrix B, which consists of multiple elements, while in Widx's case, it is a single node. ii) The number of blocks to be cached depends on the number of non-zeros in the row. iii) There could be multiple potential hits (a row split across multiple cache blocks), and all blocks are serially returned to compute datapath.</p><formula xml:id="formula_0">4 1 R 0 R 1 ... v 0 v 1 ... 3 v st v end ... ... R B ... R B+1 X-Cache R B Data Meta-tag V st V end ... Memory Stream DSA Datapath Streamed Matrix Prefetched Matrix Vector R for Mat A Vector V for Mat A (b) SpArch</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">X-Cache Hierarchies</head><p>In this section, we consider the composability of X-Cache and its interactions with address-based caches. We present three systems i) Multilevel X-Cache (MX) ii) X-Cache with Address cache (MXA), and iii) X-Cache with streaming (MXS). In practice, X-Cache with streaming (MXS) is perhaps the most common. Many DSAs we studied employ this approach. In this case, the DSA explicitly partitions the data based on the access pattern. For instance, in SpArch (Figure <ref type="figure" target="#fig_12">10b</ref>), matrix A is streamed in from the DRAM, while matrix B exhibits dynamic accesses and needs X-Cache. DSAs use global addresses for matrix A while using meta-loads (row-col ids) for the latter. Leveraging access pattern knowledge to partition the data structures is more area and energy efficient than using only X-Cache.</p><p>Multiple levels of X-Cache can also be hierarchically organized (MX). This is made feasible cause the metadata in a DSA is a global space (just like addresses). Each data element has a unique meta-tag associated with it that is common across the X-Cache hierarchy. The upstream L1's X-Cache includes no walker. Similar to a conventional cache, it requests a meta-tag at a time from the downstream X-Cache. Only the last-level X-Cache includes a walker and address-translation, since it interfaces with the DRAM.</p><p>X-Caches can also compose with address-caches (MXA). In this case, X-Cache is the closest level to the DSA datapath, and addressbased caches complete the lower levels. X-Cache will walk and generate addresses at the boundary. The address-cache simply sees a stream of cache line requests. The address cache itself handles a block at a time, while the X-Cache could proactively refill multiple blocks (e.g., entire matrix row). The address-cache is non-inclusive with X-Cache, since they use different namespaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Methodology</head><p>We use TSIM shorturl.at/iBIJ2 to drive cycle-accurate RTL simulation. TSIM is a library that manages communication between a host machine and the DSA RTL model. It provides a simple API to reset, send messages, and load/run programs on the DSA RTL. It also attaches the DSA to the DRAM model. We enclose our DSAs in an AXI shell to communicate with the DRAM. TSIM and Verilator provide a flexible interface that enables the integration of simulation models at multiple levels of abstraction. We implement the controller and X-Cache in Chisel and generate the Verilog. Verilator translates the Verilog into a cycle-accurate simulator and exposes the memory bus ports through the direct-programming interface. This interface permits us to implement the DSA's functional behaviour at a higher level of abstraction (python/c++) and interface only the loads and stores. The DRAM is modelled as another layer attached to the TSIM driver. We use DRAMsim2 to simulate the DRAM. Each of the models is driven using tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">X-Cache Setup</head><p>X-Cache is a toolflow for rapidly constructing domain-specific cache controllers. There are two major parts to X-Cache toolflow (Figure <ref type="figure" target="#fig_1">12</ref>): i) A configurable hardware generator that lets the architects rapidly create domain-specific tags and expose domain-specific loads/stores to interface with compute datapath. ii) A compiler that combines DSA-specific walking and cache management FSMs, and translates them into a microcode binary that runs on a programmable controller. The generator has been implemented as a Chisel library. It hides all the implementation details of the controller microarchitecture while exposing a simple architectural model that the designer can tune. Figure <ref type="figure" target="#fig_10">13</ref> summarizes the top module of X-Cache generator. There are two major segments: i) IOs: X-Cache interfaces with other components through a set of parameterized message bundles, i.e., latency-insensitive queues. X-Cache includes a base set of I/O to interface with the DSA datapath (MetaIO), DRAM bus, and other X-Cache or address caches. Based on system configuration and hierarchy, we instantiate the required I/Os. ii) Modules: X-Cache also exposes the parameters of the individual components from Figure <ref type="figure" target="#fig_8">8</ref>. events rely on X-registers to maintain the walker state. The number of the X-register determines the number of concurrent walkers. This, in turn, affects the number of refills in-flight and memory-level parallelism. iii) Meta-tag and Data RAM geometry: The meta-tag and data RAMS are decoupled and independently parameterized. Meta-tags are only needed for associative searches and optimized for underlying search patterns. For instance, in the case of the Graph-Pulse <ref type="bibr" target="#b29">[30]</ref>, a direct-mapped cache suffices. The cache is preloaded once, and then the accesses happen in arbitrary order. iv) #wlen: We bank and stripe a data entry across multiple sectors based on the number of words to be supplied on each hit. v) The rTable, trigger and microcode RAM (line <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19)</ref> sizes are implicitly set based on the walker coroutines. When we compile them down and encode them, we determine the number of entries required. The structures implicitly scale up or down based on walker FSM complexity.</p><p>Table <ref type="table" target="#tab_8">3</ref> lists the parameters we use for each DSA we evaluate. They have been obtained by sweeping different cache configurations and studying the hit rate and average memory access latency. It is not our goal to find the best controller configuration for each DSA.</p><p>Here we simply want to isolate the performance impact of walker and controller implementation without being influenced by geometry variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">DSA Workload Setup</head><p>Table <ref type="table" target="#tab_8">3</ref> summarizes the pareto-optimal geometries we evaluate for each DSA. Here, we maintain the same geometry for the addressbased cache, X-Cache, and baseline DSA to ensure a fair comparison. X-Cache's chisel generator is highly parameterized, permitting us to generate different cache geometries. We now describe the setup for each workload. Widx <ref type="bibr" target="#b17">[18]</ref>. Workload: MonetDB and TPC-H. Queries TPC-H 19/20/22. Dataset: 100GB. We run DSS queries from TPC-H benchmarks on MonetDB and hijack the hash-joins. X-Cache replaces the hash-index table. The meta-loads to X-Cache include the keys needed to be searched in the index table. If the key is not found in the meta-tag, X-Cache hashes and walks to search for the RID (primary keys) in the corresponding index tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSA #Active</head><p>GraphPulse <ref type="bibr" target="#b29">[30]</ref>. Workload: PageRank. Inputs: p2p-Gnutella08: N = 6.3K, NNZ = 21K, Web-Google: N = 916K, NNZ = 5.1M. The event queue is substituted by the X-Cache. The incoming events are generated by the PEs. These events hold an id (row, bin, column) and a payload. The id probes the meta-tag memory. If the id does not exist, we insert the event by putting the payload in the data memory. Otherwise, we merge the payload of the incoming event and the existing entry using an add operation.</p><p>DASX <ref type="bibr" target="#b21">[22]</ref>. Workload: MonetDB and TPC-H. DASX <ref type="bibr" target="#b21">[22]</ref> is a data structure iterator. The DSA references the keys for each object while hardwiring the address generation, not unlike a TLB walker. The execution proceeds in refill-compute-update rounds. DASX's collector runs ahead of the compute unit to refill multiple objects into a hardwired object cache. Subsequent accesses are cache hits. The cache is reloaded once a round is complete. Here, we study the hash-table, which uses preloads a set of hash keys. We use the same dataset from MonetDB as Widx.</p><p>SpGEMM: SpArch <ref type="bibr" target="#b36">[37]</ref> and gamma <ref type="bibr" target="#b34">[35]</ref>. Input: p2p-Gnutella31. N = 67K, NNZ = 147K. The input to the X-Cache would be the row number of matrix B. The walking is comprised of accessing the B.row_pt array to determine which elements from the B.value array should be loaded and bringing them to the cache. Gamma uses the Gustavson algorithm for sparse GEMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation</head><p>We answer the following questions: i) How does X-Cache compare in performance to address-based caches and the baseline DSAs that employ a customized on-chip RAM? ii) What is the power overhead of caching compared to an ideal scratchpad? Note that these DSAs cannot use scratchpads. Hence, we isolate the cost of data RAMs only (which even a scratchpad would require). iii) What is the power overhead of a programmable cache controller? What is the overhead for the different controller components when synthesized on an FPGA and ASIC? A summary of our findings:</p><p>• X-Cache can be ported and reused across multiple DSA families. We create caches for four different DSA families: Sparse GEMM <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b36">37]</ref>, GraphPulse <ref type="bibr" target="#b29">[30]</ref>, DASX <ref type="bibr" target="#b21">[22]</ref>, and Widx <ref type="bibr" target="#b17">[18]</ref>. We are the first to provide a common storage idiom for these DSAs. • Our RTL cycle-accurate simulations reveal that X-Cache is competitive with the hardwired DSAs; no performance loss and up to 50% gain (compared to specific DSAs). X-Cache outperforms sized address-based cache by 1.7× • An address-based cache consumes 26 -79% more power than X-Cache. The cache controller itself requires ≃ 24% of the total cache power (including the walking logic). Note that the walking logic is accounted for within the datapath in the baseline DSAs.</p><p>• The programmable controller that enables X-Cache to be portable across DSAs requires between 1.4% -8% of on-chip power. The tags on the cache require between 1.4-6.5% of the data SRAMs. • We synthesized our design on the FPGA and ASIC, all the way to GDS. It required less than 7% of a moderate-sized FPGA, making it applicable to DSAs mapped to FPGA as well. At 45nm, the controller occupies 0.1mm 2 (a 256K cache requires 1.1mm 2 just for the data RAM and tags).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Performance Evaluation</head><p>Result: X-Cache delivers 1.7X improvement over address-based caches. X-Cache short-circuits the walks with meta-tags and reduces the number of nested memory accesses by 2-8×. Result: On DSAs with expensive hash calculations, X-Cache delivers a 1.2× performance improvement relative to the baseline DSA. Meta-tags directly cache the keys in a hash table. On hits, they eliminate the need for hashing to find the buckets entirely. Figure <ref type="figure" target="#fig_4">14</ref> compares the runtime of X-Cache against different DSAs under two scenarios. First, we compare the speedup of X-Cache against the baseline DSA that uses a hardwired custom onchip RAM (black bar). We also compare X-Cache address-based cache of the same size. We assume the address-based cache includes an ideal walker, i.e., the walker makes orchestration decisions similar to X-Cache or DSA but incurs zero cost, i.e., all performance differences are a consequence of meta-tags, not orchestration logic.   X-Cache's performance is competitive with baseline DSAs. In the case of Widx, it can even achieve a 1.54X speed up. X-Cache achieves speedup in all the target database queries compared to Widx. On TPC-H-19 and TPC-H-20, X-Cache exhibits an even higher speedup. This is because of the cycles required for bucket index calculations. TPC-H-19 and 20 include string-based keys, their indexing stage, which is hashes this string and would require 60 cycles. In X-Cache on a hit, the load-to-use latency is 10× lower than Widx; since it does not require any hashing. DASX is similar to the Widx, except the hashing is coupled with walking, so X-Cache's gains are higher.</p><p>Compared to address-based caches, X-Cache improves performance by 1.7X on average. Address tags encounter a significant increase in the number of DRAM accesses resulting from nested walks; ≃ 6.5× more than X-Cache(see Figure <ref type="figure" target="#fig_4">14</ref>:Memory Accesses Y-axis). The extra accesses result from nested walks, which increase the footprint of the DSA and cache miss rate. Address-caches walk even when the data is already in the cache. In the case of the Widx and DASX, the root node of a bucket has to be loaded to find any element. On a miss, X-Cache will be limited by memory bandwidth and latency. However, it will minimize the number of DRAM accesses and achieve higher bandwidth utilization. In Gamma and SpArch, even though the meta-data itself is more regular (an array of index pointers), an extra DRAM access is required to load the start pointer of the Row.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Power Breakdown</head><p>Result: Address-based caches require 26-79% more power than X-Cache. Result: The X-Cache controller expends 24% of the cache power (including walking and tags. Result: The programmable RAM within the controller only require 6%, the meta-tags ≃7%. The remaining 11% is required by the walking logic, which would be accounted for within the datapath of the baseline DSA.</p><p>In this section, we study the power consumption of X-Cache. To calculate the power usage, we split up X-Cache into logic, registers and RAM components. The primary RAM components in X-Cache are the data array, meta-tag array, and the routine ROMs. For these components, we used a modified version of CACTI that models RAM arrays accurately https://github.com/bespoke-silicon-group/ bsg_fakeram <ref type="bibr" target="#b23">[24]</ref>. For modelling logic, routines and actions, we used numbers from validated logic synthesis. We use an event-driven  <ref type="table" target="#tab_10">4</ref>. The L1 cache power was modelled using CACTI 6.5; we use serial mode to ensure fair comparison against X-Cache. We also compare the power consumption of X-Cache against an address-based cache. As shown in Figure <ref type="figure" target="#fig_16">15</ref>, address-based caches consume 26-79% more power than X-Cache. The main reason is that we eliminate the walking and reduce the number of on-chip accesses. Figure <ref type="figure" target="#fig_16">15</ref> compares the power usage of on-chip RAMs against the controller and address generator. We find this to be 2-8% in the DSAs we study. This effectively measures the overheads of a reusable idiom since the programmable controller is a central requirement for portability across DSA (each requiring a specialized walker). This is a conservative estimate since we are assuming the cost of a hardwired walker to be zero.</p><p>Figure <ref type="figure" target="#fig_17">16</ref> breaks down the power consumption of the RAM components and the controller in X-Cache. As it shows, the central portion of the power is being used with on-chip data storage. Also, on average, 24% of the power consumption of X-Cache is consumed by the controller. Moreover, the cost of the Routine RAM, which is the primary difference between a programmable controller and a hardwired cache, is less than 4.2%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameters</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Performance Exploration</head><p>Result: As the hit rate increases, X-Cache will achieve higher performance relative to the DSAs by eliminating address-generation and walking. Also, design exploration shows that access pattern influences whether a DSA can take benefit of a larger X-Cache.</p><p>In Figure <ref type="figure" target="#fig_19">17</ref>, the runtime of X-Cache has been compared against the Widx for TPC-H:22 for different percentages of the on-chip data. As it depicts, as the percentage and, consequently, hit rate, goes higher, the benefit of using meta-tag against address-tag would be more evident. A higher hit rate reduces the latency for the accesses to the DRAM, which comprises the dominant portion of the runtime. Besides, using meta-tag reduces the load-to-use latency in comparison with the address-tag.   Apart from the memory-related parameters, the number of ways and the number of sets, X-Cache has two primary parameters that should be set for each benchmark. Figure <ref type="figure" target="#fig_20">18</ref> demonstrates the sweeping of these two parameters for two different datasets of GraphPulse and Widx. For GraphPulse: p2p-Gnutella08, increasing the #Active and #Exe could diminish the runtime by half compared to the baseline design. However, for Widx: TPC-H-22, increasing mentioned parameters results in at most 10 percent of speedup. This observation could be explained by the behaviour of these two DSAs. As it has been elaborated in §5, the bottleneck of the performance of Widx is DRAM access. In addition to this, even for higher hit rates, meta hit is being used for returning the requested data. Consequently, increasing the parallelism in X-Cache would not have a significant impact on the overall runtime. On the other hand, GraphPulse takes benefit of higher #Exe in X-Cache. Although the DRAM access is still the dominant part of the latency, increasing the parallelism in X-Cache brings down the latency in the event generating stage of GraphPulse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Synthesis Results</head><p>Result: Synthesis results are extracted from Quartus II V.13 for #Exe=4 and #Active=8.</p><p>We synthesized the generated X-Cache controller using Quartus II version 13.0. We set the #Exe for this synthesis on 4 and #Active on 8. In Figure <ref type="figure" target="#fig_21">19</ref>, we have breakdown the register utilization and logic utilization of the generated RTL. As shown, X-Reg uses the most register, and Action-Executor units use the majority of the logic in X-Cache. We also used OpenROAD <ref type="bibr" target="#b1">[2]</ref>, an open-source RTL-to-GDS tool for ASIC synthesisX-Cache. Figure <ref type="figure" target="#fig_22">20</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Related Work</head><p>There have been multiple proposals rethinking address-based caches. Stash <ref type="bibr" target="#b20">[21]</ref> carves out portions of the address space. Hits to the scratchpad portion directly access the data RAMs; misses</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>[Figure 2 :</head><label>2</label><figDesc>Figure 2: Walkers in Sparse GEMM DSA (Inner Product)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: X-Cache vs. state-of-the-art storage idiomsTable 1: X-Cache vs. state-of-the-art storage idioms (shaded cells indicate limitations) Caches Scratch+DMA Scratch+AE FIFOs X-Cache<ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref> e.g., Buffets<ref type="bibr" target="#b27">[28]</ref> e.g., CoRAM<ref type="bibr" target="#b5">[6]</ref> e.g., Spatial<ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> Stream<ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25]</ref> AE<ref type="bibr" target="#b4">[5]</ref>,Stash<ref type="bibr" target="#b20">[21]</ref> Pipeline<ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Walkers and coroutines for two DSAs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Load-to-use-latency. Address Tags vs. Meta-tags</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Occupancy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>6 Figure 8 :</head><label>68</label><figDesc>Figure 8: X-Cache Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8</head><label>8</label><figDesc>Figure 8 illustrates the modules in X-Cache. y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>3</head><label>3</label><figDesc>Routine Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: X-Cache Execution Model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Demonstration of two DSAs using X-Cache.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Fitting X-Cache in a memory hierarchy or next to a DSA which needs streaming too. Blue regions: Meta is used. Red regions: Global addr is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 : 8 class 10 /Figure 13 :</head><label>1281013</label><figDesc>Figure 12: X-Cache Toolflow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>TPC-H-19 TPC-H-20 TPC-H-22 p2p-31 TPC-H-19 TPC-H-20 TPC-H-22 p2p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Total Power Breakdown in X-Cache (Lower is better)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Breakdown of RAM power in X-Cache</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: X-Cache Runtime Vs Widx (runtime normalized to data in DRAM)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Sweeping Design Parameters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: FPGA Synthesis</figDesc><graphic url="image-40.png" coords="12,389.77,531.05,96.02,91.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Layout. X-Cache controller (no RAMs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>We create domain-specific caches targeting five different DSAs from three domains sparse-matrix computation, databases, and graph processing. We will be open-sourcing a Chisel generator and microcode table compiler.Figure2illustrates the walker of an inner-product sparse GEMM DSA. Matrix A is stored in CSR format and matrix B in CSC. As the DSA streams in matrix A, it fetches the non-zeros from the corresponding column in matrix B. There are multiple metadata</figDesc><table><row><cell>• Domain-specific caches improve performance 1.7× by short-</cell></row><row><cell>circuiting data structure walks and reducing memory accesses</cell></row><row><cell>by 2-8×. The controller requires 7% of energy, and tags only</cell></row><row><cell>require 1.5-6.5% of data RAM energy.</cell></row><row><cell>2 Motivation and Scope</cell></row><row><cell>2.1 Why not scratchpads</cell></row></table><note>(META) accesses, e.g., for A[0,0] we consider non zeros from B's column 0, but for A[0,1] we refill B's column 1. Since B is sparse, DSA traverses the indices (IDX) to retrieve the coordinates of the non-zeros. We then check for matches (MATCH) and find non-zero elements for which A is also non-zero. The accesses to matrix B are: i) dynamic, i.e., the tile of matrix B refilled from DRAM depends on the coordinates of matrix A's non-zero element. ii) conditional, i.e., elements in a column may be skipped over depending on A's non-zero pattern, and iii) the reuse depends on the sparsity pattern.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>: X-Cache vs. state-of-the-art storage idioms (shaded cells indicate limitations)</figDesc><table><row><cell></cell><cell></cell><cell>Caches</cell><cell cols="2">Scratch+DMA</cell><cell>Scratch+AE</cell><cell>FIFOs</cell><cell>X-Cache</cell></row><row><cell cols="3">Granularity Meta-to-Addr Behavior [3, 11, 23, 26, 27]  Target Blocks Dynamic Domain --</cell><cell cols="3">Tiles Yes. Walking and translation always required. Word Static pattern (affine) Linear data structure</cell><cell>Elements Stream</cell><cell>DSA-specific Only Misses Dynamic Flexible</cell></row><row><cell></cell><cell>Addressing</cell><cell>Implicit</cell><cell>Explicit</cell><cell></cell><cell>Implicit</cell><cell>Implicit</cell><cell>Implicit</cell></row><row><cell></cell><cell>Coupling</cell><cell cols="2">Coupled (Load/Store) Decoupled</cell><cell></cell><cell>Coupled</cell><cell>Decoupled</cell><cell>Decoupled</cell></row><row><cell></cell><cell>Trigger</cell><cell cols="2">Implicit (Load/Store)</cell><cell cols="2">Explicit (Datapath)</cell><cell>Implicit (push/pop)</cell><cell>DSA-specific</cell></row><row><cell>Design</cell><cell>Walker Control Multi.Fill</cell><cell>Hardwired Complex (MSHRs)</cell><cell cols="4">No. DSA has to walk metadata. Fixed FSM Simple (double-buffering) Complex (thread) Simple (double-buf) Simple (Routines) Only FIFO Yes (Coroutine) Hardwired Hardwired Programmable</cell></row><row><cell></cell><cell>LD/ST order</cell><cell>Arbitrary</cell><cell></cell><cell cols="2">Limited (on-chip only)</cell><cell>Only FIFO</cell><cell>Arbitrary</cell></row><row><cell></cell><cell>Preload</cell><cell>-(separate)</cell><cell></cell><cell cols="2">Limited (credit)</cell><cell>Limited (credits)</cell><cell>Yes (FSM driven)</cell></row><row><cell></cell><cell>Orch.</cell><cell>Load-to-use</cell><cell></cell><cell></cell><cell>Ready/Valid. Fill or gather</cell><cell>Load-to-Use</cell></row><row><cell cols="5">strides. We focus on algorithms with indirect indexes, sparse tensors,</cell><cell></cell></row><row><cell cols="5">and conditional accesses. Scratchpad-AE (programmable access</cell><cell></cell></row><row><cell cols="2">engine)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>e.g., Buffets<ref type="bibr" target="#b27">[28]</ref> e.g., CoRAM<ref type="bibr" target="#b5">[6]</ref> e.g., Spatial<ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> Stream<ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25]</ref> AE<ref type="bibr" target="#b4">[5]</ref>,Stash<ref type="bibr" target="#b20">[21]</ref> Pipeline<ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table Active Meta</head><label>Active</label><figDesc></figDesc><table><row><cell>Meta Load Meta Others Hit</cell><cell cols="3">Meta-tags Trigger Trigger Stage #Active Decode Stage Tag Stat. R1..Rn</cell><cell cols="2">Executor Stage #Exe</cell><cell cols="2">Data Stage SRAM Banks</cell><cell></cell><cell></cell><cell cols="2">µcode actions</cell></row><row><cell></cell><cell>#Size</cell><cell>Routine</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Default Pipeline</cell><cell>AGEN</cell></row><row><cell></cell><cell>Event State State RTN* Event Trigger</cell><cell>Table</cell><cell cols="2">µcode n Action 2 Action 1 Routine RAM</cell><cell>-Tag AGEN Data RAM Msg. Queue Loop/Branch</cell><cell>#wlen</cell><cell>Data Out</cell><cell>Peek Msg</cell><cell>Meta Tag Load</cell><cell>Rtn Table Meta-tag Meta Hit</cell><cell>Sched. Data</cell><cell>Port Tags Port Data Branch Queue</cell></row><row><cell></cell><cell></cell><cell></cell><cell>...</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rtn RAM</cell><cell></cell></row></table><note>AGENadd, and, or, xor, addi, inc, dec, shl, shr, sra, srl, not, allocR Queues enq, deq, read-data, write-data, peek Meta-tags allocM, deallocM, update, state Control bmiss, bhit, beq, bnz, blt, bge, ble DataRAM allocD, deallocD, read,writeX-Reg</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>X-Cache features benefiting DSAs</figDesc><table><row><cell>DSA</cell><cell>Tag</cell><cell cols="3">Preload Coupling Data DS</cell></row><row><cell>Widx [18]</cell><cell>Key</cell><cell>No</cell><cell>Coupled Rid</cell><cell>Hash Table</cell></row><row><cell cols="2">DASX[22] Key</cell><cell>Yes</cell><cell>Decoupl. Rid</cell><cell>Hash Table</cell></row><row><cell cols="3">Graph [30] Node Idx No</cell><cell cols="2">Decoupl. Event Graph</cell></row><row><cell cols="3">SpArch [37] Col Idx Yes</cell><cell cols="2">Decoupl. B.Row CSR</cell></row><row><cell cols="3">Gamma [36] Col Idx Yes</cell><cell cols="2">Decoupl. B.Row CSR</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>X-Cache design parameters per DSA.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">#Exe #Way</cell><cell cols="2">#Set #Word</cell></row><row><cell>Widx</cell><cell>16</cell><cell>2</cell><cell>8</cell><cell>1024</cell><cell>4</cell></row><row><cell>DASX(Hash)</cell><cell>16</cell><cell>4</cell><cell>8</cell><cell>1024</cell><cell>4</cell></row><row><cell>SpArch</cell><cell>32</cell><cell>4</cell><cell>8</cell><cell>512</cell><cell>4</cell></row><row><cell>Gamma</cell><cell>32</cell><cell>4</cell><cell>8</cell><cell>512</cell><cell>4</cell></row><row><cell>GraphPulse</cell><cell>16</cell><cell>4</cell><cell cols="2">1 131072</cell><cell>8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>Power usage per bit[pj] Energy parameters (timing: 1GHz)</figDesc><table><row><cell>Register</cell><cell>8.9e-03</cell></row><row><cell>Add</cell><cell>2.1e-01</cell></row><row><cell>Mul</cell><cell>12.6</cell></row><row><cell>Bitwise Op</cell><cell>1.8e-02</cell></row><row><cell>Shift</cell><cell>4.1e-01</cell></row><row><cell>Memory</cell><cell>Power usage [pj]</cell></row><row><cell>Tag</cell><cell>2.7 / Byte</cell></row><row><cell>L1 Cache</cell><cell>44.8 / 32 Bytes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>depicts the controller with #Exe=4 and #Active=8. Under 45nm technology, the total area required is 0.11mm 2 and 65K cells. A 256K RAM under 45nm technology require 0.8mm 2 .</figDesc><table><row><cell>31% 24%</cell><cell>10% 15% 20%</cell><cell>Rtn. Table Act. Meta X-Reg Action Exec. Others</cell><cell>45%</cell><cell>20%</cell><cell>4% 11% 20%</cell></row><row><cell cols="2">Reg Utilization</cell><cell></cell><cell cols="3">Logic Utilization</cell></row><row><cell>FPGA</cell><cell></cell><cell cols="4">Altera Cyclone IV GX</cell></row><row><cell>Model</cell><cell></cell><cell cols="4">EP4CGX150DF31C8</cell></row><row><cell cols="2">Total Logics</cell><cell></cell><cell cols="3">6985 (6% utlilized)</cell></row><row><cell cols="3">Total Combinational Functions</cell><cell cols="3">5766 (5% utilized)</cell></row><row><cell cols="2">Total Registers</cell><cell></cell><cell cols="3">3457 (2% utilized)</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>implicitly fetch the data. Jenga <ref type="bibr" target="#b32">[33]</ref> and Hotpads <ref type="bibr" target="#b33">[34]</ref> organize the hierarchy of caches as a collection of SRAM banks. GPUs <ref type="bibr" target="#b15">[16]</ref> and many cores use software-managed scratchpads. These approaches target CPUs or GPUs that role in address-translation and walking into the software. Also, prior approaches need to translate metadata to addresses (either local or global). Our observation is that if the on-chip data tags can be explicitly set to DSA-specific metadata, we can eliminate address generation (similar to a TLB).</p><p>There has been extensive work in combining the benefits of DMAs and scratchpads. Most recently, buffets <ref type="bibr" target="#b27">[28]</ref> and Ax-DAE <ref type="bibr" target="#b4">[5]</ref> developed a scratchpad+DMA storage idiom that can be reused and ported across DSAs. Both can achieve high performance when the access pattern is static, and the order of accesses is known upfront. They studied DSAs that work on tile-based data structures. The underlying orchestration pattern is hardwired. Ax-DAE is also limited by high-level-synthesis tools that do not support parallel accesses to indirectly indexed data. Finally, prior proposals are closely coupled and target static access patterns, affine types, and regular computation.</p><p>Finally, Widx <ref type="bibr" target="#b17">[18]</ref> and DASX <ref type="bibr" target="#b21">[22]</ref> accelerated the walk over data structures. Widx created an enhanced classic RISC pipeline and compiled down walkers to imperative binary. Ax-DAE leverage FPGA high-level-synthesis. Widx stored data in an address-based cache, and DAE stored the data in a scratchpad. both cases, the storage is decoupled separately from the walker logic. The walker interfaces with the storage through an address-based interface, either explicitly (Ax-DAE) or implicitly (Widx). In either case, this leads to loss of locality for metadata accesses and multiple address generations are required during the walking phase. Patch memory <ref type="bibr" target="#b6">[7]</ref> targeted image processing pipelines that need tiling. The DSA-expert has to define the loop order, and the patch runs ahead in a decoupled manner. It cannot be employed for the DSAs we explore. LEAP <ref type="bibr" target="#b0">[1]</ref> and CoRAM <ref type="bibr" target="#b5">[6]</ref> targeted BRAMs on an FPGA. Leap unified logically separate scratchpads into a tagged cache-like structure with implicit accesses. CoRAM created a framework for defining custom refill engines. Both do not include support for decoupled refill engines to prefetch data. They do not incorporate DSA-specific tags and require multiple accesses to satisfy a load/store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>We develop X-Cache, a reusable caching idiom for domainspecific-architectures. There are two key ideas in X-Cache i) Metatags: DSA-specific tags implicitly cache the elements in the indirectlyindexed data structure. Meta-tags reuse the elements and shortcircuit the data structure traversals. ii) Routines: a programmable microcode engine that runs the walkers and orchestration state machines. We are the first to create a high-performance cache controller targetting DSAs, with support for implicit accesses, decoupled miss walkers, parallel refills, and pipelined data and tag management. We will be open-sourcing the chisel generator, a compiler to translate walkers to microcode, and cache designs for five DSAs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Leap Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kermin</forename><forename type="middle">E</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angshuman</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Emer</surname></persName>
		</author>
		<idno type="DOI">10.1145/1950413.1950421</idno>
		<ptr target="https://doi.org/10.1145/1950413.1950421" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM/SIGDA International Symposium on Field Programmable Gate Arrays (FPGA &apos;11)</title>
				<meeting>the 19th ACM/SIGDA International Symposium on Field Programmable Gate Arrays (FPGA &apos;11)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">OpenROAD: Toward a Self-Driving, Open-Source Digital Layout Implementation Tool Chain</title>
		<author>
			<persName><surname>Ajayi</surname></persName>
		</author>
		<author>
			<persName><surname>Blaauw</surname></persName>
		</author>
		<author>
			<persName><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Chhabria</surname></persName>
		</author>
		<author>
			<persName><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><surname>Coltella</surname></persName>
		</author>
		<author>
			<persName><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName><surname>Dreslinski</surname></persName>
		</author>
		<author>
			<persName><surname>Fogaça</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GOMACTECH</title>
				<meeting>GOMACTECH</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1105" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ASCELLA: Accelerating Sparse Computation by Enabling Stream Accesses to Memory</title>
		<author>
			<persName><forename type="first">Bahar</forename><surname>Asgari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramyad</forename><surname>Hadidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyesoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</title>
				<meeting>of Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Impulse: building a smarter memory controller</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stoller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chi</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuramkote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schaelicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tateyama</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.1999.744334</idno>
		<ptr target="https://doi.org/10.1109/HPCA.1999.744334" />
	</analytic>
	<monogr>
		<title level="m">Proceedings Fifth International Symposium on High-Performance Computer Architecture</title>
				<meeting>Fifth International Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient data supply for hardware accelerators with prefetching and access/execute decoupling</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 49th MICRO</title>
				<meeting>of the 49th MICRO</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">CoRAM: an in-fabric memory architecture for FPGA-based computing</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Mai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PROC of the 19th FPGA</title>
				<imprint>
			<publisher>ACM Request Permissions</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Patch Memory System for Image Processing and Computer Vision</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Clemons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Chi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iuri</forename><surname>Frosio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">W</forename><surname>Daniel R Johnson</surname></persName>
		</author>
		<author>
			<persName><surname>Keckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 49th MICRO</title>
				<meeting>of the 49th MICRO</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain-Specific Hardware Accelerators</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatish</forename><surname>Turakhia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1145/3361682</idno>
		<ptr target="https://doi.org/10.1145/3361682" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2020-06">2020. June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Type-directed scheduling of streaming accelerators</title>
		<author>
			<persName><forename type="first">David</forename><surname>Durst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dillon</forename><surname>Huff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Akeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><forename type="middle">G</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilbert</forename><surname>Louis Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Patrignani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kayvon</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 41st PLDI</title>
				<meeting>of the 41st PLDI</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="408" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Near-Memory Data Transformation for Efficient Sparse Matrix Multi-Vector Multiplication</title>
		<author>
			<persName><forename type="first">Daichi</forename><surname>Fujiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niladrish</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike O'</forename><surname>Connor</surname></persName>
		</author>
		<idno type="DOI">10.1145/3295500.3356154</idno>
		<ptr target="https://doi.org/10.1145/3295500.3356154" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</title>
				<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis<address><addrLine>Denver, Colorado; New York, NY, USA, Article</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">55</biblScope>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MANIC: A Vector-Dataflow Architecture for Ultra-Low-Power Embedded Systems</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Gobieski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amolak</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Serafin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehmet</forename><surname>Meric Isgenc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358277</idno>
		<ptr target="https://doi.org/10.1145/3352460.3358277" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>Columbus, OH, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="670" to="684" />
		</imprint>
	</monogr>
	<note>MICRO &apos;52)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DeSC: decoupled supply-compute communication management for heterogeneous architectures</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">L</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Aragn</surname></persName>
		</author>
		<author>
			<persName><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th MICRO</title>
				<meeting>of the 48th MICRO</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="191" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient gather and scatter operations on graphics processors</title>
		<author>
			<persName><forename type="first">Bingsheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Naga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiong</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burton</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1145/1362622.1362684</idno>
		<ptr target="https://doi.org/10.1145/1362622.1362684" />
	</analytic>
	<monogr>
		<title level="m">SC &apos;07: Proceedings of the 2007 ACM/IEEE Conference on Supercomputing. 1-12</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A New Golden Age for Computer Architecture</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<idno type="DOI">10.1145/3282307</idno>
		<ptr target="https://doi.org/10.1145/3282307" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="48" to="60" />
			<date type="published" when="2019-01">2019. Jan. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient execution of memory access phases using dataflow specialization</title>
		<author>
			<persName><forename type="first">Chen-Han</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 42nd ISCA</title>
				<meeting>of the 42nd ISCA</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="118" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scratchpad Sharing in GPUs</title>
		<author>
			<persName><forename type="first">Vishwesh</forename><surname>Jatala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayvant</forename><surname>Anantpur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amey</forename><surname>Karkare</surname></persName>
		</author>
		<idno type="DOI">10.1145/3075619</idno>
		<ptr target="https://doi.org/10.1145/3075619" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2017-05">2017. May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Ujval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Kapasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Rixner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brucek</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><surname>Owens</surname></persName>
		</author>
		<idno type="DOI">10.1109/MC.2003.1220582</idno>
		<ptr target="https://doi.org/10.1109/MC.2003.1220582" />
	</analytic>
	<monogr>
		<title level="m">Programmable Stream Processors</title>
				<imprint>
			<date type="published" when="2003-08">2003. aug 2003</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Meet the walkers: accelerating index traversals for in-memory databases</title>
		<author>
			<persName><forename type="first">Onur</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Picorel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th MICRO</title>
				<meeting>of the 46th MICRO</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="468" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Spatial: a language and compiler for application accelerators</title>
		<author>
			<persName><forename type="first">David</forename><surname>Koeplinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghu</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Hadjis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruben</forename><surname>Fiszel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Nardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ardavan</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunle</forename><surname>Olukotun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ACM</publisher>
			<pubPlace>New York, New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic Generation of Efficient Accelerators for Reconfigurable Hardware</title>
		<author>
			<persName><forename type="first">David</forename><surname>Koeplinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghu</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Delimitrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunle</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd ISCA</title>
				<meeting>of the 43rd ISCA</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stash: have your scratchpad and cache it too</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Komuravelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnathan</forename><surname>Alsop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Huzaifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Kotsifakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakalp</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarita</forename><forename type="middle">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><surname>Vikram S Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 42nd ISCA</title>
				<meeting>of the 42nd ISCA</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="707" to="719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DASX: Hardware accelerator for software data structures</title>
		<author>
			<persName><forename type="first">Snehasish</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Vedula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arrvindh</forename><surname>Shriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijayalakshmi</forename><surname>Srinivasan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2751205.2751231</idno>
		<ptr target="https://doi.org/10.1145/2751205.2751231" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Supercomputing</title>
				<meeting>the International Conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2015-06">2015. 2015-June (2015</date>
			<biblScope unit="page" from="361" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An Efficient Hardware Accelerator for Sparse Convolutional Neural Networks on FPGAs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="17" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimizing NUCA Organizations and Wiring Alternatives for Large Caches with CACTI 6.0</title>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Muralimanohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norm</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PROC of the 40th MICRO</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stream-Dataflow Acceleration</title>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinay</forename><surname>Gangadhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newsha</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 44th ISCA</title>
				<meeting>of the 44th ISCA</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="416" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Sparse Matrix Vector Multiply Accelerator for Support Vector Machine</title>
		<author>
			<persName><forename type="first">Eriko</forename><surname>Nurvitadhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asit</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debbie</forename><surname>Marr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on Compilers, Architecture and Synthesis for Embedded Systems</title>
				<meeting>the 2015 International Conference on Compilers, Architecture and Synthesis for Embedded Systems<address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Outerspace: An outer product based sparse matrix multiplication accelerator</title>
		<author>
			<persName><forename type="first">Subhankar</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Beaumont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong-Hyeon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aporva</forename><surname>Amarnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siying</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitali</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hun-Seok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Blaauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><surname>Dreslinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="724" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Buffets: An Efficient and Composable Storage Idiom for Explicit Decoupled Data Orchestration</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Yakun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><surname>Clemons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Clayton Crago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangharajan</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">W</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th ASPLOS</title>
				<meeting>of the 24th ASPLOS</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="137" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SIGMA: A Sparse and Irregular GEMM Accelerator with Flexible Interconnects for DNN Training</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Samajdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoukjun</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Nadella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudarshan</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharat</forename><surname>Kaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">GraphPulse: An Event-Driven Hardware Accelerator for Asynchronous Graph Processing</title>
		<author>
			<persName><forename type="first">Shafiur</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Nael B Abu-Ghazaleh</surname></persName>
		</author>
		<author>
			<persName><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 53rd MICRO</title>
				<meeting>of the 53rd MICRO</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="908" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gather-Scatter DRAM: In-DRAM Address Translation to Improve the Spatial Locality of Non-Unit Strided Accesses</title>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Boroumand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<idno type="DOI">10.1145/2830772.2830820</idno>
		<ptr target="https://doi.org/10.1145/2830772.2830820" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
				<meeting>the 48th International Symposium on Microarchitecture<address><addrLine>Waikiki, Hawaii; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="267" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Primer on Memory Consistency and Cache Coherence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Sorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.2200/S00346ED1V01Y201104CAC016</idno>
		<ptr target="https://doi.org/10.2200/S00346ED1V01Y201104CAC016Publisher" />
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Computer Architecture</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="212" />
			<date type="published" when="2011-11">2011. Nov. 2011</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Jenga: Software-Defined Cache Hierarchies</title>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
		<idno type="DOI">10.1145/3079856.3080214</idno>
		<ptr target="https://doi.org/10.1145/3079856.3080214" />
	</analytic>
	<monogr>
		<title level="m">2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="652" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rethinking the memory hierarchy for modern languages</title>
		<author>
			<persName><forename type="first">An</forename><surname>Po</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Ling</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><surname>Sanchez</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2018.00025</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2018.00025" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual International Symposium on Microarchitecture, MICRO 2018-Octob</title>
				<meeting>the Annual International Symposium on Microarchitecture, MICRO 2018-Octob</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="203" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gamma: leveraging Gustavson&apos;s algorithm to accelerate sparse matrix multiplication</title>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nithya</forename><surname>Attaluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th ASPLOS</title>
				<meeting>of the 26th ASPLOS</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Gamma: Leveraging Gustavson&apos;s Algorithm to Accelerate Sparse Matrix Multiplication</title>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nithya</forename><surname>Attaluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
		<idno type="DOI">10.1145/3445814.3446702</idno>
		<ptr target="https://doi.org/10.1145/3445814.3446702" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems<address><addrLine>Virtual, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="687" to="701" />
		</imprint>
	</monogr>
	<note>ASPLOS 2021)</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SpArch: Efficient architecture for sparse matrix multiplication</title>
		<author>
			<persName><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanrui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th Int&apos;l. Symposium on High Performance Computer Architecture</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
