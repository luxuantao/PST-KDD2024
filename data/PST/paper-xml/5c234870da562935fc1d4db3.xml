<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CritICs Critiquing Criticality in Mobile Apps</title>
				<funder ref="#_5jFugRx #_8Y8WDbq #_j8j2uhd #_a5Bp2t4 #_E6egjtt #_7Mkq4su #_fBTp7kw #_ZYpZZgv">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_WmJtXen #_4pjxsWc">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_EsJcM62">
					<orgName type="full">DARPA/SRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Prasanna</forename><forename type="middle">Venkatesh</forename><surname>Rengasamy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nachiappan</forename><forename type="middle">Chidambaram</forename><surname>Nachiappan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Mahmut</roleName><forename type="first">T</forename><surname>Kandemir</surname></persName>
							<email>kandemir@psu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chita</forename><forename type="middle">R</forename><surname>Das</surname></persName>
							<email>das@psu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">? IEEE Member</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CritICs Critiquing Criticality in Mobile Apps</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Criticality</term>
					<term>CPU</term>
					<term>Mobile</term>
					<term>Energy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we conduct a systematic analysis to show that existing CPU optimizations targeting scientific/server workloads are not always well suited for mobile apps. In particular, we observe that the well-known and very important concept of identifying and accelerating individual critical instructions in workloads such as SPEC, are not as effective for mobile apps. Several differences in mobile app characteristics including (i) dependencies between critical instructions interspersed with non-critical instructions in the dependence chain, (ii) temporal proximity of the critical instructions in the dynamic stream, and (iii) the bottleneck shifting to the front from the rear of the datapath pipeline, are key contributors to the ineffectiveness of traditional criticality based optimizations. Instead, we propose the concept of Critical Instruction Chains (CritICs) -which are short, critical and self contained sequences of instructions, for aggregate level optimization. With motivating results, we show that an offline profiler/analysis framework can easily identify these CritICs, and we propose a very simple software mechanism in the compiler that exploits ARM's 16-bit ISA format to nearly double the fetch bandwidth of these instructions. We have implemented this entire framework -both profiler and compiler passes, and evaluated its effectiveness for 10 popular apps from the Play Store. Experimental evaluations show that our approach is much more effective than two previously studied criticality optimizations, yielding a speedup of 12.65%, and energy savings of 15% in the CPU (translating to a system wide energy savings of 4.6%), requiring very little additional hardware support.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The proliferation of mobile devices over the past decade has been fueled by not just hardware advancements, but also by the numerous and diverse applications (apps) that these devices can support. The number of such devices far exceeds the desktop and server markets, with nearly 2.6 billion mobile devices serving more than 35% of the world population today <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. To a large extent, the hardware and software evolution of these devices has drawn from lessons learned over the years from their desktop/server counterparts and adapted them for different resource constraints -energy/power, form-factor, etc. On the other hand, many of the mobile apps have very different characteristics, and are used in very different ways compared to desktop/server workloads (e.g., high amount of user-interaction, handling sensors, etc.). And so, it is not clear whether the same high-end device optimizations are effective for the mobile platforms.</p><p>Picking two well-studied optimizations (instruction prioritization and memory prefetching) that try to exploit a very important property, namely "criticality", of the instructions in server/desktop domains, this paper points out that these mechanisms are not well suited to mobile apps. Instead, this work proposes to track criticality at the granularity of selfcontained instruction chains, and assigns a criticality metric to each chain. With the bottleneck shifting from the rear to the front of the CPU datapath pipeline in these mobile apps, this paper introduces a novel way of prioritizing and aggregating these Critical Instruction Chains (CritIC) in software to solve this problem, requiring little to no additional hardware support.</p><p>While one could throw extra resources and hardware mechanisms into a superscalar processor's datapath to boost performance in embedded domain, it is even more important to better utilize the existing resources amongst the competing instructions, especially in resource-constrained environments. One such well studied mechanism for prioritization amongst competing instructions is based on "criticality". When a critical instruction is brought into the processor datapath, different prioritizations/optimizations can be employed. Over the years, numerous criticality based optimizations have been proposed and studied for high-end workloads -prioritizing CPU resources <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b6">[7]</ref>, caches <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>, memory request queues <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>, predicting the result of the instruction <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b16">[17]</ref>, issuing prefetch requests <ref type="bibr" target="#b17">[18]</ref>, etc. However, the impact of these optimizations has not been studied to date for mobile workloads, and that is one important void this paper intends to fill.</p><p>Unlike many desktop/server workloads which are very throughput demanding, mobile apps are highly user-interactive. User actions like screen swipes, and sensor inputs like positional (GPS) and/or movement (accelerometer) frequently control the execution, with the app reacting to such actions and coming back for additional inputs. The consequent code, though rich in the conventionally deemed "critical instructions", are not conducive enough for independent instruction-level optimizations, i.e., they are often dependent on each other with possibly one or more non-critical instructions coming into the dependence chain between them. For instance, we show that one such recent optimization <ref type="bibr" target="#b17">[18]</ref>, which prioritizes critical loads, does very well for SPEC workloads (as in prior works), but provides a measly 0.7% speedup for a wide spectrum of mobile apps. Any criticality optimization targeting mobile apps should, thus, consider these sequences/groups of critical instructions at a time, rather than optimize for each individually. We identify two additional differences: (i) the bottleneck for these critical instructions shifts from the back-end (Execute/Commit stages of the superscalar pipeline) to the front-end (Fetch stage) of the pipeline when we move from SPEC to mobile apps; and (ii) sequences/groups of critical instructions are much smaller, and occur close together in the dynamic execution stream, for mobile apps compared to SPEC workloads, making them more amenable for aggregate-level software based optimizations. We are not aware of any prior work which has pointed out the insufficiencies of criticality-based individual instruction optimizations for mobile apps, and their workload differences requiring a revisit of this topic in the mobile context.</p><p>Motivated by this insight for several off-the-shelf Android apps, we make the following contributions in this work:</p><p>? We use the concept of a self-contained Instruction Chain (IC) within a Data Flow Graph (DFG), which can be executed independent of other instructions, when encountered. We introduce a criticality metric for an IC, that is calculated as the average fan-out per instruction in that chain. ICs with a criticality exceeding a threshold are marked as CritICs, and the entire CritIC sequence of instructions is given priority. Unlike SPEC, CritICs in mobile apps are relatively short (order of 5 instructions) and are not that widely spaced out in the dynamic instruction stream either, making them suitable for software (e.g., compiler, profiler) identification. ? We note that CritIC instructions in mobile apps are bottlenecked in the Fetch stage of the pipeline, as opposed to SPEC which are back-ended (execute/commit stages), since the number of high latency instruction is a much smaller fraction in the former. Both the producer side which feeds instructions into the pipeline, and the consumer side which drains the instructions from the fetched queue are equally important contributors to this bottlenecked stage. ? Our identification of Critical and Self-contained ICs, provides a convenient abstraction for tackling the fetch bottleneck. We could theoretically hoist and aggregate all these instructions together as a macro instruction. But the number of possible CritIC sequences makes this option expensive.</p><p>Adhering to the philosophy of imposing minimal hardware enhancements, we instead propose a novel approach to doubling the fetch bandwidth for these CritIC instructions by leveraging ARM's 16-bit instruction format. We convert all these instructions into the 16 bit representation in a compiler pass, as long as there is no loss in their functionality, together with a preceding command to instruct the ARM hardware to switch to 16-bit format for these instructions. This proposed hoisting and 16-bit conversion from the software side can be employed in all current ARM CPU based devices <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>. ? We have implemented a profiler on top of the AOSP emulator <ref type="bibr" target="#b21">[22]</ref> and GEM5 simulator <ref type="bibr" target="#b22">[23]</ref> for identifying CritIC sequences. We have also added a compiler pass in the Android Runtime Compiler (ART) to hoist, aggregate and emit the 16-bit representations for the CritIC instructions.</p><p>We have evaluated our proposal in GEM5 for a Google Tablet configuration using a diverse and popular suite of 10 stock Android apps from the Play Store. ? Results show that our approach provides as much as 15% speedup (12.65% speedup on the average) for these apps, while two previously well regarded single instruction criticality based load prefetching and single instruction prioritization provide only 0.7% and 5% speedup on the average. The 16-bit representations nearly doubles the fetch bandwidth for all CritIC sequences, buying back 3.6% of the time on the producer-side of the fetch. Packing them backto-back reduces the data flow time across these instructions, buying back 2.5% of the time on the consumer-side of the fetch. All this is achieved with little to no extra hardware requirements in the existing processor datapath. ARM format for all instructions to optimize the fetch stage for all instructions. We show that while this can provide 6% improvement, our approach of identifying, hoisting and grouping CritIC sequences, and selectively using the format for such instruction sequences, does much better (12.65%).</p><p>In fact, using our solution, and then opportunistically using the 16-bit format for other instructions, complement each other to provide 16% improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CRITIQUING CRITICALITY</head><p>Within the confines of the given resources of a superscalar processor, one of the most important issues is deploying and assigning these resources to the incoming stream of instructions. This is essentially determined by the priority order (scheduling) for fetching and executing these instructions. When there are adequate resources, we would give all instructions the resources that they need. However, when resources are constrained, priority has to be given to "critical instructions" <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref>. In this work, we use a simple definition of criticality, similar to those in some prior works <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b25">[26]</ref> -an instruction is critical if its execution time becomes visible (i.e., does not get hidden) in the overall app execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Conventional criticality identification</head><p>As per the above definition, an instruction can be marked critical, only after its execution -by which time it is too late to assign resources for it. Hence, prior works propose different ways of estimating criticality of an instruction before it is even fetched. Two common heuristics for marking an instruction as critical are by using thresholds for (i) execution latency of an instruction (a long latency instruction implies instructions depending on it have to be delayed, thus making it more critical) <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b25">[26]</ref> and (ii) number of dependent instructions (referred to as fanout in this paper), particularly in the ROB at the time the instruction is being executed (as many instructions require its output before they can begin). A table is maintained for those instructions exceeding the threshold based on prior execution (similar to branch predictors), and upon an instruction fetch, this table is looked up with the PC to find whether that instruction is critical or not. B. Do these criticality schemes work for mobile apps?</p><p>Different optimizations can be employed upon fetching a critical instruction -prioritizing CPU resources <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref>, caches <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b17">[18]</ref>, memory requests <ref type="bibr" target="#b10">[11]</ref>, predicting instruction results <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b30">[31]</ref>, issuing prefetches <ref type="bibr" target="#b17">[18]</ref>, etc. Until now, these optimizations have been primarily proposed and evaluated for server/desktop workloads and not for mobile apps/platforms. Without loss in generality, we have taken two representative, wellstudied and well-proven criticality optimizations in prioritizing two important resources -one for memory which issues prefetches for critical loads <ref type="bibr" target="#b17">[18]</ref> and another for ALU resources in instruction scheduling <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. These proposals identify high-fanout loads to mark them as critical to issue prefetch <ref type="bibr" target="#b17">[18]</ref> and prioritize the critical instructions for ALU resource allocations <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. These techniques have shown significant benefits for server workloads. The highfanout based optimization has also been shown to outperform the latency based ways of identifying and exploiting criticality <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b33">[34]</ref>. We next evaluate the usefulness of both these criticality optimizations (depicted as bars) in mobile apps and compare the mean speedup obtained from employing both these techniques for SPEC.int, SPEC.float and Android apps in Fig. <ref type="figure">1a</ref> (experimental details are in Sec. IV-B).</p><p>As can be seen, the performance gains from prefetching high-fanout loads and prioritizing them at ALU resource scheduling are both quite significant for SPEC.int (15% from prefetching, 9% from prioritizing) and SPEC.float (34% from prefetching, 25% from prioritizing), re-affirming prior results <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Interestingly, the gains from these two optimizations are a relatively measly 0.7% from prefetching and 5% from prioritizing in the mobile apps. Based on this, one may think that perhaps mobile apps do not have a significant number of high fanout loads/ALU instructions to benefit from these optimizations. On the contrary, we observe that (in right y-axis of Fig. <ref type="figure">1a</ref>) the mobile apps have a much higher percentage of critical instructions than their SPEC counterparts. This should have, in turn, resulted in more opportunities for optimizing the execution. To understand why this is not the case, we next identify scenarios where these optimizations may not work and point out that such scenarios are common in mobile apps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Why do they not work?</head><p>Fig. <ref type="figure" target="#fig_1">2a</ref> shows an example DFG (Directed Flow Graph) where, executing the first instruction I0, triggers ten following instructions (I1 to I10) to become ready for execution. Any high fanout optimization will obviously execute I0 first. After this step, let us say I10 again has a fanout of 10 (i.e., instructions I11 to I20 become ready), which would cause I10 to be prioritized in the execution over say I1. If, subsequently, I11 and I12 each have 2 fanouts and each of I13 to I20 has a fanout of just 1, I11 and I12 will get scheduled before I13 to I20. But since each of I13 to I20 instructions has a fanout of 1, a highfanout instruction prioritization will not differentiate between them. Note that, I20 in turn has a dependent high fanout instruction, I22, that cannot be scheduled till I20 is completed. So, as seen in Fig. <ref type="figure" target="#fig_1">2b</ref>, by not doing this optimization of prioritizing I20 over its siblings, single a instruction criticality optimization scheme as described previously, stalls 2 cycles <ref type="bibr" target="#b11">(12,</ref><ref type="bibr" target="#b12">13)</ref> in the execution. This scenario occurs commonly in mobile executions (explained below), where an instruction despite having a low fanout, requires high-priority since there is a subsequently dependent high-fanout instruction. Consequently, it is insufficient to optimize individual high-fanout instructions independently. Instead, the whole sequence of dependent instructions from I0, I10, I20 to I22 should be scheduled as early as possible, even though I20 is a low-fanout instruction. We find evidence of this scenario occurring much more in mobile apps compared to their SPEC counterparts as shown in Fig. <ref type="figure">1b</ref>, which breaks down the dependence chains containing high-fanout instructions in terms of the number of low-fanout instructions between two successive high fanout instructions in a dependence chain. We find that the dependence chains can have between 1(22%) to 5(7%) low-fanout instructions in the dependence chain between two high fanout critical instructions, for cumulatively 52% of the time in Android apps. On the other hand, the SPEC.float and SPEC.int apps have no dependent high-fanout instructions for around 60% and 35% of the time. Compare that to Android apps, where this hardly ever happens, i.e., there is at least 1 low fanout instruction between 2 successive high fanout, and thereby critical ones. It is no surprise that SPEC apps benefited from optimizing each critical instruction individually as opposed to Android ones, where such dependent chains reduce the effectiveness of individual optimizations. These mobile app results also suggest that: (a)prioritizing/optimizing each critical instruction individually as it comes (i.e., for the "present") would not be as effective in rightfully apportioning the given resources; and (b)we need to consider these temporally proximate and dependent critical instructions (chains/sequences) together for possible optimizations, i.e., look into the future as well. Traditional criticality based optimizations <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b17">[18]</ref> have targeted one critical instruction at a time, rather than groups or chains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. What do these instructions need?</head><p>Before optimizing for these closely occurring and dependent critical instructions in Android apps, it is important to understand where they spend their time amongst the different superscalar pipeline stages. Towards this, we present a breakdown of their execution profiles amongst these stages in Fig. <ref type="figure" target="#fig_2">3(a)</ref>. In the same graph, we provide a similar profile for critical instructions identified by the same "high fanout" metric in the SPEC.float and SPEC.int apps. From these results, we observe the following: (i) unlike SPEC apps, where the Execute stage, and consequently the back-pressure in ROB queue residencies, are quite dominant, the Android apps have a much lower Execution stage latency (and consequently the ROB residency). The mix of critical instructions in Android apps do not take as much execution time (fewer long latency instructions compared to their SPEC counterparts as shown in Fig. <ref type="figure" target="#fig_2">3(c)</ref>). (ii) However, the fetch stage, and the decode stage to some extent, are much more dominant in Android apps, compared to the SPEC ones (due to the drop in contribution from the Execute stage). As much as 40% of the time goes in the Fetch stage, while similar critical instructions in SPEC spend less than 5% of their time in this stage. This shift in the profile from the rear to the front Fetch stage (consumes 40%) of the pipeline in Android, warrants us to take a closer look into this stage. Fig. <ref type="figure" target="#fig_2">3(b</ref>) breaks down the Fetch execution time in these apps into two parts -F.StallForI, which is responsible for supplying the instruction stream into this stage, and the F.StallForR+D which pulls out the instruction from this stage for subsequent decoding. The former depends on the I-cache latency, miss costs, and branch misprediction costs, while the latter is largely determined by the back-pressure exerted by the subsequent pipeline stages (i.e., wait for decode to commit time for the prior instructions).</p><p>The relative contributions of the F.StallForI and F.StallForR+D (2:3) to the overall Fetch side overheads are quite comparable across the SPEC and Android apps. However, the actual values are quite different. While F.StallForI contributes to 3% of the overall execution in SPEC, Android apps execute from a much larger code base with a diverse set of libraries (&gt;7k APIs <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref>) with more frequent function calls, which causes i-cache stalls for 15% of the execution and branch prediction stalls for another 2% from the F.StallForI. At F.StallForR+D, SPEC apps execute many high-latency instructions that creates a back-pressure on the fetch stage by 3.6% (out of the 5.4% in SPEC.float) and 13% (out of 21% in SPEC.int). In Android apps, as shown in Fig. <ref type="figure" target="#fig_2">3(c</ref>), majority of the high-fanout instructions are lowlatency instructions, not imposing much back-pressure from the execute stage itself (6% out of 40%). Instead, the dependence resolutions between various instructions (as discussed in Fig. <ref type="figure">1b</ref>) causes the most stall (11%) for the F.StallForR+D in these apps. Thus, any optimization for these critical instructions should try to reduce both F.StallForI and F.StallForR+D latencies, i.e., a simple i-cache/branchprediction optimization, or a back-end optimization alone may not suffice as we will show later on.</p><p>Key Insights on Android Apps: (a) With high fanout, and thereby "critical" instructions occurring in close temporal proximity with one or more non-critical/low-fanout instructions in the dependence chain between them, we should consider optimizing groups/sequences of these instructions concurrently, rather than one at a time; (b) Fetch stage is much more important for these instructions, and optimizations for this stage are likely to yield more rewards than throwing more hardware for the conventionally bottlenecked execute-to-commit stages; (c) We need to accelerate not just the rate of bringing in the instructions to the Fetch stage, but also accelerate the rate of pushing out instructions into the rest of the pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CRITICS: CRITICAL INSTRUCTION CHAINS</head><p>Having identified the requirements, we now explore (i) how to identify these "critical" instructions occurring in a dependence chain/sequence in close temporal proximity, and (ii) how to optimize for these sequences to provide the minimal F.StallForI and F.StallForR+D latencies in the fetch stage with minimal hardware extensions.</p><p>A. Identifying CritICs 1) CritIC Sequences: As was shown in the example in Fig. <ref type="figure" target="#fig_1">2a</ref>, identifying and optimizing for individual high fanout, and thereby critical, instructions can only provide limited options. Instead, we need to look into the future, and find other possible future critical instructions which are in its forward dependence chain/graph. Consequently, the entire chain should be prioritized/optimized even if intermediate instructions in the forward dependence chain (such as I20 in the forward dependence chain of I10, I20, I22 ) may not traditionally have been marked as critical because of their low fan-outs. Towards identifying such "Critical Instruction Chains (CritIC)", we first introduce the following metric and definitions.</p><p>Instruction Chain (IC): An instruction chain is any acyclic path of a Data Flow Graph (DFG) that is independently schedulable at that instant in the execution. In our previous example DFG of Fig. <ref type="figure" target="#fig_1">2a:</ref> ? The paths I0, I10, I20, I22 and I0, I10, I11 are independent of the other paths in the DFG. So, they are independently schedulable, and both qualify as ICs. ? The path I0, I1, I21 does not qualify as an IC as it depends on another path, I0, I10, I11, I21 and is thus not independently schedulable. ? Still, the sub-path I0, I1 qualifies as an IC as it does not depend on any other paths of this DFG, i.e., any sub-path of an IC is also an IC.</p><p>An IC is thus a self-contained sequence of instructions, and is executable as an atomic entity (e.g., a macro instruction <ref type="bibr" target="#b37">[38]</ref>- <ref type="bibr" target="#b43">[44]</ref> consisting of several micro-instructions in the sequence) without any dependencies into its individual instructions. We will exploit this property later when optimizing critical ICs.</p><p>Crit: At any instant, a DFG has several individual ICs. The goal is then to find the right order for executing these ICs -to prioritize based on their relative criticalities. For example, in Fig. <ref type="figure">4b</ref>, the execution at the top (high-fanout optimization) shows that prioritizing an IC with low-fanout instructions, I1, I6, I7, I8, I9, I10, I11, I12 is inefficientas observed in cycles 10, 11, the execution becomes serialized and there is no ILP for 2 cycles. However, identifying the relative criticalities of ICs is non-trivial, since each instruction in an IC can have a different fan-out/criticality. Simply adding up the fan-out of all its constituent instructions may not paint an accurate measure of an IC's criticality since there could be high variance amongst its instructions -a cumulatively high-fanout IC may have a very high fanout instruction at the beginning, with all subsequent instructions ending up with very low fanout, or vice-versa. While one could consider higher order representations for capturing such variances in future work, in this paper, we use a simple average fanout per instruction of an IC to capture the criticality of an IC. ICs whose average fanout per instruction exceed a certain threshold (e.g. 8) are marked as CritIC sequences in this work. Fig. <ref type="figure">4</ref> gives an example DFG, where a conventional instruction-level fanout based prioritization would give an execution as in the top part of (b) taking 14 cycles on a 2-way issue superscalar processor, while our CritIC approach would identify two ICs I1, I6, I7, I8, I9, I10, I11, I12 and I0, I5, I18 and prioritize the latter over the former because of its higher average fanout per instruction (4 vs. 2). This results in a schedule as in the lower part of (b), taking only 13 cycles.</p><p>2) How to find them?: There are two broad strategies for identifying CritICs: (a) using hardware predictor tables as used in many prior works <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b23">[24]</ref> and/or (b) using software profile-driven compilation. As explained, we would like to minimize hardware requirements as much as possible, especially since mobile devices can become highly resource constrained. So we opt for the latter approach, which raises additional issues that we address as discussed below:</p><p>? Ability to do this without User Intervention: Unlike desktop environments where users may write their own apps, many of the mobile apps are published a priori (on the Play store, iTunes, etc.). It is not unreasonable for many of these popular apps to have undergone a profile-driven compiler optimization phase, which many of them already do (for quality, revisions, performance, bugs, etc. <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>) before they get published. Our solution can be integrated into such phases for appropriate code generation. ? Dealing with diverse inputs (user-interactivity): Even if apps are available a priori, their execution can depend a lot on the input data -this is especially true for mobile apps which have high user interactivity. Conveniently, common cases of user inputs are readily provided for many of these apps in standard formats <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, that we avail for our approach. ? Ability to track long ICs and their spread: Software based approaches are often criticized because of their restricted scope in analyzing large segments of code concurrently. This would pose a problem if the ICs were long and spread out considerably in the dynamic instruction stream. For instance, if we were to apply our approach for SPEC apps, Fig. <ref type="figure">5a</ref> shows that we would need to track ICs of lengths up to 1.3K, which are spread over up to 6.3K instructions in the dynamic stream. On the other hand, in our favor, ICs for the mobile apps (as shown in the Fig. <ref type="figure">5a</ref>), are at the maximum 20 instructions long, and are at most spread over 540 instructions to make them conducive to our approach. automatically identify and optimize the CritIC sequences in a large number of Android apps. The app execution is profiled using AOSP emulation <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b48">[49]</ref> and GEM5 hardware simulator <ref type="bibr" target="#b22">[23]</ref> to get the instruction stream from which we identify the CritIC sequences. The on-device Android Runtime Compiler (ART compiler) then generates optimized ARM binary using various compiler optimization passes <ref type="bibr" target="#b49">[50]</ref>. After these passes, we have implemented an additional instrumentation pass in the compiler which visits every CritIC in the optimized DFG generated, to generate the optimization that is discussed next.</p><formula xml:id="formula_0">?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimizing CritIC Sequences</head><p>Our solution to optimizing these sequences is motivated by the two important observations: (i) CritIC sequence instructions spend nearly 40% of their execution in their fetch stage, with both F.StallForI and F.StallForR+D contributions becoming equally important; and (ii) Each CritIC sequence's instructions are "self-contained" and can execute in sequence without being influenced by any other sequence. Ideally, each CritIC sequence could, thus, be made a macro-instruction whose functionality is equivalent to executing each of its constituent instructions one after another. If our compiler could replace this entire sequence by the corresponding macro-instruction, we would avoid individual fetches for each of the constituents, and incur only 1 fetch operation -this would reduce the F.StallForI contribution. Further, by hoisting up this entire dependent chain of critical instructions into a single macro-instruction, we have reduced/eliminated any unnecessary gap between them, thus shortening the data flow from one to the other -this would reduce the F.StallForR+D contribution waiting for the later stages of the pipeline to flush out.</p><p>Creating Macro-Instructions: One obvious choice for implementing such macro-instructions is by extending the ISA with either (i) multiple mnemonics -one for each CritIC sequence, or (ii) having a new mnemonic with a passed argument that indexes a structure to find the CritIC sequence. In either case, the new macro-instruction has to know the exact sequence of micro-instructions that it needs to execute. This may be a reasonable option if the CritIC sequences are somewhat limited, i.e., there are a few common sequences which are widely prevalent across several apps as was the case in solutions such as <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref>. However, Fig. <ref type="figure">5b</ref> shows that the number of unique CritIC sequences (opcode+operands of all constituent instructions) is large -even Exploiting ARM ISA: Instead, we need a mechanism for dynamically creating/mimic-ing such macro instructions based on the CritICs at hand, and we propose a novel way of achieving this in the ARM ISA. Fig. <ref type="figure">6</ref>(a) shows the contemporary ARM ISA format <ref type="bibr" target="#b51">[52]</ref> that uses 32 bits to represent an instruction -containing 12 to 20 bits for opcodes, 12 bits for representing 2 source and 1 destination operand registers. It also supports a concise format using 16-bits called "Thumb extension" (Fig. <ref type="figure">6(b)</ref>). In this mode, the opcode is represented in 6 bits while the operands are represented in 3-4 bits each. The 16 bit format <ref type="bibr" target="#b51">[52]</ref> is used in embedded controllers for optimizing binary size. The existing ARM decoders can decode any of these formats based on simple flags and pending queue structures <ref type="bibr" target="#b50">[51]</ref>.</p><p>We propose to represent each instruction of a CritIC sequence, that we would like to optimize, in the 16-bit format (Fig. <ref type="figure">6(d)</ref>). Even though past studies <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b54">[55]</ref> report that the 16-bit format produces ? 1.6? more instructions to execute (and causes slowdown) because (i) it cannot have predicated executions, and (ii) it cuts the number of architected registers as operands from 16 to 11, we point out that the 16-bit format is very amenable for CritIC instructions<ref type="foot" target="#foot_1">1</ref> . We illustrate this by plotting the CDF of coverage of the dynamic instruction stream by the instructions in all identified CritIC sequences of the original code (in 32 bit format) in Fig. <ref type="figure">5b</ref>. In the same figure, we also plot the CDF of coverage by the CritIC instructions that can be represented in the 16-bit format without any change, i.e., they have neither predications nor use more than the allowed 11 registers. As we can see, there are very few CritIC instructions that cannot be represented (4.5% of the unique CritIC sequences), referred to as CritIC.Ideal in Sec. IV-E, which demonstrates the promise of our proposal.</p><p>Additionally, the ARM Decoder has to be informed of the instruction format, to switch back-and-forth between 32 and 16 bit representations. There are two possible ways to inform the decoder of the format switch: (i) in the current ARM hardware, this is done using explicit Branch instructions <ref type="bibr" target="#b51">[52]</ref>. But, as we will show in Sec. IV-A, this incurs additional overheads especially for relatively short (&lt; 10) CritIC instruction sequences; and (ii) our proposed alternative to extend an already existing instruction mnemonic to support CritIC thumb format switch in the decoder hardware (evaluated in Sec. IV-B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Summarizing our Methodology</head><p>Fig. <ref type="figure" target="#fig_5">7</ref> summarizes the software framework for performing and implementing the CritIC optimizations:</p><p>? Trace Collection: We run the Android apps in QEMU <ref type="bibr" target="#b21">[22]</ref> emulator with Android OS, where all the hardware components (CPU, GPU, touch, GPS, network, accelerometer, gyro, display, speakers, etc.) are modeled. We instrument its disassembler (with 1.6k lines of code or LOC) to output the trace of instructions executed and data accessed by the isolated process (app in consideration), for offline profiling. ? Identifying CritICs: This trace is used for detailed microarchitectural simulation in Gem5 <ref type="bibr" target="#b22">[23]</ref>, with modifications to identify critical instructions based on their fanouts across ROB entries (3.3k LOC). To get CritICs from the critical instructions, we implement additional tracking logic to dump all the independently schedulable ICs (whose lengths vary as discussed in Fig. <ref type="figure">5</ref>) which results in 100s of GBs of ICs. These are processed offline with a distributed hash-table using Spark PairRDD <ref type="bibr" target="#b55">[56]</ref> to sort and get the top CritICs (ICs with average fanout threshold &gt; 8) with the most coverage (3.8k LOC). We fix 8 as the most beneficial average fanout threshold and also observe that other values result in slight performance degradations. The resulting CritICs is relatively concise (?10KB) to account for ?30% of dynamic coverage. ? Compilation: Next, we modify the open-source ART compiler to add a final pass (CritIC instrumentation pass) that applies CritIC optimizations on the apk binary (.oat generation). Note that, the ART compiler already comes with different optimization passes such as constant folding, dead code elimination, etc., which work on DEX intermediate representation, as well as load store elimination, register allocation, etc., which work on the destination ARM assembly code before binary generation. Our CritIC pass works on ARM assembly code (similar to instruction simplifier pass) to take each CritIC (from the profile), checks whether each of its instructions are convertible into a 16-bit Thumb format, and if so, it lays down the entire CritIC sequence instructions one after another in this 16-bit format with appropriate two approaches explained next for switching the instruction format (1.8k LOC). Note that, other than hoisting and Thumbconverting the CritICs encountered, this pass does not affect the existing instruction scheduling. ? Off the Shelf Apps: Our framework can be readily applied to any off-the-shelf app (apk file) from the PlayStore <ref type="bibr" target="#b56">[57]</ref>.</p><p>Table <ref type="table" target="#tab_6">II</ref> shows the ten mobile apps we use for evaluations. These apps belong to a diverse set of domains ranging from texting to gaming and video/audio streaming. These apps are also top rated and have millions of downloads in PlayStore. ? Net Benefits: We have roughly doubled the instruction fetch rate (halving F.StallForI) of the critical instruction sequences by switching formats, and reduced the F.StallForR+D delays by making this self-contained dependent chain contiguous in time. We will also demonstrate that our proposed solution has very little hardware overhead to interpret the format switch. In fact, our first approach can be readily done on current hardware, albeit with some inefficiencies as shown next. The second approach uses an existing mnemonic to switch format, which is a very small extension to the switch supported in existing ARM decoders.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EVALUATIONS A. Switching Approach 1: On Actual Hardware</head><p>We use the conventional approach present in ARM decoders for switching between the two instruction formats, where two unconditional branch instructions are added at the beginning and end of each CritIC instruction sequence. The purpose of these branch instructions is to inform the decoder of the impending format switch and so both their target branch addresses are statically encoded to point to the subsequent instruction. As shown in Fig. <ref type="figure">6</ref>, (i) the branch before the CritIC sequence, is in 32 bit format (that sets the Thumb flag at decode), and jumps to the first instruction of the CritIC; (ii) the subsequent 5 CritIC instructions are decoded in 16 bit Thumb format at the decoder; (iii) the branch after the CritIC sequence is also in 16 bit format, with its target set to the next instruction after the CritIC, that resets the format flag to 32-bit at the decoder. Note that the costs of these branches would mandate long CritIC sequences in order to amortize them.</p><p>We have implemented this on a Google Tablet hardware having 4 ARM cores and 2 GB LPDDR3 memory. Fig. <ref type="figure" target="#fig_7">8</ref> shows the gains on this hardware from our CritIC optimization for all 10 apps. Along with the actual speedup gains (of a measly 3% on the average), we also show the lost potential which we could have got if there were no branches before and after the CritICs for the format switches. We are getting only 1  5 th of the possible gains since the CritIC sequences are not long enough (typically of length 5) to amortize the branch overheads. Motivated by this, we next propose an alternative, which does a very slight enhancement to the hardware, to address this problem to win back those gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Switching Approach 2: Extending Existing ARM Instruction</head><p>To avoid the aforementioned overheads, we propose to use an already existing instruction mnemonic, CDP (Co-processor CPU 4 wide Fetch/Decode/Rename/ROB/Issue/Execute/Commit superscalar pipeline; 128 ROB entries, 4k Entry 2 level BPU <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b58">[59]</ref> Memory2-way 32KB i-cache, 64KB d-cache, 2 cycle hit latency; 8-way 2MB L2 with System CLPT prefetcher (1024?7bits entries) <ref type="bibr" target="#b17">[18]</ref>   Data Processing call), and the 3-bit argument with it to denote that the next l + 1 instructions would be 16-bit format to inform the decoder accordingly. Fig. <ref type="figure" target="#fig_6">9</ref> illustrates this translation by our compiler pass for a CritIC sequence. In the first 32-bit word, the first half contains the CDP command, together with the l argument (Fig. <ref type="figure">6(d)</ref>). The second half of this word contains the first instruction of the CritIC sequence in 16-bit format. The next l/2 32-bit words contain the next l instructions of the CritIC sequence in 16-bit format. Upon encountering the CDP command, the decoder puts the subsequent l + 1 (1 coming in the latter half of the CDP word itself, and the other l coming from the remaining l/2 words) CritIC instructions for 16-bit decoding. With the CDP argument having 3 bits, this allows us to translate up to 1 + 2 3 = 9 CritIC instructions into the 16-bit format using a single CDP command. Note that we can also allow longer sequences by simply issuing more CDP commands subsequently, though we find that CritIC sequences up to 5 instructions suffice to provide the bulk of the savings (detailed in Sec. IV-H). After the last 16-bit instruction of this sequence passes through, the subsequent words get switched to the 32-bit decoding format. We also implemented and laid out the logic for the mode switch on CDP call on Synopsys Design Compiler(H-2013.03-SP5-2) <ref type="bibr" target="#b57">[58]</ref> with 45 nm technology library and find that the extra logic only consumes 80?m 2 area, dynamic and leakage power consumptions as 58?W and 414nW respectively. Although the timing for this logic is only 160ps, we conservatively assume a 1 cycle extra decoding stage delay when processing the CDP command. Even though we have not cut the entire CritIC sequence down to one instruction fetch as in the above "macroinstruction" approach, our compiler-based ARM 16-bit translation roughly doubles the instruction fetch rate (halving F.StallForI) compared to the original alternative. Further, since these instructions are next to each other in the dynamic stream, the dataflow gap is reduced, thereby helping in the F.StallForR+D as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Simulation Results</head><p>We next describe the evaluation platform used for conducting our experiments on different design scenarios and conduct an in-depth evaluation of the proposed CritIC optimizations on performance and energy consumption.</p><p>Hardware: We evaluate the app executions using the hardware configuration of a Google Tablet in GEM5 <ref type="bibr" target="#b22">[23]</ref>. As shown in Table <ref type="table" target="#tab_5">I</ref>, this hardware consists of 4 CPUs, each with a 4-issue wide superscalar core, 32KB i-cache and a 64KB d-cache <ref type="bibr" target="#b59">[60]</ref>. Further, we also simulate a detailed memory model for a 2GB LPDDR3 using DRAMSim2 <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>. This setup enables us to execute apps in a cycle-level hardware simulation and obtain performance and power consumption for CPU, caches, and memory of the SoC. App Execution: During the profiling phase (Sec. III-A2), these apps are emulated for an average of five minutes and execute, on average, around 100M instructions. This translates to ?90 seconds of app execution time without the emulator overheads. For our evaluations, we pick 100 samples at random, each containing ?500k contiguous instructions of app executions tallying to a total of ?50 million instructions (same parts for all the optimizations evaluated).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Design Space</head><p>To quantify the performance effects of the proposed CritIC design on mobile apps, we evaluate three design choices, and compare them to the baseline configuration in Table <ref type="table" target="#tab_5">I</ref>.</p><p>? Hoist: Since our solution employs two mechanisms -one hoisting all instructions of a CritIC sequence and another replacing them with 16-bit Thumb formats -we would like to study their effectiveness individually. Towards this, we implement a scheme which only does the former (i.e., identifies CritIC sequences, and hoists each sequences' instructions), but leaves them in 32-bit ARM format. We call this as Hoist in our evaluations. ? CritIC: This is our proposed CritIC design that aims to tackle the fetch side bottlenecks for high-fanout instructions as well as the F.StallForR+D bottlenecks by hoisting/aggregating the constituent instructions together and also translating these instructions to 16-bit Thumb format. ? CritIC.Ideal: As was noted earlier in Fig. <ref type="figure">5b</ref>, we choose to leverage only a subset of the total number of CritIC sequences -(i) those that are at most length 5, and (ii) those whose instructions can be translated directly to the 16-bit Thumb format. In order to find out the lost opportunity, we also evaluate a scheme called CritIC.Ideal which hypothetically aggregates and Thumb-translates for all CritIC instructions (i.e., the black CDF of Fig. <ref type="figure">5b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Performance Results</head><p>Fig. <ref type="figure">10a</ref> plots the CPU execution speedup of each app for the three scenarios discussed above to study the individual as well as combined effects of the two components of CritIC optimizations. We discuss app level speedups of each of these optimizations normalized with respect to the baseline design.</p><p>When we consider the individual optimizations evaluated in Fig. <ref type="figure">10a</ref>, we see that the CritIC optimizations consistently perform well in all apps with 9% (Music) to 15% (Acrobat) speedup. However, Hoist (which only targets StallforRD) by itself, only gives marginal improvements (average gain of 2.5%) compared to CritIC which combines both F.StallForI and F.StallForR+D optimizations, suggesting that just moving instructions does not suffice. Since this scheme only reduces the dataflow gap across critical instructions, without boosting the fetch efficiency, the impact of just a F.StallForR+D optimization is not felt across these apps, reiterating the need for fetch side improvements. Of the apps, Maps and Youtube are more bottlenecked in the F.StallForR+D (26.7% in Youtube in baseline of Fig. <ref type="figure">10b</ref>) and this in turn translates to the most benefits when it comes to optimizations for F.StallForR+D (3.1%). All the other apps have even less improvements from hoisting the CritIC instructions, with Browser and Photogallery showing the least benefits of 1.7%. CritIC, which implements both 16-bit conversions to boost the fetch bandwidth, as well as the Hoist improvements, gives 12.6% speedup improvements on the average. In fact, we see that the differences between CritIC and CritIC.Ideal, to be quite small (e.g. only 1% gap in Acrobat, Browser and Office). Limiting ourselves to CritIC lengths of 5 or to those that can be directly translated to 16-bit Thumb format, does not seem to hurt. This is because, a majority of CritIC instructions are amenable to 16-bit Thumb representation, leaving &lt;1% room for any further improvement on the average. As discussed in Sec. III, the volume of CritIC instructions representable with the 16-bit format is within 5% of the entire CritIC instruction volume. We note that the average 12.6% speedup with CritIC significantly outperforms the previously proposed single instruction criticality optimizations -load prefetching and ALU prioritization -for which we showed speedups of 0.7% and 4.1% respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. System-Wide Energy Gains</head><p>The effect of our CritIC optimizations in terms of the energy gains from various components of the mobile SoC is plotted in Fig. <ref type="figure">10c</ref>. Recall that CritIC optimizations decrease the number of accesses to the i-cache by 40% (Fig. <ref type="figure">6</ref>) for each IC execution by representing 5 ? 32-bit instructions as 3 ? 32-bit instructions. This translates to energy gains from i-cache by 0.8% for the whole SoC. The CPU speedup discussed above also results in additional energy gains for both CPU and memory. On an average, CPU contributes to 2.2% of the energy savings and the memory side of the execution contributes an additional 1.5%. Overall, we observe 4.6% energy saving for the whole system on the average, with the maximum energy savings of 6.3% (in Photogallery). Specifically, the CPU execution alone (excluding peripherals, ASIC accelerators, etc.) realizes an average energy saving of 15%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Comparing with Conventional Hardware Fetch Optimizations</head><p>One may note that numerous prior hardware enhancements proposed to address the Fetch stage problems, including larger and more intelligently managed i-caches <ref type="bibr" target="#b62">[63]</ref>- <ref type="bibr" target="#b64">[65]</ref>, better branch predictors <ref type="bibr" target="#b65">[66]</ref>- <ref type="bibr" target="#b68">[69]</ref>, and/or instruction prefetchers <ref type="bibr" target="#b69">[70]</ref>- <ref type="bibr" target="#b73">[74]</ref>. While adding sophisticated hardware for high end CPUs may be acceptable, the resource constraints of mobile platforms may not warrant such sophisticated hardware. Still, we have implemented a number of hardware solutions for addressing the Fetch bottleneck (described below), and compared them to the speedup obtained with our software-only solution -CritIC: ? 2?FD: Since CritIC uses a 16-bit format to put 2 instructions into each fetched word (selectively doubling fetch bandwidth for critical instructions), we consider a hypothetical hardware where the Fetch and Decode stage bandwidths are doubled (for all instructions -not just critical ones), with no change to other stages. In this scheme (2?FD), we simulate a hardware with half the i-cache latency and double the resources (hardware units/queues) in the fetch and decode stages. ? 4?i-cache: Though unreasonable, we compare with a hardware that has 4? the i-cache capacity (128KB vs. 32KB) to reduce instruction misses. ? EFetch <ref type="bibr" target="#b70">[71]</ref>: We implemented a recently proposed instruction prefetcher <ref type="bibr" target="#b70">[71]</ref> that is specifically useful for user-event driven applications, as in our mobile apps. This prefetcher <ref type="bibr" target="#b70">[71]</ref> tracks history of user-event call stack, and uses it to predict the next functions and prefetch its instructions. It needs a 39KB lookup table for maintaining the call stacks. ? PerfectBr: This is a hypothetical system where we assume there is no branch misprediction in the entire execution. Since CritIC addresses both (i) F.StallForI which the above 3 address; and (ii) F.StallForR+D, which is somewhat addressed by prior criticality optimizations such as <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b74">[75]</ref>- <ref type="bibr" target="#b76">[77]</ref>, which prioritize the backend resources for those instructions, we additionally consider the following configurations:</p><p>? BackendPrio <ref type="bibr" target="#b32">[33]</ref>: This platform implements the prioritization hardware for the back-end resources proposed in <ref type="bibr" target="#b32">[33]</ref>, using the tracking hardware proposed in <ref type="bibr" target="#b31">[32]</ref>, which requires 1.5KB SRAM for maintaining the tokens. ? AllHW: This consists of hardwares for both front and backends, i.e., 4?i-cache+EFetch+PerfectBr+BackendPrio.</p><p>? With CritIC: In addition to comparing with vanilla CritIC, which has no additional hardware needs, we also study CritIC in combinations with every above hardware mechanisms. Results: We observe in Fig. <ref type="figure" target="#fig_9">11a</ref> that previously proposed hardware mechanisms yield ?4% to 12% speedup. However, it is important to optimize for both F.StallForI and F.StallForR+D. These hardware mechanisms only benefit one of these two stalls (Fig. <ref type="figure" target="#fig_9">11b</ref>). For example, 2?FD, 4? larger i-cache and EFetch lower miss penalties to reduce the F.StallForI by ?7%, while PerfectBr completely eliminates branch penalties to reduce fetch stalls by 12%. These mechanisms have no effect on F.StallForR+D. Similarly, BackendPrio only addresses the F.StallForR+D problem, reducing it by 3% and does not tackle the F.StallForI.</p><p>While one could throw all this hardware to tackle both these stalls, as in AllHW, to get the overall speedup benefits of 23.2%, such extensive hardware may be unacceptable for a mobile platform. CritIC, by itself, which does need any additional hardware, does significantly better than each of these individual hardware mechanisms. If future mobile platforms are to incorporate one or more of these F.StallForI and F.StallForR+D hardware mechanisms, our results in Fig. <ref type="figure" target="#fig_9">11a</ref> show that CritIC can synergistically boost the benefits further. In fact, even with a system that incorporates all of the above hardware (AllHW) which gives a speedup of 23.2%, can be boosted to give a speedup of 31% with CritIC on top.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Sensitivity to CritIC length</head><p>The speedup and energy gains reported above are for a small CritIC size of 5 instructions. We next investigate the impact of CritIC length on application performance.</p><p>Even though CritIC.Ideal showed not much difference compared to the realistic CritIC (which uses lengths of up to 5 instructions), it is interesting to see which CritIC length gives the most rewards individually, i.e., not just all CritICs up to length n, but for each individual n. Note that as n increases, we are saving more on the fetch costs -both F.StallForI and F.StallForR+D latencies. However, the probability of finding a CritIC of exactly length n, where all its n instructions can be directly translated to the 16-bit Thumb format, decreases as n increases. To study these trade-offs, in Fig. <ref type="figure" target="#fig_10">12a</ref> we study the impact of a given n (x-axis) on the fetch cost savings (right y-axis) and the consequent speedup (left y-axis). As expected, fetch costs keep dropping with larger n, though with diminishing returns. The speedup increases up to a point (n = 5), beyond which it starts dropping since the probability of finding such sequences diminishes. In fact, we observe a drop in coverage of CritICs executed from 16% to 15% as we move for a longer CritIC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Sensitivity to Profiling</head><p>Since our technique uses offline profiling to identify and modify critical chains, we also study the sensitivity of results to the extent of profiling, i.e. the percentage of the app execution that is profiled. Fig. <ref type="figure" target="#fig_10">12b</ref> shows the speedup (y-axis) as a function of the percentage of the execution that is profiled (x-axis), averaged across all apps. The results presented so far use profiling that covers 72% of the execution. While a lower coverage does reduce the speedup obtained, we see that even when only a third of the execution is profiled and transformed into CritIC thumb sequences, we still get 10% speedup across these apps. If we further the profiling, and transform the entire application, we can get up to 15% speedup on the average.</p><p>V. WHY EVEN BOTHER WITH CRITICALITY?</p><p>While we have proposed the use of Thumb 16-bit format to nearly double the fetch bandwidth of the CritIC instructions, one may use this approach opportunistically for all instructions amenable to such modification in the instruction stream. If so, one could question why we bothered to identify CritICs in the first place. To justify the need, in Fig. <ref type="figure" target="#fig_11">13a</ref>, we plot the speedup obtained with the following schemes: ? OPP16: In this approach, we opportunistically convert any amenable sequence of consecutive dynamic instructions (sequence has to be of at least length 3) to the 16-bit Thumb format, regardless of whether they are critical or not. Note that if there is an instruction which is not amenable to such format conversion between two other instructions which are amenable, OPP16 will NOT move the instructions around for the conversion. Also, as explained earlier, if the dynamic sequence exceeds 9 contiguous instructions that can be converted, we use another CDP instruction to accommodate longer sequences for such conversion. ? Compress: This is a state-of-the-art thumb compression technique, implementing the Fine-Grained Thumb Conversion heuristic from <ref type="bibr" target="#b77">[78]</ref>, that first converts a whole function to Thumb, then replaces frequently occurring "slower thumb instructions" back to 32 bit ARM instructions. over the baseline. Even smartly employing the Thumb format (Compress), as in <ref type="bibr" target="#b77">[78]</ref>, only yields a 8% speedup. Since both OPP16 and Compress are agnostic to critical instruction chains, they can only save on fetch costs (F.StallForI) whenever possible without hoisting the dependent instructions in the chain. Hence, both these techniques provide less than 40% of the benefits provided by our CritIC optimization, even though as shown in Fig. <ref type="figure" target="#fig_11">13b</ref>, CritIC converts around 37% and 50% fewer instructions in the dynamic stream to the 16-bit format compared to OPP16 and Compress respectively. This clearly points out the need to identify the critical instruction sequences for such optimization, instead of blindly doing this for all instructions. In fact, nothing precludes adding on the optimization for other instructions on top of CritIC, as is shown for OPP16+CritIC schemes, furthering the speedup by 25% over doing CritIC alone. VI. RELATED WORK Criticality: Instruction criticality has been shown to be an important criterion in selectively optimizing the instruction stream. Prior work has revolved around both (i) identifying critical instructions <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref> using metrics such as fanout, tautness, execution latencies, slack, and execution graph representations, as well as (ii) optimizing for those identified using techniques such as critical load optimizations <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b78">[79]</ref> or even backend optimizations for critical instructions such as <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b74">[75]</ref>- <ref type="bibr" target="#b76">[77]</ref>. While one can potentially employ these optimizations for mobile apps, as we showed (in Fig. <ref type="figure">1b</ref>), mobile apps have close data-dependent, clustered occurrences of critical instructions, requiring their ensemble optimization rather than their consideration individually. Optimizing Instruction Chains/Ensembles: There are prior works, specifically for high-end processors, in identifying and extracting dependence chains <ref type="bibr" target="#b79">[80]</ref>- <ref type="bibr" target="#b81">[82]</ref>. However, such techniques require fairly extensive hardware to identify these chains, and optimizing for them, e.g. techniques such as <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b75">[76]</ref>, <ref type="bibr" target="#b76">[77]</ref> require 16KB SRAM, and <ref type="bibr" target="#b78">[79]</ref> incurs 22% additional power, making them less suitable for resource-constrained mobile SoCs. In contrast, our solution is an entirely software approach for identifying dependence chains, and a software approach in optimizing for them by intelligently employing the ARM 16-bit thumb compression <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b50">[51]</ref> mechanism. Front-end Optimizations for Mobile Platforms: There has been significant recent interest to optimize mobile CPU execution <ref type="bibr" target="#b82">[83]</ref>- <ref type="bibr" target="#b88">[89]</ref>. Some of these optimizations target specific domains (e.g. web-browsers <ref type="bibr" target="#b89">[90]</ref>- <ref type="bibr" target="#b92">[93]</ref>), while others address overall efficiency <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b93">[94]</ref>- <ref type="bibr" target="#b95">[96]</ref>. Unlike our approach, many of these optimizations either provision more CPU hardware <ref type="bibr" target="#b89">[90]</ref>, <ref type="bibr" target="#b94">[95]</ref>, <ref type="bibr" target="#b95">[96]</ref>, or optimize for only specific app domains <ref type="bibr" target="#b89">[90]</ref>- <ref type="bibr" target="#b91">[92]</ref>. This paper is amongst the first to show that mobile apps are bottlenecked in the Fetch stage of the pipeline, suggesting that there can be considerable rewards in targeting this stage. Fetch stage bottlenecks have been extensively addressed in high end processors through numerous techniques -smart i-cache management (e.g. <ref type="bibr" target="#b62">[63]</ref>- <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b96">[97]</ref>- <ref type="bibr" target="#b98">[99]</ref>) prefetching (e.g. <ref type="bibr" target="#b69">[70]</ref>- <ref type="bibr" target="#b73">[74]</ref>), branch prediction (e.g <ref type="bibr" target="#b65">[66]</ref>- <ref type="bibr" target="#b68">[69]</ref>), instruction compression <ref type="bibr" target="#b99">[100]</ref> SIMD <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, VLIW <ref type="bibr" target="#b39">[40]</ref>, vector processing <ref type="bibr" target="#b40">[41]</ref>, etc. However, many of these require extensive hardware that mobile platforms may not be conducive for. As we showed, our software solution employs a simple trick of hoisting and Thumb conversion on critical instructions to extract the same performance that many of these high-end hardware mechanisms provide. Further, as mobile processors evolve to incorporate more hardware for optimizing the fetch stage, as shown, our CritIC software approach can synergistically integrate with them to significantly boost the improvements. While similar in spirit to some of the prior work on instruction stream compression <ref type="bibr" target="#b100">[101]</ref>- <ref type="bibr" target="#b102">[103]</ref>, we quantitatively showed the need to identify critical chains and hoisting the instructions selectively before doing the compression. Software Profiling for Mobile Platforms: A number of software profiling frameworks have been proposed <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b103">[104]</ref>- <ref type="bibr" target="#b106">[107]</ref> -studying library usage <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b105">[106]</ref>, app-market level changes to the source/advertisement models, <ref type="bibr" target="#b103">[104]</ref>, <ref type="bibr" target="#b104">[105]</ref>, dynamic instrumentation mechanisms <ref type="bibr" target="#b106">[107]</ref>, developer side debugging/optimizations <ref type="bibr" target="#b107">[108]</ref>, <ref type="bibr" target="#b108">[109]</ref> etc. Some of these tools can also be extended for the profiling and compilation phases described in this work. We have built on top of the AOSP emulation <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b48">[49]</ref> and Gem5 hardware simulator <ref type="bibr" target="#b22">[23]</ref> for profiling, and ART compiler for code transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>This paper targets to enhance the performance a growing class of applications -mobile apps -that are more prevalent and user driven than traditional server/scientific workloads. In this context, we show that mobile apps have unique characteristics such as high volume of critical instructions occurring as short sequences of dependent instructions that makes them less attractive for exploiting well-known criticality-based optimization techniques. We instead introduce the concept of CritICs as a granularity for tracking and exploiting criticality in these apps. We present a novel profiler-driven approach to identify these CritICs, and hoist and aggregate them by exploiting existing ARM ISA's Thumb instruction format in a compiler pass to boost the front-end fetch bandwidth. The end-to-end design starting from application profiling, identification of CritICs, hoisting those instructions and transformation them to the 16bit Thumb format has been evaluated for a Google Tablet using the GEM5 simulator to estimate the performance and energy benefits. Evaluations with ten popular mobile apps indicate that the proposed solution results in an average 12.6% speedup and 4.6% reduction in system-wide energy consumption compared to the baseline design, requiring little to no hardware support. The proposed technique can also be synergistically integrated with other optimizations such as hardware prefetching, or even opportunistically converting as many instructions as possible to the Thumb format, to further the benefits.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1: (a) Despite having frequent Critical Instructions, mobile apps do not benefit as much. (b) Reason: Critical instructions in SPEC do not depend much on other critical instructions. But, Android apps have two successive high-fanout instructions in a dependence chain, with 0(direct-dependence) to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>(a) Example DFG ,??? ? &amp;????? ?? /?????????? K???????????? ???|????????? / /? ????? K???????????? ?K?? ^?????? ? ? ? ? ? ? ? ? ? ?? ?? ?? ?? ?? ?? ?? ?? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?? ?? ? ? ? ? ?? ?? ? ?? ?? ?? ?? ?? ?? ?? ?? ? ??? ? ?? ? ? ? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ? ? ? ? ? ? ? ? ? ?? ?? ?? ?? ?? ?? ?? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ?? ?? ?? ? ? ? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ? ??? ? ? ? ? ? ? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? (b) Timing in superscalar processor with issue width 2 Illustrating why high-fanout prioritization may not help.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: (a) Fetch to Commit breakdown of high-fanout instructions in SPEC vs Android (b) In Android, Fetch is more bottlenecked due to both (i) stalling for instructions to be fetched (F.StallForI), and (ii) stalling for resources and dependencies (F.StallForR+D) to move the instructions down the pipeline. (c) Mobile apps have fewer high latency instructions compared to SPEC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Example DFG ,??? ? &amp;????? ?? K???????????? ???|????????? ???/ K???????????? ?K?? ^?????? ????? ? ? ? ? ? ? ? ? ? ?? ?? ?? ?? ?? E? ? /??? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? /???? ? /? /? /? /? /? /? /?? /?? /?? /? /?? /?? /?? /?? /???? ? /? /? /? /?? /?? /?? /?? /?? /?? /?? /?? ????? ? ? ? ? ? ? ? ? ? ?? ?? ?? ?? E?? /????? ? ? ? ? ? ? ? ? ? ? ? ? ? /???? ? /? /? /?? /? /? /? /?? /?? /?? /?? /?? /?? /?? /???? ? /? /? /? /? /? /?? /?? /?? /?? /?? /?? /?? (b) Timing in superscalar processor with issue width 2 Fig. 4: Example: Need to optimize CritICs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :Fig. 6 :</head><label>56</label><figDesc>Fig. 5: (a)IC length and their corresponding spread in dynamic instruction execution in SPEC vs Android apps; (b)CDF of coverage by unique CritICs.</figDesc><graphic url="image-787.png" coords="5,431.75,598.52,123.19,83.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Proposed Software Framework for our Methodology each app can have 10 6 unique CritIC sequences -making it impossible to extend the ISA for this purpose, or building dedicated hardware for each unique CritIC sequence.Exploiting ARM ISA: Instead, we need a mechanism for dynamically creating/mimic-ing such macro instructions based on the CritICs at hand, and we propose a novel way of achieving this in the ARM ISA. Fig.6(a) shows the contemporary ARM ISA format<ref type="bibr" target="#b51">[52]</ref> that uses 32 bits to represent an instruction -containing 12 to 20 bits for opcodes, 12 bits for representing 2 source and 1 destination operand registers. It also supports a concise format using 16-bits called "Thumb extension" (Fig.6(b)). In this mode, the opcode is represented in 6 bits while the operands are represented in 3-4 bits each. The 16 bit format<ref type="bibr" target="#b51">[52]</ref> is used in embedded controllers for optimizing binary size. The existing ARM decoders can decode any of these formats based on simple flags and pending queue structures<ref type="bibr" target="#b50">[51]</ref>.We propose to represent each instruction of a CritIC sequence, that we would like to optimize, in the 16-bit format (Fig.6(d)). Even though past studies<ref type="bibr" target="#b50">[51]</ref>,<ref type="bibr" target="#b51">[52]</ref>,<ref type="bibr" target="#b54">[55]</ref> report that the 16-bit format produces ? 1.6? more instructions to execute (and causes slowdown) because (i) it cannot have predicated executions, and (ii) it cuts the number of architected registers as operands from 16 to 11, we point out that the 16-bit format is very amenable for CritIC instructions 1 . We illustrate this by plotting the CDF of coverage of the dynamic instruction stream by the instructions in all identified CritIC sequences of the original code (in 32 bit format) in Fig.5b. In the same figure, we also plot the CDF of coverage by the CritIC instructions that can be represented in the 16-bit format without any change, i.e., they have neither predications nor use more than the allowed 11 registers. As we can see, there are very few CritIC instructions that cannot be represented (4.5% of the unique CritIC sequences), referred to as CritIC.Ideal in Sec. IV-E, which demonstrates the promise of our proposal.Additionally, the ARM Decoder has to be informed of the instruction format, to switch back-and-forth between 32 and 16 bit representations. There are two possible ways to inform the decoder of the format switch: (i) in the current ARM hardware, this is done using explicit Branch instructions<ref type="bibr" target="#b51">[52]</ref>. But, as we will show in Sec. IV-A, this incurs additional overheads especially for relatively short (&lt; 10) CritIC instruction sequences; and (ii) our proposed alternative to extend an already existing instruction mnemonic to support CritIC thumb format switch in the decoder hardware (evaluated in Sec. IV-B).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Code Generation after CritICs have been identified. There are 2 CritICs, A and B, in this original instruction sequence.</figDesc><graphic url="image-881.png" coords="7,311.51,77.72,76.51,172.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Optimizing CritICs in existing hardware leaves 11% performance gap with the Ideal scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>: (a)Speedup over baseline; (b) Fetch stage savings of CritIC instructions; (c) Energy gains with CritIC optimization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 :</head><label>11</label><figDesc>Comparison with Hardware Mechanisms (a) Speedup and (b) Impact on F.StallForIand F.StallForR+D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 :</head><label>12</label><figDesc>Sensitivity Analysis: (a) Fetch savings and speedup w.r.t CritIC length; and (b) Speedup w.r.t CritIC Profile Coverage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 :</head><label>13</label><figDesc>Fig. 13: Opportunistically transforming to 16-bit Thumb format. (a) Speedup and (b) Percentage of Dynamic Instructions converted to 16-bit format.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>?</head><label></label><figDesc>While one could increase i-cache capacity, improve branch prediction accuracies, and/or employ instruction prefetchers to address the fetch bottleneck, all these may require extra hardware than what current mobile platforms support because of resource-constraints. Even if future platforms incorporate such additional hardware to address the fetch problem, we show that our simple software technique can do as well as any of these hardware approaches (even a platform that has 4? the i-cache capacity and a perfect branch predictor). Further, it can synergistically provide an additional 11% speedup over what these hardware techniques can provide.? It may appear that one could opportunistically use the16-bit   </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>^?? d???? &amp;??? ??? ???? ???? ??? ???? ????</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>???? ? ?</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>??????????</cell></row><row><cell>?</cell><cell>/??? ? /??? ?</cell><cell>?</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>?</cell><cell>/??? ? /??? ?</cell><cell>?</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>? ? ?</cell><cell>???/ ? /??? ? ???/ ? ???/ ? /??? ? ???/ ?</cell><cell>???/</cell><cell></cell><cell></cell><cell></cell></row><row><cell>?</cell><cell>???/ ? ???/ ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>?</cell><cell>???/ ? ???/ ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>?</cell><cell>/??? ? /??? ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>? ?? ??</cell><cell>/??? ? ???/ ? ???/ ? ???/ ? /??? ? ???/ ?</cell><cell>???/</cell><cell></cell><cell></cell><cell></cell></row><row><cell>??</cell><cell>/??? ? /??? ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>??</cell><cell>???/ ? ???/ ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>??</cell><cell>/??? ? /??? ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>??</cell><cell>???/ ? ???/ ?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>?? ?? ?? ??</cell><cell>???/ ? /??? ? ???/ ? /??? ? ???/ ? /??? ? ???/ ? /??? ?</cell><cell cols="2">???/ ? /??? ? /??? ? /??? ? ???/ ? ???/ ?</cell><cell></cell><cell>?????? ????????? E?? ?????? E?? ?????? ?????????</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>? ?? ???? W??? ?????????? ???/?? ? ^?? ????? ?????? ? ??? ????????? ????? ?? ? ?? d????? Z???? &amp;????</head><label></label><figDesc></figDesc><table><row><cell>?</cell><cell>?? ????</cell><cell>???/?? ?</cell><cell>???/?? ?</cell></row><row><cell>?</cell><cell>?? ????</cell><cell>???/?? ?</cell><cell>???/?? ?</cell></row><row><cell>?</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>?</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>?</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>?? ???? W??? ?????????? ???/?? ? ^?? ????? ?????? ? ??? ????????? ????? ??? ?? d????? Z???? &amp;???? ??</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>?? ????</cell><cell>???/?? ?</cell><cell>???/?? ?</cell></row><row><cell>??</cell><cell>?? ????</cell><cell>???/?? ?</cell><cell>???/?? ?</cell></row><row><cell>??</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>??</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>??</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell>??</cell><cell>?? ????</cell><cell>/??? ?</cell><cell>E????? /???</cell></row><row><cell></cell><cell></cell><cell>???/ ?</cell><cell></cell></row><row><cell></cell><cell></cell><cell>/??? ?</cell><cell></cell></row><row><cell></cell><cell></cell><cell>???/ ?</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>; hit=10 cycles; 1 Ch;2 Ranks/Ch; 8 Banks per rank; open-page; Vdd = 1.2V; tCL,tRP,tRCD = 13, 13, 13 ns</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE I :</head><label>I</label><figDesc>Baseline Simulation configuration.</figDesc><table><row><cell>Domain</cell><cell>App</cell><cell>Activities Performed</cell><cell>Domain</cell></row><row><cell></cell><cell>Acrobat</cell><cell>View, add comment</cell><cell>Document readers</cell></row><row><cell></cell><cell>Angrybirds</cell><cell>1 Level of game</cell><cell>Physics games</cell></row><row><cell></cell><cell>Browser</cell><cell>Search and load pages</cell><cell>Web interfaces</cell></row><row><cell></cell><cell>Facebook</cell><cell>RT-texting</cell><cell>Instant messengers</cell></row><row><cell></cell><cell>Email</cell><cell>Send,receive mail</cell><cell>Email clients</cell></row><row><cell>Mobile</cell><cell>Maps</cell><cell>Search directions</cell><cell>Navigation</cell></row><row><cell></cell><cell>Music</cell><cell>2 minutes song</cell><cell>Music/audio players</cell></row><row><cell></cell><cell>Office</cell><cell>Slide edit, present</cell><cell>Interactive displays</cell></row><row><cell></cell><cell>PhotoGallery</cell><cell>Browse Images</cell><cell>Image browsing</cell></row><row><cell></cell><cell>Youtube</cell><cell>HQ video stream</cell><cell>Video streaming</cell></row><row><cell>SPEC.int</cell><cell cols="3">bzip2, hmmer, libquantum, mcf, gcc, gobmk, sjeng, h264ref</cell></row><row><cell>SPEC.float</cell><cell cols="3">sperand, namd, gromacs, calculix, lbm, milc, dealII, leslie3d</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE II :</head><label>II</label><figDesc>Popular Mobile and SPEC apps used in evaluation.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0"><p>low fanout instructions between them.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>If any instruction of a CritIC sequence cannot be represented in the 16-bit format as is, then the entire sequence is left as is (in the original format) and is not optimized, i.e., all or nothing property (quantified in Fig.5b).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This work has been supported in part by <rs type="funder">NSF</rs> grants <rs type="grantNumber">1439021</rs>, <rs type="grantNumber">1629915</rs>, <rs type="grantNumber">1526750</rs>, <rs type="grantNumber">1629129</rs>, <rs type="grantNumber">1763681</rs>, <rs type="grantNumber">1409095</rs>, <rs type="grantNumber">1317560</rs>, <rs type="grantNumber">1320478</rs>, <rs type="grantNumber">182293</rs>, <rs type="grantNumber">162651</rs> and <rs type="grantNumber">1439057</rs>, and a <rs type="funder">DARPA/SRC</rs> <rs type="grantName">JUMP grant</rs>. We would also like to thank <rs type="person">Jack Sampson</rs> for his feedback on this paper.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5jFugRx">
					<idno type="grant-number">1439021</idno>
				</org>
				<org type="funding" xml:id="_8Y8WDbq">
					<idno type="grant-number">1629915</idno>
				</org>
				<org type="funding" xml:id="_j8j2uhd">
					<idno type="grant-number">1526750</idno>
				</org>
				<org type="funding" xml:id="_a5Bp2t4">
					<idno type="grant-number">1629129</idno>
				</org>
				<org type="funding" xml:id="_E6egjtt">
					<idno type="grant-number">1763681</idno>
				</org>
				<org type="funding" xml:id="_7Mkq4su">
					<idno type="grant-number">1409095</idno>
				</org>
				<org type="funding" xml:id="_fBTp7kw">
					<idno type="grant-number">1317560</idno>
				</org>
				<org type="funding" xml:id="_ZYpZZgv">
					<idno type="grant-number">1320478</idno>
				</org>
				<org type="funding" xml:id="_WmJtXen">
					<idno type="grant-number">182293</idno>
				</org>
				<org type="funding" xml:id="_4pjxsWc">
					<idno type="grant-number">162651</idno>
				</org>
				<org type="funding" xml:id="_EsJcM62">
					<idno type="grant-number">1439057</idno>
					<orgName type="grant-name">JUMP grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Number of Smartphone Users WorldWide</title>
		<author>
			<persName><surname>Statista</surname></persName>
		</author>
		<author>
			<persName><surname>Com</surname></persName>
		</author>
		<ptr target="https://goo.gl/PCGQPA" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mobile Marketing Statistics</title>
		<author>
			<persName><surname>Smartinsighs</surname></persName>
		</author>
		<author>
			<persName><surname>Com</surname></persName>
		</author>
		<ptr target="https://goo.gl/vNpuEr" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">1B Smartphone Users Globally by 2020 Overtaking Basic Fixed Phone Subscriptions</title>
		<author>
			<persName><surname>Techcrunch</surname></persName>
		</author>
		<author>
			<persName><surname>Com</surname></persName>
		</author>
		<ptr target="https://goo.gl/aoSN5q" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Slack: Maximizing Performance Under Technological Constraints</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Critical Path Analysis of the TRIPS Architecture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE International Symposium on Performance Analysis of Systems and Software</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Large, Fast Instruction Window for Tolerating Cache Misses</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koppanalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Criticality-Aware DVFS Runtime Utility for Optimizing Power Efficiency of Multithreaded Applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Parallel Distributed Processing Symposium Workshops</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Non-critical Buffer: Using Load Latency Tolerance to Improve Data Cache Efficiency</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Bahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1999 IEEE International Conference on Computer Design: VLSI in Computers and Processors</title>
		<meeting>1999 IEEE International Conference on Computer Design: VLSI in Computers and Processors</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Cat. No.99CB37040</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Locality vs. Criticality</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>-C. Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Using Packet Information For Efficient Communication in NoCs</title>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Madhu</forename><surname>Mutyam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-09">Sep 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving Memory Scheduling via Processor-side Load Criticality Information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mart?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Load Latency Tolerance in Dynamically Scheduled Processors</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture</title>
		<meeting>the International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Instruction and Logic for Managing Cumulative System Bandwidth through Dynamic Request Partitioning</title>
		<author>
			<persName><forename type="first">Jayesh</forename><surname>Gaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Rengasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-06">Jun 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Continual Flow Pipelines</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Akkary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Upton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dual-core Execution: Building a Highly Scalable Singlethread Instruction Window</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architecture and Compilation Techniques (PACT)</title>
		<meeting>the International Conference on Parallel Architecture and Compilation Techniques (PACT)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploiting staleness for approximating loads on CMPs</title>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Taylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kandemir</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Chita R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architecture and Compilation Techniques (PACT)</title>
		<meeting>the International Conference on Parallel Architecture and Compilation Techniques (PACT)</meeting>
		<imprint>
			<date type="published" when="2015-10">Oct 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Criticality-based Optimizations for Efficient Load Processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bracy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Cortex-A75</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<author>
			<persName><surname>Com</surname></persName>
		</author>
		<ptr target="https://developer.arm.com/products/processors/cortex-a/cortex-a75" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Cortex-A55</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<author>
			<persName><surname>Com</surname></persName>
		</author>
		<ptr target="https://developer.arm.com/products/processors/cortex-a/cortex-a55" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Cortex-A35</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<author>
			<persName><surname>Com</surname></persName>
		</author>
		<ptr target="https://developer.arm.com/products/processors/cortex-a/cortex-a35" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The Fast! processor emulator</title>
		<ptr target="http://www.qemu-project.org/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>QEMU Project</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName><forename type="first">N</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sardashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shoaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vaish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Gem5 Simulator</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quantifying Instruction Criticality</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Tune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architecture and Compilation Techniques (PACT)</title>
		<meeting>the International Conference on Parallel Architecture and Compilation Techniques (PACT)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Quantifying Instruction Criticality for Shared Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Annual ACM Symposium on Parallel Algorithms and Architectures</title>
		<meeting>the Fifteenth Annual ACM Symposium on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Critical-path Aware Processor Architectures</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tune</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Balanced Scheduling: Instruction Scheduling when Memory Latency is Uncertain</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kerns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Instruction Scheduling and Executable Editing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schnarr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dynamic Speculative Precomputation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The Effect of Instruction Fetch Bandwidth on Value Prediction</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gabbay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Rock: A High-Performance Sparc CMT Processor</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cypher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Landin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tremblay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>IEEE Micro</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Focusing Processor Policies via Critical-path Prediction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bodik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 28th Annual International Symposium on Computer Architecture</title>
		<meeting>28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluating design tradeoffs in dual speed pipelines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pyreddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Complexity-Effective Design in conjunction with ISCA</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dynamic Prediction of Critical Path Instructions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Atlidakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andrus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Geambasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mitropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nieh</surname></persName>
		</author>
		<title level="m">POSIX Abstractions in Modern Operating Systems: The Old, the New, and the Missing</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Proceedings of the Eleventh European Conference on Computer Systems</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Android Developer Reference Doc</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://developer.android.com/reference/packages.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Characterizing Diverse Handheld Apps for Customized Hardware Acceleration</title>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Chidhambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chita</surname></persName>
		</author>
		<author>
			<persName><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Symposium on Workload Characterization</title>
		<meeting>IEEE International Symposium on Workload Characterization</meeting>
		<imprint>
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Internet Streaming SIMD Extensions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thakkur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Intel AVX: New Frontiers in Performance Improvements and Energy Efficiency</title>
		<author>
			<persName><forename type="first">N</forename><surname>Firasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jinbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nasri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kuo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Intel white paper</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Lx: A Technology Platform for Customizable VLIW Embedded Processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Faraboschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Desoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M O</forename><surname>Homewood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Computer Vector Register Processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Cray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">US Patent</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">880</biblScope>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Ip</surname></persName>
		</author>
		<ptr target="https://ip.cadence.com/ipportfolio/tensilica-ip" />
		<title level="m">Tensilica Custimizable Processor and DSP IP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automatic Design of Domain-specific Instructions for Low-power Processors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gonzlez-Lvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Sartor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jimnez-Gonzlez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 26th International Conference on Application-specific Systems, Architectures and Processors (ASAP)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The Renewed Case for the Reduced Instruction Set Computer: Avoiding ISA Bloat with Macro-Op Fusion for RISC-V</title>
		<author>
			<persName><forename type="first">C</forename><surname>Celio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dabbelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.02318</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">App Review</title>
		<author>
			<persName><surname>Apple</surname></persName>
		</author>
		<ptr target="https://developer.apple.com/app-store/review/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">App Quality</title>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<ptr target="https://developer.android.com/develop/quality-guidelines/core-app-quality.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Monkeyrunner</title>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/test/monkeyrunner/index.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">rePLay: A Hardware Framework for Dynamic Optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lumetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Android Open Source Project (AOSP)</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/android" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">ART Compiler Optimizing</title>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<ptr target="http://android.googlesource.com/platform/art/+/master/compiler/optimizing/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">High Performance Code Compression Architecture for the Embedded ARM/THUMB Processor</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference on Computing Frontiers</title>
		<meeting>the 1st Conference on Computing Frontiers</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">ARM Architecture Reference Manual</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<ptr target="https://www.arm.com/products/processors/technologies/biglittleprocessing.php" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Bundled Execution of Recurring Traces for Energy-efficient General Purpose Processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>August</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A Scalable Application-specific Processor Synthesis Methodology</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Jha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCAD-2003. International Conference on Computer Aided Design</title>
		<imprint>
			<publisher>IEEE Cat</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Enhanced Code Compression for Embedded RISC Processors</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mcintosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 1999 Conference on Programming Language Design and Implementation</title>
		<meeting>the ACM SIGPLAN 1999 Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName><surname>Apache</surname></persName>
		</author>
		<author>
			<persName><surname>Api</surname></persName>
		</author>
		<author>
			<persName><surname>Java</surname></persName>
		</author>
		<author>
			<persName><surname>Javapairrdd</surname></persName>
		</author>
		<ptr target="https://spark.apache.org/docs/0.7.2/api/core/spark/api/java/JavaPairRDD.html" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Google Play</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://play.google.com/store?hl=en" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">DC Ultra</title>
		<author>
			<persName><surname>Synopsys</surname></persName>
		</author>
		<ptr target="https://www.synopsys.com/implementation-and-signoff/rtl-synthesis-test/dc-ultra.html" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><surname>Anandtech</surname></persName>
		</author>
		<ptr target="https://developer.arm.com/products/processors/cortex-a/cortex-a75" />
		<title level="m">ARM A53/A57/T760 investigated -Samsung Galaxy Note 4 Exynos Review</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Nexus 7 Tablet Specifications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="https://goo.gl/aPRBuw" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">DRAMSim2: A Cycle Accurate Memory System Simulator</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cooper-Balis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Production Data Sheet: 8Gb, 16Gb: 253-Ball, Dual-Channel 2C0F Mobile LPDDR3 SDRAM (pdf)</title>
		<author>
			<persName><surname>Micron</surname></persName>
		</author>
		<ptr target="https://goo.gl/JELDcz" />
		<imprint>
			<date type="published" when="2016-03-29">2016. March-29-2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Kill the Program Counter: Reconstructing Program Behavior in the Processor Cache Hierarchy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Modified LRU policies for improving second-level cache behavior</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Baer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Optimal partitioning of cache memory</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Turek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A New Case for the TAGE Branch Predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Checkpoint Processing and Recovery: Towards Scalable Large Instruction Window Processors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akkary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Two-level Adaptive Training Branch Prediction</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Effective Optimization of Branch Predictors through Lightweight Simulation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Design (ICCD)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Rethinking Belady? Algorithm to Accommodate Prefetching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Efetch: Optimizing instruction fetch for event-driven web applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chadha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanasamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architecture and Compilation Techniques (PACT)</title>
		<meeting>the International Conference on Parallel Architecture and Compilation Techniques (PACT)</meeting>
		<imprint>
			<date type="published" when="2014-08">Aug 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Proram: Dynamic prefetcher for oblivious ram</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Dijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Best-offset hardware prefetching</title>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Cherry: Checkpointed Early Resource Recycling in Out-of-order Microprocessors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mart?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Renau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Prvulovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">BeBoP: A Cost Effective Predictor Infrastructure for Superscalar Value Prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">EOLE: Paving the Way for an Effective Implementation of Value Prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Profile Guided Selection of ARM and Thumb Instructions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krishnaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Languages, Compilers and Tools for Embedded Systems: Software and Compilers for Embedded Systems, ser. LCTES/SCOPES</title>
		<meeting>the Joint Conference on Languages, Compilers and Tools for Embedded Systems: Software and Compilers for Embedded Systems, ser. LCTES/SCOPES</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The Load Slice Core microarchitecture</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Allam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">SlicK: Slicebased Locality Exploitation for Efficient Redundant Multithreading</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gurumurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2006-10">Oct. 2006</date>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Select-free instruction scheduling logic</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">A survey of program slicing techniques</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tip</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Amsterdam, The Netherlands, The Netherlands</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Mobile CPU&apos;s Rise to Power: Quantifying the Impact of Generational Mobile CPU Design Trends on Performance, Energy, and User Satisfaction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Vip: Virtualizing ip chains on handheld platforms</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boroumand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ausavarungnirun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuusela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Knies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Enabling Cross-ISA Offloading for COTS Binaries</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccamant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bobba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Annual International Conference on Mobile Systems, Applications, and Services (MOBISYS)</title>
		<meeting>the ACM Annual International Conference on Mobile Systems, Applications, and Services (MOBISYS)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">AVS Video Decoding Acceleration on ARM Cortex-A with NEON</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Signal Processing, Communication and Computing (ICSPCC)</title>
		<meeting>International Conference on Signal Processing, Communication and Computing (ICSPCC)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Race-To-Sleep + Content Caching + Display Caching: A Recipe for Energy-efficient Video Streaming on Handhelds</title>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Chidambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chita</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">FLOSS: FLOw Sensitive Scheduling on Mobile Platforms</title>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Chidambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chita</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Design and Automation Conference (DAC)</title>
		<meeting>the Design and Automation Conference (DAC)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">WebCore: Architectural Support for Mobileweb Browsing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">GreenWeb: Language Extensions for Energyefficient Mobile Web Computing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Accelerating Asynchronous Programs Through Event Sneak Peek</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chadha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanasamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Race Detection for Event-driven Mobile Applications</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Flinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Energy-efficient Cache Design in Emerging Mobile Platforms: The Implications and Optimizations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</title>
		<meeting>the Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">NVIDIA&apos;s Denver processor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rozas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Venkatraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HOTChips</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">ARM big.LITTLE Technology</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Technical Reference Manual</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Performance-Energy Considerations for Shared Cache Management in a Heterogeneous Multicore Processor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Holey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mekkat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Cache memories</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Survey</title>
		<imprint>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A survey on replacement strategies in cache memory for embedded systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raveendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)</title>
		<imprint>
			<date type="published" when="2016-08">Aug 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Area and Power Reduction of Embedded DSP Systems Using Instruction Compression and Re-configurable Encoding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mehendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Computer Aided Design</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
	<note>Cat. No.01CH37281</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Improving Code Density Using Compression Techniques</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lefurgy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Reducing Code Size with Runtime Decompression</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lefurgy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Piccininni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Code Compression Based on Operandfactorization for VLIW Processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Compression Conference</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
	<note type="report_type">Proceedings</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A Measurement Study of Google Play</title>
		<author>
			<persName><forename type="first">N</forename><surname>Viennot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS Perform</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">An Explorative Study of the Mobile App Ecosystem from App Developers&apos; Perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">A Study of Modern Linux API Usage and Compatibility: What to Support when You&apos;Re Supporting</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Abdul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh European Conference on Computer Systems</title>
		<meeting>the Eleventh European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A Dynamic Binary Instrumentation Engine for the ARM Architecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 International Conference on Compilers, Architecture and Synthesis for Embedded Systems</title>
		<meeting>the 2006 International Conference on Compilers, Architecture and Synthesis for Embedded Systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Android Studio</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/index.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">The Compiler Design Handbook: Optimizations and Machine Code Generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Whole Execution Traces and their use in Debugging</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
