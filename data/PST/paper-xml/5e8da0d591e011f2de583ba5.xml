<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LLHD: A Multi-level Intermediate Representation for Hardware Description Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-04-07">7 Apr 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fabian</forename><surname>Schuiki</surname></persName>
							<email>fschuiki@iis.ee.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">Integrated Systems Laboratory (IIS) ETH Zürich Zürich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Kurth</surname></persName>
							<email>akurth@iis.ee.ethz.ch</email>
							<affiliation key="aff1">
								<orgName type="institution">Integrated Systems Laboratory (IIS) ETH Zürich Zürich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tobias</forename><surname>Grosser</surname></persName>
							<email>tobias.grosser@inf.ethz.ch</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Scalable Parallel Computing Laboratory (SPCL)</orgName>
								<orgName type="institution">ETH Zürich Zürich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><surname>Benini</surname></persName>
							<email>lbenini@iis.ee.ethz.ch</email>
							<affiliation key="aff3">
								<orgName type="institution">Integrated Systems Laboratory (IIS) ETH Zürich Zürich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LLHD: A Multi-level Intermediate Representation for Hardware Description Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-04-07">7 Apr 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2004.03494v1[cs.PL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>Hardware → Hardware description languages and compilation</term>
					<term>• Computing methodologies → Simulation languages</term>
					<term>• Software and its engineering → Compilers hardware description languages, intermediate representations, transformation passes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern Hardware Description Languages (HDLs) such as SystemVerilog or VHDL are, due to their sheer complexity, insufficient to transport designs through modern circuit design flows. Instead, each design automation tool lowers HDLs to its own Intermediate Representation (IR). These tools are monolithic and mostly proprietary, disagree in their implementation of HDLs, and while many redundant IRs exists, no IR today can be used through the entire circuit design flow. To solve this problem, we propose the LLHD multilevel IR. LLHD is designed as simple, unambiguous reference description of a digital circuit, yet fully captures existing HDLs. We show this with our reference compiler on designs as complex as full CPU cores. LLHD comes with lowering passes to a hardware-near structural IR, which readily integrates with existing tools. LLHD establishes the basis for innovation in HDLs and tools without redundant compilers or disjoint IRs. For instance, we implement an LLHD simulator that runs up to 2.4× faster than commercial simulators but produces equivalent, cycle-accurate results. An initial vertically-integrated research prototype is capable of representing all levels of the IR, implements lowering from the behavioural to the structural IR, and covers a sufficient subset of SystemVerilog to support a full CPU design.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The workflow we use today to design digital circuits, including CPUs and GPUs, has a severe redundancy problem. The sheer complexity of modern designs, requiring billions of transistors to be placed and costing millions of dollars on designers have to "hope", for example, that the circuit synthesizer interprets the semantics of a design in the same way as the simulator used for verification, and the standards can be very subtle <ref type="bibr" target="#b25">[26]</ref>. As a consequence, designers resort to a "safe subset" of each language known to produce identical results across most tools, which precludes the practical use of many distinguishing high-level features of SystemVerilog and VHDL.</p><p>All of our modern computing infrastructure depends on getting this tool flow right. As a consequence, the Electronic Design Automation (EDA) industry invests significant resources into finding safe subsets of the languages, establishing coding styles, and developing linting tools to enforce adherence to such conventions <ref type="bibr" target="#b25">[26]</ref>. In contrast to software development, where the advent of IRs and frameworks such as LLVM <ref type="bibr" target="#b15">[16]</ref> has provided a productive platform for open development, the hardware design flow remains isolated and vendor-locked. The EDA market is dominated by closedsource, proprietary, monolithic toolchains, which have been highly optimized over decades. New open-source tools face the hurdle of implementing complex language frontends before being able to compete. We observe that hardware engineering and compiler design communities have evolved in isolation, even though many optimizations and methodological improvements readily apply to both worlds. This is to hardware engineering's severe disadvantage, as we see ample opportunity for the two communities to connect, exchange, and benefit from each other.</p><p>We propose LLHD, an IR to represent digital circuits throughout the entire design flow, from simulation, testbenches and formal verification, behavioural and structural modeling, to synthesis and the final gate-level netlist. There cannot be a single IR that fits all hardware needs, as this would require high-level simulation constructs without hardware equivalents, yet still be trivially synthesizable. However, the constructs needed to describe a netlist form a subset of those needed for synthesis, which are in turn a subset of those needed for simulation. As such, LLHD is a multi-level IR with three distinct levels or dialects, which cater to the corresponding parts of the tool flow. LLHD adheres to Static Single Assignment (SSA) form <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref>, which lends itself exceptionally well to represent digital circuits, which are exactly that: signals with single, static driver assignments. LLHD borrows the basic IR syntax from LLVM but defines an IR for digital circuits, which must explicitly deal with the passing of time and, since digital circuits are inherently concurrent, must be able to describe concurrency. Together with Moore, a compiler frontend for HDLs, LLHD significantly reduces redundancy in the design flow and allows novel, open languages to thrive, as depicted in Figure <ref type="figure">1</ref>.</p><p>Many IRs for hardware designs already exist. For instance, EDA tools have internal IRs, but these are highly tool-specific and mostly proprietary. In general, the vast majority of IRs puts a narrow focus on circuit synthesis. To prevent redundancy and disagreement in compilers and gaps between IRs, we argue that one IR must cover the entire circuit design flow. To our knowledge this paper is the first to propose this solution. We make the following contributions:</p><p>• We define a multi-level IR that captures current HDLs in an SSA-based form compatible with modern, imperative compilers but with extensions and specializations crucial to represent digital hardware ( § 2). • We show how existing industry-standard HDLs, such as SystemVerilog and VHDL, map to this IR ( § 3). • We establish transformation passes to lower from Behavioural LLHD to hardware-near Structural LLHD ( § 4). • We show that such a multi-level IR can improve the existing EDA tool flow, even without explicit support by commercial tools ( § 5). • We provide evidence that the IR can capture complex designs such as entire CPU cores <ref type="bibr" target="#b30">[31]</ref>, that a minimal reference simulator models those designs identically to commercial simulators, and that an early optimized simulator runs up to 2.4× faster than a commercial simulator ( § 6).</p><p>Finally, we provide an open-source implementation of our IR, its reference simulator, and an accompanying HDL compiler. <ref type="foot" target="#foot_0">1</ref> The implementation acts as a vertically-integrated research prototype. This prototype is currently capable of capturing behavioural, structural, and netlist LLHD. Lowering from behavioural to structural LLHD is partially implemented in order to demonstrate the key transformations, but is not complete at the time of writing. Lowering from structural to netlist LLHD is the domain of hardware synthesizers and as such outside the scope of this work. The Moore compiler supports a subset of SystemVerilog which is large enough to represent a full CPU core <ref type="bibr" target="#b30">[31]</ref> and covers a sufficient amount of non-synthesizable constructs of the language to support simple testbenches. Initial experimental work on VHDL support is underway. Our simulator implementation covers the vast majority of all three LLHD dialects, except a few instruction that were not instrumental to simulate the designs presented in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The LLHD Intermediate Representation</head><p>The LLHD IR is designed as an SSA language <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref> which enables a very direct representation of the data flow in a digital circuit. The rationale is that modern digital circuits are essentially the same as an SSA data flow graph, where each logic gate corresponds to a node in the graph. LLHD has an in-memory representation, a human-readable representation, and a planned binary on-disk representation, and all three representations are equivalent. In this section, we define the core concepts of the LLHD language; the complete and entity @acc_tb () -&gt; () { %zero0 = const i1 0 %zero1 = const i32 0 %clk = sig i1 %zero0 %en = sig i1 %zero0 %x = sig i32 %zero1 %q = sig i32 %zero1 inst @acc (i1$ %clk, i32$ %x, i1$ %en) -&gt; (i32$ %q) inst @acc_tb_initial (i32$ %q) -&gt; (i1$ %clk, i32$ %x, i1$ %en) } proc @acc_tb_initial (i32$ %q) -&gt; (i1$ %clk, i32$ %x, i1$ %en) { entry: %bit0 = const i1 0 %bit1 = const i1 1 %zero = const i32 0 %one = const i32 ; i*(i+1) %qexp = div i32 %ixip1, %two ; i*(i+1)/2 %eq = eq i32 %qexp, %q ; q == i*(i+1)/2 call void @llhd. A testbench for an accumulator design as an illustrative example for LLHD code. See § 2 for a detailed description, Figure <ref type="figure" target="#fig_1">3</ref> for the corresponding SystemVerilog code, and Figure <ref type="figure" target="#fig_4">5</ref> for the implementation of @acc.</p><p>precise specification is part of the LLHD Language Reference Manual. <ref type="foot" target="#foot_1">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Describing Digital Circuits</head><p>A hardware description requires a notion of passing time, must be able to represent concurrency, and provide a way to describe the structure and hierarchy of a circuit. This is due to digital circuits being inherently hierarchical, concurrent, and time-dependent. LLHD draws from the abstractions established in modern HDLs over the past decades, and distills them into fundamental orthogonal concepts. Figure <ref type="figure" target="#fig_0">2</ref> shows a sample LLHD source text describing a testbench for an accumulator circuit as an illustrative example. The language provides three modeling constructs:</p><p>Functions capture a mapping from a set of input values to an output and allow for reuse of computation. They facilitate code reuse, recursion and program-defined mapping of a set of input values to a singular output value in the SSA graph, but they do not have a direct hardware equivalent. (See Figure <ref type="figure" target="#fig_0">2a</ref>) Processes are Turing-complete subprograms that describe how a circuit's state and output reacts to a change in its input. This provides a behavioural circuit description. (See Figure <ref type="figure" target="#fig_0">2b</ref>) Entities build hierarchy by instantiating other processes or entities, which then operate concurrently. This provides a structural circuit description. Such instantiation translates into reuse by replication in the physical silicon, which is an essential contributor to our ability to manufacture designs with billions of transistors. (See Figure <ref type="figure" target="#fig_0">2c</ref>)</p><p>Circuit designs written in HDLs generally model circuits behaviourally and structurally. Physical silicon itself is a purely structural arrangement of circuits and thus fully captured by a hierarchy of entities. Functions and processes are merely modeling tools to fully capture HDLs, including simulation and verification components which have no physical equivalent. To capture these levels of abstraction, LLHD is a three-level IR, as described in the following paragraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multi-level Intermediate Representation</head><p>LLHD can capture all aspects of a digital design written in a higher-level HDL such as SystemVerilog or VHDL, including simulation, verification, and testing constructs. However, its structure also allows it to clearly capture parts relevant for synthesis, as well as represent the netlist that results from synthesis. This makes LLHD a multi-level IR with the following levels:</p><p>Behavioural LLHD aims at capturing circuit descriptions in higher-level HDLs as easily as possible. It allows for simulation constructs and test benches to be fully represented, including assertions, file I/O, or formal verification information as intrinsics. Structural LLHD limits the description to the parts that describe the input to output relations of a design. This covers essentially everything that can be represented by an entity (see § 4 for a more technical description). Netlist LLHD further limits the description to just entities and instructions to instantiate and connect subcircuits. More specifically allowed are just the entity construct, as well as signal creation (sig), connection (con), delay (del), and sub-circuit instantiation (inst).</p><p>We observe that the constructs of Netlist LLHD are a strict subset of Structural LLHD, which in turn is a strict subset of Behavioural LLHD. Rather than defining three separate IRs, we thus propose one holistic IR to cover the entire process. As a design makes its way through the hardware design flow, the simulation and design verification phase uses the full IR of Behavioural LLHD. Before synthesis, LLHD compiler passes lower the design to Structural LLHD. A synthesizer then lowers the design to a netlist by performing logic synthesis and mapping the design to a target silicon technology, which can be expressed in Netlist LLHD. The remainder of this section provides a more detailed treatment of the constructs in LLHD. In the following two sections, we first discuss mapping a design from a HDL to LLHD ( § 3) and then the compiler passes to transform the design between the different LLHD levels ( § 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modules, Names, and Types</head><p>A single LLHD source text is called a module. Modules consist of functions, processes, and entities. Multiple modules can be combined by a linker, which resolves references in one module against the definitions made in the other.</p><p>LLHD distinguishes between three types of names. Most importantly, to minimize naming conflicts in complex designs, only global names, such as @foo, are visible to other modules during linking. Local names, such as %bar, and anonymous names, such as %42, are only visible within the current module (for functions, processes, and entities) or the current unit (for values).</p><p>LLHD is a strongly-typed language, i.e., every value must have a type. LLHD supports a set of types typical for an imperative compiler: void (no value), iN (N-bit integers), T* (pointer to type T), [N x T] (array of N elements of type T, and {T1,T2,...} (structure with fields of type T1 etc.). LLHD defines the following hardware-specific types: time represents a point in time. This allows to describe delays (e.g., through gates) and elapsed time (e.g., in simulation). nN is an enumeration value that can take one of N distinct values. This allows to represent non-power-of-two values (e.g., the set of states in a state machine or the inputs to a multiplexer). lN is a nine-valued logic value, defined in the IEEE 1164 standard <ref type="bibr" target="#b1">[2]</ref>. This allows to model states that a physical signal wire may be in (drive strength, drive collision, floating gates, and unknown values). T$ is a signal carrying a value of type T. This represents a physical signal wire. The prb and drv instructions are used to read the current value of the signal and trigger a future change of the signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Units</head><p>The three main constructs of LLHD, functions, processes, and entities, are called units. As shown in Table <ref type="table" target="#tab_1">1</ref>, LLHD defines for each unit how instructions are executed (execution paradigm) and how time passes during the execution of the unit (timing model). The execution paradigm is either control or data flow. Control flow units consist of basic blocks, where execution follows a clear control flow path. Each basic block must have exactly one terminator instruction which transfers control to another basic block, to the caller, or halts completely. Data flow units consist only of a set of instructions which form a Data Flow Graph (DFG). Execution of instructions is implied by the propagation of value changes through the graph.</p><p>The timing model can be immediate or timed. Immediate units execute in zero time. They may not contain any instructions that suspend execution or manipulate signals. These units are ephemeral in the sense that their execution starts and terminates in between physical time steps. As such no immediate units coexist or persist across time steps. Timed units coexist and persist during the entire execution of the IR. They represent reactions to changes in signals and as such model the behaviour of a digital circuit. Such units may suspend execution or interact with signals by probing their value or scheduling state changes.</p><p>2.4.1 Functions. Functions represent a mapping from zero or more input arguments to zero or one return value. Functions are defined with the func keyword and are called from other units with the call instruction. For example, Figure <ref type="figure" target="#fig_0">2a</ref> defines a function to assert that an input value %q matches the sum of all integers up to %i, and Figure <ref type="figure" target="#fig_0">2d</ref> calls that function. Functions execute immediately, meaning that they cannot interact with signals or suspend execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Processes.</head><p>Processes, in contrast, can interact with time. Similar to functions, they are executed in a control flow manner. Processes represent a circuit with zero or more inputs and outputs. The inputs and outputs must be of a signal type T$; other types are not permitted. Figure <ref type="figure" target="#fig_0">2b</ref> defines a process that generates the patterns to test an accumulator circuit, and Figure <ref type="figure" target="#fig_0">2e</ref> instantiates that process. Upon initialization, control starts at the first basic block and proceeds as it would in a function. Processes may probe and drive the value of signals (see § 2.5.2), which are a process' only means to communicate with other parts of the design. Additionally, processes may suspend execution for a period of time or until a signal change (wait, Figure <ref type="figure" target="#fig_0">2f</ref>), or indefinitely (halt, Figure <ref type="figure" target="#fig_0">2g</ref>). In contrast to functions, processes exist throughout the entire lifetime of the circuit and never return.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Entities.</head><p>Entities describe a pure DFG and their execution is not governed by any control flow. Upon initialization, all instructions are executed once. At all subsequent points in time, instructions are re-executed if one of their inputs changes. This creates an implicit execution schedule for the instructions. Entities build structure and design hierarchies by allocating registers and signals via the reg and sig instructions, and instantiating other entities and processes via the inst instruction. For example, Figure <ref type="figure" target="#fig_0">2c</ref> defines an entity which has four local signals (h), and instantiates the @acc design to be tested (k) and the @acc_tb_initial process to execute the test (e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Instruction Set</head><p>LLHD's simple instruction set captures the essence of hardware descriptions at a hardware-near level of abstraction. Nevertheless, LLHD preserves arithmetic operations, which are the main target of many optimizations in commercial hardware synthesizers. As a general rule, all instructions contain sufficient type annotations to determine the type of each operand and the result. We omit a detailed description of all instructions, especially those that are common in imperative compiler IRs such as LLVM, and focus on the hardware-specific concepts.</p><p>2.5.1 Hierarchy. Hierarchy and structure is described via the inst instruction, which is limited to entities. The instruction names a process or entity to be instantiated and associates each of its inputs and outputs with a signal (see Figure <ref type="figure" target="#fig_0">2ek</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Signals.</head><p>Signals are created with the sig instruction by providing the type of the value the signal carries, together with its initial value. The current value of a signal can be probed with the prb instruction, which takes a signal as its argument. A new value may be driven onto the signal with the drv instruction, which takes a target signal, value to be driven, drive delay, and an optional condition as arguments. These instructions are limited to processes and entities. For example in Figure <ref type="figure" target="#fig_0">2</ref>, the @acc_tb_initial process (b) uses prb to "read" the value of its input %q (m), and drv to "write" a change to its outputs %en, %clk, and %x (n). The @acc_tb entity uses sig to define local signals (h) that connect @acc (k) and @acc_tb_initial (e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3">Registers.</head><p>State-holding storage elements such as registers and latches are created with the reg instruction, which is limited to entities. The reg instruction takes the stored value type and the initial value as first arguments. These are followed by a list of values, each with a trigger that describes when this value is stored. The trigger consists of the keyword low, high, rise, fall, and both, followed by a value. This allows for active-low/high, as well as rising, falling, and dual edge-triggered devices to be described. To model conditionally-enabled circuits, an optional if gating clause can be used to discard the trigger if some condition is not met. For example, the optimized @acc_ff entity in Figure <ref type="figure" target="#fig_4">5k</ref> further ahead uses reg to allocate a rising-edge triggered flip-flop to store the current accumulator state.</p><p>2.5.4 Data Flow. Data flow instructions, including constants, logic and arithmetic operations, shifts, and comparisons, are a significant part of the instructions in LLHD. For example in Figure <ref type="figure" target="#fig_0">2</ref>, the @acc_tb_check function (a) uses the add, mul, div, and eq instructions to check the accumulator result. Selection between multiple values is performed with the mux instruction, which takes a sequence of values of the same type as arguments followed by a discriminator that chooses among them.</p><p>2.5.5 Bit-precise Insertion/Extraction. Bit-precise control of values is essential to describe digital designs. The insf and extf instructions allow to set (insert) or get (extract) the value of individual array elements or struct fields. The inss and exts instructions allow to set or get the value of a slice of array elements or bits of an integer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.5.6</head><p>Pointer/Signal Arithmetic. The extraction (extf and exts) and shift (shl and shr) instructions can also operate on pointers and signals. In this mode, these instructions return a new pointer or signal, which directly points at the extracted field or slice or to the shifted value. These operations are very useful when translating from HDLs, where slices or subsets of signals are frequently accessed or driven. In order to translate into hardware, these partially-accessed signals must be subdivided to the granularity of these accesses, in order to arrive at canonical drive and storage conditions for generated flip-flops or signal wires.</p><p>2.5.7 Control and Time Flow. Control flow instructions are the typical ones used in imperative compilers: conditional and unconditional branches, function calls, and returns. The example in Figure <ref type="figure" target="#fig_0">2</ref> uses br to implement a loop, call to execute the @acc_tb_check function (d), and ret to return from that function.</p><p>Time flow instructions allow processes to control the passing of time. The wait instruction suspends execution until one of its operand signals changes and optionally until a certain amount of time has passed. Execution then resumes at the basic block passed to the wait instruction as its first argument. The halt instruction suspends execution of the process forever. The example in Figure <ref type="figure" target="#fig_0">2</ref> uses wait to suspend execution for 2 ns in each loop iteration (f), and halt to stop once the loop terminates (g).</p><p>2.5.8 Memory. Stack and heap (or "dynamic") memory are required to fully map HDLs. Stack memory holds local variables in functions (e.g., loop variables). Heap memory is required for Turing completeness, which is necessary to represent all simulation and verification code in today's HDLs. For example, SystemVerilog provides builtin dynamic queues and vectors, sparse associative arrays, and a mechanism to call into native code loaded from an object file, or vice versa. These features require heap allocation and deallocation of memory, and are heavily used in more advanced testbenches and verification code. Values in allocated memory are loaded and stored with the ld and st instructions. Stack allocation is implemented by the var instruction, and heap allocation and deallocation by alloc and free, respectively.</p><p>LLHD code intended for hardware synthesis is expected to require a bounded amount of stack and heap memory known at compile-time, usually none at all. Bounded heap allocations are guaranteed to be promotable to stack allocations, and bounded stack allocations guarantee that the total amount of required memory is known at compile time. An algorithm similar to LLVM's memory-to-register promotion allows LLHD to promote memory instructions to values and phi nodes. Lowering to Structural LLHD requires all stack and heap memory instructions to be promoted in this way, as a design is otherwise not implementable in hardware and can be rejected. Verification code, which is expected to run in an interpreter, does not have to meet these requirements.</p><p>2.5.9 Intrinsics and Debugging. Additional functionality beyond what is provided as explicit instructions may be represented as intrinsics. An intrinsic is a call to a predefined function prefixed with "llhd." (e.g. Figure <ref type="figure" target="#fig_0">2p</ref>). This allows for concepts such as stdin/stdout, file I/O, or assertions to be preserved when transporting from HDLs into LLHD. We envision debug information such as HDL source locations and naming to be attached to instructions and units via metadata nodes akin to LLVM. Furthermore, a special obs instruction could be used to describe an observation point for a signal as the user has written it in the original HDL. This allows a design to remain debuggable and recognizable to a user despite aggressive synthesis transformation -a feature which is currently lacking in commercial synthesizers and place-and-route software.</p><p>3 Mapping HDLs to LLHD LLHD's primary goal is to capture designs described in HDLs such as SystemVerilog or VHDL. This explicitly includes simulation and verification constructs and not just the synthesizable subset of a language. As part of the LLHD project we are developing the Moore compiler, which maps SystemVerilog and VHDL to LLHD. This is comparable to the interaction between Clang and LLVM. Moore's goal is to map as much of SystemVerilog and VHDL to LLHD as possible, providing a reference implementation for both HDLs and a platform for future efforts in hardware synthesis, verification, and simulation without the need to reinvent the HDL compiler wheel. This section explores how common constructs in these languages map to LLHD, based on our accumulator and testbench running example, the SystemVerilog source  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hierarchy</head><p>The fundamental elements of reuse and hierarchy are "modules" in SystemVerilog and "entities" in VHDL. Both describe a circuit as a list of input and output ports and a body of signals, sub-circuits, and processes. Thus, they trivially map to LLHD entities, for example Figure <ref type="figure" target="#fig_1">3a</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Processes</head><p>Processes are the main circuit modeling tool in most HDLs. SystemVerilog provides the always, always_ff, always_latch, always_comb, initial, and final constructs, while VHDL has a general-purpose process concept. Using these constructs, a circuit can be described in a behavioural fashion by providing an imperative subprogram that maps a change in input signals to a change in output signals: essentially, the body of a process is re-executed whenever one of its input signals changes. LLHD's processes are designed to capture these constructs through an almost verbatim translation from an HDL process. Processes allow for a very high-level and general description of circuits. However, it is common practice to follow a strict modeling style in HDLs to ensure synthesizers infer the proper hardware, which we briefly describe in the following.  <ref type="figure" target="#fig_1">3c</ref>, which directly maps signals q and x to an output value d. This translates into the @acc_comb LLHD process in Figure <ref type="figure" target="#fig_4">5n</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Sequential</head><p>Processes. Sequential processes describe state-keeping elements such as flip-flops and latches. A process is sequential if at least some of its output signals are only assigned under certain conditions. Synthesizers detect these kinds of processes, usually requiring the designer to adhere to a very strict pattern, and map them to the corresponding storage gate. Consider the always_ff process in Figure <ref type="figure" target="#fig_1">3d</ref>, which maps to the @acc_ff LLHD process in Figure <ref type="figure" target="#fig_4">5p</ref>. LLHD can capture register descriptions in the behavioral form (see Figure <ref type="figure" target="#fig_4">5p</ref>) but also provides an explicit reg instruction (see Figure <ref type="figure" target="#fig_4">5k</ref>) to canonically represent registers, which is inferred by lowering passes discussed in § 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Mixed</head><p>Processes. SystemVerilog and VHDL allow designers to mix combinational and sequential styles in one process, but support for this is limited even in commercial synthesizers. The desequentialization pass ( § 4.6) can help split mixed processes into combinational and sequential parts for higher compatibility with many synthesizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Generate Statements and Parameters</head><p>Many HDLs provide generate statements and parameters to allow for parametrized generation of hardware. LLHD does not provide such constructs, but rather expects these statements to be unrolled already by the compiler frontend (e.g., Moore). The rationale is that HDL designs parametrized over constants and types lead to significant changes in the generated hardware that go beyond mere type or constant substitution. For example, a parameter might cause the generate statements in a design to unroll to a completely different circuit.</p><p>Capturing this flexibility in LLHD would require a significant meta-programming layer to be added, which in our opinion is best left to a higher-level language or IR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Verification</head><p>Modern HDLs feature constructs to verify hardware designs. SystemVerilog, for example, provides the assert, assume, and require constructs. We propose to map these to LLHD intrinsics such as llhd.assert. A simulator may then choose to emit error messages when the condition passed to such an intrinsic is false. A formal verification tool, on the other hand, can extract these intrinsics and set up a satisfiability Inline IS problem or perform bounded model checking <ref type="bibr" target="#b9">[10]</ref>. Higherlevel constructs to describe Linear Temporal Logic (LTL) and Computational Tree Logic (CTL*) properties <ref type="bibr" target="#b12">[13]</ref> shall be mapped to intrinsics as well, such that a formal verification tool can recover them from the IR. An interesting side-effect of preserving these verification constructs as intrinsics is that Field-Programmable Gate Array (FPGA) mappings of an LLHD design may choose to implement the assertions in hardware, to perform run-time checks of a circuit. These features are not yet implemented in our research prototype, and an LLHD-based verification tool is yet to be written.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Lowering to Structural LLHD</head><p>One of the key contributions of LLHD is a framework to translate the high-level behavioural circuit descriptions of an HDL into a lower-level structural description that can be readily synthesized. Existing commercial and open-source synthesizers all have redundant proprietary implementations of this procedure; see Figure <ref type="figure">1</ref>. With LLHD and language frontends such as Moore, this translation can be performed as a lowering pass on the IR directly, rather than individually by each synthesizer. The general objective of this lowering is to replace branches with branch-free code. In particular, it consists of the following high-level steps:</p><p>• Reduce complexity of operations ( § 4.1)</p><p>• Move arithmetic out of basic blocks (ECM, § 4.2)</p><p>• Move drives out of basic blocks (TCM, § 4.3)</p><p>• Replace phi and control flow with mux (TCFE, § 4.4)</p><p>• Replace trivial processes with entities (PL, § 4.5)</p><p>• Identify flip-flops and latches (Deseq., § 4.6)</p><p>Consider the accumulator design in Figure <ref type="figure" target="#fig_4">5</ref>, which is a typical example of Behavioural LLHD as it is generated from a SystemVerilog source. Let us step through the transformations in Figure <ref type="figure" target="#fig_3">4</ref> to lower this example to Structural LLHD. The processes @acc_ff and @acc_comb are lowered to entities through various transformations, and are eventually inlined into the @acc entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Basic Transformations</head><p>In a first step, we apply basic transformations such as Constant Folding (CF), Dead Code Elimination (DCE), and Common Subexpression Elimination (CSE), which are equivalent to their LLVM counterparts. Furthermore, Instruction Simplification (IS) is used as a peephole optimization to reduce short instruction sequences to a simpler form, similar to LLVM's instruction combining. To facilitate later transformations, all function calls are inlined and loops are unrolled at this point. Where this is not possible, the process is rejected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Early Code Motion (ECM)</head><p>ECM moves instructions "up" in the Control Flow Graph (CFG), to facilitate later control flow elimination. This is similar to and subsumes Loop-Invariant Code Motion (LICM) in LLVM in that code is hoisted into predecessor blocks, but ECM does this in an eager fashion. The underlying motif of lowering to Structural LLHD is to eliminate control flow, since that does not have an equivalent in hardware. An essential step towards this is to eagerly move instructions into predecessor blocks as far as possible. As shown in Figure <ref type="figure" target="#fig_4">5a</ref>, this moves all constants into the entry block, and arithmetic instructions to the earliest point where all operands are available. Special care is required for prb as in Figure <ref type="figure" target="#fig_4">5b</ref>, which must not be moved across wait, as that would imply a semantic change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Temporal Code Motion (TCM)</head><p>The wait instructions naturally subdivide a process into different Temporal Regions (TRs), i.e. sections of code that execute during a fixed point in physical time. A key step towards eliminating control flow is to move drv instructions into a single exiting block for their respective TR. The condition under which the control flow reaches a drv instruction before the move is added as an additional operand to the instruction. Let us elaborate in more detail by first introducing the concept of TRs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Temporal Region (TR).</head><p>The capability of wait to suspend execution mid-process until a later point in time calls for novel techniques to reason about the synchronicity of instructions. More specifically, we would like to know if two instructions execute at the same instant of physical time under all circumstances. Consider the %clk signal in Figure <ref type="figure" target="#fig_4">5q</ref> as an illustrative example: when we reach the neq instruction, we would like to be able to reason that %clk0 is an "old" sampling of %clk from before the wait, and that %clk1 reflects the current state of %clk. Each basic block in LLHD has an associated TR. Multiple blocks may belong to the same TR. The set of blocks in the same TR represents the bounds within which prb and drv instructions may be rearranged without changing the process behaviour. As an intuition, TRs are assigned to individual blocks based on the following rules:</p><p>1. If any predecessor has a wait terminator, or this is the entry block, generate a new TR. 2. If all predecessors have the same TR, inherit that TR. 3. If they have distinct TRs, generate a new TR.</p><p>Note that as a result of rule 3, there is one unique entry block for each TR where control transfers to from other TRs. Figure <ref type="figure" target="#fig_4">5ab</ref> shows the temporal regions assigned to the individual blocks. Note that the flip-flop process @acc_ff has two TRs, whereas the combinational process @acc_comb has just one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Single</head><p>Exiting Block per TR. We would like each TR to have a single exiting block. This is essential to have a single point in the CFG to move drvs to such that they are always executed in this TR. If TR A has multiple control flow arcs leading to TR B, an additional intermediate block is inserted in order to have a single arc from TR A to B. This is always possible since as a result of rule 3 in § 4.3.1, all branches to TR B target the same unique entry block. In Figure <ref type="figure" target="#fig_4">5b</ref> for example, blocks check and event both branch to init, which is in a different TR. In this case an auxiliary block is created as part of TCM, where check and event branch to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Moving Drive Instructions.</head><p>As the main part of TCM, drv instructions are moved into the single exiting block of their TR. We first find the closest common dominator of the exiting block and the instruction. If no such dominator exists, the instruction is left untouched, which later causes the lowering to reject the process. As a second step, we find the sequence of branch decisions that cause control to flow from the dominator to the drv instruction. This essentially builds a chain of ands with the branch conditions "along the way", or their inverse, as operands. As the final third step, the drv instruction is moved into the exiting block, and the expression found in the second step is set as the drv's optional condition operand. In Figure <ref type="figure" target="#fig_4">5c</ref>, control flow only reaches the drv if the %posedge branch argument is true. Consequently, %posedge is added as drive condition in Figure <ref type="figure" target="#fig_4">5d</ref>. In Figure <ref type="figure" target="#fig_4">5e</ref>, control flow always reaches the drvs, which are consequently moved into the existing single exiting block final without adding a condition operand, as in Figure <ref type="figure" target="#fig_4">5f</ref>. Since both drvs target the same signal, they are coalesced into one instruction, and selection of the driven value is factored out into a phi instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Total Control Flow Elimination (TCFE)</head><p>The goal now is to replace control flow with data flow, branches with multiplexers. The previous transformations leave many empty blocks behind. TCFE eliminates these blocks such that only one block remains per TR. This is the case in Figure <ref type="figure" target="#fig_4">5df</ref>, where only the init, check, and entry blocks remain. Furthermore, all phi instructions are replaced with mux instructions, as shown in Figure <ref type="figure" target="#fig_4">5g</ref>. The selector for the mux instruction is found in the same way as the drv condition in § 4.3.3. As a result, combinational processes ( § 3.2.1) now consist of a single block and TR, and sequential processes ( § 3.2.2) of two blocks and TRs. Processes for which neither holds are rejected by the lowering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Process Lowering (PL)</head><p>At this point, processes with a single block and a wait terminator of the correct form are lowered to an entity. This is done by removing the wait and moving all other instructions to an entity with the same signature. In order for this to be equivalent, the wait must be sensitive to all prb'd signals.</p><p>See Figure <ref type="figure" target="#fig_4">5h</ref> for an example where this is the case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Desequentialization (Deseq.)</head><p>For the remaining processes we would like to identify if they describe a sequential circuit such as a flip-flop or latch. HDLs expect these to be inferred from signals that are only driven under certain conditions, e.g., if a clock signal changed or a gate signal is high. The TCM pass canonicalizes processes into a form which makes this rather straightforward. We only consider processes with two basic blocks and TRs, which covers all relevant practical HDL inputs. In a first step, we canonicalize the condition operand of each drv into its Disjunctive Normal Form (DNF). The DNF exists for all boolean expressions, is trivially extended to eq and neq, and can retain all non-canonicalizable instructions as opaque terms. Each separate disjunctive term of the DNF identifies a separate trigger for the flip-flop or latch. The drv in Figure <ref type="figure" target="#fig_4">5d</ref>, for example, has the canonical condition ¬%clk0 ∧ %clk1. In a second step, we identify which terms of the condition are sampled before the wait, and which are sampled after. This is done based on the TR of the corresponding prb. The TR of the wait is considered the "past", and the TR of the drv is considered the "present". In a third step, we isolate terms T which are sampled both in the past (T 0 ) and the present (T 1 ), and pattern match as follows:</p><formula xml:id="formula_0">• ¬T 0 ∧ T 1 is a rising edge on T • T 0 ∧ ¬T 1 is a falling edge on T • (¬T 0 ∧ T 1 ) ∨ (T 0 ∧ ¬T 1 )</formula><p>are either edges on T All other terms are moved into the set of "trigger conditions". At this point, a separate entity is created which will hold the identified sequential elements. In a final step, all drvs, for which the above trigger identification was successful, are mapped to an equivalent reg instruction. Each trigger is added to the reg separately, together with the corresponding set of trigger conditions: edge terms are mapped to corresponding rise, fall, or both edge triggers, and all remaining terms to high or low level triggers. Furthermore, the entire DFG of the drv operands, namely driven signal, value, delay, and condition, is added to the entity. See Figure <ref type="figure" target="#fig_4">5k</ref>. This procedure identifies and isolates edgeand level-triggered sequential elements into an entity. The remaining process is either empty and removed, lowered by PL, or rejected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Synthesizability</head><p>The class of "synthesizable" hardware descriptions and subsets of HDLs is defined rather loosely. In practice, hardware descriptions adhere to sufficiently strict coding guidelines that enable the above transformations to occur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Toolflow Integration</head><p>Languages such as SystemVerilog are too high-level to reliably transport digital circuits through the design flow. This is mainly due to the difficulty to consistently implement these languages, as described in § 1. For example, designs are simulated and verified in their HDL description, by a simulator or verification tool. A Logical Equivalence Checker (LEC) is then used to verify that the design has been mapped correctly from HDL to an equivalent netlist. Not only does this require the LEC to fully implement the SystemVerilog standard as well, it also only verifies that the synthesizer's interpretation of the HDL matches the LEC's. However, it does not verify whether the simulation and verification tool's interpretation matches the LEC's. This is potentially disastrous given the complexity of languages such as SystemVerilog.</p><p>LLHD provides a design representation that is much simpler to implement consistently. Simulating and verifying the LLHD mapping of a circuit rather than its original HDL means converging to a single simple representation early in the design flow. Synthesis tools and LECs running on this reference LLHD mapping then ensure correct translation of the circuit into a netlist. LLHD's simplicity offers a much smaller "surface for implementation errors".</p><p>Many commercial tools already use a proprietary IR internally. These are generally accessible to the user, such that a Structural LLHD description can be mapped directly to such a tool's IR. Where this is not possible, the description may be mapped to a simple, structural Verilog equivalent to be ingested by the tool. Ideally, vendors eventually support direct input of LLHD, but this is not required.</p><p>We conclude that LLHD fits very well into existing commercial tool flows. Its simplicity makes it a prime candidate to harden the HDL-to-netlist verification chain. Furthermore, its expressivity allows it to subsume other IRs, offering a platform to transport designs between FIRRTL <ref type="bibr" target="#b13">[14]</ref>, RTLIL <ref type="bibr" target="#b29">[30]</ref>, CoreIR <ref type="bibr" target="#b18">[19]</ref>, and others. Table <ref type="table">2</ref>. Evaluation of the simulation performance of LLHD. We compare the LLHD reference interpreter to a JIT-accelerated LLHD simulator and to a commercial simulator. The former two operate on unoptimized LLHD code as emitted by the Moore frontend with the -O0 flag. We list the lines of code "LoC" and executed clock "cycles" to provide an indication for the design and simulation complexity. Traces match between the two simulators for all designs. See Section 6.1 for a detailed description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sim. Time [s]</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>LoC Cycles Int. 1 LLHD reference interpreter (LLHD-Sim), extrapolated; 2 JIT-accelerated simulator (LLHD-Blaze); 3 Commercial HDL simulator Moreover, LLHD significantly lowers the hurdle for innovation in the digital hardware design ecosystem. For instance, a new HDL only needs to be lowered to LLHD to become supported by all existing toolchains, High-level Synthesis (HLS) compilers can generate LLHD as output, simulators only have to parse the simple LLHD rather than complex HDLs, and synthesizers can take Structural LLHD as their input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>We have implemented the Moore compiler and LLHD as a vertical research prototype. Moore covers enough of the SystemVerilog standard to show merit on a non-trivial set of open-source hardware designs: specifically, we consider the designs listed in Table <ref type="table">2</ref>, which range from simple arithmetic primitives, over First-In First-Out (FIFO) queues, Clock Domain Crossings (CDCs), and data flow blocks, up to a full RISC-V processor core <ref type="bibr" target="#b28">[29]</ref>. The lines of SystemVerilog code ("LoC") in Table <ref type="table">2</ref> provides a rough indication of the respective hardware complexity. The designs are mapped from SystemVerilog to Behavioural LLHD with the Moore compiler, without any optimizations enabled. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4-Valued Logic</head><p>(IEEE 1364 <ref type="bibr" target="#b2">[3]</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral Structural</head><p>Netlist</p><formula xml:id="formula_1">LLHD [us] 3 ✓ ✓ ✓ ✓ ✓ ✓ ✓ FIRRTL [14] 3 † - - - - -✓ ✓ CoreIR [19] 1 - ✓ - - -✓ - µIR [24] 1 - - - - -✓ - RTLIL [30] 1 - - - ✓ ✓ ✓ - LNAST [28] 1 - - - - ✓ -- LGraph [27] 1 - - - - -✓ ✓ netlistDB [6]</formula><p>1 -----✓ ✓ † Mentioned conceptually but not defined precisely</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Circuit Simulation</head><p>In a first evaluation, we simulate the designs in Table <ref type="table">2</ref> mapped to LLHD using LLHD-Sim, the LLHD reference interpreter, and LLHD-Blaze, a simulator leveraging just-in-time (JIT) code generation. Both simulators support all levels of the LLHD IR. LLHD-Sim is deliberately designed to be the simplest possible simulator of the LLHD instruction set, rather than the fastest. LLHD-Blaze is a first implementation of JIT compilation to show the potential of massively accelerated simulation. For each of the designs, we compare the execution time of a commercial SystemVerilog simulator ("Comm. ") with our two approaches in Table <ref type="table">2</ref>. Simulations were executed on an Intel Core i7-4770 CPU running at 3.4 GHz. Without JIT compilation, LLHD-Sim is slower than its commercial counterpart, which trades initial optimization overhead at startup for increased simulation performance. Most importantly, however, the LLHD simulation trace is equal to the one generated by the commercial simulator for all designs. That is, even with a simple prototype implementation of Moore and LLHD, we can fully and correctly represent a RISC-V processor in Behavioural LLHD.</p><p>JIT compilation provides an opportunity to massively accelerate LLHD simulation. For this, we map LLHD to LLVM IR and then use LLVM to optimize for execution on the simulation machine. This makes LLHD-Blaze ("JIT") competitive with commercial simulators, even though the former is a prototype whereas the latter have been optimized for decades. In some cases, LLHD-Blaze is already up to 2.4× faster than commercial simulators.</p><p>These benefits manifest themselves even on entirely unoptimized LLHD code as it is emitted by Moore with the -O0 flag, comparable to Clang's equivalent. We expect the discrepancies between LLHD-Blaze and the commercial simulator to disappear as we add optimizations to the simulator in the future. This will especially affect complex benchmarks such as the RISC-V core, where the lack of code optimization currently incurs significant overheads. Note that the lines of SystemVerilog code and simulation cycles do not always fully portray the complexity of a design: some SystemVerilog constructs can produce significantly more LLHD code than others, leading to significant differences in simulation time.</p><p>Much of the complexity and engineering effort of our work lies in Moore, the HDL compiler frontend, which tackles the extensive SystemVerilog standard. Further extensions of Moore to implement additional SystemVerilog constructs can vastly increase the scope of designs that can be mapped to LLHD. Once a design is in LLHD, simulating it correctly is trivial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison with other Hardware IRs</head><p>LLHD is not the first IR targeted at hardware design. However, to our knowledge it is the first multi-level IR capable of capturing a design throughout the entire hardware design flow, from simulation to synthesized netlist. Table <ref type="table" target="#tab_6">3</ref> compares the part of the design flow covered by LLHD and other IRs. We observe that almost all other IRs support structural descriptions of circuits and many IRs support representing a synthesized netlist. This is due to the fact that most of them were designed as synthesis IRs to capture and apply transformations before and after synthesis. A notable example is FIRRTL, which acts as an interface between the Chisel <ref type="bibr" target="#b6">[7]</ref> frontend and subsequent synthesis. As the only other IR, FIRRTL defines multiple levels of abstraction together with transformations to lower designs from higher to lower levels. µIR is designed to capture entire accelerator architectures as structural description and caters more to an HLS flow. RTLIL and LNAST both support the behavioural description of circuits. RTLIL is geared towards simplifying Verilog input to make it amenable for synthesis. LNAST represents behavioural HDL code as language-agnostic Abstract Syntax Tree (AST) and offers transformation passes. As the only other IR, CoreIR focuses on adding formal verification support to HDLs. No other IR is Turing-complete, which is essential to represent arbitrary reference models and verification constructs. FIRRTL provides limited support for testbench constructs in the form of message logging and clocking control.</p><p>LLHD covers all stages of the flow: Behavioural LLHD captures testbench, verification, and behavioural circuit descriptions, to facilitate interfacing with HDLs; Structural LLHD captures circuits structurally, to interface with synthesis and low-level circuit analysis and transformation tools; and Netlist LLHD represents the individual gates of a finalized circuit. Hence LLHD is the only IR capable of representing the full semantics of the SystemVerilog/VHDL input language for the full hardware design flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Size Efficiency</head><p>An important aspect of a hardware IR is how efficiently it captures a design in terms of memory used, both in on-disk and in-memory representations. Table <ref type="table" target="#tab_7">4</ref> shows the size in kB occupied by the previously introduced designs.</p><p>For on-disk representations, we consider the SystemVerilog HDL code as a baseline (first numeric column). First, we observe that the unoptimized LLHD text (second column) emitted by the Moore compiler using the -O0 flag (equivalent to the corresponding Clang/GCC flag) is significantly larger than SystemVerilog. This is due to the fact that Moore tries to keep code generation as simple as possible and emits numerous redundant operations. Furthermore, many operations which are implicit in SystemVerilog, for example, expression type casts and value truncation/extension, require explicit annotation in LLHD. Future optimizations can reduce redundant operations and produce more compact instructions, which we expect to be significantly smaller. Utilizing a binary "bitcode" representation (third column) instead can greatly reduce the on-disk size of the design, such that compiled HDL input represented as LLHD unoptimized bitcode is already comparable in size to the input source code. The bitcode itself is not yet implemented. Sizes are estimated based on a strategy similar to LLVM's bitcode, considering techniques such as run-length encoding for numbers, interning of strings and types, compact encodings for frequently-used primitive types and value references. This makes LLHD a viable format to transport a design into the initial stages of the design flow, such as testbenches and simulation, formal verification, and synthesis.</p><p>The in-memory size of an IR (last column of Table <ref type="table" target="#tab_7">4</ref>) is even more important for transformation and optimization passes. While there is no baseline for this, we observe that even a full RISC-V core only requires 1 MB of memory. As the in-memory complexity scales linearly with the complexity of the design, we argue that representing even entire System on Chip (SoC) designs with hundreds of CPU cores will be feasible with tens of gigabytes of memory, which is fully viable for today's workstations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Intermediate representations are an established and very successful concept both for representing imperative programs and the design of hardware circuits. This work has been in development over the past three years and predates efforts such as MLIR <ref type="bibr" target="#b16">[17]</ref>, which aims at providing a unifying framework for defining compiler IRs. The proposed concepts can likely be expressed in MLIR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Compiler Intermediate Representations</head><p>Since the early days of compilers and program optimizations it has been clear that in the process of translating a computer program to machine code the program passes a variety of different representations <ref type="bibr" target="#b21">[22]</ref>. Machine-independent internal program representations have been discussed as early as 1979 in the PQCC project <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b22">23]</ref> which introduced a tree-structured common optimization language (TCOL) and showed its use in an optimizing Ada compiler. Intermediate representations are standard in most compilers today. Functional programming languages often use continuationpassing style representations <ref type="bibr" target="#b24">[25]</ref>. For imperative programming languages, SSA-based intermediate representations <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref> have shown most successful, and are used in large compiler infrastructures such as LLVM <ref type="bibr" target="#b15">[16]</ref>, GCC <ref type="bibr" target="#b19">[20]</ref>, but also research compilers such as Cetus <ref type="bibr" target="#b14">[15]</ref>. While most SSA-based compilers today use the concept of imperative branching transitioning between sequences of instruction blocks, Click and Cooper <ref type="bibr" target="#b10">[11]</ref> removed this restriction by introducing the sea-of-nodes concept of graph-based intermediate languages where all freely floating instructions are only constrained by explicit control and data dependences. This concept is used in research compilers such as libfirm <ref type="bibr" target="#b7">[8]</ref> or Google's Turbo-Fan JavaScript compiler. <ref type="foot" target="#foot_2">3</ref> While the above approaches have shown the benefit of, especially SSA-based, intermediate representations the above concepts all aim for the generation of executable software, but do not target hardware design. Graph-based IRs certainly serve as inspiration to our Netlist LLHD, but existing compilers use graph-based IRs mostly for software compilation. Nevertheless, there are first efforts to define intermediate representations for hardware designs, which we will discuss in detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">FIRRTL</head><p>FIRRTL <ref type="bibr" target="#b13">[14]</ref> is the IR most closely related to LLHD known to us. FIRRTL acts as an abstraction layer between the Chisel <ref type="bibr" target="#b6">[7]</ref> hardware generation framework and subsequent transformation passes and synthesis. FIRRTL's semantics are closely coupled to those of Chisel and focuses mainly on the synthesis portion of the design flow. Notable exceptions are support for certain testbench constructs (see Section 6.2). We identify the following four fundamental differences between LLHD and FIRRTL:</p><p>(1) FIRRTL's fundamental data structure is an AST <ref type="bibr" target="#b17">[18]</ref>. Nodes may be assigned multiple times and at different granularities, making identification of a value's single producer difficult. In contrast, algorithms operating on SSA forms prevail in modern compilers, and most research on transformations focuses on SSA. While low FIRRTL also requires SSA form, algorithms requiring this form are precluded from operating on all but the lowest level of abstraction.</p><p>(2) FIRRTL cannot represent testbench and simulation constructs such as precise delays, events, and queues and dynamic arrays, as well as arbitrary programs that stimulate and check a circuit. These constructs are essential to fully represent industry-standard HDLs such as SystemVerilog and to transport designs written in such languages through the full digital design flow.</p><p>(3) FIRRTL does not represent four-or nine-valued logic as defined by IEEE 1364 and IEEE 1164, respectively. These types of logic model the additional states of a physical signal wire (beyond the fundamental 0 and 1) and captures concepts such as driving strength and impedance. Industry-standard hardware designs in SystemVerilog and VHDL rely on this modeling capability to describe bidirectional signals, propagate unknown values, identify driving conflicts, and describe optimization opportunities during logic synthesis.</p><p>(4) FIRRTL has the concept of "three forms" but does not clearly define their boundaries and to which parts of the design flow they apply <ref type="bibr" target="#b13">[14]</ref>. It merely states that low FIRRTL maps directly to Verilog constructs with straightforward semantics.</p><p>Overall we observe that LLHD is a superset of FIRRTL. Since LLHD provides a Turing-complete modeling construct for a circuit, and FIRRTL does not, any FIRRTL representation can be translated into an equivalent LLHD representation, but not vice-versa. And by the same reasoning, modern HDLs such as SystemVerilog and VHDL cannot be fully mapped to FIRRTL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Verification IRs</head><p>CoreIR <ref type="bibr" target="#b18">[19]</ref> focuses on verification. It is designed to interact with higher-level functional descriptions of a circuit, such as Halide <ref type="bibr" target="#b20">[21]</ref> or Verilog (via Yosys <ref type="bibr" target="#b29">[30]</ref>), and represent these within a formal verification infrastructure. Additional steps allow designs to be mapped to Coarse-Grained Reconfigurable Arrays (CGRAs). CoreIR is geared specifically towards verification and deployment on FPGA-like devices, and as such does not cater to a full chip design flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Synthesis IRs</head><p>Many IRs beside FIRRTL are engineered to interact with hardware synthesizers. LNAST <ref type="bibr" target="#b27">[28]</ref> targets the representation of the synthesizable parts of an HDL circuit description in a language-agnostic AST. RTLIL <ref type="bibr" target="#b29">[30]</ref> is part of the "Yosys" open-source tool suite and focuses mainly on logic synthesis. It cannot represent higher-level constructs such as aggregate types or conditional assignment. µIR <ref type="bibr" target="#b23">[24]</ref> is geared towards HLS design flows and tries to capture entire accelerator architectures. These IRs are very specifically crafted to transport designs into a synthesizer and focus solely on this part of the flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Netlist IRs</head><p>IRs exist that aim at capturing the gate-level netlist of a circuit.</p><p>LGraph <ref type="bibr" target="#b26">[27]</ref> is an open-source graph representation of such a circuit, together with additional aspects of the physical design flow such as cell libraries, timing and power characteristics, and placement information. NetlistDB <ref type="bibr" target="#b5">[6]</ref> follows a similar goal. These IRs cater only to the very end of the hardware design flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We showed with Moore and LLHD that a small and concise multi-level intermediate representation can represent the complex semantics of real-world VHDL and SystemVerilog circuits throughout the complete hardware design process. Thanks to a novel three-level IR, we present a hardware design language that is effective from simulation, over formal verification, to synthesized netlists. We demonstrate the effectiveness of our design by outperforming commercial simulators on a variety of simulation tasks. We expect that our concise and well-defined hardware design language, crafted in the spirit of the most successful SSA-based compiler IRs, both minimal and still expressive enough for real-world use cases, will provide the foundation for an open hardware design stack that follows the impressive evolution of modern compilers in recent years.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure2. A testbench for an accumulator design as an illustrative example for LLHD code. See § 2 for a detailed description, Figure3for the corresponding SystemVerilog code, and Figure5for the implementation of @acc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. SystemVerilog source code for the testbench and accumulator LLHD code in Figure 2 and Figure 5, as an instructive example as to how HDL concepts map to LLHD. See § 3 for a detailed description.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>to Figure 2c, or Figure 3b to Figure 5m.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Optimization and transformation passes on the different IR levels of LLHD. See § 4 for a detailed description.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. An end-to-end example of how a simple accumulator design is lowered from Behavioural LLHD (left) to Structural LLHD (right). See § 4 for a detailed description of the individual steps. The processes @acc_ff and @acc_comb are lowered to entities through various transformations, and are eventually inlined into the @acc entity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Overview of the design units available in LLHD with their execution paradigm and timing model. See § 2.1 and § 2.4 for a detailed description.</figDesc><table><row><cell>Unit</cell><cell cols="2">Execution Timing</cell><cell>Use</cell></row><row><cell cols="4">Function control flow immediate user-def. SSA mapping</cell></row><row><cell>Process</cell><cell cols="2">control flow timed</cell><cell>behavioural circ. desc.</cell></row><row><cell>Entity</cell><cell>data flow</cell><cell>timed</cell><cell>structural circ. desc.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>3.2.1 Combinational Processes.Combinational processes describe a purely functional mapping from input signals to output signals, without any state-keeping elements such as flip-flops as side effect. Synthesizers can readily map such processes to logic gates. A process is combinational if there are no control flow paths that leave any of its output signals unassigned. Combinational processes can be mapped to a pure data flow graph of logic gates. Consider the always_comb process in Figure</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>1 JIT 2 Comm.3   </figDesc><table><row><cell>Gray Enc./Dec.</cell><cell cols="3">17 12.6 M 9740 6.33</cell><cell>6.07</cell></row><row><cell>FIR Filter</cell><cell>20</cell><cell cols="2">5 M 4430 10.35</cell><cell>14.60</cell></row><row><cell>LFSR</cell><cell>30</cell><cell cols="2">10 M 2350 14.53</cell><cell>14.10</cell></row><row><cell>Leading Zero C.</cell><cell>52</cell><cell cols="2">1 M 11000 3.23</cell><cell>7.84</cell></row><row><cell>FIFO Queue</cell><cell>102</cell><cell cols="2">1 M 1370 5.92</cell><cell>5.55</cell></row><row><cell>CDC (Gray)</cell><cell>108</cell><cell cols="2">1 M 1380 8.72</cell><cell>6.45</cell></row><row><cell>CDC (strobe)</cell><cell>122</cell><cell cols="2">3.5 M 1570 9.39</cell><cell>6.11</cell></row><row><cell>RR Arbiter</cell><cell>159</cell><cell cols="2">5 M 49400 10.92</cell><cell>25.54</cell></row><row><cell>Stream Delayer</cell><cell>219</cell><cell>2.5 M</cell><cell>477 4.28</cell><cell>4.99</cell></row><row><cell>RISC-V Core</cell><cell>3479</cell><cell cols="2">1 M 24000 23.44</cell><cell>4.47</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Comparison against other hardware-targeted intermediate representations. Most other IRs are geared towards synthesis and the resulting netlists. See Section 6.2 for a detailed description.</figDesc><table><row><cell>IR</cell><cell>No. of Levels</cell><cell>Turing-</cell><cell>Complete</cell><cell>Verification (e.g., assertions)</cell><cell>9-Valued Logic (IEEE 1164 [2])</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 .</head><label>4</label><figDesc>Size efficiency of the human-readable text representation, an estimate of a prospective bitcode, and the inmemory data structures of LLHD. See § 6.3 for details.</figDesc><table><row><cell></cell><cell>SV</cell><cell></cell><cell>LLHD [kB]</cell><cell></cell></row><row><cell>Design</cell><cell cols="4">[kB] Text Bitcode 1 In-Mem.</cell></row><row><cell>Gray Enc./Dec.</cell><cell cols="2">3.0 11.9</cell><cell>3.6</cell><cell>41.8</cell></row><row><cell>FIR Filter</cell><cell cols="2">1.2 12.9</cell><cell>3.8</cell><cell>46.7</cell></row><row><cell>LFSR</cell><cell>2.4</cell><cell>4.9</cell><cell>1.8</cell><cell>18.4</cell></row><row><cell>Leading Zero C.</cell><cell cols="2">4.6 97.4</cell><cell>21.8</cell><cell>309.1</cell></row><row><cell>FIFO Queue</cell><cell cols="2">7.1 20.5</cell><cell>6.5</cell><cell>71.3</cell></row><row><cell>CDC (Gray)</cell><cell cols="2">8.5 38.1</cell><cell>12.5</cell><cell>129.5</cell></row><row><cell>CDC (strobe)</cell><cell cols="2">6.3 17.7</cell><cell>6.0</cell><cell>63.3</cell></row><row><cell>RR Arbiter</cell><cell cols="2">11.2 39.4</cell><cell>9.9</cell><cell>129.8</cell></row><row><cell>Stream Delayer</cell><cell cols="2">12.2 18.7</cell><cell>6.7</cell><cell>68.6</cell></row><row><cell>RISC-V Core</cell><cell cols="2">174.4 349.4</cell><cell>93.6</cell><cell>1096.3</cell></row><row><cell>1 estimated</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Project Website: http://llhd.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Language Reference Manual: http://llhd.io/spec.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">http://v8.dev</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>entity @acc_ff (…) -&gt; (…) { %delay = const time 1ns %clkp = prb i1$ %clk %dp = prb i32$ %d reg i32$ %q, %dp rise %clkp after %delay } entity @acc (i1$ %clk, i32$ %x, i1$ %en) -&gt; (i32$ %q) { %zero = const i32 0 %d = sig i32 %zero %q = sig i32 %zero inst @acc_ff (i1$ %clk, i32$ %d) -&gt; (i32$ %q) inst @acc_comb (i32$ %q, i32$ %x, i1$ %en) -&gt; (i32$ %d) } proc @acc_ff (i1$ %clk, i32$ %d) -&gt; (i32 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">VHDL Language Reference Manual</title>
		<idno>IEEE 1076-2008</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Standard Multivalue Logic System for VHDL Model Interoperability</title>
		<idno>IEEE 1164. 1993</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Standard for Verilog Hardware Description Language</title>
		<idno>IEEE 1364. 2005</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">SystemVerilog Unified Hardware Design, Specification, and Verification Language</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detecting equality of variables in programs</title>
		<author>
			<persName><surname>Bowen Alpern</surname></persName>
		</author>
		<author>
			<persName><surname>Mark N Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zadeck</forename><surname>Kenneth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGPLAN-SIGACT symposium on Principles of programming languages</title>
				<meeting>the 15th ACM SIGPLAN-SIGACT symposium on Principles of programming languages</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">netlistDB: Intermediate format for digital hardware representation with graph database API</title>
		<author>
			<persName><forename type="first">Anon</forename></persName>
		</author>
		<ptr target="https://github.com/HardwareIR/netlistDB" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Chisel: constructing hardware in a scala embedded language</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huy</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsup</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Waterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rimas</forename><surname>Avižienis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wawrzynek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC Design Automation Conference</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1212" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Firm-a graph-based intermediate representation. KIT, Fakultät für Informatik</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Buchwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zwinkau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Code Generation in a Machine-independent Compiler</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Roderic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Cattell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><forename type="middle">W</forename><surname>Newcomer</surname></persName>
		</author>
		<author>
			<persName><surname>Leverett</surname></persName>
		</author>
		<idno type="DOI">10.1145/800229.806955</idno>
		<ptr target="https://doi.org/10.1145/800229.806955" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1979 SIGPLAN Symposium on Compiler Construction</title>
				<meeting>the 1979 SIGPLAN Symposium on Compiler Construction<address><addrLine>Denver, Colorado, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="65" to="75" />
		</imprint>
	</monogr>
	<note>SIGPLAN &apos;79)</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Bounded model checking using satisfiability solving. Formal methods in system design</title>
		<author>
			<persName><forename type="first">Edmund</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Biere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Raimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunshan</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="7" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Combining analyses, combining optimizations</title>
		<author>
			<persName><forename type="first">Cliff</forename><surname>Click</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">D</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="181" to="196" />
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
	<note>TOPLAS)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An efficient method of computing static single assignment form</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Cytron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeanne</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">N</forename><surname>Barry K Rosen</surname></persName>
		</author>
		<author>
			<persName><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zadeck</forename><surname>Kenneth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming languages</title>
				<meeting>the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming languages</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Formal hardware verification methods: A survey</title>
		<author>
			<persName><forename type="first">Aarti</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer-Aided Verification</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="5" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reusability is FIRRTL ground: Hardware construction languages, compiler frameworks, and transformations</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Izraelevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chick</forename><surname>Markley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Lawson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Computer-Aided Design</title>
				<meeting>the 36th International Conference on Computer-Aided Design</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Experiences in using cetus for source-to-source transformations</title>
		<author>
			<persName><forename type="first">Sang-Ik</forename><surname>Troy A Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayon</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Basumallik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rudolf</forename><surname>Upadhyaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">P</forename><surname>Eigenmann</surname></persName>
		</author>
		<author>
			<persName><surname>Midkiff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Languages and Compilers for Parallel Computing</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">LLVM: A compilation framework for lifelong program analysis &amp; transformation</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international symposium on Code generation and optimization: feedback-directed and runtime optimization</title>
				<meeting>the international symposium on Code generation and optimization: feedback-directed and runtime optimization</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nicolas Vasilache, and Oleksandr Zinenko</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uday</forename><surname>Bondhugula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacques</forename><surname>Pienaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">River</forename><surname>Riddle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Shpeisman</surname></persName>
		</author>
		<idno>arXiv:cs.PL/2002.11054</idno>
	</analytic>
	<monogr>
		<title level="m">MLIR: A Compiler Infrastructure for the End of Moore&apos;s Law</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Specification for the FIRRTL Language</title>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">M</forename><surname>Izraelevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<idno>UCB/EECS- 2016-9</idno>
		<ptr target="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-9.html" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>EECS Department, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CoSA: Integrated Verification for Agile Hardware Design</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Mattarei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makai</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><forename type="middle">G</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dillon</forename><surname>Huff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Formal Methods in Computer Aided Design (FMCAD). IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tree ssa-a new high-level optimization framework for the gnu compiler collection</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Novillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nord/USENIX Users Conference</title>
				<meeting>the Nord/USENIX Users Conference</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connelly</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédo</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acm Sigplan Notices</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="519" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Design and optimization of compilers</title>
		<author>
			<persName><forename type="first">Randall</forename><surname>Rustin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Prentice Hall</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">TCOL Ada: an intermediate representation for the DOD standard programming language</title>
		<author>
			<persName><forename type="first">Bruce</forename><forename type="middle">W</forename><surname>Bruce R Schatz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Leverett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">H</forename><surname>Newcomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">A</forename><surname>Reiner</surname></persName>
		</author>
		<author>
			<persName><surname>Wulf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>CARNEGIE-MELLON UNIV PITTSBURGH PA DEPT OF COMPUTER SCIENCE</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">µIR: An intermediate representation for transforming and optimizing the microarchitecture of application accelerators</title>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Sharifian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Hojabr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navid</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apala</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arrvindh</forename><surname>Shriraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="940" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Lambda: The ultimate imperative</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steele</forename><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Jay Sussman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>MASSACHUSETTS INST OF TECH CAMBRIDGE ARTIFICIAL INTELLIGENCE LAB</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A proposal for a standard synthesizable subset of SystemVerilog-2005: What the IEEE failed to define</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Sutherland</surname></persName>
		</author>
		<ptr target="http://sutherland-hdl.com/papers/2006-DVCon_SystemVerilog_synthesis_subset_paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Design Verification Conference</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">LGraph: A Unified Data Model and API for Productive Open-Source Hardware Design</title>
		<author>
			<persName><forename type="first">Sheng-Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><forename type="middle">T</forename><surname>Possignolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Ganpati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Renau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Second Workshop on Open-Source EDA Technology</title>
		<imprint>
			<date type="published" when="2019-11">2019. Nov 2019</date>
			<publisher>WOSET</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">LNAST: A Language Neutral Intermediate Representation for Hardware Description Languages</title>
		<author>
			<persName><forename type="first">Sheng-Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akash</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Renau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Second Workshop on Open-Source EDA Technology</title>
		<imprint>
			<date type="published" when="2019-11">2019. Nov 2019</date>
			<publisher>WOSET</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The RISC-V Instruction Set Manual</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Waterman</surname></persName>
			<affiliation>
				<orgName type="collaboration">CALIFORNIA UNIV BERKELEY DEPT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Yunsup</forename><surname>Lee</surname></persName>
			<affiliation>
				<orgName type="collaboration">CALIFORNIA UNIV BERKELEY DEPT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
			<affiliation>
				<orgName type="collaboration">CALIFORNIA UNIV BERKELEY DEPT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi</surname></persName>
			<affiliation>
				<orgName type="collaboration">CALIFORNIA UNIV BERKELEY DEPT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>User-Level ISA</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Yosys Manual, RTLIL specification</title>
		<author>
			<persName><forename type="first">Clifford</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="http://www.clifford.at/yosys/files/yosys_manual.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Florian</forename><surname>Zaruba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Schuiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Benini</surname></persName>
		</author>
		<idno>arXiv:cs.AR/2002.10143</idno>
		<title level="m">Snitch: A 10 kGE Pseudo Dual-Issue Processor for Area and Energy Efficient Execution of Floating-Point Intensive Workloads</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
