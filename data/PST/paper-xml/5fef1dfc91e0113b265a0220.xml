<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Making Pre-trained Language Models Better Few-shot Learners</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-12-31">31 Dec 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
							<email>tianyug@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University ‡ Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
							<email>fisch@csail.mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University ‡ Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
							<email>danqic@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University ‡ Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Making Pre-trained Language Models Better Few-shot Learners</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-12-31">31 Dec 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2012.15723v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent GPT-3 model (Brown et al.,  2020)  achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. Inspired by their findings, we study few-shot learning in a more practical scenario, where we use smaller language models for which fine-tuning is computationally efficient. We present LM-BFF-better few-shot fine-tuning of language models 1 -a suite of simple and complementary techniques for finetuning language models on a small number of annotated examples. Our approach includes (1) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and (2) a refined strategy for dynamically and selectively incorporating demonstrations into each context. Finally, we present a systematic evaluation for analyzing few-shot performance on a range of NLP tasks, including classification and regression. Our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting, achieving up to 30% absolute improvement, and 11% on average across all tasks. Our approach makes minimal assumptions on task resources and domain expertise, and hence constitutes a strong task-agnostic method for few-shot learning. 2 * The first two authors contributed equally.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The GPT-3 model recently introduced by Brown et al. <ref type="bibr">(2020)</ref> has made waves in the natural language processing (NLP) community by demonstrating astounding few-shot capabilities on myriad language understanding tasks. Given only a natural language prompt and a few demonstrations of the task, GPT-3 is able to make accurate predictions without updating any of the weights of its underlying language model. However, while remarkable, GPT-3 consists of 175B parameters, which makes it challenging to use in most real-wold applications.</p><p>In this work, we study a more practical scenario in which we only assume access to a moderatelysized language model such as BERT <ref type="bibr" target="#b11">(Devlin et al., 2019)</ref> or RoBERTa <ref type="bibr" target="#b21">(Liu et al., 2019)</ref>, and a small number of examples (i.e., a few-shot setting), which we can use to fine-tune the weights of the language model. This setting is appealing as (1) such models can be trained on typical research hardware;</p><p>(2) few-shot settings are realistic, as it is generally both easy to acquire a few annotations (e.g., 32 examples) and efficient to train on them; and (3) updating parameters typically leads to better performance. Inspired by GPT-3's findings, we propose several novel strategies for expanding its few-shot learning abilities to our setting, considering both classification and-for the first time-regression.</p><p>First, we follow the route of prompt-based prediction, first developed by the GPT series <ref type="bibr" target="#b28">(Radford et al., 2018</ref><ref type="bibr" target="#b29">(Radford et al., , 2019;;</ref><ref type="bibr" target="#b7">Brown et al., 2020)</ref> for zero-shot prediction and recently studied by PET <ref type="bibr">(Schick and Schütze, 2020a,b)</ref> for fine-tuning. Promptbased prediction treats the downstream task as a (masked) language modeling problem, where the model directly generates a textual response to a given prompt (see Figure <ref type="figure" target="#fig_1">1</ref>). Finding the right prompts, however, is an art-requiring both domain expertise and an understanding of the language model's inner workings. Even if significant effort is invested, manual prompts are likely to be suboptimal. We address this issue by introducing a novel decoding objective to automatically generate prompts given the few-shot training data using the generative T5 model <ref type="bibr" target="#b30">(Raffel et al., 2020)</ref>. This allows us to cheaply obtain effective prompts that match or outperform our manually chosen ones.</p><p>Second, we adopt the idea of incorporating Demonstration for label:positive Demonstration for label:negative Template Input Vocab V &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / 8 v 1 8 X M / 5 j j H z 8 B u 3 K q o b B y k b c g = " &gt; A A A B 9 H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y C u I i z J T F F 0 W 3 L i s Y B / Q D i W T Z t r Q J D M m m U I Z + h 1 u X C j i 1 o 9 x 5 9 + Y a W e h r Q c C h 3 P u 5 Z 6 c I O Z M G 9 f 9 d t b W N z a 3 t g s 7 x d 2 9 / Y P D 0 t F x S 0 e J I r R J I h 6 p T o A 1 5 U z S p m G G 0 0 6 s K B Y B p + 1 g f J f 5 7 Q l V m k X y 0 U x j 6 g s 8 l C x k B B s r + Z W e w G Z E M E 9 b s 0 q / V H a r 7 h x o l X g 5 K U O O R r / 0 1 R t E J B F U G s K x 1 l 3 P j Y 2 f Y m U Y 4 X R W 7 C W a x p i M 8 Z B 2 L Z V Y U O 2 n 8 9 A z d G 6 V A Q o j Z Z 8 0 a K 7 + 3 k i x 0 H o q A j u Z Z d T L X i b + 5 3 U T E 9 7 6 K Z N x Y q g k i 0 N h w p G J U N Y A G j B F i e F T S z B R z G Z F Z I Q V J s b 2 V L Q l e M t f X i W t W t W 7 q l 4 / 1 M r 1 y 7 y O A p z C G V y A B z d Q h 3 t o Q B M I P M E z v M K b M 3 F e n H f n Y z G 6 5 u Q 7 J / A H z u c P S E y R t g = = &lt; / l a t e x i t &gt; Label space Y &lt; l a t e x i t s h a _ b a s e = " K i H z M q O e u x e j T C r D O m n C A P I = " &gt; A A A B H i c b V D L S s N A F L p r p f V Z d u B l t B X J S k K L o s u H F Z w T k D W U y n b R D J M M y m U O w I R t M O / / G S Z q F t h Y O J x z L / f M S L O l L b t b u w t r x u V X c L u s u f l A + P i q M J a E t E v J Q d j s K G e C t j T T n H Y j S X H g c d r x J r e p l S q V g o H v Q s o m A R L j G B t J L f a D A e E y T x l U K Y N T s D W i V O T i q Q o z k o f / W H I Y k D K j T h W K m e Y f a T b D U j H A L / V j R S N M J n h E e Y K H F D l J l n o O T o z y h D o T R P a J S p v z c S H C g C z w z m W Z U y q / u f Y u f u A k T U a y p I I t D f s y R D l H a A B o y S Y n m M M w k c x k R W S M J S b a F Q y J T j L X l X r N u a x d d c r j Y u j i K c w C m c g w P X I A a E I L C D z B M z C m z W X q x M x W r D y n W P A + v z B z e k b k = &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Label mapping M(Y)</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E w I V 6 u l O E 3 r 2 P 2 X P h M U 3 V S s y D n U = " &gt; A A A C A 3 i c b Z D L S s N A F I Z P 6 q 3 W W 9 S d b g Z b o b o o S V F 0 W X D j R q h g L 9 K G M p l O 2 q G T C z M T o Y S C G 1 / F j Q t F 3 P o S 7 n w b J 2 0 Q r f 4 w 8 P G f c 5 h z f j f i T C r L + j R y C 4 t L y y v 5 1 c L a + s b m l r m 9 0 demonstrations into each input in the form of additional context. GPT-3's naive "in-context learning" paradigm picks up to 32 randomly sampled examples, and simply concatenates them with the input. This method is not guaranteed to prioritize the most informative demonstrations. Prioritizing informative demonstrations, however, is crucial, as (1) the number of usable demonstrations is bounded by the model's maximum input length; and (2) mixing numerous random examples from different classes together creates long contexts which can be hard to learn from. We develop a more refined strategy, where, for each input, we randomly sample a single example at a time from each class to create multiple, minimal demonstration sets. We also devise a novel sampling strategy that pairs inputs with similar examples, thereby providing the model with more discriminative comparisons.</p><formula xml:id="formula_0">5 R h L A h t k J C H o u 1 i S T k L a E M x x W k 7 E h T 7 L q c t d 3 S R 1 l t 3 V E g W B j d q H F H H x 4 O A e Y x g p a 2 e u V f q + l g N C e b J 1 a T 8 z b e T o 1 L P L F o V a y r 0 F + w M i p C p 3 j M / u v 2 Q x D 4 N F O F Y y o 5 t R c p J s F C M c D o p d G N J I 0 x G e E A 7 G g P s U + k k 0 x s m 6 F A 7 f e S F Q r 9 A o a n 7 c y L B v p R j 3 9 W d 6 Z J y v p a a / 9 U 6 s f L O n Y Q F U a x o Q G Y f e T F H K k R p I K j P B C W K j z V g I p j e F Z E h F p g o H V t B h 2 D P n / w X m t W K f V I 5 v a 4 W a 8 d Z H H n Y h w M o g w 1 n U I N L q E M D C N z D I z z D i / F g P B m v x t u s N W d k M 7 v w S 8 b 7 F 0 p n l z g = &lt; / l a t e x i t &gt; Vocab V &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / 8 v 1 8 X M / 5 j j H z 8 B u 3 K q o b B y k b c g = " &gt; A A A B 9 H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y C u I i z J T F F 0 W 3 L i s Y B / Q D i W T Z t r Q J D M m m U I Z + h 1 u X C j i 1 o 9 x 5 9 + Y a W e h r Q c C h 3 P u 5 Z 6 c I O Z M G 9 f 9 d t b W N z a 3 t g s 7 x d 2 9 / Y P D 0 t F x S 0 e J I r R J I h 6 p T o A 1 5 U z S p m G G 0 0 6 s K B Y B p + 1 g f J f 5 7 Q l V m k X y 0 U x j 6 g s 8 l C x k B B s r + Z W e w G Z E M E 9 b s 0 q / V H a r 7 h x o l X g 5 K U O O R r / 0 1 R t E J B F U G s K x 1 l 3 P j Y 2 f Y m U Y 4 X R W 7 C W a x p i M 8 Z B 2 L Z V Y U O 2 n 8 9 A z d G 6 V A Q o j Z Z 8 0 a K 7 + 3 k i x 0 H o q A j u Z Z d T L X i b + 5 3 U T E 9 7 6 K Z N x Y q g k i 0 N h w p G J U N Y A G j B F i e F T S z B R z G Z F Z I Q V J s b 2 V L Q l e M t f X i W t W t W 7 q l 4 / 1 M r 1 y 7 y O A p z C G V y A B z d Q h 3 t o Q B M I P M E z v M K b M 3 F e n H f n Y z G 6 5 u Q 7 J / A H z u c P S E y R t g = = &lt; / l a t e x i t &gt;</formula><p>We present a systematic evaluation for analyzing few-shot performance on 8 single-sentence and 7 sentence-pair NLP tasks, that cover both classification and regression. We observe that given a small number of training examples,</p><p>• Prompt-based fine-tuning largely outperforms standard fine-tuning;</p><p>• Our automatic prompt search matches or outperforms manual prompts;</p><p>• Incorporating demonstrations is effective for finetuning, and boosts few-shot performance.</p><p>Together, these simple-yet-effective methods contribute towards a dramatic improvement across all the tasks we evaluate on, as we obtain gains up to 30% absolute improvement (and 11% on average) compared to standard fine-tuning. For instance, we find that a RoBERTa-large model achieves around 90% accuracy on most binary sentence classification tasks, while only relying on 32 training examples. We refer to our approach as LM-BFF, better few-shot fine-tuning of language models: a strong, task-agnostic method for few-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Language model prompting The GPT series <ref type="bibr" target="#b28">(Radford et al., 2018</ref><ref type="bibr" target="#b29">(Radford et al., , 2019;;</ref><ref type="bibr" target="#b7">Brown et al., 2020)</ref> fueled the development of prompt-based few-shot learning approaches. In this work, we follow many of GPT-3's core concepts-including prompting and in-context learning-but explore them in smaller language models with fine-tuning.</p><p>We are also greatly inspired by the recent PET work <ref type="bibr">(Schick and Schütze, 2020a,b)</ref>, although they mainly focus on a semi-supervised setting in which a large set of unlabeled examples are provided. We only use a few annotated examples as supervision, and also explore automatically generated prompts and fine-tuning with in-context demonstrations. Furthermore, we deviate from their evaluation by providing a more rigorous framework, as we will discuss in detail in §3.3. Finally, there is a large body of work on prompting for mining knowledge from pre-trained language models <ref type="bibr" target="#b38">(Trinh and Le, 2018;</ref><ref type="bibr" target="#b26">Petroni et al., 2019;</ref><ref type="bibr" target="#b10">Davison et al., 2019;</ref><ref type="bibr">Talmor et al., 2020, inter alia)</ref>. Different from these works, we focus on leveraging prompting for fine-tuning on downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic prompt search</head><p>Other recent work has also identified that manually finding appropriate prompts is a significant challenge. <ref type="bibr" target="#b34">Schick and Schütze (2020a)</ref> and <ref type="bibr" target="#b33">Schick et al. (2020)</ref> explore ways of identifying label words automatically in their PET approach, however, none of these results lead to better performance compared to handpicked ones. In contrast, our method searches over both templates and label words, and is able to match or outperform our manual prompts. Several other attempts have been made in additionhowever, these approaches either operate in limited domains <ref type="bibr" target="#b19">(Jiang et al., 2020)</ref> such as finding patterns to express specific relations, e.g., (X, born in, ?), or require a large number of examples for gradient-guided search <ref type="bibr" target="#b35">(Shin et al., 2020)</ref>. Our approach aims to develop general-purpose search methods that rely only on a few annotations.</p><p>Fine-tuning of language models A number of recent studies have focused on better methods for fine-tuning language models <ref type="bibr" target="#b17">(Howard and Ruder, 2018;</ref><ref type="bibr" target="#b12">Dodge et al., 2020;</ref><ref type="bibr" target="#b20">Lee et al., 2020;</ref><ref type="bibr">Zhang et al., 2020)</ref>. These works mainly focus on optimization and regularization techniques to stabilize fine-tuning. Here we use standard optimization techniques, and instead mainly focus our efforts on better prompt-based fine-tuning in a more extreme few-shot setting. We anticipate that results of these studies are largely complementary to ours.</p><p>Few-shot learning Broadly speaking, our setting is also connected to other few-shot learning paradigms in NLP, including (1) semi-supervised learning <ref type="bibr" target="#b23">(Miyato et al., 2017;</ref><ref type="bibr" target="#b45">Xie et al., 2020)</ref>, where a set of unlabeled examples are given; (2) meta-learning <ref type="bibr" target="#b16">(Yu et al., 2018;</ref><ref type="bibr" target="#b16">Han et al., 2018;</ref><ref type="bibr">Bansal et al., 2020a,b;</ref><ref type="bibr" target="#b2">Bao et al., 2020)</ref>, where a set of auxiliary tasks are given; and (3) intermediate training <ref type="bibr" target="#b27">(Phang et al., 2018;</ref><ref type="bibr">Yin et al., 2020)</ref>, where a related, intermediate task is given. We deviate from these settings by making minimal assumptions about available resources: we only assume a few annotated examples and a pre-trained language model. Our focus is on understanding how far we can push without any other advantages.</p><p>3 Problem Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task formulation</head><p>In this work, we assume access to a pre-trained language model L that we wish to fine-tune on a new task D with a label space Y. For this new task, we only assume K training examples per class,<ref type="foot" target="#foot_2">3</ref> such that the total number of examples is K tot = K × |Y|, and D train = {(x i in , y i )} Ktot i=1 . Our goal is then to develop task-agnostic learning strategies that generalize well to examples from the task's unseen test set, (x test in , y test ) ∼ D test . For model selection and hyper-parameter tuning, we assume a development set D dev , of the same size, i.e., |D dev | = K tot . This distinction is important: using a larger development set confers a significant advantage (Appendix C), and subverts our initial goal of learning from limited data. On the other hand, <ref type="bibr">Schick and Schütze (2020a,b)</ref> assume no access to a development set and adopt a fixed set of hyper-parameters based on practical considerations. This is akin to "shooting in the dark" on a setting that we show can have quite unintuitive outcomes. Apart from D train and D dev , we make minimal data assumptions, and do not use any additional data sources, supervised or not. For all of the following experiments (unless specified otherwise), we use L = RoBERTa-large and set K = 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation datasets</head><p>We conduct a systematic study across 8 singlesentence and 7 sentence-pair English tasks (see Table <ref type="table" target="#tab_0">1</ref>). Our evaluation is derived from 8 tasks from the GLUE benchmark <ref type="bibr" target="#b41">(Wang et al., 2019)</ref>, SNLI <ref type="bibr" target="#b6">(Bowman et al., 2015)</ref>, and 6 other popular sentence classification tasks (SST-5, MR, CR, MPQA, Subj, TREC). See Appendix A for details. We coarsely divide our tasks into two categories:</p><p>1. Single-sentence tasks. The goal is to make a prediction based on an input sentence x in = x 1 , such as whether a movie review is positive or not. Our tasks range from sentiment analysis to question classification and grammaticality assessment. We interchangeably refer to the single-sentence inputs to this task as &lt;S 1 &gt;.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Sentence-pair tasks. The goal is to make a prediction based on a pair of input sentences x in = (x 1 , x 2 ), such as predicting the relationship between them. Our tasks include natural language inference and paraphrase detection. We interchangeably refer to the sentence-pair inputs to this task as (&lt;S 1 &gt;, &lt;S 2 &gt;).</p><p>Note that we limit ourselves to datasets with relatively short inputs (i.e., single sentences), or with a fairly small number of classes (for classification).</p><p>We discuss limitations and future work in §8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation protocol</head><p>Systematically evaluating few-shot performance can be tricky. It is well-known that fine-tuning on small datasets can suffer from instability <ref type="bibr" target="#b12">(Dodge et al., 2020;</ref><ref type="bibr">Zhang et al., 2020)</ref> and results may change dramatically given a new split of data. To account for this, for every experiment we measure average performance across 5 different randomly sampled D train and D dev splits, using a fixed set of seeds S seed . Note that this issue has also been discussed by Schick and Schütze (2020b)-they suggested using a fixed set of 32 examples for training. We argue that sampling multiple D train and D dev gives a more robust measure of a model's performance, and a better estimate of the variance. We also observe that hyper-parameters (as simple as the learning rate or batch size) can make a significant difference across model settings or data splits. For each set {D s train , D s dev }, s ∈ S seed , we perform a grid search over multiple hyper-parameters, and take the best one as measured on D s dev . More details can be found in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Prompt-based Fine-tuning</head><p>We focus on classification and regression tasks, where the input x in is either a sentence x in = x 1 , or a pair of sentences x in = (x 1 , x 2 ), and has a label space Y. Given a masked language model L,<ref type="foot" target="#foot_3">4</ref> we first convert x in to a fixed token sequence x and L then maps x to a sequence of hidden vectors</p><formula xml:id="formula_1">{h k ∈ R d }.</formula><p>In the standard fine-tuning procedure, we usually take xsingle =</p><formula xml:id="formula_2">[CLS]x 1 [SEP] or xpair = [CLS]x 1 [SEP]x 2 [SEP]. For down- stream classification tasks, we train a task-specific head softmax(W o h [CLS]</formula><p>), where h is the hidden vector of [CLS], and W o ∈ R |Y|×d is a set of randomly initialized parameters introduced at the start of fine-tuning. All of the parameters of L as well as W o are jointly fine-tuned to maximize the log-probability of the correct label. Similarly, for a regression task, we can introduce w o ∈ R d and optimize the mean squared error between w o • h [CLS] and the gold label. In either case, the number of new parameters can be substantial-for example, a simple binary classification task will introduce 2,048 new parameters for a RoBERTa-large model-making it challenging to learn from a small amount of annotated data (e.g., 32 examples).</p><p>An alternative approach to solving this problem is prompt-based fine-tuning, in which the language model is directly tasked with "auto-completing" natural language prompts with the correct outputs. For instance, we can formulate a binary sentiment classification task as a prompt with an input sentence x 1 (e.g., "No reason to watch it.") as:</p><formula xml:id="formula_3">x prompt = [CLS]x 1 It was [MASK]. [SEP]</formula><p>and let L decide whether it is better to fill in "great" (positive) or "terrible" (negative) for the masked position. Next, we formalize this approach for classification and regression ( §4.1 and §4.2), and discuss the importance of prompt selection ( §4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Classification</head><p>Let M : Y → V be an injective mapping connecting task labels to individual words 5 in our vocabulary V, where V is given by the pre-trained language model L. Then for each input x in , let the manipulation x prompt = T (x in ) be a masked language modeling input which contains exactly one [MASK] token. In this way, we can now cast our task as a language modeling task and model the probability of predicting class y ∈ Y as:</p><formula xml:id="formula_4">p(y | x in ) = p ([MASK] = M(y) | x prompt ) = exp w M(y) • h [MASK] y ∈Y exp w M(y ) • h [MASK] ,<label>(1)</label></formula><p>where h [MASK] is the hidden vector corresponding to the [MASK] position obtained by applying L on x prompt , and w v denotes the pre-softmax output vector for any word used in pre-training, v ∈ V.</p><p>When supervised examples {(x in , y)} are available, L can be fine-tuned to minimize cross entropy. It is important to note that this approach re-uses the pretrained output weights w v and does not introduce any new parameters for fine-tuning. It also reduces the gap between fine-tuning and pre-training, making it more effective to use in few-shot scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Regression</head><p>We assume the same basic setup as in classification, but now the label space Y is taken to be a bounded interval of the real line, [v l , v u ]. Inspired by recent work in prototypical few-shot regression <ref type="bibr" target="#b22">(Mettes et al., 2019)</ref>, we model the problem as an interpolation between two opposing poles {y l , y u } with values v l and v u , respectively. For instance, we can formulate our previous sentiment analysis task as a regression problem in the range [0, 1], where we slide between "terrible" (value 0) and "great" (value 1). In this way, we express y as a mixture model of these two quantities:</p><formula xml:id="formula_5">y = v l • p(y l | x in ) + v u • p(y u | x in ), (2)</formula><p>where p(y u | x in ) is the probability of choosing y u , and p(y l | x in ) = 1 − p(y u | x in ). We define M as a map of {y l , y u } to two words in our vocabulary, {w l , w u } ⊂ V, and model p(y u | x in ) as:</p><formula xml:id="formula_6">p(y u | x in ) = exp (w wu • h [MASK] ) w ∈{wu,w l } exp (w w • h [MASK] )</formula><p>.</p><p>(3)</p><p>5 More generally, we can consider a one-to-many mapping M : Y → 2 |Y| in which we map labels to sets of words. However, we did not find significant gains in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Template</head><p>Label  When supervised examples {(x in , y)} are available, we fine-tune L to minimize the KL-divergence between the inferred p(y u | x in ) of Eq. ( <ref type="formula">3</ref>) and the observed mixture weight, (y</p><formula xml:id="formula_7">− v l )/(v u − v l ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Manual prompts: the good and the bad</head><p>After formulating classification and regression tasks as language model problems, the remaining challenge is to construct the template T and label words M(Y)-we refer to these two things together as a prompt P. Considering the previous sentiment analysis task again, how can we tell that appending the short sentence "It was <ref type="bibr">[MASK]</ref>." after the input example x 1 , and choosing between the completions (great, terrible), will be a good choice for the task? Previous works <ref type="bibr">(Schick and Schütze, 2020a,b)</ref> hand-craft both the templates and label words. This usually requires domain expertise and trial and error. Table <ref type="table">B</ref>.1 summarizes the manual templates and label words chosen for each dataset. These templates were designed by intuition, and by considering what formats have been found to work well for similar tasks in the literature.</p><p>To better understand what constitutes a good template or set of label words, we conduct a pilot study on SST-2 and SNLI. Table <ref type="table" target="#tab_2">2</ref> shows that different prompts can have marked differences in final accuracy. Specifically, when a template is fixed, the better the label words match the "semantic classes", the better the final accuracy is (great/terrible &gt; good/bad &gt; cat/dog). In extreme cases where we swap plausible label words (e.g., terrible/great), we achieve the worst overall performance. <ref type="foot" target="#foot_4">6</ref> Furthermore, with the same set of label words, even a small change in the template (e.g., removing punctuation) can make a difference. More drastically, for SNLI, if we put [MASK]at the end, or swap sentence order, we observe a 10-15% accuracy drop.</p><p>The above evidence clearly underlines the importance of selecting good templates and label words. Searching for prompts, however, is hard, as the search space can be very large, especially for the template. Even worse, we only have a few examples to use to guide our search, which can easily overfit. We will address these issues next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Automatic Prompt Generation</head><p>We now explore principled ways of automating the search process for label words ( §5.1) and templates ( §5.2). Our goals are to reduce the human efforts to design prompts, and to find more optimal settings than those that we manually choose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic selection of label words</head><p>We first study how to construct a label word mapping M given a fixed template T . In the following, we assume a classification task, but the process for regression is analogous. Our goal is to select M * that maximizes accuracy on D dev after finetuning. Naively searching all possible assignments, however, is (1) generally intractable, as the search space is exponential in the number of classes; and</p><p>(2) prone to overfitting, as we will tend to uncover spurious correlations given only a few annotations. As a simple solution, for each class c ∈ Y, we construct a pruned set V c ⊂ V of the top k vocabulary words based on their conditional likelihood using the initial L. That is, let D c train ⊂ D train be the subset of all examples of class c. We take V c as</p><formula xml:id="formula_8">Top-k v∈V    x in ∈D c train log P L [MASK] = v | T (x in )    ,<label>(4)</label></formula><p>where P L denotes the output probability distribution of L. We then find the top n assignments over the pruned space that maximize accuracy on D train (Both n and k are hyper-parameters, see Appendix B). As the ranking of assignments before fine-tuning is not necessarily preserved after finetuning, we fine-tune all top n assignments, and re-rank the best one using D dev . This approach is similar to the automatic verbalizer search methods in Schick and Schütze (2020a); <ref type="bibr" target="#b33">Schick et al. (2020)</ref>, except that we use a much simpler search process (brute-force) and also apply re-ranking-which we find to be quite helpful for our final performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Automatic generation of templates</head><p>Next, we study how to generate a diverse set of templates {T } automatically from a fixed set of label words M(Y). To address this challenging problem, we propose to use T5 <ref type="bibr" target="#b30">(Raffel et al., 2020)</ref>, a large pre-trained text-to-text Transformer. T5 is pre-trained on a mixture of unsupervised objectives. One of its most effective unsupervised objectives is to replace one or more spans of contiguous tokens with a sentinel token (e.g. &lt;X&gt; or &lt;Y&gt;), and then to generate the missing spans as its output. For example, given the input "Thank you &lt;X&gt; me to your party &lt;Y&gt; week", T5 is trained to generate the sequence "&lt;X&gt; for inviting &lt;Y&gt; last &lt;Z&gt;", meaning that "for inviting" is the replacement for &lt;X&gt; and "last" is the replacement for &lt;Y&gt;. This is well suited for prompt generation: we can simply take input sentence(s) from D train and let the T5 model construct the prompt, without having to specify a pre-defined number of tokens for T .</p><p>Given an input example (x in , y) ∈ D train , denote &lt;X&gt; and &lt;Y&gt; as T5 mask tokens, and M(y) as the label word for y. We then consider the following simple conversions, denoted as T g (x in , y), as the inputs to the T5 model: 7</p><formula xml:id="formula_9">&lt;S 1 &gt; −→ &lt;X&gt; M(y) &lt;Y&gt; &lt;S 1 &gt; &lt;S 1 &gt; −→ &lt;S 1 &gt; &lt;X&gt; M(y) &lt;Y&gt; &lt;S 1 &gt;, &lt;S 2 &gt; −→ &lt;S 1 &gt; &lt;X&gt; M(y) &lt;Y&gt; &lt;S 2 &gt;</formula><p>We then rely on T5 to fill in the placeholders, &lt;X&gt; and &lt;Y&gt;. When decoding, our goal is to find an output that can work well for all examples in D train . Formally, we want the template that maximizes (x in ,y)∈D train log P T5 (T | T g (x in , y)) where P T5 denotes the output distribution of the pre-trained T5. It can be decomposed according to:</p><formula xml:id="formula_10">|T | j=1 (x in ,y)∈D train log P T5 t j | t 1 , ..., t j−1 , T g x in , y , (5)</formula><p>where (t 1 , . . . , t |T | ) are the template tokens. 7 We consider putting the label word both before and after the input sentence for single-sentence tasks. However, we find that it is always better to put the label words in the middle (between the two sentences) for sentence-pair tasks.  We use beam search to decode multiple template candidates. Concretely, we use a wide beam width (e.g., 100) to cheaply obtain a large set of diverse templates. We then fine-tune each generated template on D train and use D dev to either pick the single template with the best performance (Table <ref type="table" target="#tab_3">3</ref>); or pick the top k templates to use as an ensemble (Table 4). Though it might appear to be expensive to fine-tune the model on each individual template, this is fast in practice due to the small size of D train , and is fully automated, making it easy to use compared to manually tuning prompts for each dataset. Figure <ref type="figure" target="#fig_3">2</ref> illustrates the template generation process.</p><formula xml:id="formula_11">I V 6 u l O E 3 r 2 P 2 X P h M U 3 V S s y D n U = " &gt; A A A C A 3 i c b Z D L S s N A F I Z P 6 q 3 W W 9 S d b g Z b o b o o S V F 0 W X D j R q h g L 9 K G M p l O 2 q G T C z M T o Y S C G 1 / F j Q t F 3 P o S 7 n w b J 2 0 Q r f 4 w 8 P G f c 5 h z f j f i T C r L + j R y C 4 t L y y v 5 1 c L a + s b m l r m 9 0 5 R h L A h t k J C H o u 1 i S T k L a E M x x W k 7 E h T 7 L q c t d 3 S R 1 l t 3 V E g W B j d q H F H H x 4 O A e Y x g p a 2 e u V f q + l g N C e b J 1 a T 8 z b e T o 1 L P L F o V a y r 0 F + w M i p C p 3 j M / u v 2 Q x D 4 N F O F Y y o 5 t R c p J s F C M c D o p d G N J I 0 x G e E A 7 G g P s U + k k 0 x s m 6 F A 7 f e S F Q r 9 A o a n 7 c y L B v p R j 3 9 W d 6 Z J y v p a a / 9 U 6 s f L O n Y Q F U a x o Q G Y f e T F H K k R p I K j P B C W K j z V g I p j e F Z E h F p g o H V t B h 2 D P n / w X m t W K f V I 5 v a 4 W a 8 d Z H H n Y h w M o g w 1 n U I N L q E M D C N z D I z z D i / F g P B m v x t u s N W d k M 7 v w S 8 b 7 F 0 p n l z g = &lt; / l a t e x i t &gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Fine-tuning with Demonstrations</head><p>We now study whether we can leverage demonstrations when fine-tuning medium-sized LMs, and more importantly, find better ways to exploit them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Training examples as demonstrations</head><p>For most downstream tasks, GPT-3's naive approach to in-context learning simply involves concatenating the input with up to 32 examples randomly drawn from the training set. This approach is likely to be suboptimal as: (1) the number of available demonstrations is bounded by the model's maximum input length, and hence including uninformative demonstrations is wasteful;<ref type="foot" target="#foot_5">8</ref> (2) mixing numerous random examples from different classes together creates extremely long contexts which can be hard to leverage, especially for a smaller model.</p><p>To </p><formula xml:id="formula_12">T (x in ) ⊕ T (x (1) in , y (1) ) ⊕ • • • ⊕ T (x (|Y|) in , y (|Y|) ),</formula><p>where ⊕ denotes concatenation of input sequences and T * denotes the template with in-context augmentation (see Figure <ref type="figure" target="#fig_1">1</ref> for a concrete example) and is used as the input of L for fine-tuning. During both training and inference we sample multiple such demonstration sets for each input. In training we update on each instance independently, while in inference we ensemble predictions across all sets. This is reminiscent of Matching Networks <ref type="bibr" target="#b39">(Vinyals et al., 2016)</ref>, and more specifically BERT-PAIR <ref type="bibr" target="#b14">(Gao et al., 2019)</ref>, used in metalearning, but here we do not explicitly learn a similarity metric, and only focus on the end prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Sampling similar demonstrations</head><p>We observe that controlling the construction of the demonstration examples {(x in are all dramatically different-from each other, or from the query x in -then it becomes challenging for the language model to decipher meaningful patterns. As a result, the model may simply ignore the context, or even get confused by the additional examples. To address this issue, we devise a simple strategy in which we only sample examples that are semantically close to x in . Specifically, we use a pretrained Sentence-BERT <ref type="bibr" target="#b32">(Reimers and Gurevych, 2019)</ref> model to obtain embeddings for all input sentences (for sentence-pair tasks, we use the concatenation of the two sentences). For each query x in and label c, we sort all training instances by their similarity score cos(e(x in ), e(x)) for x ∈ D c train , and only sample from the top r% instances (we use r = 50) for each class to use as demonstrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>In the following we present our main few-shot results, and address several key research questions pertaining to our LM-BFF approach. More implementation details are in Appendix B.  <ref type="formula">2020</ref>) with RoBERTa-large (no parameter updates).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Main results</head><p>We conduct our experiments using a RoBERTalarge model for L and set K = 16. A comparison of using RoBERTa vs BERT can be found in Appendix D. For automatic prompt search, in our main table we report results obtained using automatic template search only (which consistently performs best, see Table <ref type="table">5</ref>). To put our results in perspective, we compare to a number of baselines, namely (1) standard fine-tuning in our few-shot setting;</p><p>(2) standard fine-tuning when using the full training set; (3) a majority baseline where we simply take the most frequent class (measured on the full training set); (4) prompt-based zero-shot prediction where we take our manual prompts and use L "out-of-the-box" without using any training examples; and (5) "GPT-3" in-context learning, where we use the same prompt-based zero-shot setting, but augment the context with randomly sampled demonstrations up to the maximum input length (and still use the smaller RoBERTa model as the underlying language model). <ref type="table" target="#tab_3">3</ref> shows our main experimental results. For all these results, we only consider using one prompt, either our manually designed (Table <ref type="table">B</ref>.1) or the best generated prompt. First, a zero-shot prediction based on our manual prompt achieves much better performance than the majority class, showing the pre-encoded knowledge in RoBERTa. We find that the GPT-3-style in-context learning, which simply packs training examples into the input together without fine-tuning, does not always improve over the zero-shot prediction. We hypothesize that smaller language models are not expressive enough to use off-the-shelf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single prompt Table</head><p>Second, prompt-based fine-tuning can greatly outperform standard fine-tuning, either using a manual, or our generated prompt. The only exception is CoLA (the linguistic acceptability task), which is an interesting case as the input may be a non-grammatical sentence, and never seen during pre-training. Generally, our automatically searched templates can achieve comparable or even higher results than manual ones. For tasks in which constructing strong manual templates is less intuitive (e.g., TREC, QNLI and MRPC), automatic templates can bring a significant improvement.</p><p>Third, using demonstrations in context leads to consistent gains in a majority of tasks. In summary, our final solution-fine-tuning with automatically searched templates and sampled demonstrations as context-achieves a 30% gain on SNLI compared to standard fine-tuning and 11% on average.</p><p>Ensemble An advantage of our automatic prompt search is that we can generate as many prompts as we want, train individual models, and create large ensembles. PET <ref type="bibr">(Schick and Schütze, 2020a,b)</ref> also ensembles multiple models trained with manual prompts. <ref type="foot" target="#foot_7">10</ref> In Table <ref type="table" target="#tab_4">4</ref>, we make a direct comparison of our searched prompts and the manual prompts taken from PET on MNLI and RTE (the only two datasets that we evaluate in common). <ref type="foot" target="#foot_8">11</ref>As it is shown, ensembling with multiple templates always improves performance. Also, an ensemble of the same number of automatic templates achieves comparable or better performance compared to the ensemble of PET's manual prompts. Moreover, increasing the number of automatic templates used for the ensemble brings further gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Analysis of generated prompts</head><p>Table <ref type="table">5</ref> gives the results of using manual vs. automatic prompts. For automatic prompts, we compare label word search only using manual templates (Auto L), template search only using manual label words (Auto T), and a joint variant (Auto T + L) in which we search both templates and label words one after the other (starting from a fixed set of manual label words, we apply Auto T, and then Auto L). In most cases, Auto T achieves comparable, or higher, performance than manual prompts, and is consistently the best variant. Auto L outperforms manual prompts on TREC and MRPC-but is considerably worse on SNLI. Auto T + L is often better than Auto L, but only sometimes better than  <ref type="table">5</ref>: Comparison between manual prompts, autogenerated templates (Auto T), auto-generated label words (Auto L), and their combination (Auto T + L).</p><p>SST-2 (positive/negative) Auto T. Table <ref type="table" target="#tab_6">6</ref> shows several outputs from Auto T and Auto L (A full list can be found in Appendix E). Auto T templates generally fit the context and label words well, but can contain potentially biased peculiarities (e.g., "{Yes/No}. That's right." in MRPC). For Auto L words, things are mixed: while most look intuitively reasonable, there are also some mysterious abnormalities (e.g., "At" for the "equivalent" class in MRPC).</p><formula xml:id="formula_13">Auto T M(Y) = {great, terrible} #1. &lt;S 1 &gt; A [MASK] one . #2. &lt;S 1 &gt; A [MASK] piece . #3. &lt;S 1 &gt; All in all [MASK] . Auto L T (x in ) = &lt;S 1 &gt; It was [MASK]. #1. irresistible/pathetic #2. wonderful/bad #3. delicious/bad MRPC (equivalent/not equivalent) Auto T M(Y) = {Yes, No} #1. &lt;S 1 &gt; . [MASK] ! &lt;S 2 &gt; #2. &lt;S 1 &gt; . [MASK] . This is the first time &lt;S 2 &gt; #3. &lt;S 1 &gt; . [MASK] . That's right . &lt;S 2 &gt; Auto L T (x in ) = &lt;S 1 &gt;[MASK], &lt;S 2 &gt; #1. Rather/Alas #2. At/Thus #3. Instead/Moreover</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Analysis of demonstration sampling</head><p>Table <ref type="table">7</ref> compares the performance of in-context fine-tuning using only random sampling with our filtered sampling approach using Sentence-BERT (SBERT), across a number of selected tasks. We acknowledge that Sentence-BERT is trained on a combination of SNLI and MNLI datasets, thus we also tried a simple sentence encoder using mean pooling over the hidden representations from RoBERTa-large. We find that in either case, using this sophisticated sampling process outperforms uniform sampling, highlighting the importance of sampling similar examples for demonstrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Sample efficiency</head><p>Taking a step back, it is interesting to see how standard fine-tuning and our method (LM-BFF) compare as K increases. Figure <ref type="figure" target="#fig_6">3</ref> illustrates the trends for SST-2 and SNLI. We can see that for a simple task such as SST-2 (also see MR, CR and MPQA in Table <ref type="table" target="#tab_3">3</ref>), despite using only 32 total examples, LM-BFF has already nearly saturated its performance-and achieves comparable results to standard fine-tuning over the entire dataset. On the harder task of SNLI, LM-BFF continues to improve as K increases while still maintaining a performance gap over standard fine-tuning, until the two approaches converge around K = 256.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>Reformulating NLP tasks as language modeling problems has exciting implications for few-shot learning, but also has limitations. First, while our collection of LM-BFF models greatly outperform standard fine-tuning, Table <ref type="table" target="#tab_3">3</ref> shows that, overall, the performance still substantially lags behind finetuning results obtained with many thousands of examples, especially for sentence-pair tasks. Additionally, like standard fine-tuning, our results also suffer from high variance-while the average performance is generally high, in the worst case (over different splits or random seeds), the performance can be up to several points lower. As described in §2, several recent studies have tried to counter instability in standard fine-tuning <ref type="bibr" target="#b12">(Dodge et al., 2020;</ref><ref type="bibr" target="#b20">Lee et al., 2020;</ref><ref type="bibr">Zhang et al., 2020)</ref> and we expect these methods to also help here.</p><p>With respect to our automatic prompt generation process, despite its effectiveness, we still find it practically challenging to substantially expand the search space, or generalize well based on only ap- proximately 32 examples. This is partly due to our lingering reliance on some manual design-either in the form of manual templates (label search) or in manual label words (template search). These minimal inputs allow us to get our search process off the ground, but do also bias it towards areas of the search space that we might have already imagined.</p><p>Finally, it is important to clarify that this approach favors certain tasks, namely those that (1) can be naturally posed as a "fill-in-the-blank" problems; (2) have input sequences that are not very long; and (3) do not contain many output classes. Issues ( <ref type="formula">2</ref>) and ( <ref type="formula">3</ref>) might be ameliorated with longercontext language models (e.g., <ref type="bibr" target="#b4">Beltagy et al., 2020)</ref>. For tasks such as structured prediction, however, issue (1) is more fundamental, as they are not straightforward to formulate using prompting alone. We leave it as an open question for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this paper we presented LM-BFF, a set of simple but effective techniques for fine-tuning language models using only a few examples. Our approach proposes to (1) use prompt-based finetuning with automatically searched prompts; and</p><p>(2) include dynamically selected task demonstrations (training examples) as part of the input context. We show through a series of systematic evaluations that our method outperforms vanilla finetuning by up to 30% (and 11% on average). We concluded by discussing the limitations of our approach, and posed open questions for future study. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Datasets</head><p>For SNLI <ref type="bibr" target="#b6">(Bowman et al., 2015)</ref> and datasets from GLUE <ref type="bibr" target="#b41">(Wang et al., 2019)</ref>, including SST-2 <ref type="bibr" target="#b36">(Socher et al., 2013)</ref>, CoLA <ref type="bibr" target="#b42">(Warstadt et al., 2019)</ref>, MNLI <ref type="bibr" target="#b44">(Williams et al., 2018)</ref>, QNLI <ref type="bibr" target="#b31">(Rajpurkar et al., 2016)</ref>, RTE <ref type="bibr" target="#b9">(Dagan et al., 2005;</ref><ref type="bibr" target="#b3">Bar-Haim et al., 2006;</ref><ref type="bibr" target="#b15">Giampiccolo et al., 2007;</ref><ref type="bibr" target="#b5">Bentivogli et al., 2009)</ref>, MRPC <ref type="bibr" target="#b13">(Dolan and Brockett, 2005)</ref>, QQP<ref type="foot" target="#foot_9">12</ref> and STS-B <ref type="bibr" target="#b8">(Cer et al., 2017)</ref>, we follow Zhang et al. ( <ref type="formula">2020</ref>) and use original development sets for testing. For the datasets which require a cross-validation evaluation-MR <ref type="bibr" target="#b25">(Pang and Lee, 2005)</ref>, CR <ref type="bibr" target="#b18">(Hu and Liu, 2004)</ref>, MPQA <ref type="bibr" target="#b43">(Wiebe et al., 2005)</ref>, Subj <ref type="bibr" target="#b24">(Pang and Lee, 2004</ref>)-we simply randomly sample 2,000 examples as the testing set and leave them out from training. For SST-5 <ref type="bibr" target="#b36">(Socher et al., 2013)</ref> and TREC <ref type="bibr" target="#b40">(Voorhees and Tice, 2000)</ref>, we use their official test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experimental Details</head><p>Hyperparameter selection For each set of {D s train , D s dev }, s ∈ S seed , we perform grid search of hyper-parameters and take the best combination on D s dev . Specifically, we take learning rates from {1e-5, 2e-5, 5e-5} and batch sizes from {2, 4, 8}. These numbers are picked by some pilot experiments on the GLUE datasets. We also use early stopping to avoid overfitting to the training data. For each trial, we train the model for 1,000 steps and validate the performance every 100 steps.</p><p>Prompt-based fine-tuning All of the manual templates and label words that we use in our experiments are provided in Table <ref type="table">B</ref>.1.</p><p>For automatic template search with T5, we take the T5-3B model <ref type="bibr" target="#b30">(Raffel et al., 2020)</ref>, which is the largest publicly available one that can fit on a single GPU. For automatically searching label words, we set k to 100 for all tasks except SST-5 and TREC. For SST-5 we set a smaller k = 30, as it is a 5way classification task. For TREC, we observe that filtering V c using conditional likelihood alone is still noisy, thus we set k = 1000, and then rerank V c according to the nearest neighbors of the original task labels and take the top 30 per class. We set n to 100 in all experiments.</p><p>We follow the hyper-parameter search described in Appendix A for the main experiments. Specially, for automatic search, due to the large number of trials, we take a fixed set of hyper-parameters: batch size of 8 and learning rate of 1e-5. Since the idea of prompt-based fine-tuning is to make the input and output distribution close to the pre-training, the implementation details are crucial. For templates, we put extra space before sentences if it is not at the beginning of the input. Also, we lowercase the first letter of the sentence if it is concatenated with a prefix (e.g., &lt;S 2 &gt; in Table <ref type="table">B</ref>.1). Also if one sentence is appended any punctuation (e.g., &lt;S 1 &gt; in Table <ref type="table">B</ref>.1), then the last character of the original sentence is discarded. Finally, we prepend a space for label words in M(Y). For example, we use " great" instead of "great" in the RoBERTa vocabulary, where " " stands for space.</p><p>Fine-tuning with demonstrations When finetuning with demonstrations, we sample 16 different sets of demonstrations for each input and average the predicted log probability for each class during inference. We find that further increasing the number of samples does not bring substantial improvement. Additional, we have tried different aggregation methods like taking the result with the maximum confidence and don't find a meaningful improvement. For sampling similar demonstrations, we take roberta-large-nli-stsb-meantokens<ref type="foot" target="#foot_10">13</ref> from Reimers and Gurevych (2019) as our default sentence embedding model. 16 and learning rate = 1e-5. We also experiment a variant that we sample a development set of 10 times larger than the training set. We can see that using larger development sets leads to better performance, and this is why we stick to |D train | = |D dev | in our few-shot learning experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C The Effect of Development Sets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Comparisons of BERT vs RoBERTa</head><p>Table <ref type="table">D</ref>.1 shows the results of using BERT-large (uncased) and RoBERTa-large in our settings. Our prompt-based fine-tuning with demonstrations also works for BERT on some datasets, but the results are mixed compared to RoBERTa. The main reason is that BERT adopts the use of segment embeddings to distinguish different parts of inputs (e.g., premise and hypothesis in NLI tasks). There are only 2 pre-trained segment embeddings, and when incorporating demonstrations, we need to introduce additional parameters, which is suboptimal in few-shot scenarios. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Generated Prompts</head><p>We show the top 3 automatically generated templates and label words for all tasks in Table <ref type="table">E</ref>.1. In general, most automatic templates are reasonable and grammatically correct. For the label words, the generated results look intuitive for most single sentence tasks. For other tasks, the automatic ones can be counterintuitive in some cases. It is still unclear why the language model picks these words and sometimes they actually work well. We leave this for future study. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Prompt-based fine-tuning with demonstrations (our approach)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of (a) masked language model (MLM) pre-training, (b) standard fine-tuning, and (c) our proposed LM-BFF using prompt-based fine-tuning with demonstrations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>MASK] one. &lt;S&gt; This is [MASK]. … &lt;S&gt; A [MASK] one. A fun ride. &lt;X&gt; great &lt;Y&gt; A pleasure to watch. &lt;X&gt; great &lt;Y&gt; No reason to watch. &lt;X&gt; terrible &lt;Y&gt; This junk. &lt;X&gt; terrible &lt;Y&gt; Fine-tune and evaluate positive: great, negative: terrible Label mapping M(Y) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our approach for template generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>address these issues, we propose a simple solution for incorporating training examples into the input context. At each training step, we randomly sample one example from each class and concatenate them with the current example x in . 9 As in §5.1, let D c train be the subset of all examples of class c. Then we sample (x x in = "A fun ride." and y = positive, we can write T (x (c) in , y (c) ) = "A fun ride. It was great." We combine the prompts to form T * (x in ):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Standard fine-tuning vs. our LM-BFF as a function of K (# instances per class). For lower K, our method consistently outperforms standard fine-tuning. As K increases the two methods gradually converge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The datasets evaluated in this work. |Y|: # of classes for classification tasks (with one exception: STS-B is a real-valued regression task over the interval [0, 5]). L: average # of words in input sentence(s). Note that we only sample D train and D</figDesc><table><row><cell>median value, and hence Ktot = 2K.</cell></row></table><note>dev of K × |Y| examples from the original training set in our few-shot experiments ( §3.3).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The impact of templates and label words on prompt-based fine-tuning (K = 16). Surprisingly, slight differences can have quite large effects.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Our main results using RoBERTa-large.</figDesc><table><row><cell></cell><cell>SST-2</cell><cell>SST-5</cell><cell>MR</cell><cell>CR</cell><cell>MPQA</cell><cell>Subj</cell><cell>TREC</cell><cell>CoLA</cell></row><row><cell></cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(Matt.)</cell></row><row><cell>Majority  †</cell><cell>50.9</cell><cell>23.1</cell><cell>50.0</cell><cell>50.0</cell><cell>50.0</cell><cell>50.0</cell><cell>18.8</cell><cell>0.0</cell></row><row><cell>Prompt-based zero-shot  ‡</cell><cell>83.6</cell><cell>35.0</cell><cell>80.8</cell><cell>79.5</cell><cell>67.6</cell><cell>51.4</cell><cell>32.0</cell><cell>2.0</cell></row><row><cell cols="9">"GPT-3" in-context learning 84.8 (1.3) 30.6 (0.9) 80.5 (1.7) 87.4 (0.8) 63.8 (2.1) 53.6 (1.0) 26.2 (2.4) -1.5 (2.4)</cell></row><row><cell>Fine-tuning</cell><cell cols="8">81.4 (3.8) 43.9 (2.0) 76.9 (5.9) 75.8 (3.2) 72.0 (3.8) 90.8 (1.8) 88.8 (2.1) 33.9 (14.3)</cell></row><row><cell>Prompt-based FT (man)</cell><cell cols="7">92.7 (0.9) 47.4 (2.5) 87.0 (1.2) 90.3 (1.0) 84.7 (2.2) 91.2 (1.1) 84.8 (5.1)</cell><cell>9.3 (7.3)</cell></row><row><cell>+ demonstrations</cell><cell cols="8">92.6 (0.5) 50.6 (1.4) 86.6 (2.2) 90.2 (1.2) 87.0 (1.1) 92.3 (0.8) 87.5 (3.2) 18.7 (8.8)</cell></row><row><cell>Prompt-based FT (auto)</cell><cell cols="8">92.3 (1.0) 49.2 (1.6) 85.5 (2.8) 89.0 (1.4) 85.8 (1.9) 91.2 (1.1) 88.2 (2.0) 14.0 (14.1)</cell></row><row><cell>+ demonstrations</cell><cell cols="8">93.0 (0.6) 49.5 (1.7) 87.7 (1.4) 91.0 (0.9) 86.5 (2.6) 91.4 (1.8) 89.4 (1.7) 21.8 (15.9)</cell></row><row><cell>Fine-tuning (full)  †</cell><cell>95.0</cell><cell>58.7</cell><cell>90.8</cell><cell>89.4</cell><cell>87.8</cell><cell>97.0</cell><cell>97.4</cell><cell>62.6</cell></row><row><cell></cell><cell>MNLI</cell><cell>MNLI-mm</cell><cell>SNLI</cell><cell>QNLI</cell><cell>RTE</cell><cell>MRPC</cell><cell>QQP</cell><cell>STS-B</cell></row><row><cell></cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(acc)</cell><cell>(F1)</cell><cell>(F1)</cell><cell>(Pear.)</cell></row><row><cell>Majority  †</cell><cell>32.7</cell><cell>33.0</cell><cell>33.8</cell><cell>49.5</cell><cell>52.7</cell><cell>81.2</cell><cell>0.0</cell><cell>-</cell></row><row><cell>Prompt-based zero-shot  ‡</cell><cell>50.8</cell><cell>51.7</cell><cell>49.5</cell><cell>50.8</cell><cell>51.3</cell><cell>61.9</cell><cell>49.7</cell><cell>-3.2</cell></row><row><cell cols="9">"GPT-3" in-context learning 52.0 (0.7) 53.4 (0.6) 47.1 (0.6) 53.8 (0.4) 60.4 (1.4) 45.7 (6.0) 36.1 (5.2) 14.3 (2.8)</cell></row><row><cell>Fine-tuning</cell><cell cols="8">45.8 (6.4) 47.8 (6.8) 48.4 (4.8) 60.2 (6.5) 54.4 (3.9) 76.6 (2.5) 60.7 (4.3) 53.5 (8.5)</cell></row><row><cell>Prompt-based FT (man)</cell><cell cols="8">68.3 (2.3) 70.5 (1.9) 77.2 (3.7) 64.5 (4.2) 69.1 (3.6) 74.5 (5.3) 65.5 (5.3) 71.0 (7.0)</cell></row><row><cell>+ demonstrations</cell><cell cols="8">70.7 (1.3) 72.0 (1.2) 79.7 (1.5) 69.2 (1.9) 68.7 (2.3) 77.8 (2.0) 69.8 (1.8) 73.5 (5.1)</cell></row><row><cell>Prompt-based FT (auto)</cell><cell cols="8">68.3 (2.5) 70.1 (2.6) 77.1 (2.1) 68.3 (7.4) 73.9 (2.2) 76.2 (2.3) 67.0 (3.0) 75.0 (3.3)</cell></row><row><cell>+ demonstrations</cell><cell cols="8">70.0 (3.6) 72.0 (3.1) 77.5 (3.5) 68.5 (5.4) 71.1 (5.3) 78.1 (3.4) 67.7 (5.8) 76.4 (6.2)</cell></row><row><cell>Fine-tuning (full)  †</cell><cell>89.8</cell><cell>89.5</cell><cell>92.6</cell><cell>93.3</cell><cell>80.9</cell><cell>91.4</cell><cell>81.7</cell><cell>91.9</cell></row></table><note>†: full training set is used (see dataset sizes in Table 1); ‡: no training examples are used; otherwise we use K = 16 (# examples per class) for few-shot experiments. We report mean (and standard deviation) performance over 5 different splits ( §3.3). Majority: majority class; FT: fine-tuning; man: manual prompt (Table B.1); auto: automatically searched templates ( §5.2). "GPT-3" in-context learning: using the in-context learning proposed in Brown et al. (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ensemble models using prompts from PET(Schick and Schütze, 2020a,b)  and our automatically generated prompts. PET uses 4 manual prompts for MNLI and 5 for RTE. We also use an equal number of prompts in |P ours | = |P PET | for a fair comparison.</figDesc><table><row><cell>Prompt-based Fine-tuning</cell><cell>MNLI</cell><cell>RTE</cell></row><row><cell>Our single manual P P PET P ours , |P ours | = |P PET | + demonstrations</cell><cell cols="2">68.3 (2.3) 69.1 (3.6) 71.9 (1.5) 69.2 (4.0) 70.4 (3.1) 73.0 (3.2) 74.0 (1.9) 71.9 (4.6)</cell></row><row><cell>P ours , |P ours | = 20 + demonstrations</cell><cell cols="2">72.7 (2.5) 73.1 (3.3) 75.4 (1.6) 72.3 (4.5)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Examples of our automatically generated templates (auto T) and label words (auto L).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table C .</head><label>C</label><figDesc>1 shows how the size of the development sets can affect the final performance of the model. For "No D dev ", we take the same hyper-parameters fromSchick and Schütze (2020a,b): batch size = &lt;S 1 &gt; It was [MASK] . positive: great, negative: terrible SST-5 &lt;S 1 &gt; It was [MASK] . v.positive: great, positive: good, neutral: okay, negative: bad, v.negative: terrible MR &lt;S 1 &gt; It was [MASK] . positive: great, negative: terrible CR &lt;S 1 &gt; It was [MASK] . positive: great, negative: terrible Subj &lt;S 1 &gt; This is [MASK] . subjective: subjective, objective: objective TREC [MASK] : &lt;S 1 &gt; abbr.: Expression, entity: Entity, description: Description human: Human, location: Location, numeric: Number COLA &lt;S 1 &gt; This is [MASK] . grammatical: correct, not grammatical: incorrect MNLI &lt;S 1 &gt; ? [MASK] , &lt;S 2 &gt; entailment: Yes, netural: Maybe, contradiction: No SNLI &lt;S 1 &gt; ? [MASK] , &lt;S 2 &gt; entailment: Yes, netural: Maybe, contradiction: No QNLI &lt;S 1 &gt; ? [MASK] , &lt;S 2 &gt; entailment: Yes, not entailment: No RTE &lt;S 1 &gt; ? [MASK] , &lt;S 2 &gt; entailment: Yes, not entailment: No MRPC &lt;S 1 &gt; [MASK] , &lt;S 2 &gt; equivalent: Yes, not equivalent: No QQP &lt;S 1 &gt; [MASK] , &lt;S 2 &gt; equivalent: Yes, not equivalent: No STS-B &lt;S 1 &gt; [MASK] , &lt;S 2 &gt; y u : Yes, y l : No Table B.1: Manual templates and label words that we used in our experiments. STS-B is a regression task-see the explanation of y u and y l in Section 4.2.</figDesc><table><row><cell>Task</cell><cell cols="2">Template</cell><cell></cell><cell>Label words</cell></row><row><cell>SST-2 Fine-tuning</cell><cell></cell><cell cols="3">SST-2 TREC SNLI MRPC</cell></row><row><cell cols="3">79.5 81.4 |D dev | = 10|D train | 83.5 No |D dev | |D dev | = |D train |</cell><cell>83.9 88.8 89.4</cell><cell>49.2 48.4 52.0</cell><cell>77.8 76.6 79.6</cell></row><row><cell cols="2">Prompt-based FT</cell><cell cols="3">SST-2 TREC SNLI MRPC</cell></row><row><cell cols="3">92.1 92.7 |D dev | = 10|D train | 93.0 No |D dev | |D dev | = |D train |</cell><cell>84.8 84.8 89.3</cell><cell>75.3 77.2 79.7</cell><cell>70.2 74.5 80.9</cell></row><row><cell cols="5">Table C.1: Impact of different sizes of development</cell></row><row><cell cols="5">sets. Standard deviations are omitted here to save space.</cell></row><row><cell>For No |D</cell><cell></cell><cell></cell><cell></cell></row></table><note>dev |, we use the same set of hyper-parameters inSchick and Schütze (2020a,b).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Table D.1: A comparison of BERT-large vs RoBERTalarge. We use manual prompts in these experiments.</figDesc><table><row><cell>BERT-large</cell><cell cols="4">SST-2 TREC SNLI MRPC</cell></row><row><cell>Fine-tuning</cell><cell>80.8</cell><cell>80.3</cell><cell>51.4</cell><cell>73.8</cell></row><row><cell>Prompt-based FT</cell><cell>85.6</cell><cell>81.3</cell><cell>59.2</cell><cell>66.8</cell></row><row><cell cols="2">+ demonstrations 86.4</cell><cell>79.6</cell><cell>58.6</cell><cell>71.0</cell></row><row><cell>RoBERTa-large</cell><cell cols="4">SST-2 TREC SNLI MRPC</cell></row><row><cell>Fine-tuning</cell><cell>81.4</cell><cell>88.8</cell><cell>48.4</cell><cell>76.6</cell></row><row><cell>Prompt-based FT</cell><cell>92.7</cell><cell>84.8</cell><cell>77.2</cell><cell>74.5</cell></row><row><cell cols="2">+ demonstrations 92.6</cell><cell>87.5</cell><cell>79.7</cell><cell>77.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>&lt;S 1 &gt; A [MASK] one . irresistible/pathetic &lt;S 1 &gt; A [MASK] piece . wonderful/bad &lt;S 1 &gt; All in all [MASK] . delicious/bad SST-5 (very positive/positive/neutral/negative/very negative) &lt;S 1 &gt; The movie is [MASK] . wonderful/remarkable/hilarious/better/awful &lt;S 1 &gt; The music is [MASK] . wonderful/perfect/hilarious/better/awful &lt;S 1 &gt; But it is [MASK] . unforgettable/extraordinary/good/better/terrible MR (positive/negative) It was [MASK] ! &lt;S 1 &gt; epic/terrible &lt;S 1 &gt; It's [MASK] . epic/awful &lt;S 1 &gt; A [MASK] piece of work . exquisite/horrible CR (positive/negative) &lt;S 1 &gt; It's [MASK] ! fantastic/horrible &lt;S 1 &gt; The quality is [MASK] . neat/pointless &lt;S 1 &gt; That is [MASK] . &lt;S 1 &gt; It's all [MASK] . everywhere/tragic &lt;S 1 &gt; It's [MASK] . everywhere/horrifying &lt;S 1 &gt; Is it [MASK] ? something/surreal TREC (abbreviation/entity/description/human/location/numeric) Q: [MASK] : &lt;S 1 &gt; Application/Advisor/Discussion/Culture/Assignment/Minute &lt;S 1 &gt; Why [MASK]? Production/AE/Context/Artist/Assignment/Minute &lt;S 1 &gt; Answer: [MASK] . Personality/Advisor/Conclusion/Hum/Assignment/Minute CoLA (grammatical/not grammatical) &lt;S 1 &gt; You are [MASK] . one/proof It is [MASK] . &lt;S 1 &gt; wrong/sad I am [MASK] . &lt;S 1 &gt; misleading/disappointing MNLI (entailment/neutral/contradiction) &lt;S 1 &gt; . [MASK] , you are right , &lt;S 2 &gt; Fine/Plus/Otherwise &lt;S 1 &gt; . [MASK] you're right &lt;S 2 &gt; There/Plus/Otherwise &lt;S 1 &gt; . [MASK] ! &lt;S 2 &gt; Meaning/Plus/Otherwise SNLI (entailment/neutral/contradiction) &lt;S 1 &gt; . [MASK] , no , &lt;S 2 &gt; Alright/Watch/Except &lt;S 1 &gt; . [MASK] , in this case &lt;S 2 &gt; Hi/Watch/Worse &lt;S 1 &gt; . [MASK] this time &lt;S 2 &gt; Regardless/Fortunately/Unless QNLI (entailment/not entailment) &lt;S 1 &gt; ? [MASK] . Yes , &lt;S 2 &gt; Okay/Nonetheless &lt;S 1&gt; ? [MASK] . It is known that &lt;S 2 &gt; Notably/Yet &lt;S 1 &gt; ? [MASK] , however , &lt;S 2 &gt; Specifically/Notably RTE (entailment/not entailment) &lt;S 1 &gt; . [MASK] , I believe &lt;S 2 &gt; Clearly/Yet &lt;S 1 &gt; . [MASK] , I think that &lt;S 2 &gt; Accordingly/meanwhile &lt;S 1 &gt; . [MASK] , I think &lt;S 2 &gt; So/Meanwhile MRPC (equivalent/not equivalent) &lt;S 1 &gt; . [MASK] ! &lt;S 2 &gt; Rather/Alas &lt;S 1 &gt; . [MASK] . This is the first time &lt;S 2 &gt; At/Thus &lt;S 1 &gt; . [MASK] . That's right . &lt;S 2 &gt; Instead/Moreover QQP (equivalent/not equivalent) &lt;S 1 &gt; ? [MASK] , but &lt;S 2 &gt; Me/Since &lt;S 1 &gt; ? [MASK] , please , &lt;S 2 &gt; Um/Best &lt;S 1 &gt; ? [MASK] , I want to know &lt;S 2 &gt; Ironically/Beyond STS-B (y u /y l ) &lt;S 1 &gt; . [MASK] sir &lt;S 2 &gt; Note/Next &lt;S 1 &gt; . [MASK] , it is not . &lt;S 2 &gt; Yesterday/meanwhile &lt;S 1 &gt; . [MASK] . It is &lt;S 2 &gt; Yeah/meanwhileTable E.1: Top 3 automatically generated templates and label words for all tasks based on one sample of K = 16 training examples. Note that automatic template results are based on manual label words and automatic label word results are based on manual templates provided in Table B.1.</figDesc><table><row><cell>Task</cell><cell>Auto template</cell><cell>Auto label words</cell></row><row><cell>SST-2</cell><cell>(positive/negative)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>magnificent/unacceptable</cell></row><row><cell cols="2">MPQA (positive/negative)</cell><cell></cell></row><row><cell></cell><cell>&lt;S 1 &gt; is [MASK] .</cell><cell>important/close</cell></row><row><cell></cell><cell>&lt;S 1 &gt;, [MASK] !</cell><cell>needed/bad</cell></row><row><cell></cell><cell>&lt;S 1 &gt;. [MASK] .</cell><cell>unexpected/shocking</cell></row><row><cell>Subj</cell><cell>(subjective/objective)</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Alternatively, language models' best friends forever.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Our implementation is publicly available at https:// github.com/princeton-nlp/LM-BFF.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">For regression tasks we partition the training set into two "clusters" according to being above or below the empirical</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">Note that it is also possible to use auto-regressive language models, but we choose to focus on MLMs in this work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4">It is unclear, however, why RoBERTa thinks that "cat" is more positive than "dog". The authors tend to disagree.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5">GPT-3 uses a context size of 2,048 while most smaller language models (e.g., RoBERTa) have a context size of 512.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6">We also explored sampling multiple examples per class, but did not observe any improvements.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7">They then use unlabeled data and distillation to get a single model, which is outside of our scope.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8">In the PET NLI templates, the hypothesis is put before the premise, which we actually found to be suboptimal. In our experiments, we swap the two and get better results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9">https://www.quora.com/q/quoradata/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_10">https://github.com/UKPLab/ sentence-transformers</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the members of Princeton, MIT, and Tsinghua NLP groups for their valuable feedback. TG is supported by a Graduate Fellowship at Princeton University and AF is supported by an NSF Graduate Research Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to few-shot learn across diverse natural language classification tasks</title>
		<author>
			<persName><forename type="first">Trapit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishikesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics (COLING)</title>
				<imprint>
			<date type="published" when="2020">2020a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Self-supervised meta-learning for few-shot natural language classification tasks</title>
		<author>
			<persName><forename type="first">Trapit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishikesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Few-shot text classification with distributional signatures</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menghua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The second PASCAL recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The fifth PASCAL recognizing textual entailment challenge</title>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<editor>TAC</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iñigo</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 11th International Workshop on Semantic Evaluation</title>
				<imprint>
			<date type="published" when="2017">2017. SemEval-2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The PASCAL recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the First International Conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual Object Classification, and Recognizing Textual Entailment</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Commonsense knowledge mining from pretrained models</title>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics (NAACL)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06305</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Third International Workshop on Paraphrasing (IWP2005)</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FewRel 2.0: Towards more challenging few-shot relation classification</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing</title>
				<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The third PASCAL recognizing textual entailment challenge</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<title level="m">How can we know what language models know? Transactions of the Association of Computational Linguistics (TACL)</title>
				<imprint>
			<date type="published" when="2020-06">Jun Araki, and Graham Neubig. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mixout: Effective regularization to finetune large-scale pretrained language models</title>
		<author>
			<persName><forename type="first">Cheolhyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanmo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: A robustly optimized BERT pretraining approach</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Elise van der Pol, and Cees Snoek</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Mettes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Hyperspherical prototype networks</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adversarial training methods for semisupervised text classification</title>
		<author>
			<persName><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Language models as knowledge bases?</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Févry</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01088</idno>
		<title level="m">Sentence encoders on STILTs: Supplementary training on intermediate labeled-data tasks</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>OpenAI</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>OpenAI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing</title>
				<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatically identifying words that can serve as labels for few-shot text classification</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics (COLING)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Timo Schick and Hinrich Schütze. 2020b. It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07676</idno>
		<idno>arXiv:2009.07118</idno>
		<imprint>
			<date type="published" when="2020">2020a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Exploiting cloze questions for few-shot text classification and natural language inference</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">AutoPrompt: Automatic prompt construction for masked language models</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">oLMpics-on what language model pre-training captures</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02847</idno>
		<title level="m">A simple method for commonsense reasoning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
				<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Bowman</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural network acceptability judgments. Transactions of the Association of Computational Linguistics (TACL)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="625" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
