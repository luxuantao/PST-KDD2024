<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zen-NAS: A Zero-Shot NAS for High-Performance Image Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ming</forename><surname>Lin</surname></persName>
							<email>ming.l@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Alibaba Group Bellevue</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pichao</forename><surname>Wang</surname></persName>
							<email>pichao.wang@alibaba-inc.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group Bellevue</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenhong</forename><surname>Sun</surname></persName>
							<email>zhenhong.szh@alibaba-inc.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hesen</forename><surname>Chen</surname></persName>
							<email>hesen.chs@alibaba-inc.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiuyu</forename><surname>Sun</surname></persName>
							<email>xiuyu.sxy@alibaba-inc.com</email>
							<affiliation key="aff4">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Qian</surname></persName>
							<email>qi.qian@alibaba-inc.com</email>
							<affiliation key="aff5">
								<orgName type="institution">Alibaba Group Bellevue</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Li</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rong</forename><surname>Jin</surname></persName>
							<email>jinrong.jr@alibaba-inc.com</email>
							<affiliation key="aff7">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Zen-NAS: A Zero-Shot NAS for High-Performance Image Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accuracy predictor is a key component in Neural Architecture Search (NAS) for ranking architectures. Building a high-quality accuracy predictor usually costs enormous computation. To address this issue, instead of using an accuracy predictor, we propose a novel zero-shot index dubbed Zen-Score to rank the architectures. The Zen-Score represents the network expressivity and positively correlates with the model accuracy. The calculation of Zen-Score only takes a few forward inferences through a randomly initialized network, without training network parameters. Built upon the Zen-Score, we further propose a new NAS algorithm, termed as Zen-NAS, by maximizing the Zen-Score of the target network under given inference budgets. Within less than half GPU day, Zen-NAS is able to directly search high performance architectures in a data-free style. Comparing with previous NAS methods, the proposed Zen-NAS is magnitude times faster on multiple server-side and mobile-side GPU platforms with stateof-the-art accuracy on ImageNet. Searching and training code as well as pre-trained models are available from https://github.com/idstcv/ZenNAS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The design of high-performance deep neural networks is a challenging task. Neural Architecture Search (NAS) methods facilitate this progress. There are mainly two key components, architecture generator and accuracy predictor, in existing NAS algorithms. The generator proposes potential high-performance networks and the predictor predicts their accuracies. Popular generators include uniform sampling <ref type="bibr" target="#b12">[13]</ref>, evolutionary algorithm <ref type="bibr" target="#b40">[41]</ref> and reinforcement learning <ref type="bibr" target="#b29">[30]</ref>. The accuracy predictors include bruteforce methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b40">41]</ref>, predictor-based methods <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b28">29]</ref> and one-shot methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>A major challenge of building a high-quality accuracy predictor is the enormous computational cost. Both brute-forced methods and predictor-based methods require to train considerable number of networks. The one-shot methods reduce the training cost via parameter sharing. Albeit being more efficient than brute-forced methods, the oneshot methods still need to train a huge supernet which is still computationally expensive. Recent studies also find that nearly all supernet-based methods suffer from model interfering <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b62">63]</ref> which degrades the quality of accuracy predictor <ref type="bibr" target="#b45">[46]</ref>. In addition, since the supernet must be much larger than the target network, it is difficult to search large target networks under limited resources. These issues make the one-shot methods struggling in designing high-performance networks.</p><p>To solve these problems, instead of using an expensive accuracy predictor, we propose an almost zero-cost proxy, dubbed Zen-Score, for efficient NAS. The Zen-Score measures the expressivity <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b30">31]</ref> of a deep neural network and positively correlates with the model accuracy. The computation of Zen-Score only takes a few forward inferences on randomly initialized network using random Gaussian inputs, making it extremely fast, lightweight and data-free. Moreover, Zen-Score deals with the scale-sensitive problem caused by Batch Normalization (BN) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35]</ref>, making it widely applicable to real-world problems.</p><p>Based on Zen-Score, we design a novel Zen-NAS algorithm. It maximizes the Zen-Score of the target network within inference budgets. Zen-NAS is a Zero-Shot method since it does not optimize network parameters during search <ref type="foot" target="#foot_0">1</ref> . We apply Zen-NAS to search optimal networks under various inference budgets, including inference latency, FLOPs (Floating Point Operations) and model size, and achieve the state-of-the-art (SOTA) performance on CIFAR-10/CIFAR-100/ImageNet, outperforming previous human-designed and NAS-designed models by a large margin. Zen-NAS is the first zero-shot method that achieves SOTA results on large-scale full-resolution ImageNet-1k dataset <ref type="bibr" target="#b11">[12]</ref> by the time of writing this work <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Our approach is inspired by recent advances in deep learning studies <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b59">60]</ref> which show that deep models are superior than shallow ones since deep models are more expressive under the same number of neurons. According to the bias-variance trade-off in statistical learning theory <ref type="bibr" target="#b18">[19]</ref>, increasing the expressivity of a deep network implies smaller bias error. When the size n of training dataset is large enough, the variance error will diminish as O(1/ √ n) → 0. This means that the generalization error is dominated by the bias error which could be reduced by more expressive networks. These theoretical results are well-aligned with large-scale deep learning practices <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>We summarize our main contributions as follows:</p><p>• We propose a novel zero-shot proxy Zen-Score for NAS. The proposed Zen-Score is computationally efficient and is proved to be scale-insensitive in the present of BN. A novel NAS algorithm termed Zen-NAS is proposed to search for networks with maximal Zen-Score in the design space. • Within half GPU day, the ZenNets designed by Zen-NAS achieve up to 83.6% top-1 accuracy on ImageNet that is as accurate as EfficientNet-B5 with inference speed magnitude times faster on multiple hardware platforms. To our best knowledge, Zen-NAS is the first zero-shot method that outperforms trainingbased methods on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We briefly review the related works. For comprehensive review of NAS, the monograph <ref type="bibr" target="#b42">[43]</ref> is referred to.</p><p>In the early days of NAS, brute-force methods are adopted to search architectures by directly training a network to obtain its accuracy. For example, the AmoebaNet <ref type="bibr" target="#b40">[41]</ref> conducts structure search on CIFAR-10 using Evolutionary Algorithm (EA) <ref type="bibr" target="#b19">[20]</ref> and then transfers the structure to ImageNet. It takes about 3150 GPU days of searching and achieves 74.5% top-1 accuracy on ImageNet. Inspired by the success of AmoebaNet, many EA-based NAS algorithms are proposed to improve the searching efficiency, such as EcoNAS <ref type="bibr" target="#b68">[69]</ref>, CARS <ref type="bibr" target="#b61">[62]</ref>, GeNet <ref type="bibr" target="#b56">[57]</ref> and PNAS <ref type="bibr" target="#b24">[25]</ref>. These methods search on down-sampled images or reduce the number of queries. Reinforced Learning is another popular generator (sampler) in NAS, including NAS-Net <ref type="bibr" target="#b69">[70]</ref>, Mnasnet <ref type="bibr" target="#b48">[49]</ref> and MetaQNN <ref type="bibr" target="#b2">[3]</ref>.</p><p>Both EA and RL based methods require lots of network training. To address this problem, the predictor-based methods encode architectures into high dimensional vectors. A number of architectures are trained to obtain their accuracies <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b28">29]</ref> and then are used as training data for learning accuracy predictor. The one-shot methods further reduce the training cost by training a big supernet. This framework is widely applied in many efficient NAS methods, including DARTS <ref type="bibr" target="#b25">[26]</ref>, SNAS <ref type="bibr" target="#b58">[59]</ref>, PC-DARTS <ref type="bibr" target="#b60">[61]</ref>, ProxylessNAS <ref type="bibr" target="#b5">[6]</ref>, GDAS <ref type="bibr" target="#b65">[66]</ref>, FBNetV2 <ref type="bibr" target="#b53">[54]</ref>, DNANet <ref type="bibr" target="#b20">[21]</ref>, Single-Path One-Shot NAS <ref type="bibr" target="#b12">[13]</ref>.</p><p>Although the above efforts have greatly reduced the searching cost, their top-1 accuracies on ImageNet are below 80.0%. The authors of OFANet <ref type="bibr" target="#b4">[5]</ref> noted that weightsharing suffers from model interfering. They propose a progressive-shrinking strategy to address this issue. The resultant OFANet achieves 80.1% accuracy after searching for 51.6 GPU days. EfficientNet <ref type="bibr" target="#b49">[50]</ref> is another high precision network designed by NAS. It takes about 3800 GPU days to search EfficientNet-B7 whose accuracy is 84.4%. In comparison, Zen-NAS achieves 83.6% accuracy while using magnitude times fewer resources.</p><p>A few on-going works are actively exploring zero-shot proxies for efficient NAS. However, these efforts have not delivered the SOTA results. In a recent empirical study, <ref type="bibr" target="#b0">[1]</ref> evaluates the performance of six zero-shot pruning proxies on NAS benchmark datasets. The synflow <ref type="bibr" target="#b50">[51]</ref> achieves best results in their experiments. We compare synflow with Zen-Score under fair settings and show that Zen-Score achieves +1.1% better accuracy on CIFAR-10 and +8.2% better accuracy on CIFAR-100. The concurrent work TE-NAS <ref type="bibr" target="#b6">[7]</ref> uses a combination of NTK-score and network expressivity as NAS proxy. Specifically, the TE-NAS estimates the expressivity by directly counting the number of active regions R N on randomly sampled images. In comparison, Zen-Score not only considers the distribution of linear regions but also considers the Gaussian complexity of linear classifier in each linear region, giving a more accurate estimation of network expressivity. The computation of Zen-Score is 20 to 28 times faster than TE-NAS score. In terms of performance, TE-NAS achieves 74.1% top-1 accuracy on ImageNet, lagging behind SOTA baselines. Zen-NAS achieves +9.5% better accuracy within similar searching cost. Another concurrent work NASWOT <ref type="bibr" target="#b32">[33]</ref> computes the architecture score according to the kernel matrix of binary activation patterns between mini-batch samples. It achieves similar top-1 accuracies on CIFAR-10/CIFAR-100 as TE-NAS.</p><p>It is important to distinguish Zen-NAS from unsupervised NAS (UnNAS) <ref type="bibr" target="#b23">[24]</ref>. In UnNAS, the network is trained to predict the pre-text tasks therefore it still requires parameter training. In Zen-NAS, no parameter training is required during the search.</p><p>In this work, we mostly focus on the vanilla network space described in the next section. Several previous works design networks in a more general irregular design space, such as DARTS <ref type="bibr" target="#b25">[26]</ref> and RandWire <ref type="bibr" target="#b57">[58]</ref>. Zen-NAS cannot be applied to these irregular design spaces since Zen-Score is not mathematically well-defined in irregular design spaces. In practice, the vanilla network space is a large enough space which covers most SOTA networks, including but not limited to ResNet, MobileNet and EfficientNet. Particularly, Zen-NAS outperforms DARTS-based methods by a significant margin on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Expressivity of Vanilla Network</head><p>In this section, we discuss how to measure the expressivity of vanilla convolutional neural network (VCNN) family, an ideal prototype for theoretical studies. We show that the expressivity of a network can be efficiently measured by its expected Gaussian complexity, or Φ-score for short. In the next section, we further show that for very deep networks, directly computing Φ-score incurs numerical overflow. This overflow can be addressed by adding BN layers and then rescaling the Φ-score by a constant. This new score is named as Zen-Score in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Notations</head><p>An L-layer neural network is formulated as a function f : R m0 → R m L where m 0 is the input dimension and m L is the output dimension. x 0 ∈ R m0 denotes the input image. Correspondingly, the output feature map of the t-th layer is denoted by x t . The t-th layer has m t−1 input channels and m t output channels. The convolutional kernel is θ t ∈ R mt×mt−1×k×k . The image resolution is H × W . The mini-batch size is B. The Gaussian distribution of mean µ and variance σ 2 is denoted by N (µ, σ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Vanilla Convolutional Neural Network</head><p>The vanilla convolutional neural network (VCNN) is a widely used prototype in theoretical studies <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b13">14]</ref>. The main body of a vanilla network is stacked by multiple convolutional layers. Each layer consists of one convolutional operator followed by RELU activation. All other components are removed from the backbone, including residual link and Batch Normalization. After the main body, global average pool layer (GAP) reduces the feature map resolution to 1x1, followed by a fully-connected layer. At the end a soft-max operation converts the network output to label prediction. Given the input x and network parameters θ, f (x|θ) refers to the output of the main body of the network, that is the feature map before the GAP layer (pre-GAP layer). We measure the network expressivity with respect to pre-GAP because it contains most of the information we need.</p><p>Modern networks use auxiliary structures such as residual link , Batch Normalization and self-attention block <ref type="bibr" target="#b15">[16]</ref>. These structures will not significantly affect the representation power of networks. For example, BN layer can be merged into convolutional kernel via kernel fusion. Selfattention linearly combines existing feature maps hence spans the same subspace. Therefore, these structures are temporarily removed when measuring network expressivity and then added back in training and testing stages. For non-RELU activation functions, they are replaced by RELU in a similar way. These simple modifications make our method applicable to a majority of non-VCNN models widely used in practice. In fact, nearly all single-branch feed-forward networks can be converted to vanilla network by the aforementioned modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Φ-Score as Proxy of Expressivity</head><p>Given a VCNN f (x|θ), we propose a novel numerical index Φ-score as a proxy of its expressivity. The definition of Φ-score is inspired by recent theoretical studies on deep network expressivity <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b59">60]</ref>. A key observation in these studies is that a vanilla network can be decomposed into piece-wise linear functions conditioned on activation patterns <ref type="bibr" target="#b33">[34]</ref>:</p><p>Lemma 1 ( <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b30">31]</ref>). Denote the activation pattern of the t-th layer as A t (x). Then for any vanilla network f (•),</p><formula xml:id="formula_0">f (x|θ) = Si∈S I x (S i )W Si x (1)</formula><p>where S i is a convex polytope depending on</p><formula xml:id="formula_1">{A 1 (x), A 2 (x), • • • , A L (x)}; S is a finite set of con- vex polytopes in R m0 ; I x (S i ) = 1 if x ∈ S i otherwise zero; W Si is a coefficient matrix of size R m L ×m0 .</formula><p>According to Lemma 1, any vanilla network is an ensemble of piece-wise linear functions segmented by convex polytopes S = {S 1 , S 2 , • • • , S |S| } where |S| is the number of linear-regions (see Figure <ref type="figure">2</ref> in <ref type="bibr" target="#b13">[14]</ref>. The number of linear regions |S| has been used as expressivity proxy in several theoretical studies <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b59">60]</ref>. However, directly using |S| incurs two limitations: a) Counting |S| for large network is computationally infeasible; b) The representation power of each W Si is not considered in the proxy. The first limitation is due to fact that the number of linear regions grow exponentially for large networks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b59">60]</ref>. To understand the second limitation, we recall the Gaussian complexity <ref type="bibr" target="#b17">[18]</ref> of linear classifiers:</p><formula xml:id="formula_2">Lemma 2 ([18]). For linear function class {f : f (X) = W X s.t. ∥W ∥ F ≤ G}, its Gaussian complexity is upper bounded by O(G).</formula><p>In other words, Lemma 2 says that the expressivity of linear function class measured by Gaussian complexity is controlled by the Frobenius norm of its parameter matrix W . Inspired by Lemma 1 and Lemma 2, we define the following index for measuring network expressivity : Definition 1 (Φ-score for VCNN). The expected Gaussian complexity for a vanilla network f (•) is defined by</p><formula xml:id="formula_3">Φ(f ) = log E x,θ Si∈S I x (S i )∥W Si ∥ F (2) = log E x,θ ∥∇ x f (x|θ)∥ F .<label>(3)</label></formula><p>In Definition 1, we measure the network expressivity by its expected Gaussian complexity, or Φ-score for short. Since any VCNN is ensemble of linear functions, it is nature to measure its expressivity by averaging the Gaussian complexity of linear function in each linear region. To this end, we randomly sample x and θ from some prior distributions and then average ∥W Si ∥ F . This is equivalent to compute the expected gradient norm of f with respect to input x. In our implementation, x and θ are sampled from standard Gaussian distribution which works well in practice. It is important to note that in Φ-score, only the gradient of x rather than θ is involved. This is different to zero-cost proxies in <ref type="bibr" target="#b0">[1]</ref> which compute gradient of θ in their formulations. These proxies measure the trainability <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b6">7]</ref> instead of the expressivity of networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Zen-Score and Zen-NAS</head><p>In this section, we show that directly computing Φ-score for very deep networks incurs numerical overflow due to the gradient explosion without BN layers. The gradient explosion could be resolved by adding BN layers back but the Φ-score will be adaptively re-scaled, making it difficult to compare Φ-score between different networks. The same phenomenon has been known as 'scale-sensitive' problem in deep learning complexity analysis <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35]</ref>. To address this open question, we propose to re-scale the Φ-score one more time by the product of BN layers' variance statistics. This new score is denoted as Zen-Score in order to distinguish from the original Φ-score. The Zen-Score is proven to be scale-insensitive. Finally, we present Zen-NAS algorithm built on Zen-Score and demonstrate its effectiveness in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Overflow and BN-rescaling</head><p>When computing Φ-score for very deep vanilla networks, numerical overflow incurs almost surely. This is because BN layers are removed from the network and the magnitude of network output grows exponentially along depth. To see this, we construct a set of vanilla networks P w/oBN without BN layers. All networks have the same widths but different depths. Figure <ref type="figure">2</ref>(a) plots the Φ-scores for P w/oBN . After 30 layers, Φ-score overflows. To address the overflow, we add BN layers back and compute the Φscores in Figure <ref type="figure">2(b)</ref>. This time the overflow dismisses but the Φ-scores are scaled-down by a large factor. This phenomenon is termed as BN-rescaling.</p><p>To demonstrate that BN-rescaling disturbs architecture ranking, we construct another two set of networks, Q w/oBN and Q BN , with and without BN respectively. All networks have two layers and have the same number of input and final output channels. The number of bottleneck channels, that is the width of the hidden layer, varies from 2 to 60. The corresponding Φ-score curves are plotted in Figure <ref type="figure">2(d) and</ref> (e) respectively. When BN layer is presented, the Φ-score becomes nearly constant for all networks. This will confuse the architecture generator and drive the search to a wrong direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">From Φ-Score to Zen-Score</head><p>In the above subsection, we showed that BN layer is necessary to prevent numerical overflow in computing Φ-score but comes with the side-effect of re-scaling. In this subsection, we design a new Zen-Score which is able to calibrate Algorithm 1 Zen-Score Require: Network F(•) with pre-GAP feature map f (•); α = 0.01. Ensure: Zen-Score Zen(F).</p><p>1: Remove all residual links in F.</p><p>2: Initialize all neurons in F by N (0, 1).</p><formula xml:id="formula_4">3: Sample x, ϵ ∼ N (0, 1). 4: Compute ∆ ≜ E x,ϵ ∥f (x) − f (x + αϵ)∥ F . 5:</formula><p>For the i-th BN layer with m output channels, compute σi = j σ 2 i,j /m where σ i,j is the mini-batch standard deviation statistic of the j-th channel in BN. 6: Zen(F ) ≜ log(∆) + i log(σ i ).</p><p>re-scaling when BN layer is present. The computation of Zen-Score is described in Algorithm 1. Figure <ref type="figure" target="#fig_1">3</ref> visualizes the computational graph of Algorithm 1.</p><p>In Algorithm 1, all residual links are removed from the network as pre-processing. Then we randomly sample input vectors and perturb them with Gaussian noise. The perturbation of the pre-GAP feature map is denoted as ∆ in Line 4. This step replaces the gradient of x with finite differential ∆ to avoid backward-propagation. To get Zen-Score, the scaling factor σ2 i is averaged from the variance of each channel in BN layer. Finally, the Zen-Score is computed by the log-sum of ∆ and σi . The following theorem guarantees that the Zen-Score of network with BN layers approximates the Φ-score of the same network without BN layers. The proof is postponed to Supplementary I. Theorem 1. Let f (x 0 ) = xL be an L-layer vanilla network without BN layers. f (x 0 ) = x L is its sister network with BN layers. For some constants 0 &lt; δ &lt; 1,</p><formula xml:id="formula_5">K 0 ≤ O[ log(1/δ)], when BHW ≥ O[(LK 0 ) 2 ]</formula><p>is large enough, with probability at least 1 − δ, we have</p><formula xml:id="formula_6">(1 − Lϵ) 2 ≤ ( L t=1 σ2 t )E θ {∥x L ∥ 2 } E θ ∥x L ∥ 2 ≤ (1 + Lϵ) 2 (4) where ϵ ≜ O(2K 0 / √ BHW ).</formula><p>Informally speaking, Theorem 1 says that to compute ∥ f (•)∥, we only need to compute ∥f (•)∥ then re-scale with L t=1 σt . The approximation error is bounded by Lϵ. By taking gradient of x on both f (•) and f (•), we obtain the desired relationship between Zen-Score and Φ-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Zen-NAS For Maximizing Expressivity</head><p>Algorithm 2 Zen-NAS Require: Search space S, inference budget B, maximal depth L, total number of iterations T , evolutionary population size N , initial structure F 0 . Ensure: NAS-designed ZenNet F * .</p><p>1: Initialize population P = {F 0 }.</p><formula xml:id="formula_7">2: for t = 1, 2, • • • , T do 3:</formula><p>Randomly select F t ∈ P.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Mutate Ft = MUTATE(F t , S)</p><formula xml:id="formula_8">5:</formula><p>if Ft exceeds inference budget or has more than L layers then 6:</p><p>Do nothing. Get Zen-Score z = Zen( Ft ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Append Ft to P. Uniformly alternate the block type, kernel size, width and depth of h within some range. 3: Return the mutated structure Ft .</p><p>We design Zen-NAS algorithm to maximize the Zen-Score of the target network. The step-by-step description of Zen-NAS is given in Algorithm 2. The Zen-NAS uses Evolutionary Algorithm (EA) as architecture generator. It is possible to choose other generators such as Reinforced Learning or even greedy selection. The choice of EA is due to its simplicity.</p><p>In Algorithm 2, we randomly generate N structures. At each iteration step t, we randomly select a structure in the population P and mutate it. The mutation algorithm is presented in Algorithm 3. The width and depth of the selected layer is mutated in a given range. We choose [0.5, 2.0] as the mutation range in this work, that is, within half or double of the current value. The new structure Ft is appended to the population if its inference cost does not exceed the budget. The maximal depth of networks is controlled by L, which prevents the algorithm generate over-deep structures. Finally, we maintain the population size by removing networks with the smallest Zen-Scores. After T iterations, the network with the largest Zen-Score is returned as the output of Zen-NAS. We name the found architectures as ZenNets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, experiments on CIFAR-10/CIFAR-100 <ref type="bibr" target="#b19">[20]</ref> and ImageNet-1k <ref type="bibr" target="#b11">[12]</ref> are conducted to validate the superiority of Zen-NAS. We first compare Zen-Score to several zero-shot proxies on CIFAR-10 and CIFAR-100, using the same search space, search policy and training settings. Then we compare Zen-NAS to the state-of-the-art methods on ImageNet. Zen-NAS on CIFAR-10/CIFAR-100 can be found in Supplementary D. Finally, we compare the searching cost of Zen-NAS with SOTA methods in subsection 5.3.</p><p>Due to space limitation, the inference speed on NVIDIA T4 and Google Pixel2 is reported in Supplementary C. The Zen-Scores of ResNets and accuracies under fair training settings are reported in Supplementary E. We enclose one big performance table of networks on ImageNet in Supplementary J.</p><p>To align with previous works, we consider the following two search spaces:</p><p>• Search Space I Following <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b39">40]</ref>, this search space consists of residual blocks and bottleneck blocks defined in ResNet. • Search Space II Following <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b37">38]</ref>, this search space consists of MobileNet blocks. The depth-wise expansion ratio is searched in set {1, 2, 4, 6}. Please see Supplementary A for datasets description and detail experiment settings.</p><p>In each trial, the initial structure is a randomly selected small network which is guaranteed to satisfy the inference budget. The kernel size is searched in set {3, 5, 7}. Following conventional designs, the number of stages is three for CIFAR-10/CIFAR-100 and five for ImageNet. The evolutionary population size is 256, number of evolutionary iterations T = 96, 000. The resolution is 32x32 for CIFAR-10/CIFAR-100 and 224x224 for ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Zen-Score v.s. Other Zero-Shot Proxies</head><p>Following <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref>, we compare Zen-Score to five zeroshot proxies: FLOPs, gradient-norm (grad) of network parameters, synflow <ref type="bibr" target="#b50">[51]</ref>, TE-NAS score (TE-Score) <ref type="bibr" target="#b6">[7]</ref> and NASWOT <ref type="bibr" target="#b32">[33]</ref>. For each proxy, we replace Zen-Score by The convergence curves are plotted in Supplementary C. In these figures, all six scores improves monotonically along iterations.</p><p>After the above NAS step, we train the network of the best score for each proxy under the same training setting. To provide a random baseline, we randomly generate networks. The width of the layer varies in range <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">512]</ref>, and the depth of each stage varies in range <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>. If the network size is larger than 1 M, we shrink its width by factor 0.75 each time until it satisfies the budget. 32 random networks are generated and trained in total.</p><p>The top-1 accuracy is reported in Table <ref type="table" target="#tab_1">1</ref>. Zen-Score significantly outperforms the other five proxies on both CIFAR-10 and CIFAR-100. TE-Score and NASWOT are the runner-up proxies with similar performance, followed by synflow. It is not surprise to see that naive proxies, such as FLOPs and gradient-norm, perform poorly, even worse than random search.</p><p>To compare the computational efficiency of Zen-Score and TE-score, we compute two scores for ResNet-18 and ResNet-50 at 224x224 resolution. The expected time cost is averaged over 100 trials. We find that averaging Zen/TE-Score over N = 16 random images is sufficient to reduce the statistical error below 5%. The results are reported in Table <ref type="table">2</ref>. The computation of Zen-Score is 20 ∼ 28 times faster than TE-Score.</p><p>We tried our best to benchmark NASWOT for ResNet-18/50 using the official code. However, the official code always outputs Inf for ResNet-18/50 at resolution 224. Despite of the Inf issue, Zen-Score is 3.3x times faster than NASWOT on ResNet-18 and 1.6x times faster on ResNet-50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Zen-NAS on ImageNet</head><p>We use Zen-NAS to search efficient network (ZenNet) on ImageNet. We consider the following popular networks as baselines: (a) manually-designed networks, including ResNet <ref type="bibr" target="#b14">[15]</ref>, DenseNet <ref type="bibr" target="#b16">[17]</ref>, ResNeSt <ref type="bibr" target="#b64">[65]</ref>, MobileNet-V2 <ref type="bibr" target="#b44">[45]</ref> (b) NAS-designed networks for fast inference on GPU, including OFANet-9ms/11ms <ref type="bibr" target="#b4">[5]</ref>, DFNet <ref type="bibr" target="#b21">[22]</ref>, Reg-Net <ref type="bibr" target="#b39">[40]</ref>; (c) NAS-designed networks optimized for FLOPs, including OFANet-389M/482M/595M <ref type="bibr" target="#b4">[5]</ref>, DNANet <ref type="bibr" target="#b20">[21]</ref>, EfficientNet <ref type="bibr" target="#b49">[50]</ref>, Mnasnet <ref type="bibr" target="#b48">[49]</ref>.</p><p>Among these networks, EfficientNet is a popular baseline in NAS-related works. EfficientNet-B0/B1 are suitable for mobile device for their small FLOPs and model size. EfficientNet-B3∼B7 are large models that are best to be deployed on a high-end GPU. Although EfficientNet is optimized for FLOPs, its inference speed on GPU is within toptier ones. Many previous works compare to EfficientNet by inference speed on GPU <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Searching Low Latency Networks Following previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b39">40]</ref>, we use Zen-NAS to optimize network inference speed on NVIDIA V100 GPU. We use Search Space I in this experiment. The inference speed is tested at batch size 64, half precision (float16). We search for networks of inference latency within 0.1/0.2/0.3/0.5/0.8/1.2 milliseconds (ms) per image. For testing inference latency, we set batch-size=64 and do mini-batch inference 30 times. The averaged inference latency is recorded. The top-1 accuracy on ImageNet v.s. inference latency is plotted in Figure <ref type="figure" target="#fig_0">1</ref>. Clearly, ZenNets outperform baseline models in both accuracy and inference speed by a large margin. The largest model ZenNet-1.2ms achieves 83.6% top-1 accuracy which is between EfficientNet-B5 and B6. It is about 4.9x faster than EfficientNet at the same accuracy level.</p><p>Searching Lightweight Networks Following previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b49">50]</ref>, we use Zen-NAS to search lightweight networks with small FLOPs. We use Search Space II in this experiment. We search for networks of computational cost within 400/600/900 M FLOPs. Similar to OFANet and Ef-ficientNet, we add SE-blocks after convolutional layers. The top-1 accuracy v.s. FLOPs is plotted in Figure <ref type="figure">4</ref>.</p><p>Again, ZenNets outperform most models by a large margin. ZenNet-900M-SE achieves 80.8% top-1 accuracy which is comparable to EfficientNet-B3 with 43% fewer FLOPs. The runner-up is OFANet whose efficiency is similar to ZenNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Searching Cost of Zen-NAS v.s. SOTA</head><p>The major time cost of Zen-NAS is the computation of Zen-Score. The network latency is predicted by an in-house latency predictor whose time cost is nearly zero. According to Table <ref type="table">2</ref>, the computation of Zen-Score for ResNet-50 only takes 0.15 second. This means that scoring 96,000 networks similar to ResNet-50 only takes 4 GPU hours, or 0.17 GPU day.</p><p>We compare Zen-NAS searching cost to SOTA NAS methods in Table <ref type="table">3</ref>. Since every NAS method uses different settings, it is difficult to make a fair comparison that everyone agrees with. Nevertheless, we only concern about the best model reported in each paper and the corresponding searching cost. This gives us a rough impression of the efficiency of these methods and their practical ability of designing high-performance models.</p><p>From Table <ref type="table">3</ref>, for conventional NAS methods, it takes hundreds to thousands GPU days to find a good structure of accuracy better than 78.0%. Many one-shot methods are very fast. For most one-shot methods, the best accuracy is below 80%. In comparison, Zen-NAS achieves 83.6% top-1 accuracy within 0.5 GPU day. Among methods achieving above 80.0% top-1 accuracy in Table <ref type="table">3</ref>, the searching speed of Zen-NAS is nearly 100 times faster than OFANet and 7800 times faster than EfficientNet. TE-NAS uses less GPU day than Zen-NAS in Table <ref type="table">3</ref>. This does not conflict with Table <ref type="table">2</ref> because the total number of networks evaluated by the two methods are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We proposed Zen-NAS, a zero-shot neural architecture search framework for designing high performance deep image recognition networks. Without optimizing network parameters, Zen-NAS ranks networks via network expressivity which can be numerically measured by Zen-Score. The searching speed of Zen-NAS is dramatically faster than previous SOTA methods. The ZenNets automatically designed by Zen-NAS are significantly more efficient in terms of inference latency, FLOPs and model size, in multiple recognition tasks. We wish the elegance of Zen-NAS will inspire more theoretical researches towards a deeper understanding of efficient network design.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. ZenNets top-1 accuracy v.s. inference latency (milliseconds per image) on ImageNet. Benchmarked on NVIDIA V100 GPU, half precision (FP16), batch size 64, searching cost 0.5 GPU day.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 2. Φ-scores and Zen-Scores of networks, with different depths and bottleneck channels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, the network of the highest Zen-Score in P. Structure F t , search space S. Ensure: Randomly mutated structure Ft .</figDesc><table><row><cell>10:</cell><cell>end if</cell></row><row><cell>11:</cell><cell>Remove network of the smallest Zen-Score if the size</cell></row><row><cell></cell><cell>of P exceeds B.</cell></row><row><cell cols="2">12: end for</cell></row><row><cell cols="2">13: Return F  Algorithm 3 MUTATE</cell></row><row><cell cols="2">Require:</cell></row></table><note>* 1: Uniformly select a block h in F t . 2:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Top-1 accuracies on CIFAR-10/CIFAR-100 for five zeroshot proxies. Budget: model size N ≤ 1 M. 'Random': average accuracy ± std for random search.</figDesc><table><row><cell></cell><cell>proxy</cell><cell></cell><cell cols="4">CIFAR-10 CIFAR-100</cell><cell>NAS</cell><cell>Method Top-1 (%) GPU Day</cell></row><row><cell></cell><cell cols="2">Zen-Score</cell><cell>96.2%</cell><cell></cell><cell>80.1%</cell><cell></cell><cell>AmoebaNet-A [41]</cell><cell>EA</cell><cell>74.5</cell><cell>3150 †</cell></row><row><cell></cell><cell>FLOPs</cell><cell></cell><cell>93.1%</cell><cell></cell><cell>64.7%</cell><cell></cell><cell>EcoNAS [69] CARS-I [62]</cell><cell>EA EA</cell><cell>74.8 75.2</cell><cell>8 0.4</cell></row><row><cell></cell><cell>grad</cell><cell></cell><cell>92.8%</cell><cell></cell><cell>65.4%</cell><cell></cell><cell>GeNet [57]</cell><cell>EA</cell><cell>72.1</cell><cell>17</cell></row><row><cell></cell><cell>synflow</cell><cell></cell><cell>95.1%</cell><cell></cell><cell>75.9%</cell><cell></cell><cell>DARTS [26] SNAS [59]</cell><cell>GD GD</cell><cell>73.1 72.7</cell><cell>4 1.5</cell></row><row><cell></cell><cell cols="2">TE-Score</cell><cell>96.1%</cell><cell></cell><cell>77.2%</cell><cell></cell><cell>PC-DARTS [61]</cell><cell>GD</cell><cell>75.8</cell><cell>3.8</cell></row><row><cell></cell><cell cols="2">NASWOT Random</cell><cell cols="4">96.0% 93.5±0.7% 71.1±3.1% 77.5%</cell><cell>ProxylessNAS [6] GDAS [66] FBNetV2-L1 [54]</cell><cell>GD GD GD</cell><cell>75.1 74 77.2</cell><cell>8.3 0.8 25</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NASNet-A [70]</cell><cell>RL</cell><cell>74</cell><cell>1800</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mnasnet-A [49]</cell><cell>RL</cell><cell>75.2</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MetaQNN [3]</cell><cell>RL</cell><cell>77.4</cell><cell>96</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PNAS [25]</cell><cell>SMBO 74.2</cell><cell>224</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SemiNAS [29]</cell><cell>SSL</cell><cell>76.5</cell><cell>4</cell></row><row><cell></cell><cell>proxy</cell><cell cols="2">model</cell><cell>N</cell><cell cols="2">time speed-up</cell><cell>TE-NAS [7]</cell><cell>ZS</cell><cell>74.1</cell><cell>0.2</cell></row><row><cell></cell><cell>TE-Score</cell><cell cols="4">ResNet-18 16 0.34</cell><cell>1/28x</cell><cell cols="2">OFANet [5] EfficientNet-B7 [50] Scaling 84.4 PS 80.1</cell><cell>51.6 3800 ‡</cell></row><row><cell></cell><cell></cell><cell cols="4">ResNet-50 16 0.77</cell><cell>1/20x</cell><cell>Zen-NAS</cell><cell>ZS</cell><cell>83.6</cell><cell>0.5</cell></row><row><cell></cell><cell cols="5">NASWOT † ResNet-18 16 0.040</cell><cell>1/3.3x</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">ResNet-50 16 0.059</cell><cell>1/1.6x</cell><cell cols="2">Table 3. NAS searching cost comparison. 'Top-1': top-1 accuracy on ImageNet-1k. 'Method': 'EA' is short for Evolutionary Algo-</cell></row><row><cell></cell><cell>Zen-Score</cell><cell cols="4">ResNet-18 16 0.012</cell><cell>1.0</cell><cell cols="2">rithm; 'GD' is short for Gradient Descent; 'RL' is short for rein-</cell></row><row><cell></cell><cell></cell><cell cols="4">ResNet-50 16 0.037</cell><cell>1.0</cell><cell cols="2">forcement Learning; 'ZS' is short for Zero-shot; 'SMBO', 'SSL', 'PS' and 'Scaling' are special searching methods/frameworks.  †:</cell></row><row><cell cols="7">Table 2. Time cost (in seconds) of computing Zen/TE-Score for</cell><cell cols="2">Running on TPU;  ‡: The cost is estimated by [54];</cell></row><row><cell cols="7">ResNet-18/50 at resolution 224x224. The statistical error is within</cell><cell></cell></row><row><cell cols="7">5%. 'time': time for computing Zen/TE-score for N images, mea-sured in seconds, averaged over 100 trials. 'speed-up': speed-up rate of TE-Score v.s. Zen-Score.</cell><cell cols="2">rithm 2. Following convention, we search for best network on CIFAR-10/CIFAR-100 within model size N ≤ 1 M.</cell></row><row><cell cols="7">†: The official implementation outputs Inf score for ResNet-18/50.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>44% Reduction</cell><cell></cell><cell></cell></row><row><cell>Top-1 Accuracy (%)</cell><cell>72.5 75.0 77.5 80.0 70.0</cell><cell></cell><cell></cell><cell></cell><cell>RegNet EfficientNet OFANet MobileNet</cell><cell>MnasNet DNANet DFNet ZenNet</cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.5</cell><cell cols="2">1.0</cell><cell>1.5</cell><cell>2.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">FLOPs</cell><cell>×10 9</cell><cell></cell></row><row><cell></cell><cell cols="6">Figure 4. ZenNets optimized for FLOPs.</cell><cell></cell></row><row><cell cols="7">that proxy in Algorithm 2 and then run Algorithm 2 for T =</cell><cell></cell></row><row><cell cols="7">96, 000 iterations to ensure convergence. Since synflow is</cell><cell></cell></row><row><cell cols="7">the smaller the better, we use its negative value in Algo-</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Obviously, the final searched architecture must be trained on the target dataset before deployment.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Zero-Cost Proxies for Lightweight NAS</title>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">S</forename><surname>Abdelfattah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Dudziak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge Distillation from Internal Representations</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenlei</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Designing Neural Network Architectures using Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectrally-normalized margin bounds for neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><forename type="middle">J</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matus</forename><forename type="middle">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Once-for-All: Train One Network and Specialize it for Efficient Deployment on Diverse Hardware Platforms</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Neural architecture search on imagenet in four gpu hours: A theoretically inspired perspective</title>
		<author>
			<persName><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Progressive DARTS: Bridging the Optimization Gap for NAS in the Wild</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inductive Bias of Deep Convolutional Networks through Pooling Geometry</title>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amnon</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dandelion Mane, Vijay Vasudevan, and Quoc V. Le. AutoAugment: Learning Augmentation Policies from Data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName><surname>Zoph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity</title>
		<author>
			<persName><forename type="first">Amit</forename><surname>Daniely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Single Path One-Shot Neural Architecture Search with Uniform Sampling</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Complexity of Linear Regions in Deep Networks</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Hanin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhua</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Densely Connected Convolutional Networks</title>
		<author>
			<persName><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambuj</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Koltchinskii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">2033</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Blockwisely Supervised Neural Architecture Search with Knowledge Distillation</title>
		<author>
			<persName><forename type="first">Changlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiefeng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liuchun</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangrun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Partial Order Pruning: For Best Speed/Accuracy Trade-off in Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Why Deep Neural Networks for Function Approximation</title>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Are Labels Necessary for Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Progressive Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic Gradient Descent with Warm Restarts</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Expressive Power of Neural Networks: A View from the Width</title>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongming</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-Supervised Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Architecture Optimization. In NIPS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the Expressive Power of Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04647</idno>
		<title level="m">Neural Architecture Search without Training</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural Architecture Search without Training</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the Number of Linear Regions of Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Montúfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The role of over-parametrization in generalization of neural networks</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Behnam Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinadh</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth</title>
		<author>
			<persName><forename type="first">Thao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10580</idno>
		<title level="m">Meta Pseudo Labels</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient Neural Architecture Search via Parameters Sharing</title>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melody</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exponential expressivity in deep neural networks through transient chaos</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhaneil</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Designing Network Design Spaces</title>
		<author>
			<persName><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Large-Scale Evolution of Image Classifiers</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Pengzhen</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The power of deeper networks for expressing natural functions</title>
		<author>
			<persName><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Tegmark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">MobileNetV2: Inverted Residuals and Linear Bottlenecks</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Christian</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaicheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08142</idno>
		<title level="m">Evaluating the Search Phase of Neural Architecture Search</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">and Srikumar Ramalingam. Bounding and Counting Linear Regions of Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Tjandraatmadja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Vincent Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Platform-Aware Neural Architecture Search for Mobile</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Mnasnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pruning neural networks without any data by iteratively conserving synaptic flow</title>
		<author>
			<persName><forename type="first">Hidenori</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kunin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Hugo Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.12877</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">High-Dimensional Probability: An Introduction with Applications in Data Science</title>
		<author>
			<persName><forename type="first">Roman</forename><surname>Vershynin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cambridge Series in Statistical and Probabilistic Mathematics</title>
				<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">FBNetV2: Differentiable Neural Architecture Search for Spatial and Channel Dimensions</title>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Picking Winning Tickets Before Training by Preserving Gradient Flow</title>
		<author>
			<persName><forename type="first">Chaoqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Neural Predictor for Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Genetic CNN</title>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01569</idno>
		<title level="m">Exploring Randomly Wired Neural Networks for Image Recognition</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">SNAS: Stochastic neural architecture search</title>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On the Number of Linear Regions of Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search</title>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">CARS: Continuous Evolution for Efficient Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">NAS-Bench-101: Towards Reproducible Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">ResNeSt: Split-Attention Networks</title>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Overcoming Multi-Model Forgetting in One-Shot NAS With Diversity Maximization</title>
		<author>
			<persName><forename type="first">Miao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Empirical Studies on the Properties of Linear Regions in Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongrui</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Random Erasing Data Augmentation</title>
		<author>
			<persName><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">EcoNAS: Finding Proxies for Economical Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Dongzhan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuesen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Learning Transferable Architectures for Scalable Image Recognition</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
