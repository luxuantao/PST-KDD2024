<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differential Privacy: Now it&apos;s Getting Personal</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hamid</forename><surname>Ebadi</surname></persName>
							<email>hamid.ebadi@chalmers.se</email>
							<affiliation key="aff0">
								<orgName type="institution">Chalmers University of Technology</orgName>
								<address>
									<settlement>Göteborg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Sands</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Chalmers University of Technology</orgName>
								<address>
									<settlement>Göteborg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gerardo</forename><surname>Schneider</surname></persName>
							<email>gerardo@cse.gu.se</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Gothenburg</orgName>
								<address>
									<settlement>Göteborg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Differential Privacy: Now it&apos;s Getting Personal</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F3EC7BDCB1773157ADC04E0C966819D0</idno>
					<idno type="DOI">10.1145/2676726.2677005</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.3.2 [Programming Languages]: Language Classifications-Specialized application languages General Terms Design</term>
					<term>Languages</term>
					<term>Theory differential privacy</term>
					<term>provenance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differential privacy provides a way to get useful information about sensitive data without revealing much about any one individual. It enjoys many nice compositionality properties not shared by other approaches to privacy, including, in particular, robustness against side-knowledge.</p><p>Designing differentially private mechanisms from scratch can be a challenging task. One way to make it easier to construct new differential private mechanisms is to design a system which allows more complex mechanisms (programs) to be built from differentially private building blocks in principled way, so that the resulting programs are guaranteed to be differentially private by construction.</p><p>This paper is about a new accounting principle for building differentially private programs. It is based on a simple generalisation of classic differential privacy which we call Personalised Differential Privacy (PDP). In PDP each individual has its own personal privacy level. We describe ProPer, a interactive system for implementing PDP which maintains a privacy budget for each individual. When a primitive query is made on data derived from individuals, the provenance of the involved records determines how the privacy budget of an individual is affected: the number of records derived from Alice determines the multiplier for the privacy decrease in Alice's budget. This offers some advantages over previous systems, in particular its fine-grained character allows better utilisation of the privacy budget than mechanisms based purely on the concept of global sensitivity, and it applies naturally to the case of a live database where new individuals are added over time.</p><p>We provide a formal model of the ProPer approach, prove that it provides personalised differential privacy, and describe a prototype implementation based on McSherry's PINQ system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Differential privacy is a relatively new notion of privacy <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. The theory shows that by adding the right amount of noise to statistical queries, one can get useful results at the same time as providing a quantifiable notion of privacy. Its definition does not involve a syntactic condition on the data itself, but rather it is a condition formed by comparing the results of a query on any database with or without any one individual: a query Q (a randomised function) is ε-differentially private if the difference in probability of any query outcome on a data-set only varies by a factor of e ε (approximately 1 + ε for small ε) whenever an individual is added or removed.</p><p>Research on differential privacy has developed a variety of query mechanisms that provide differential privacy for a useful range of statistical problems. A few works have focussed more on composition principles that allow new differential private mechanisms to design a system which allows more complex mechanisms (programs) to be built from differentially private building blocks in principled way, so that the resulting programs are guaranteed to be differentially private by construction <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24]</ref>. PINQ <ref type="bibr" target="#b16">[17]</ref> is the starting point for the present work.</p><p>PINQ-style Global Privacy Budget PINQ is an implmentation of interactive differential privacy which ensures, at runtime, that queries adhere to a global privacy budget. Third-party client code freely decides how sensitive data sets should be processed and queried. The run-time system ensures that this does not break a specified privacy budget ε. PINQ builds on a collection of standard differentially private primitive queries, together with simple composition principles -mathematical properties enjoyed by the definition of differential privacy. One central principle is that multiple queries (e.g. with differential privacy ε1 and ε2 respectively) have an additive effect (ε1 + ε2) on the overall differential privacy. Another central idea is to track sensitivity of functions to measure how much a change in the input might affect the value of the data. Together, these components allow the system to track how much to deduct from the global privacy budget on each invocation of a primitive query.</p><p>Limitations of the Global Privacy Budget In a batch system where all computations are described up-front as a monolithic program, a global budget is reasonable. In an interactive system, however, there are several limitations to this style of accounting. Imagine a scenario involving a large data set of individuals -a cross-set of the population -containing various information about health and lifestyle. Let us suppose, further, that we aim for ε-differential privacy for some specified value of ε. On Monday the analyst selects all the people from the database who have a particular blood type, AB-negative, and constructs an algorithm which extracts information about them as part of medical research. Since just 0.6% of the population have this blood type, the proportion of the database involved in this study is relatively small, but the database is known to be big enough for it to be meaningful. Let us suppose that the cost of this analysis, according to the system, is ε1. Now on Tuesday the analyst gets a new task, to extract information about the lifestyle of smokers, towards an advertising campaign for nicotine gum. This is a significantly larger portion of the database, possibly overlapping Monday's research group. The analyst has ε -ε1 left to spend. If ε1 is large, the analyst has blown the budget by analysing the small group, even though that study did not touch the data of the larger part of the population. PINQ offers a way around this problem by adding nonstandard database primitives. Here we would partition the data into (AB -, not AB -) and perform the two studies in parallel, with cost being the maximum of the cost of the two studies.</p><p>This leads to a batch-style reasoning and an unnatural programming style. But it also has another limitation. What if the database is live -we obtain new data over time, or if data is continually being added? A global budget forces us to be unnecessarily pessimistic about new as-yet unexploited data.</p><p>Personalised Differential Privacy This paper addresses these issues by offering a simple generalisation of differential privacy called personalised differential privacy (PDP) which permits each individual to have a personalised privacy budget. The definition supports generalised versions of the composition principles upon which systems like PINQ are based ( §2), and moreover enjoys a number of properties which allow for less wasteful compositional principles ( §3). For example, any query about the drinking habits of adults offers 0-differential privacy for Adrian, aged 13, as it does for any records of individuals which enter the database after the query has been made.</p><p>From these principles we design a system, in the style of PINQ, called ProPer (Provenance for Personalised Differential Privacy- §4). The ProPer system maintains a personal budget for every record entering the system. Instead of using sensitivity, ProPer tracks the provenance of every record in the system, and uses the exact provenance to calculate how a query should affect the budgets of the individuals. Unlike PINQ, the system is described as an abstract formal model for which we prove personalised differential privacy. This is important because the correctness of ProPer is not obvious for two reasons. Firstly, the individual budgets become highly sensitive and how we handle them is novel. More specifically, if a query involves records that would break the budget of an individual they are silently dropped from the data set upon which the query is calculated. In the example above, Tuesday's analysis of smokers will automatically exclude data derived from any diseased individuals as soon as the cost of the queries exceeds their budgets. Secondly, it is necessary to restrict the domain of computations over data sets to a class which guarantees that the provenance of any derived record is affine (zero or one record), otherwise the number of records which might get excluded due to a small change in the input might be too big to give privacy guarantees. The approach is suitable for integration with other systems, since we assume the existence of basic primitives providing classical differential privacy. We have implemented a prototype of the ProPer approach which extends the PINQ system ( §6) with personalised budgets and the ability to input live data. We compare the performance of our provenance-based implementation with PINQ to show that the runtime overhead is not significant.</p><p>We conclude with a discussion of related work ( §7), a summary of our contributions ( §8), and the current limitations of the approach as well as directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Differential Privacy</head><p>We begin by reviewing the classic definition of differential privacy, and its simple composition principles that allow the construction of new differentially-private algorithms from existing components. In this work the "data sets" will abstract representations of databases, modelled simply as multisets over some unspecified set of records. When we say that A and B differ on at most one record, also written A ∼ B, we mean that they are either identical, or one can be obtained from the other by adding a single record. Definition 2.1. A randomised function Q provides ε-differential privacy if for all data sets A ∼ B, and any set of possible outputs S ⊆ range(Q), we have:</p><formula xml:id="formula_0">P r[Q(A) ∈ S] ≤ P r[Q(B) ∈ S] × e ε</formula><p>Thus the likelihood of a given output to a query Q only changes by a quantifiable amount with or without any individual. The smaller the ε the better the privacy guarantee for the individual. The literature contains many examples of differentially private aggregate operations on data, achieving an appropriate balance between privacy and utility by the principled use of statistical noise. In this work we take the existence of such building blocks as given.</p><p>We will adopt the convention of writing Qε to denote an εdifferentially private query. Queries will be algorithms rather than just abstract mathematical functions, so we assume that the range of Q is finite and moreover the result of a query forms a discrete probabilistic distribution. Given this, we can simplify the conditions of the form Q(A) ∈ S to Q(A) = v for any value in the range of Q.</p><p>Definition 2.1 satisfies a number of useful properties that serve as building blocks for systems enforcing differential privacy <ref type="bibr" target="#b16">[17]</ref>, which we outline informally here.</p><p>Query Composition If we apply two queries Qε 1 and then Qε 2 to a data set, then the combined result is ε1 + ε2 differentially private. This result holds even if Qε 2 is chosen in response to the result of Qε 1 . Although useful, the sequential query composition principle can be very wasteful. If two queries are applied to disjoint sets of data then the privacy loss is the maximum of the privacy losses of the two queries. This observation prompted McSherry to include this as a nonstandard parallel query operation in PINQ.</p><p>Pre-processing and Sensitivity What if we transform data before applying a query? A key compositionally concept is the sensitivity of a function <ref type="bibr" target="#b4">[5]</ref> (it is also a key concept in the design of primitive differentially private operations <ref type="bibr" target="#b7">[8]</ref>, although that is not our focus here). Roughly speaking, a function f has sensitivity c (also known as stability c <ref type="bibr" target="#b16">[17]</ref>) if whenever the distance between two inputs is n, the distance between the results of applying f is at most c × n. For (multi-)sets, the distance between A and B is just the size of their symmetric difference. Not all functions have a bounded sensitivity. For example consider the cartesian product of two data sets: adding a record to one data set can add unboundedly many elements to the result -it depends on the size of the other argument.</p><p>We dub the following property the sensitivity composition principle:</p><formula xml:id="formula_1">If data-set transformer F has sensitivity c, then Qε • F is (ε • c)-differentially private.</formula><p>The proof of this follows easily from the following scaling property of differential privacy: if data sets A and B differ by k elements, then</p><formula xml:id="formula_2">P r[Q(A) ∈ S] ≤ P r[Q(B) ∈ S] × e (k•ε) .</formula><p>Post-processing A very simple -perhaps obvious -property is that a differentially private query is robust under post-processing:</p><formula xml:id="formula_3">For any function F , F • Qε is ε-differentially private.</formula><p>This means that post-processing the result of a query cannot extract more private information than the query itself released. This is also the case when F is chosen in response to other queries -or the result of other "side knowledge" about the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Personalised Differential Privacy</head><p>Now we turn to the main concept introduced in this paper, Personalised or "big epsilon" differential privacy, and its analogous compositionality properties.</p><p>Definition 3.1 (Personalised (Big Epsilon) Differential Privacy).</p><p>We say that data sets A and B differ on record r, written A r ∼ B, if A can be obtained from B by adding the record r, or vice-versa.</p><p>Let E be a function from records to non-negative real numbers. A randomized query Q provides E -differential privacy if for all records r, and all A r ∼ B, and any set of outputs S ⊆ range(Q), we have:</p><formula xml:id="formula_4">P r[Q(A) ∈ S] ≤ P r[Q(B) ∈ S] × e E (r)</formula><p>Personalised differential privacy allows each individual (record) to have its own personal privacy level. This may turn out to be a useful concept in its own right, but its main purpose in this work is as a generalisation that permits a more fine-grained accounting in the construction of classical differentially private mechanisms, and one which plays well with dynamic databases. The following proposition summarises the relation to "small-epsilon" differential privacy:</p><formula xml:id="formula_5">Proposition 3.2. (i) If Q is ε-differentially private, then Q is λx.ε-differentially private. (ii) If Q is E -differentially private, and sup(range(E )) = ε then Q is ε-differentially private.</formula><p>Now we consider the composition principles analogous to those above. We keep the presentation informal since we will not apply these principles directly in our formal developments -rather they provide an intuition behind the approach. Most of the principles above generalise to personalised differential privacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Composition</head><p>In the sequential composition of queries, if Q1 and Q2 are E1 and E2-differentially private, respectively, then applied in sequence they yield a λx.E1(x) + E2(x)-differentially private query. For parallel queries let us be a little more precise:</p><p>Let {Ri}i∈I be a partition of the set of all records, and {Qi}i∈I be a set of queries. we define a parallel query P (A) = Πi∈I Qi(A ∩ Ri) where Π is just the n-ary cartesian product of sets. Now we have the following natural generalisation of the parallel query principle:</p><formula xml:id="formula_6">If Qi is Ei-differentially private then P is E -differentially private, where E (r) = Ei(r) if r ∈ Ri.</formula><p>Now we introduce the first specialised principle which takes advantage of the fine-grained nature of personalised differential privacy, the selection principle:</p><formula xml:id="formula_7">For set A, define selectA(x) = x ∩ A. If Q is E -differentially private, then Q • selectA is E [r → 0 | r ∈ A]-differentially private.</formula><p>Here E [r → 0 | r ∈ A] denotes the function which maps every element outside A to 0, and behaves as E otherwise. In simple terms, a query which operates on A is perfectly private for individuals outside of A. In contrast, the composition principle of ε-differential privacy has nothing helpful to say here: the sensitivity of the selection function is 1.</p><p>How does this help us? It can show how the sequential composition principle for E -differential privacy gives greater accounting precision. Specifically, parallel composition is simply no longer necessary to give a reasonably accurate estimate of privacy cost. Suppose we compute P (A) by sequentially computing Qi • selectR i . Then the sequential composition principle calculates the cost of this iterated sequential composition as λx.Σi∈I (if x ∈ Ri then Ei(x) else 0) which is precisely the cost calculated for the parallel query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensitivity Composition</head><p>The sensitivity composition principle also lifts into the world of personalised differential privacy:</p><p>If data-set transformer F has sensitivity c, and</p><formula xml:id="formula_8">Q is E -differentially private, then Q • F is λx.(E (x) × c)- differentially private.</formula><p>The proof analogously follows easily from the following scaling property: If data sets A and B differ on elements C, then</p><formula xml:id="formula_9">P r[Q(A) ∈ S] ≤ P r[Q(B) ∈ S] × exp(Σr∈C E (r)).</formula><p>The Personalised Sensitivity Principle A key feature of personalised differential privacy is that it supports a fine-grained composition property for a large and important class of functions, namely functions that are union preserving. A function F from multisets to multisets is union preserving if F (A B) = F (A) F (B), A B denotes the additive union of multisets A and B. In standard relational algebra, for example, all functions are union preserving in each of their arguments, with the exception of the (multi-)set difference operator which is not union preserving in its second argument. Complex union-preserving functions may be built from simple ones as they are closed under compositions. You will read more about supported compositions in section 4.3.</p><p>The characteristic property of union preserving functions is that their behaviour can be completely characterised by their behaviour on individual records. This gives us a completely precise way to compute the influence of a single record on the result of the function, since F (A {r}) = F (A) F {r}. This leads us to the following.</p><formula xml:id="formula_10">Lemma 3.3. If F is a union-preserving function and Q is E - differentially private, then Q•F is (λx.Σ s∈F {x} E (s))-differentially private.</formula><p>Proof. Follows easily from the scaling property.</p><p>Taking E = λr.ε yields the following useful corollary which is the core of our approach to combining existing differentially private mechanisms with our personalised approach:</p><formula xml:id="formula_11">Corollary 3.4. If F is a union-preserving function and Q is ε-differentially private, then Q • F is (λx.size(F {x}) × ε)- differentially private.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ProPer: Provenance for Personalised Privacy</head><p>In this section we provide an abstract model of the ProPer system. The ProPer system encapsulates sensitive databases and manages computations over them via an imperative API. It guarantees (as we shall prove) E -differential privacy for the records which enter the system.</p><p>Descriptive vs Prescriptive Systems The principles described in the previous section are a guide as to how we can build a system that allows non-expert analysts to compose new differentially private algorithms from differentially private components. In principle such systems can be of two kinds: descriptive, or prescriptive. In a descriptive system we can apply the principles to compute and report on the level of privacy achieved by a given run of a program. A prescriptive system, on the other hand, is given a goal -an amount of privacy that is to be achieved, and the system must use the principles and ensure that the privacy stays within the bound. <ref type="foot" target="#foot_0">1</ref> In a dy-namic system like PINQ, however, it is more natural to describe a prescriptive system -one which does not violate a preconceived level of privacy.</p><p>In a prescriptive system the desired amount of privacy can be thought of as a budget, and in the literature it is often referred to as such. For ProPer this is an amount of privacy per record as described by some function E . But the principles described above know nothing of budgets -they are purely descriptive. It is therefore important to design a mechanism which is private even when the program fails to meet the intended goals. With personalised differential privacy this is a crucial question -because the budget itself is clearly a sensitive object. In a nutshell, the ProPer approach involves tracking the provenance of each record in any intermediate table (on which sensitive input record does it depend), and by silently dropping records from the arguments to statistical queries if the presence of those records would break the privacy budget of some individual. The provenance information is used to make that link.</p><p>We begin with an informal overview before describing the system in formal terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview of ProPer</head><p>The ProPer system is described in terms of two main components: the protected system which stores all sensitive data and its derivatives, and mediates all computation over that data, and the client program which queries the sensitive data, requests computations to be performed over the sensitive data, and drives the inclusion of new input records into the protected system. An illustration of the architecture is given in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table Environment</head><p>Noisy responses Inputs From the viewpoint of a client program, the system just stores tables. Tables are referenced via table variables. A client program will issue a command to the protected system phrased in terms of table variables. These commands will represent transformations such as "Select all females from table A and assign the result to table B", or "Input some new records and assign them to table C", or primitive differential-private queries such as "Return the number of records in table C, with 0.5-differential privacy.".</p><p>The records that are input are the subject of our privacy concerns. We refer to those records as individuals. To provide Edifferential privacy for the individuals, the protected system needs to maintain more information than just the mapping between table variables and tables. For each individual r that has been input to the system so far, a privacy budget for r needs to be maintained. Initially the budget will be E (r). As queries are performed over time the budget for each individual may decrease.</p><p>There are two key issues that the system must address: (i) how much should the budget for each individual be decreased when a table is queried, and (ii) how do we prevent the budget from becoming negative (which would imply that we have violated privacy).</p><p>The solution to this is to track, together with each record, its provenance. The provenance of a given record is just the individual from which that record was derived (if any). Problem (i) is then solved by noting that the cost for individual r is the privacy cost of the query multiplied by the number of elements in the table which have provenance r (c.f. Corollary 3.4).</p><p>Before we can provide the formal definitions of the above sketch we need to define our basic domains and introduce some suitable notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Preliminary Definitions and Notation</head><p>Given sets A and B, A B denotes the set of partial functions between A and B with finite domain. If f is (partial) function then f [x → y] denotes the (partial) function which maps x to y and behaves as f for all other arguments. We will also write partial functions (and updates) using a set-comprehension style notation, e.g.</p><formula xml:id="formula_12">[x → x + 1|x ∈ {-1, 0, 1}].</formula><p>We assume an untyped set of records Rec, ranged over by r, s, etc. We will work extensively with multisets, in particular multisets of records. For a set A, we write mset(A) to denote the set of multisets over A (isomorphic to functions A → N). More specifically, the set of tables Table is defined to be mset(Rec).</p><p>It will be convenient to introduce some notation for working with multisets. We use multiset brackets such as e.g. A = {|5, 5, 6| }, denoting a multiset A containing two copies of 5 and one 6. We write multiset membership a n ∈ A to mean that there are exactly n copies of a in A, and a ∈ A means ∃n &gt; 0. a n ∈ A. Analogous to set-comprehensions (set-builder notation) we will use multiset comprehensions, with the ability to express multiplicities. For example:</p><formula xml:id="formula_13">{|x [n] | x n ∈ {|5, 5, -5| } ∧ x &gt; 0 | } = {|5, 5| }.</formula><p>But note that multiplicities may "sum up" as in this example:</p><formula xml:id="formula_14">{|0 × x [n] | x n ∈ {|5, 5, -5| } | } = {|0, 0, 0| }.</formula><p>Given multisets A and B, we write A B to denote the additive union, which is the least multiset such that whenever</p><formula xml:id="formula_15">a n ∈ A and a m ∈ B then a m+n ∈ (A B)</formula><p>Multi-Relations Binary relations are to sets as multi-relations are to multisets. In other words a multi-relation is just a notation for a multiset of pairs <ref type="bibr" target="#b12">[13]</ref>.</p><p>We will use the concept of multi-relation extensively to model the records of a table together with their provenance. For example, a table containing just three copies of a record r, two of which where derived from individual Alice and one from individual Bob, will be modelled by a multi-relation {|(r, Alice), (r, Alice), (r, Bob)| }.</p><p>Before we show how we use this in practice we need some notation to make reasoning with multi-relations more palatable.</p><p>Formally, given sets A and B we write A ↔ B to denote</p><formula xml:id="formula_16">mset(A × B). If R ∈ A ↔ B then we write a n R b to mean a is related to b, n times, i.e., (a, b) n ∈ R.</formula><p>Definition 4.1 (Operations on Multi-relations). Let R and S range over X ↔ X for some X, let be T is a subset of X, and U ∈ mset(X). We define the following operations involving multirelations:</p><formula xml:id="formula_17">Domain of a Relation dom(R) def = {|a [n] | (a, b) n ∈ R | } Relation Composition R ; S def = {|(a, c) [m•n] | a n R b ∧ b m S c | } Application R • U def = {|a [n•m] | a n R b ∧ b m ∈ U | } Right Restriction R £ T def = {|(a, b) [n] | a n R b ∧ b ∈ T | } Example 4.2.</formula><p>Given the following two multi-relations:</p><formula xml:id="formula_18">R = {|(x, y), (x, w), (x, w)| } S = {|(y, z), (w, z), (w, v)| }</formula><p>then dom(S) = {|y, w, w| }, R ; S = {|(x, z) [3] , (x, v) [2] | }, R £ {w} = {|(x, w) [2] | }, and R • {|w [2] , y| } = {|x [5] | }.</p><p>The following properties are easily verified.</p><p>Proposition 4.3. For all multi-relations R, R , S, and S , and set T , (i) Composition is -preserving in both arguments:</p><formula xml:id="formula_19">(R R ) ; S = (R ; S) (R ; S) R ; (S S ) = (R ; S) (R ; S ),</formula><p>(ii) restriction is -preserving in its first argument:</p><formula xml:id="formula_20">(R S) £ T = (R £ T ) (S £ T ),</formula><p>(iii) restriction and composition associate as follows:</p><formula xml:id="formula_21">(R ; S) £ T = R ; (S £ T ),</formula><p>(iv) and finally:</p><formula xml:id="formula_22">dom(R £ T ) = R • T</formula><p>Note that, as in (iv), we will freely use sets as if they were multisets without making the obvious injection operation explicit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Provenance Tracing</head><p>As mentioned, we will track the provenance of each record derived.</p><p>The key idea to achieve personalised differential privacy is that the provenance of a given record must be at most one record. We call this affine provenance.</p><p>Supported operations As we explained, in this setting, records' provenance should be affine. This is achieved by simply requiring that all transformations are unary and -preserving i.e., transformations F for which F (A B) = F (A) F (B). This guarantees that provenance can be tracked by observing the action of F on singletons, and (ii) provenance will always be a single element.</p><p>To give a simple syntactic characterisation of a class of unarypreserving functions, we can use a grammar of terms built from the standard operations of relational algebra, used here over multisets. The basic operators of relational algebra, transposed to multisets, are the set operations (multiset union , set difference -, cartesian product ×), together with record selection σp, which selects all elements satisfying property p, and projection πa which transforms each row by retaining only the columns given by schema a. We omit the details of the definitions and refer to <ref type="bibr" target="#b10">[11]</ref> for definitions of multiset variants of these standard operations. Definition 4.4 (Affine Relational Terms). Let V range over sets of variables and T over literal multisets. We define a family of variable-indexed relational algebra terms AV by the following grammar:</p><formula xml:id="formula_23">AV ::= x (∈ V ) | AV AV |AV -A {} |AV × A {} |A {} × AV | σp(AV ) | πa(AV ) | T Theorem 4.5. Any multiset transformation F defined by F (x) = A {x} is -preserving.</formula><p>The proof follows by induction on the definition of A {x} using the union-preserving properties of the operators. The restrictions imposed by the grammar are due to the facts that all the operations preserve unions in each argument individually, except for the second argument of set difference, and that preserves unions across its arguments simultaneously, whereas × does not (i.e.</p><formula xml:id="formula_24">(A A ) × (B B ) = (A × B) (A × B ) ).</formula><p>Provenance Tables The fact that we will track affine provenance leads us to define a provenance table as a table in which the affine provenance of each element is recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.6 (Provenance Table). A provenance table is a multi relation of type</head><formula xml:id="formula_25">ProvTable def = Rec ↔ Rec ⊥ , where Rec ⊥ def = Rec ∪ {⊥} for some distinguished non-record ⊥.</formula><p>The underlying table T represented by a provenance table D is obtained by simply taking the domain of D, i.e. T = dom(D). The provenance of each element r of the table T is given by the element to which they are related, viz, if rDs then there is a copy of r in T that has provenance s. If some record r is related to ⊥ this signifies that r is present in the table, but that it has no provenance (i.e. it was not derived from any individual).</p><p>In the remainder of this section we introduce the notation and techniques necessary to permit provenance to be traced across computation.</p><p>How do we build and maintain provenance tables? We need a way to create provenance tables from new tables, and we need a way to construct the provenance table of a table produced by a transformation applied to a (provenance) table.</p><p>When new records of individuals enter the system then their provenance table has a simple form: the provenance of each record is itself. When we create a new literal table (i.e. where the elements do not depend on individuals) then each record has provenance ⊥. The following notation for these cases will be useful: Definition 4.7. For a set of records R, define the identity provenance table</p><formula xml:id="formula_26">IdR def = {|(r, r) | r ∈ R | }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For a table T define the constant provenance table</head><formula xml:id="formula_27">ConstT def = {|(r, ⊥) [n] | r n ∈ T | }.</formula><p>The final building block is to show how to lift a function F which computes over tables to a function F which computes over provenance tables so that (in particular) the following diagram commutes:</p><formula xml:id="formula_28">D F / / dom D dom T F / / T Definition 4.8. Given a -preserving function F ∈ Table → Table, define F ∈ ProvTable → ProvTable by F (D) def = F ; D where F ∈ Rec ↔ Rec is defined by t n F s ⇔ t n ∈ F ({s})</formula><p>The fact that the diagram above commutes is captured as follows: Lemma 4.9 (functional correctness). dom( F (D)) = F (dom(D))</p><p>Proof. First we show that the relational representation of F and the relational application operator behave as expected:</p><formula xml:id="formula_29">F • A = F (A)<label>(1)</label></formula><formula xml:id="formula_30">F • A = {|a [m•n] | a n F b, b m ∈ A | } = {|a [m•n] | a n ∈ F ({b}), b m ∈ A | } (Def. 4.8) = {|a [k] | a k ∈ F (A) | } (F preserves ) = F (A)</formula><p>Now we show:</p><formula xml:id="formula_31">dom(D ; D ) = D • dom(D ) (2) dom(D ; D ) = dom({|(a, c) [m•n] | a m D b, b n D c | }) = {|a [m•n] | a m D b, b n D c | } = {| a [m•k] | (a, b) m ∈ D ∧ b k ∈ dom(D ) | } = D • dom(D )</formula><p>Finally we calculate:</p><formula xml:id="formula_32">dom( F (D)) = dom( F ; D) = F • dom(D) (Eq. 2 ) = F (dom(D)) (Eq. 1 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">The System Model</head><p>The semantics of the overall system will be given by a probabilistic transition system described by combining the client program with the protected system.</p><p>Protected System The protected system is a collection of states which encodes four pieces of information:</p><p>1. the set of individuals which have been input to the system so far, 2. a privacy budget (a positive real) for each of these individuals indicating how much of the personalised privacy remains, Here we assume that F ranges over an unspecified set denoting -preserving functions in  </p><formula xml:id="formula_33">| F (tv 1 • • • tv k ) Transform | T Table literal, T ∈ Table | input</formula><p>Reference to the input stream Figure <ref type="figure" target="#fig_7">2</ref>. ProgAct: the labels of the transition system an unspecified set of queries with the convention that Qε denotes an ε-differentially private query. Note that we will not formally distinguish the name of a function (as used here to define the set of actions) from its denotation (as used in the specification of the semantics of the system below). The idea is that programs have no direct access to tables, but make requests for the system to manipulate them on their behalf. This includes making a request for the system to collect new individuals via an input action (and place them in a table variable). The primitive query action is special. Firstly, it does not model a request, but rather a request and its result all in one. The reason for this is that it allows us to model value passing without needing to introduce any specific syntax for programs. Secondly, the value returned by the query is known to the program, and the program can act on it accordingly. From the perspective of the program and the protected system together, this value will be considered an observable output of the whole system. We also model internal actions of the program (and hence the passage of time) via the traditional silent action τ . A program, then, is just a ProgAct-labelled transition system. However we impose some mild restrictions on the transition system which model the fact that (i) the query operation really is an input operation, so if the program issues a query, there must be a transition for that query with every possible value, and that (ii) the program is fully deterministic, so that at most one type of action is possible in any given state, and the action determines the next state. Remark: Implicit parameters To avoid excessive parameterisation of definitions, in what follows we will fix some arbitrary client program P, →, P0 and some arbitrary personal budget E and make definitions relative to these.</p><p>Configuration Semantics Now we can provide the semantics of the combination of a program and the protected system -what we will call a configuration:</p><formula xml:id="formula_34">C ∈ Config def = P × (TVar → ProvTable) × (Rec R + )</formula><p>We will write a configuration as a triple P, E, B where metavariable E ranges over the table environment and B ranges over the budget.</p><p>The behaviour of a configuration will be a form of probabilistic labelled transition system whose labels are the values of queries made by the program, the silent transition τ , and the tables of unique individuals which are input by the environment. Definition 4.12 (Initial configuration). The initial configuration is formed from the initial program state, the environment that maps every variable to the empty provenance table, and the empty budget table: We put "probability" in parentheses because the relation is not a priori probabilistic but something that must be proven; this is established in Lemma 4.16. First we provide some explanation of each nontrivial rule in turn.</p><formula xml:id="formula_35">C0 def = P0, [tv → {|| } | tv ∈ TVar], []</formula><p>[Input] The program requests an input to be made and assigned to a table variable. The rule imposes a constraint on the records T which are input: it must be a set of records, and this set must be disjoint from the records previously input (the domain of B). This reflects the idea that the input records are the subject of privacy and represent unique individuals. The transition of the configuration is labelled with T to record that the environment chose to input T . The probability of the transition is 1, meaning that the choice of input is treated nondeterministically. The configuration is updated in two ways. Firstly, the table is converted to a provenance table by recording that the provenance of each record is itself. Secondly the budget for each new record is initialised from E .</p><p>[Assign] The program requests a transformation of existing data. Here we apply the mechanisms developed in Section 4.3 to lift the function (respectively, table) into the world of provenance tables.</p><p>[Query] Here the program is requesting the value of a query Qε(tv ). To answer the query we must determine the eligible records, L, from the table tv , which can safely be involved in this query. To do this we first determine a Cost map C, which describes the privacy cost which would be inflicted upon individual r by releasing the query Qε(tv ); the cost of an ε-differentially private query on tv to an individual r is ε multiplied by the number of records in tv which have provenance r. Given the cost map, we can determine A, the set of individuals for which this cost is Acceptable -i.e. those who have sufficient budget. Finally we can use A to determine L: it is the sub-table of records which depend at most on records in A.</p><p>The probability of the transition is inherited from the probability that the query returns that particular value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Trace semantics</head><p>The transition system on configuration C a -→p C is fully probabilistic in that C and the value of a uniquely determine p and, when p &gt; 0, C . This makes it very straightforward to lift the single-step semantics to a probabilistic trace semantics.</p><p>In what follows let σ range over traces, sequences of zero or more actions Act * . The empty trace is denoted by [] and aσ denotes the trace starting with a and continuing with σ. We write C σ = ⇒p to mean C σ = ⇒p C for some C . Although we have a trace-labelled transition system involving numbers derived from probabilities, it remains to show in what sense we have specified a probabilistic system. We begin with a definition which describes when an input sequence is compatible with a given trace. Definition 4.15 (Input Compatibility). An input trace i is a sequence of mutually disjoint sets of records. We say that a trace t is compatible with i, written t i iff the subsequence of inputs in t is a prefix of i. Now we can state the sense in which the transition system is probabilistic: it can be viewed as a probabilistic function of the input and the length of the trace observed: Lemma 4.16 (Traces are Probabilistic). For all input traces i, and all n ≥ 0,</p><formula xml:id="formula_36">Σ{|p | C0 t = ⇒p ∧ t i ∧ size(t) = n | } = 1</formula><p>I.e. in response to a given input, the possible traces of a program of a given length form a probability distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof. (sketch)</head><p>A key here is the following determinacy property: whenever C a -→p C and C a -→q C for p, q &gt; 0, then C = C and p = q. This can be established by cases according to the transition, and depends crucially on the assumption that the program transitions are deterministic. From this it is straightforward to show that C t = ⇒p C and C t -→q C for p, q &gt; 0, imply p = q and C = C . The first clause(p = q) is easily established by cases according to the rule inducing the transition, making use of determinism assumption about programs; the second clause (C = C ) then follows easily from the first. Armed with these two properties, the proof follows by induction on n.</p><p>So whenever C σ = ⇒p, p is the probability of observing σ among traces of the same length and for which the input sequence is the same. We thus write P r(C</p><formula xml:id="formula_37">σ = ⇒) = p to mean C σ = ⇒p.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ProPer Provides E -Differential Privacy</head><p>In this section we establish the main theorem for the system, which states that the trace semantics is an E -differentially private function of its input. In order to state this in a convenient way we introduce some notation.  = ⇒) = q for some q such that p ≤ q • exp(E (r)). where where This relation will be used to express a key invariant in the correctness proof, and can also be thought of (in the main proof) as establishing the correctness of the provenance information. Now we establish some basic properties of this relation on provenance tables. </p><formula xml:id="formula_38">D =      F (E(tv 1) • • • E(tv n)) if e = F (tv 1 • • • tv n) Const(T ) if e = T E(tv ) if e = tv</formula><formula xml:id="formula_39">C = [s → ε.size(E(tv ) • {s}) | s ∈ dom(B)] A = {r | B(r) ≥ C(r)} L = E(tv ) • (A ∪ {⊥}) p = Pr(Qε(L) = n)</formula><formula xml:id="formula_40">r D i ) ⇒ i∈I Di r i∈I D i Proof. ∀i ∈ I.(D i £ {r}) Di = D i ⇒ i ((D i £ {r}) Di) = i D i ⇒ i (D i £ {r}) ( i Di) = i D i ⇔ ( i D i £ {r}) ( i Di) = i D i (4.3(ii)) ⇔ i∈I Di r i∈I D i (def of r )</formula><p>The following establishes that computations over provenance tables preserves Proof. Assume premise.</p><formula xml:id="formula_41">F (D ) = F ; D (def.) = F ; (D £ {r} D) (premise) = ( F ; (D £ {r})) ( F ; D) (4.3(i)) = (( F ; D ) £ {r}) ( F ; D) (4.3(iii)) = (( F (D )) £ {r}) F (D) ( F def.)</formula><p>Hence ⇒ F (D) r F (D ) as required.</p><p>Definition 5.7 ((r, ε)-similarity for configurations). We define the following similarity relations for (the components of) configurations:</p><formula xml:id="formula_42">• E r E ⇐⇒ ∀tv . E(tv ) r E (tv ) ∨ E(tv ) = E (tv ) • B r,ε B ⇐⇒ B[r → ε] = B ∧ ε ∈ [0, E (r)] • P, E, B r,ε P , E , B ⇐⇒ P = P ∧E r E ∧B r,ε B Finally, define C r,ε ∼ C iff C r,ε C or C r,ε C.</formula><p>The generalised version of Theorem 5.2 establishes the invariant relation between configurations from which the Theorem is a straightforward corollary. ∼ C for some ε such that p ≤ q. exp(E (r) -ε).</p><p>The proof is given in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Implementation and Experimental Results</head><p>In this section we start by briefly describing the implementation of ProPer. We continue with a small example to give a taste on how the tool is used, and finally we present some experimental results in terms of time and memory execution applied to a couple of benchmarks, comparing ProPer with PINQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Description of the Tool</head><p>We have implemented our PDP approach into the tool ProPer. The tool has been implemented in C#.</p><p>In order to interact with the tool, the user must be working on a programming environment (e.g., C#) and needs to create an instance of the ProPer class. After this, there are a number of constructs available thorough the ProPer API to initialise and manipulate data. ProPer is based on LINQ, and its interface has been designed having PINQ as inspiration so not surprisingly the way a user interacts with both tools is similar, modulo some syntactic differences.</p><p>Despite similarities there are important differences in the way PINQ and ProPer are implemented as explained below.</p><p>(i). When a new data set is given to ProPer, each record of the data set is assigned a unique key and an individual privacy budget. In PINQ records do not have a key and the privacy budget is global.</p><p>(ii). ProPer performs provenance tracking using the above mentioned record keys. One feature of this provenance tracking is that each record depends at most on one record from the input set.</p><p>(iii). Some transformations are implemented differently: In ProPer Where and Select are equipped with provenance tracking mechanisms, but this is not the case in PINQ.</p><p>(iv). Though the dynamic updating of databases (adding records) is possible in PINQ, the added records inherit the current global budget and thus they can be used as many times in queries as the old records. In ProPer, PDP guarantees that added records may participate in as many queries as their individual budget allows, not depending on others' record budget (or global budget).</p><p>In what follows we elaborate on how ProPer works. Let us assume the user has initialised a data set and wants to perform a number of transformations in order to make some queries. In order to do this, a ProPer object is first created, the data set is imported into ProPer, the transformations are applied to this object, and finally the user can then run arbitrary queries on that ProPer object. The above description is a simplification as ProPer only supports transformations where each resulting record depends on at most one record. If other transformations not respecting this constraint are neededthen a PINQ subroutine will be called, and treated like a primitive query.</p><p>In more detail, in ProPer, sensitive data is stored in a protected object with the generic type of ProPer&lt;T&gt; (in PINQ sensitive data is placed in a PINQueryable&lt;T&gt; object). When data is manipulated using -preserving transformations, provenance information is also transferred and attached to the resulting records. Two important supported transformations are Where and Select representing the projection(π) and selection(σ) primitive operators in relational algebra. When it comes to aggregation, records with sufficient privacy budget are selected and their privacy budget is reduced. Also when a transformation with unsupported type of provenance is issued, the data set may switch to classical differential privacy by calling AsPINQ(double epsilon). This reduces the budget of each involved record by ε, and creates a protected object of type PINQueryable&lt;T&gt;. From this point the resulting PINQueryable&lt;T&gt; object can be used in other arbitrary transformations defined in classical differential privacy or contribute in other ε-differentially private aggregations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Example</head><p>As mentioned previously, PINQ introduces a special parallel composition operation for applying queries to disjoint parts of a data set. We argued that personalised budgets implies that the analyst does not need to construct parallel queries ( §3) -it is just as efficient to pose sequential queries. But in situations where there is no natural partition of data our approach is not only more convenient, but also gives strictly better results. Let us assume a data set on which we will perform three queries, each one with accuracy ε, and such that the pairwise intersection of the intended domains of these queries is nonempty but where we know that that the intersection of the 3 queries is empty (see Figure <ref type="figure" target="#fig_13">4</ref>). In the universe where each person is allowed to have at most two roles, the queries Teachers, Managers and Headmasters are asking about individuals in different roles. In this case, we cannot use parallel composition (as in PINQ) since it would require that the queries are disjoint. If we run them sequentially it would consume 3ε, whereas if we use PDP we will consume 2ε. (Note, that in the case of 3 disjoint queries, the PDP approach would consume the same budget as in the parallel case (ε).) The above case may be generalised: Given n queries such that each record is involved in at most g queries, would give the following: parallel composition (à la PINQ) cannot be applied, PINQ sequential composition would consume n • ε, while PDP would consume g • ε.</p><p>As a simple example we demonstrate how this analysis can be implemented in ProPer. We use the structure described below to store an individual's information, where each individual has at most two different roles: role1 (e.g., Teacher), and role2 (e.g., Manager). To initialise and populate our database with sample data we can pass an array of type Individual as an argument to the constructor method:</p><formula xml:id="formula_43">Individual [] population = new Individual [] {</formula><p>new Individual { name = " Alice " , role1 = " Teacher " , role2 = " Headmaster "} , new Individual { name = " Bob " , role1 = " Manager " , role2 = " Teacher "} , ... } var protectData = new ProPer &lt; Individual &gt; ( population . AsQueryable () , budget ) ;</p><p>To construct a ProPer protected object that only stores information about Teachers we can use the selection operation. Note that each record in the resulting ProPer has a dependency relation with exactly one record from the input data set:</p><p>var Admins = protectData . Where ( person = &gt;( person . role1 . Equals (" Teacher ") || person . role2 . Equals (" Teacher ") ) ) ;</p><p>Using the Select transformation we can modify an attribute's value or totally remove an attribute from a relation. For instance, as you can see in the following code, we transformed the table storing information about all Teachers into another table containing the length of their names:</p><p>var NameLengths = Admins . Select ( person = &gt; ( person . name ) . Length ) ;</p><p>Finally, to extract information from the above table we call the method AsPINQ(epsilon) which will reduce the budget of each individual record from the data set under consideration by ε, and will create a PINQueryable object with total budget ε. Now it is possible to run a classical differential privacy query; the simplest one being to call an aggregation function with accuracy ε, as shown in the code below. Similarly, the ProPer object can be converted into a PINQueryable object as follows:</p><p>var pinqObj = NameLengths . AsPINQ ( epsilon ) ;</p><p>Note that PINQueryable objects can also be used in more complicated transformations like Join and GroupBy, available in PINQ.</p><p>As we have previously mentioned, another distinct feature of ProPer is its ability to deal with dynamic databases. For that, ProPer has the following available methods: Update, Insert and Delete. It is also possible for users to define their own methods to manipulate data if needed be. A function to refresh the contents of the database when it is called can be defined with the SetRefresh() method. The defined function is called by the client program each time Refresh() is called: protectData . SetRefresh ( obj = &gt;( obj . Remove ( predicate = &gt; true ) )</p><p>. Insert ( newPopulation . AsQueryable () , epsilon ) ) ; protectData . Refresh () ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experimental results</head><p>To have a space and execution time comparison we implemented the k-means clustering algorithm both in PINQ and ProPer. This algorithm only uses projection and selection primitives which makes it a perfect candidate for comparison. The k-means algorithm accepts four parameters: a list of records, the number of centres, the number of dimensions, and the number of iterations. For the purpose of this research we fixed three of the parameters (Number of dimensions = 4 , Number of centres = 4 , Number of iterations = 5), and modified the number of records to see its effect on execution time and memory usage.</p><p>The result of our experiments concerning time is shown in Figure <ref type="figure" target="#fig_10">5</ref>, where it is possible to see the effect on execution time when varying the number of records. As it can be seen in the figure, adding provenance tracking (ProPer) has a negative effect on the execution time and slows down the system by around 15 percent. Concerning the memory usage, ProPer implementation of the k-means clustering algorithm uses twice as much memory as the PINQ implementation. This can be motivated by the fact that each record has the type double, and for each record a key with type int and a structure to keep track of privacy budget is needed. This high memory usage is justifiable since these extra structures (key and privacy budget) has almost the same size as the size of the record. More generally the overhead in memory will be the ratio of the size of the record with and without the provenance record key.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Limitations</head><p>The restriction of ProPer to unary union-preserving transformations means that in some cases we simply have to fall back to using PINQ routines. For example, in the network analysis example of McSherry and Mahajan <ref type="bibr" target="#b15">[16]</ref> the first transformation of the dataset is to group network requests by IP address. If the number of possible IP addresses was small and statically known, then we could iterate over this list to select the elements corresponding to each IP. But since they are not, the list of groups clearly has multiple provenances and is thus not supported by our method. So in this example we immediately fall back to using a PINQ subprogram, and appear to get no benefit from personalised budgets. But potential benefits from personalised budgets are not far away. For example, if one decided to restrict analysis to a specific geolocation, then personalised budgets would ensure that we don't waste the budget of the rest of the world. Another example is if traffic data arrives continuously over time, in which case we would automatically filter the records which have an exhausted budget without requiring any visible bookkeeping at the level of the analyst code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Related work</head><p>The literature on differential privacy, although only ten years old, is already vast. For an overview we refer to Dwork's surveys <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. We consider work related along four dimensions: general systems which provide mechanisms for constructing differentially private analyses, approaches to dealing with dynamic data, provenance and its connection to privacy, and approaches to improving the utilisation of privacy budget.</p><p>Systems Enforcing Differential Privacy As mentioned earlier, the interactive style of our system is inspired by PINQ <ref type="bibr" target="#b16">[17]</ref>. The implementation of PINQ has a number of side-channels as pointed out in <ref type="bibr" target="#b11">[12]</ref>; these and other implementation weaknesses ( <ref type="bibr" target="#b18">[19]</ref>) are certainly present in our implementation and it has not been our goal to focus on those. Other systems of note include Airavat <ref type="bibr" target="#b23">[24]</ref>, which is a MapReduce-based framework for constructing differentially private programs. Untrusted client analysts construct mappers, and the system provides differentially private reducers. Note that mapping is restricted in Airavat (by modifying the JVM) to be a union-preserving operation ("only a single record is allowed to affect the key-value pairs output by the mapper"), so it would be interesting to explore personalised budgets in that setting since it could potentially improve the budget utilisation over time, and perhaps remove the need to statically decide and enforce the exact number of elements produced by the mapper. Another line of work developing the Fuzz and DFuzz prototypes <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b22">23]</ref> describes non-interactive differential privacy in which the whole computation over private data is described by a domain-specific functional program, and a sensitivity-based static type system determines statically whether the computation will be within budget. This approach would combine well with ours by using it as a (necessarily sideeffect free) query sublanguage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamic systems and data streams</head><p>There are different senses in which a system might support dynamic data. In one sense the users are static, but their data arrive as a stream. One approach to privacy on streaming data is Pan-privacy <ref type="bibr" target="#b17">[18]</ref>, a stronger notion than differential privacy which ensures that the entire state of the system is private. Streaming PINQ is a version of PINQ that supports this kind of data <ref type="bibr" target="#b25">[26]</ref>. GUPT introduces a novel concept of privacy which degrades over time. It seems that this is a feature that could be added to ProPer by periodic increase in the budgets of records. Tschantz, Kaynar, and Datta <ref type="bibr" target="#b24">[25]</ref> build a model and proof techniques for reasoning about interactive differential privacy with records that are input over time. They introduce a specific generalisation of differential privacy called differential noninterference. Their formal model of noninterference has similarities to ours, based on probabilistic transition systems. They develop bisimulation-like proof methods and similar ideas could be useful in our setting to refactor our main proof. In our setting the one system we reason about is parameterised over any program which uses the internal API. In the formal model of Tschantz et al the queries are supplied by the environment. Thus the model of the (malicious) analysis is the sequence of all possible queries (for all possible input sequences). A question mark over this model is that is does not capture the strategy of the user; for a probabilistic systems it is known from the noninterference literature that modelling the user using nondeterminism rather than a strategy can hide the presence of information leaks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b26">27]</ref>. One aspect of their model is not captured in our system, they model bounded memory. This causes an unexpected magnification in the privacy cost of computations, since addition of one record into an input stream will cause a full memory to change by two records (the record itself and the record that it displaces).</p><p>Provenance and Lineage The notion of provenance that we use is more specifically called what provenance in the terminology of Cheney et al <ref type="bibr" target="#b1">[2]</ref>. More specifically it is the lineage notion from Cui et al <ref type="bibr" target="#b2">[3]</ref>. Union-preserving transformations are called dispatchers in that work.</p><p>Our main principle is the tracking of data from input to the point at which it is used in a query. Complementary to this, Birgisson, McSherry and Abadi <ref type="bibr" target="#b0">[1]</ref> show how to improve privacy budgets by tracking from the result of a query to the final result of the (batch) program; if the query is not used to produce the final result then you don't need to count it's cost. In some sense this optimisation is already built into systems like Fuzz. Our model assumes that the results of intermediate queries are observed by the attacker, so using this principle would require us to refine our model, but it can be plugged straight into our implementation.</p><p>There are a number of other works which link the concepts of provenance and privacy, although these are mainly connected with answering queries about the provenance of data in a privacy preserving manner, e.g. <ref type="bibr" target="#b3">[4]</ref>.</p><p>Improving the Budgeting Accuracy of Composition Many methods in differential privacy deal with improving the ε-bound that is attributed to a given class of computations. Some of these are related to the deficiency of the sequential query composition principle, and are typically much more specialised (and therefore more technically sophisticated) than the method of provenance tracing described here -see for example <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b27">28]</ref>. Palamidessi and Stronati <ref type="bibr" target="#b20">[21]</ref> provide a compositional method for improving the sensitivity estimation for relational algebra terms. It would be interesting to investigate whether these ideas can be used alongside our personalised approach.</p><p>Proserpio, Goldberg and McSherry <ref type="bibr" target="#b21">[22]</ref> introduced wPINQ, a framework for weighted datasets. In wPINQ, "problematic" records (those inducing extra noise to preserve privacy) are specially treated. The idea is that in order to better preserve privacy while not degrading the accuracy of the query result, the weight of those individual records in an aggregate query is scaled down, instead of scaling up the noise added to all records. Note that weights in wPINQ are associated with each and every record, whereas budgets in ProPer are associated just with individuals (the original inputs). By making weights part of every record, the privacy of the weights themselves will be protected by the requirements of the definition of differential privacy. Weights are used to track sensitivity at the level of each record level -similar to the fine-grained accounting achieved by tracking provenance. But the number of transformations that wPINQ supports is more than in PINQ. The price to pay is that every primitive query must be implemented to use the weights appropriately, and must be proven to be differentially private. In ProPer the correctness argument for the system itself has to be argued from first principles, but the method is able to reuse arbitrary differentially private queries as sub-programs without modification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We have introduced a new concept of personalised differential privacy (PDP) that improves the bookkeeping regarding the cost of composed queries, and makes it easy to include dynamic expansion of the data base. We have realised this idea in the design of ProPer, a system which enforces PDP for all (deterministic) client programs that compute against a simple API. We have proved that the ProPer model provides personalised -and therefore also standard -differential privacy.</p><p>On Limitations of Affine Provenance In our development of this work, the implementation preceded the theoretical development <ref type="bibr" target="#b8">[9]</ref>. Our first implementation traced the provenance for a much more general class of (SQL) functions, i.e. we traced provenance across operations like join, which implies non affine provenance (the provenance of a record may be more than one input record). Through our formalisation we subsequently discovered that this in fact violates differential privacy. Used as a descriptive mechanism, where we record privacy debt rather than spend from a budget, this approach is still sound since it never needs to exclude any records from queries, but it is less clear how to deploy such a system. The restriction to unary union-preserving functions, on the other hand, limits the functionality of client programs, but seems no worse than Airavat's mapper restrictions. In section 4.3 you can see a list of relational algebra operations that guarantee to have records with affine provenance. In any case, when a subcomputation cannot be expressed via a union-preserving transformation we can still plug in any other black-box differential privacy mechanism. This was further discussed in Section 6.4.</p><p>On Dynamic Data and Utility Perhaps the biggest advantage of PDP is that it smoothly supports dynamic databases in a PINQ style system -something that seems difficult to achieve in the presence of a single global budget. Our prototype implementation shows a 15% slowdown compared to PINQ, requiring just a constant space overhead per record.</p><p>Another potential advantage of PDP is precisely personalisation; each individual can set her own privacy budget. However we are cautious in our assessment of this as a feature in its own right rather than just a means to an end. What is missing in the theory of PDP is a proper treatment of utility. The personal budget determines how quickly a record will be "used up". This complicates the understanding of the utility of the information returned by queries. But even if we start out with every record being assigned the same budget, if the analyst has no prior on the data then it can be hard to say much about the utility of any given query.</p><p>One particular case where utility guarantees may be easy to give (without a prior) is the case when the rate at which new data enters the database is sufficiently high relative to the rate at which queries consume their budgets. Assume a stream of inputs with flow rate f , queue size l and individual privacy budget of b. If we apply ε-differentially private queries at an execution rate below b×f l×ε , then we can guarantee that ProPer can answer all queries without excessive noise caused by blocking too many old records from being used in queries. A more rigorous analysis of this idea is appropriate for future work.  ∼ C . Since the probability of the input transition is 1 we have p = q and hence p ≤ q. exp(E (r) -E (r)) as required. </p><p>From here we argue by cases according to the rule applied for the last transition P1, E1, B1 a -→p 2 P, E, B . In every case except for the query transition we will see that p2 = 1, and that P1, E1, B1 a -→1 C for some C . In those cases it follows that p ≤ q • exp(E (r) -ε) by taking ε = ε1 and using (6).     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. ProPer System Structure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>|</head><label></label><figDesc>Qε(tv )?v Primitive Query returning v ∈ Val Expr ::= tv Table variable</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Definition 4 . 11 (-→ P then 1 .</head><label>4111</label><figDesc>Client Program). A client program (a programfor short) is a labelled transition system P, →, P0 where P is the set of program states with initial state P0 and transition relation → ⊆ (P × ProgAct × P), satisfying the following properties. Firstly it is deadlock free -a program can always make a transition, and secondly it satisfies the determinacy property:For all states P , if P a -→ P and P b if a = b then P = P , 2. if a is not a query then a = b, 3. if a = Qε(tv )?r then b = Qε(tv )?r for some r , and for all s there exists a Ps such that P Qε(tv )?s -----→ Ps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definition 4 . 13 (</head><label>413</label><figDesc>Operational Semantics). The operational semantics of configurations is given by a "probabilistic" labelled transition relation with transitions of the form C a -→p C where a ∈ Act def = {τ } ∪ Val ∪ 2 Rec , and (probability) p ∈ [0, 1]. The definition is given by cases in Figure 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition 4 . 14 (</head><label>414</label><figDesc>Trace semantics). Define the trace transition relation ⇒ ⊆ Config × Act * × [0, 1] × Config inductively by the following rules:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Definition 5 . 1</head><label>51</label><figDesc>(r-difference). For any record r and any tables T and T , we write T r T to mean that T {|r| } = T . We lift this relation to traces, writing σ r σ to mean σ = σ1T σ2 and σ = σ1T σ2, for some σ1, σ2, T , T such that T r T . We will further lift T r T to various structures containing tables. In all cases we define the overloaded relation r So when σ r ∼ σ then σ and σ differ in exactly one element, an input set, and and their difference is exactly the record r.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 5 . 2</head><label>52</label><figDesc>(E -differential privacy for all traces). If σ r ∼ σ and Pr(C σ = ⇒) = p then Pr(C σ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 -</head><label>2</label><figDesc>Rec T ∩ dom(B) = ∅ P, E, B T -→1 P , E[tv → Id(T )], B[r → E (r) | r ∈ T ] →1 P , E[tv → D], B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>P , E, B[r → B(r) -C(r) | r ∈ A]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Operational Semantics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Proposition 5 .</head><label>5</label><figDesc>4. D r D ⇒ dom(D ) = D • {r} dom(D) Proof. D r D ⇒ (D £ {r}) D = D ⇒ dom((D £ {r}) D) = dom(D ) ⇒ dom(D £ {r}) dom(D) = dom(D ) ⇔ D • {r} dom(D) = dom(D ) (4.3(iv)) Proposition 5.5. ∀i ∈ I.(Di</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>r.</head><label></label><figDesc>Proposition 5.6. D r D ⇒ F (D) r F (D )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Lemma 5 . 8 .</head><label>58</label><figDesc>If σ r ∼ σ and C0 σ = ⇒p C, then C0 σ = ⇒q C where C r,ε</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. T=Teachers, M= Managers and H=Headmasters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Console . WriteLine ( NameLengths . NoisyAverage ( epsilon , x = &gt; x /20) * 20 ) ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Comparing PINQ and ProPer wrt execution time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>A</head><label></label><figDesc>. Proof of Main Lemma (5.8) Proof. Assume that σ r ∼ σ and C0 σ = ⇒p C. We proceed by induction on the length of the trace σ, and by cases according to the last step of the trace. Case 1: σ = []. Vacuous since we cannot have σ r ∼ σ if there are no inputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Case 2 : 1 =</head><label>21</label><figDesc>σ = σ1a. Suppose that C0 σ ⇒p 1 P1, E1, B1 a -→p 2 P, E, B = C, and hence that p = p1p2. We split this into two cases according to whether r is input on the last step, or earlier in the trace: Case 2.1: σ = σ1a and {a, a } = {T, T ∪ {r}}. Suppose that a = T (the other case is argued similarly). Then we must have P1 tv :=input -----→ P for some tv , and hence:C = P, E1[tv → Id(T )], B1[s → E (s) | s ∈ T ] C = P, E1[tv → Id(T ∪ {r})], B1[s → E (s) | s ∈ (T ∪ {r})] = P, E1[tv → Id(T ∪ {r})], B1[s → E (s) | s ∈ T ][r → E (r)] Hence C r,E (r)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Case 2 . 2 :∼ σ 1 . 1 =</head><label>2211</label><figDesc>σ = σ 1 a and σ1 r The induction hypothesis gives us q1, P1, E 1 , B 1 and ε1 such thatC0 σ ⇒q 1 P1, E 1 , B 1 p1 ≤ q1. exp(E (r) -ε1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Case 2 . 2 . 1 :</head><label>221</label><figDesc>Input. In this case a = T and P1 input ---→ P . Hence we have transitionsP1, E1, B1 T -→1 C P1, E 1 , B 1 T -→1 C where C = P, E1[tv → Id(T )], B1[s → E (s) | s ∈ T ] C = P, E 1 [tv → Id(T )], B 1 [s → E (s) | s ∈ T ]Since r ∈ T , it follows easily from 4 and 5 that C r,ε 1 ∼ C .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Case 2 . 2 . 2 :</head><label>222</label><figDesc>Silent. Similar (but simpler) argument to above -the only change in the configuration is the program component, so it follows directly from the IH.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Case 2 . 2 . 3 :</head><label>223</label><figDesc>Constant Transformation. P1 tv :=T ----→ P and hence P1, E1, B1 τ -→1 C and P1, E 1 , B 1 τ -→1 C where C = P, E1[tv → Const(T )], B1 C = P, E 1 [tv → Const(T )], B 1 and we reason as for case 2.2.1. Case 2.2.4: Table variable. Similar to the previous case, P1 tv :=tv ----→ P and hence P1, E1, B1 τ -→1 C and P1, E 1 , B 1 τ -→1 C where C = P, E1[tv → tv ], B1 C = P, E 1 [tv → tv ], B 1 and we reason as for case 2.2.1. Case 2.2.5: F -Transformation. Here P1 t:=F (t 1 ... tn)----------→ P, and so we haveC = P, E1[tv → F (E1(tv 1) • • • E1(tv n))], B1 C = P, E 1 [tv → F (E 1 (tv 1) • • • E 1 (tv n))], B 1Since, from 4 we have E1(tv i) r ∼ E 1 (tv i), i ∈ {1, . . . , n}, and so from 5.6 and 5.5 it follows that F (E1(tv1) • • • E1(tv n)) r ∼ F (E 1 (tv 1) • • • E 1 (tv n))and hence we have that C r,ε 1 ∼ C .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Case 2 . 2 . 6 :r,ε 1 ∼</head><label>2261</label><figDesc>Query. Here we have a rule instance of the form Query P1 Qε(tv )?n ------→ P P1, E1, B1 n -→p 2 Cand thus there is an analogous transitionP1, E 1 , B 1 n -→q 2 CwhereC = P, E1, B B = B1[s → B1(s) -C(s) | s ∈ A] C = P, E 1 , B B = B 1 [s → B 1 (s) -C (s) | s ∈ A ] C = [s → ε • size(E1(tv ) • {s}) | s ∈ dom(B1)] C = [s → ε • size(E 1 (tv ) • {s}) | s ∈ dom(B 1 )] A = {s | B1(s) ≥ C(s)} L = E1(tv ) • A A = {s | B 1 (s) ≥ C (s)} L = E 1 (tv ) • A p2 = Pr(Qε(L) = n) q2 = Pr(Qε(L ) = n)Since the environments are unchanged in this transition, E1r ∼ E 1 follows immediately from the induction hypothesis. Suppose, without loss of generality, that r is in C. Then it remains to show that, for some ε ,p1 • p2 ≤ q1 • q2 • exp(E (r) -ε )(8)Let us first compare the respective cost mappings C and C : E1r E 1 gives size(E1(tv ) • {tv }) = size(E 1 (tv ) • {s}) whenever s = r.Hence the only difference between C and C is a single mapping:C = C [r → ε • size(E1(tv ) • {r})].(9)Now consider A and A . Since C and C only differ on r, then if B1(r) ≥ C(r) then A = A {r}. Otherwise A = A . Consider these cases in turn: Case 2.2.6.1: A = A . and hence L = L , and hence p2 = q2. By taking ε to be ε1, requirement (8) follows from the induction hypothesis<ref type="bibr" target="#b5">(6)</ref>. Since the budget of r is unchanged in either transition, then B B follows from the induction hypothesis (5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Case 2 . 2 . 6 . 2 :</head><label>2262</label><figDesc>A = A {r}. L = E1(tv ) • (A {r}) = E1(tv ) • A E1(tv ) • {r} L = E 1 (tv ) • A = E1(tv ) • Awhere the last step follows since r ∈ A and E1 r ∼ E 1 . Hence L = L (E(tv ) • {r}) -i.e. the difference in the size of the sets on which the respective queries are made is size(E(tv ) • {r}). Since Qε is ε-differentially private, it follows from the definition of vanilla differential privacy thatp2 ≤ q2 • exp(ε • size(E(tv ) • {r}))(10)Combining this inequality with (6) we getp1 • p2 ≤ q1 • q2 • exp(E (r) -ε1) • exp(ε • size(E(tv ) • {r}))Rearranging the exponents gives p1• p2 ≤ q1 • q2 • exp(E (r) -ε ) when ε = ε1 -ε • size(E(tv ) • {r}).We complete the proof by showing that this value of ε gives B r,ε ∼ B . From the induction hypothesis (5) we have that B1 and B 1 agree on all values in their domains except r, and from (9) we have that the same holds for C and C . Thus B and B only differ on r, for which B(r) = B1(r) -C(r) = ε1 -ε • size(E(tv ) • {r}) and hence B r,ε ∼ B as required.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The first two items are modelled by a partial function from individuals to budgets, and we assume that the set of table variables is fixed (and at least countable). This leads us to the formal definition of the states: Definition 4.10 (Protected System States).Client Program ModelWe work with an abstract notion of a client program. A program is just a labelled transition system, subject to some restrictions, where the labels -the actions -represent the imperative API through which the program interacts with the protected system.The program model, inspired by PINQ<ref type="bibr" target="#b16">[17]</ref>, is an imperative program that computes with tables by requesting that the commands a ∈ ProgAct are performed. ProgAct is specified in figure 2.</figDesc><table><row><cell>States</cell><cell>def = (TVar → ProvTable) × (Rec</cell><cell>R + )</cell></row></table><note><p><p>3. a set of table variables</p>TVar used to identify intermediate tables computed, and 4. a table environment which maps each table variable to the provenance table it represents.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table → Table , and</head><label>→,</label><figDesc>Qε ranges over</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In an approach based on static analysis, such as the type-system of Fuzz<ref type="bibr" target="#b11">[12]</ref>, one could say that these two approaches are unified.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research has been partially supported by a grant from the Swedish Foundation for Strategic Research (SSF). Many thanks to our colleagues in the ProSec and Formal Methods groups for many helpful discussions, and special thanks Raúl Pardo Jiménez for participation in the early stage of the research, and to Niklas Broberg for comments on an earlier draft. Thanks also to Cédric Fournet and the anonymous referees for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Differential privacy with information flow control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Birgisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 6th Workshop on Programming Languages and Analysis for Security, PLAS &apos;11</title>
		<meeting>the ACM SIGPLAN 6th Workshop on Programming Languages and Analysis for Security, PLAS &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Provenance in databases: Why, how, and where</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chiticariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends databases</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="379" to="474" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lineage tracing for general data warehouse transformations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal The International Journal on Very Large Data Bases</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="58" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On provenance and privacy</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Database Theory</title>
		<meeting>the 14th International Conference on Database Theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Differential privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd International Colloquium on Automata, Languages and Programming, part II (ICALP 2006)</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4052</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory and Applications of Models of Computation</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4978</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A firm foundation for private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="95" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Cryptography</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">PINQuin, a framework for differentially private analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ebadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>Chalmers University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Linear dependent types for differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gaboardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haeberlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL &apos;13</title>
		<meeting>the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL &apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A multi-set extended relational algebra: a formal approach to a practical issue</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Grefen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>De By</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Engineering, 1994. Proceedings. 10th International Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="80" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Differential privacy under fire</title>
		<author>
			<persName><forename type="first">A</forename><surname>Haeberlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-relations in z</title>
		<author>
			<persName><forename type="first">I</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="62" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Practical differential privacy via grouping and smoothing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kellaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Papadopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th international conference on Very Large Data Bases, PVLDB&apos;13</title>
		<meeting>the 39th international conference on Very Large Data Bases, PVLDB&apos;13</meeting>
		<imprint>
			<publisher>VLDB Endowment</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="301" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing linear counting queries under differential privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS &apos;10</title>
		<meeting>the Twenty-ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS &apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="123" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Differentially-private network trace analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGCOMM Comput. Commun. Rev</title>
		<idno type="ISSN">0146-4833</idno>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="123" to="134" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Privacy integrated queries: an extensible platform for privacy-preserving data analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Mcsherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 ACM SIGMOD International Conference on Management of data</title>
		<meeting>the 2009 ACM SIGMOD International Conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Panprivate algorithms via statistics on sketches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS &apos;11</title>
		<meeting>the Thirtieth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On significance of the least significant bits for differential privacy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Computer and Communications Security</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Information-flow security for interactive programs</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSFW</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="190" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Differential Privacy for relational algebra: improving the sensitivity bounds via constraint systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Palamidessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stronati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">QAPL -Tenth Workshop on Quantitative Aspects of Programming Languages</title>
		<imprint>
			<publisher>Open Publishing Association</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="92" to="105" />
		</imprint>
	</monogr>
	<note>Electronic Proceedings in Theoretical Computer Science</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Calibrating data to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Proserpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">40th International Conference on Very Large Data Bases, VLDB&apos;14</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="637" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distance makes the types grow stronger: A calculus for differential privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIG-PLAN International Conference on Functional Programming, ICFP &apos;10</title>
		<meeting>the 15th ACM SIG-PLAN International Conference on Functional Programming, ICFP &apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Airavat: Security and privacy for mapreduce</title>
		<author>
			<persName><forename type="first">I</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T V</forename><surname>Setty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kilzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Formal verification of differential privacy for interactive systems (extended abstract)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Tschantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kaynar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Datta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Notes Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="2011-09">Sept. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Privacy integrated data stream queries</title>
		<author>
			<persName><forename type="first">L</forename><surname>Waye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th annual conference on Systems, programming, and applications: software for humanity</title>
		<meeting>the 5th annual conference on Systems, programming, and applications: software for humanity</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Information flow in nondeterministic systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wittbold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="144" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Differentially private data release through multidimensional partitioning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th VLDB Conference on Secure Data Management</title>
		<meeting>the 7th VLDB Conference on Secure Data Management</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
