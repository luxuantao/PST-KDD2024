<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How do Search Engines Handle Greek Queries?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fotis</forename><surname>Lazarinis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Miguel</forename><surname>Alonso</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Noriko</forename><surname>Kando</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nasredine</forename><surname>Semmar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Sutcliffe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">I</forename><surname>Tait</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Efthimis</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
							<email>efthimis@u.washington.edu</email>
						</author>
						<author>
							<persName><forename type="first">Nicos</forename><surname>Malevris</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Apostolos</forename><surname>Kousaridas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexandra</forename><surname>Lepeniotou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Loutas</surname></persName>
							<email>nloutas@aueb.gr</email>
						</author>
						<author>
							<persName><forename type="first">Υπουργείο</forename><surname>Εξωτερικών</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Υπουργείο</forename><forename type="middle">Μακεδονίας</forename><surname>Θράκης</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Λαική</forename><surname>Τράπεζα</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Laiki</forename><surname>Bank</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Πανεπιστημιο</forename><surname>Αιγαίου</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Η</forename><forename type="middle">Καθημερινή</forename><surname>Kathimerini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Σιδηροδρόμων</forename><surname>Οργανισμός</surname></persName>
						</author>
						<author>
							<persName><surname>Ελλάδος</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Greek</forename><surname>English</surname></persName>
						</author>
						<author>
							<persName><forename type="first">English -Αγγλικά</forename><surname>Greek</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
							<email>craigm@dcs.gla.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Christina</forename><surname>Lioma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
							<email>ounis@dcs.gla.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Farag</forename><surname>Ahmed</surname></persName>
							<email>fahmed@iws.cs.uni-magdeburg.de</email>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Nürnberger</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Technological Educational Institute of Mesolongli</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Jesus Vilares</orgName>
								<orgName type="institution">University of A Coruna</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">John I. Tait</orgName>
								<orgName type="institution" key="instit2">University of Sunderland</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of A Coruna</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Kuang-hua Chen</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Theodore Dalamagas</orgName>
								<orgName type="institution">National Technical University of Athens</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution" key="instit1">Chu-Ren Huang</orgName>
								<orgName type="institution" key="instit2">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">Ghassan Kanaan</orgName>
								<orgName type="institution" key="instit2">Yarmouk University</orgName>
								<address>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">National Institute of Informatics</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Fotis Lazarinis</orgName>
								<orgName type="institution">Technological Educational Institute of Mesolongli</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">David Losada</orgName>
								<orgName type="institution">University of Santiago de Compostela</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="institution" key="instit1">Alexandros Ntoulas</orgName>
								<orgName type="institution" key="instit2">Microsoft Search Labs</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<orgName type="department">Doug Oard</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Gabriel Pereira</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff13">
								<orgName type="institution">Universidade Nova de Lisboa</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff14">
								<orgName type="institution" key="instit1">Carol Peters</orgName>
								<orgName type="institution" key="instit2">ISTI-CNR</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff15">
								<orgName type="institution" key="instit1">Owen Rambow</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff16">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff17">
								<orgName type="department">Jacques Savoy</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff18">
								<orgName type="laboratory">LIC2M/CEA-LIST</orgName>
								<orgName type="institution">New Jersey Institute of Technology</orgName>
								<address>
									<settlement>Min Song</settlement>
									<country>France, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff19">
								<orgName type="institution" key="instit1">Sofia Stamou</orgName>
								<orgName type="institution" key="instit2">University of Patras</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff20">
								<orgName type="institution">University of Limerick</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff21">
								<orgName type="institution">University of Sunderland</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff22">
								<orgName type="department">Jesus Vilares</orgName>
								<orgName type="institution">University of A Coruna</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff23">
								<orgName type="department">Manuel Vilares</orgName>
								<orgName type="institution">University of Vigo</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff24">
								<orgName type="department">Maarten de Rijke Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Kruislaan 403</addrLine>
									<postCode>1098 SJ</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff25">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff26">
								<orgName type="department">Department of Informatics Athens University of Economics and Business Athens</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff27">
								<orgName type="laboratory">Ministry of Macedonia Thrace Εθνική Τράπεζα της Ελλάδος National Bank Of Greece</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff28">
								<orgName type="department">Aegean TEI Σερρών Technological Education Institute</orgName>
								<orgName type="institution">University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff29">
								<orgName type="department">Νέα Ελληνική Τηλεόραση ΝΕΤ</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff30">
								<orgName type="laboratory">Banks Τράπεζες Universities Πανεπιστήμια Radio Stations Ραδιόφωνο Colleges ΤΕΙ Travel Agents Ταξιδιωτικά Γραφεία TV stations Τηλεόραση Museums</orgName>
								<address>
									<postBox>Μουσεία anazitisis 63 321 776 396 190 532 1065 80 271 70 261 0 0 554 75 0 0 96 135 96 135 702 529 243 1375 950 anokato 502 200 580 1221 460 2268 634 200 phantis 412 483 978 652 459 502 trinity 1488 1429 2386 2614 1900 3641 806 672 visto 850 930 1340 2073 930 316 1650 400 300 a9</postBox>
									<postCode>1334 1030, 2044 2304, 1306 1478, 2094 524 1304, 1776 1311, 2666 2385</postCode>
									<settlement>AltaVista</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff31">
								<orgName type="department">Department of IT</orgName>
								<orgName type="institution">Chalmers University</orgName>
								<address>
									<postCode>S-412 96</postCode>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff32">
								<orgName type="department">Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff33">
								<orgName type="department">Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff34">
								<orgName type="department">Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<postCode>G12 8QQ</postCode>
									<settlement>Glasgow</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff35">
								<orgName type="department">Faculty of Computer Science Faculty of Computer Science</orgName>
								<orgName type="laboratory">Information Retrieval Group Information Retrieval Group</orgName>
								<orgName type="institution">Otto-von-Guericke-University of Magdeburg Otto-n-Guericke-University of Magdeburg</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">How do Search Engines Handle Greek Queries?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E58426960C3FC8680AC76CF37B88F3F1</idno>
					<note type="submission">2046 1493 3192 1049 1602 google 1866 1312 2953 3039 1841 1817 3100 1169 1712 Msn 1262 1030 2126 2418 1242 1430 2114 524 1260 yahoo 1435 1073 1985 1953 1519 1527 2827 818 1396 Totals: 10988 9119 17314 19761 10796 10853 23326 6822 9476 anazitisis 897 170 381 958 180 106 149 7 anokato 1376 1371 642 290 phantis 90 495 1197 152 242 271 81 trinity 1957 849 1519 2818 363 950 298 298 visto 1243 130 290 290 280 a9 703 541 1244 2656 1091 172 AltaVista 1109 494 1458 2844 136 1085 245 361 google 1875 688 1650 2926 352 1169 281 181 Msn 688 531 1244 2391 1047 100 yahoo 1057 495 1119 2785 130 1044 254 100 Totals: 11459 4058 9661 20021 2437 6734 2338 1300 Global Διεθνείς Greek Ελληνικές</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 Information Search and Retrieval, query formulation, search process</term>
					<term>H.3.4 Systems and Software, Performance evaluation (efficiency and effectiveness) Measurement, Performance, Experimentation Web Search Evaluation, Greek Queries, Greek Web, Search Engine Evaluation H.4 [Information Storage and retrieval]: Information Search and Retrieval Measurement, Performance, Experimentation Web retrieval, Known-item retrieval, Multilingual retrieval, Language-specific stemming Measurement, Performance, Experimentation Greeklish, query transliteration, web search H.3 [Information Storage and Retrieval]:H.3.3 Information Storage and Retrieval: Information Retrieval and Search-Conflation techniques</term>
					<term>Algorithms, Measurement, Performance, Experimentation, Languages, Verification Information retrieval, N-gram approaches, Stemming, Arabic language Performance, Design Search engine, information retrieval, Basque, agglutinative language, minority language Multilingual Queries and Retrieval EuroWordNet, RDF/OWL, Multilingual Search Engines E-Orthography, Farsi Documentation, Design Natural language processing, text categorization, thesaurus Natural language processing Fuzzy text search, Spelling variation, Orthographic and phonetic similarity, Writing systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Over the past few years there has been a lot of progress in technology used for addressing monolingual or multilingual web queries in languages other than English. Nevertheless, a great deal of work still remains to be done, e.g., on the morphological analysis of non-English web queries, before the retrieval performance on English and non-English are on a par. There's another pressing issue, however, that's at least as important: we know very little about users of monolingual or multilingual (non-English) web search facilities. Who are they? What do they search for? What are their intents? At WebCLEF ---the multlingual web retrieval track run at CLEF ---these questions and concerns have led to a very explicit definition of the retrieval task, where various assumption are being recorded as part of the topic statement. In the talk I will review the choices made at WebCLEF over the past few years and detail (and motivate) the current set-up.</p><p>Another important aspect of the talk concerns the lack of user data that most academic research groups have to work with. I discuss various ways around this, one example being the use of publicly available and usable showcases and demonstrators. We (the University of Amsterdam) have run and continue to run a small number of Dutch language online search and browsing tools. At the workshop I will discuss a number of findings of this strategy, based on a brief log analysis together with both quanitative and qualitative analyses. This talk is based on joint work with Leif Azzopardi (Glasgow), Krisztian Balog, Valentin Jijoun, Jaap Kamps (Amsterdam), and Borkur Sigurbjornsson (Barcelona).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preface</head><p>The First Workshop on Improving Non English Web Searching (iNEWS'07) took place on July 27 in Amsterdam (The Netherlands) in conjunction with the 30th Annual International ACM SIGIR Conference (SIGIR'07) aiming at bringing together researchers interested in non-English web searching.</p><p>Nowadays, over 60% of the online population are non-English speakers and it is probable the number of non-English speakers is growing faster than English speakers. Recent studies showed that non-English queries and unclassifiable queries have nearly tripled since 1997. Most search engines were originally engineered for English. They do not take full account of inflectional semantics nor, for example, diacritics or the use of capitals.</p><p>The main conclusion from the literature is that searching using non-English and non-Latin based queries results in lower success and requires additional user effort so as to achieve acceptable recall and precision. Furthermore, international search engines (like Yahoo and Google) are relatively weaker with monolingual non-English queries.</p><p>So, new tools and resources are needed to support researchers in non-English retrieval, new methodologies need to be proposed which will help the identification of problems in existing search engines and new teaching strategies should be formed aiding users to become more efficient in formulating their queries.</p><p>Taking into account these needs, the main objectives of this workshop are the proposal of techniques and the evaluation of tools which improve the effectiveness of the existing search engines. This way, the specific aims of the workshop have been:</p><p>▪ Evaluate search engines in non-English queries and measure the additional user effort.</p><p>▪ Define methodologies for evaluating the effectiveness of search engines in non-English queries.</p><p>▪ Study the user query patterns in non-English Web retrieval.</p><p>▪ Identify the factors that influence utilization of search engines in a multicultural world.</p><p>▪ Propose extensions to the search engines to improve non-English Web retrieval.</p><p>▪ Propose teaching strategies for helping users improve their searching behaviour.</p><p>▪ Identify how standard IR techniques (Indexing, Query representation, Query reformulation, etc) can be adapted in Web retrieval for non-English languages.</p><p>▪ Discuss the application of natural language processing techniques for non-English Web IR.</p><p>In response to our call, 13 papers were submitted. After a triple blind reviewing process, 4 papers were selected by the Program Committee for presentation as full papers and 6 more as short papers.</p><p>Finally, we wish to thank SIGIR organizers, the program committee and our sponsor, the "Rede Galega de Procesamento da Linguaxe e Recuperacion de Informacion (Galician Network for Language Processing and Information Retrieval)", funded by Xunta de Galicia government, for its support.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>July 2007</head><p>Fotis Lazarinis Jesus Vilares John I. Tait</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>iNEWS'07 Organization</head><p>Workshop Chairs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table of contents</head><p>Invited talk: Who's the user? Who's the researcher?</p><p>Invited Talk "Who's the user? Who's the researcher?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The web continues to expand and the dominant search engines, Google and Yahoo! claim to have indexed more than 20 billion pages <ref type="bibr">[10]</ref>. Recent statistics on Internet usage by language show that 29.5% is English and 70.5% is non-English <ref type="bibr">[7]</ref>. As the non-English web usage increases there are an increasing number of non-English queries that need to be handled by the search engines.</p><p>The goals of this research are (a) to evaluate how well search engines respond to Greek language queries; and, (b) to assess whether the Greek or global search engines are more effective in satisfying the user requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>[2] Bar-Ilan and Gutman explored how three search engines, AltaVista, FAST and Google, respond to four non-English languages, Russian, French, Hungarian and Hebrew. They found that the search engines ignored the special language characteristics and do not handle diacritics well. Moukdad <ref type="bibr">[11]</ref> studied how AltaVista, AllTheWeb, and Google handle Arabic queries compared to three Arabic engines (Al bahhar, Ayna, and Morfix). He found that the former had shortcomings in handling Arabic. Lazarinis <ref type="bibr">[9]</ref> used five Greek language queries to evaluate the performance of eight search engines, six global and two Greek. He noted that there were variations in the handling of Greek. Moukdad and Cui <ref type="bibr">[12]</ref> investigated how Chinese language queries are handled by Google and AlltheWeb, as well as Sohu and Baidu, the Chinese search engines. They found that the "global" search engines were not able to process the Chinese queries satisfactorily, thus introducing unexpected results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE GREEK LANGUAGE</head><p>The Greek language uses a different script to that of Latin-based languages. The Greek alphabet set has twenty four upper case letters, twenty five lower case letters and a number of diacritics or accent marks depending on the form used. The most commonly known forms of the Greek language are ancient or classical Greek, Katharevousa, and Demotic Greek (Dhimotiki). Depending on the system of accents used Greek is either polytonic or monotonic. The polytonic orthography system for Greek uses three accents, two breathings, iota subscripts and diaeresis. The polytonic system was used since the ancient times and was simplified into the monotonic system in 1982. The monotonic Greek language system uses one accent and the diaeresis, in order to signify that two adjacent vowels are pronounced separately and not as a diphthong.</p><p>Transliteration of Greek to Latin letters is common but adds to the complexity of processing Greek because of the different transliteration standards. Furthermore, individuals often ignore the standards and apply their own phonetic interpretation. The widespread use of computers and the Internet coupled with the slow progress in adopting non-Latin-based scripts has given rise to Greeklish, which is a form of transliteration used to exchange email messages and post to discussion fora.</p><p>Alevizos et al. <ref type="bibr">[1]</ref> discuss the challenges faced by search systems in handling Greek. <ref type="bibr">Kalamboukis [8]</ref> introduces the inflectional aspects of Greek and presents a stemming approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">METHODOLOGY 4.1 Selecting the Search Engines</head><p>For the study we selected ten search engines based on their popularity and market share. These were divided into two groups, five global or international in scope, and five Greek search engines. The global search engines are: A9, AltaVista, Google, MSN (Live) Search, and Yahoo!. The Greek engines are: Anazitisis, Ano-Kato, Phantis, Trinity, and Visto. <ref type="bibr">Appendix 8</ref>.1 lists the engines and their corresponding URLs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">User Needs and Task Definition</head><p>There has been a three fold increase in the numbers of Greeks using the Internet between 2000 and 2006, jumping from 9.1% to 33.5% respectively <ref type="bibr">[6]</ref>. Similarly, the Greek web has proliferated with an increasing presence of governmental and commercial entities. In 2004, most of the Greek web pages (63.5%) were in the Greek language <ref type="bibr">[4]</ref>. Though most Greeks learn a second language to some degree of proficiency, it is reasonable to assume that they would search in Greek to find information in the Greek web. Following the Broder <ref type="bibr">[3]</ref> classification of web queries we selected the "navigational" class as the basis of a user task definition. We assume that a user will search to find the specific site of an organization. To that respect our methodology relates to that of Hawking et al. <ref type="bibr">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Queries and Subject Categories</head><p>We identified ten popular broad categories in which we selected organizations to search for. The categories are: government departments, universities, colleges, travel agencies, museums, media (TV, radio, newspapers), transportation, and banks. Using professional and business directories we selected two hundred and seventeen (217) organizations that had a web presence. For each organization we established the formal name in Greek, its non-Greek equivalent if available (usually in English or other Latinbased language) and the URL(s) of the web site.</p><p>Table <ref type="table" target="#tab_0">1</ref> lists the subject categories and the corresponding numbers of Greek organizations. There were a total of 217 organizations, of which 92 had a corresponding English or other non-Greek equivalent name, thus, resulting in 309 queries.</p><p>Searches were submitted automatically to the engines in August 2006. The queries searched were the Greek and English or Romanized names of each organization. Thus, the Greek and English queries are equivalent. Examples of the queries are given in Table <ref type="table" target="#tab_7">2</ref>. Total / Σύνολο 217 92</p><p>The queries were submitted for search in the typical format of typing out the keyword separated by spaces. No advance search techniques were employed in order to simulate the input of a nonexpert searcher. The ideal retrieval would be to get the website of that organization ranked first in the result set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2: Examples of queries</head><p>In Greek Equivalent in English or in a transliterated form Υπουργείο Αγροτικής Ανάπτυξης και Τροφίμων</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Criteria</head><p>For every search we recorded the top ten results and their rank order. Then we evaluated whether the organization's URL was found in the results set, and, if so, recorded the rank position and the number of times. The evaluation also counted whether there was an exact or partial match of the desired URL.</p><p>The score includes two components, the rank position, and the depth of the page as indicated in the URL. For example, if the correct URL were found in rank 1, then the score assigned was 100, if in rank two 90, and so on. If the URL were a partial match, that is, it came from a page in the website but not the top page, then, the score was adjusted depending on the depth of the page retrieved. The latter gives some credit for partial matches, assuming that the searcher will be able to identify that the returned result is related to the desired result. This way the search engine is penalized for the additional navigational effort that will be required by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Qualitative aspects of searching</head><p>Table <ref type="table" target="#tab_8">3</ref> presents how search engines respond to Greek queries that either have or do not have accent marks. It also shows whether the engines handle articles, prepositions, pronouns, etc.</p><p>The five global search engines and one Greek return different results. The differences observed in the top ten results vary from providing totally different results, to having some small overlap in the results, but with differences in rank order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3: How search engines handle Greek accent marks</head><p>Handling of articles, prepositions, etc. Search Engine</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Search Results by Rank Order</head><p>The 309 queries were submitted to each of the 10 search engines for a total of 3090 searches. Of those 276 queries or 2760 searches returned valid results, while 33 queries or 330 searches did not return any results at all.  <ref type="bibr">Table 4</ref> presents the rank distribution of the results for both the Greek and English queries by search engine. The table lists also the number of organizations missed by each engine, and their success rate. Of the organizations found it appears that most results were presented in the first three ranks. The global search engines have higher success rates, ranging from 48.54% to 73.79%, than the Greek engines which range from 10.68% to 52.43%. Google is the best performing global engine and Trinity is the best Greek engine.</p><p>The above results give an overall performance rate for the search engines but do not show how the engines respond to Greek or non-Greek queries. Table <ref type="table" target="#tab_2">5</ref> and Table <ref type="table" target="#tab_4">6</ref> present the rank distributions of the results by language. In Table <ref type="table" target="#tab_2">5</ref> we see that AltaVista and Google handle Greek queries better than all the other engines with a success rate of 72,81%, and 70,96% respectively, whereas MSN and A9 are almost tied in last rank with about 50%. The best performance of the Greek engines was recorded by Trinity with 49.3%. The rank distribution of the results from the queries in English or in a transliterated form is given in Table <ref type="table" target="#tab_4">6</ref>. These show mixed results, as we observe variations in performance for almost all the search engines. When compared to results from the Greek queries (Table <ref type="table" target="#tab_2">5</ref>) Google (80.43%) has increased its performance by about 10%, Yahoo!'s performance remained the same (~63%), whereas MSN, AltaVista, and A9 decreased theirs. Of the Greek search engines Trinity's performance increased to 59.78%, whereas the performance of all other engines decreased. For a small web domain size like the Greek web neither Greek nor Global search engines perform well. The percentages can be improved taking into consideration that the best performance on Greek is about 70% and on English or Romanized queries is about 80%. In other words, one in three Greek language queries are not answered correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Search results by subject category.</head><p>Using the method discussed in the section evaluation criteria all queries were scored and then grouped by category. This enables a finer evaluation of the performance of the search engines in the study. Table <ref type="table" target="#tab_40">7</ref> shows the results of this evaluation grouped by language and by subject category. Based on the scoring the larger the number the better the performance of a search engine. Google from the global engines and Trinity from the Greek engines outperformed the other engines in their respective groups. But, this is not to say that Trinity's performance is good. On the contrary when comparing the Greek and global engines the Greek engines failed miserably.</p><p>Based on the aggregate results for all search engines per category for Greek queries the coverage of the categories is in the following rank order: travel agencies, universities, banks, government departments, newspapers, colleges (TEI), radio stations, museums, transportation &amp; communication services, TV stations. Similarly, the aggregate results for all search engines for English queries show that the rank order of the coverage of the categories is: universities, newspapers, banks, government departments, colleges, transportation &amp; communication services, travel agents, radio stations, and TV stations. Travel agencies is the category with most variation in rank amongst Greek and English, positions 1 and 7 respectively. Newspapers also ranged from rank 5 for Greek queries to rank 2 for English queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>This study aimed at evaluating how search engines handle Greek language queries. The study evaluated ten search engines, five Greek and five global. Our results corroborate and extend the findings of <ref type="bibr">[7]</ref>. The analysis shows that the global search engines ignore the characteristics of the Greek language, hence treating Greek queries differently. Despite this finding the performance of the global search engines outperforms that of the Greek engines. A set of 309 navigational queries was used in the evaluation. The rank distribution of all search results indicates that on average the search engines retrieved the desired document in the first three rank positions. However, the rate of success leaves much to be desired as the most successful engine, Google, was able to find the correct answer to only 73.91% of the English and 70.96% of the Greek queries. The engines seem to have poor coverage of the search Greek web, and the results returned by the engines are different depending on how the searcher has typed the Greek query, e.g., with or without accents. Therefore, the implications for Greek users are many as they need to be aware of the nuances to searching using Greek.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Fine-Grained Model for Language Identification</head><p>Harald Hammarstrom</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The language identification problem is to decide for a natural language text which language it is written in. The usual setting is to assume that one has access to training corpora beforehand for the languages to be considered. Some language fingerprint model is built from the training corpora and then classification of unseen text (belonging to one of the languages at hand) is performed through this model.</p><p>Existing state-of-the-art techniques rely on a surprisingly simple model, namely, a frequency table of character 3grams for each language, read off directly from the training corpora. The corresponding 3-gram frequency table for the text to be classified is then compared to each stored language by some rank-frequency metric. In practice, this approach performs very well (99%-ish accuracy) if the text to be classified is of size, say, 100 characters or more <ref type="bibr">[12]</ref>. Thus the language identification problem is a solved problem for most practical applications.</p><p>However, the crude 3-character gram method has a certain drawback (which may or may not be practical problem), in that it is not monotone. That is, if two texts s1, s2 are classified as l1, l2 respectively, then it is not certain that the concatenation of s1 and s2 is classified as either l1 or l2.</p><p>We will present an alternative model which aims at reliable classification of new text as short as one word. This model combines a frequency dictionary from each training corpus and a component that tries to recognize completely unseen words by looking at affixes (which would e.g. identify a word like jihading 'fighting the jihad' correctly as English). This latter component is crucial, not only for languages which make more use of affixes than English, but because there will always pop up completely novel words for any natural language no matter what size the training data. The affix detection technique implemented also builds from the same training corpora and requires no extra supervision or work by a human.</p><p>There are certainly practical applications which do require reliable classification of small segments and autodetection of language switches. These include spell checkers that wish to disregard interspersed foreign words, text-to-speech systems that make intermediate use of grapheme-to-phoneme conversion likewise wish to indentify interspersed foreign words, and multilingual information retrieval systems would benefit from knowing the language(s) of the words of a short query. For a lot of other practical applications, the granularity of the proposed new model is superfluous. For these applications, the only advantage of the proposed model is elegance and absolute lack of training supervision.</p><p>The resultant language identifier is evaluated using bible corpora for 32 languages, spanning the full range of morphological typology of languages of the world <ref type="bibr">[7]</ref>. Both its ability to classify short segments into one language and to autodetect short segments that may be composed of several languages, are evaluated. However, we do not compare these figures to existing systems, because they were not designed for classifying short segments accurately (and thus perform very poorly) 1 . On longer segments, i.e. 100 char-acters, performance is near perfect, and it is presumed that the state-of-the-art systems would also perform near perfect if tested on the same set.</p><p>With the improved accuracy on short segments and wide typological testing range, we hope to have met the challenges for written language identification set out in a recent survey article by <ref type="bibr">[11]</ref>.</p><p>All the training corpora used in this paper are bible corpora, since they are the only sufficiently large corpora available for a reasonably varied set of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PREVIOUS WORK</head><p>My full bibliography of works dealing narrowly with written language identification spans over 100 articles, a handful of technical reports and one PhD thesis <ref type="bibr">[25]</ref> -it is therefore not possible to review them all here. Many pointers to older work and language identification of speech signals are given in <ref type="bibr">[19,</ref><ref type="bibr">2]</ref>. <ref type="bibr">[22]</ref> is an excellent review and comparison of techniques used in early work.</p><p>For the language identification problem in the setting as in this paper, namely, written language identification trained on reference language data, two different feature models have been prevalent. One that looks at common words and one based on character n-grams <ref type="bibr">[9,</ref><ref type="bibr">3,</ref><ref type="bibr">6,</ref><ref type="bibr">8]</ref> -see <ref type="bibr">[15,</ref><ref type="bibr">13]</ref> for refinements of the n. The classification can then be done by comparing input text features to reference language features using rank-order statistics. More recent work in this direction has aimed at trimming overweight feature models <ref type="bibr">[20,</ref><ref type="bibr">23]</ref> or at combining n-gram and whole word features <ref type="bibr">[21]</ref>. See, however <ref type="bibr">[1]</ref> for a novel, completely different approach based on words clustered on sentence-co-occurrence. (The accuracy of this identifier is comparable to the older approaches, but it is not, as claimed therein, unsupervised, because there is a very large number of manually set parametres/thresholds and word-frequency statistics are gathered from curated corpora.) There is also more recent work targeting web pages specifically <ref type="bibr">[24,</ref><ref type="bibr">16,</ref><ref type="bibr">14]</ref>, that address the proper treatment of HTML tags.</p><p>Whereas the language identification problem has variously been labelled 'easy' and 'solved' <ref type="bibr">[17]</ref>, it depends on whether one sets the goal higher than distinguishing non-minimal noise-free samples of European languages. Some recent articles <ref type="bibr">[18,</ref><ref type="bibr">5,</ref><ref type="bibr">4]</ref> identify practical problems where this is not so. For instance, as far as we can ascertain, the best systems in van Noord's Online Summary 2 minimally require some 20 characters of text to make a judgment at all. Nor are they capable of realizing that a sample text is a concatenation of two languages. For example, The Xerox MLTT Language Identifier 3 classifies the sentence 'good fish prefer their snake' correctly as English, the sentence 'fina fiskar sprattlar inte ofta' correctly as Swedish, but the concatenation of the two is classified as Norwegian (even though there is actually no legal Norwegian word in either sentence).</p><p>As indicated already, the present method seeks to tackle also smaller sample texts, which is crucial in order to be able to track whether a text is a composition of words from found do not allow uploading the training/test set we use, which is crucial in order to assess language-dependentness. several languages. While the classic n-gram approaches have found that a good n = 3, i.e. that salient morphemes can be approximated as being exactly 3 characters, a more elegant alternative is to hold this variable, so that salient affixes can have any length in any language. Furthermore, we wish to extend the testing scope, as present published testing has been only on a rather small set of European languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DEFINITIONS AND PRELIMINARIES</head><p>Start with a finite non-empty alphabet Σ. The following terminology and notation will be used.</p><p>word: a non-empty finite string over Σ. Thus the set of all possible words can be denoted Σ + . Lowercase w with subscripts will be used for variables over words. A word will be enclosed in quotes if confusion could arise otherwise.</p><p>sentence: a finite non-empty tuple of words w1, w2, . . . , wn .</p><p>Commas and brackets will be omitted when no confusion can arise. However, variables that range over tuples, e.g. l , will always be written with brackets.</p><p>SΣ : let SΣ = { w1w2 . . . wn |wi ∈ Σ + , n ∈ N} denote the set of all possible sentences. language: a probability distribution over sentences L : SΣ → [0, 1] such that P s L(s) = 1. training corpus: a finite sequence of sentences. However, we will never make use of the order of sentences, or order or words in the sentences, so a training corpus may be equated with its bag of words. Thus, if T is a training corpus, let fT (w) denote the frequency of the word w in T . Also, use WT = {w|fT (w) ≥ 1} for the set of words in the training corpus.</p><p>names and variables: Unless we are talking about existing natural languages, e.g. English, natural numbers 1, 2, . . . will be used for language names. Σ1, Σ2, . . . will be used for their corresponding alphabets, with Σ = S i Σi for the mother alphabet. L1, L2, . . . will be used for languages, i.e. probability distributions, and coindexed T1, T2, . . . for training corpora (where Ti is assumed to be sampled from Li).</p><p>The idea is of course that sentences which are illegal or illformed in some natural language will have zero probability and legal sentences will have a non-zero probability corresponding to their relative frequency. A natural way to see how a natural language should correspond to such a formal probabilistic language is to consider ever increasing amounts of natural language text and let the probability of each sentence be its limiting relative frequency. This correspondence requires that this limit actually exists for all sentences. If there are natural languages that do not live up to this, or which cannot be modelled so with an acceptable level of discrepancy, they should not be thought of as languages in our terminology.</p><p>Our notion of language is a generalization of the more common formalization of natural language as a set of sentences. We actually need this greater flexibility in order for language identifiers to exploit the fact that some words (and thus some sentences) which are legal in several natural languages may be distinguished by their different levels of frequency. It also provides a framework for gracious treatment of new words and proper names which are so ubiquitous in open domain natural language text (such as newspaper text) that they cannot be "abstracted away". With the probability model we have the power to say that any word is possible in any language, for example as a proper name, but it is more probable that an instance of e.g. 'the' is from English than in some other language where it may have occurred as a proper name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A FINE-GRAINED MODEL OF LANGUAGE IDENTIFICATION</head><p>From the input of a training corpus, the proposed model characterizes a language using the following two components:</p><p>Frequency dictionary: Stores each seen word and its (relative) frequency. The frequency of seen words is a very powerful predictor of a language.</p><p>Unsupervised affix detection: Salient affixes are extracted (in an unsupervised manner), which form the basis for a probabilistic guessing of previously unseen words.</p><p>These two components are combined into a word emission probability distribution that aims to predict how likely a language is to have emitted a given word. In principle, a collection of such probability distributions are sufficient to make up a standard case of language identifier that always outputs exactly one language. However, we shall also use another component, a language holdback bias, to enable intuitively correct identification of text that is concatenated from several languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word Emission Probability</head><p>A frequency dictionary FD l is built simply as:</p><formula xml:id="formula_0">F D l (w) = fT l (w)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P</head><p>w ∈Σ fT l (w ) Following <ref type="bibr">[10]</ref> we use an unsupervised algorithm to gather information on the salient affixes for a given language. The algorithm uses W l as its input and outputs a probability distribution on character strings that aims to say whether a given segment is likely to be a characteristic prefix or suffix for the language at hand. To be more precise, the probability distribution aims to capture the notion of morpheme probability that one arrives at if: 1. A linguist does a morphemic segmentation of the word types (not words tokens) occurring in a corpus, 2. The frequencies of the individual morphemes, in prefix or suffix position, are interpreted as probabilities. For example, -qvj would likely get zero probability in an English corpus. An example output, adapted from <ref type="bibr">[10]</ref>, is given in Table <ref type="table" target="#tab_0">1</ref>, sorted on highest probability. The outcome of the algorithm for languages which do not have any morphology at all is a fairly even spread of probability mass over initial and final characters of the words of the language in question. For reasons of space, the reader is referred to the said paper for a discussion of the inner workings and alternative algorithms.</p><p>As mentioned, the output from the affix extraction is a probability distribution over affixes. What we need is a probability distribution over words, in which any word ending in some salient suffix should have nonzero probability. One quite reasonable way to achieve this is to assign geometrically decreasing probabilities for longer and longer words. Thinking in this way, we let all observed (in W l ) word lengths get the probability mass proportional to the number of observed words with such lengths, and unseen word lengths get geometrically decreasing probability. Thus, to get a well-defined probability distribution over words based on the affix probability distribution, we multiply together the word-length mass for w with the highest (not necessarily longest!) matching, if any, affix probability, for a given word w. The details aren't interesting, but use A l (w) to denote the just described affix-based probability distribution.</p><p>Putting the affix detection together with the frequency dictionary to make an emission probability involves a related kind of estimatate. How much probability mass should be assigned to seen vs. unseen words? There are probably many similar alternatives, but here we have simply guessed that unseen words are like hapax words, and assigned the probability mass proportions to be like the proportion of hapax words:</p><formula xml:id="formula_1">α l = |{w∈W l |f T l (w)=1}| |W l | .</formula><p>We are now ready to define emission probability:</p><formula xml:id="formula_2">P l (w) = (1 -α l ) • F D l (w) if w ∈ W l α l • A l (w) if w / ∈ W l</formula><p>It can happen that there is more mass given to an unseen word than to a (rare) seen word, even within one particular language. In fact, proportions vary quite wildly between languages, as can be seen in Table <ref type="table" target="#tab_7">2</ref> with figures computed on the translations of the same bible text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Language Holdback Bias</head><p>If we have L1, . . . , Ln languages, the previous section shows how to construct the corresponding P1, . . . , Pn probability distributions over words. Next, we shall define a family of probability measures over sequences of words. There will be one probability distribution for each language tuple of the same length as the sequence to be measured:</p><formula xml:id="formula_3">P l 1 l 2 ...lm (w1w2 . . . wm) = Y i P l i (wi)</formula><p>Given a sequence of words we could then naïvely decide which language(s) it most probably belonged to by listing each tuple of the appropriate length and computing which tuple has the highest probability of having generated the sequence of words. However, for several reasons, such an approach is not advisable. First, with n languages there are n m language tuples so it would not be tractable to enumerate them all. Second, the probability measures so defined, the output will be the concatenation of the most probable language for each word individually. This is probably not what we want since many words that are legal in several languages differ in frequency. Consider a sequence of a million words indisputably belonging to language L1, and, interspersed inside, a word that is legal in both L1 and L2 but slightly more common in L2. The naïve language identifier would yield L2 disregarding the suggestive surrounding million words of L1. While it is technically not impossible that it is a concatenation of the two languages, a human would never see it as that. Third, it's not clear how to see if an input sequence is non-trivially legal in more than one way (i.e. there are several satisfactory language tuples). Either we insert some kind of threshold which would be hard to know how to set, or we have to say that pretty much all tuples are satisfactory identification of the sequence only with some degree variation.</p><p>For the first problem, it is easy to see that not all tuples need to be enumerated to get the maximally probable one (if we want only this one, rather than the probabilities for all). As defined, the emission probabilities depend only on a particular word, not anything else in the sequence, so maximas can be computed locally in the sequence and glued together as in any standard application of dynamic programming. For the second and third problem, we shall propose a refinement of the strategy that obviates the need for any thresholds.</p><p>We propose that a machine language identifier like ours should have a bias towards minimizing the number of times we change languages in an identification sequence. To be more precise, the prior probability that a sequence should switch language c times should decrease exponentially in c. Also, other things being equal, the longer the sequence the stronger the bias should be, i.e. it should not be less likely that a million word sequence should switch language once somewhere within it, than that a two-word sequence should switch language (once) within it. This is the way to say that having seen a million words of language L1 counts for more than having seen just one word of L1. We do not see any basis for this to be a sequential property, e.g. that language switches are significantly more (or less) likely after or before certain words, wherefore a (H)MM-modeling technique offers no advantage.</p><p>Formally, let C(l1l2 . . . lm) = |{i|li = li+1}| denote the number of times a change in language occurs in a language sequence. Clearly, we have 0 ≤ c ≤ m -1. Let l = l1l2 . . . lm be an arbitrary language tuple under consideration and c = C( l ) its number of switches. Now, for any language identifier parametrized on c and m, we wish the bias, regardless of the particular languages at hand, to ensure that:</p><formula xml:id="formula_4">P (c,m) P (c+k,m) ≥ 2 k for all k ≥ 0, m P (c, m) &gt; P (c, m + k) for all k ≥ 1, c</formula><p>A simple fulfilment of these is the following Language Holdback Bias function B(c, m):</p><formula xml:id="formula_5">B(c, m) = 1 m c • 1 P 0≤i≤m-1 1 m i</formula><p>There of course alternative bias functions that also fulfill the desiderata, but this is the simplest one. Now, with the bias function defined we are ready to present our full definition of the output of the now rather sophisticated language identifier. ID(w1 . . . wm) = the set of all tuples l = l1 . . . lm such that for all l B(C( l ), m)</p><formula xml:id="formula_6">• P l (w1 . . . wm) ≥ B(C( l ), m) • P l (w1 . . . wm)</formula><p>The formula conveys the following: look for tuples with as few cuts (i.e. minimal c) as possible, that are such that they have higher probability, the bias respected, than any other tuple with more cuts. This is the key feature which eliminates the need for a threshold. Thus, for example, a word sequence will be said to be of language L l iff it has higher probability than any division of the sequence into two parts of different languages (or three parts etc). There may be several such languages, but hardly all, so the yield will be a strong prediction.</p><p>The following more procedural reformulation of the identification function may be easier to understand. It should also make it clear that language identification is still polynomial in the sequence length, since there are still no dependencies between the word-probabilities. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Example 1: The kings hon walikusoma</head><p>Consider the sequence the kings hon walikusoma which consists of the, which is of course the English definite article; kings is the well-known English lexical item which does occur in the training corpus -it also happens to end in -s which is a very common Swedish inflectional ending (but there is no lexical item 'king' or 'kings' in Swedish); hon is a Swedish personal pronoun, abundantly occurring in the Swedish training corpus; and walikusoma is a well formed Swahili word whose individual morphemes all individually occur abundantly in the Swahili training corpus -but the The individual word-probabilities as well as a selection of the more interesting tuple-probabilities for the sequence as a whole, are shown in Table <ref type="table" target="#tab_8">3</ref>. As can be seen, the Peng,eng,swe,swa value beats all tuples with zero or one switches. It also happens to beat all tuples with three switches and it is the only such tuple. Therefore, in this case, the output will be exactly English, English, Swedish, Swahili.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Example 2: The kings are there</head><p>The complicated interaction seen in the previous example does not disturb the "normal" easy class of classifications. Table <ref type="table" target="#tab_1">4</ref> shows the word-probabilities for the almost trivial sentence the kings are there. There is a certain zero-switch tuple which is way ahead of the others. As it also beats all one-switch tuples (and no other zero-switch tuple does), it will be the output of the identifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Example 3: De la</head><p>There are instances where there are several "winning" tuples, though informal tests show that this is not achieved very often. The sequence de la is very common to both Spanish and French. In English it is not common at all. In Swedish de is a personal pronoun so it enjoys a certain frequency, whereas la is not a word in (bible) Swedish. Similarly, la is a negator in Swahili and is therefore fairly frequent. Table <ref type="table" target="#tab_2">5</ref> shows the relevant probabilities. The output </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION AND DISCUSSION</head><p>Three extensive tests were performed using a parallel corpus of the bible in 32 languages, which contains languages from the isolating Maori to the record holding polysynthetic Greenlandic <ref type="bibr">[7]</ref>. In order to get a sufficiently cross-language comparable evaluation, size and randomness were equalized between languages the following way. A random verse from each chapter was selected (there are 1209 chapters in the bible). This was done once for the whole language set. Of course, these verses were removed from the training data. A random word from each selected verse was selected. This word-selection was done separately for each language. For each language, we thus get a set of randomly selected words E l . Though 1209 word-selections were made for each language, many selections happened to select the same word. Thus the size of the E l -sets varied from 350 (for Maori) to 974 (for Greenlandic). The descrepancy is not disturbing. Words are not entities of the same kind across languages, but our classifier operates on the granularity of words, and the desiderata is an evaluation of 'accuracy per (randomly selected) word'. An alternative, e.g. selecting 1000 unique words of each language would have made interpretation of the result difficult, because for Maori, it is likely that most of the 1000 words would have been seen words, occurring in other verses, whereas the opposite is the case for Greenlandic.</p><p>If E is a set of tuples (possibly one-word tuples), drawn for language l, we define the accuracy RE(l) of a language identifier ID:</p><formula xml:id="formula_7">RE(l) = |{ x |ID( x ) = l and x ∈ E}| |E|</formula><p>One-word classification: The RE l was calculated for each of the 32 languages. Since the input sequence is of length 1, there will never be any cuts, so the language identifier was set to output the language with highest probability of having emitted the input word. The E l -sets as defined above may contain words that are "impossible" predict where they were taken from, on the basis of the word alone. For example, let's say a word w is legal in two languages but much more common in l1 than l2. If it happened to be drawn from L l 2 , it is hard to see how this can be predicted. However, we computed figures on the possible influence of this issue, and it turned out to be minor. Therefore, the results in Table <ref type="table" target="#tab_4">6</ref> stand, but could be adjusted upwards by very small percentages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verse classification:</head><p>To check how accurate the identifier was on longer segments, we chose to test on segments of roughly the length of a verse. Verses, in fact, happen to be around 100 characters long on average. From the 1209 verses selected (as above), those 100 verses thereof whose number of characters were closest to the average verse length of that language, were selected for testing. Denoting these 100-verse sets by V l , the verse-classification accuracy RV l was calculated. This score, as well as data on average verse length, can be seen in Table <ref type="table" target="#tab_4">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4-tuple multilingual classification:</head><p>A set of 1000 mixed language 4-tuples were built from E1, . . . , E32 as follows.</p><p>1. Pick a random language l and pick two random words from that E l . 2. Precede it with a random word from a random language E l . 3. Add a random word from a random language E l at the end.</p><p>The results of this test was 193 (19.3%) fully correctly identified tuples and 204 (20.4%) with exactly one word misclassified.</p><p>Some figures are low, not surprisingly for languages with a lot of morphology, but overall we hold the results are very reasonable given the exceedingly difficult test problems of one-word and multi-language classification. It is very easy to make mistakes on single words when there are so many languages in the pool -the results are much higher if the number of competing languages is halved.</p><p>Unfortunately, we cannot contrast the verse-test with figures from competing state-of-the-art systems, as none of the systems known to us give enough details (on thresholds and such) to reconstruct a fair version of the classifier.</p><p>A matter requiring further commentary is the use of a bias function to do the job a scalar threshold value does in related work. (Human language identifiers, having the ability to assess syntactic and semantic coherence, need not use either.) Conceptually the bias function employed is nothing other than a complex system of thresholds, in terms of growth behaviour (exponential, linear etc.) rather than scalar values. Arguably, this is an elegance improvement, although it comes with the cost of being harder to understand, compute and analyse. Also, in the experiments reported above, the bias function approach experimentally outperforms a simple systems of scalar threshold values. For example, through supervised training we have tried tuning one single threshold value for all experiments, one threshold value individually for each language, different threshold values for different classification tasks (i.e. one for multi-language classification and one for single language classification) and so on, resulting in generally lower accuracy on the same test set (obviously, there is little room for presenting and discussing figures from these tests here). Nevertheless, it remains possible that some other, yet undiscovered, system of scalar thresholds is superior to the bias function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>We have described a new model with considerable elegance for language identification on small, possibly mixed languages segments. We have also added significantly to the set of published evaluations of a language identification system with a balanced cross-language test. For larger input texts the new model has excellent accuracy, but it is bigger and slower in practice than the existing state-of-the-art systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The field of Information Retrieval (IR) addresses the general problem of how to retrieve information, which is relevant to a user need, from a large repository of information, such as a collection of documents. Information in the document collection is represented in the form of an index, which contains statistics of term frequencies in each document and in the whole collection. Typically, using these statistics, term weighting models compute weights for individual terms, which capture the importance of the terms to the content of each document. A matching function then estimates the likely relevance of a document to a query, on the basis of these term weights, and the most relevant documents are identified and retrieved <ref type="bibr">[26]</ref>.</p><p>In brief, IR systems typically contain an indexing component, which stores a collection of information, and a matching component, which retrieves relevant information in response to a user query. This very basic architecture is typically enriched with a variety of retrieval-enhancing tech-niques, aiming to facilitate the system's efficiency and effectiveness. Examples of such techniques are removing stopwords or reducing variants of the same word to a single form (stemming). These IR system techniques were originally engineered for English collections of documents and queries.</p><p>Nowadays, it is reported that the majority of Web users are non-native English speakers. This means that most people wishing to retrieve information relevant to their need from the Web are likely to do so in a language other than English <ref type="bibr">[4]</ref>. It is estimated that non-English queries and unclassifiable queries are not only numerous, but also that they grow increasingly bigger in number. This fact creates a problem for most search engines, which are typically optimised to process mainly English queries. For example, most search engines do not take full account of diacritics or the use of capitals in a user query. Such limitations in processing non-English queries make multilingual retrieval less effective <ref type="bibr">[9]</ref>. Consequently, it is usually acknowledged that international search engines (like Yahoo! and Google) are less effective with monolingual non-English queries. In fact, Google has only very recently announced the upcoming launch of a cross-lingual functionality.</p><p>In this paper, we investigate how the Terrier retrieval platform <ref type="bibr">[19]</ref> can deal with non-English queries. Terrier is a robust and modular IR engine, with an established track record of solid high performance for English retrieval <ref type="bibr">[14,</ref><ref type="bibr">15]</ref>. By testing it on non-English queries, we aim to identify whether standard IR techniques implemented in it are appropriate for non-English retrieval. Specifically, the IR technique we investigate is the application of appropriate stemming in a multilingual Web IR environment.</p><p>Stemming consists of reducing morphological variants of a word to a single form (or stem). This technique has been popular with IR systems, because it allows for different word forms to be represented under a single entry. For example, by stemming singular and plural forms of a word to a common form, the occurrence of that word in a document is represented more accurately, and hence retrieval performance and system efficiency improves <ref type="bibr">[10]</ref>.</p><p>Nevertheless, in a multilingual Web IR setting, stemming is not a straightforward process. Firstly, before stemming is applied, the language of the query/document needs to be known, so that the correct stemmer is used. Secondly, morphological complexity varies greatly per language, from the relatively simple (e.g. English), to the relatively more elaborate (e.g. Hungarian). This practically means that, whereas stemming might work for some languages, it might not work for others. Finally, as with other types of lan-guage resources (e.g. part-of-speech taggers, named entity extractors, and so on), the availability of stemmers for many languages is sparse. In such cases, what is the best strategy: applying no stemming, or using stemmers designed for other languages?</p><p>These are the main issues we address in this paper. By doing so, we seek to gain insights into what is the most appropriate way for an IR system to process words in many languages, so that they are accurately indexed and efficiently matched to user queries.</p><p>The remainder of this paper is organised as follows. Section 2 gives an overview of studies relating to this work. Section 3 describes how we adapt Terrier to multilingual retrieval. Section 4 presents our experiments and discusses the experimental results. Section 5 concludes this paper with lessons learnt and opted future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED STUDIES</head><p>The Web is an heterogeneous environment, in which information may appear in a great variety of different languages. The workshops on the evaluation of multilingual Web IR (WebCLEF) <ref type="bibr">[4,</ref><ref type="bibr">24]</ref> constitute an organised effort into looking at how Web IR systems can scale up to retrieval in a multilingual setting. These workshops have produced literature on a variety of techniques that can extend standard English IR systems to perform multilingual retrieval. One such reported technique is the extension of Web-based features (for example document structure) for retrieval in a multilingual setting <ref type="bibr">[1,</ref><ref type="bibr">8,</ref><ref type="bibr">16,</ref><ref type="bibr">17,</ref><ref type="bibr">18,</ref><ref type="bibr">25]</ref>. Another technique is applying language-specific stemming when retrieving documents in different languages <ref type="bibr">[16,</ref><ref type="bibr">17,</ref><ref type="bibr">25]</ref>. An alternative to stemming in a multilingual environment is the use of character n-grams to represent the terms in the index <ref type="bibr">[12]</ref>. Further techniques used with retrieval in different languages include normalising diacritics and accents <ref type="bibr">[13]</ref>. Encoding issues, one of the biggest problems with non-English retrieval, have been dealt with either by adapting the retrieval system to process specific encodings, such as UTF-8 for example <ref type="bibr">[16]</ref>, or by transliterating characters into encodings that the system can process <ref type="bibr">[13]</ref>.</p><p>Overall, the above work draws an encouraging yet incomplete picture of multilingual Web IR: encouraging, because the community addresses the problem with organised efforts for standard evaluation. Incomplete, because these efforts reveal that technical difficulties, such as character encoding, are not yet overcome, while there is not a clear consensus on whether standard IR techniques, such as stemming, are beneficial to multilingual IR.</p><p>It is this last point that motivates the work in this paper: we address the technical difficulties in doing Web IR across languages by extending the modular Terrier platform, and we investigate the usability of stemming by experimenting with different combinations of stemmers and languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ADAPTING TERRIER TO MULTILINGUAL RETRIEVAL</head><p>In this section, we present how we adapt Terrier's functionalities for non-English retrieval. There are two main components in the overall architecture of the Terrier platform, namely indexing (described in Section 3.1), and matching (described in Section 3.2). Indexing describes the process during which Terrier parses a document collection and represents the information in the collection in the form of an index that contains statistics on term frequency in each document and in the whole collection. Term weights are generated for each term based on these statistics. Retrieval describes the process during which Terrier weights each document term and estimates the likely relevance of a document to a query, on the basis of these term weights.</p><p>In order to adapt Terrier into a multilingual environment, we focus on the application of appropriate stemming strategies. This technique is part of the system's indexing process, which is presented next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing</head><p>Indexing consists in parsing a document collection and appropriately indexing the information contained in it. In a multilingual setting, indexing collections in an appropriate way means being able to support retrieval in different languages, so that the IR system can accurately and uniquely represent each term in the corpus. To meet this requirement, we use a Terrier version that supports multiple character set encodings <ref type="foot" target="#foot_1">1</ref> , ensuring that we have a robust representation of the collection.</p><p>Terrier achieves modularity in indexing collections of documents by splitting the process into four stages, where, at each stage, plugins can be added to alter the indexing process. The four stages of indexing with Terrier are <ref type="bibr">[19]</ref>:</p><p>• handling a collection of documents,</p><p>• handling and parsing each individual document,</p><p>• processing terms from documents, and</p><p>• writing the index data structures.</p><p>During indexing, Terrier assigns to each term extracted from a document three fundamental properties, namely</p><p>• the actual string textual form of the term,</p><p>• the position of the term in the document, and</p><p>• the document fields in which the term occurs (fields can be arbitrarily defined by the document plugin, but typically relate to HTML/XML tags).</p><p>During indexing, the terms pass through a configurable 'Term Pipeline', which transforms them in various ways, using plugins such as stemming, removing stopwords in various languages, expanding acronyms, and so on. The outcome of the Term Pipeline is passed to the Indexer, which writes the data structures of the final index. We adapt Terrier's indexing component as follows: during the parsing of the collection, we use heuristics to identify the correct character set encoding of each document. In particular, we examine the Content-Type HTTP header of the request, and any equivalent META tag in the header of the HTML document. If neither of these are found, then a default encoding is assumed based on the language of the document (as described below). For example a Czech document is likely to be encoded in ISO8859-2. Once the correct encoding for each document is determined, the collection is parsed, each term being read and converted into UTF-8 representation. Hence, we ensure that terms from different languages encoded using different character sets are accurately represented in the index.</p><p>Terrier's modular architecture allows for any number of different stemmers to be easily applied at this stage. In particular, to determine the language of each document, we use the language identification tool TextCat <ref type="bibr">[5]</ref>, combined with evidence from the URL and the HTML of each document. For instance, if the identifier fails to identify the language of a document, then we can assume that documents from the .fr domain are likely to be in French. Alternatively, the HTML tag of an HTML document can have a lang attribute describing the language of the document. In this work, in addition to English stemming, we use several language-specific stemmers, appropriately selected using the language identification data. The application of stemmers is detailed in Sections 4.1 and 4.2.</p><p>Because in this paper we investigate the effect of different combinations of stemming upon multilingual retrieval performance, we create different indices of the collection, so that each index applies a different type of stemming strategy. This point is further detailed in Sections 4.1 and 4.2. Overall, we apply several stemming combinations to index the collection. This means that we create different indices of the collection. In each index, we keep field information for each term, so that we can identify which terms occur in which fields of the documents. This is motivated by the fact that, for Web IR, knowing where in a document terms occur may help retrieval performance <ref type="bibr">[6]</ref>. In this work, we use different document fields when matching relevant documents to queries, as explained next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Matching</head><p>So far we have seen how Terrier indexes a collection, so that terms in different languages are represented accurately, and how information on the location of the terms in the documents is also kept. This positional information for terms takes into account document structure in order to enhance retrieval performance. By document structure we denote specific document sections, also referred to as fields in the literature. It has been shown that using document fields can enhance retrieval performance in a Web IR setting <ref type="bibr">[6,</ref><ref type="bibr">16,</ref><ref type="bibr">22]</ref>. The specific document fields we use in this work are the body of the document, the title of the document, and the anchor text information for a document (i.e. the text associated with the incoming links of a Web document).</p><p>We consider these different sources of evidence when matching a document to a query, using a weighting model that is specifically designed to combine term frequencies from different document fields. Specifically, we use the PL2F weighting model from the Divergence From Randomness (DFR) framework <ref type="bibr">[2]</ref>. PL2F is a derivative of the PL2 model, which is specifically adapted to combine evidence from different fields. Using the PL2F model, the relevance score of a document d for a query Q is given by:</p><formula xml:id="formula_8">score(d, Q) = X t∈Q qtw • 1 tf n + 1 `tf n • log 2 tf n λ<label>(1)</label></formula><formula xml:id="formula_9">+(λ -tf n) • log 2 e + 0.5 • log 2 (2π • tf n) ẃhere</formula><p>λ is the mean and variance of a Poisson distribution, given by λ = F/N ; F is the frequency of the query term t in the collection, and N is the number of documents in the whole collection. The query term weight qtw is given by qtf /qtfmax; qtf is the query term frequency. qtfmax is the maximum query term frequency among the query terms.</p><p>tf n corresponds to the weighted sum of the normalised term frequencies tf f for each used field f , known as Normalisation 2F <ref type="bibr">[16]</ref>:</p><formula xml:id="formula_10">tf n = X f " w f • tf f • log 2 (1 + c f • avg l f l f ) « , (c f &gt; 0) (2)</formula><p>where tf f is the frequency of term t in field f of document d; l f is the length in tokens of field f in document d, and avg l f is the average length of the field across all documents. The contribution of the field is controlled by the weight w f ; c f is a hyper-parameter for each field, which can be set automatically <ref type="bibr">[11]</ref>, and which controls the term frequency normalisation. The c f and w f values used in this work are given in Section 4.1, along with the rest of the experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EVALUATION</head><p>The aim of our experiments is to investigate whether the standard IR techniques implemented in Terrier are appropriate for non-English retrieval, with special focus on the use of stemming in a multilingual setting. Section 4.1 describes the datasets and resources used, while Section 4.2 describes how we organise our experiments. Experimental results are presented in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We adapt Terrier for multilingual Web IR (as presented in Section 3), and we evaluate it on the mixed monolingual task from WebCLEF 2005 and 2006. The mixed monolingual task simulates a user searching for a known-item page in a European language. This task uses known-item topics, namely homepage finding and named page finding queries. The homepage topics are names of a site that the user wants to reach, and named page topics concern non-homepages that the user wants to reach. The mixed monolingual retrieval task is based on a stream of known-item topics in a range of languages.</p><p>The mixed-monolingual retrieval task uses the EuroGOV test collection <ref type="bibr">[23]</ref>, and more than 800 monolingual knownitem topics in various languages.</p><p>EuroGOV consists of Web documents crawled from European governmental sites. As such, it is a multilingual Web corpus, containing 3.5 million pages from 27 primary domains, and covering over 20 languages. Specifically, Eu-roGOV contains documents from the following (top-level) domains:</p><formula xml:id="formula_11">pt(=portugal) se(=sweden) sk(=slovakia)</formula><p>There is no single language that dominates the corpus, and its linguistic diversity provides a natural setting for multilingual Web search. Files in EuroGOV have the following format: &lt;EuroGOV:bin domain="" &lt;!--The top level domain --&gt; id=""&gt; &lt;!--The name of the file --&gt; &lt;EuroGOV:doc url="" &lt;!--URL of the page --&gt; id="" &lt;!--DocID of the format Exx-yyy-z --&gt; &lt;!--E is E and stands for EuroGOV --&gt; &lt;!--xx is the top level domain --&gt; &lt;!--yyy is the file name --&gt; &lt;!--z is the character offset of the document --&gt; md5="" &lt;!--MD5 checksum of the content of the page --&gt; fetchDate="" &lt;!--Fetch date of the page --&gt; contentType=""&gt; &lt;!--contentType as given by the web server --&gt; &lt;EuroGOV:content&gt; &lt;![CDATA[ ... content ... &lt;!--This is the actual page --&gt; ]]&gt; &lt;/EuroGOV:content&gt; &lt;/EuroGOV:doc&gt; ... &lt;/EuroGOV:bin&gt;</p><p>The structure of documents in EuroGOV is clearly marked by the annotation shown above.</p><p>An example of the topic format used at WebCLEF 2005 is: &lt;topic&gt; &lt;num&gt;WC0006&lt;\num&gt; &lt;title&gt;Minister van buitenlandse zaken&lt;\title&gt; &lt;metadata&gt; &lt;topicprofile&gt; &lt;language language="NL"/&gt; &lt;translation language="EN"&gt; dutch minister of foreign affairs &lt;/translation&gt; &lt;/topicprofile&gt; &lt;targetprofile&gt; &lt;language language="NL"/&gt; &lt;domain domain="nl"/&gt; &lt;/targeprofile&gt; &lt;userprofile&gt; &lt;native language="IS"/&gt; &lt;active language="EN"/&gt; &lt;active language="DA"/&gt; &lt;active language="NL"/&gt; &lt;passive language="NO"/&gt; &lt;passive language="SV"/&gt; &lt;passive language="DE"/&gt; &lt;passive other&gt;Faroese&lt;/passive other&gt; &lt;countryofbirth country="IS"/&gt; &lt;countryofresidence country="NL"/&gt; &lt;/userprofile&gt; &lt;/metadata&gt; &lt;/topic&gt;</p><p>The topics used in WebCLEF include a large amount of metadata, as can be seen above. Real-life user queries on the Web do not come with such a variety of metadata. In fact, they typically consist of very few keywords <ref type="bibr">[20]</ref>. In order to simulate as much as we can real user queries, in our experiments we only use the title field of the topics.</p><p>There is a significant amount of queries available for the 2005 and 2006 mixed-monolingual task. Specifically, the 2005 topics contain 547 queries, consisting of 242 homepage finding queries, and 305 named page finding queries. These queries have been created manually by humans and target pages in 11 different languages: Spanish, English, Dutch, Portuguese, German, Hungarian, Danish, Russian, Greek, Icelandic, and French. The 2006 topics differ from the 2005 topics as follows: a great part of the 2006 topics has been created automatically, using Azzopardi and de Rijke's technique for automatically generating known-item topics <ref type="bibr">[3]</ref>. The 2006 topic set also includes a number of manual (human-generated) topics. Specifically, there is a total of 1120 new topics for 2006, 817 of which are automatic, and 303 of which are manual. The 2006 manual queries cover only languages for which human expertise was available (Dutch, English, German, Hungarian, and Spanish) and are supplemented by including some of the queries from the 2005 topic set, while the 2006 automatic queries cover almost all languages. However, in this work, we consider only the manual queries, as the evaluation using the automatic queries did not correlate highly with the true performance of the IR systems as measured by the manual queries <ref type="bibr">[4]</ref>.</p><p>Section 3 presented how we extend Terrier's indexing component to take into account various stemmers, and how we match documents to queries using a field-based weighting model. Specifically, we apply the following stemmers:</p><p>• For English, we use Porter's English stemmer;</p><p>• For all other languages, we use their corresponding Snowball stemmer<ref type="foot" target="#foot_3">2</ref> , with the exception of languages for which there was no stemmer available:</p><p>-For Icelandic, we use the Danish Snowball stemmer; our reasonsing is that Danish is 'linguistically' relatively close to Icelandic.</p><p>-For Hungarian, we use Hunstem<ref type="foot" target="#foot_4">3</ref> as the Snowball stemmer for Hungarian was not available at the time of our experiments.</p><p>We do not remove stopwords during indexing, because we do not have stopword lists for all languages, and we do not wish to give an unfair advantage to some languages over others. For retrieval, we use the language topic metadata to select the appropriate stemmer and stopword list for that language. Moreover, we use the body, title, and anchor text 4 fields of documents, which we weight using the PL2F model (Section 3.2). The setting of the parameters c f and field weights w f presented in Section 3.2 is taken from <ref type="bibr">[16]</ref>, and is the following:</p><p>• c = 4.10 &amp; w = 1 for the body of the document;</p><p>• c = 100 &amp; w = 40 for the title and anchor text of the document.</p><p>Finally, we mentioned earlier that the WebCLEF topics are known-item topics, where a unique URL is targeted. This means that an early precision measure is more suitable to evaluate retrieval in this case. We use the metric also used in WebCLEF, namely the mean reciprocal rank (MRR). The reciprocal rank is calculated as 1 divided by the rank at which the (first) relevant page is found. The mean reciprocal rank is obtained by averaging the reciprocal ranks of a set of topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Methodology</head><p>We hypothesise that being able to apply the correct stemmer to a document and a topic can increase retrieval performance. To test this hypothesis, we create three indices of the EuroGOV collection:</p><p>1. we index the collection without applying stemming;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">we index the collection by applying Porter's English</head><p>stemmer to all documents, regardless of their domain and language;</p><p>3. we index the collection by applying stemming to each document according to the language of the document. The language of each document is determined by the language identification data provided by the TextCat utility described in Section 3.1.</p><p>We organise our experiments as follows:</p><p>• NoStem: retrieval without stemming the documents or the queries. This is our baseline.</p><p>• PorStem: retrieval using Porter's English stemmer for all documents and queries, regardless of their language. This run is a simple baseline showing the effects of applying an English-oriented IR system. For languages not in the Latin character set, Porter's stemming should have no effect.</p><p>• AllStem: retrieval using language-specific stemming, where the language of the query is defined by the topicmetadata.</p><p>• SelStem: retrieval using language-specific stemming, where the language of the query is guessed using the TextCat language identifier. When the language identifier fails to identify a language, no stemming is applied to the query and the the unstemmed index is used.</p><p>While the run AllStem is not realistic in the sense that users would likely not state the language of their query at submission time, it allows us to determine the extent to which the language identification of the queries adds noise to the SelStem run. In addition to the runs described above, we compare the system's retrieval performance on a perlanguage basis, so that we may distinguish between 'harder' and 'easier' languages. The next section details the findings of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>Table <ref type="table" target="#tab_0">1</ref> displays the retrieval performance of Terrier on the 2005 topic set. We display the MRR scores according to the topic language, the named-page (NP) and home-page (HP) topics, and for all topics in total (All). In Table <ref type="table" target="#tab_0">1</ref> we observe the following:</p><p>• Applying no stemming is generally the most effective approach. This is the general conclusion for all languages. However, on a per-language basis, stemming helps retrieval for German.</p><p>• Applying Porter's English stemmer for all languages results in the most stable retrieval performance (the deviation in MRR across all topics is the smallest of all, σ=0.426). However, applying Porter's stemming to all languages significantly harms retrieval performance, yet less than using language-specific stemming. This is the general conclusion for all languages. On a per-language basis, language-specific stemming is better for Danish, German, and Greek. The particularly low performance when applying the correct stemmer to the Hungarian topics (AllStem) implies that the Hungarian stemmer is not effective.</p><p>• There exists a considerable amount of variation across languages. This point is also displayed graphically in Figure <ref type="figure" target="#fig_0">1</ref>(a). This observation is consistent with the general trend observed in WebCLEF 2005 <ref type="bibr">[24]</ref>, namely that some languages were hard for all systems. Specifically, in WebCLEF 2005, it was reported that most systems scored relatively high for Dutch, relatively low for Russian and Greek, and close to average for German. We observe that Terrier is not only consistent with this, but also generally robust across different languages, including Russian.</p><p>• Named page runs score higher than home page runs. This is consistent with the general trend reported in WebCLEF 2005 <ref type="bibr">[24]</ref>, and also the English monolingual experiments of the Text REtrieval Conference (TREC) <ref type="foot" target="#foot_6">5</ref> for the Web track of 2003 and 2004 <ref type="bibr">[6,</ref><ref type="bibr">7]</ref>.</p><p>• As expected, the selective application of stemming using the language identifier (SelStem) normally decreases in performance compared to the AllStem run. This happens when the inaccuracy of the language identifier has caused the wrong stemmer to be selected. For some languages the performance of SelStem is better than when the correct stemmer is used (AllStem); we suggest that this is mostly the case when the language identifier fails to guess a language, and in these cases the system used the unstemmed query with the unstemmed index was used (which has a better performance).</p><p>Table <ref type="table" target="#tab_7">2</ref> displays the retrieval performance of Terrier on the 2006 topic set. From the table, we observe the following:</p><p>• Similarly to before, applying no stemming is the most effective approach, overall, and for both NP and HP tasks, as well as for most languages.</p><p>Lang.</p><p>NoStem   • Similarly to before, applying Porter's stemming gives the most stable retrieval performance throughout (smallest deviation among languages throughout), which is however not the best performance in terms of retrieval effectiveness.</p><p>• The considerable amount of variation across languages reported for the 2005 topics is observed here as well (see Figure <ref type="figure" target="#fig_25">1(b)</ref>). This trend was also reported in WebCLEF 2006 <ref type="bibr">[4]</ref>, namely that some languages were hard for all systems.</p><p>• The SelStem run never outperforms the AllStem run for any language. This suggests that, unlike for the 2005 topics, the language identifier has failed to suggest a language for only a few queries, meaning that there has been insufficient fallback (cf NoStem) to increase the overall performance for those languages. This is confirmed by Table <ref type="table" target="#tab_8">3</ref>, which is described below.</p><p>Overall, we can summarise the observations drawn from Tables <ref type="table" target="#tab_34">1</ref> and<ref type="table" target="#tab_7">2</ref> as follows:</p><p>• In a multilingual Web IR environment, applying no stemming at all is generally the most effective approach. As predicted, applying Porter's English stemming to all languages results in a signficant decrease compared to applying no stemming. However, unexpectedly, applying Porter's English stemmer does achieve the most stable retrieval performance across both tasks. Applying language-specific stemming is neither the most stable, nor the most effective retrieval approach, and in particular, always results in a statistically significant degradation in overall MRR.</p><p>• In a realistic Web IR environment, the languages of each query are not available. However, using modern language identification tools to select an appropriate stemmer can affect the performance of a selective stemming system. In particular, Table <ref type="table" target="#tab_8">3</ref> shows the accuracy and the number of unknowns generated by the language identification tool for the topic and documents respectively. While 94% accuracy is achievable for the language identification of the documents, due to the much shorter nature of the queries, only 50% accuracy is achieved in query language identification. This explains the difference in performance exhibited between the AllStem and SelStem runs in Tables <ref type="table" target="#tab_34">1</ref> and<ref type="table" target="#tab_7">2</ref>.</p><p>This conclusion is not entirely generalisable, but subject to the quality of the stemming resources used. The different stemmers used for various languages are not necessarily of the same quality. For example, the performance of the Hungarian stemmer is not entirely satisfactory; the stemmer used for Icelandic is in fact designed to stem Danish. On the contrary, Porter's stemmer for English is a generally popular and well-established stemmer, the performance of which can be expected to be relatively reliable. More and better resources are needed in order to have a more accurate idea of whether language-specific stemming is indeed not beneficial for multilingual Web IR. Additionally, the accuracy of language-specific stemming is partly depicted by the extent to which the language of the queries can be identified, and hence we believe that it is in this area that future research should also be directed. Table <ref type="table" target="#tab_8">3</ref>: Accuracy of the language identification for the language of the topics, and the language of the target documents of the topics. Unknown is the fraction that the classifier failed to suggest any languages. Note that there is only a language identification ground truth available for the relevant documents, not all documents in the collection. Finally, Table <ref type="table" target="#tab_1">4</ref> displays the best MRR scores reported in our experiments next to the top three runs on the manual queries submitted to WebCLEF 2005 and 2006 from all participating groups. However, because these are the official submitted runs of participating groups, they all use more than baseline settings: for example, they make use of retrieval-enhancing techniques, such as some knowledge about the document URL, query expansion, Natural Language Processing (NLP) functionalities, and so on. In fact, the best scoring run for the manual runs of 2005 (MRR of 0.5135) uses the same retrieval system and weighting model on fields as our reported runs. Nevertheless, that run outperforms our equivalent run (MRR of 0.4900), because it uses URL evidence and acronym expansion, while we only use the baseline weighting model with document fields. Note that for the 2006 manual topics, our reported run obtains the best overall performance. Naturally, the retrieval performance reported here could be improved by using retrievalenhancing techniques, such as the ones mentioned above, and by further optimising the system's settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WebCLEF</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>We investigated whether the standard IR techniques implemented in Terrier are appropriate for non-English retrieval, with special focus on the use of stemming in a multilingual setting. The bare-system approach of applying no stemming at all is very effective, and in addition is a safe and stable option, where the results are significantly better than those produced by the best stemming approach for that language. It is not clear that stemming with respect to a language can assist retrieval performance, and in particular the performance of such is partly depicted by the accuracy of the language identifier tool used for the documents and the queries.</p><p>With regards to the retrieval platform used, we have shown how Terrier's modular configuration allows for some simple extensions that easily solve some well-noted technical problems in the field (e.g. character encoding). Experiments in a mixed monolingual environment show that the platform is thoroughly robust in dealing with queries in 11 European languages.</p><p>Future work includes using more realistic settings as well as more and better quality resources (e.g. non-English stemmers). Moreover, we will aim to adapt Terrier to non-European languages with different writing systems, such as Chinese or Japanese, where the tokenisation performed is much more important. In particular, the success of Terrier on retrieval in a Japanese content can be evaluated using collections from the NTCIR evaluation forum 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Querying the Greek Web in Greeklish</head><p>Paraskevi Tzekou Sofia Stamou Nikos Zotos Lefteris Kozanidis</p><p>Computer Engineering Department, Patras University 26500 Greece {tzekou, stamou, zotosn, kozanid} @ceid.upatras.gr</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>In this paper, we experimentally study the problem of querying the web in a hybrid language, namely Greeklish. Greeklish is the transliteration of Greek in Latin characters of the ASCII code.</p><p>Although Greeklish emerged as a convenient mean for the creation and distribution of digital data at a time when Unicode Transformation Format was not supported for the Greek alphabet, nevertheless it is still being utilized as a matter of habit or need. Today, a considerable amount of the Greek web data contains pages written in Greeklish. Although, these are less official web pages and they appear mainly in blogs or forums, their contents may be of good quality and usefulness to the Greek online information seekers. However, the paradox of searching the Greek web is that search engines perceive Greeklish as a totally different language form Greek and as such they do not return Greek pages in response to Greeklish queries. As a consequence, users who issue Greeklish queries (sometimes for technical reasons) are systematically deprived of information that would otherwise be valuable to their search intentions. In an analogous manner, searching the web via Greek queries excludes from the search results pages of valuable content simply because they are written in Greeklish. In this paper, we study the phenomenon of Greeklish web searches and we propose a model that treats Greek and Greeklish web data in a uniform manner. Our aim is to improve the usability of Greek search engines and ameliorate the user experience, regardless of the preferred query alphabet. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories and Subject Descriptors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The most prominent way for finding information on the web is go to a search engine, submit keyword queries that describe an information need and receive a list of results that satisfy the information sought. Although English is the lingua franca of the web, the majority of the web users are non-English speakers <ref type="foot" target="#foot_7">1</ref> . As the size of the non-English speaking online population grows rapidly, and the amount of non-English web data increases, it is increasingly important to support web searches in languages other than English. In this direction, there have been previous studies that investigate the problem of searching the web through non-English queries (cf. to <ref type="bibr">[4]</ref> for a recent overview). The striking majority of existing studies concentrate on either searching the web in a particular natural language (other than English) <ref type="bibr">[18]</ref> [12] [13] [6] <ref type="bibr">[15]</ref>, or on multilingual web information retrieval <ref type="bibr">[16]</ref> [9] <ref type="bibr">[7]</ref>. However, one aspect that none of the reported studies addresses is the phenomenon of querying the web via transliterated queries. Transliteration, as defined in Wikipedia, is:</p><p>"the practice of transcribing a word or text written in one writing system into another writing system."</p><p>In this paper, we investigate the problem of searching the Greek web using a hybrid language, namely Greeklish. Greeklish, a blend of the words Greek and English, is the representation of Greek textual data with the Latin script. The use of Greeklish as a means of writing Greek via the Latin alphabet dates back to the 17 th century, when Greek merchandisers living abroad used the Latin script in their writings to communicate with other expatriate Greeks. For a thorough understanding in the history of Greeklish, we refer the interested reader to the works of <ref type="bibr">[2]</ref> and <ref type="bibr">[11]</ref>.</p><p>Greeklish became widely known in the 1990's because of the spread of computer-mediated communication across the Greek society. In the digital era, Greeklish revived as a convenient mean for verbalizing Greek, since not all operating systems and applications back then had support for Greek. Today, modern software supports Greek but still it is much easier for Greek computer literates to e-write in Greeklish because it is faster to type and they do not have to worry for orthography issues. Moreover, Greeklish is being used for practical reasons since some people might not have access to the Greek character set. For instance it is impossible to send an SMS text message from a web-based interface using Greek characters to a cell phone. Despite the long official debates on whether Greeklish is threatening the cultural integrity of the Greek language, and letting aside the recent (2004) movement against Greeklish, the current literacy practices in Greek cyberspace demonstrate that users still communicate, search, write and receive information in Greeklish.</p><p>When it comes to the web searching paradigm, Greeklish imposes a number of challenges to the search engine community, which to the best of our knowledge have not been formally addressed inso-far. One challenge is to understand the users' search behavior when querying the Greek web through Greeklish queries. That is, to find out whether there is any purposeful reason for issuing Greeklish queries, besides that of convenience and practicality (such as the lack of Greek fonts). Another challenge is to study whether Greeklish queries aim at the retrieval of data written in Greeklish only, or do they aim at locating data written in both Greeklish and Greek? Yet a more stimulating challenge is to investigate whether it would be useful for Greek web users to equip search engines with applications that automatically convert Greeklish pages and queries to Greek, in order to support global searches on the Greek web, regardless of the alphabet in use. In such case, a number of modifications would be required at the search engines' indexing modules, in order to be able to maintain stored pages in both their original and transliterated scripts.</p><p>Moreover, there should be modifications at the engines' ranking functions in order to account for the Greeklish web data while ordering search results. Finally, the engines' query processing modules should integrate a Greeklish to Greek converter for automatically transcribing a query of the Latin alphabet into the Greek alphabet.</p><p>In this paper, we address the above challenges and we try to plug in the missing information about the impact that Greeklish may have on the effectiveness of Greek web searching. In particular, we experimentally study the difference between searching in Greek and searching in Greeklish, in terms of text-based retrieval performance. In the course of our study, we have developed a Greeklish-to-Greek translator that converts the contents of Greeklish pages into Greek. Moreover, our system converts Greeklish queries into Greek, so as to enable searching in the Greek web space via transliterated queries. We applied our translator to a number of experimental queries that we issued to Google Greece<ref type="foot" target="#foot_9">2</ref> search engine that indexes pages in both Greek and Greeklish and we evaluated the relevance of the returned results. We also carried out a user survey where we study how Greek users select the alphabet of their queries and how their selections exemplify their search pursuits and influence their search experiences. Obtained results demonstrate that there exist several diversifications between the Greek and the Greeklish web data, which inevitably influence retrieval performance. Moreover, our findings indicate that users have different goals in mind when searching in Greeklish compared to searching in Greek. In this respect, the use of Greeklish queries could serve as a useful guide while trying to predict the users' search goals.</p><p>The remainder of the paper is organized as follows. We start our discussion with a brief introduction to the Greeklish writing system and we present our approach towards making search engines understand Greeklish. In Section 3, we describe our experimental study and the dataset that we used. Experimental results are presented in Section 4. We conclude the paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">UNDERSTANDING GREEKLISH</head><p>Greeklish is not a language, but rather an alternative way of writing Greek using non-Greek fonts. For example, the sentence καµία ερώτηση δεν έµεινε αναπάντητη (no question was left unanswered) would transliterate in the Latin script as kamia erotisi den emine anapantiti. But, this is not the only way of transliterating /transcribing<ref type="foot" target="#foot_10">3</ref> the Greek characters of the sentence into Latin ones. Another way of writing our example sentence would be kamia erwthsh den emeine anapanthth.</p><p>As our example demonstrates, Greeklish is characterized by spelling variation in which the characters of the Greek alphabet may be transliterated with more that one Latin equivalents. These transliterations can be of two general types, namely orthographic and phonetic <ref type="bibr">[1]</ref>. In orthographic transliterations the Greek orthography is generally reproduced in Latin characters as the transliterated terms erwthsh, emeine and anapanthth indicate in our second Greeklish example sentence. Conversely, in phonetic transliterations there is not a one to one mapping between Greek and Latin letters, but rather the pursuit is to phonetically transcribe Greek words with Latin characters, as the terms erotisi, emine and anapantiti in our first Greeklish example sentence illustrate. Yet, there still exist quite a few variations in both orthographic and phonetic transliterations of certain Greek characters. For instance, the Greek letter θ (theta) may be written as 8, 9, 0, q, u in the orthographic use of Greeklish and th in the phonetic use. What makes things more complicated is that oftentimes people switch between phonetic and orthographic transliterations, therefore increasing the heterogeneity of Greeklish writing. Recently, it has been attested <ref type="bibr">[2]</ref> [21] that the different Greeklish writing styles might be attributed to several factors besides phonetic and visual ones such as psychological, educational or geographical factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Unraveling the Greeklish Web</head><p>A fraction of the textual data that is available on the Greek web is written in Greeklish. Although many consider the use of Greeklish in web sites as an indication of the site operators' lacking knowledge of the language, nevertheless Greeklish persist mainly due to technical and ergonomic reasons. With respect to technical issues, Greeklish is a suitable vehicle for getting the message through when the Greek characters are not supported by a system or an Internet Service provider. On the other hand, ergonomic reasons imply that the additional burden of switching between the keyboard settings when writing foreign words in Greek texts is not worth the effort of the user who wants to write fast and communicate instantly.</p><p>Based on the above, it is not surprising that Greeklish is endorsed by the online population for social and international communication. Currently, there exist several web sites whose purpose is to enable people communicate in an instant and interactive manner.</p><p>Most of these sites have a more social than professional character and include blogs, forums, chat rooms, message boards, etc. The wealth of the data stored in such sites is primarily textual and might be of great importance to web users who are interested in finding information about other peoples' comments, experiences and perspectives on a particular subject. With the current growth of the web as a part of our commercial life and the flourishing emarket of online goods, it is more demanding than ever to enable instant access to other peoples' shared viewpoints, opinions and recommendations, through the use of search engines.</p><p>Unfortunately, not all Greek search engines index blogs or forums and those that do, they never return Greeklish pages in response to Greek queries. Nevertheless, besides social sites, there exist quite a few academic (i.e. university) sites that release part of their content in Greeklish. Given the dual nature of the Greek web's script, search engines perceive Greeklish as a totally distinct language from Greek. Therefore Greek pages are retrieved for Greek queries only, and Greeklish pages are returned for Greeklish queries only. But, a search engine indented for a large audience should treat all pages in the Greek web space uniformly regardless of the script in use, and it should never neglect the potential information gain of the users who have global access to the information that exists on the Greek web.</p><p>To enable search engine users get the gist of the information that is available on the Greek web, we need to design a sound model that not only manages to download, index and retrieve pages written in Greeklish, but which is also capable of interpreting Greeklish efficiently. By interpretation, we mean that a search engine should be able to understand the subject of a Greeklish page, the degree with which it relates to a given query and the page's importance on the Greek web. Likewise, the engine needs to understand Greeklish queries in order to answer them successfully.</p><p>Most importantly, the engine should not discriminate between Greek and Greeklish data in the results returned for some query, unless it is otherwise specified by the user.</p><p>Given the lack of a standard transliteration for Greeklish, it is extremely difficult to automatically process Greeklish data. Because of that, search engines either prefer not to waste resources for indexing Greeklish pages or they index Greeklish pages but solely retrieve them in response to Greeklish queries by employing string matching techniques. Evidently, in both cases, search engine users are systematically deprived of either the Greeklish or the Greek web data, depending on their preferred query alphabet.</p><p>One approach towards enabling the uniform retrieval of the data that is available on the Greek web regardless of the script or writing style is to cast the problem of Greeklish web data processing as a translation problem. That is, to translate Greeklish web pages and queries in Greek and thereafter employ traditional text indexing and retrieval methods for enabling their exploration by the search engine users. The availability of a Greeklish-to-Greek translator would not only facilitate the retrieval of Greek pages through the use of Greeklish queries, but it would also enable the reverse approach, i.e. the retrieval of Greeklish data in response to Greek queries. The latter could be achieved by mapping Greek queries to the translated Greeklish pages and upon the identification of query matching pages, return the latter to the user either in their original (Greeklish) or in their translated (Greek) writing.</p><p>To fill this void, we have developed a Greeklish-to-Greek converter that we applied to a number of searches against Google Greece search engine and we experimentally evaluate the impact that the conflation of Greek and Greeklish online data has on retrieval performance. Our goal is to assist Greek web users locate accurate, valuable and interesting information while interacting with search engines. Next, we present our approach towards conflating Greek and Greeklish data at the search engine level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Translating Greeklish</head><p>The problem of transcribing Greeklish to Greek is not new. Currently, there exist quite a few converters <ref type="bibr">[20]</ref> [8] that cope with some Greeklish transliteration patterns and can be either accessed online or downloaded from the web. Moreover there exist some Greek to Greeklish translators <ref type="bibr">[19]</ref> [3] that convert Greek characters into Latin ones. Although Greek-to-Greeklish translation is quite straightforward and it can be effectively achieved via a one to one character mapping, the translation of Greeklish to Greek is much more complicated, essentially due to the inconsistency in the Greeklish writing styles. Most of existing Greeklish-to-Greek translators rely on a predefined fixed set of transliteration rules, which simply replace every Latin character with a suitable Greek one. Few of the existing translators utilize regular expressions <ref type="bibr">[10]</ref> in order to cope with context-dependent patterns. Currently, the most successful Greeklish translator is the "All Greek to me!" system <ref type="bibr">[5]</ref> that automatically transliterates any type of Greeklish. "All Greek to me!" is the first translator to use a set of transliteration rules together with a lexicon, a speller and a language identification module. However, the translator is not freely available and it is a stand alone tool that cannot be readily integrated into a third party application.</p><p>Given the lack of an open Greeklish-to-Greek translator that could be easily integrated in a web search engine, we decided to build our own translator for conducting our study on the Greeklish web searches. Although the process for building the translator goes beyond the scope of this work, we briefly present the basic modules that our tool incorporates and we describe how it can be employed in the context of web searching.</p><p>Our Greeklish-to-Greek translator incorporates a set of transliteration rules that have been manually determined based on a number of writing patterns that we have extracted from a Greeklish web corpus of nearly 800K words. Given an input Greeklish text, our translator firstly performs all possible conversions of the Latinized terms into their corresponding Greek script. Thereafter, it checks the derived terms against a morphological lexicon of nearly 1,000,000 distinct wordforms <ref type="bibr">[14]</ref>. The lexicon entries are organized in an inverted trie structure in order to facilitate dynamic dictionary string matching. Based on the lexicon data files, our translator improves malformed characters and retains only valid transcriptions, i.e. terms identified in the lexicon. Terms not recognized as valid Greek terms in the lexicon are given as input to a spell-checker, which corrects orthographic, intonation and typing errors. Correctly spelled Greek words together with valid transcriptions are utilized for deriving the Greek translation of the input Greeklish text. The remaining terms that cannot be recognized by any of our modules are stored in a separate list which is manually examined by the translator expert. Figure <ref type="figure" target="#fig_0">1</ref>, illustrates the overall architecture of our Greeklish-to-Greek translator.</p><p>In a similar but much more simplified manner we have developed a Greek to Greeklish translation module, which transcribes Greek text in the Latin script. Having presented our translation module, we now turn our attention to the way in which this could be fruitfully explored in web search applications.</p><p>Rendering a search engine with some level of understanding on the correspondence between Greeklish and Greek basically entails the integration of translation services in both the engine's indexing and query processing modules. With respect to Greeklish indexing, one approach might be to parse the Greeklish pages, remove markup and tokenize the pages' textual content. Thereafter, use the pages' Latinized word tokens as input to our Greeklish-to-Greek translator, which will convert them into their corre-sponding Greek words. Following translation, one might employ traditional indexing techniques to represent the pages' content at the index level. Note however that indexed terms should be maintained in both their Greek and Greeklish representations so as to enable the pages' retrieval through any of the two query languages. For the Greeklish representation of the indexing terms it would be preferable to use not only the writing style of Greeklish in which the terms appear in the pages, but also to use all their possible (or at least common) variations. To enable that, it would be useful to employ a converter, so as to transcribe the indexing terms into all their possible Greeklish variants.  Following the above process, we can represent every indexed Greeklish page as a set of keywords, both Greeklish and Greek, so as to ensure that the underline page will be retrieved in response to a keyword query, irrespectively of the alphabet or the writing style adopted by the user. Queries can be treated in a similar manner and searched against the engine's conflated index. More specifically, Greeklish queries should be converted into their Greek equivalents and Greek queries into all their possible Greeklish variants. To some extend, this approach might be perceived as a query expansion technique, in which all possible alphabetic variants of a query word participate in the search process. The approach described above can be applied to every page on the Greek web so as to ensure that the search engines will be capable of capturing the complete picture of the Greek web's content. It is important to note that a pre-requisite step that the engine's modules need to take before initializing the translation process it to accurately identify the language of the page. To that end, we suggest the utilization of a language identification module that would be able to recognize Greeklish as a potential language in which web pages are written.</p><p>Following the translation and the processing of the Greeklish web data as given above, we can easily improve the engine's ability in interpreting both the relevance and the importance of a Greeklish web page in response to some query. In particular, we can explore the translated page's content terms against a semantic resource or a lexical ontology in order to automatically derive the page's topical category. Moreover, we can explore the translated page's content in order to compute the degree with which it relates to a particular query. Query-page relevance estimations may be either statistical or semantic driven, depending on the query matching algorithms the engine employs. Finally, the query-page correlation values could be fruitfully utilized for ranking the pages retrieved for some query. Next we describe how our proposed modules can be applied while searching the Greek web and we experimentally demonstrate the impact that the conflation of Greek and Greeklish might have on retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL FRAMEWORK</head><p>To evaluate the impact that the conflation of Greeklish and Greek online content might have on search engines' retrieval performance, we carried out two distinct, yet complementary, experimental studies. In one experiment, we conducted a user survey in order to collect data about the query patterns of the Greek web users. In particular, we examined the frequency with which Greek users issue Greeklish queries, the search goals hidden behind such queries and the users' perception on the usefulness of the Greeklish web pages. In our second experiment, we applied our Greeklish-to-Greek translator to a number of web searches that we performed to Google Greece search engine that indexes both Greek and Greeklish data, and we compared the performance of our mixed Greeklish and Greek queries in delivering relevant results to the performance of Greek-only and Greeklish-only queries. We start our discussion with the description of our experimental studies and we discuss obtained results in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">User Goals in Greeklish Queries</head><p>To study the users' search goals and expectations associated with issuing Greeklish queries, we carried out a human survey in which we examined the reasons why people query the Greek web through Greeklish queries, the kind of data that they wish to obtain, the perceived quality of the Greeklish web pages and what in the users' opinion could improve Greeklish web searches. In our survey, we recruited 42 graduate students in our department, with high levels of computer literacy and familiarity with Greeklish and we asked them to fill in a questionnaire that we designed for our study on Greeklish web searches. We decided to limit our survey to computer science graduate students mainly because of their ease of access and their proficiency in searching the web. However, we believe that this restriction does not introduce a significant bias in our results, because our experimental queries (presented next) are also collected from the same department and users. All our study participants had support for Greek characters in their workstations. The exact questions that we presented to our survey subjects are given in Table <ref type="table" target="#tab_0">1</ref>.</p><p>While distributing the questionnaire to our participants, we notified them that the purpose of our study was to investigate how users perceive the Greeklish web through both the queries they issue and the pages they visit. Our subjects were given ample of time for completing the questionnaire, but it generally took less than half an hour until all our participants delivered their answers.</p><p>As a final note, our participants volunteered to complete the questionnaire and they were encouraged to ask for clarifications in case they could not fully understand a particular question. Before reporting our survey results, we proceed with the description of our second experiment where we evaluated the effectiveness of blending Greeklish and Greek in retrieval performance.</p><p>Table <ref type="table" target="#tab_0">1</ref>. The questions distributed to our study participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Greeklish Web Information Retrieval</head><p>To measure the impact that the conflation of Greek and Greeklish data might have on web retrieval performance, we carried out an experimental study, in which we issued a number of queries in both Greek and Greeklish to Google Greece search engine and we evaluated obtained results.</p><p>To collect our experimental queries we asked from each of our study participants to specify a query that mimics a search they had performed earlier that day. For each of the queries, we asked our participants to write it down in both Greek and Greeklish and indicate which of the two writings they had used in their actual submission of the queries. Moreover, we asked them to indicate the search goal of their query by selecting one of the following<ref type="foot" target="#foot_11">4</ref> : (i) navigational, (ii) informational, and (iii) resource. Finally, we advised them to adopt their personal style of Greeklish writing for typing their queries in Greeklish. In total we collected a set of 42 queries, of which 31 were originally submitted in Greek and 11 were originally submitted in Greeklish.</p><p>We issued our experimental queries to Google Greece search engine, which indexes both Greek and Greeklish data. We submitted every query three different times: in the first submission every query was issued in Greek, in the second submission que-ries were issued in Greeklish while in the third submission every query was typed in both Greek and Greeklish. For example, the query databases was written as βάσεις δεδοµένων in its first submission (Greek), as baseis dedomenwn in its second submission (Greeklish) and as βάσεις δεδοµένων / baseis dedomenwn in its third submission (both Greeklish and Greek). Note that the combined Greek and Greeklish queries (i.e. in their third submissions) are processed as Boolean OR queries, in the sense that the pages that are retrieved in their response might be written either in Greek or in Greeklish.</p><p>Before the actual submission of our queries, we processed them as follows. All Greek queries went through a spell-checker in order to ensure that they would contain only correctly spelled terms. Moreover, Greek queries passed through our Greek-to-Greeklish converter which returned for every transliterated query all its possible Greeklish variations. On average, for every Greek query our system returned 4.3 Greeklish transliterations. Finally, Greeklish queries were transcribed in Greek through the usage of our Greeklish-to-Greek translator. Thereafter, we submitted each of our experimental queries to the selected search engine three different times: (i) in Greek, (ii) in Greeklish (cf. all variations considered), and (iii) in both Greek and Greeklish. Out of the 42 experimental queries, 37 returned results in both their Greek and Greeklish submissions. Experimental evaluation concerns those 37 queries.</p><p>Following query issuing, we collected the first ten results returned for every query in each of the submissions and we asked our study participants to evaluate the results' relevance to the respective queries as follows. Each participant was shown the first ten results returned for her query across all the three query submissions. Retrieved results were displayed to our subjects in a random order. We then asked our participants to read each of the pages returned for every query and rate them using a fourpoint scale. Results' scoring indicates the degree to which the users perceive retrieval results to be relevant to their query intention and take values from 0, meaning that the result is irrelevant, to 3 meaning that the result is highly relevant.</p><p>Based on the users' relevance judgments, we computed the average relevance values of the top ten results delivered for a query across the three submissions, in order to evaluate the impact that the conflation of Greek and Greeklish have on retrieval performance compared to Greek-only and Greeklish-only information retrieval. Experimental results are discussed in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Why Greeklish?</head><p>In this section, we present our human survey results, which help us improve our understanding in the users' search habits when querying the web in Greeklish. Due to space constraints, we do not graphically illustrate the distribution of the answers that our participants gave to every question. Nevertheless, we report percentage values for all the issues examined in our study. In particular, our results indicate that Greeklish is frequently used by our study participants (62.5% of our users write in Greeklish daily), although most of them (56%) sometimes find Greeklish hard to read. Moreover, 47.5% of our subjects visit Greeklish sites/ pages on a regular basis (i.e. more than once every week) and 65% of our users evaluate the content of Greeklish pages as generally useful. However, the fraction of our subjects' visits to Greeklish sites/pages through the use of search engines accounts to 20%, whereas a significant number of visits (37.5%) are accidental, in the sense that our users come across Greeklish pages as they navigate in the web.</p><p>When it comes to Greeklish web searches, 17.5% of our subjects use Greeklish often in their queries, while 37.5% use it sometimes, 37.5% do not generally use it and 7.5% have never tried Greeklish queries. Figure <ref type="figure" target="#fig_9">2</ref> illustrates the breakdown of the reasons behind issuing Greeklish queries as these are determined by our study participants who have used Greeklish in their queries. As we can see, a large number of people (40.5%) query the web in Greeklish as an alternative way of locating information in case their Greek searches fail to return useful data.</p><p>With respect to the information sources that people expect to obtain in response to Greeklish queries, 37.8% of our users indicated that they query in Greeklish when looking for sites/pages that contain information about products, goods and services, and 24.4% of them when looking for blogs, forums, chat boards, etc. An interesting finding is that none of our users prefer Greeklish queries to look for pages maintained by official sites or by people living abroad. This is in line with the responses that our subjects gave to Question 10 and which indicates that the most common search goal behind Greeklish queries is to obtain resources rather than reach to a particular page or find information on a topic of interest. Figure <ref type="figure" target="#fig_10">3</ref>, depicts the distribution of search goals in Greeklish queries. Concerning the users' reaction when a Greeklish query fails to return any useful results, a surprising observation is that 29.8% of our subjects issue a different Greeklish query and 21.6% of them try the same query in Greek, as illustrated in Figure <ref type="figure" target="#fig_5">4</ref>.</p><p>Another interesting finding is that 25% of our users expect to read Greek in the pages returned for Greeklish queries, while 27.5% of our subjects expect to read Greeklish and 32.5% expect to read both Greek and Greeklish in the pages retrieved for Greeklish requests. This is a quite interesting result that merits further investigation before we can justify the grounds of the participants' answers and before we realize whether the expectation for Greek content in the results of Greeklish queries is attributed to the nature of the queries, (e.g. names of products, proper names) or to the nature of the pages (e.g. pages that blend Greek and Greeklish content) What is interesting though is that most of the users (67.5%) would like to read Greek in the pages returned for Greeklish queries. If search engines could support the retrieval of Greek content in the results delivered for Greeklish queries, our subjects indicated that they would issue more Greeklish queries; 62.5% of our users gave a positive answer to Question 13 (Yes, I believe I would) and only 22.5% of them answered negatively (No, I believe I would not). This observation justifies the need for our work on Greeklish web searches and we hope that our findings will stimulate the interest of others in assisting Greek web users experience improved searches.</p><p>A secondary objective in our human survey was to examine the variety of transliterations exemplified in our users' Greeklish writings. For that, we included Question 14 in our questionnaire in order to obtain perceptible evidence on the different ways in which Greek words can be transliterated in Greeklish. An analysis of the obtained transliterations demonstrates that these can vary to orthographic, phonetic or mixed transliterations, where the latter conflate visual and phonetic transcription of terms.</p><p>Table 2 reports our study results on the different transliterations that our subjects projected to their answers in the last question that we gave them.   *the words with asterisks are actually transcribed as there is no variation between their orthographic and phonetic transliterations *+ although the word in transcribed as "sto" one of our subjects replaced s with 6 as this resembles more the Greek letter 'σ'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. Results on Greeklish transliterations.</head><p>A close look on the data reported in Table <ref type="table" target="#tab_7">2</ref> demonstrates the great inconsistency in Greeklish writings as well as the frequent alterations between orthographic and phonetic transliterations.</p><p>For instance the only difference between the orthographic and the phonetic transcriptions in the terms κάθε (every) and µεθόδους (methods) concerns the transliteration of the letter θ (theta). Although, 60% of our subjects selected a phonetic transliteration for representing θ in the first term, this percentage went up to 65% for the transliteration of θ in the second term. This practically implies the inconsistency in the personal writings of Greeklish, as the same user may switch between different transliterations in a single sentence.</p><p>Another noteworthy observation is that one of our subjects transliterated the term βρω (find) as Bpw, which is a more visual than strictly orthographic transcription. The above example indicates that people not only have their personal styles in writing Greeklish, but also that they try to make their Greeklish transliterations look as if written in the Greek alphabet, even when the latter is not utilized. This last conclusion is further supported in the transliteration of the term πρόβληµα (problem) for which one of our users transcribed the first letter π (pi) as two consecutive capitalized Latin T (i.e. TT).</p><p>Summarizing, the results obtained from our human survey verify that the number of people who prefer Greeklish in their web transactions is non-negligible and it is expected to grow as the commercial usage of the web increases. However, the vast majority of people prefer to read Greek in the obtained results, regardless of their selected query alphabet. In case such option was provided in today's search engines, they would probably issue more Greeklish queries. Lastly, given the remarkable variation in the Greeklish writing, we believe that a search engine capable of understanding Greeklish and the correlation it has to the Greek language would assist information seekers encounter successful web searches. The validity of our argument is experimentally supported in the findings of our second study, discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Greeklish Retrieval Performance</head><p>In this section we report on the results obtained in our second experimental study where we evaluated the effectiveness that the conflation of Greek and Greeklish alphabet has on retrieval performance. As discussed in Section 3.2 our evaluation was based on a set of 37 real queries that we submitted to Google Greece search engine. Query submissions followed a 3-step approach with a different query alphabet utilized in every step.</p><p>In the first submission of the queries we used the Greek alphabet, in the second submission we used the Latin alphabet, while in the third submission we used both alphabets, simply by expanding Greeklish queries with their Greek transliterations and vice versa.</p><p>Experimental queries are classified into three groups depending on their underlying search goals as these have been determined by our study participants. The first group contains navigational queries such as "Athens University of Economics and Business".</p><p>The second group contains informational queries such as "mother's day' and the third group contains resource queries such as "map of Patras University". Out of the 37 queries examined, 8 have been associated with a navigational goal, 24 have been associated with an informational goal, and the remaining 5 have been associated with a resource goal.</p><p>To evaluate the impact that the query alphabet has on retrieval performance, we relied on the relevance judgments that our study participants indicated for the first ten results retrieved for a query across each of the three query submissions. Figures <ref type="figure" target="#fig_31">5,</ref><ref type="figure" target="#fig_7">6</ref> and 7 show obtained results for resource, informational and navigational queries respectively. In the figures, the x-axis represents experimental queries and the y-axis shows the average relevance scores of the top 10 pages retrieved for every query in each of the submissions. For each query, the first bar represents the average relevance values of the top ten results retrieved for the Greek query, the second bar represents the average relevance scores of the top ten pages returned for the same query in its Greeklish submission, while the third bar represents the average relevance scores of the top ten results delivered for the conflated Greek and Greeklish query.</p><p>Resource Queries 0,0 Results demonstrate that our mixed Greek and Greeklish search can successfully identify query relevant pages, especially when these pertain to resource requests. In particular, based on our the results of our human survey we found that a significant number of Greeklish queries intend to retrieve resources that the user will either download, interact with or save/print them for further utilization (cf. Figure <ref type="figure" target="#fig_10">3</ref>).</p><p>For such search goals, expanding Greeklish queries with their Greek equivalents increases the likelihood that the resources sought will appear at the top positions in the results list. For instance, consider the case of the Greeklish query Q36 syntagh gia patsitsio (pastitsio recipe) which retrieved results with an average perceived relevance of 0.3 at ranking point 10. A closer look at the first ten obtained results demonstrates that these mainly come from forums where people discuss about recipes, foods that they like, etc. Unfortunately, none of the top ten Greeklish pages contains a recipe for patsitsio, which is the information that the user was hopping to receive. Let's now turn our attention to the results retrieved for the same query following its expansion with the Greek terms. The overall relevance of the first ten pages returned for the expanded query is 2.9, while a closer look at the first few retrieved pages demonstrates that most of them concern pages written in Greek and which they do give a recipe.</p><p>Likewise, the first ten pages returned for the Greeklish query Q35 isotimia euro dollariou (euro dollar exchange rate) have an average relevance of 0.7, as they mainly concern pages in forums that discuss users' opinions on the exchange rates. On the other hand, expanding the query by appending the Greek terms yields an average relevance of 2.8 at retrieval point 10 and results include pages in Greek such as the homepage of the Athens stock market as well as financial news articles that give exchange rates. In overall, as Figure <ref type="figure" target="#fig_6">5</ref> illustrates, the expansion of Greeklish queries with their Greek equivalents yields improved retrieval relevance for all our resource queries.</p><p>Informational Queries Conversely, for informational queries where the Greek alphabet is generally preferred, the results obtained for Greek requests generally outperform retrieval relevance for their Greeklish counterparts. In particular for 21 of the 24 informational queries examined, Greek retrieval delivered improved results compared to the results returned for their Greeklish transliterations.</p><formula xml:id="formula_13">0,0 0,5<label>1</label></formula><p>Considering that our participants indicated that a large number of their Greeklish queries follow their unsuccessful Greek searches (cf. Figure <ref type="figure" target="#fig_9">2</ref>), we may speculate that it would be useful to return the Greeklish transliterations of the queries together with the search results for the initial (Greek) query so that the user can utilize them in case she wishes to refine her search by adding terms to the initial query.</p><p>For instance, the average relevance of the first ten pages retrieved for the Greek query Q6 πρωτάθληµα µπάσκετ (basket championship) has a value of 1.7 and with the first ten results containing pages about basket championships in elementary schools or local communities among others. Following the expansion of the Greek query with its Greeklish variants, the average relevance of the first ten pages goes up to 2.2, as results include also pages from forums and blogs, where people discuss about the games, comment on the teams' scores, etc. For this particular query, expansion yields increased retrieval relevance mainly because the Latin script of the term µπάσκετ (basket) is widely used in Greek writings.</p><p>Likewise, for the Greek query Q14 κάµερα κινητού (cell phone camera), retrieval relevance has an average value of 1.2 and with the first page containing pictures taken from a cell phone. However, when the query is expanded with its Greeklish variants, average relevance goes up to 2.1 with most of the pages at ranking point 10 discussing cell phone models that incorporate a camera. Again the particularity of the query is that the term κάµερα (camera) is used in both Greek and Latin scripts in many Greek pages.</p><p>As our examples indicate, expanding Greek queries with their Greeklish transliterations can yield improved search results especially when the transliterations account to a common writing of a Greek term. This is especially true for technical terms most of which are primarily written in the Latin script. Therefore, we argue that recommending query transliterations as additional terms for improving a query can be beneficial to the user who might not consider Greeklish queries as an option for modifying her search.</p><p>Navigational Queries 0,0 0,5  Finally with respect to navigational queries, our results indicate that Greeklish can successfully retrieve the desired information especially when the term of the query appears in the URLs of the sought page. Given that page URLs use the Latin script it is reasonable to assume that Greeklish requests have good chances of detecting relevant pages for navigational queries. As our example query Q27 τα νέα (the news) shows Greeklish search has an increased retrieval performance compared to Greek essentially because the query refers to the name of a popular Greek online newspaper that uses its name in the URL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Queries Average Relevance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GREEK GREEKLISH MIXED</head><p>Based on our findings and considering that 67.5% of the users would like to see Greek pages in the results returned for Greeklish queries (on the provision that these relate to their information need) we may suggest that the conflation of both Greeklish and Greek has a significant potential in improving retrieval performance. Therefore, leaving the option of conflation or not the user can significantly improve the engine's usability and it will definitely assist users gain more control over their searchers, regardless of their preferred query alphabet.</p><p>Summarizing, our study is the first reported attempt to understand and evaluate the Greeklish web data from a search engine perspective. Our findings indicate that equipping search engines with mechanisms that can conflate Greek and Greeklish data in a single resource can be beneficial to the web users. We realize that such conflations would increase the computations required for translating the indexed pages from one alphabet to the other and that it would also entail additional storage capacity for maintaining translated pages at the index level, nevertheless it is worth the effort considering that the translation process is performed offline, while processing downloaded pages. Above all, the major goal of the search engine community is to assist users find the information sought in an effortless yet effective manner. With this goal in mind, we argue that Greek information seekers can benefit from the search engines' enhancement with mixed Greek and Greeklish search options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUDING REMARKS</head><p>In this paper, we experimentally studied the phenomenon of querying the web in a hybrid language. In particular, we focused our study on searching the Greek web via Greeklish queries, i.e. Greek language queries that are written with the Latin script. Through a human subject study, we first showed that about 46% of our participants issue Greeklish queries when looking for web resources. This study further suggested that 40.5% of our subjects use Greeklish queries when their Greek searches fail to retrieve the desired information. Moreover, 67.5% of our study participants indicated that they would like to receive both Greek and Greeklish data in the results of their Greeklish queries. We then proposed the conflation of Greek and Greeklish data in the searches performed by Greek information seekers and we experimentally evaluated the impact that the blended Greek and Latin alphabet has on retrieval performance. Our evaluation showed that expanding Greeklish query terms with their Greek equivalents increases the relevance of the search results.</p><p>Although querying the web in a hybrid language is not a global phenomenon, nevertheless there exist quite a few writing systems that, either adopt the Latin alphabet for transcribing terms in orthographically complex languages, or they combine elements of different languages in one script. One example is Runglish, a neologism used to denote latinizations of the Cyrillic alphabet or mixing English and Russian grammatical structures. We may not know whether and how such invented amalgamate languages are employed when it comes to the web data; however we hope that our work will open up avenues for future research in the direction of both query-based and speech-based web searches.</p><p>Finally, our study on Greeklish web searches should be interpreted as neither an endorsement nor a rejection to the use of Greeklish. Rather, it should be perceived as the investigation of a phenomenon that influences peoples' interaction with search engines, a valuable tool for acquiring worldwide knowledge. Given the freedom that characterizes the nature of the web, people creating, using, interacting and searching the web should be given the freedom to choose their personal style of expressing their thoughts. Through our work, we are only giving them the tools to do that efficiently so as to help others benefit from it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Conflation is a general term for all processes of merging together nonidentical words which refer to the same principal concept i.e. to merge words which belong to same meaning class. The primary goal of conflation is to allow matching of different variants of the same word. In natural language processing, conflation is the proc-ess of merging or lumping together nonidentical words which refer to the same principal concept <ref type="bibr">[1]</ref>. In the context of information retrieval (IR) conflation has a more restricted meaning and usually refers to grouping together morphological variants of the same or related words <ref type="bibr">[2]</ref>. Conflation algorithms can be broadly divided into two main classes: stemming algorithms, which are language dependent and which are designed to handle morphological variants, and string-similarity algorithms, which are (usually) language independent and which are designed to handle all types of variant <ref type="bibr">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Arabic language</head><p>Arabic is a Semitic language, it consist of 28 letters, and its basic feature is that most of its words are built up from, and can be analyzed down to common roots. The exceptions to this rule are common nouns and particles. Arabic is a highly inflectional language with 85% of words derived from tri-lateral roots. Nouns and verbs are derived from a closed set of around 10,000 roots <ref type="bibr">[4]</ref>. Arabic has three genders, feminine masculine and neuter; three numbers, singular, dual (represent 2 things), and plural. May be replace by "The specific characteristics of Arabic morphology make Arabic language particularly difficult for developing natural language processing methods for information retrieval. One of the main problems in retrieving Arabic language text is the variation in word forms, for example the Arabic word "kateb" (author) is built up from the root "ktb" (write). Prefixes and suffixes can be added to the words that have been built up from roots to add number or gender, for example adding the Arabic suffix ‫"ان"‬ (an) to the word "kateb" (author) will lead to the word "kateban" (authors) which represent dual masculine. What makes Arabic complicated to process is that Arabic nouns and verbs are heavily prefixed. The definite article ‫"ال"‬ (al) is always attached to nouns, and many conjunctions and prepositions are also attached as prefixes to nouns and verbs, hindering the retrieval of morphological variants of words <ref type="bibr">[5]</ref>. In Table <ref type="table" target="#tab_0">1</ref> an example for the word student is presented in order to clarify this issue. Arabic is different from English and other Indo-European languages with respect to a number of important aspects: words are written from right to left; it is mainly a consonantal language in its written forms, i.e. it excludes vowels; its two main parts of speech are the verb and the noun in that word order, and these consist, for the main part, of trilateral roots (three consonants forming the basis of noun forms that are derived from them); it is a morphologically complex language in that it provides flexibility in word formation: as briefly motivated above, complex rules govern the creation of morphological variations, making it possible to form hundreds of words from one root <ref type="bibr">[6]</ref>. Furthermore the letters shapes are changeable</p><p>Copyright is held by the author/owner(s). SIGIR'07 iNEWS07 workshop, July 27, 2007, Amsterdam, The Netherlands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Stemmer approaches Table 1. Word form variations that share the same principal concept whose English translation contain the word student or students</head><p>In information retrieval systems stemming is used to reduce variant word forms to common roots and thereby improve the ability of the system to match query and document vocabulary <ref type="bibr">[7]</ref>. Although stemming has been studied mainly for English, stemming techniques have also been developed for several other languages such as Malay <ref type="bibr">[8]</ref>, Latin <ref type="bibr">[9]</ref>, Indonesian <ref type="bibr">[10]</ref>, Swedish <ref type="bibr">[11]</ref> Dutch <ref type="bibr">[12]</ref>, German <ref type="bibr">[13]</ref>, French <ref type="bibr">[14]</ref>, Slovene <ref type="bibr">[15]</ref>, Turkish <ref type="bibr">[3]</ref> and Arabic <ref type="bibr">[16,</ref><ref type="bibr">17]</ref>. There are three main approaches for stemming, Dictionary-based, Rule-based, and Statistical-based approaches <ref type="bibr">[18]</ref>. Dictionary based approaches provide very good results at the cost of high development efforts for the dictionary. The dictionary contains all known words with their inflection forms. The main weakness for this approach is the missing words in the dictionary which would not be recognized by the system for stemming. <ref type="bibr">An</ref> weakness is the inability of this method to stem inert names and foreign words. Also the need to process a large dictionary during runtime can result in high requirements for storage space and processing time. The closest Arabic equivalent for this kind of stemmer is the Root-Based stemmer which is based on extracting the root of a given Arabic surface word by striping off all attached prefix and/or suffix then attempt to extract the root of a given Arabic surface word. Several morphological analyzers were developed based on this concept <ref type="bibr">[19]</ref>  <ref type="bibr">[16]</ref>. The weaknesses for this stemmer are: it does nothing when it comes across some words which have no root, for example the Arabic words " ‫ﺑﻌﺪ‬ , (after) ‫ﺗﺤﺖ‬ (under). Furthermore, the construction of the corresponding dictionaries or rules is a tedious and labor consuming task due to the result of the morphology complexity of Arabic language. Another problem is that only some small linguistic resources are available for Arabic language. The second approach is the Rule-Based approach; it is based on set of predefined conditions rules. The most well known stemmer is Porter stemmer <ref type="bibr">[20]</ref>. The main weakness for this stemmer is that building the rules for the arbitrary language is time consuming. Furthermore, there is a need for experts with linguistic knowledge in that particular language. The Arabic equivalent for this is the Light stemmer. Unlike English, both prefixes and suffixes need to be removed for effective stemming. it is based on striping of prefix and suffix from the word, it use predefined list of prefix and suffix, it is simply striping of prefix and/or suffix without any further processing in the rest of the stemmed word <ref type="bibr">[21,</ref><ref type="bibr">17,</ref><ref type="bibr">22]</ref>. The weakness of this stemmer is that the striping of prefixes or suffix in Arabic is a not an easy task, removing them can lead to unexpected results, as many words start with one letter or more which can mistakenly assumed to be prefix or suffix. Due to the fact that all light stemmers use the normalization, which consist of several steps, one of them is to Replace in form, depending on the location of the letter at beginning, middle or at the end of the word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English Translation Feminine Masculine</head><p>Based on these properties of Arabic language, i.e. that nouns and verbs are massively prefixed and suffixed, we derived the need for modifications of the commonly used n-gram based conflation techniques so that these specific properties are considered. Furthermore, the ambiguity with respect to the similarity score measure of the pure n-gram approach should be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>‫أ‬ , ‫ﺁ‬ ‫إ‬</head><p>and with bare alef The remainder of this paper is organized as follows. In Sec. 2 we discuss previous related work on conflation techniques. In Sect. 3 the proposed algorithm is described. The used data, the evaluation and results are discussed in Sect. 4. Some concluding remarks are finally given in Sect. 5.</p><p>‫ا‬ to avoid the ambiguity as most of the Arabic users use just the bare alef ‫ا‬ in their search, this is will lead to the result that all ‫ال"‬ " (al) will be mistakenly identified as prefix even if they are in reality not. Example for that the Arabic words ‫ﺁﻻت"‬ " (Machines), ‫ﺁﻻف"‬ ‫ﺁﻻم‬ ‫أﻻن‬ " (Thousands), " " (Afflictions)," " (now) ‫ﺁﻟﻢ",‬ " ‫ﺁﻟﻴﺎت‬ ‫ال‬</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Conflation techniques</head><p>(Mechanisms). When stripping off all " " (pain)," " (al) then the result of the stemmer will be whether other Arabic words, example for that the Arabic word "</p><p>In the following we briefly discuss the two major conflation techniques: stemmers and n-gram based techniques.</p><p>‫"ﺁﻻم‬ when stripping off the ‫ال"‬ ‫ام‬ " then the result will be " " which mean mother, or the result will be not an Arabic word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">N-gram conflation techniques ‫اﺳﺘﻤﺮارﻳﺔ‬</head><p>The main idea of n-gram based approaches, which groups together words that contain identical character sub-strings of length n called n-grams <ref type="bibr">[23]</ref>, is that the character structure of the word can be used to find semantically similar words and word variants. N-gram as conflation technique differs from stemmers in terms of not requiring language knowledge, predefined rules or a vocabulary database. Furthermore; n-gram approaches take into account the misspelled and the transliterated words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">N-Gram and Arabic text</head><p>Over the last years there were several studies which explore the use of n-grams for processing Arabic text. Mayfield et al. <ref type="bibr">[24]</ref> have found that n-grams work well in many languages; furthermore they investigated the use of character n-grams for Arabic retrieval in TREC-2001 and found that n-grams of length 4 were most effective. Darwish and Oard examined multiple tokenization strategies for retrieval of scanned Arabic documents, they found out that n-grams of size n=3 or n=4 are well suited to Arabic document retrieval <ref type="bibr">[25]</ref>. In <ref type="bibr">[26]</ref> Suleiman H. Mustafa assessed the overall performance of two n-gram techniques that he called conventional and hybrid. The conventional approach combines as usual for comparison the first character with the second and second with third and so on till w n-1 +w n . The so-called hybrid approach combines the first character with the second and first with third then second with third and second with fourth till w n-2 +w n-1 ,w n-2 +w n , w n-1 +w n . Furthermore, three different levels of word stemming were applied: no stemming, light stemming, and higher-order stemming. In his results Mustafa pointed out that the hybrid approach outperforms the conventional approach. Classifying Arabic text using n-gram frequencies also have been fruitful <ref type="bibr">[27]</ref>. However, all of the previous studies rely on the investigation of the use of n-gram on the Arabic text based on those factors: The effectiveness of n-gram size and assessing the performance of existing n-gram approaches. None of the prior studies attempt to modify the pure n-gram model such that it considers also language characteristic while computing the similarity score in order to improve its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Computing similarity scores based on ngrams</head><p>The n-gram model can be used to compute the similarity between two strings by counting the number of similar n-grams they share. The more similar n-grams between two strings exist the more similar they are. Based on this idea the similarity coefficient can be derived. The similarity coefficient δ is defined by the following equation:</p><formula xml:id="formula_14">β α β α δ ∪ ∩ = ) , ( b a n (<label>1</label></formula><formula xml:id="formula_15">)</formula><p>where α and β are the n-gram sets for two words a and b to be compared. |α ∩ β | denotes the number of similar n-grams in α and β , and |α ∪ β | denotes the number of unique n-grams in the union of α and β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Revised n-gram approach</head><p>Arabic nouns and verbs are heavily prefixed and suffixed as described in the first section. As a result of that, it is possible to have words with different lengths that share same principal con-cept. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of two Arabic words:</p><p>(Continuousness) and ‫اﺳﺘﻤﺮار‬ (Continued) that have different length but belong to same meaning class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 Bigram similarity measure between 2 words with different lengths</head><p>Furthermore, the pure n-gram based approach to compute the similarity coefficient as described above Eq (1), does not consider the order of the n-grams in the target word <ref type="bibr">[28]</ref>. This increases the probability that the matching score between two strings will be higher even though they do not share the same concept. Therefore, we revised the computation of a similarity between words to take these two aspects into account.</p><p>Based on our previous work <ref type="bibr">[29]</ref> where we applied a revised ngram approach (Multispell) for spelling error corrections, we propose here a modified version for the conflation task. For simplicity, we describe our algorithm for n=2 (bigrams). However, the approach can be applied for trigrams and n-grams with n&gt;3 as well. We define bigrams of words by their respective position in the word w i,i+(n-1) where i defines the position of the first letter and i+(n-1) the position of the last letter of the considered n-gram. Thus, the last possible position of an n-gram in a word is defined by</p><formula xml:id="formula_16">1 | | + - = n w j</formula><p>, where defines the length of the word. In order to deal with the first and second aspect mentioned above, we define a window of n-grams of the target candidate words that should be compared, i.e. while in Eq. (1) all n-grams are compared with each other, we only compare n-grams that are in close proximity to the position of the n-gram in the word to be compared when computing the similarity score. For example, for a window of size 3, which is the average of the Arabic prefix length, the search will shift to the left or right side. An example is given in Fig. <ref type="figure" target="#fig_0">1</ref>, where w' defines the given word ‫ﻣﺘﺴﻠﺴﻠﺔ‬ (Serialized) and w a target candidate | | w ‫ﺗﺴﻠﺴﻞ‬ (Sequence), in case we don't find the n-gram w' 3,4 of w' in the proper location the algorithm will shift the search to the right side in specific locations, so the n-gram w' 3,4 will be compared first with the n-grams w 3,4 , then w 2,3 or w 1,2 of the target candidate w, in case w greater than w' then the search will shift to left side. This will help also in case of misspelled words. Figure <ref type="figure" target="#fig_10">3</ref> show the similarity measure between the Arabic word ‫اﻟﺘﺤﺎﻟﻔﺎت‬ ‫اﻟﻔﺎﺗﺢ‬ (the Alliances) and (the Conqueror). Using the pure n-gram model, the similarly coefficient is quite high (85.72 %) although the two words do not belong to the same meaning class. This results from not taking into account the order of the n-gram on the target word. Figure <ref type="figure" target="#fig_10">3</ref> (right) shows the same example using the revised n-gram model. The similarity coefficient is quite low (28.57 %), since the order of n-gram was taken into account. The approaches were evaluated against 500 queries that were formulated randomly ensuring that the length of the query terms vary and short as well as long query terms are included. In order to construct the random queries, the algorithm requires the availability of a lexicon of terms that were extracted from the test data. Overall, the computation of the similarity score S for a given ngram size n and a given odd-numbered window size m can be defined as follows assuming that u is the longer word (if v is longer than u then u and v can be simply exchanged):</p><formula xml:id="formula_17">N v u g u,v S n u i m m j n j i j i n i i m n ∑ ∑ + - = - - - = - + + + - + = 1 | | 2 2 1 2 1 ) 1 ( , ) 1 ( , , )<label>, ( ) ( (2)</label></formula><p>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4. Example of an Arabic Document</head><p>Here, u and v are the words to be compared, the nested sum counts the number of n-grams in v that are similar to n-grams at a window of size m around the same position in word v. N is computed similarly as in Eq. (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>In our experiments we compared our approach with the pure ngram approach for bigrams and trigrams. The reason for not taking a larger value for n is the problem of eliminating short words. Previous Arabic studies demonstrate that the character n-gram with n=3 or n=4 are well suited for Arabic document retrieval. Thus, words with length less than 3 or 4 will not be retrieved, since for these no n-grams can be constructed. For example, when trying to retrieve the query ‫ﻳﻘﺮ‬ (Acknowledges) using trigrams, the relevant result ‫ﻗﺮ‬ (Acknowledged) will be eliminated because no n-grams can be constructed for it as it is less than 3 characters long. The targets words must be at least one character longer than the size of n in order to have the chance to be retrieved. For this reason, we used n=2 in the proposed approach to enable retrieval of short words, as well as other words lengths Furthermore, we used the revised n-gram model to avoid ambiguity as described above in Sect. 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data selection</head><p>To collect test data for our evaluations, we crawled the web for articles published on one popular Arabic news Web site ("CNN-Arabic" 1 ) in the period from January 2002 until March 2007 (for an example see Fig. <ref type="figure" target="#fig_5">4</ref>). We thus obtained 5,792 Arabic documents, all of which are abstracts of articles on news, sport, art, economy and Information Science (size ~60MB). More than 1,400,000 Arabic words were extracted with 101,210 unique words. These articles are supposed to be correctly written and have both a large and rich vocabulary and therefore offer more 1 http://arabic.cnn.com/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison of revised and pure n-gram approaches</head><p>where and</p><formula xml:id="formula_18">⎩ ⎨ ⎧ = = otherwise 0 if 1 ) , ( b a b a g</formula><p>In a first experiment we calculated the average precision for each conflation approaches. Table <ref type="table" target="#tab_7">2</ref> compares the result of the revised bigram and trigram approach with the result of the pure bigram and trigram models. As shown in the Table <ref type="table" target="#tab_7">2</ref> the result are quite close. The reason for this is that only 6.5 % out of 500 queries words had a length of less than 3 characters, which is the length that affects the ambiguity. The revised bigram and trigram achieved a better improvement over the pure bigram and trigram due to the reduction of the ambiguity. In a second experiment we calculated the average precision for the pure trigram and the revised bigram for the similarity thresholds of 60, 65, 70, 75, 80, 85, 90 and 95%. Table <ref type="table" target="#tab_25">3a</ref> and 3b show the comparison of retrieved, relevant, irrelevant and average precision between the revised bigram and pure trigram approaches. The revised bigram achieved clearly improvement over the pure trigram. The reason for that is that the revised bigram takes into account all words lengths which will increase the retrieved index terms size, on the other hand the it take into account the order of the n-gram which will decrease the pure n-gram ambiguity results. This will result in decreasing irrelevant terms retrieved. The trigram achieved better results in terms of the ratio of relevant index terms to the index terms retrieved. The revised bigram achieved better results in terms of how many relevant index terms were retrieved compared to the total number of index terms retrieved (relevant and irrelevant). For example, when selecting a threshold of 60 %, the revised bigram retrieved 5472 index terms relevant and 520 irrelevant, while the pure trigram retrieved 4253 index terms relevant and 189 irrelevant. The pure trigram retrieved less irrelevant index terms at the expense of the total number of relevant index terms retrieved while the revised bigram retrieved less irrelevant index terms compared to the total number of relevant index terms retrieved. It is important to notice, that when interpreting Figure <ref type="figure" target="#fig_31">5c</ref>, one need to consider the big difference between the relevant index terms retrieved from each method for different thresholds. As it is shown in Table <ref type="table" target="#tab_25">3a</ref> and 3b the performance of the revised n-gram approach is better than that of the pure n-gram in terms of the total number of relevant index terms retrieved. Table <ref type="table" target="#tab_27">4a</ref> and 4b provide a typical example where revised bigram model retrieved 33 relevant index terms while the pure trigram model retrieved 25 relevant index terms. In the second example, Table <ref type="table" target="#tab_29">4c</ref> and 4d show that the revised bigram model retrieved 18 index terms and all were relevant while the pure trigram retrieved only 8 relevant index terms. Figure <ref type="figure" target="#fig_31">5a</ref> illustrates that although with a threshold of 85% both approaches have maximum precision, the revised bigram performs better than the pure trigram in terms of the number of relevant index terms retrieved.    In a third experiment we estimated the average recall and Fmeasure for a sample of 30 queries out of 500. The query terms were selected in the same way as described in Sect. 4.1. For all queries the number of relevant documents were obtained manually, by selecting all possible word variations. As shown in Tables 5a and 5b both approaches have very similar precisions, but the pure trigram approach missed many relevant index terms and therefore has a lower average recall than the revised bigram approach. The revised bigram approach gained up to 75% average recall while the pure trigram approach achieved 49%. Figure <ref type="figure" target="#fig_7">6</ref> illustrates that revised bigram gained a higher average recall than the pure trigram approach, since it took into account different words length and similarity enhancement. As shown in Tables 5a and 5b revised bigram approach gained a higher F-measure up to 76% compared to the pure trigram approach that gained 59%. These results show that the revised n-gram has gained an overall higher degree of retrieval performance than the pure n-gram approach.  </p><formula xml:id="formula_19">⎩ ⎨ ⎧ &lt;= = otherwise. " " if ) ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We presented a language independent conflation approach, i.e. the approach does not depend on any predefined rules or prelinguistic information knowledge for the target language. We evaluated our approach on Arabic language which is one of most inflectional languages in the world. Since the previous Arabic studies demonstrated that n-grams of size 3 or 4 are the most suitable sizes for Arabic information retrieval, we focused on comparing our approach with trigram based models. The experimental results indicate, that the selection of the n-gram size affects the retrieval performance, i.e. the number of relevant and irrelevant documents retrieved. Using a big size of n lead to the fact that most of the documents retrieved are relevant but at the expense of missing many relevant documents, since the selection of a big n will eliminate short words to be considered. On the other hand, selecting a small value for n lead to the fact that many relevant documents are retrieved but at the same time many irrelevant documents are retrieved due to the ambiguity that is resulting of the small size of the n-grams. Therefore we proposed a revised approach to compare the similarity of words based on n-grams that take the order of n-grams into account. Based on the experimental results we could show that the revised bigram approach provided very good results compared to pure trigrams as well as n-grams with n&gt;3. Furthermore, we demonstrated that the enhancement of the n-gram model provided very good results in term of conflation for heavy inflection languages such as Arabic.</p><p>Our algorithm was evaluated against 500 randomly selected queries. Unfortunately we had no benchmark results to compare our results with, but based on the quantitative and qualitative experimental results we could show that our algorithm achieved better results than pure n-gram approaches. Furthermore, our algorithm helps to achieve a higher degree of accuracy in the conflation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">MOTIVATION</head><p>The problems that non-English languages, and agglutinative languages in particular, have with search engines are well known <ref type="bibr">[5]</ref> [6] <ref type="bibr">[7]</ref>. While some search engines do seem to use some sort of additional techniques for languages like German <ref type="bibr">[9]</ref>, other languages, like Hungarian, have no choice but to implement their own engines in order to have a proper web searching tool available <ref type="bibr">[8]</ref>.</p><p>Basque is also an agglutinative language, so these problems are also applicable, but these are not the only difficulties. Being a minority language, Basque has an additional problem: no search engine offers the possibility of returning pages in Basque alone. Therefore, it is impossible to obtain results for numerous words in Basque, because their forms coincide with words existing in other languages.</p><p>So the need for a proper Basque search service is clear. A possible solution could be to set up our own search engine, one that would only include pages that are in Basque and which would not index the word forms that a page contains, but its lemmas, as proposed in <ref type="bibr">[14]</ref> -Basque language detection and lemmatizing were implemented long ago <ref type="bibr">[1]</ref>-, but it is beyond our possibilities and objectives to implement and maintain all the infrastructure that a search engine and its crawling, indexing and serving involvesbandwidth, disk, reliability, etc.-. This is why we embarked on a project to develop a proper Basque search service built upon the APIs of existing search engines, so that the solution obtained and the methodology could be applied to other agglutinative or minority languages as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODOLOGY 2.1 Description of the problem</head><p>There are two main reasons that make existing search engines unsuitable for the case of Basque. The first is that Basque is an agglutinative language, that is to say, a given lemma makes many different word forms, depending on the case (genitive, locative, etc.) or the number (singular, plural, indefinite) for nouns and adjectives, and the person (me, he, etc.) and the tense (present, past, etc.) for verbs. A brief morphological description of Basque</p><p>Copyright is held by the author/owner(s) SIGIR'07 iNEWS07 workshop, July 27, 2007, Amsterdam, The Netherlands can be found in <ref type="bibr">[3]</ref>. For example, the lemma lan ("work") forms the inflections lana ("the work"), lanak ("works" or "the works"), lanari ("to the work"), lanei ("to the works"), lanaren ("of the work"), lanen ("of the works"), etc. This means that looking only for the exact word given or the word plus an "s" for the plural is not enough for Basque. And the use of wildcards, which some search engines allow, is not an adequate solution, as these can return occurrences of not only conjugations or inflections of the word, but also derivatives, unrelated words, etc. For example, looking for lan* would also return all the forms of the words lanabes ("tool"), lanbide ("job"), lanbro ("fog"), and many more.</p><p>The second reason is that none of the existing search services can discriminate Basque pages in their searches. Searching in any of them for a technical word that also exists in other languagesanorexia, sulfuroso, byte or allegro, to cite just a few examples of the many that exist-or a proper noun or a short word, will not only not yield results exclusively in Basque, but often not yield any results in Basque at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Looking for conjugations and inflections</head><p>When asking a search engine for a word, we need it to return pages that contain its conjugations or inflections, too. Our approach to this matter is based on morphological query expansion. The importance and use of morphology for various IR tasks has been widely documented <ref type="bibr">([13] [15]</ref> [16] <ref type="bibr">[4]</ref>), although it is normally applied by lemmatization at the indexation stage, which is an unattainable objective for us, as has been stated above. Instead, we apply morphological generation at the querying stage. In order to generate all the possible forms of a given lemma, we use a tool created by the IXA Group of the University of the Basque Country. This tool gives us all the possible inflections or conjugations of the lemma, and we ask the search engine to look for all of them by using an OR operator. For example, if the user asks for etxe ("house"), we ask the search engine for "(etxe OR etxea OR etxeak OR etxeari OR etxeek OR etxearen OR…)".</p><p>This is basically how we solve the first problem. It is a straightforward approach, easy to implement, but one which poses, of course, many minor problems and tweaks. The most relevant ones are as follows:</p><p>• The API of each search engine has its limitations with regard to search term count, length of search phrase, etc. We found no documentation on this, so we had to discover each limit by trial and error.</p><p>• These limitations render a proper lemmatized search for Basque impossible, as we cannot search for all the conjugations or inflections. So we used a corpus to see which the most frequent cases, numbers, tenses, etc. were, and we send their respective forms, in order to make the search results as satisfactory and representative as possible. In those cases in which the search engine is too limited, we make more than one query, each with some of the conjugations or inflections.</p><p>• Unfortunately, there is not much documentation about how search engines behave when they are given more than one search term in an OR. Do they start by looking for the first search term and return its results, and only go on to the next term if there are not enough results with the first one? If so, our results would only be better than those of a general search engine if the word in question was very rare. Anyway, we do not think this is what search engines do, as the snippets -short extracts of the pages containing the search term(s)-that they return often contain more than one of the search terms. In fact, we have the impression that they try to return pages that have as many different search terms as possible, which is best for our purposes as it improves representativeness. The increase in recall that emerged in the evaluation seems to confirm our previous assumptions.</p><p>All in all, we can conclude that this method enables us to obtain a satisfactory lemmatized search for Basque.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Language discrimination</head><p>We have mentioned earlier that there is no commercial search engine that can distinguish pages in Basque and return them alone. This poses a problem when searching for a proper noun or a word that exists in other languages; this often happens with technical words -anorexia, sulfuroso, byte, allegro…-and short words. Although there are language detection tools for Basque, a search for such words returns pages in English, Spanish, etc. but rarely any in Basque, so a subsequent filtering of these pages using a language detection tool would be useless.</p><p>The approach we have taken to solve this problem is to include, in the search phrase as a filter, the most frequently used words in Basque, in conjunction with an AND operator. Again, we used a corpus to see which these most used words were.</p><p>Unfortunately, the most frequent words in Basque are short and, as such, the chances of their existing in other languages or being used as abbreviations or acronyms is quite high -the four most used words are eta ("and"), da ("is"), ez ("no") and ere ("too"), and the first two at least have well-known meanings used in other languages-. Therefore, we had to include more than one filter word, but how many were needed? The higher the number of these words we included, the higher the precision obtained (fewer non-Basque pages were returned). However, there was also loss in recall (more Basque pages were left out because they did not contain one or more of the words), and vice versa. The logical choice was to opt for precision -showing the user results in other languages would give a poor image of a Basque search and, besides, the user would never know how many results he or she was missing-, so in the default behaviour we include four of these most frequent terms in the search phrase. However, if the number of results is too low, the user is given the option of trying again increasing the recall -that is, with less filtering words.</p><p>Nevertheless, this failed to resolve the language-filtering problem completely. Even with the filtering words method, non-Basque pages or bilingual pages in which the search term was in a non-Basque part were returned at times. To filter these results, we use LangId, a free language identifier based on word and trigram frequency developed by the IXA group of the University of the Basque Country. This is applied to the snippet returned by the search engine.</p><p>By combining these methods we are able to show results that are exclusively in Basque with a high degree of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Variant searching</head><p>Expanding the query using variants of the search term to improve the results was suggested long ago <ref type="bibr">[10]</ref>. When performing a Basque search, having the option of looking not only for the word but also for different variants of a word -archaic spellings, common errors-or even typing errors is very interesting. It must be taken into account that the standardization of Basque only started in the late sixties, and that many rules, words and spellings have changed since. Besides, Basque was not taught in schools until the seventies, nor in universities until nearly into the eighties. All this has led to a scenario in which even written production abounds with misspellings, corrections, uncertainties, different versions of a word, etc. But, above all, the main problem is that there are many areas or words upon which no decision as to the standard word or spelling has yet been taken.</p><p>The possibility of looking for variants as well has been added as a user option in our tool. All the linguistic tools made for Basque rely upon EDBL, a lexical database developed by the IXA Group of the University of the Basque Country <ref type="bibr">[2]</ref>. This database links each word with its known variants, common errors and archaic spellings. So when sending all the possible inflections or conjugations of a word in an OR to the search engine, it is possible to include these variants, too. If, for example, the user inputs the word jarduera ("activity"), the system can ask the search engine to seek , simultaneously, the forms of iharduera, a now deprecated spelling widely used until 1998.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EUSBILA</head><p>EusBila is the solution we have developed for a Basque search service, making use of the APIs of major search engines and applying the methods mentioned above -lemma-based searching, language-filtering words and variant searching option-. In this section we will explain in more detail how EusBila works, and what its features are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System architecture</head><p>The general architecture of the system is as follows:</p><p>•</p><p>The user enters a search term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>If the user has selected the corresponding option, EusBila uses EDBL to obtain the variants of the search term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The morphological generator is called to obtain the inflections and conjugations of the search term.</p><p>• A search phrase is built by combining the conjugations and inflections of the search term within an OR operator, and the filtering words with an AND operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The APIs of the search engines are queried with the search phrase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The snippets returned by the engines are subjected to a final language test using LangId.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The results are returned to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>Some of the features of EusBila are as follows:</p><p>• Lemma-based and language-filtered search: EusBila performs an internet search for Basque by making use of the APIs of search engines, but simultaneously using morphological generation to obtain a lemma-based search and filtering words to obtain a language-filtered search.</p><p>• Variant searching: The user can also choose to look for known variants -common errors, archaic forms…-of the word.</p><p>• More than one search term: The user can enter more than one search term, and the lemma-based search is performed for all of them. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Lemma and POS of the search term: The user can enter a search term that is not a plain lemma but a form of a lemma -conjugation or inflection-. The search term is analyzed to get its lemma and POS, and the morphological generation is made according to them. If the form is ambiguous, the most probable lemma and POS are taken for the morphological generation, but when the results are returned, the user is given the option of trying with the other analysis.</p><p>• Calls for showing proper snippets: Snippets are the short extracts of the pages that search engines return. As EusBila includes some language-filtering words in the search phrase, the snippets sometimes show these language-filtering words, rather than the word the user was looking for. In these cases EusBila shows no snippet, as the information it contains is irrelevant to the user. But snippets are very useful to help the user decide which link may contain the information he or she is looking for, so EusBila offers the possibility of trying to show as many snippets as possible. This is done by making another call to the APIs of the search engines' for each result without a proper snippet, but restricted to the site and without the filtering words. Naturally, activating this option makes the search slower.</p><p>• Various search engines: EusBila can choose among different search engines (Google, Yahoo, Microsoft, Alexa…). But each of these APIs have their own limit in terms of the number of queries per day. So when opening the service to the public, these limits have been taken into account, and we have chosen to offer EusBila's Basque search service through Microsoft's API. The other choices will either be insufficient for the use a Basque search service might have, or else a fee must be paid to use them.</p><p>We are of the opinion that the number of queries per day offered by Microsoft's API will be enough for EusBila; if not, the commercial license is possible too. In any case, for other minority languages, the other choices might possibly be suitable. The following table shows the limits and licensing possibilities of the APIs we have implemented. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EVALUATION</head><p>The overall impression of any EusBila user is positive. It is clear that it outperforms the major search engines for a Basque search, as it solves the two problems mentioned above. But in order to translate these impressions into objective figures, we have designed and carried out a quantitative evaluation, comparing the results of EusBila with those of a major search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design of the evaluation</head><p>To carry out the evaluation, we decided to assess the two improvements of EusBila -morphological generation and language-filtering words-separately, and see the effect they had on precision and recall.</p><p>In order to do this, we ran searches for a sample of Basque words both through a commercial search engine and through EusBila (using the API of that same engine), in which only the improvement method being evaluated was activated, and then we compared the first 100 results. We thought it was best to use only one API throughout the whole evaluation, and we chose Microsoft, as it is the one that offers the highest number of queries per day -the intensive use of the API needed for the evaluation would easily surpass the daily limit of the others and would many days just to retrieve the results.</p><p>For evaluating the effects of the improvements in recall -either loss or gain-, we measured two variables: the difference in the estimated hit counts returned by the API and the number of different results in the improved query. We are aware that hit counts returned by search engines do not constitute an exact or reliable measure <ref type="bibr">[12]</ref>, but they are used by many researchers as an acceptable approximation <ref type="bibr">[11]</ref>. For our case, we think that hit counts are a clearer indicator of recall than the other measure. Nevertheless, we show the results of the two variables. Both of them were measured and compared automatically, without human intervention.</p><p>For evaluating the gain in precision, we measured the difference in the percentage of Basque pages. This was done by language experts, who recorded the language each page returned was in.</p><p>With respect to the words, we thought it would be better to carry out the evaluation using real, ordinary Basque search terms, rather than choosing random words. For this purpose, we obtained the search logs spanning a whole year from a very popular science portal in Basque, Zientzia.net (http://www.zientzia.net), which meant that we had more than 500,000 searches that made up a total of more than 50,000 different words. We lemmatized these words and ordered them according to decreasing frequency, and took the topmost ones.</p><p>We mentioned above that EusBila's language-filtered search is most noticeable when the search term exists in other languages, or when it is short, or when it is a proper noun. If the word only exists in Basque, the language-filtering words might bring little benefit or even none at all. So when possible, the evaluation variables were measured separately for different categories of words:</p><p>• Short words: Words with 5 characters or less. The probability of their existing in other languages is high. The most searched for words in this category (and consequently the ones used for our evaluation) were: ur ("water"), herri ("people", "town"), lur ("earth", "ground"), zuri ("white", "to you"), baso ("wood"), euri ("rain"), HIES ("AIDS"), berri ("new"), hartz ("bear"), nola ("how").</p><p>• Proper nouns: Proper nouns are usually the same in other languages. The words for this category were Egipto ("Egypt"), Galileo, Edison, Newton, Pluton ("Pluto"), Darwin, Galilei, Thomas, Franklin, Einstein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>International words: Words that we know definitely exist in another language (usually English, Spanish or French). These were the most searched for words in this category: energia ("energy"), historia ("history"), mota ("kind"), sistema ("system"), ozono ("ozone"), planeta ("planet"), mineral ("mineral"), droga ("drug"), biografia ("biography"), natural ("natural").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Words that are probably found in other languages: Technical words which, despite not being exactly the same in the three languages mentioned above, have quite similar spellings in all of them, so the probability of their existing in some other language is high. These were the words used: animalia ("animal"), petrolio ("petrol"), zelula ("cell"), nuklear ("nuclear"), zentral ("central"), klima ("climate"), efektu ("effect"), zientzia ("science"), elektriko ("electric"), aparatu ("system", "device").</p><p>• Basque words: Words that we are almost sure do not exist in any other language. The most searched for words in this category were kutsadura ("pollution"), berriztagarri ("renewable"), elikadura ("feeding"), gaixotasun ("illness"), ugalketa ("reproduction"), berotegi ("greenhouse"), gizaki ("human"), basamortu ("desert"), elikagai ("food"), minbizi ("cancer").</p><p>For the overall measure, we made a weighted average of them, taking into account the frequency of use of each category. To calculate these frequencies, we classified approximately the first 400 words out of the more than 50,000 into one of the categories. This may not seem very much, but they do in fact account for more than 40% of the queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Gain in recall due to morphological query expansion</head><p>As we decided to evaluate each improvement of EusBila separately, in order to evaluate the effects of morphological generation without using the language-filtering words, it was necessary that it should be done only with the Basque words. We searched for them in Microsoft's search API, and then we repeated the operation, but using morphological generation. These were the results obtained: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Gain in precision due to language-filtering words</head><p>We then evaluated the effect of language-filtering words without applying morphological query expansion. We first made a normal search and then an additional one with language-filtering words.</p><p>We measured the increase in the percentage of Basque results for each category of word, and obtained the following results: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Loss in recall due to language-filtering words</head><p>In order to measure the loss in recall that language-filtering words could cause, we needed to have some Basque results before applying them, so it was essential that the chosen words should be exclusively Basque words. Thus we searched for such words in Microsoft's search API, and then carried out the same search, but using language-filtering words. Again, we measured the difference in the hit counts returned by the API and the number of results that did not appear in the first 100 results of the nonlanguage-filtered-search.</p><p>We have pointed out above that EusBila gives the option of choosing between precision and recall, and accordingly includes more or fewer language-filtering words. We have made searches with all the different options, from 1 filtering word to 4, so the result of this evaluation is a range of percentages, as shown in the following tables. Although the loss in recall is not negligible quantitatively speaking, it is not so important in terms of real user experience. The results that are left out because they do not have one or more of the filter words do not usually have very much content. Any text in Basque that is sufficiently long normally contains the filter words. Therefore, even if some results are left out, the ones that remain are usually longer and, therefore, more relevant. This is an impression we have; it has not been evaluated. And in any case, if there are not enough results or if the user does not find the desired result, the system gives the option of trying again with increased recall -that is, with fewer filter words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Gain in recall due to morphological query expansion with language-filtering words applied</head><p>After measuring the two improvements separately, we thought it would be interesting to evaluate both of them together. The application of language-filtering words would let us measure the effect of morphological generation in words that do not exist exclusively in Basque.</p><p>This time we used the most searched for words for each category of word once again. Firstly, we tried a search with the languagefiltering words and then with both language-filtering words and morphological generation. Again we measured the difference in the approximate hit counts returned by the API and the number of new results that did not appear in the first 100 results of the nonmorphological-query-expansion search.</p><p>The results of each category of word and the weighted average can be seen in the following table: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Summary</head><p>This is a summary of the results obtained in the evaluation:</p><p>• Gain in precision due to language-filtering-words: increase of 70.55 points -from 27.19% to 97.74%-in the percentage of Basque pages.</p><p>• Loss in recall due to language-filtering words: a decrease ranging between 6.48% and 57.69% in hit counts, depending on the number of words</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gain in recall due to morphological generation:</head><p>o With words that exist only in Basque and without language-filtering words: an 89.43% increase in hit counts o With any word and applying language-filtering words: a 40.19% increase in hit counts</p><p>The evaluation shows that the benefits obtained with our methodology for a Basque search are considerable, so we can conclude that EusBila is a valid service for searching in Basque.</p><p>Although the loss in recall due to language-filtering words is significant in quantitative terms, we have the impression that those fewer results are qualitatively better, and in any case, the user can reduce the amount of filter words if necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>Using search engines for making a query in a minority and agglutinative language like Basque is often a frustrating experience, as they do not perform lemma-based searching or return results in Basque alone.</p><p>With EusBila we have built a Basque search service that doesn't need to crawl or index anything, as it makes use of the APIs of the main search engines. To obtain a lemma-based search it uses morphological query expansion, and to obtain pages in Basque alone it uses language-filtering words.</p><p>The evaluation has shown that the methodology used is valid, as the increase in performance -gain in precision due to languagefiltering words and gain in recall due to morphological generation-is significant. Even if there is a loss in recall due to the language-filtering words, the reduced result set seems to be qualitatively better; moreover, it can be avoided as the inclusion of filter words -and the number of them-is optional.</p><p>Furthermore, it seems to us that the methodology used in EusBila could be used by other minority and agglutinative languages to build a search service suited to them, even more so if we take into account that the requirements of the system are very low, as it makes use of the APIs of the search engines. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In general, an information retrieval system tries to find and retrieve relevant documents related to a user query, with * Copyright is held by the author/owner(s). SIGIR'07 iN-EWS07 workshop, July 27, 2007, Amsterdam, The Netherlands.</p><p>documents and query being in the same language <ref type="bibr">[1]</ref>, <ref type="bibr">[14]</ref>, <ref type="bibr">[15]</ref>, <ref type="bibr">[20]</ref>. 6,700 languages are spoken in 228 countries and English is the native language of only 6% of the world population <ref type="bibr">[10]</ref>. There are Web pages in almost every popular language. While approximately 70% of the available Web content is in English, the number of native English speakers only constitutes 35.8% of the world's online population <ref type="bibr">[18]</ref>. The first accessible Web sites were in English and the first search services (in about 1995) were implemented to meet the needs of this speaking community (e.g. Lycos, AltaVista, Yahoo!). The users of these services were mainly academic people and had enough knowledge of the English language to formulate meaningful queries and to understand the documents retrieved <ref type="bibr">[16]</ref>. However, the number of web sites from non-English speaking countries is increasing progressively, and thus the multilingual processing of documents is becoming more and more important.</p><p>Nowadays, at least two different user types of a multilingual information retrieval system are identified <ref type="bibr">[15]</ref>, <ref type="bibr">[16]</ref>: The first group of users have good skills in reading a text in a foreign language, but cannot express the information need as well as in the own language. For this case, the system should provide the possibility to find documents in the foreign language using their mother tongue. Such users will benefit enormously if they can enter the queries in their native language, because they can examine relevant documents even if they are not translated. The second users are persons who are monolingual but interested in finding information in documents that are written in foreign languages. Thus, they want to be able to evaluate the relevance of a document to their query before starting a search with a full translation of their information need. These users can use translation aids to be able to understand their search results in a second language.</p><p>Now, different features that were seen as too complicated to help the users in the search process, are used. Some examples are given from 'natural language queries', ranked retrieved document results, 'query-by example' or query formulation assistance <ref type="bibr">[2]</ref>. Such features are now partially implemented in some search interfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MULTILINGUAL LEXICAL RE-SOURCES</head><p>Lexical resources can be used in natural language processing in order to obtain a context description of different word senses. Searching for a word, we can select concepts based on the linguistic relations of the lexical resource that defines the different word senses. Such disambiguating relations are intuitively used by humans. However, if we want to automate this process, we have to use resources -such as probabilistic language models or ontologies -that define appropriate relations. One of the most important resources available to researchers for this purpose is WordNet <ref type="bibr">[13]</ref> and its variations like MultiWordNet <ref type="bibr">[17]</ref> and EuroWordNet <ref type="bibr">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">EuroWordNet</head><p>In the beginning, WordNet was only developed for the English language. Then, different versions were developed for other languages as for example EuroWordNet <ref type="bibr">[22]</ref> for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). Its structure is the same as the Princeton WordNet <ref type="bibr">[13]</ref> in terms of SynSets with different semantic relations between them. Each individual wordnet represents a unique language-internal system of lexicalizations. The Inter-Lingual-Index (ILI) was introduced in order to connect the WordNets of the different languages. Thus, it is possible to access the concepts (SynSets) of a word sense in different languages.</p><p>Since our goal is to support the user in searching relevant documents in multilingual web collections, we decided to use EuroWordNet <ref type="bibr">[22]</ref> for retrieving the meanings of the query and the related translations that can be used for query (re)formulation and translation (see also Sect. 3). But analyzing EuroWordNet, we encountered different problems that had to be solved in order to use it as supporting resource in the search process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fine and Coarse Grained Representation of Word Senses</head><p>Since many lexical resources or ontologies, especially Word-Net, frequently provide too fine grained word sense distinctions, we implemented the tool LexiRes <ref type="bibr">[7]</ref> that offers the possibility to navigate lexical information and helps authors of already available lexical resources to delete or restructure concepts by using semi-automatic merging methods. The restructured information can be navigated and explored. Authors can decide if word senses are unambiguous and important enough to keep them at the same place in the hierarchy or if they express similar concepts and can be merged under the same (now, more general) meaning. One way to obtain a higher granularity is to merge SynSets if they describe a very similar meaning of the same word (see also <ref type="bibr">[9]</ref>).</p><p>For web search, such methods could be used for creating a reduced structure of the ontology hierarchy, having fewer word senses that are carriers of a more distinctive meaning, in order to categorize the documents retrieved <ref type="bibr">[5]</ref>. Therefore, we implemented four online methods to merge SynSets based on the relations of hypernymy and hyponymy, meaning context and domain. An overview and a detailed description of the merging methods is given in <ref type="bibr">[9]</ref>. With these methods we can adapt the word sense granularity of a term to the users' needs. Every user has different associations within a concept, so we can adapt the description granularity of a word, adapting it to these associations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Combining and Translating Word Senses</head><p>The search of a word sense can be expanded using different words. These words not only describe the word context, but also a combination of meanings. In German, for example, there are a lot of words that are compounds. An example of transparent compound words "Schrankwand" (wall unit) in German. Compound words are often not contained in linguistic ontologies such as EuroWordNet. However, the meaning of such a word can, in many cases, be obtained from the combination of the meanings of the word parts. If people, for example, do not know what this compound word means, they start to decompose it in order to extract the individual word senses. In order to understand the sense of the complete compound word, the word parts are then translated in their own language. This process can be applied to many languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">RDF/OWL EuroWordNet Representation</head><p>Because of the different problems related to WordNet and its variations (see Sect. 2.3, Sect. 2.2 and <ref type="bibr">[9]</ref>, <ref type="bibr">[8]</ref>, <ref type="bibr">[4]</ref>), we decided to convert it into an RDF/OWL representation, in order to enable the development of more flexible revision methods. In EuroWordNet, one SynSet contains all related word senses, synonyms and relations to other SynSets and to the Inter-Lingual-Index. This information had to be prepared for inclusion in the appropriate RDF Schema and reorganized for a new data representation.</p><p>The decision of converting EuroWordNet was also based on the need of extending it (because not all meanings are covered) with other resources. Since most domain-specific ontologies are in OWL and a WordNet monolingual RDF/OWL representation has already been implemented, we decided to extend it for multilinguality purposes. Based on the work done in <ref type="bibr">[21]</ref>, we converted EuroWordNet into an RDF/OWL representation <ref type="bibr">[11]</ref>.</p><p>Since EuroWordNet has several relations and a structure that is different from the Princeton WordNet, several steps were required to adapt the data to the RDF/OWL Schema of WordNet and to extend this RDF Schema with the new relations. We first analysed the requirements for EuroWord-Net and adapted the WordNet RDF Schema to a multilingual representation of EuroWordNet. Then, we converted the EuroWordNet relations into OWL properties and extended the ontology with two domain ontologies <ref type="bibr">[11]</ref>. In previous work <ref type="bibr">[11]</ref>, we discussed this conversion and extension of EuroWordNet in OWL. We described the steps of this conversion and the problems that arose. Afterwards, we showed the inclusion of the OWL "pizza" and "travel" ontologies under the EuroWordNet structure with examples. The first step before including the domain ontologies in the new EuroWordNet OWL hierarchy was to convert these into the OWL format taken from <ref type="bibr">[21]</ref>. We applied some merging methods to add these domain ontologies to the Eu-roWordNet OWL representation implemented. The domain ontology is then added to the generic one, directly under its new hyperonym. The new resulting OWL structure is then shown in LexiRes <ref type="bibr">[8]</ref>, a visualization tool we developed and adapted, in this case, for handling OWL ontology structures. This work was a first attempt to evaluate how well EuroWordNet could be used as OWL ontology. The use of this OWL implementation and its performance has to be evaluated further in order to see the benefits of it. Another important remark is that at the moment we can only extend EuroWordNet in a "monolingual way". But finding multilingual parallel resources, we could also easily extend it in a "multilingual way".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SUPPORTING WEB SEARCH WITH MULTILINGUAL LEXICAL RE-SOURCES</head><p>In this section, we discuss approaches for using multilingual lexical resources for combining language exploration and web searches. The main idea is to support users to navigate information using semantic connections between word senses provided by multilingual lexical resources. This can help the user to better understand the different meanings of a word in his/her native language, and even more important, to explore its meanings in a foreign language. Combined web searches can help to understand meanings, since the search results provide examples for word and phrase usage. Furthermore, hit statistics of word co-occurrences in web pages provide hints about correct translations or word usage.</p><p>Tools designed to combine the information from both resources in order to support multilingual web search or help to disambiguate word meanings by providing information about the distribution of words in the web to a user, are presented in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multilingual Web Exploration</head><p>Due to the increasing globalization, people are nowadays forced to obtain and to process information not only in their native language, but also in foreign languages. Especially if people want to access and search in multilingual document collections, they need to posses good language skills to discover the correct meaning of the concepts in the target language. Unfortunately, people frequently have a good passive understanding of a foreign language, but are very often not able to find the correct word sense translation. Thus, tools that are able to translate words and implicitly support language acquisition, would be beneficial. In order to support this need, we consider the Web as a learning repository where learners can find examples of word usage. The web documents are a representative example of the combination of words for finding the correct translation and the word-related relevant documents. This combination can be used in tools for language acquisition in computer-assisted language learning (CALL) environments <ref type="bibr">[19]</ref> or for crosslanguage retrieval, while solving some of the still existing problems of multilingual retrieval systems and at the same time implicitly supporting the user in language acquisition. Approaches like CALL applications are used for language teaching and learning in order to support language learners with computer technology. Usually, these tools help the learner to evaluate, reinforce and present the learned topics essentially with interactive elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multilingual Lexical Resource Exploration</head><p>In order to support users dealing with multilingual document collections, we use multilingual lexical resources because they provide information about the linguistic relation of words in-between languages. However, they usually cannot be applied directly, e.g., for tasks like translation or multilingual search, due to the ambiguity of words. On the other hand, huge document collections like the World Wide Web provide statistical information about the distribution and co-occurence of words in almost all languages. This tool was designed to combine the information provided by multilingual lexical resources with the information provided by web searches. Thus, it allows us to study how both resources can be efficiently combined.</p><p>A first visualization interface for multilingual search, Multi-LexExplorer <ref type="bibr">[4]</ref>, was developed with a focus on multilingual explorative search. MultiLexExplorer combines word sense disambiguation with a text retrieval approach in an interactive framework. It uses lexical resources to support the user in disambiguating documents (retrieved from the web or a local document collection) given the different meanings (retrieved from lexical resources, in our case EuroWordNet <ref type="bibr">[22]</ref>) of a search term having unambiguous descriptions in different languages. By visualizing search results grouped by keyword combinations and word senses, the user can discover languages using lexical resources for disambiguating meanings, combining words and their translation. The translations of all possible source language senses are provided in the target language based on the ILI entries of EuroWordNet (see <ref type="bibr">[22]</ref>). Thus, the multilingual exploration is carried out in two directions: finding the correct translations using lexical resources and finding documents according to the search terms and their translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combining Lexical Resources and Web Searches</head><p>Figure <ref type="figure" target="#fig_0">1</ref> shows how our tools are related to the system architecture which implements different functionalities for browsing multilingual lexical resources and related Web documents. Two types of users are recognized. On the one hand, we have the learner/user who first wants to find all possible word senses, retrieve the appropriate translation from the lexical resources and categorize documents (if the user needs such an automatic help) to the proper word sense and, finally, visualize the search results together with the information provided from the used lexical resources. This user can use the MultiLexExplorer <ref type="bibr">[3]</ref> for navigating both multilingual lexical resources and documents. On the other hand, we find the author who uses the RDF/OWL LexiRes tool that works with RDF/OWL structures (see Sect. 4), where he/she can load OWL ontologies. In this way the Eu-roWordNet word senses and translations are restructured and provided for query (re)formulation or translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RDF/OWL LEXIRES</head><p>The main idea of the RDF/OWL LexiRes Tool is to give authors the possibility to navigate the ontology hierarchy in order to re-structure it, by manual merging, adding or deleting word senses. The tool is implemented in Java and uses the Jena Semantic Web Framework <ref type="bibr">[12]</ref> for querying and retrieving lexical data. It provides an RDF/OWL model in order to access and query the lexical resource. Using EuroWordNet for cross-language retrieval, we support the author in: Figure <ref type="figure" target="#fig_9">2</ref> shows a screenshot of the LexiRes editor. On the top left side, we can choose the source language and enter the query term. On the right side (under the "Show Relations" area), we can choose which collection we want to use and which linguistic relations are to be considered for visualization. Query translations can be enabled in the "Show Translations" area.</p><p>Looking for the word "bank", in the English language, the ontology engine retrieves 15 meanings. These meanings describe the different word senses. Every word sense is represented as a SynSet. The author can choose to "Show Properties" or "Hide Properties" with a left mouse click on a SynSet. Here all SynSet-related information is shown. The original RDF resource part of the SynSet can also be displayed by clicking on the right mouse button and choosing the "Show RDF Resource" option. The properties and the RDF code are then shown on the right-hand side under the "Details" box. After logging in, a user-specific lexical resource collection can be created. In our case, the collection contains a reference to the EuroWordNet lexical resource (as default). The author can add or remove meanings in order to enrich or restructure the hierarchy. It is also possible to query the adapted EuroWordNet lexical resource.</p><p>To create new meanings, the author has to integrate them into the hierarchy. This is achieved by specifying the most appropriate superordinate node. New words (and their related terms) can be entered in the "Create New Word Sense" dialog. The system searches for known meanings of these terms and suggests (to the author) a list of candidates with their synonyms, descriptions and generic terms. If any meaning matches the meaning of the query term in the hierarchical context, it can be selected and grouped under the superordinate node. Alternatively, the author can generate a new meaning which is then added to the hierarchy (see Figure <ref type="figure" target="#fig_10">3</ref>). External domain-specific ontologies can be merged into the collection using the "Import Ontology" option. Then, the ontology can be uploaded and, if suitable, be added in the relation hierarchy. Further details are given in <ref type="bibr">[11]</ref>.   When a word sense is removed, the system updates the hierarchy by also removing the respective connections from the linguistic relations. In a graphical representation, this corresponds to deleting all adjacent edges along with the node. If a meaning is deleted, the resulting lack of connection between super-and subordinate words becomes a remarkable situation. Because semantic relations do not have to be transitive, the super-and subordinate nodes cannot always be directly connected. Such situations have to be resolved by the author.</p><p>The tool also allows the manual merging of SynSets when the author decides that two SynSets belong to the same meaning and/or describe the same concept. For example, the two "bank" SynSets under the superordinate "incline" SynSet in Figure <ref type="figure" target="#fig_5">4</ref> could be merged. Therefore, the author can pick a "source" SynSet in the hierarchy that should be merged to a "target" SynSet. The "Merge Word Sense To" menu shows all possible target meanings. The "source" meaning with all its relations is transferred to the "target" meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>Summarizing, by using EuroWordNet for cross-language text retrieval, we support users in different tasks. They can explore the linguistic context of a word in the general hierarchy. They can search in different languages, e.g., by translating word senses using EuroWordNet. The word senses of different word combinations can be disambiguated. Users can interact with the system changing the search context of the original query and, thus, also the search words and the number of retrieved results, or expanding the original query to restrict the number of retrieved documents. The retrieved web documents can be automatically categorized by using different categorization methods (e.g., as described in <ref type="bibr">[5,</ref><ref type="bibr">6]</ref>).</p><p>In our future work, we plan to use information from a learner profile that could be used to automatically modify the granularity of the senses that are distinguished by the system (see the discussion in Section 2.1). An advanced learner might be interested in very fine grained sense distinctions, while a beginner is usually more interested in learning quickly rough language concepts. Currently, it is only possible to manually adapt the granularity of word sense distinction. The use of different ontologies is already possible through our system architecture. A Protégé plug-in could be made available for building knowledge-based tools and applications, or we could make our "RDF/OWL LexiRes" tool publicly available. In the future, we are also planning a user study in order to evaluate the performance of our tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>People in different countries use different characters to represent the words of their native languages. With library automation and the development of networked information structures, the problem of finding a unique way to show information has become much more complex <ref type="bibr">[1][2]</ref>. Unicode <ref type="bibr">[4]</ref> was devised so that one unique code is used to represent each character, even if that character is used in multiple languages <ref type="bibr">[3]</ref>. In this paper, we describe Farsi language transcription in Unicode framework and we discuss challenges that someone would face when processing and retrieving Farsi e-texts.</p><p>Farsi is a member of the Indo-Iranian family of the Indo-European languages. Farsi has the properties of agglutinative languages.</p><p>[5] <ref type="bibr">[6]</ref> The majority of affixes in Farsi are suffix with limited prefixes as well. After the Arab's conquest in 651 A.D., the Persians adopted an extension of unified Arabic script for writing. Salient characteristics of Arabic script are: existence of various connecting letters, varying graphic forms for many letters depending on their position in a word, varying letter width, absence of full size characters for vowels (vowels are represented with particular signs above and below characters), existence of a number of digraphs and composite letters, writing direction from right to left and absence of upper case and lower case letters.</p><p>General rules of Arabic writing system are followed by the writing system of Farsi.</p><p>Since Arabic is a cursive script, the number of possible shapes that letters actually can adopt exceeds the number of these letters <ref type="bibr">[8]</ref>. Letters attach to each other to represent a word. Since Arabic is a Semitic language, it is obvious that how letters must be attached to each other to represent a word. In Farsi, however, due to the fact that it is an agglutinative language, there could be ambiguity in what letters should be written attached together or detached. For instance, the plural form of the word ' ‫ﮐﺘﺎب‬ ' /ketâb/ (book) may be written as ‫'آﺘﺎﺑﻬﺎ'‬ /ketâbhâ/ or ‫هﺎ'‬ ‫'آﺘﺎب‬ /ketâb hâ/ (books). This results in some difficulties in Farsi text analysis as cited in <ref type="bibr">[7]</ref>[8] <ref type="bibr">[9]</ref>, i.e. tokenization of Farsi e-text since word boundaries are not clear. Also, the fact that short vowels usually are not written and capitalization is not used will result in ambiguities that impede computational analysis of the texts. Since these various representations of Farsi are encoded in different manner, then in many cases a search engine can not retrieve Farsi texts.</p><p>In the following, after a brief introduction to Farsi encoding, we will introduce the concept of e-orthography and we discuss how it may be used to tackle the problems when analyzing and retrieving Farsi e-texts. The rest of paper is organized as follows: section 2 introduces Farsi transcription and encoding. Section 3, describes the e-orthography concept and its application to Farsi. Finally, we conclude in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Farsi Transcription and Encoding in Digital Environments</head><p>"Iranian Academy of Persian Language and Literature", which is a governmental body presiding over the use of the Farsi language, has created an official orthography of the Farsi language, entitled "Dastur-e Xatt-e Fârsi" (Farsi Script Orthography) <ref type="bibr">[10]</ref>, for the proper representation of texts in the paper based system of writing. This orthography is the common orthography widely used by the Persian speakers and indicates how characters must attached to each other to present a Farsi Word. For example, it specifies how affixes should be attached to words.</p><p>Unicode standard version 4.0 reserves the range 0600 to 06FF for Arabic characters. The important design principles observed in the Unicode standard and relevant to the representation of Arabic script are characters not glyphs. As mentioned in the previous section, Arabic letters can have up to four different positional forms depending on their position relative to other letters or spaces. According to the design principle "characters, not glyphs", there is no individual code for each visual form (glyph) that an Arabic character can take in varying contexts but there exists only</p><p>Copyright is held by the author/owner (s).</p><p>SIGIR'07 iNEWS07 workshop, July 27, 2007, Amsterdam, The Netherlands.</p><p>one code for each actual letter. The correct glyphs to be displayed for a particular sequence of Arabic characters can be determined by an algorithm. In order to display the characters properly, two special characters namely Zero Width Joiner (0x200D) and Zero Width Non Joiner (0x200C) are added to the character codes, either before or after them. The use of these special characters after a code means that a ZWJ or a ZWNJ should be added after the character if the character is not followed by a "right-join causing" character, or a "non-joining character" respectively.</p><p>The ISIRI 6219:2002 (Information Technology -Farsi Information Interchange and Display Mechanism, using Unicode) <ref type="bibr">[11]</ref> has been proposed as the Farsi standard for using Unicode in digital environment. This standard indicates a subset of Arabic character set in Unicode to be used by Farsi users. Despite this standard, Farsi keyboard layouts are using different codes and therefore, many of Farsi users do not follow this standard. Moreover, the ISIRI 6219:2002 standard does not enlighten how Farsi Orthography can be obeyed in this standard.</p><p>The mentioned fact imposes difficulties when retrieving Persian texts, since characters, and therefore words are represented with different codes and search engines do not cover this problem. For example, a word like ‫'اﺗﻤﯽ'‬ /atomi/ which means "Atomic" can be represented in two different coding string since the last character has two encoding option. So, if you search for documents which contain this word, you may miss number of actual results since you have searched just for one of the forms of the word depending on the keyboard layout of your system. The problem is getting more complex when an affix is used to change morphosyntactic features of words. Usually affixes can be written in three different forms regarding the word, attached to the word, detached and with a space between word and affix, detached but with a ZWNJ character between them.</p><p>We should consider that the policy of text encoding, tokenization, orthography, and text processing are in interaction with each other. As a real example, consider we would like to define a tag set for Farsi Corpus tagging. As mentioned, in Farsi it is possible that a bound morpheme appears detached from its stem with an intervening space; if we assume space as a delimiter in the tokenization process according to the used orthography, either we have to consider a tag for these bound morphemes during corpus tagging or, we have to consider a more complicated tokenization process as it is cited in <ref type="bibr">[7] [9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Farsi e-Orthography</head><p>Unfortunately there exists no standard format for Farsi orthography in the digital environment. As mentioned above, the encoding standard is not sufficient to represent a consistent representation for Farsi. For this reason, we have suggested an approach to represent Farsi electronic texts, or e-orthography. In other words, the e-orthography indicates how the orthography of a language can be followed within an encoding system. Therefore, e-orthography should notice what character codes must be used, how they attach to each other to form a word, and finally which tokenization policy must be taken.</p><p>As to Persian, according to the proposed paper-based orthography by the Academy, Farsi affixes must be written attached to their stem. In some cases when the stem ends in a letter which is a "right-join causing character", the affix must attach to the stem with a short space character before it. In order to reach this objective in electronic texts, ZWNJ character has been used as the short space. Also a character set based on the proposed standard in <ref type="bibr">[11]</ref> has been used. This way, space characters represent unambiguous word boundaries and the orthography of Farsi etexts remains consistent with the one proposed in <ref type="bibr">[10]</ref>. Also, this transcription results in Farsi e-texts which are more consistent with the e-texts of other languages.</p><p>In a keyword based search engine, the e-orthography with the proposed definition influences the effect of search engines in two ways. First of all, the index terms may be changed since the tokenization policy may be varied. Moreover, the user query can be described in other forms which are consistent with proposed eorthographies. To have an idea, as to Farsi, if we search for a word like ' ‫ﮐﺘﺎب‬ ‫هﺎ‬ ' /ketâbhâ/, a search engine may just retrieve 10% of documents containing this term, considering that first of all character may be represented by different codes, the suffix is written in other forms, characters represented with different lengths, and short vowels may be written or not. An application of proposed e-orthography may be viewed in the development of '1984 corpus' for Farsi <ref type="bibr">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>This paper introduces the concept of e-orthography and its important role in the efficiency of keyword based search engines. e-orthography tells us how the orthography of a language can be followed in an encoding system, what character codes should be used, how they attach to each other to form a word, and which tokenization policy must be taken in document processing. E-Orthography can be a guideline for both systems that generate e-text, as well systems which are used to retrieve and manage etexts. As to the keyword based search engines, the e-orthography can describe how the input query of the users should be refined to retrieve documents. Also e-orthography can change the indices and keywords which are used to retrieve documents.</p><p>Although the paper concerns Farsi, the concept of e-orthography can be expanded to other languages as well. Including the eorthography concept as part of search engines' design can enhance recall and precision parameters. Moreover, the e-orthography concept can be used in other domains like natural language processing and corpus tagging. The mentioned fact indicates that the present standards for text encoding are not sufficient for proper representation, as well as retrieving e-texts.</p><p>The concept of e-orthography is getting more important while analyzing languages such as Farsi and Kurdish; languages that have problems in their representation because of the language nature and their writing system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In many document processing tasks a correct identification of relevant topics offers a helpful starting point to develop advanced applications to deal with browsing and searching in large collections of documents. In this context, one of the most valuable tools are specialized thesauri. These kinds of structure organize a set of concepts relevant to a given domain in a hierarchical structure, making it possible to employ a sort of controlled vocabulary to simplify document processing.</p><p>The classical approach <ref type="bibr">[2]</ref> relies on human processing to perform thesaurus term selection after reading each document in the collection. This approach requires the availability of trained experts and suffers from a lack of scalability, since this kind of work is very time consuming and difficult to apply on large collections of documents. We propose to partially replace this kind of human made task with an automatic tool able to identify, for each input document, a list of potential descriptors taken from the domain thesaurus.</p><p>In this paper we describe our preliminary work on the automatic assignment of relevant topics, taken from a structured thesaurus, to documents written in natural languages. In our case we are interested in the domain of legislative texts in Spanish. We have an available thesaurus, manually built, with more than 1800 concepts, arranged in a tree structure. We also have a collection of legislative documents, whose main topics have been identified by humans according to the entries in that thesaurus. The approach we have followed models thesaurus topic assignment as a multiple label classification problem, where the whole set of possible classes is hierarchically organized. Many previous proposals <ref type="bibr">[11]</ref> have dealt with text categorization, but the case of hierarchical classes is usually omitted <ref type="bibr">[8]</ref> or the generalization to multiple label classification is not directly supported <ref type="bibr">[3,</ref><ref type="bibr">4]</ref>.</p><p>Our aim is to build a system able to assign descriptive topics to input documents. The set of possible topics is taken from the thesaurus entries and for each document many descriptors may be selected with no special restrictions about the relationships among them. So, in the set of assigned descriptors we could find pairs of sibling entries or any combination of ancestors and descendants.</p><p>We also want our system to model in some way the processing made by humans when they perform this kind of task. In our domain, legal texts in Spanish, a very restricted kind of document structures is commonly employed. Document contents can be segmented into consistent text regions and expert users pay special attention to those specific portions which usually carry the most relevant content. Examples of these are the document introduction, the description of the document aims, the destination section or text portions dealing with legal motivations and background. Also, human experts tend to use the thesaurus structure as a guide to select descriptive topics from it. So, we maintain this two intuitions in our approach that filters entries from the topics hierarchy in a top-down fashion.</p><p>The article is outlined as follows. Section 2 introduces our classification framework. Next, Section 3 describes the document representation and processing. In Section 4 the most relevant details about the training and classification strategies are described. Section 5 shows the results obtained in our preliminary experiments. Finally, Section 6 presents our conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">TOPIC ASSIGNMENT AS A CLASSIFI-CATION TASK</head><p>Some questions need to be taken into account before starting to describe our proposal. First of all, we are working on a big domain from a text processing point of view. On the one hand, we have a very large collection of legislative documents. These documents tend to be quite long, with sizes ranging from hundreds to thousands of words. On the other hand, we also have a big set of potential classes arranged in a tree. In this context there are two main aspects to have in mind. First of all, we must ensure a practical computational cost, both in the training phase and specially in the topic assignment phase. We also must offer a robust classification framework, able to return a consistent list of topics for a great variety of input documents, without contradictions. With regard to the available resources, we have a thesaurus built by hand for the domain of legislative text and a set of historic documents with their corresponding descriptors assigned by human experts, which will be employed in the training phase.</p><p>With these premises in mind, a first approach could be to take the available documents and train a big classifier using all of the topics in the thesaurus as output classes. This approach is almost impractical from a computational cost point of view, but also it has many important problems with output quality and a lack of robustness and consistency. Training such a classifier involves estimating a large number of parameters with too many irrelevant features that will disturb the classification decision.</p><p>The strategy we have chosen is inspired by Koller and Sahami's work <ref type="bibr">[6]</ref> and takes advantage of the class hierarchy to simplify the classification task in two aspects. Firstly, the global classification problem is reduced to a sequence of partial classifications, guided by the structure of our topic tree. Secondly, the computational cost for each classification step is reduced and the resulting quality is improved by means of the use of a specific set of features, exclusive to each node in the hierarchy. In this manner, the classification decision is distributed over a set of partial classifiers across the topics tree. In this model each internal node will be responsible for a local classification decision, where only a small set of features from the document will be taken into account to select the most promising descendants, where this processing will be repeated.</p><p>The main difference from Koller and Sahami's proposal is the final output of our classifier. Our aim is to get a set of relevant topics taken from the thesaurus, ordered according to their relevance, instead of a single class. We replace the greedy approach used in the original work, where only the best successor for each node was considered at each step.</p><p>In our proposal, we proceed level by level, and all of the paths starting at successors with higher evaluation values are taken into account, and they are followed until no further expansion is admissible. The final set of topics is composed of those class nodes, ranking them according to the strength of the classification steps that lead to them.</p><p>In Fig. <ref type="figure" target="#fig_0">1</ref> we show the main phases in our approach, where three main components are outlined. Document processing, which is applied both in training and classification, has the responsibility of cleaning the documents to reduce the number of features employed to represent them. In the training phase, the training set of documents are taken and the topic hierarchy is traversed top-down, performing at each node local feature selection and training the corresponding partial classifier. Finally, in the classification phase, for each input document the topic tree is traversed top-down using the trained classifiers to decide whether the corresponding topic is suitable to be taken as a final descriptor and to make routing decisions to select one or more branches to continue searching. At the end, the list of potential descriptors for that document will be ranked and returned to the user.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DOCUMENT PROCESSING</head><p>Since this is a first approach to this kind of problem, we have tried to avoid using complex linguistic resources, like taggers, lemmatizers or shallow parsing <ref type="bibr">[12]</ref>. Original documents were in HTML and PDF format and the first step was to extract plain text from them. Those text files were previously preprocessed to segment their text into regions and to identify which of those regions are relevant and could be suitable to extract potential descriptors from them.</p><p>A first processing, shown in Fig. <ref type="figure" target="#fig_9">2</ref>, is performed on the whole collection. To omit non-relevant words we use a generic stopword list for Spanish. Remaining words are normalized by means of stemming rules to overcome lexical variation problems. Once all of the the documents in the collection have been cleaned, two structures are built. A specific stopword list, containing a vocabulary of commonly used words in the considered domain, makes it possible to get rid of words frequently employed in legislative texts. A dictionary of similar words, that allows us to identify groups of related words, is also built. We have employed a method to detect similar tokens at orthographic level by means of a hierarchical clustering algorithm which uses a n-gram based distance <ref type="bibr">[7]</ref> between word characters.</p><p>Both in training and classification, the list of features to be employed is extracted from cleaned documents in the way shown in Fig. <ref type="figure" target="#fig_10">3</ref>. From the relevant regions of the input document, domain specific stopwords are deleted. Optionally, some words that appear as labels in the thesaurus topics can be recovered to be taken into account as features. These features have been demonstrated to be useful when short documents are processed. The surviving features will undergo a sort of semantical normalization using the similar word clusters built from the whole training collection. After that we obtain the list of features that will describe the input document in the training and classification phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">TRAINING AND CLASSIFICATION</head><p>In this section we show the main components that comprise our approach. Once the set of training documents have been processed they are employed to train our hierarchical categorization model. This model contains for each thesaurus node the set of features with higher discrimination power at that level and a trained partial classifier to make the routing decisions. The idea behind this strategy is that using this set of classifiers' decisions will be more precise and the overall classification quality will be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training the hierarchy</head><p>In the training phase we take the whole training collection with the set of topics associated to each document and we  traverse the topic tree, performing two tasks at every thesaurus entry. For each node, the subset of documents with at least one descriptor being a descendant of the current concept is selected. With these documents we apply very simple feature selection techniques to find a set of features with the highest discrimination power among the different branches starting at this node.</p><p>The actual feature selection method employed in our system is controlled by two thresholds, Th1 and Th2, and works as follows:</p><p>1. The set of classes for the current node, C, is built.</p><p>• One class will correspond to the topic at the current node, which will be associated with documents having that topic as a descriptor.</p><p>• For every direct descendant of the current topic another class is defined, which will be associated with documents having at least one of the descriptors belonging to the branch starting at that descendant, as shown in Fig. <ref type="figure" target="#fig_5">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">For each class Ci ∈ C:</head><p>• Every word wij in a document j associated with Ci is inspected.</p><p>• Word wij will survive feature selection if:</p><p>(a) wij is present in at least Th1 % of documents being associated with class Ci (b) wij is present in no more than Th2 % of documents not being associated with class Ci</p><p>Once the external feature selection is performed, a specialized classifier is trained to select the most promising branches at the current level. For each document a feature vector is built. Only the relevant stems selected for the current concept are employed, using their tf-idf <ref type="bibr">[10]</ref> as feature values. The class for this training vector will be the current topic, if it is actually associated with the document, or the label of one of its sons, if some topic associated with the document falls into that branch. Fig. <ref type="figure" target="#fig_5">4</ref> illustrates this idea. We have employed the WEKA machine learning engine <ref type="bibr">[13]</ref> to train the specialized classifiers for each topic in our hierarchical thesaurus. We have tested several classification algorithms to be employed inside this hierarchical categorization scheme, as it can be seen in the experimental results section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hierarchical classification</head><p>Once all of the partial classifiers have been trained, the assignment of topics to new documents means traversing the thesaurus tree, as shown in Fig. <ref type="figure" target="#fig_6">5</ref>. Starting at the thesaurus root, the feature vector for the document is built using the selected features for each node, and the most promising branches according to the partial classifier results are followed.</p><p>The original proposal by Koller and Sahami defines a single class output. They perform a greedy search selecting at each node only one class and stopping when a leaf is reached. Since we are interested in multilabel classification, we have added two new components in our classification strategy. In this way, node classifiers have two missions. The first one is to detect if a topic is suitable to be considered as a final descriptor, and the second one is to make a routing decision to determine the next steps in the search.</p><p>The routing decisions taken at each node are controlled by simple thresholds that take into account both the number of alternatives at each node and the strength of the potential classes returned by the classifier. If the class for the current topic has an evaluation value higher than this threshold it is considered to be suitable as a topic for describing this document. When a leaf is reached or no successor classes have sufficient strength, the deeping is stopped. The final list of potential topics is ranked according to the set of values obtained in the sequence of partial classifications that lead to them. Different formulae, average, maximum or product, can be used to combine the strength values obtained in the path of classifications from the root to that descriptor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTAL RESULTS</head><p>To illustrate our proposal we will review some preliminary experiments we have performed to test our method. In these experiments we have employed a portion of the legal corpus donated by Telemaco, S.L., with 2333 legislative documents with their corresponding set of descriptors assigned by human experts. These descriptors where taken from a set of 1873 thesaurus topics about the fields of agriculture, livestock and fishing. This corpus was randomly split to build a training data set with 2124 documents and a test dataset with 209 documents. To evaluate the experimental results we have employed two well known measures in the Information Retrieval field, precision and recall, using a modified version of the standard trec eval 1 tool to compute them.</p><p>In the experiments reported in this paper we have evaluated two aspects in our proposal. Firstly we have tested the influence on the final results of different approaches to generating the input text. Secondly we have evaluated the suitability of several text classification algorithms. Fig. <ref type="figure" target="#fig_7">6</ref> shows the results obtained using different text sources from the original documents to extract features from them. We have taken words only from the document title (experiment [t]), words from the title and the relevant regions (experiment [t+rr]) and we included selected words taken from non-relevant regions, giving them different weights (experiments [t+rr+sw] and [t+rr+2sw], where selected words count twice). As can be seen in Fig. <ref type="figure" target="#fig_7">6</ref> the best results were obtained using words from the title, words from relevant regions and selected words from non-relevant ones.</p><p>In Fig. <ref type="figure" target="#fig_8">7</ref> we show the average precision and recall values obtained in a set of experiments to test the use of different machine learning algorithms to perform the partial classifications across the thesaurus tree. We have tested a Naive-Bayes implementation <ref type="bibr">[5]</ref>, a k-Nearest Neighbors(k-NN) <ref type="bibr">[1]</ref> learning method, with different values for k, and a Support Vector Machine model using Sequential Minimal Optimization(SMO) <ref type="bibr">[9]</ref>, all of them are included in the WEKA machine learning engine <ref type="bibr">[13]</ref>. As can be seen, the best results, both in precision and recall, where obtained with the k-NN method, with a better balance between absolute recall and precision when seven neighbors were employed. In a deeper review of the descriptors obtained in that run, our approach gave better results when dealing with the most general topics, but it was unable to get a human level performace with 1 http://trec.nist.gov/trec eval the most specific descriptors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS AND FUTURE WORK</head><p>In this article we have proposed the use of a hierarchical multilabel classification approach which allows us to face the thesaurus topic assignment problem. We have followed a very flexible method, easy to be adapted to deal with different practical domains and allowing the use of several classification and text processing algorithms. The developed system offers quite good performance on average documents, even being able to avoid some human inconsistencies. When complex or very specific documents are processed, our tools are unable to work at human expert level, opening a field for further improvements.</p><p>With respect to future work, several aspects should be studied in our classification approach. Firstly, we intend to extend our experiments to other domains and languages, in order to test its generality. Secondly, we aim to improve the system by integrating more powerful natural language processing tools.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Text search is the first step in information access or retrieval, without which effective information retrieval (IR) is not possible. However, for many languages, it becomes meaningful only when it is fuzzy, not literal. In this paper we present a more accurate method for this purpose. This method uses deeper information about the writing system used by a language. In this paper we do not consider other aspects of IR such as estimating the relevance of a document because the biggest problems for the languages considered in this paper are at the level of text search and they have not been adequately addressed so far.</p><p>Fuzzy text search is required mainly because of the widespread variation and rich morphology in many very highly used languages of the world, and sometime also because of the nature of problem requires approximate matching of strings. This variation can be spelling variation, dialectal variation or regional variation. The variants need not be 'errors': some or all of them may be acceptable (Section-4 and Figure <ref type="figure" target="#fig_25">-1</ref>). It is useful even for languages like English, but mostly for applications like spell checking or Google Suggest<ref type="foot" target="#foot_13">1</ref> etc. For Indian and many other languages (Section-3) on the other hand, it is unavoidable for almost any kind of information access. Masuyama and Nakagawa <ref type="bibr">[19,</ref><ref type="bibr">18]</ref> and Ohtake et al. <ref type="bibr">[21]</ref> have previously discussed the importance of accounting for variants for the purpose of information access or retrieval.</p><p>Our focus in this paper is on the languages using scripts or writing systems belonging to the Abugida category (Section-3). We present a method for fuzzy text search which works much better than Scaled Edit Distance or SED <ref type="bibr">[8]</ref> for these languages. Pingali et al. <ref type="bibr">[23]</ref>, who attempted to build a crawler called WebKhoj for the Indian languages, had also faced problems in searching text due to variation.</p><p>We propose that the idea of fuzzy text search is based on the notion of surface similarity, which (at least for Abugida scripts) can be roughly defined as combined orthographic and phonetic similarity. A method based on a measure of surface similarity can give better results. The Abugida scripts have characteristics (like highly phonetic nature) which can be used for designing a very effective measure of surface similarity. Our method is based on this measure.</p><p>The paper is organized as follows. In Section-2, we present a brief literary survey of some related work. Section-3 is an introduction to the Abugida and Brahmi scripts from the point of view of our work. In the same section, we also mention the Indian languages, as these are the languages on which we have evaluated our method. Section-4 is about variation which is very common in Indian languages and because of which fuzzy text search is important. Section-5 introduces the notion of surface similarity which is different from string similarity and is the basis of fuzzy text search. In this section, we also describe the Computational Phonetic Model of Scripts (CPMS) proposed by Singh <ref type="bibr">[25]</ref>, on which our measure of surface similarity and our method of fuzzy text search is based (Section-6). In Section-7, we describe the experimental setup and the evaluation of our approach. Finally, we conclude in Section-8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Emeneau <ref type="bibr">[9]</ref>, in his classic paper 'India as a Linguistic Area' showed that there are a lot of similarities among Indian languages, even though they belong to different families. One of these similarities is that many of these languages use scripts derived from Brahmi.</p><p>There has been a lot of linguistic work on writing systems <ref type="bibr">[4,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b227">33]</ref> from the linguistic point of view. An example of work relevant to computation is a computational theory of writing systems by Sproat <ref type="bibr" target="#b225">[31]</ref>. Sproat also studied the Brahmi scripts <ref type="bibr">[29]</ref> and presented a formal computational analysis of Brahmi scripts <ref type="bibr" target="#b224">[30]</ref>.</p><p>The development of a standard for Brahmi origin scripts <ref type="bibr">[1,</ref><ref type="bibr">3]</ref>, called Indian Standard Code for Information Interchange (ISCII) can also be mentioned here. This super-encoding <ref type="bibr">[16]</ref> takes into account some of the similarities among the alphabets of Brahmi origin scripts. This is why ISCII has been used as the basis for the 'model of alphabet', which is a part of the Computational Phonetic Model of Scripts <ref type="bibr">[25]</ref>. Om transliteration scheme <ref type="bibr">[11]</ref> also provides a script representation which is common for all Indian languages. The display and input is in human readable Roman script. Transliteration is partly phonetic.</p><p>There has also been work on phonetic modeling of graphemes. For example, Rey et al. <ref type="bibr">[24]</ref> argued that graphemes are perceptual reading units and can thus be considered the minimal 'functional bridges' in the mapping between orthography and phonology. Black et al. <ref type="bibr">[2]</ref> discuss some issues in building general letter to sound rules within the context of speech processing. Galescu and Allen <ref type="bibr">[10]</ref> present a statistical model for language independent bidirectional conversion between spelling and pronunciation, based on joint grapheme/phoneme units extracted from automatically aligned data. Daelemans and Bosch <ref type="bibr">[5]</ref> describe another method for the same. Killer <ref type="bibr">[14]</ref> has tried building a grapheme based speech recognition as a way to build large vocabulary speech recognition systems. Kopytonenko et al. <ref type="bibr">[15]</ref> also focussed on computational models that perform graphemeto-phoneme conversion.</p><p>Two of the best known methods for approximate string matching are the SOUNDEX algorithm <ref type="bibr">[6]</ref> and the double metaphone algorithm <ref type="bibr">[22]</ref>. The latter uses some information about the phonetic values of letters.</p><p>Loan words and spelling variations in a corpus or on the Web create a problem for information retrieval. A previous work on solving this problem was by Li et al. <ref type="bibr">[17]</ref>. It involved spelling correction of the query based on distributional similarity. A work on extraction of spelling variants for loan words in Japanese <ref type="bibr">[19]</ref> used a large corpus and contextual similarities. Since Indian languages are lacking in large resources these methods may not be very applicable.</p><p>Singh <ref type="bibr">[25]</ref> had proposed a computational phonetic model of Brahmi scripts based on orthographic and phonetic features. These features were defined based on the characteristics of the scripts. The similarity between two letters was calculated using an SDF and the algorithm used for 'aligning' two strings was dynamic time warping (DTW). This model tries to relate letters with phonetic and orthographic features in a way that allows some fuzziness by using linguistic knowledge about the writing systems. It has been used for shallow morphological analysis <ref type="bibr">[26]</ref>, study of cognates among Indian languages <ref type="bibr">[27]</ref> and comparative study of languages using text corpora <ref type="bibr">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SCRIPTS AND LANGUAGES</head><p>Abugida is a term for a type of scripts such as those used by most of the major languages of the Indian subcontinent. In fact, about half of the writing systems used in the world belong to this category 2 . Such scripts are also sometimes called alphasyllabary or syllabics because one the basic unit in these scripts more or less corresponds to a syllable, even though these scripts also have alphabets. A consonant in these scripts is implicitly associated with a vowel, which means that absence (rather than presence) of a vowel after a consonant has to be indicated explicitly. Another major characteristic of these scripts is that the letters have a very close and almost unambiguous correspondence with phonetic features. Some other important (graphemic) char-acteristics are about the way letters are written together, but since these characteristics have more to do with shapes, we will not discuss them. We will only consider characteristics relevant for electronic text, i.e. encoded text where letters have integer codes. The shapes assigned to them are relevant only for rendering, not for text processing.</p><p>The most important family of Abugida scripts is the Indic or Brahmi family <ref type="bibr">[13]</ref>. The most well known Brahmi script is perhaps Devanagari, which is used for Hindi, Sanskrit, Marathi, Nepali and many other languages. These have originated from the ancient Brahmi script which was used for Sanskrit, Pali, Prakrit etc. The important point is that they have retained many characteristics of Brahmi which are crucial for the method we are presenting in this paper. Some of these characteristics can be summarized as:</p><p>• Close correspondence among letters and phonetic features (Figure -2)</p><p>• The main unit of the script corresponds closely to a syllable</p><p>• The letters are organized very systematically in the alphabet, in such a way that letter positions indicate phonetic and orthographic features</p><p>• The arrangement of letters in the alphabet is common among all the Brahmi origin scripts, even if letter shapes seem to be completely different</p><p>• It is possible to use a common super-encoding like ISCII <ref type="bibr">[1]</ref> for all these scripts</p><p>The Indian or South Asian subcontinent is home to hundreds of languages belonging to different linguistic families. However, most of the major Indian languages fall within two families: Indo-Aryan and Dravidian <ref type="bibr">[12]</ref>. And most of these languages use Brahmi origin scripts. In fact, many languages of other areas also used these scripts, e.g. Thai, Laotian, Cambodian (Khmer) etc. The Indian or South Asian languages alone account for more than one billion people. In terms of number of speakers, at least three or four Indian languages are usually placed among the top ten most heavily used languages of the world <ref type="bibr" target="#b226">[32]</ref>. Some of these languages are: Hindi/Urdu, Bengali, Telugu, Punjabi, Tamil, Malayalam, Kannada, Marathi, Gujarati, Oriya, Assamese. Our method works for all these languages. Two characteristics of Indian languages are very relevant for the present work. The first is their rich morphology, which makes processing of verbs (and sometimes even nouns) much more difficult, even for relatively easy problems like stemming. The second is lack of standardization, due to which variation is very common in text written in these languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">VARIATION AND FUZZY SEARCH</head><p>The problem of spelling variants in Indian Languages is somewhat similar to that in East Asian Languages. For example, in Japanese, the Katakana variants cause a lot of problems in information retrieval, text summarization, machine translation and question-answering.</p><p>To give an indication of the extent of the problem, we conducted a small experiment. We took one highly used English word ('information') borrowed into Hindi and one very familiar (to Indians) proper noun ('Tamilnadu') and searched them among the Hindi (UTF-8) documents on Google. Then we tried to search all the possible variations of these words and noted down the number of results returned by the search engine. These are shown in Figure <ref type="figure" target="#fig_25">-1</ref>. Note the large number of variations in spite of the fact that the amount of Hindi text in UTF-8 on the Web is nowhere near the text in English, which means that the 'Web as corpus' in Hindi (in UTF-8 encoding) is very small in size.</p><p>Fuzzy text search (as opposed to literal text search) is needed to take care of the variation mentioned in the previous section. The computational method used for this purpose should be able to take into account the usual phenomenon in string variation like deletions, additions, substitutions, etc. But more importantly, the method should be able to give scores for these phenomenon such that all the available information is used. For example, if we know that /t/ is more similar to /d/ than to /f/, then the similarity score for matching two strings should reflect this fact. Abugida scripts allow this (and many other such things) to be done easily because of their characteristics described earlier. And our method does this more thoroughly than other methods.</p><p>The possible variants of a word are usually not arbitrary. They follow some phonetic or orthographic principles (e.g., /t/ is more likely to become /d/ then /f/) and these principles are closely tied to the nature of the scripts, at least in the case of Abugida scripts. This is why we can use a much better way of finding out how similar two strings are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SURFACE SIMILARITY AND CPMS</head><p>Surface similarity is a kind of string similarity which is deeper (despite the name) than literal string similarity. More specifically, it includes some linguistic knowledge about the units of a script. It is different from similarities based on edit distance. We are calling it surface similarity even though it is a deeper similarity because it doesn't include semantic similarity. We are still talking about similarity of the surface forms, not their meanings.</p><p>The notion of surface similarity can be applicable wherever string similarity is applicable, but it is an especially more suitable idea for natural language processing applications. If we can find a good method to calculate such similarity, we can have much better fuzzy text search. The method used by us is based on the Computational Phonetic Model of Scripts <ref type="bibr">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Computational Phonetic Model of Scripts</head><p>Given the similarities among the alphabets of Brahmi origin scripts and the fact that these scripts have phonetic characteristics, it is possible to build a phonetic model for these scripts. We have used a modified version of the Computational Phonetic Model of Scripts (CPMS) proposed by Singh <ref type="bibr">[25]</ref>. The phonetic model tries to represent the sounds of Indian languages and their relations to the letters. It includes phonetic or articulatory features, some orthographic features, numerical values of these features, and a distance function to calculate how phonetically similar two letters are. The scripts covered by this model are: Devanagari (Hindi, Marathi, Nepali), Bengali (Bengali and Assamese), Gurmukhi (Punjabi), Gujarati, Oriya, Tamil, Telugu, Kannada, and Malayalam.</p><p>The CPMS itself consists of the model of alphabet, the model of phonology and the SDF. The core of the model of phonology is the definition of phonetic features (table-1) and the numerical values assigned to them. The CPMS assigns a mostly phonetic representation for each ISCII letter code in terms of the phonetic and orthographic features. For example, vowel o and consonant n will be represented as:</p><p>176 → [type=v, voiced=t, length=s, vowel2=m, vowel1=m, height=b] 198 → [type=c, voiced=t, place=v, manner=n</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Model of Alphabet</head><p>The model of alphabet is meant to cover all the alphabets of the related scripts, but it may be more than a superset of these alphabets. By 'model of alphabet' we essentially mean a meta alphabet, i.e., number of letters and their arrangement, including the basis of this arrangement. It is a conceptual view of the alphabet and also includes a representation based on this view. Of course, this model will be applicable for only those scripts which have an alphabet.</p><p>Since Brahmi origin scripts have a very well organized alphabet with arrangement of letters based on phonetic features, and also because these alphabets are very similar, it is possible and very useful to have a unified model of alphabet for these scripts. Such a model can simplify computational processing in a multilingual environment, e.g. in our case it allows us to use the same setup for all the languages which Brahmi origin scripts. This is evident from the fact that if the alphabet is written in the usual conventional way on paper (Figure-2), we can draw rectangles around consonants such that each rectangle represents a particular articulatory feature. The CPMS makes explicit, in computational terms, the phonetic (as well as orthographic) characteristics of the letters in this unified alphabet by mapping the letters to a set of feature and their (numerical) values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Stepped Distance Function (SDF)</head><p>To calculate the orthographic and phonetic similarity between two letters, we use a stepped distance function (SDF). Since phonetic features differentiate between two sounds (or the letters representing them) in a cascaded or hierarchical way, the SDF calculates similarity at several levels. For example, the first level compares the type (vowel, consonant, punctuation etc.). There is a branching at the second level and, depending on whether the letters being checked CPMS stands for our method using a measure of surface similarity based on the Computational Phonetic Model of Scripts. These results are for those thresholds which gave the best performance for a particular Language-Method pair. Note that the thresholds of SED and CPMS are not directly comparable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Method of Fuzzy Text Search</head><p>Once a surface similarity measure is defined, fuzzy text search is just a matter of setting up a threshold and finding the matches with similarity scores Ss lower than (or higher than, depending upon the way scores are calculated) the threshold t. Most of the detail has already been presented in the preceding sections. The only thing that remains to be described is the modified DTW algorithm used by us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Modified DTW Algorithm</head><p>The DTW algorithm <ref type="bibr">[20]</ref> is heavily used in speech recognition and for problems like gene sequencing. Our version of this algorithm can be roughly described as follows:</p><p>Let the query string be Sq Let the retrieval string be Sr Here, K(i, j) is a heuristic function which can take into account language specific issues like the inflectional nature of a language, e.g. giving the last two characters (which are most likely to represent an inflection) a lesser weight for Hindi. SDF [Sq[i], Sr <ref type="bibr">[j]</ref>] is the cost between two letters Sq[i] and Sr[j] of the two strings which are being compared at a particular node in the trellis. This is the basic formulation of our modified DTW algorithm. However, several optimization techniques were used to increase the speed of the algorithm, including trie based search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">EVALUATION</head><p>Since there was no standard data set over which we could perform our experiments, we randomly selected words from a corpus consisting of documents obtained by crawling the Web. We randomly selected 400 words each from Hindi and Telugu. For each word we collected all the possible spelling variants. Some words did not have spelling variants, so we dropped them from our data set. In case of uncertainties about spelling variations, we verified them by checking their document level contexts. We were left with 318 Hindi words with 1020 variant pairs. For Telugu, 202 words were left with 674 variants. We tested our algorithm on this data set.</p><p>Since we could not find any algorithm based on phonetic matching for Indian languages, we used a scaled version of the Levenshtein distance<ref type="foot" target="#foot_15">3</ref>  <ref type="bibr">[8]</ref>. Such a version has been used in various applications including cognate alignment and dialectology. Edit distances in general have been used in many other applications including spell checking and identifying spelling variants.</p><p>Scaled Edit Distance (SED) is an edit distance which is scaled with the sum of the lengths of words under consideration. The advantage of scaling is that it alleviates the disparity between long words in comparison to short words, which is a problem in simple edit distances.</p><p>If ED is an edit distance between two words w1 and w2 (with lengths |w1| and |w1|, respectively), then SED can be defined as: SED(w1, w2) = 2 * ED(w1, w2)</p><formula xml:id="formula_20">|w1| + |w2|<label>(3)</label></formula><p>To evaluate our algorithm we performed fuzzy search of the words in our test set word list (318 Hindi, 202 Telugu) over the words from entire web corpus that we had. We compared the list returned by our fuzzy text search to our reference variant pair list (1020 Hindi, 674 Telugu). This allowed us to calculate precision, recall and F-measure. We tried various thresholds to select the one which gives the maximum F-measure. We did a similar experiment on SED.</p><p>The results of the evaluation are given in table-2. The performance of both the methods for Hindi and Telugu has been plotted against the threshold in Figures-4 to 7. As can be seen from the results, our method outperforms the method based on SED by up to or even more than 30%. The results are somewhat lower for Telugu. This is explained by the fact that Telugu is a more agglutinative language than Hindi and has a richer morphology.</p><p>The plots against thresholds indicate that for both the methods there is a lower value of threshold up to which performance (F-measure) increases. Beyond this value, there is not much increase in performance, as the F-measure more or less stabilizes.</p><p>Another objective way to compare the performance of the two methods would be to look at the F-measure at the point (on the plots shown in Figures <ref type="figure" target="#fig_5">4</ref><ref type="figure" target="#fig_6">5</ref><ref type="figure" target="#fig_7">6</ref><ref type="figure" target="#fig_8">7</ref>) at which precision and recall lines cross (say, P = R point). As is clear from the   graphs, our method performs significantly better than SED for both Hindi and Telugu.</p><note type="other">Hindi Test Set</note><p>An interesting observation is that precision is more stable after the P = R point in the case of SED, but in the case of CPMS it is more stable before the P = R point. However, recall has similar behavior for both the approaches in these terms. This might have important implications for practical applications where a trade-off is to be achieved between precision and recall and we might not know where exactly the P = R point lies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>We argued in this paper that fuzzy text search is an important, unavoidable problem for languages which use Abugida scripts. We presented a more accurate method of fuzzy text search for Indian languages. We also introduced the notion of surface similarity. In our opinion, fuzzy text search is based on a measure of surface similarity. For Abugida scripts (which include Brahmi origin scripts), surface similarity can be defined roughly as combined orthographic and phonetic similarity. Our method for calculating surface similarity uses a Computational Phonetic Model of Scripts (CPMS) and thereby takes into account the characteristics of Brahmi origin scripts. Moreover, the same setup can be used for all the languages which use Brahmi origin scripts. We were able to improve results (in terms of F-measure) for some Indian   languages by up to 30% over scaled edit distance. Based on the experiments for various thresholds, some observations were reported with regard to the trade-off between precision and recall. An interesting question is whether the method described in this paper can be applied to or adapted for other kinds of scripts. This should be possible for scripts like Hangul because Hangul too is a 'phonemic alphabet organized into syllabic blocks'<ref type="foot" target="#foot_16">4</ref> . For Latin like scripts, it might be a bit harder, and even more hard for logographic or ideographic scripts. This can be a good area for further work.</p><note type="other">Telugu Test Set</note></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 .</head><label>1</label><figDesc>Find minimal c such that there exists a tuple l with C( l ) = c and: B(c, m) • P l (w1 . . . wm) ≥ B(C( l ), m) • P l (w1 . . . wm) for all l with C( l ) &gt; c 2. Output all tuples l with C( l ) = c and: B(c, m) • P l (w1 . . . wm) ≥ B(C( l ), m) • P l (w1 . . . wm) for all l with C( l ) &gt; c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>WebCLEF 2006 (Manual) Topics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: MRR per language with different stemming combinations for the WebCLEF 2005 and 2006 topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Architecture of the Greeklish-to-Greek translator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Why Greeklish queries? Figure 3. Goals of Greeklish queries.Figure 4. What if Greeklish fails?</figDesc><graphic coords="35,229.44,140.46,154.56,143.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 2. Why Greeklish queries? Figure 3. Goals of Greeklish queries.Figure 4. What if Greeklish fails?</figDesc><graphic coords="35,53.58,140.46,170.10,144.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Average relevance of the top 10 results for our resource queries with respect to each of the query alphabets considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Average relevance of the top 10 results for our informational queries with respect to each of the query alphabets considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Average relevance of the top 10 results for our navigational queries with respect to each of the query alphabets considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Words with different word lengths that belong to same meaning class</figDesc><graphic coords="41,335.22,639.00,205.38,51.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Pure bigram (left) and revised bigram (right)</figDesc><graphic coords="42,54.00,72.00,240.06,54.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. : a) -Average Precision. b) -Total index terms retrieved. c) -Relevant index terms retrieved. d) -Irrelevant index terms retrieved.</figDesc><graphic coords="44,317.94,72.00,240.18,121.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 6</head><label>6</label><figDesc>Figure 6 Average Recall for Revised bigram and Pure trigram approaches (sorted by recall value)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Screen capture of EusBila with results for paper. As can be seen, the results are lemma-based and in Basque alone</figDesc><graphic coords="53,52.50,274.86,488.52,437.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Architecture.</figDesc><graphic coords="58,53.80,52.91,502.12,335.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example of the word "bank" -SynSet translations -in the LexiRes Editor.</figDesc><graphic coords="59,78.91,64.24,451.91,282.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of the word "bank" -create new word sense -in the LexiRes Editor.</figDesc><graphic coords="59,78.91,399.98,451.91,282.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of the word "bank" -manual merging functions -in the LexiRes Editor.</figDesc><graphic coords="60,78.91,52.91,451.91,282.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Classification framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Collection preprocessing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Document processing and representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of training at two nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Hierarchical classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Evaluation of input text extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Evaluation of classification algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: First Column: Variants of a commonly used borrowed word 'information' found by searching on Google. Second Column: Variants of a very familiar proper noun 'Tamilnadu' (the name of one of India's states) found by searching on Google. Third Column: Variants of a very familiar proper noun 'Narayana' (a person name as well as the name of a god) found by searching on Google. The numbers are the results returned by the search engine for a particular variant.</figDesc><graphic coords="72,66.52,54.00,213.38,343.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Phonetically arranged basic consonants in the unified Brahmi alphabet. The vowels also have a systematic arrangement.</figDesc><graphic coords="74,188.59,53.93,232.46,330.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>The phonetic nature of Brahmi based alphabets can be seen in the following properties (see Figure-2 too): • Letters neatly arranged on phonetic basis • Vowels and consonants separated • Consonants themselves separated on the basis of phonetic features</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>m = stringLength(Sq) n = stringLength(Sr) initMatrix DTW[m,n] for i = 1 to n for j = 1 to m cost = SDF[Sq[i], Sr[j]] * K(i,j) DTW[i,j] = min(DTW[i-1, j] + cost,// insertion DTW[i, j-1] + cost, // deletion DTW[i-1, j-1] + cost) // substitution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of SED for Hindi plotted against threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance of CPMS for Hindi plotted against threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance of SED for Telugu plotted against threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performance of CPMS for Telugu plotted against threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="33,57.90,145.32,479.46,431.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Subject categories searched and number of queries.</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Subject Categories</cell><cell cols="2">Organizations in:</cell></row><row><cell>(in English)</cell><cell>(in Greek)</cell><cell>Greek</cell><cell>English</cell></row><row><cell>Government Departments</cell><cell>Υπουργεία</cell><cell>18</cell><cell>14</cell></row><row><cell>Universities</cell><cell>Πανεπιστήμια</cell><cell>21</cell><cell>20</cell></row><row><cell>Colleges</cell><cell>ΤΕΙ</cell><cell>14</cell><cell>8</cell></row><row><cell>Travel Agencies</cell><cell>Ταξιδιωτικά Γραφεία</cell><cell>39</cell><cell>4</cell></row><row><cell>Museum</cell><cell>Μουσεία</cell><cell>19</cell><cell>0</cell></row><row><cell>Transportation &amp; Communication Services</cell><cell>Μέσα Μεταφοράς, Επικοινωνίες</cell><cell>12</cell><cell>7</cell></row><row><cell>Banks</cell><cell>Τράπεζες</cell><cell>28</cell><cell>13</cell></row><row><cell>Newspapers</cell><cell>Εφημερίδες</cell><cell>17</cell><cell>16</cell></row><row><cell>Television Stations</cell><cell>Τηλεόραση</cell><cell>12</cell><cell>3</cell></row><row><cell>Radio Stations</cell><cell>Ραδιόφωνο</cell><cell>37</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 : Rank distribution of all search results by search engine.</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rank</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>%</cell></row><row><cell></cell><cell></cell><cell>Search</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Total</cell><cell>success</cell></row><row><cell></cell><cell></cell><cell cols="2">Engines 1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell cols="2">5 6 7 8 9 1 0 Missed</cell><cell>Found</cell><cell>rate</cell></row><row><cell>G reek</cell><cell>E λληνικές</cell><cell cols="3">anokato anazitisis 17 53 16 7 phantis 23 5 trinity 142 10</cell><cell>5 4 2 5</cell><cell>2 0 1 3</cell><cell>2 2 2 0 1 0 2 1 1 2 0 1 1 0 0 0 0 1 0 1 1 0 0 0</cell><cell>226 274 276 147</cell><cell>83 35 33 162 52.43% 26.86% 11.33% 10.68%</cell></row><row><cell></cell><cell></cell><cell>visto</cell><cell cols="2">78 20</cell><cell>6</cell><cell>4</cell><cell>4 2 1 1 1 0</cell><cell>192</cell><cell>117 37.86%</cell></row><row><cell></cell><cell></cell><cell>a9</cell><cell cols="4">106 17 11 3</cell><cell>4 5 3 2 1 0</cell><cell>157</cell><cell>152 49.19%</cell></row><row><cell>G lobal</cell><cell>Δ ιεθνείς</cell><cell cols="5">altavista 166 30 10 2 google 199 11 8 1 msn 101 18 12 6</cell><cell>2 2 4 2 0 3 2 3 1 1 1 1 5 3 3 1 1 0</cell><cell>88 81 159</cell><cell>221 71.52% 228 73.79% 150 48.54%</cell></row><row><cell></cell><cell></cell><cell>yahoo</cell><cell cols="4">133 30 13 7</cell><cell>3 3 3 1 2 0</cell><cell>114</cell><cell>195 63.11%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 : Rank distribution of results for Greek queries.</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>%</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1 2 3 4 5 6 7 8 9 10</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Anokato</cell><cell>32 11 3 1 2 2 1 0 1 0</cell><cell>53</cell><cell>24,42%</cell></row><row><cell>Greek</cell><cell>Ελληνικές</cell><cell cols="2">Anazitisis 12 5 3 0 2 1 1 2 0 1 Phantis 18 1 1 1 1 0 0 0 0 1 Trinity 94 6 3 2 0 1 1 0 0 0 Visto 63 16 4 3 4 0 1 1 1 0</cell><cell>27 23 107 93</cell><cell>12,44% 10.59 49,3% 42.86%</cell></row><row><cell></cell><cell></cell><cell>a9</cell><cell>82 7 9 3 3 1 2 1 1 0</cell><cell>109</cell><cell>50.23%</cell></row><row><cell></cell><cell></cell><cell cols="2">AltaVista 118 23 8 1 2 0 3 2 0 1</cell><cell>158</cell><cell>72.81%</cell></row><row><cell>Global</cell><cell>Διεθνείς</cell><cell>Google msn Yahoo</cell><cell>131 10 5 1 2 2 1 1 0 1 79 9 8 6 3 2 1 1 1 0 104 12 8 5 3 1 2 0 2 0</cell><cell>154 110 137</cell><cell>70.96% 50.69% 63,13%</cell></row><row><cell></cell><cell></cell><cell cols="2">total queries 217</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>success Total Found Search En ines Rank g</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 : Rank distribution of results for English queries.</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Search</cell><cell>Rank</cell><cell>Total</cell><cell>%</cell></row><row><cell></cell><cell></cell><cell>Engines</cell><cell>1 2 3 4 6 7 8 9 10</cell><cell>Found</cell><cell>success</cell></row><row><cell></cell><cell></cell><cell>Anokato</cell><cell>21 5 2 1 0 1 0 0 0</cell><cell>30</cell><cell>32.61%</cell></row><row><cell>Greek</cell><cell>Ελληνικές</cell><cell>Anazitisis Phantis Trinity Visto</cell><cell>5 2 1 0 0 0 0 0 0 5 4 1 0 0 0 0 0 0 48 4 2 1 0 0 0 0 0 15 4 2 1 2 0 0 0 0</cell><cell>8 10 55 24</cell><cell>8.69% 10,87% 59,78% 26,09%</cell></row><row><cell></cell><cell></cell><cell>a9</cell><cell>24 10 2 0 4 1 1 0 0</cell><cell>43</cell><cell>46.73%</cell></row><row><cell></cell><cell></cell><cell>Altavista</cell><cell>48 7 2 1 2 1 0 0 2</cell><cell>63</cell><cell>68.48%</cell></row><row><cell>Global</cell><cell>Διεθνείς</cell><cell>Google msn Yahoo</cell><cell>68 1 3 0 1 0 0 1 0 22 9 4 0 1 2 0 0 0 29 18 5 2 2 1 1 0 0</cell><cell>74 40 58</cell><cell>80.43% 43,48% 63,04%</cell></row><row><cell></cell><cell></cell><cell cols="2">total queries 92</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>2 http://odur.let.rug.nl/ ∼ vannoord/TextCat/ competitors.html accessed the 25th of May 2005. 3 http://www.xrce.xerox.com/competencies/ content-analysis/tools/guesser accessed 20 Jan 2007.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 :</head><label>1</label><figDesc>Comparative figures for prefix vs. suffix detection for three sample languages.</figDesc><table><row><cell cols="2">Swedish</cell><cell cols="2">English</cell><cell>Swahili</cell></row><row><cell>för-</cell><cell cols="2">0.097 -ed</cell><cell>0.132 -a</cell><cell>0.100</cell></row><row><cell>-en</cell><cell cols="2">0.086 -eth</cell><cell cols="2">0.109 wa-</cell><cell>0.095</cell></row><row><cell>-na</cell><cell cols="2">0.036 -iah</cell><cell cols="2">0.099 ali-</cell><cell>0.065</cell></row><row><cell cols="2">-ade 0.035 -ly</cell><cell></cell><cell cols="2">0.090 nita-0.059</cell></row><row><cell>-a</cell><cell cols="4">0.034 -ings 0.068 aka-0.049</cell></row><row><cell>-ar</cell><cell cols="2">0.033 -ing</cell><cell cols="2">0.062 ni-</cell><cell>0.046</cell></row><row><cell>-er</cell><cell cols="2">0.033 -ity</cell><cell cols="2">0.059 ku-</cell><cell>0.044</cell></row><row><cell>-as</cell><cell cols="4">0.032 -edst 0.058 ata-</cell><cell>0.042</cell></row><row><cell>-s</cell><cell cols="2">0.031 -ites</cell><cell cols="2">0.046 ha-</cell><cell>0.032</cell></row><row><cell>-de</cell><cell>0.031 -s'</cell><cell></cell><cell>0.036 a-</cell><cell>0.031</cell></row><row><cell>. . .</cell><cell>. . . . . .</cell><cell></cell><cell>. . . . . .</cell><cell>. . .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Some indications as to the widely differing identification cues for three languages; the polysynthetic Greenlandic versus the almost isolating Haitian creole.</figDesc><table><row><cell>Language</cell><cell>|T |</cell><cell>|W |</cell><cell>α</cell><cell cols="2">argmaxw(F D(w))</cell></row><row><cell>Greenlandic</cell><cell>382188</cell><cell>107918</cell><cell>0.706</cell><cell>taava (then)</cell><cell>0.00857</cell></row><row><cell>Swedish</cell><cell>758773</cell><cell>26825</cell><cell>0.407</cell><cell>och (and)</cell><cell>0.05566</cell></row><row><cell>Haitian creole</cell><cell>904915</cell><cell>7796</cell><cell>0.335</cell><cell>yo (PL/they)</cell><cell>0.05531</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>Example 1: P l (w) for a set of languages and some interesting words, followed by a selection of the more interesting tuple-probabilities.</figDesc><table><row><cell></cell><cell>'the'</cell><cell>'kings'</cell><cell>'hon' 'walikusoma'</cell></row><row><cell cols="4">English 0.051522 0.000286 0.000003</cell><cell>0.000004</cell></row><row><cell cols="4">Swedish 0.000002 0.000040 0.000916</cell><cell>0.000043</cell></row><row><cell>Swahili</cell><cell cols="3">0.000218 0.000000 0.000000</cell><cell>0.000317</cell></row><row><cell></cell><cell cols="3">All one-language tuples</cell></row><row><cell></cell><cell cols="2">Peng,eng,eng,eng</cell><cell>1.350e-016</cell></row><row><cell></cell><cell cols="3">Pswe,swe,swe,swe 2.468e-018</cell></row><row><cell></cell><cell cols="3">Pswa,swa,swa,swa 1.878e-025</cell></row><row><cell></cell><cell cols="3">Some top one-switch tuples</cell></row><row><cell></cell><cell cols="2">Peng,swe,swe,swe</cell><cell>2.034e-014</cell></row><row><cell></cell><cell cols="2">Peng,eng,swe,swe</cell><cell>1.465e-013</cell></row><row><cell></cell><cell cols="2">Peng,eng,eng,swa</cell><cell>3.008e-015</cell></row><row><cell></cell><cell cols="3">The top two-switch tuple</cell></row><row><cell></cell><cell cols="2">Peng,eng,swe,swa</cell><cell>2.701e-013</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Example 2: P l (w) for a set of languages and some words that are very easy to classify, followed by examples to indicate that the dominance of a certain zero-switch tuple over some others.</figDesc><table><row><cell></cell><cell>'the'</cell><cell>'kings'</cell><cell>'are'</cell><cell>'there'</cell></row><row><cell cols="5">English 0.051522 0.000286 0.002812 0.002065</cell></row><row><cell cols="5">Swedish 0.000002 0.000040 0.000006 0.000035</cell></row><row><cell>Swahili</cell><cell cols="4">0.000218 0.000000 0.000004 0.000006</cell></row><row><cell cols="2">Peng,eng,eng,eng</cell><cell cols="3">8.5467629403443202e-011</cell></row><row><cell cols="5">Pswe,swe,swe,swe 1.2961894211016589e-020</cell></row><row><cell cols="5">Pswa,swa,swa,swa 2.5363460513704776e-023</cell></row><row><cell>. . .</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">perfectly well-formed word 'walikusoma' does not occur in</cell></row><row><cell cols="5">the training corpus (it would mean 'they read you').</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Example 3: P l (w) for a set of languages and two words, followed by a selection of the more interesting tuple-probabilities. be only the tuples spa, spa and f re, f re, because tuples like swe, swa and spa, f re lose out because of the bias, favouring few switches.</figDesc><table><row><cell></cell><cell>'de'</cell><cell>'la'</cell></row><row><cell>French</cell><cell cols="2">0.029172 0.016325</cell></row><row><cell cols="3">English 0.000000 0.000000</cell></row><row><cell cols="3">Swedish 0.008400 0.000001</cell></row><row><cell>Swahili</cell><cell cols="2">0.000000 0.001517</cell></row><row><cell cols="3">Spanish 0.033905 0.014280</cell></row><row><cell cols="2">P f re,f re 0.0003174886</cell></row><row><cell cols="2">Pspa,spa 0.0003227756</cell></row><row><cell cols="2">P spa,f re 0.0001844997</cell></row><row><cell>. . .</cell><cell>. . .</cell></row></table><note><p>will</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Accuracies for the one-word and verse tests plus average verse length in characters (V ).</figDesc><table><row><cell>Language</cell><cell cols="2">1-word Verse</cell><cell>V</cell></row><row><cell>Haitian Creole</cell><cell>0.839</cell><cell cols="2">1.00 101.79</cell></row><row><cell>Zarma</cell><cell>0.781</cell><cell>1.00</cell><cell>99.45</cell></row><row><cell>Kekchi</cell><cell>0.720</cell><cell cols="2">1.00 148.78</cell></row><row><cell>English</cell><cell>0.678</cell><cell cols="2">1.00 104.19</cell></row><row><cell>Maori</cell><cell>0.665</cell><cell cols="2">1.00 107.73</cell></row><row><cell>Hindi</cell><cell>0.607</cell><cell cols="2">1.00 119.50</cell></row><row><cell>Hausa</cell><cell>0.605</cell><cell>1.00</cell><cell>94.10</cell></row><row><cell>Afrikaans</cell><cell>0.594</cell><cell cols="2">1.00 103.34</cell></row><row><cell>Danish</cell><cell>0.580</cell><cell>1.00</cell><cell>89.30</cell></row><row><cell>Cebuano</cell><cell>0.573</cell><cell cols="2">1.00 129.48</cell></row><row><cell>Icelandic</cell><cell>0.550</cell><cell>1.00</cell><cell>95.58</cell></row><row><cell>Swedish</cell><cell>0.547</cell><cell cols="2">1.00 107.20</cell></row><row><cell>Adamawa Fulfulde</cell><cell>0.539</cell><cell>1.00</cell><cell>96.57</cell></row><row><cell>German</cell><cell>0.533</cell><cell cols="2">1.00 103.52</cell></row><row><cell>Albanian</cell><cell>0.523</cell><cell cols="2">1.00 114.80</cell></row><row><cell>Spanish</cell><cell>0.511</cell><cell>1.00</cell><cell>95.83</cell></row><row><cell>French</cell><cell>0.507</cell><cell cols="2">1.00 101.83</cell></row><row><cell>Swahili</cell><cell>0.494</cell><cell cols="2">1.00 105.03</cell></row><row><cell>Slovene</cell><cell>0.488</cell><cell cols="2">1.00 100.12</cell></row><row><cell>Polish</cell><cell>0.487</cell><cell cols="2">1.00 144.52</cell></row><row><cell>Portuguese</cell><cell>0.481</cell><cell>1.00</cell><cell>98.41</cell></row><row><cell>Esperanto</cell><cell>0.473</cell><cell>1.00</cell><cell>97.80</cell></row><row><cell>Italian</cell><cell>0.473</cell><cell cols="2">1.00 116.80</cell></row><row><cell>Catalan</cell><cell>0.450</cell><cell cols="2">1.00 109.70</cell></row><row><cell>Dutch</cell><cell>0.415</cell><cell cols="2">1.00 109.36</cell></row><row><cell>Lithuanian</cell><cell>0.396</cell><cell cols="2">1.00 104.99</cell></row><row><cell>Hungarian</cell><cell>0.386</cell><cell cols="2">1.00 102.10</cell></row><row><cell>Latin</cell><cell>0.366</cell><cell cols="2">0.99 112.54</cell></row><row><cell>Turkish</cell><cell>0.348</cell><cell>0.95</cell><cell>93.43</cell></row><row><cell>Finnish</cell><cell>0.345</cell><cell cols="2">0.99 107.88</cell></row><row><cell>Malayalam</cell><cell>0.276</cell><cell cols="2">0.88 128.65</cell></row><row><cell>Greenlandic</cell><cell>0.222</cell><cell cols="2">0.87 126.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 1 :</head><label>1</label><figDesc>Mean Reciprocal Rank (MRR) of WebCLEF 2005 mixed monolingual runs. Statistically significant differences on All from the NoStem baseline (Wilcoxon Signed Rank Test) are denoted * and ** for (p &lt; 0.05) and (p &lt; 0.01) respectively. Lang. = topic language. (∆%) = % diff. from NoStem. σ=st. deviation. NP = named page. HP = homepage.</figDesc><table><row><cell></cell><cell></cell><cell>PorStem</cell><cell>(∆%) AllStem</cell><cell>(∆%) SelStem</cell><cell>(∆%)</cell></row><row><cell>Dan</cell><cell>0.5130</cell><cell>0.4886</cell><cell>(-4.8%) 0.5263</cell><cell>(+2.6%) 0.4891</cell><cell>(-4.7%)</cell></row><row><cell>Ger</cell><cell>0.4389</cell><cell>0.4421</cell><cell>(+0.7%) 0.4498</cell><cell>(+2.5%) 0.4476</cell><cell>(+2.0%)</cell></row><row><cell>Gre</cell><cell>0.2056</cell><cell>0.2056</cell><cell>(0.0%) 0.2119</cell><cell>(+3.1%) 0.2119</cell><cell>(+3.1%)</cell></row><row><cell>Eng</cell><cell>0.5226</cell><cell>0.4892</cell><cell>(-6.4%) 0.4789</cell><cell>(-8.4%) 0.5045</cell><cell>(-3.5%)</cell></row><row><cell>Spa</cell><cell>0.4381</cell><cell>0.4370</cell><cell>(-0.3%) 0.4203</cell><cell>(-4.1%) 0.4188</cell><cell>(-4.4%)</cell></row><row><cell>Fre</cell><cell>1.0000</cell><cell>1.0000</cell><cell>(0.0%) 1.0000</cell><cell>(0.0%) 1.0000</cell><cell>(0.0%)</cell></row><row><cell>Hun</cell><cell>0.5071</cell><cell>0.5062</cell><cell>(-0.2%) 0.1137</cell><cell>(-77.6%) 0.2702</cell><cell>(-46.7%)</cell></row><row><cell>Ice</cell><cell>0.1722</cell><cell>0.1722</cell><cell>(0.0%) 0.1750</cell><cell>(+1.6%) 0.1750</cell><cell>(+1.6%)</cell></row><row><cell>Dut</cell><cell>0.6371</cell><cell>0.6433</cell><cell>(+1.0%) 0.6251</cell><cell>(-1.9%) 0.6222</cell><cell>(-2.3%)</cell></row><row><cell>Por</cell><cell>0.5361</cell><cell>0.5197</cell><cell>(-3.1%) 0.4866</cell><cell>(-9.2%) 0.5277</cell><cell>(-0.2%)</cell></row><row><cell>Rus</cell><cell>0.4530</cell><cell>0.4530</cell><cell>(0.0%) 0.4549</cell><cell>(+0.4%) 0.4883</cell><cell>(+7.8%)</cell></row><row><cell>σ</cell><cell>0.429</cell><cell></cell><cell>0.426</cell><cell>0.428</cell><cell>0.430</cell></row><row><cell cols="2">All NP 0.5142</cell><cell>0.4928</cell><cell>(-4.2%) 0.4630</cell><cell>(-10.0%) 0.4909</cell><cell>(-4.5%)</cell></row><row><cell cols="2">All HP 0.4597</cell><cell>0.4643</cell><cell>(+1.0%) 0.4254</cell><cell>(-7.5%) 0.4320</cell><cell>(-6.0%)</cell></row><row><cell>All</cell><cell>0.4900</cell><cell cols="2">0.4802** (-2.0%) 0.4464**</cell><cell>(-8.9%) 0.4648**</cell><cell>(-5.1%)</cell></row><row><cell cols="3">Lang. NoStem PorStem</cell><cell>(∆%) AllStem</cell><cell>(∆%) SelStem</cell><cell>(∆%)</cell></row><row><cell>Dan</cell><cell>0.6914</cell><cell>0.6901</cell><cell>(-0.2%) 0.6735</cell><cell>(-2.6%) 0.6735</cell><cell>(-2.6%)</cell></row><row><cell>Ger</cell><cell>0.4451</cell><cell>0.4415</cell><cell>(-0.8%) 0.4145</cell><cell>(-6.9%) 0.4196</cell><cell>(-5.7%)</cell></row><row><cell>Eng</cell><cell>0.6509</cell><cell>0.6167</cell><cell>(-5.3%) 0.6158</cell><cell>(-5.4%) 0.6024</cell><cell>(-7.5%)</cell></row><row><cell>Spa</cell><cell>0.4428</cell><cell>0.4237</cell><cell>(-4.3%) 0.4002</cell><cell>(-9.6%) 0.3916</cell><cell>(-11.6%)</cell></row><row><cell>Fre</cell><cell>0.1111</cell><cell>0.1111</cell><cell>(0.0%) 0.0000</cell><cell>(n/a) 0.0000</cell><cell>(n/a)</cell></row><row><cell>Hun</cell><cell>0.3862</cell><cell>0.3862</cell><cell>(0.0%) 0.3080</cell><cell>(-20.2%) 0.2855</cell><cell>(-26.1%)</cell></row><row><cell>Dut</cell><cell>0.5601</cell><cell>0.5573</cell><cell>(-0.5%) 0.5467</cell><cell>(-2.4%) 0.4974</cell><cell>(-11.2%)</cell></row><row><cell>Por</cell><cell>0.5068</cell><cell>0.4942</cell><cell>(-2.5%) 0.4367</cell><cell>(-13.8%) 0.3600</cell><cell>(-29.0%)</cell></row><row><cell>Rus</cell><cell>0.5755</cell><cell>0.5755</cell><cell>(0.0%) 0.5772</cell><cell>(+0.3%) 0.5755</cell><cell>(0%)</cell></row><row><cell>σ</cell><cell>0.423</cell><cell>0.418</cell><cell>0.425</cell><cell>0.425</cell><cell></cell></row><row><cell>All</cell><cell>0.5150</cell><cell>0.5031*</cell><cell>(-2.3%) 0.4733**</cell><cell cols="2">(-8.1%) 0.4530** (-12.0%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NoStem</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>PorStem AllStem</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SelStem</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MRR</cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>Dan Ger Gre Eng Spa Fre Hun</cell><cell>Ice</cell><cell>Dut</cell><cell>Por Rus</cell></row><row><cell></cell><cell></cell><cell>Topic set (language)</cell><cell></cell><cell></cell></row></table><note><p>Mean Reciprocal Rank (MRR) of the WebCLEF 2006 mixed monolingual runs (manual topics). Statistically significant differences on All from the NoStem baseline (Wilcoxon Signed Rank Test) are denoted * and ** for (p &lt; 0.05) and (p &lt; 0.01) respectively. Lang. = topic language. (∆%) = % diff. from NoStem. σ = st. deviation. n/a = non applicable.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell>Year</cell></row><row><cell>2005</cell><cell>2006</cell></row><row><cell cols="2">0.5135 0.5150</cell></row><row><cell cols="2">0.4900 0.3145</cell></row><row><cell>0.4780</cell><cell>0.1396</cell></row><row><cell>0.2860</cell><cell>0.0923</cell></row></table><note><p>Terrier's best runs (bold) versus top 3 submitted runs for WebCLEF 2005 &amp; 2006 (mixed monolingual task).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Type of transliterations Words Number of transliterations Orthographic Phonetic Mixed</head><label></label><figDesc></figDesc><table><row><cell>Κάθε</cell><cell>2</cell><cell>40%</cell><cell>60%</cell><cell></cell></row><row><cell>µέρα *</cell><cell>1</cell><cell>100%</cell><cell>100%</cell><cell></cell></row><row><cell>χρησιµοποιώ</cell><cell>5</cell><cell>47.5%</cell><cell></cell><cell>52.5%</cell></row><row><cell>διαφορετικές *</cell><cell>1</cell><cell>100%</cell><cell>100%</cell><cell></cell></row><row><cell>µεθόδους</cell><cell>2</cell><cell>35%</cell><cell>65%</cell><cell></cell></row><row><cell>για *</cell><cell>1</cell><cell>100%</cell><cell>100%</cell><cell></cell></row><row><cell>να *</cell><cell>1</cell><cell>100%</cell><cell>100%</cell><cell></cell></row><row><cell>βρω</cell><cell>5</cell><cell>57.5%</cell><cell>7.5%</cell><cell>35%</cell></row><row><cell>τη</cell><cell>2</cell><cell>52.5%</cell><cell>447.5%</cell><cell></cell></row><row><cell>λύση</cell><cell>6</cell><cell>50%</cell><cell>25%</cell><cell>25%</cell></row><row><cell>στο *+</cell><cell>2</cell><cell>100%</cell><cell>97.5% +</cell><cell></cell></row><row><cell>πρόβληµα</cell><cell>5</cell><cell>37.5%</cell><cell>20%</cell><cell>42.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 2 . Average precision for all approaches</head><label>2</label><figDesc></figDesc><table><row><cell>, u j i</cell><cell>substring</cell><cell>( u</cell><cell>,</cell><cell>i</cell><cell>j</cell><cell>i</cell><cell>j</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Techniques</cell><cell>Precision</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Revised bigram</cell><cell>92.28 %</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pure bigram</cell><cell>86.22 %</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Revised trigram</cell><cell>98.74 %</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pure trigram</cell><cell>96.62 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 3a . Average precision of pure trigram model for differ- ent thresholds on 500 words queries</head><label>3a</label><figDesc></figDesc><table><row><cell>Threshold</cell><cell></cell><cell cols="2">Pure trigram</cell><cell></cell></row><row><cell></cell><cell>Ret.</cell><cell>Relev.</cell><cell>Irrelev.</cell><cell>Precision</cell></row><row><cell>60</cell><cell>4442</cell><cell>4253</cell><cell>189</cell><cell>0.957</cell></row><row><cell>65</cell><cell>3086</cell><cell>2969</cell><cell>117</cell><cell>0.962</cell></row><row><cell>70</cell><cell>2075</cell><cell>2045</cell><cell>30</cell><cell>0.985</cell></row><row><cell>75</cell><cell>1872</cell><cell>1843</cell><cell>29</cell><cell>0.984</cell></row><row><cell>80</cell><cell>1015</cell><cell>1007</cell><cell>8</cell><cell>0.992</cell></row><row><cell>85</cell><cell>549</cell><cell>549</cell><cell>0</cell><cell>1</cell></row><row><cell>90</cell><cell>549</cell><cell>549</cell><cell>0</cell><cell>1</cell></row><row><cell>95</cell><cell>549</cell><cell>549</cell><cell>0</cell><cell>1</cell></row><row><cell></cell><cell cols="2">Average Precision</cell><cell></cell><cell>0.985</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 3b . Average precision of revised bigram model for dif- ferent threshold on 500 words queries</head><label>3b</label><figDesc></figDesc><table><row><cell>Threshold</cell><cell></cell><cell cols="2">Revised bigram</cell><cell></cell></row><row><cell></cell><cell>Ret.</cell><cell>Relev.</cell><cell>Irrelev.</cell><cell>Precision</cell></row><row><cell>60</cell><cell>5992</cell><cell>5472</cell><cell>520</cell><cell>0.913</cell></row><row><cell>65</cell><cell>4367</cell><cell>4196</cell><cell>171</cell><cell>0.961</cell></row><row><cell>70</cell><cell>2960</cell><cell>2882</cell><cell>78</cell><cell>0.973</cell></row><row><cell>75</cell><cell>2464</cell><cell>2393</cell><cell>71</cell><cell>0.971</cell></row><row><cell>80</cell><cell>1817</cell><cell>1803</cell><cell>14</cell><cell>0.992</cell></row><row><cell>85</cell><cell>694</cell><cell>694</cell><cell>0</cell><cell>1</cell></row><row><cell>90</cell><cell>518</cell><cell>518</cell><cell>0</cell><cell>1</cell></row><row><cell>95</cell><cell>518</cell><cell>518</cell><cell>0</cell><cell>1</cell></row><row><cell></cell><cell cols="2">Average Precision</cell><cell></cell><cell>0.976</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 4a . The result of the query ‫"ﻣﺴﺎﻋﺪ"‬ (helper) using the revised bigram approach</head><label>4a</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>9</cell><cell cols="2">‫آﻤﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>As a help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>10</cell><cell cols="2">‫وﻣﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>And helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>11</cell><cell cols="2">‫وﻣﺴﺎﻋﺪﻩ‬</cell><cell>Rel</cell><cell>And his helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>12</cell><cell cols="2">‫وﻣﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>And help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>13</cell><cell cols="2">‫وﺳﺎﻋﺪ‬</cell><cell>Rel</cell><cell>And he helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell>14</cell><cell cols="2">‫ﻟﻤﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>For helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>15</cell><cell cols="2">‫ﻟﻤﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>For help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>16</cell><cell cols="2">‫ﻧﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>We help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>17</cell><cell cols="2">‫ﻣﺴﺎﻋﺪي‬</cell><cell>Rel</cell><cell>My helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>18</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﻳﻦ‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>19</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﻳﻪ‬</cell><cell>Rel</cell><cell>His helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>20</cell><cell cols="2">‫ﻣﺴﺎﻋﺪو‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>21</cell><cell cols="2">‫ﻣﺴﺎﻋﺪون‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>22</cell><cell cols="2">‫ﻣﺴﺎﻋﺪوﻩ‬</cell><cell>Rel</cell><cell>His helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>23</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﻩ‬</cell><cell>Rel</cell><cell>His helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>24</cell><cell cols="2">‫ﻣﺴﺎﻋﺪهﺎ‬</cell><cell>Rel</cell><cell>Her helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>25</cell><cell cols="2">‫ﻣﺴﺎﻋﺪا‬</cell><cell>Rel</cell><cell>A helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>26</cell><cell cols="2">ً ‫ﻣﺴﺎﻋﺪا‬</cell><cell>Rel</cell><cell>A helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>27</cell><cell cols="2">‫ﻣﺴﺎﻋﺪات‬</cell><cell>Rel</cell><cell>Helps</cell></row><row><cell></cell><cell></cell><cell></cell><cell>28</cell><cell cols="2">‫ﻣﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>Help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>29</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﺗﻲ‬</cell><cell>Rel</cell><cell>My help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>30</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﺗﻪ‬</cell><cell>Rel</cell><cell>His help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>31</cell><cell cols="2">‫أﺳﺎﻋﺪ‬</cell><cell>Rel</cell><cell>I help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>32</cell><cell cols="2">‫اﻟﻤﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>The helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>33</cell><cell cols="2">‫ﻣﺴﺎﻋﺪون‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>34</cell><cell cols="2">‫وﻣﺴﺎع‬</cell><cell>Irr</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>35</cell><cell cols="2">‫ﺑﻤﺴﺎع‬</cell><cell>Irr</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>36</cell><cell>‫ﺴﺎع‬</cell><cell>‫ﻟﻤ‬</cell><cell>Irr</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>37</cell><cell cols="2">‫ﻣﺴﺎﻋﻲ‬</cell><cell>Irr</cell><cell>-</cell></row><row><cell></cell><cell cols="3">Revised bigram approach</cell><cell></cell></row><row><cell>S/N</cell><cell>Word</cell><cell>Rel/Irr</cell><cell>Translation</cell><cell></cell></row><row><cell>1</cell><cell>‫ﻣﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>Helper</cell><cell></cell></row><row><cell>2</cell><cell>‫ﺑﻤﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>By helper</cell><cell></cell></row><row><cell>3</cell><cell>‫ﺑﻤﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>By help</cell><cell></cell></row><row><cell>4</cell><cell>‫ﺗﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>She helps</cell><cell></cell></row><row><cell>5</cell><cell>‫ﺳﺎﻋﺪ‬</cell><cell>Rel</cell><cell>He helped</cell><cell></cell></row><row><cell>6</cell><cell>‫ﺳﺎﻋﺪﻩ‬</cell><cell>Rel</cell><cell>He helped him</cell><cell></cell></row><row><cell>7</cell><cell>‫ﺳﺎﻋﺪت‬</cell><cell>Rel</cell><cell>She helped</cell><cell></cell></row><row><cell>8</cell><cell>‫ﻳﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>He helps</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 4b . The result of the query ‫"ﻣﺴﺎﻋﺪ"‬ (helper) using the pure trigram approach</head><label>4b</label><figDesc></figDesc><table><row><cell>18</cell><cell>‫ﻣﺴﺎﻋﺪهﺎ‬</cell><cell>Rel</cell><cell>Her helper</cell><cell></cell></row><row><cell>19</cell><cell>‫ﻣﺴﺎﻋﺪا‬</cell><cell>Rel</cell><cell>A helper</cell><cell></cell></row><row><cell>20</cell><cell>ً ‫ﻣﺴﺎﻋﺪا‬</cell><cell>Rel</cell><cell>A helper</cell><cell></cell></row><row><cell>21</cell><cell>‫ﻣﺴﺎﻋﺪات‬</cell><cell>Rel</cell><cell>Helps</cell><cell></cell></row><row><cell>22</cell><cell>‫ﻣﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>Help</cell><cell></cell></row><row><cell>23</cell><cell>‫ﻣﺴﺎﻋﺪﺗﻲ‬</cell><cell>Rel</cell><cell>My help</cell><cell></cell></row><row><cell>24</cell><cell>‫ﻣﺴﺎﻋﺪﺗﻪ‬</cell><cell>Rel</cell><cell>His help</cell><cell></cell></row><row><cell>25</cell><cell>‫اﻟﻤﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>The helper</cell><cell></cell></row><row><cell>26</cell><cell>‫ﻣﺴﺎع‬</cell><cell>Irr</cell><cell>-</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Pure trigram approach</cell></row><row><cell></cell><cell></cell><cell></cell><cell>S/N</cell><cell cols="2">Word</cell><cell>Rel/Irr</cell><cell>Translation</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell cols="2">‫ﻣﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>Helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>2</cell><cell cols="2">‫ﺑﻤﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>By helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>3</cell><cell cols="2">‫ﺑﻤﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>By help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>4</cell><cell cols="2">‫ﺳﺎﻋﺪ‬</cell><cell>Rel</cell><cell>He helped</cell></row><row><cell></cell><cell></cell><cell></cell><cell>5</cell><cell cols="2">‫ﺴﺎﻋﺪة‬</cell><cell>‫آﻤ‬</cell><cell>Rel</cell><cell>As a help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>6</cell><cell cols="2">‫وﻣﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>And helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>7</cell><cell cols="2">‫وﻣﺴﺎﻋﺪﻩ‬</cell><cell>Rel</cell><cell>And his helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>8</cell><cell cols="2">‫وﻣﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>And help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>9</cell><cell cols="2">‫ﻟﻤﺴﺎﻋﺪ‬</cell><cell>Rel</cell><cell>For helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>10</cell><cell cols="2">‫ﻟﻤﺴﺎﻋﺪة‬</cell><cell>Rel</cell><cell>For help</cell></row><row><cell></cell><cell></cell><cell></cell><cell>11</cell><cell cols="2">‫ﻣﺴﺎﻋﺪي‬</cell><cell>Rel</cell><cell>My helper</cell></row><row><cell></cell><cell></cell><cell></cell><cell>12</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﻳﻦ‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>13</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﻳﻪ‬</cell><cell>Rel</cell><cell>His helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>14</cell><cell cols="2">‫ﻣﺴﺎﻋﺪو‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>15</cell><cell>‫ﻋﺪون‬</cell><cell>‫ﻣﺴﺎ‬</cell><cell>Rel</cell><cell>Helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>16</cell><cell cols="2">‫ﻣﺴﺎﻋﺪوﻩ‬</cell><cell>Rel</cell><cell>His helpers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>17</cell><cell cols="2">‫ﻣﺴﺎﻋﺪﻩ‬</cell><cell>Rel</cell><cell>His helper</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head>Table 4c . The result of the query ‫"اﻟﺴﻴﺎﺳﺔ"‬ (The politics) using the revised bigram approach</head><label>4c</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Revised bigram approach</cell></row><row><cell>S/N</cell><cell>Word</cell><cell></cell><cell>Rel/Irr</cell><cell>Translation</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>The politics</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﻲ‬</cell><cell>Rel</cell><cell>The Political (m)</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﻴﻴﻦ‬</cell><cell>Rel</cell><cell>The Politicians (m)</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﻴﻮن‬</cell><cell>Rel</cell><cell>The Politicians (m)</cell></row><row><cell></cell><cell cols="2">ّ ‫اﻟﺴﻴﺎﺳﻲ‬</cell><cell>Rel</cell><cell>The Political (m)</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﻴﺎت‬</cell><cell>Rel</cell><cell>The Politicians (f)</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﻴﺔ‬</cell><cell>Rel</cell><cell>The Political (f)</cell></row><row><cell></cell><cell cols="2">‫اﻟﺴﻴﺎﺳﺎت‬</cell><cell>Rel</cell><cell>The Policies</cell></row><row><cell></cell><cell cols="2">‫ﺑﺎﻟﺴﻴﺎﺳﻴﺔ‬</cell><cell>Rel</cell><cell>By Political</cell></row><row><cell></cell><cell cols="2">‫ﺑﺎﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>By politics</cell></row><row><cell></cell><cell cols="2">‫ﺳﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>politics</cell></row><row><cell></cell><cell cols="2">‫آﺎﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>As politics</cell></row><row><cell></cell><cell cols="2">‫وﻟﻠﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>And for politics</cell></row><row><cell></cell><cell cols="2">‫واﻟﺴﻴﺎﺳﻲ‬</cell><cell>Rel</cell><cell>And the Political (m)</cell></row><row><cell></cell><cell cols="2">‫واﻟﺴﻴﺎﺳﻴﺔ‬</cell><cell>Rel</cell><cell>And the Political (f)</cell></row><row><cell></cell><cell cols="2">‫واﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>And the politics</cell></row><row><cell></cell><cell cols="2">‫ﻟﻠﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>For politics</cell></row><row><cell></cell><cell>‫ﺴﻴﺎﺳﺔ‬</cell><cell>‫ﻟ‬</cell><cell>Rel</cell><cell>To politics</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head>Table 4d . The result of the query ‫"اﻟﺴﻴﺎﺳﺔ"‬ (The politics) using the revised pure trigram approach</head><label>4d</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">Pure trigram approach</cell></row><row><cell>S/N</cell><cell>Word</cell><cell>Rel/Irr</cell><cell>Translation</cell></row><row><cell>1</cell><cell>‫اﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>The politics</cell></row><row><cell>2</cell><cell>‫اﻟﺴﻴﺎﺳﻲ‬</cell><cell>Rel</cell><cell>The Political (m)</cell></row><row><cell>3</cell><cell>‫ﺑﺎﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>By politics</cell></row><row><cell>4</cell><cell>‫ﺳﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>politics</cell></row><row><cell>5</cell><cell>‫آﺎﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>As politics</cell></row><row><cell>6</cell><cell>‫واﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>And the politics</cell></row><row><cell>7</cell><cell>‫ﻟﻠﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>For politics</cell></row><row><cell>8</cell><cell>‫ﻟﺴﻴﺎﺳﺔ‬</cell><cell>Rel</cell><cell>To politics</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head>Table 5a . Average Recall, Precision and F-measure for the pure trigram approach</head><label>5a</label><figDesc></figDesc><table><row><cell>20</cell><cell>28</cell><cell>28</cell><cell>2</cell><cell>1</cell><cell>0.94</cell><cell>0.97</cell><cell></cell></row><row><cell>21</cell><cell>10</cell><cell>10</cell><cell>6</cell><cell>1</cell><cell>0.63</cell><cell>0.77</cell><cell></cell></row><row><cell>22</cell><cell>10</cell><cell>10</cell><cell>30</cell><cell>1</cell><cell>0.25</cell><cell>0.40</cell><cell></cell></row><row><cell>23</cell><cell>11</cell><cell>11</cell><cell>17</cell><cell>1</cell><cell>0.40</cell><cell>0.57</cell><cell></cell></row><row><cell>24</cell><cell>20</cell><cell>20</cell><cell>13</cell><cell>1</cell><cell>0.60</cell><cell>0.75</cell><cell></cell></row><row><cell>25</cell><cell>12</cell><cell>12</cell><cell>8</cell><cell>1</cell><cell>0.49</cell><cell>0.66</cell><cell></cell></row><row><cell>26</cell><cell>12</cell><cell>12</cell><cell>30</cell><cell>1</cell><cell>0.29</cell><cell>0.45</cell><cell></cell></row><row><cell>27</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>0.51</cell><cell>0.68</cell><cell></cell></row><row><cell>28</cell><cell>38</cell><cell>38</cell><cell>19</cell><cell>1</cell><cell>0.57</cell><cell>0.73</cell><cell></cell></row><row><cell>29</cell><cell>16</cell><cell>16</cell><cell>10</cell><cell>1</cell><cell>0.62</cell><cell>0.77</cell><cell></cell></row><row><cell>30</cell><cell>5</cell><cell>5</cell><cell>1</cell><cell>1</cell><cell>0.84</cell><cell>0.91</cell><cell></cell></row><row><cell></cell><cell>366</cell><cell>360</cell><cell>374</cell><cell>0.98</cell><cell>0.49</cell><cell>0.59</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pure trigram</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>S/N</cell><cell>Ret.</cell><cell>Rel.</cell><cell>Irr.</cell><cell>Miss. R.</cell><cell>Precision</cell><cell>Recall</cell><cell>F</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>7</cell><cell>6</cell><cell>1</cell><cell>7</cell><cell>0.85</cell><cell>0.47</cell><cell>0.61</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell>6</cell><cell>6</cell><cell>0</cell><cell>11</cell><cell>1</cell><cell>0.36</cell><cell>0.53</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>17</cell><cell>17</cell><cell>0</cell><cell>13</cell><cell>1</cell><cell>0.57</cell><cell>0.73</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>2</cell><cell>1</cell><cell>0.34</cell><cell>0.51</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell>29</cell><cell>28</cell><cell>1</cell><cell>0</cell><cell>0.96</cell><cell>1</cell><cell>0.98</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>6</cell><cell>10</cell><cell>9</cell><cell>1</cell><cell>11</cell><cell>0.90</cell><cell>0.45</cell><cell>0.60</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>7</cell><cell>22</cell><cell>22</cell><cell>0</cell><cell>3</cell><cell>1</cell><cell>0.88</cell><cell>0.94</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>8</cell><cell>13</cell><cell>13</cell><cell>0</cell><cell>23</cell><cell>1</cell><cell>0.37</cell><cell>0.54</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>9</cell><cell>7</cell><cell>7</cell><cell>0</cell><cell>22</cell><cell>1</cell><cell>0.25</cell><cell>0.40</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell>6</cell><cell>6</cell><cell>0</cell><cell>14</cell><cell>1</cell><cell>0.30</cell><cell>0.46</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>11</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>19</cell><cell>1</cell><cell>0.05</cell><cell>0.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>12</cell><cell>6</cell><cell>5</cell><cell>1</cell><cell>11</cell><cell>0.83</cell><cell>0.32</cell><cell>0.23</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>13</cell><cell>3</cell><cell>3</cell><cell>0</cell><cell>23</cell><cell>1</cell><cell>0.12</cell><cell>0.46</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>14</cell><cell>11</cell><cell>11</cell><cell>0</cell><cell>8</cell><cell>1</cell><cell>0.58</cell><cell>0.73</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>15</cell><cell>14</cell><cell>14</cell><cell>0</cell><cell>24</cell><cell>1</cell><cell>0.37</cell><cell>0.54</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>16</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>6</cell><cell>1</cell><cell>0.15</cell><cell>0.26</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>17</cell><cell>14</cell><cell>13</cell><cell>1</cell><cell>6</cell><cell>0.92</cell><cell>0.69</cell><cell>0.79</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>18</cell><cell>18</cell><cell>17</cell><cell>1</cell><cell>19</cell><cell>0.94</cell><cell>0.48</cell><cell>0.64</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>19</cell><cell>16</cell><cell>16</cell><cell>0</cell><cell>14</cell><cell>1</cell><cell>0.54</cell><cell>0.70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_32"><head>Table 5b . Average Recall, Precision and F-measure for the revised bigram approach</head><label>5b</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Pure trigram</cell><cell></cell><cell></cell></row><row><cell>S/N</cell><cell>Ret.</cell><cell>Rel.</cell><cell>Irr.</cell><cell>Miss. R.</cell><cell>Precision</cell><cell>Recall</cell><cell>F</cell></row><row><cell>1</cell><cell>9</cell><cell>7</cell><cell></cell><cell>6</cell><cell>0.77</cell><cell>0.54</cell><cell>0.63</cell></row><row><cell>2</cell><cell>7</cell><cell>7</cell><cell></cell><cell>10</cell><cell>1</cell><cell>0.42</cell><cell>0.60</cell></row><row><cell>3</cell><cell>28</cell><cell>26</cell><cell></cell><cell>2</cell><cell>0.92</cell><cell>0.93</cell><cell>0.92</cell></row><row><cell>4</cell><cell>3</cell><cell>3</cell><cell></cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>5</cell><cell>29</cell><cell>28</cell><cell></cell><cell>0</cell><cell>0.96</cell><cell>1</cell><cell>0.98</cell></row><row><cell>6</cell><cell>13</cell><cell>12</cell><cell></cell><cell>6</cell><cell>0.92</cell><cell>0.67</cell><cell>0.78</cell></row><row><cell>7</cell><cell>25</cell><cell>24</cell><cell></cell><cell>0</cell><cell>0.96</cell><cell>1</cell><cell>0.98</cell></row><row><cell>8</cell><cell>36</cell><cell>35</cell><cell></cell><cell>1</cell><cell>0.97</cell><cell>0.98</cell><cell>0.97</cell></row><row><cell>9</cell><cell>15</cell><cell>14</cell><cell></cell><cell>15</cell><cell>0.93</cell><cell>0.49</cell><cell>0.64</cell></row><row><cell>10</cell><cell>10</cell><cell>10</cell><cell></cell><cell>10</cell><cell>1</cell><cell>0.50</cell><cell>0.67</cell></row><row><cell>11</cell><cell>7</cell><cell>5</cell><cell></cell><cell>13</cell><cell>0.71</cell><cell>0.28</cell><cell>0.40</cell></row><row><cell>12</cell><cell>18</cell><cell>16</cell><cell></cell><cell>0</cell><cell>0.88</cell><cell>1</cell><cell>0.94</cell></row><row><cell>13</cell><cell>12</cell><cell>12</cell><cell></cell><cell>14</cell><cell>1</cell><cell>0.47</cell><cell>0.64</cell></row><row><cell>14</cell><cell>29</cell><cell>19</cell><cell>10</cell><cell>0</cell><cell>0.65</cell><cell>1</cell><cell>0.79</cell></row><row><cell>15</cell><cell>38</cell><cell>38</cell><cell></cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>16</cell><cell>4</cell><cell>4</cell><cell></cell><cell>3</cell><cell>1</cell><cell>0.58</cell><cell>0.73</cell></row><row><cell>17</cell><cell>20</cell><cell>13</cell><cell></cell><cell>6</cell><cell>0.65</cell><cell>0.69</cell><cell>0.67</cell></row><row><cell>18</cell><cell>18</cell><cell>17</cell><cell></cell><cell>19</cell><cell>0.94</cell><cell>0.48</cell><cell>0.64</cell></row><row><cell>19</cell><cell>21</cell><cell>17</cell><cell></cell><cell>13</cell><cell>0.80</cell><cell>0.57</cell><cell>0.67</cell></row><row><cell>20</cell><cell>29</cell><cell>27</cell><cell></cell><cell>1</cell><cell>0.93</cell><cell>0.97</cell><cell>0.95</cell></row><row><cell>21</cell><cell>16</cell><cell>16</cell><cell></cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>22</cell><cell>27</cell><cell>26</cell><cell></cell><cell>14</cell><cell>0.96</cell><cell>0.65</cell><cell>0.78</cell></row><row><cell>23</cell><cell>17</cell><cell>17</cell><cell></cell><cell>11</cell><cell>1</cell><cell>0.61</cell><cell>0.76</cell></row><row><cell>24</cell><cell>28</cell><cell>28</cell><cell></cell><cell>5</cell><cell>1</cell><cell>0.85</cell><cell>0.92</cell></row><row><cell>25</cell><cell>27</cell><cell>23</cell><cell></cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>26</cell><cell>22</cell><cell>22</cell><cell></cell><cell>20</cell><cell>1</cell><cell>0.53</cell><cell>0.70</cell></row><row><cell>27</cell><cell>3</cell><cell>3</cell><cell></cell><cell>1</cell><cell>1</cell><cell>0.75</cell><cell>0.86</cell></row><row><cell>28</cell><cell>49</cell><cell>49</cell><cell></cell><cell>8</cell><cell>1</cell><cell>0.86</cell><cell>0.92</cell></row><row><cell>29</cell><cell>30</cell><cell>29</cell><cell></cell><cell>7</cell><cell>0.96</cell><cell>0.81</cell><cell>0.88</cell></row><row><cell>30</cell><cell>6</cell><cell>6</cell><cell></cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>596</cell><cell>553</cell><cell>42</cell><cell>185</cell><cell>0.93</cell><cell>0.75</cell><cell>0.76</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_34"><head>Table 1 . Limits and licensing possibilities of the APIs Free access API Queries / day Results / Query Commercial license</head><label>1</label><figDesc></figDesc><table><row><cell>Google</cell><cell>1,000</cell><cell>10</cell><cell>No</cell></row><row><cell>Yahoo</cell><cell>5,000</cell><cell>100</cell><cell>No</cell></row><row><cell>Microsoft</cell><cell>25,000</cell><cell>50</cell><cell>Yes</cell></row><row><cell>Alexa</cell><cell>-</cell><cell>-</cell><cell>Yes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_35"><head>Table 2 . Frequency and query percentage of each category of word</head><label>2</label><figDesc></figDesc><table><row><cell>Category of word</cell><cell cols="2">Word</cell><cell cols="2">Query</cell></row><row><cell></cell><cell>Count</cell><cell>%</cell><cell>Count</cell><cell>%</cell></row><row><cell>Short words</cell><cell>72</cell><cell>18.65%</cell><cell>44,214</cell><cell>18.64%</cell></row><row><cell>Proper nouns</cell><cell>46</cell><cell>11.92%</cell><cell>17,491</cell><cell>7.37%</cell></row><row><cell>International words</cell><cell>63</cell><cell>16.32%</cell><cell>46,853</cell><cell>19.76%</cell></row><row><cell>Words probably in other languages</cell><cell>100</cell><cell>25.91%</cell><cell>63,266</cell><cell>26.68%</cell></row><row><cell>Basque words</cell><cell>105</cell><cell>27.20%</cell><cell>65,345</cell><cell>27.55%</cell></row><row><cell>Total categorized</cell><cell>386</cell><cell>0.73%</cell><cell>237,169</cell><cell>40.27%</cell></row><row><cell>Total</cell><cell cols="2">52,701</cell><cell cols="2">588,996</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36"><head>Table 3 . Gain in recall due to morphological query expansion for Basque words alone</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Hit counts</cell><cell></cell><cell cols="2">New results among</cell></row><row><cell>Word</cell><cell cols="2">without with</cell><cell>Increase</cell><cell cols="2">the first 100</cell></row><row><cell></cell><cell cols="2">morphological query expansion</cell><cell></cell><cell>Count</cell><cell>%</cell></row><row><cell>kutsadura</cell><cell>2,778</cell><cell>3,373</cell><cell>21.42%</cell><cell>37</cell><cell>37.00%</cell></row><row><cell>berriztagarri</cell><cell>65</cell><cell cols="2">2,729 4,098.46%</cell><cell>88</cell><cell>135.38%</cell></row><row><cell>elikadura</cell><cell cols="2">10,804 11,818</cell><cell>9.39%</cell><cell>41</cell><cell>41.00%</cell></row><row><cell>gaixotasun</cell><cell>4,113</cell><cell>7,617</cell><cell>85.19%</cell><cell>75</cell><cell>75.00%</cell></row><row><cell>ugalketa</cell><cell>1,474</cell><cell>1,467</cell><cell>-0.47%</cell><cell>34</cell><cell>34.00%</cell></row><row><cell>berotegi</cell><cell>226</cell><cell>247</cell><cell>9.29%</cell><cell>34</cell><cell>34.00%</cell></row><row><cell>gizaki</cell><cell>4,897</cell><cell>12,853</cell><cell>162.47%</cell><cell>85</cell><cell>85.00%</cell></row><row><cell>basamortu</cell><cell>210</cell><cell>845</cell><cell>302.38%</cell><cell>69</cell><cell>69.00%</cell></row><row><cell>elikagai</cell><cell>2,579</cell><cell>8,957</cell><cell>247.31%</cell><cell>84</cell><cell>84.00%</cell></row><row><cell>minbizi</cell><cell>147</cell><cell cols="2">1,795 1,121.09%</cell><cell>84</cell><cell>84.00%</cell></row><row><cell>Total</cell><cell cols="2">27,293 51,701</cell><cell>89.43%</cell><cell>631</cell><cell>65.39%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_37"><head>Table 4 . Gain in precision obtained by language-filtering words for each category of word, and weighted average % of Basque pages without with Category of word Weight filtering words Increase</head><label>4</label><figDesc></figDesc><table><row><cell>Short words</cell><cell>18.64%</cell><cell>9.82%</cell><cell>97.38%</cell><cell>87.56</cell></row><row><cell>Proper nouns</cell><cell>7.37%</cell><cell>0.20%</cell><cell>76.41%</cell><cell>76.21</cell></row><row><cell cols="2">International words 19.76%</cell><cell>0.00%</cell><cell>97.18%</cell><cell>97.18</cell></row><row><cell>Words probably in other languages</cell><cell>26.68%</cell><cell cols="2">18.40% 100.00%</cell><cell>81.6</cell></row><row><cell>Basque words</cell><cell>27.55%</cell><cell>77.80%</cell><cell>99.57%</cell><cell>21.77</cell></row><row><cell cols="2">Weighted average</cell><cell>27.19%</cell><cell>97.74%</cell><cell>70.55</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_38"><head>Table 5 . Loss in recall due to language-filtering words for Basque words alone, measured in hit count decrease Decrease in hit counts with</head><label>5</label><figDesc></figDesc><table><row><cell>Word</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell></cell><cell></cell><cell cols="2">language-filtering words</cell><cell></cell></row><row><cell>kutsadura</cell><cell>4.72%</cell><cell>19.26%</cell><cell>35.39%</cell><cell>42.84%</cell></row><row><cell>berriztagarri</cell><cell>-44.62%</cell><cell>-38.46%</cell><cell>-13.85%</cell><cell>-4.62%</cell></row><row><cell>elikadura</cell><cell>4.69%</cell><cell>45.82%</cell><cell>69.40%</cell><cell>73.85%</cell></row><row><cell>gaixotasun</cell><cell>1.56%</cell><cell>10.60%</cell><cell>24.48%</cell><cell>35.52%</cell></row><row><cell>ugalketa</cell><cell>60.65%</cell><cell>86.30%</cell><cell>83.45%</cell><cell>84.74%</cell></row><row><cell>berotegi</cell><cell>3.10%</cell><cell>13.72%</cell><cell>17.26%</cell><cell>21.68%</cell></row><row><cell>gizaki</cell><cell>2.37%</cell><cell>8.35%</cell><cell>14.03%</cell><cell>45.62%</cell></row><row><cell>basamortu</cell><cell>22.38%</cell><cell>7.62%</cell><cell>26.67%</cell><cell>28.10%</cell></row><row><cell>elikagai</cell><cell>0.58%</cell><cell>28.15%</cell><cell>44.44%</cell><cell>54.91%</cell></row><row><cell>minbizi</cell><cell>11.56%</cell><cell>13.61%</cell><cell>19.05%</cell><cell>76.19%</cell></row><row><cell>Total</cell><cell>6.48%</cell><cell>30.67%</cell><cell>46.40%</cell><cell>57.69%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_39"><head>Table 6 . Loss in recall due to language-filtering words for Basque words alone, measured in pages no longer among the first 100 % of pages no longer among the first 100 with 1 2 3 4 Word language-filtering words</head><label>6</label><figDesc></figDesc><table><row><cell>kutsadura</cell><cell>31.43%</cell><cell>34.29%</cell><cell>37.14%</cell><cell>42.86%</cell></row><row><cell>berriztagarri</cell><cell>28.07%</cell><cell>35.09%</cell><cell>50.88%</cell><cell>47.37%</cell></row><row><cell>elikadura</cell><cell>41.79%</cell><cell>44.78%</cell><cell>67.16%</cell><cell>74.63%</cell></row><row><cell>gaixotasun</cell><cell>38.75%</cell><cell>40.00%</cell><cell>50.00%</cell><cell>58.75%</cell></row><row><cell>ugalketa</cell><cell>61.54%</cell><cell>58.97%</cell><cell>61.45%</cell><cell>65.38%</cell></row><row><cell>berotegi</cell><cell>34.09%</cell><cell>40.91%</cell><cell>46.59%</cell><cell>52.27%</cell></row><row><cell>Gizaki</cell><cell>46.91%</cell><cell>43.21%</cell><cell>49.38%</cell><cell>59.26%</cell></row><row><cell>basamortu</cell><cell>37.68%</cell><cell>34.78%</cell><cell>43.48%</cell><cell>56.52%</cell></row><row><cell>elikagai</cell><cell>30.77%</cell><cell>33.33%</cell><cell>46.15%</cell><cell>55.13%</cell></row><row><cell>minbizi</cell><cell>25.61%</cell><cell>24.39%</cell><cell>34.15%</cell><cell>75.61%</cell></row><row><cell>Total</cell><cell>37.87%</cell><cell>39.07%</cell><cell>48.40%</cell><cell>59.07%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_40"><head>Table 7 . Gain in recall obtained by morphological generation for each category of word and weighted average Category of word Weight Gain in hit counts % of new results</head><label>7</label><figDesc></figDesc><table><row><cell>Short words</cell><cell>18.64%</cell><cell>43.75%</cell><cell>71.30%</cell></row><row><cell>Proper nouns</cell><cell>7.37%</cell><cell>11.83%</cell><cell>37.85%</cell></row><row><cell>International words</cell><cell>19.76%</cell><cell>16.51%</cell><cell>53.47%</cell></row><row><cell>Words probably in other languages</cell><cell>26.68%</cell><cell>64.37%</cell><cell>61.05%</cell></row><row><cell>Basque words</cell><cell>27.55%</cell><cell>57.36%</cell><cell>59.50%</cell></row><row><cell cols="2">Weighted average</cell><cell>40.19%</cell><cell>59.94%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_42"><head>Table 2 :</head><label>2</label><figDesc>Comparison of results for fuzzy text search. SED stands for a method based on a measure of string similarity called Scaled Edit Distance.</figDesc><table><row><cell></cell><cell>Hindi</cell><cell></cell><cell>Telugu</cell><cell></cell></row><row><cell></cell><cell cols="2">SED CPMS</cell><cell cols="2">SED CPMS</cell></row><row><cell>Precision</cell><cell cols="4">53.22% 94.16% 42.58% 83.67%</cell></row><row><cell>Recall</cell><cell cols="4">76.76% 94.90% 59.87% 71.52%</cell></row><row><cell cols="5">F-Measure 62.86% 94.53% 49.77% 77.12%</cell></row><row><cell>Threshold</cell><cell>0.4</cell><cell>0.9</cell><cell>0.2</cell><cell>1.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>There would also have been practical problems in doing justice as many descriptions of existing systems hide information on parameter tweaking. Online systems we have</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>The latest open source release of Terrier (version 1.1.0) supports various encodings of documents, and the use of non-Latin character sets. More details can be found at: http://ir.dcs.gla.ac.uk/terrier/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>at(=austria) cy(=cyprus) de(=germany) ee(=estonia) eu(=european union) fr(=france) hu(=hungary) it(=italy) lu(=luxemburg) mt(=malta) pl(=poland) ru(=russia) si(=slovenia) uk(=united kingdom) be(=belgium) cz(=czech republic) dk(=denmark) es(=spain) fi(=finland) gr(=greece) ie(=ireland) lt(=lithuania) lv(=latvia) nl(=the netherlands)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>http://snowball.tartarus.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>http://magyarispell.sourceforge.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>During indexing, anchor text from a document with a different language to the target document is stemmed using the stemmer of the language of the source document.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_6"><p>http://trec.nist.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_7"><p>According to the data provided by Global Reach, nearly 64.8% of the web users are non-English speakers.Copyright is held by the author/owner(s) SIGIR'07 iNEWS workshop, July</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="27" xml:id="foot_8"><p>2007, Amsterdam, Netherlands</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_9"><p>http://www.google.gr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_10"><p>If the relations between letters and sounds are similar in two languages, a transliteration may be (almost) the same as transcription. Greeklish is the only writing system that mixes transliteration and transcription.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_11"><p>The taxonomy of query goals is the one proposed in[17].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_12"><p>Copyright is held by the author/owner(s). SIGIR'07 iNEWS07 workshop, July 27, 2007, Amsterdam, The Netherlands.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_13"><p>http://www.google.com/webhp?complete=1&amp;hl=en</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_14"><p>http://en.wikipedia.org/wiki/Abugida</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_15"><p>http://www.merriampark.com/ld.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_16"><p>http://en.wikipedia.org/wiki/Hangul</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Author Lefetris Kozanidis was funded by the 03ED_413 research project, implemented within the "Reinforcement Programme of Human Research Manpower" (PENED) and cofinanced by National and Community Funds (25% from the Greek Ministry of Development-General Secretariat of Research and Technology and 75% from EU-European Social Fund).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The research reported in this paper has been partially supported by Telémaco, Información, Documentación y Sistemas, S.L. (http://www.telemaco.com), Xunta de Galicia (PGIDIT05SIN044E, PGIDIT05PXIC30501PN), Ministry of Education and Science (TIN2004-07246-C03-01) and University of Vigo</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>aitzol.ezeiza@ehu.es</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>The performance of major search engines for Basque is far from satisfactory, partly due to the agglutinative nature of the language -it is commonly known that search engines do not perform well with such languages-and partly because it is not a language to which search engines restrict their results.</p><p>In this paper we present EusBila, a search service for Basque that relies on the APIs of search engines, yet obtains a lemma-based and language-filtered search by means of morphological query expansion and language-filtering words. It is a cost-effective approach, which we think can be used for other agglutinative or minority languages. We also evaluate how well EusBila performs when carrying out a Basque query, and we compare this performance to that of a major search engine in terms of precision and recall, thus demonstrating that EusBila is a very valid solution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories and Subject Descriptors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>In this paper, we describe our system architecture that supports users in query formulation and retrieval. Different functionalities for browsing multilingual lexical resources and related Web documents have been implemented. On the one hand, we support the learner/user who first wants to find all possible word senses, retrieve the appropriate translation from the lexical resources and categorize documents (if the user needs such an automatic help) to the most likely word sense and, finally, visualize the search results together with the information provided from the used lexical resources. On the other hand, we help the author who works with RDF/OWL structures for editing and structuring EuroWordNet word senses and translations that are used for query (re)formulation or translation. In this way we help users in formulating multilingual queries, giving also the possibility to explore the intended meanings in other languages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories and Subject Descriptors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Farsi e-Orthography: An Example of e-Orthography Concept</head><p>Behrang Qasemizadeh</p><p>Text and Speech Ltd Tehran, Iran qasemizadeh@comp.iust.ac.ir</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>Farsi, also known as Persian, is the official language of Iran and Tajikistan and one of the two main languages spoken in Afghanistan. Farsi enjoys a unified Arabic script as its writing system. The fact of using Arabic scripts, a Semitic Language, for representation of Farsi, an Indo-European Language, leads to problems when analyzing, and retrieving Farsi e-text. In this paper we briefly introduce Farsi writing system, and highlight problems when analyzing Farsi electronic texts especially during retrieving Farsi e-texts. Then we introduce the concept of eorthography. We discuss how e-orthography could be used to improve search results while using keyword based search engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thesaurus topic assignment using hierarchical text categorization</head><p>Franciso </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>In this paper we present a method for assigning topics from a hierarchical thesaurus to documents written in natural languages. The approach we have followed models thesaurus topic assignment as a multiple label classification problem, where the whole set of possible classes is hierarchically organized. In our case the classification problem is reduced to a sequence of partial classifications, guided by the structure of the topic tree, using a specific set of features at each node in the hierarchy. anil@research.iiit.net, surana.h@gmail.com, karthikg@students.iiit.net</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories and Subject Descriptors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>Text search is a key step in any kind of information access.</p><p>For doing it effectively, we can use knowledge about the concerned writing systems. Methods based on such knowledge can give significantly better results for searching text, at least for some languages. This can improve information retrieval in particular and information access in general. In this paper, we present a method for fuzzy text search for languages which use Abugida scripts, e.g. Hindi, Bengali, Telugu, Amharic, Thai etc. We use characteristics of a writing system for fuzzy search and are able to take care of spelling variation, which is very common in these languages. Our method shows an improvement in F-measure of up to 30% over scaled edit distance.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories and Subject Descriptors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">MEASURING SURFACE SIMILARITY</head><p>In this section we will first formally define surface similarity measure and then describe a method to use this measure with reference to the background given in the previous sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Surface Similarity Measure</head><p>Surface similarity measure is a fuzzy measure of similarity between two strings or words. As mentioned earlier, it includes knowledge about the scripts. Formally, we can define this measure for Abugida scripts as follows:</p><p>where f is a function representing an alignment algorithm, w1 and w2 are the two words or strings to be compared, A is the alphabet, W is the set of orthographic features, P is the set of phonetic features, Wn and Pn are the sets of numerical values assigned to the orthographic and phonetic features, and D is a distance function for calculating the similarity between two letters.</p><p>To relate the parameters to the preceding and the following sections, f represents the modified DTW algorithm used by us, A represents the model of alphabet, W and P represent the orthographic and phonetic features (the model of phonology) and D represents the SDF. Note that D can itself be defined as: D = f (l1, l2, A, W, Wn, P, Pn)</p><p>where l1 and l2 are the two letters being compared as part of the alignment algorithm.</p><p>Another important point here is that this formulation allows a lot of flexibility with respect to the model of alphabet, the way orthographic and phonetic features are designed, the numerical values given to them, the distance function used to calculate the similarity of two letter, and the alignment algorithm used to align the strings or words. Therefore, the method used by us is, strictly speaking, just one instance of this type of methods. In other words, there is a scope of a lot of exploration here.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Information retrieval and Greek-Latin text</title>
		<author>
			<persName><forename type="first">T</forename><surname>Alevizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Galiotou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Skourlas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International online information meeting</title>
		<meeting><address><addrLine>London; Oxford, UK.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-06-12">1988. 06/12/1988</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="791" to="801" />
		</imprint>
	</monogr>
	<note>Learned Information Europe</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How do search engines respond to some non-English queries</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bar-Ilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="28" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A taxonomy of web search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<idno type="DOI">10.1145/792550.792552</idno>
		<ptr target="http://doi.acm.org/10.1145/792550.792552" />
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="10" />
			<date type="published" when="2002-09">2002. Sep. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Charting the Greek Web</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASIST&apos;04: American Society for Information Science and Technology Annual Conference</title>
		<meeting><address><addrLine>Providence, Rhode Island</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-11-13">2004. November 13-18, 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Which search engine is best at finding airline site home pages?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Griffiths</surname></persName>
		</author>
		<idno>01/45</idno>
		<ptr target="http://es.csiro.au/pubs/craswell_tr01.pdf" />
		<imprint>
			<date type="published" when="2001-03">March, 2001</date>
		</imprint>
	</monogr>
	<note type="report_type">CMIS Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<ptr target="http://www.internetworldstats.com/eu/gr.htm" />
	</analytic>
	<monogr>
		<title level="m">Internet Usage and Marketing report</title>
		<meeting><address><addrLine>Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-05-15">2007. May 15, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<ptr target="http://www.internetworldstats.com/stats7.htm" />
	</analytic>
	<monogr>
		<title level="m">Internet World Users By Language</title>
		<imprint>
			<date type="published" when="2007-03-19">2007. 3/19/07. May 15, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Suffix Stripping with Modern Greek</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Z</forename><surname>Kalamboukis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Program</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="321" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Do search engines understand Greek or user requests &quot;sound Greek&quot; to them?</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lazarinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Intelligence &amp; Intelligent Agent Technology, France)</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="43" to="46" />
		</imprint>
	</monogr>
	<note>Open Source Web Information Retrieval Workshop</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Our Blog is Growing Up, And So Has Our Index</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mayer</surname></persName>
		</author>
		<ptr target="http://www.ysearchblog.com/archives/000172.html" />
	</analytic>
	<monogr>
		<title level="j">Yahoo! Search Blog</title>
		<imprint>
			<date type="published" when="2005-08-08">2005. 8/8/05, retrieved May 15, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lost In Cyberspace: How Do Search Engines Handle Arabic Queries?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moukdad</surname></persName>
		</author>
		<ptr target="www.cais-acsi.ca/proceedings/2004/moukdad_2004.pdf" />
	</analytic>
	<monogr>
		<title level="m">Access to Information: Technologies, Skills, and Socio-Political Context. University of Manitoba</title>
		<meeting><address><addrLine>Winnipeg, Manitoba</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06-03">2004. June 3 -5, 2004</date>
		</imprint>
	</monogr>
	<note>Proceedings Editors: H. Julien and S. Thompson</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">How do search engines handle Chinese queries? Webology</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moukdad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<ptr target="http://www.webology.ir/2005/v2n3/a17.html" />
		<imprint>
			<date type="published" when="2005-10">2005. October, 2005</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><surname>Appendix</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">List of search engines used in the study</title>
		<ptr target="http://www.a9.com/)" />
	</analytic>
	<monogr>
		<title level="j">Global Search Engines: A</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="http://www.google.com.gr/)" />
		<title level="m">Google</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><surname>Yahoo</surname></persName>
		</author>
		<ptr target="http://www.yahoo.com/)" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="http://www.altavista.com/)" />
		<title level="m">Altavista</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><surname>Msn</surname></persName>
		</author>
		<ptr target="http://www.msn.com/)" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<ptr target="http://www.anazitisis.gr/)" />
		<title level="m">Greek Search Engines: Anazitisis</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ano-Kato</surname></persName>
		</author>
		<ptr target="http://www.ano-kato.com/)" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><surname>Phantis</surname></persName>
		</author>
		<ptr target="http://www.phantis.gr/)" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<ptr target="http://www.trinity.gr/)" />
		<title level="m">Trinity</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<ptr target="http://www.visto.gr/)" />
		<title level="m">Visto</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Disentangling from babylonian confusion -unsupervised language identification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teresniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing, 6th International Conference, CICLing 2005</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</editor>
		<meeting><address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">February 13-19, 2005. 2005</date>
			<biblScope unit="volume">3406</biblScope>
			<biblScope unit="page" from="773" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Automatic language identification bibliography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Caseiro</surname></persName>
		</author>
		<ptr target="http://www.phys.uni.torun.pl/kmk/projects/ali-bib" />
		<imprint>
			<date type="published" when="1999">May 2005. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">N-gram-based text categorization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Cavnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Trenkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval</title>
		<meeting>SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval<address><addrLine>Las Vegas, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="161" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Identification of document language is not yet a completely solved problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIMCA &apos;06: Proceedings of the International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="212" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Identification of document language in hard contexts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G P</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGIR 2006 Workshop on New Directions in Multilingual Information Access</title>
		<meeting>the SIGIR 2006 Workshop on New Directions in Multilingual Information Access<address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gauging Similarity with n-Grams: Language-Independent Categorization of Text</title>
		<author>
			<persName><forename type="first">M</forename><surname>Damashek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="issue">5199</biblScope>
			<biblScope unit="page" from="843" to="848" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prefixing versus suffixing in inflectional morphology</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Dryer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">World Atlas of Language Structures</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Comrie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Dryer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Gil</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Haspelmath</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="110" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Statistical identification of language</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dunning</surname></persName>
		</author>
		<idno>MCCS-94-273</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>Computing Research Lab (CRL), New Mexico State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Techical Report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Comparing two language identification schemes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The proceedings of 3rd International Conference on Statistical Analysis of Textual Data (JADT 95)</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bolasco</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Lebart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Salem</surname></persName>
		</editor>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-12">Dec. 1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A naive theory of morphology and an algorithm for extraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hammarström</surname></persName>
		</author>
		<ptr target="http://www.cs.chalmers.se/∼harald2/sigphon06.pdf" />
	</analytic>
	<monogr>
		<title level="m">SIGPHON 2006: Eighth Meeting of the Proceedings of the ACL Special Interest Group on Computational Phonology</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Wicentowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kondrak</surname></persName>
		</editor>
		<meeting><address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006-06-08">8 June 2006. 2006</date>
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reconsidering language identification for written language resources</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 5th International Conference on Language Resources and Evaluation (LREC2006)</title>
		<meeting>5th International Conference on Language Resources and Evaluation (LREC2006)<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="485" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Language identification, automatic</title>
		<author>
			<persName><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Language and Linguistics</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Brown</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="508" to="510" />
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Language identification based on string kernels</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kruengkrai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srichaivattana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Communications and Information Technology</title>
		<imprint>
			<date type="published" when="2005">2005. 2005. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="926" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Automatic language identification of written texts</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Lins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gonçalves</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAC &apos;04: Proceedings of the 2004 ACM symposium on Applied computing</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1128" to="1133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A syllable-scale framework for language identification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="276" to="302" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Language identification in web pages</title>
		<author>
			<persName><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAC &apos;05: Proceedings of the 2005 ACM symposium on Applied computing</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="764" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Language identification: a solved problem suitable for undergraduate instruction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computing Sciences in Colleges</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="94" to="101" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Language identification from small text samples</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Quantitative Linguistics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="80" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automatic language identification</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Muthusamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Spitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Survey of the State of the Art in Human Language Technology</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cole</surname></persName>
		</editor>
		<meeting><address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Center for Spoken Language Understanding CSLU, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">of Language and Computers -Studies in Practical Linguistics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Poutsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics in the Netherlands 2001: Selected Papers from the Twelfth CLIN Meeting</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Mariët</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Nijholt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Hondorp</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="179" to="189" />
		</imprint>
	</monogr>
	<note>Applying monte carlo techniques to language identification</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Language identification for multilingual documents</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName><surname>Linguini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Management Information Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="71" to="102" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Language identification: Examining the issues</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sibun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Reynar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Symposium on Document Analysis and Information Retrieval</title>
		<meeting><address><addrLine>Las Vegas, Nevada, U.S.A.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="125" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Centroid-based language identification using letter feature set</title>
		<author>
			<persName><forename type="first">H</forename><surname>Takci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sogukpinar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing: 5th International Conference, CICLing 2004 Seoul</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</editor>
		<meeting><address><addrLine>Korea; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">February 15-21, 2004. 2004</date>
			<biblScope unit="volume">2945</biblScope>
			<biblScope unit="page" from="640" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Language identification in web documents using discrete HMMs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Xafopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kotropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Almpanidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="583" to="594" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">The Automatic Identification of Languages Using Linguistic Recognition Signals</title>
		<author>
			<persName><forename type="first">D.-V</forename><surname>Ziegler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>University of New York at Buffalo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Using the Web information structure for retrieving Web pages</title>
		<author>
			<persName><forename type="first">M</forename><surname>Adriani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pandugita</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="892" to="897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Probabilistic Models for Information Retrieval based on Divergence from Randomness</title>
		<author>
			<persName><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Glasgow</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Automatic construction of known-item finding test beds</title>
		<author>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2006</title>
		<meeting>SIGIR 2006</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="603" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Overview of WebCLEF</title>
		<author>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes CLEF 2006</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Nardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Vicedo</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">N-Gram-Based Text Categorization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Cavnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Trenkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SDAIR&apos;94</title>
		<meeting>SDAIR&apos;94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="161" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Overview of the TREC-2004 Web track</title>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TREC-2004</title>
		<meeting>TREC-2004</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2003 Web track</title>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TREC-2003</title>
		<meeting>TREC-2003</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Web page retrieval by combining evidence</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Figuerola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L A</forename><surname>Berrocal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">F Z</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R V</forename><surname>De Aldana</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="880" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Cross language information retrieval: a research roadmap</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="72" to="80" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A failure analysis on the limitations of suffixing in an online environment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 1987</title>
		<meeting>SIGIR 1987</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="102" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A study of the dirichlet priors for term frequency normalisation</title>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2005</title>
		<meeting>SIGIR 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="465" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Web retrieval experiments with the EuroGOV</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Strötgen</surname></persName>
		</author>
		<ptr target="http://research.nii.ac.jp/ntcir/" />
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="837" to="845" />
		</imprint>
	</monogr>
	<note>University of Hildesheim</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Combination methods for crosslingual Web retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sigurbjörnsson</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="856" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">University of Glasgow at TREC 2006: Experiments in Terabyte and Enterprise Tracks with Terrier</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TREC-2006</title>
		<meeting>TREC-2006</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">University of Glasgow at TREC 2005: Experiments in Terabyte and Enterprise Tracks with Terrier</title>
		<author>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings TREC-2005</title>
		<meeting>TREC-2005</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">University of Glasgow at WebCLEF 2005: Experiments in per-field normalisation and language specific stemming</title>
		<author>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="898" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">University of Alicante at the CLEF 2005 WebCLEF track</title>
		<author>
			<persName><forename type="first">T</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Noguera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="865" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">MIRACLE at WebCLEF 2005: Combining Web specific and linguistic information</title>
		<author>
			<persName><forename type="first">Á</forename><surname>Martínez-González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De Pablo-Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Villena-Román</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="869" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of OSIR 2006</title>
		<meeting>OSIR 2006</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A day in the life of Web searching: an exploratory study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ozmutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Spink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Ozmutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="345" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Accessing Multilingual Information Repositories, 6th Workshop of the Cross-Language Evalution Forum, CLEF 2005</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-09-23">21-23 September, 2005. 2006</date>
			<biblScope unit="volume">4022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Simple BM25 extension to multiple weighted fields</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM 2004</title>
		<meeting>CIKM 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">EuroGOV: Engineering a multilingual Web corpus</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sigurbjörnsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="825" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Overview of WebCLEF</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sigurbjörnsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="810" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Danish and Greek Web search experiments with Hummingbird SearchServer TM at CLEF 2005</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tomlinson</surname></persName>
		</author>
		<editor>Peters et al.</editor>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="846" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval. Butterworths</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Latin-Greek spelling in e-mail messages: usage and attitudes. (in Greek)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in Greek Linguistics</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Transliteration practice and discourse in a setting of computer-mediated digraphia. Standard Languages and Language Standards: Greek, Past and Present</title>
		<author>
			<persName><forename type="first">J</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName><surname>Greeklish</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">ASDA Greek-to-Greeklish converter</title>
		<ptr target="http://home.asda.gr/active/GrLish2.asp" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">How do search engines respond to some non-English queries</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bar-Ilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="28" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">All Greek to me! An automatic Greeklish to Greek transliteration system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chalamandaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Protopapas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tsiakoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raptis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5 th Intl. Conference in Language Resources and Evaluation</title>
		<meeting>the 5 th Intl. Conference in Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1226" to="1229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Web searching in Chinese: a study of a search engine in Hong Kong</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1004" to="1054" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Adaptive support for crosslanguage text retrieval</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Deluca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nurnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Intl. Conference in Adaptive Hypermedia and Adaptive Web-Based Systems</title>
		<meeting>the Intl. Conference in Adaptive Hypermedia and Adaptive Web-Based Systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="425" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Cross-language information retrieval: the way ahead</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="431" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">An experimental interface for automatic transliteration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karakos</surname></persName>
		</author>
		<author>
			<persName><surname>Greeklish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Inf. Science &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1069" to="1074" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Greeklish and Greekness: Trends and Discourses of &quot;Glocalness</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koutsogiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mitsikopoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Mediated Communication</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Information retrieval from fulltext Arabic databases: can search engines designed for English do the job?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moukhad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Large</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Libri</publisher>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Mining answers in German web pages</title>
		<author>
			<persName><forename type="first">G</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Web Intelligence</title>
		<meeting>the Conference on Web Intelligence</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Use of a Morphosyntactic lexicon as the basis for the implementation of the Greek wordnet. In the 2 nd Intl</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stamou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsakou</surname></persName>
		</author>
		<author>
			<persName><surname>Tsalidis Ch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tzagarakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vagelatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Conference</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">How do Greek Searchers Form their Web Queries?</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lazarinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3 rd Intl. WebIST Conference</title>
		<meeting>the 3 rd Intl. WebIST Conference</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="404" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Supporting multilingual information retrieval in web applications: an English-Chinese web portal experiment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 6 th Intl. Conference on Asian Digital Libraries</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="149" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Understanding user goals in web search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Levinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Intl. World Wide Web Conference</title>
		<meeting>the Intl. World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="13" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Web search engines for Polish information retrieval: questions of search capabilities and retrieval performance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sroka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Library Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Greek-Greeklish converted</title>
		<author>
			<persName><surname>Translatum</surname></persName>
		</author>
		<ptr target="http://www.translatum.gr/converter/greeklish-converter.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<author>
			<persName><surname>Tsik Greeklish</surname></persName>
		</author>
		<ptr target="ttp://www2.cs.ucy.ac.cy/~tsik/others.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">MyGreeklish to standard Greeklish translator needed</title>
		<author>
			<persName><forename type="first">M</forename><surname>Varouta</surname></persName>
		</author>
		<ptr target="http://www.proz.com/translation-articles/articles/930/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Another stemmer</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Paice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR Forum</title>
		<imprint>
			<date type="published" when="1990">1990. 1990</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="56" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Evaluation of n-grams conflation approach in text-based information retrieval</title>
		<author>
			<persName><forename type="first">Serhiy</forename><surname>Kosinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th String Processing and Information Retrieval Symposium</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="136" to="142" />
		</imprint>
	</monogr>
	<note>SPIRE 2001</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Stemming and n-gram matching for term conflation in Turkish texts</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Ekmekcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Research News</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="6" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Anew algorithm to generate Arabic root-pattern forms</title>
		<author>
			<persName><forename type="first">Al-Fedaghi</forename><surname>Sabah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Fawaz</forename><surname>Al-Anzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th National Computer Conference, King Fahd University of Petroleum &amp; Minerals</title>
		<meeting>the 11th National Computer Conference, King Fahd University of Petroleum &amp; Minerals<address><addrLine>Dhahran, Saudi Arabia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="4" to="07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Lost in Cyberspace: How do search engines handle Arabic queries?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moukdad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Access to Information: Technologies, Skills, and Socio-Political Context. Proceedings of the 32nd Annual Conference of the Canadian Association for Information Science</title>
		<meeting><address><addrLine>Winnipeg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06-03">2004. June 3-5, 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Information retrieval from full-text Arabic databases: Can search engines designed for English do the job?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moukdad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Large</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Libri</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="74" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Corpus-Based Stemming using Co-occurrence of Word Variants</title>
		<author>
			<persName><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno>TR96-67</idno>
	</analytic>
	<monogr>
		<title level="m">ACM TOIS</title>
		<imprint>
			<date type="published" when="1996">Jan. 1998. 1996</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="61" to="81" />
		</imprint>
		<respStmt>
			<orgName>Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">On designing an automated Malaysian stemmer for the Malay language. (poster)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Abdullah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth international workshop on information retrieval with Asian languages</title>
		<meeting>the fifth international workshop on information retrieval with Asian languages<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="207" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Processing morphological variants in searches of Latin text</title>
		<author>
			<persName><forename type="first">M</forename><surname>Greengrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Robyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information research news</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2" to="5" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Indexing the Indonesian web: Language identification and miscellaneous issues</title>
		<author>
			<persName><forename type="first">V</forename><surname>Berlian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bressan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth International World Wide Web Conference</title>
		<meeting><address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Improving precision in information retrieval for Swedish using stemming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carlberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dalianis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Knutsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NODALIDA &apos;01 -13th Nordic conference on computational linguistics</title>
		<meeting>NODALIDA &apos;01 -13th Nordic conference on computational linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Viewing stemming as recall enhancement</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pohlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR96</title>
		<meeting>ACM SIGIR96</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Shallow morphological analysis in monolingual information retrieval for Dutch, German and Italian</title>
		<author>
			<persName><forename type="first">Monz</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evaluation of Cross-Language Information Retrieval Systems</title>
		<title level="s">Lecture Notes in Computer Science.</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001. 2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="262" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">West group at CLEF 2000: Non-English monolingual retrieval</title>
		<author>
			<persName><forename type="first">I</forename><surname>Moulinier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcculloh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Crosslanguage information retrieval and evaluation: Proceedings of the CLEF 2000 workshop</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">The effectiveness of stemming for natural-language access to Slovene textual data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASIS</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="384" to="390" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Stemming Arabic</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khoja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garside</surname></persName>
		</author>
		<ptr target="www.comp.lancs.ac.uk/computing/users/khoja/stemmer.ps" />
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Lancaster</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computing Department,Lancaster University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Arabic Computational Morphology: Knowledge-based and Empirical Methods</title>
		<author>
			<persName><forename type="first">L</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Kluwer/Springer&apos;s series on Text, Speech, and Language Technology</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Soudi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Van Den Bosch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Neumann</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Light Stemming for Arabic IR</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Detecting Inflection Patterns in NL by Minimization of Morphological Model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIARP 2004</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3287</biblScope>
			<biblScope unit="page" from="432" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Buckwalter Arabic Morphological Analyzer Version 1.0 www.ldc.upenn.edu/Catalog/CatologE ntry</title>
		<author>
			<persName><forename type="first">T</forename><surname>Buckwalter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2002L49</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">An algorithm for suffix stripping</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">A morphologically sensitive clustering algorithm for identifying Arabic roots</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>De Roeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Al-Fares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ACL-2000</title>
		<meeting>ACL-2000<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">An Arabic Morphological analyzer</title>
		<author>
			<persName><forename type="first">K</forename><surname>Darwish</surname></persName>
		</author>
		<ptr target="http://www.glue.umd.edu/~Kareem/research/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">The use of an association measure based on character structure to identify semantically related pairs of words and document titles</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boreham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Storage and Retrieval</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="253" to="260" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">JHU/APL at TREC 2001: Experiments in Filtering and in Arabic, Video, and Web Retrieval</title>
		<author>
			<persName><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Piatko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Text Retrieval Conference</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Tenth Text Retrieval Conference<address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">2001. July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Term selection for searching printed Arabic</title>
		<author>
			<persName><forename type="first">K</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual international ACM SIGIR conference on research and development in information retrieval (SIGIR--2002)</title>
		<meeting>the 25th annual international ACM SIGIR conference on research and development in information retrieval (SIGIR--2002)<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Character contiguity in N-grambased word matching: the case for Arabic text searching</title>
		<author>
			<persName><forename type="first">H</forename><surname>Suleiman</surname></persName>
		</author>
		<author>
			<persName><surname>Mustafa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">formation Processing and Management</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="819" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Arabic Text Classification Using N-Gram Frequency Statistics A Comparative Study</title>
		<author>
			<persName><forename type="first">Laila</forename><surname>Khreisat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2006 International Conference on Data Mining Part of the 2006 World Congress in Computer Sciences DMIN</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="78" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<author>
			<persName><forename type="first">Badam-Osor</forename><surname>Khaltar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tetsuya</forename><surname>Ishikawa</surname></persName>
		</author>
		<title level="m">Extracting loanwords from Mongolian corpora and producing a a Japanese-Mongolian bilingual dictionary , Annual Meeting of the ACL Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL</title>
		<meeting><address><addrLine>Sydney, Australia Pages</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
	<note>Year of Publication</note>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">MultiSpell: an N-Gram Based Language-Independent Spell Checker</title>
		<author>
			<persName><forename type="first">Farag</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernesto</forename><forename type="middle">William</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Poster-Proceedings of Eighth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2007)</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">EUSLEM: A lemmatiser / Tagger for Basque</title>
		<author>
			<persName><forename type="first">I</forename><surname>Aduriz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aldezabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Alegria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Artola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ezeiza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urizar</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://ixa.si.ehu.es/Ixa/Argitalpenak/Artikuluak/100091163" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Euralex Conference</title>
		<meeting>Euralex Conference<address><addrLine>Göteborg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
	<note>Also [online</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">EDBL: a Multi-Purpose Lexical Support for the Treatment of Basque</title>
		<author>
			<persName><forename type="first">I</forename><surname>Aduriz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aldezabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ansa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Artola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diaz De Ilarraza</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://ixa.si.ehu.es/Ixa/Argitalpenak/Artikuluak/100091170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Language Resources and Evaluation</title>
		<meeting>the First International Conference on Language Resources and Evaluation<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>II 821-826. Also [online</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Automatic morphological analysis of Basque</title>
		<author>
			<persName><forename type="first">I</forename><surname>Alegria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Artola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sarasola</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://hal.ccsd.cnrs.fr/docs/00/08/13/51/PDF/96LITER_M.pdf&gt;" />
	</analytic>
	<monogr>
		<title level="m">Literary &amp; Linguistic Computing</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Natural Language Technology in Precision Content Retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ambroziak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://www.sun.com/research/techrep/1998/smli_tr-98-69.pdf&gt;" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference of Natural Language Processing and Industrial Applications</title>
		<meeting>the International Conference of Natural Language Processing and Industrial Applications<address><addrLine>Moncton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Also [online</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Expectations versus reality -Search engine features needed for Web research at mid 2005. In Cybermetrics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bar-Ilan</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://www.cindoc.csic.es/cybermetrics/articles/v9i1p2.html&gt;" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Scientometrics, Informetrics and Bibliometrics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>nº 1 paper 2. Also [online</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">How do search engines handle non-English queries? -A case study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bar-Ilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://www2003.org/cdrom/papers/alternate/P415/415.pdf&gt;" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12 th international World Wide Web Conference</title>
		<meeting>the 12 th international World Wide Web Conference<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="415" to="424" />
		</imprint>
	</monogr>
	<note>Also [online</note>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">How do search engines respond to some non-English queries?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bar-Ilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="13" to="28" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Searching a small national domain -a preliminary report</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sarlós</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Windhager</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://www2003.org/cdrom/papers/poster/p184/p184-benczur.html&gt;" />
	</analytic>
	<monogr>
		<title level="m">Poster of the 12 th international World Wide Web Conference</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">184</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Tauglichkeit von Suchmaschinen für deutschesprachige Abfragen</title>
		<author>
			<persName><forename type="first">E</forename><surname>Guggenheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bar-Ilan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information, Wissenschaft und Praxis</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Automatic search term variant generation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Tait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Documentation</title>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="50" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Using the web to obtain frequencies for unseen bigrams</title>
		<author>
			<persName><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://acl.ldc.upenn.edu/J/J03/J03-3005.pdf&gt;" />
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="459" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Googleology is bad science</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="147" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Viewing morphology as an inference process</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16 th annual international ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 16 th annual international ACM SIGIR conference on Research and Development in Information Retrieval<address><addrLine>Pittsburgh, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Natural languages and the world wide web</title>
		<author>
			<persName><forename type="first">S</forename><surname>Langer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bulletin de linguistique appliquée et générale</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="89" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Aggressive morphology for robust lexical coverage</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://acl.ldc.upenn.edu/A/A00/A00-1030.pdf&gt;" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Applied Natural Language Processing</title>
		<meeting>the Sixth Conference on Applied Natural Language Processing<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="218" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Linguistic knowledge can improve information retrieval</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Bookman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Kuhns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<idno>date: 2007-05-20</idno>
		<ptr target="&lt;http://acl.ldc.upenn.edu/A/A00/A00-1036.pdf&gt;" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Applied Natural Language Processing</title>
		<meeting>the Sixth Conference on Applied Natural Language Processing<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="262" to="267" />
		</imprint>
	</monogr>
	<note>Also [online</note>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Cross-language information retrieval using ontology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abdelali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Farwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ogden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Helmreich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Traitement Automatique des Langues Conference (TALN 2003)</title>
		<meeting>the Traitement Automatique des Langues Conference (TALN 2003)<address><addrLine>Batz-sur-Mer, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">What do people want from information retrieval? (the top 10 research issues for companies that use and sell ir systems)</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-11">November, 1995</date>
			<publisher>D-Lib Magazine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Multilexexplorer: Combining multilingual web search with multilingual lexical resources</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hauke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schlechtweg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the combined Workshop on Language-Enabled Educational Technology and Development and Evaluation of Robust Spoken Dialogue Systems</title>
		<meeting>the combined Workshop on Language-Enabled Educational Technology and Development and Evaluation of Robust Spoken Dialogue Systems<address><addrLine>Riva del Garda, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
	<note>Conjunction with ECAI&apos;06</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Using multilingual ontologies for adaptive web-based language exploration</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hauke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schlechtweg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Applications of Semantic Web Technologies for E-Learning</title>
		<meeting>the International Workshop on Applications of Semantic Web Technologies for E-Learning<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>AH</publisher>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
	<note type="report_type">SW-EL06</note>
	<note>Conjunction with the International Conference on Adaptive Hypermedia and Adaptive Web-Based Systems</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Improving ontology-based sense folder classification of document collections with clustering methods</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Workshop on Adaptive Multimedia Retrieval</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Detyniecki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</editor>
		<meeting>the 2nd International Workshop on Adaptive Multimedia Retrieval</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>AMR 2004), part of ECAI 2004</note>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Supporting mobile web search by ontology-based categorization</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sprachtechnologie, mobile Kommunikation und linguistische Ressourcen, Proceedings of GLDV 2005</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Fisseni</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-C</forename><surname>Schmitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schröder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="28" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Lexires: A tool for exploring and restructuring eurowordnet for information retrieval</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">conjunction with the 17th European Conference on Artificial Intelligence (ECAI&apos;06)</title>
		<meeting><address><addrLine>Riva del Garda, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Proceedings of the Workshop on Text-based Information Retrieval (TIR-06)</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Rebuilding lexical resources for information retrieval using sense folder detection and merging methods</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006)</title>
		<meeting>the 5th International Conference on Language Resources and Evaluation (LREC 2006)<address><addrLine>Genova, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">The use of lexical resources for sense folder disambiguation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop Lexical Semantic Resources (DGfS-06)</title>
		<meeting><address><addrLine>Bielefeld, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Survey: Multilingual text retrieval and access</title>
		<author>
			<persName><forename type="first">H</forename><surname>Haddouti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technical Report review issue</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>FORWISS (Bavarian Research Center for Knowledge-Based Systems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Converting eurowordnet in owl and extending it with domain ontologies</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W D</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nürnberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Lexical-Semantic and Ontological Resources</title>
		<meeting>the Workshop on Lexical-Semantic and Ontological Resources</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Conjunction with the GLDV Conference (GLDV 2007)</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">An introduction to rdf and the jena rdf api</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcbride</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boothby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dollin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Five papers on wordnet</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Lexicology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<title level="m" type="main">A survey of multilingual text retrieval</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<idno>CS-TR-3615</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Improving cross-language text retrieval with human interactions</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Ogden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HICSS</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Multilingual information access</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lectures on Information Retrieval, Third European Summer-School, ESSIR 2000</title>
		<meeting><address><addrLine>Varenna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Multiwordnet: developing an aligned multilingual database</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pianta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Girardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First International Conference on Global WordNet</title>
		<meeting><address><addrLine>Mysore, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Reach</surname></persName>
		</author>
		<title level="m">Global internet statistics</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title level="m" type="main">Computer-assisted language learning: concepts, contexts and practices</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Son</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>iUniverse</publisher>
			<pubPlace>Lincoln, NE</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Eurowordnet as a resource for cross-language information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004)</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation (LREC 2004)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<title level="m" type="main">Wordnet in rdfs and owl</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Assem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gangemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schreiber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>W3C</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">Eurowordnet general document, version 3, final</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vossen</surname></persName>
		</author>
		<ptr target="www.illc.uva.nl/EuroWordNet/docs/GeneralDocPS.zip" />
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Options For Presentation of Multi-Lingual Text: Use Of the Unicode Standard</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Erickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Library Hi Tech</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Unicode and Arabic Script, Workshop &quot;Unicode Und Mehrschriftlichkeit In Katalogen</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lutz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Sbb Pk, Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Orthographic Diacritics and Multilingual Computing, Language Problems and Language Planning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Wells</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<monogr>
		<ptr target="Http://www.Unicode.org/" />
		<title level="m">The Unicode Standard At</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Typological Features Of Farsi</title>
		<author>
			<persName><forename type="first">I</forename><surname>Samare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Of Linguistics</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="1990">1990</date>
			<publisher>Iran University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<monogr>
		<title level="m" type="main">Suffix Derivation in Contemporary Farsi</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keshani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Iran University Press</publisher>
		</imprint>
	</monogr>
	<note>First Edition</note>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Processing Farsi Text: Tokenization In The Shiraz Project</title>
		<author>
			<persName><forename type="first">Karine</forename><forename type="middle">M</forename><surname>Zajac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nmsu, Crl, Memoranda In Computer And Cognitive Scienc</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Qasemizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Farsi</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><surname>Morphology</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">11 th Computer Society of Iran Computer Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>IPM, Tehran, Iran</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Tokenizing an Arabic Script Language</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rezaie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Arabic Language Processing: Status and Prospects, Acl/Eacl</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Iran&apos;s Academy Of Farsi Language and Literature. Official Farsi Orthography</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>3 rd Edition</note>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Information Technology -Farsi Information Interchange and Display Mechanism Using Unicode</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="volume">6219</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Persian in MULTEXT-East Framework</title>
		<author>
			<persName><forename type="first">B</forename><surname>Qasemizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahimi</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FinTAL</title>
		<imprint>
			<biblScope unit="volume">4139</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="2006">2006. 2006</date>
			<publisher>Springer Publisher</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Instance-based learning algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Aha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="37" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">An object-based approach to managing domain specific thesauri: semiautomatic thesaurus construction and query-based browsing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<idno>TR 98/11</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Chonbuk National University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">A fast algorithm for hierarchical text classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tiyyagura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Giuffrida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2nd Int. Conf. on Data Warehousing and Knowledge Discovery (DaWaK&apos;00)</title>
		<meeting>of the 2nd Int. Conf. on Data Warehousing and Knowledge Discovery (DaWaK&apos;00)<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="409" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Hierarchical classification of Web content</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM-SIGIR-00, 23rd ACM Int. Conf. on Research and Development in Information Retrieval</title>
		<meeting>of ACM-SIGIR-00, 23rd ACM Int. Conf. on Research and Development in Information Retrieval<address><addrLine>Athens, GR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="256" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Estimating Continuous Distributions in Bayesian Classifiers</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eleventh Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>of the Eleventh Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="338" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Hierarchically classifying documents using very few words</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 14th Int. Conf. on Machine Learning</title>
		<meeting>of 14th Int. Conf. on Machine Learning<address><addrLine>Nashville, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="170" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
		<title level="m">Foundations of Statistical Natural Language Processing</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Learning to classify text from labeled and unlabeled documents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 15th National Conference on Artifical Intelligence, AAAI-98</title>
		<meeting>of the 15th National Conference on Artifical Intelligence, AAAI-98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main">Fast Training of Support Vector Machines using Sequential Minimal Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<editor>B. Schoelkopf, C. Burges, and A. Smola</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Advances in Kernel Methods -Support Vector Learning</note>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title level="m" type="main">Automatic text processing</title>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Salton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Machine learning in automated text categorization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Effective Use of Natural Language Processing Techniques for Automatic Conflation of Multi-Word Terms: The Role of Derivational Morphology, Part of Speech Tagging, and Shallow Parsing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tzoukermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jacquemin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>of ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="148" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<title level="m">Frank Data Mining: Practical machine learning tools and techniques</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<monogr>
		<title level="m" type="main">Indian standard code for information interchange (iscii)</title>
		<author>
			<persName><surname>Bis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Issues in building general letter to sound rules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESCA Synthesis Workshop, Australia</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="164" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<author>
			<persName><forename type="first">C-Dac</forename></persName>
		</author>
		<ptr target="http://www.cdac.in/html/gist/standard.asp" />
		<title level="m">Standards for indian languages in it</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<title level="m" type="main">Writing Systems: An Introduction to their Linguistic Analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Coulmas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">A language-independent, data-oriented architecture for grapheme-to-phoneme conversion</title>
		<author>
			<persName><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Bosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ESCA-IEEE&apos;94</title>
		<meeting>ESCA-IEEE&apos;94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">A technique for computer detection and correction of spelling errors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Damerau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">171176</biblScope>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<title level="m" type="main">The World&apos;s Writing Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Measuring language divergence by intra-lexical comparison</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Ellison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">India as a linguistic area</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Emeneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Bi-directional conversion between graphemes and phonemes using a joint n-gram model</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ISCA Tutorial and Research Workshop on Speech Synthesis</title>
		<meeting>the 4th ISCA Tutorial and Research Workshop on Speech Synthesis</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">OM: One Tool for Many (Indian) Languages</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ganapathiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICUDL: International Conference on Universal Digital Library</title>
		<meeting><address><addrLine>Hangzhou</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">Ethnologue: Languages of the world</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gordon</surname></persName>
		</author>
		<ptr target="http://www.ethnologue.com/web.asp" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>fifteenth edition</note>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">An introduction to indic scripts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ishida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Int. Unicode Conference</title>
		<meeting>the 22nd Int. Unicode Conference</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<monogr>
		<title level="m" type="main">Grapheme based speech recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Killer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schultz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Comparison of phonological representations for the grapheme-to-phoneme mapping</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kopytonenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lyytinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krkkinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Constraints on Spelling Changes: Fifth International Workshop on Writing Systems</title>
		<meeting><address><addrLine>Nijmegen, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<monogr>
		<title level="m" type="main">Found resources: Hindi</title>
		<author>
			<persName><surname>Ldc</surname></persName>
		</author>
		<ptr target="http://lodl.ldc.upenn.edu/found.cgi?lan=HINDI" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Exploring Distributional Similarity Based Models for Query Spelling Correction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Web-based acquisition of japanese katakana variants</title>
		<author>
			<persName><forename type="first">T</forename><surname>Masuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="338" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Automatic Construction of Japanese KATAKANA Variant List from Large Corpus</title>
		<author>
			<persName><forename type="first">T</forename><surname>Masuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Computational Linguistics (COLING04)</title>
		<meeting>the 20th International Conference on Computational Linguistics (COLING04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1214" to="1219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">A comparative study of several dynamic time-warping algorithms for connected word recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Bell System Technical Journal</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1389" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Detecting transliterated orthographic variants via two similarity metrics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sekiguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">The double metaphone search algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">/C++ Users Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">WebKhoj: Indian language IR from multiple character encodings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jagarlamudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th international conference on World Wide Web</title>
		<meeting>the 15th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="801" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Graphemes are perceptual reading units</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Zieglerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Jacobse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">A computational phonetic model for indian language scripts</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Constraints on Spelling Changes: Fifth International Workshop on Writing Systems</title>
		<meeting><address><addrLine>Nijmegen, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title level="m" type="main">Using a model of scripts for shallow morphological analysis given an unannotated corpus. Workshop on Morpho-Syntactic Analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Surana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Pathum Thani, Thailand</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Study of cognates among south asian languages for the purpose of building lexical resources</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Surana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of National Seminar on Creation of Lexical Resources for Indian Language Computing and Processing</title>
		<meeting>National Seminar on Creation of Lexical Resources for Indian Language Computing and Processing<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Can corpus based measures be used for comparative study of languages?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Surana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop Computing and Historical Phonology</title>
		<meeting>the ACL Workshop Computing and Historical Phonology<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Brahmi scripts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sproat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Constraints on Spelling Changes: Fifth International Workshop on Writing Systems</title>
		<meeting><address><addrLine>Nijmegen, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">A formal computational analysis of indic scripts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sproat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Indic Scripts: Past and Future</title>
		<meeting><address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<title level="m" type="main">A Computational Theory of Writing Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sproat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Nijmegen, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<title level="m" type="main">List of languages by number of native speakers</title>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/List" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<monogr>
		<title level="m" type="main">Writing system</title>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/Writingsystem" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
