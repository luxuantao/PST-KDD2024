<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcdonnell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Waagen</surname></persName>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EECE749C70E900B4D78C1D1C1039637A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Absfract43volutionary programming, a systematic multi-agent stochastic search technique, is used to generate recurrent perceptrons (nonlinear IIR filters). A hybrid optimization scheme is proposed that embeds a single-agent stochastic search technique, the method of Solis and Wets, into the evolutionary programming paradigm. The proposed hybrid optimization approach is further augmented by "blending" randomly selected parent vectors to create additional offspring. The first part of this work investigates the performance of the suggested hybrid stochastic search method. After demonstration on the Bohachevsky and Rosenbrock response surfaces, the hybrid stochastic optimization approach is applied in determining both the model order and the coefficients of recurrent perceptron time-series models. An information criterion is used to evaluate each recurrent perceptron structure as a candidate solution. It is speculated that the stochastic training method implemented in this study for training recurrent perceptrons can be used to train perceptron networks that have radically recurrent architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evolving Recurrent Perceptrons</head><p>for Time-Series Modeling</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RTIFICIAL neural networks with recurrent connections</head><p>A represent an altemative to feedforward networks for nonlinear models of time-series data. Feedback connections allow for the feedforward information to be distributed back into the network, and may result in increasingly complex nonlinear manifolds with an increasing order of recurrency. This work demonstrates the application of the evolutionary search method in "evolving" simple recurrent perceptrons that may serve as building blocks for more complicated structures.</p><p>Once feasibility is demonstrated for simple recurrent perceptron structures, the evolutionary search method can then be applied to highly recurrent perceptron networks with complex architectures. Stochastic methods are an attractive training option for complicated architectures because they are not constrained to a specific network topology. This feature allows both the network structure and weights to be determined during the training process. Simultaneously determining both perceptron weights and structure requires a procedure that is amenable to combinatorial optimization problems. Successful algorithms for these types of problems have generally been stochastic search techniques such as simulated annealing [ 11, genetic algorithms the ability to determine model structure <ref type="bibr">[5]</ref>, and the ability to train neural networks <ref type="bibr">[6]</ref>.</p><p>The "perceptron" in this study refers to a recursive adaptive filter with an arbitrary output function. <ref type="bibr">Fig. ]</ref>(a) shows the proposed perceptron structure or nonlinear IIR filter. <ref type="bibr">Fig. l(b)</ref> shows a linear-nonlinear architecture, although, as will be seen in the later studies, the linear activation function could be replaced by one that is nonlinear. This recurrent perceptron model is inspired by the structure of infinite impulse response (IIR) filters and is postulated for time-series modeling. This work applies an evolutionary or systematic multi-agent stochastic search to determine the order of the recurrent perceptron structure as well as the tapped-delay line weights. Modifications to the perceptron topology are accomplished by either increasing or decreasing the number of tapped delays on the input or feedback lines, respectively. These structural modifications are limited to a random change of plus or minus one tapped delay on a randomly selected line. Since the model is determined during training, a possibility exists that nonlinear finite impulse response (FIR) perceptrons will result should the feedback order become zero. <ref type="bibr">Williams [7]</ref> characterizes recurrency based on its utilization in a connectionist architecture. Conservative recurrence corresponds to a tapped-delay input signal and is termed a 1045-9227/94$04.00 0 1994 IEEE rransversal filter network. This approach yields a network that is sensitive to temporal pattems without directly incorporating recurrent units. Transversal filter networks have been widely applied in the field of speech recognition (e.g., <ref type="bibr">Waibel et al. [SI)</ref>. Liberal recurrence is the feedback from the output to the input units and corresponds to a nonlinear multi-input, multioutput (MIMO) IIR filter. Williams assigns the term recursive filter to transversal filter networks with tapped-delays on the output line feeding back as inputs. Radical recurrence refers to recurrent networks that model systems with strongly hidden states. By definition, if a system has a weakly visible state, it can be modeled with either the transversal or recursive filter networks. The radical approach allows coupling effects that are not possible with the more traditional transversal and recursive filter approaches. Both structures shown in Fig. <ref type="figure">1</ref> have liberal recurrence with the potential to reduce to conservative recurrence during the evolutionary training process.</p><p>Feedforward networks have been successfully used for both time-series prediction and system modeling, generally using tapped-delay, or transversal filter, network structures. However, these networks are not necessarily the typical feedforward configuration trained solely by error backpropagation. For example, a Connectionist Normalized Linear Spline Network (CNLS) has been formulated by the Center for Nonlinear Studies at Los Alamos National  Pruning connections <ref type="bibr">[12-131 or</ref> weight sharing <ref type="bibr" target="#b12">[14]</ref> can improve generalization capabilities as well as increase processing throughput, since architecture size is reduced. Using only the most recent observation, Rao and Ramamurti <ref type="bibr" target="#b13">[15]</ref> generate a radically recurrent network based upon a cascade-correlation [ 161 approach.</p><p>Saravanan [17] utilizes a purely recurrent structure so that next-step estimates are only a function of previous estimates. This network is trained using evolutionary search methods Recurrent neural network structures have also been successfully trained using EP by <ref type="bibr">McDonnell and Waagen [18]</ref> and Angeline et al. <ref type="bibr" target="#b17">[19]</ref>. Other types of recursive structures that have been evolved include finite state machines [3] and the order and coefficients of ARMA models <ref type="bibr">[5]</ref>, <ref type="bibr">[20]</ref>. While "optimal prediction can be thought of, quite simply, in terms of optimal filtering in absence of measurements" [ 2 11, practical applications make use of recent observations. Li and Haykin <ref type="bibr" target="#b20">[22]</ref> and <ref type="bibr">McDonnell and Waagen [18]</ref> utilize both a window of observations and a window of previous estimates for nonlinear time-series prediction. If an event occurs which precludes making an observation, then substitution of the estimate for past observations may suffice, depending on the accuracy of the model and noise levels.</p><p>The combination of more efficient local search methods with global techniques is appealing. As Yao <ref type="bibr" target="#b21">[23]</ref> states, "the efficiency of evolutionary training can be improved by incorporating a local search procedure into the evolution." However, this requirement may limit the applicability of the global search method to specific types of architectures since local search techniques are somewhat restrictive. To alleviate this concem and maintain the integrity of the stochastic search, only direct search methods are considered for being embedded into EP. This rationale was successfully used in the development of the stochastic direction algorithm by Waagen et al. <ref type="bibr" target="#b22">[24]</ref>.</p><p>Before discussing the optimization of recurrent perceptrons, Section I1 describes and demonstrates a hybrid optimization approach that combines the Solis and Wets random optimization technique and EP. Variants of both methods are applied to finding extrema of an unknown function. A hybrid strategy is subsequently developed that embeds the Solis and Wets technique within EP. Once the hybrid approach has been successfully demonstrated, the recurrent perceptron structure is discussed in Section 111. Results are then given in Section IV for evolving recurrent perceptron next-step predictors for a variety of time-series data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">MULTI-AGENT STOCHASTIC SEARCH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Benefits of Stochastic Optimization</head><p>As a direct search method, stochastic optimization does not require derivatives of the objective function nor continuity of the response surface <ref type="bibr">[25]</ref>. The advantages of random search methods include ease of implementation, insensitivity to the type of criterion function, efficiency, flexibility, and the generation of information about the response surface <ref type="bibr">[26]</ref>. Efficiency refers to the allocation of resources for evaluating additional points on the response surface versus deciding which point to evaluate next. Of course, this can be detrimental if the criterion function requires an extensive amount of computation. If it is computationally expensive to evaluate the objective function, then the information generated during the course of the stochastic search can be used to direct the search procedure. <ref type="bibr">Pierre [27]</ref> stipulates that the following search evaluation criteria should be considered before selecting any particular optimization strategy: " 1) How much computational equipment is required? 2) Has the search technique proved to be completely successful on similar types of performance measures? 3) What accuracy is required of the search? 4) What is a fair measure of the cost of the search? 5) How will the time spent in evaluating the performance measure and its derivative, if used, compare with the time spent on other aspects of the search?"</p><p>In response to these issues, some generalizations may be made with respect to evolutionary search strategies. 1) The computational resources must provide sufficient memory and processor power to conduct N separate searches, since evolutionary methods are based on multi-agent search strategies. Most implementations occur on serial platforms even though multi-agent search strategies are inherently parallelizable. Considerable computational resources may be required if the problem has an extremely high dimensionality. 2 ) As previously discussed, evolutionary search strategies are an excellent means to solve combinatorial optimization problems and discover globally optimal solutions. 3) The issue of accuracy has ramifications with respect to a priori knowledge of the response surface. If a correct model structure is assumed, evolutionary search strategies will, in general, tend to be slower than traditional optimization schemes. This results from the inefficiency of not using information about the gradient (although gradient methods can be incorporated in parallel with the evolutionary search strategy). However, the time complexity for evolutionary search does not necessarily increase dramatically with increased dimensionality [28] or additional constraints. In sum, evolutionary search strategies are robust across a broad spectrum of problem domains. 4) The number of function evaluations is a useful metric for comparing evolutionary search strategies. Time complexity or accuracy may serve as a useful metric for comparisons with other search methods. 5) The matter of efficiency is discussed in the previous paragraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . Single-Agent Stochastic Search</head><p>Random optimization has traditionally been based on singleagent stQchastic search (SASS) strategies. Both Rao <ref type="bibr">[25]</ref> and Kamop [261 generate a random walk sequence to an extremum by perturbing the search point with a uniform random variable. Rao also exploits the directionality of the randomly generated vectors that continue to yield lower valued objective functions. In an algorithmic formulation similar to that of Rao, Matyas utilizes Gaussian perturbations about the search point along with a bias term to direct the search <ref type="bibr">[29]</ref>. <ref type="bibr">Solis and Wets [30]</ref> have enhanced this approach by evaluating the objective function at x -Sz if evaluation at z + Sz does not improve the current value of the objective function and by incorporating a variable perturbation variance. The bias and additional function evaluation serve as stochastic equivalents to incorporating momentum and gradient information. Baba has successfully applied the method of Solis and Wets to training feedforward networks to predict SO2 concentrations in air [31].</p><p>Algorithm 1 from <ref type="bibr">Solis and Wets [30]</ref> was used in the studies presented here. The variance of the perturbation size &lt; is controlled by the repeated number of successes, sent, or failures,fcnt, in decreasing the objective function f . The contraction ct and expansion ex constants, as well as the upper and lower bounds on standard deviation of the random perturbations (T are set by the user. The Algorithm 1 variant gives the basic Solis and Wets method global optimization capability by increasing the standard deviation of the perturbation when it falls below an arbitrary lower bound (see step 2 below). The formulation is described as follows 1. Initialize the search vector xo and bias vector bo = 0. Set k = 0, scnt=O, fcnt=O. Fix ex, ct, Scnt, Fcnt, U&amp;, CTlb and initialize (T, = 1. 2. <ref type="bibr">scnt=scnt+l, fcnt=O. 4(c)</ref>. Otherwise,, x k + l = XI; and b k + l = 0.5bk, fcnt=fcnt +1, scnt=O.</p><formula xml:id="formula_0">f e z . g k -1 if sent &gt; Scnt ct . (Tk-1 i f f c n t &gt; Fcnt c u b if u k -1 &lt; Ulb Set (Tk = u k -1 otherwise 4(b). Otherwise, if f(xk -E k ) &lt; f ( x l i ) &lt; f(xli + E l i ) , then set xk+l = xk -&lt;k and b k + l = b k -0.4&lt;k,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">If k = maximum number of iterations then stop, else</head><p>The coefficient values 0.4 and 0.2 are retained from <ref type="bibr">Solis and Wets' results [30]</ref>. Note that the conditions in Step 2 are not mutually exclusive. The standard deviation CT specifies the size of the sphere that most likely contains the perturbation vector, and the bias term b locates the center of the sphere based on directions of past success. Step 4(b) implements a reversal strategy seeking a better solution in the direction opposite to that of initial perturbation.</p><p>Optimization experiments were conducted to find the point The first set of experiments consisted of using the Solis and Wets' algorithm outlined above. The second set of experiments employed the same algorithm, except that the bias term was not used. A third set of experiments employed Gaussian perturbations having a standard deviation proportional to the magnitude of the objective function such that &lt; -N(b, f(x)I). The final set of experiments did not incorporate a bias term so that 5 -N ( 0 , f(x)I). The variance modification parameters are the same as those reported in [30]: ez = 2,ct = 0.5,Scnt = 5 , and Fcnt = 3. The upper and lower bounds on the standard deviation were set as (Tub = 1.0 and Ulb = 0.00001, respectively. The average results of 10 trials are shown in Fig. <ref type="figure">2</ref>. Based on these experiments of low dimensionality, it appears that the accuracy of the extremum point may be improved significantly if the standard deviation of the random perturbations is allowed to expand and contract independently of the response surface height. Also, roughly an order of magnitude improvement in the cost function was observed using a random perturbation N N ( 0 , JfoI) as opposed to &lt; -N ( 0 , f(x)I). Modification of the perturbation size remains an active area of research, as exemplified by work in evolution strategies [33] and meta-EP WI.</p><formula xml:id="formula_1">(zl,<label>z2</label></formula><p>As successful as the basic Solis and Wets algorithm appears, search surfaces may be encountered for which global optimization is not practical if oZlb is continually less than some critical standard deviation that guarantees one can tunnel from any point on the search surface to an extremum with reasonable likelihood. To reduce the occurrence of entrapment conditions encountered in SASS strategies, it is suggested that the Solis and Wets random optimization method be embedded in a multi-agent stochastic search such as EP. Even if u u b is not constrained, a multi-agent search technique will provide a more rigorous search over high-dimensional spaces. </p><formula xml:id="formula_2">k = IC + 1 and go to Step 2. f ( ~) = X: + 2 ~; -O . ~C O S ( ~T Z ~) -O . ~C O S ( ~? T ~Z ) + 0.7. l c ---_ ---_ _ _ -.-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C . The Evolutionary Programming Paradigm</head><p>In 1958, Brooks [35] described a creeping random method where k points were generated via Gaussian perturbations about a search point. The best point was kept and the process repeated. Brooks observed that "there are some rather intriguing analogies that can be made between the creeping random method and evolution." This analogy was also apparent to Fogel et al. <ref type="bibr">[ 3 ]</ref> who proposed a population-based random search strategy termed evolutionary programming where, instead of keeping the single best point, a population of search points is maintained.</p><p>EP is a systematic multi-agent stochastic search (MASS) paradigm that can be used for finding global extrema on response surfaces. Although the EP methodology simulates the evolutionary process found in nature, the mechanisms incorporated in this framework and resulting characteristics may also be found in some of the stochastic optimization techniques previously discussed. Normally distributed perturbations are applied to the j t h element z;j in the solution</p><formula xml:id="formula_3">vector x i according to Sxij N N ( 0 , Sf,ij . J, + &amp;) where</formula><p>Sf,;j is the scale factor, J; is the magnitude of the objective or criterion function corresponding to x i , and &amp; is an offset vector [5]. The scale factor can be considered as a probabilistic analog to the step-size used in gradient methods. Similar to the hill-climbing and tunneling ability of simulated annealing relaxation methods, EP employs a competition process that allows less fit organisms (search points) to be retained in the population in a probabilistic fashion. The competition process is viewed as a competitive annealing mechanism. An EP optimization algorithm similar to that in [5] is given below:</p><formula xml:id="formula_4">1. Form an initial population P = [xoxlx:! . . . X2N-11</formula><p>of size 2N by randomly inirializing each n-dimensional solution vector xi. A user-specified search domain x; E [zmin, z,,ln may be imposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Assign a cost to each element x; in the population based</head><p>on the associated objective function Ji = @ ( x i ) s . t . @ : R" + R. from the N highest ranked elements (XO . ' . XN-1) in the population by modifying each element x;j E x; with a random perturbation 6xij N N ( 0 , Sf,ij . J; i -&amp;) such that x;+N,j = x i j + 6x;j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">. Loop to Step 2 .</head><p>A trajectory of the best population member at each generation during a search on the Bohachevsky surface is superimposed on the Bohachevsky contours as shown in Fig. <ref type="figure" target="#fig_4">3(a)</ref>. Fig. <ref type="figure" target="#fig_4">3(b)</ref> shows best cost in the population at each generation of the EP optimization process. The search is stochastic, so it is expected this trajectory will vary in every trial.</p><p>A variety of other techniques may be employed as altematives to the methods given above. For example, each additional offspring can replace the least fit organism in the population, as is done by <ref type="bibr" target="#b15">[17]</ref> and <ref type="bibr">[36]</ref>. In a parallel implementation, Yip and Pa0 [37] generate a multitude of offspring from each parent and replace the parent with the best offspring in a probabilistic manner using simulated annealing. When the offspring are generated with structural modification(s), some level of parameter optimization should occur rapidly to reduce the occurrence of discarding good structures. One approach might be to allow these new, higher-cost members of the population to mature by modification of the objective function according to J'(z, IC) = (1e--(T.kt(Y)) <ref type="bibr">J ( z )</ref> where the maturity level IC of a population member could be determined by how many generations it has existed within the population and the parameters 7 and Q are user-specified. A deterministic means to minimize redundancy might also be employed to delay the potential dominance of a single member in the population. After all, only a single solution is required and convergence of all the members in the population to a single point reduces the effectiveness of the search process in exploring other portions of the search space. Retention of higher-cost search points can be done probabilistically by setting the number of competitions to an arbitrarily low value, thus allowing a more relaxed search. As the number of competitions increases, the retention of the more fit individuals becomes more deterministic. Fogel <ref type="bibr">[34]</ref> discusses other variants of the EP paradigm.</p><p>The EP search outlined above was augmented with simple bisection search capabilities by averaging, or "blending," randomly chosen vectors according to xo = 0.5(xi + xj)</p><p>where x i and xj are the randomly chosen parent vectors selected from {XO, . . . , X N -~} and xo is the offspring vector.</p><p>This was done for half the offspring while the other half were generated using the perturbation approach &amp;ai N N ( 0 , J; . I)</p><p>where the covariance matrix is an identity matrix scaled by the value of the objective function. The normal perturbations complement the averaging or bisection search method since it is unlikely that the best solution point exists on the line between two search points. Likewise, blending elements of the population complements the random walk procedure generated by the evolutionary search if it is assumed that the population By decoupling the perturbation variance from the objective function, roughly an order of magnitude improvement in the best member of generation 100 was observed as shown in Fig. <ref type="figure">4</ref>. <ref type="bibr">Fogel [5]</ref> reports requiring an average of 65.5</p><p>generations over 20 trials to achieve loglo(f(x)) &lt; -6 using the same number of parents <ref type="bibr" target="#b48">(50)</ref> and offspring (one per parent).</p><p>By decoupling the cost function and implementing a simple bisection search, it took less than 30 generations, as averaged over 10 trials, to achieve similar results. The bisection search will not provide an advantage unless the global optimum is bounded by a portion of the population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. A Hybrid Approach</head><p>Single-agent stochastic search methods can be easily incorporated into EP without sacrificing the integrity of the evolutionary search procedure. A variant of EP is proposed to take advantage of the benefits offered by Solis and Wets The standard deviation can be tied to the height of the response surface so that a = sj .cost.</p><p>The second set of offspring is generated by an averaging or blending process. The third set of offspring is generated according to the Solis and Wets algorithm and deterministically replace the parents of a lower cost is achieved. Note that the variances in the offspring are generated by different methods and are not the same.</p><p>multi-agent search capabilities, EP is an attractive framework for combining a variety of stochastic search procedures. Although the previous experiments in a two-dimensional search space are not conclusive, the following properties appear potentially beneficial to a hybrid approach: 1) multi-agent search and variance expansion tend to avoid local minima, 2) information garnered during the search process about the response surface can be used to direct the search, and 3) convex optimization and perturbation variance reduction independent of the response surface height may improve accuracy.</p><p>Making the perturbation variance proportional to the value of the cost function may not always yield optimal performance. Decoupling the perturbation variance from the cost function value may prove beneficial since the shape of the response surface is often not well known and may even take on negative values. A similar decoupling strategy was employed by Waagen et al. <ref type="bibr" target="#b22">[24]</ref>. If the height of the response surface is known a priori, then the offset , O (see Step 4 of the EP algorithm) in the standard deviation of the perturbations can be incorporated. Unfortunately, knowledge of the height of the response surface generally corresponds to determining the location of the global extrema. If cost functions for which the optimal value is zero, such as mean-squared error, are employed, then this issue is less significant.</p><p>Figure <ref type="figure">5</ref> illustrates a hybrid approach that employs different methods for offspring generation within EP. While parents are selected from the whole population in the usual fashion [ 5 ] ,</p><p>the manner in which the offspring are generated is variable.</p><p>The first set of offspring results from parent search points that are perturbed by a random vector 6x N N ( 0 , a . I) where (T can be fixed <ref type="bibr" target="#b22">[24]</ref>, proportional to the corresponding height of the response surface [ 5 ] , or conditionally based on search performance <ref type="bibr">[33]</ref>. The second set of offspring results from blending the parameters associated with a pair of randomly chosen parents. This may be as simple as averaging all of the elements in the search string. If the model structure is part of the search vector, then both the first and second set of offspring can easily accommodate changes in the model structure as well as the weights. The final set of offspring is generated using the method of Solis and Wets, which acts on the existing parent structures. Each offspring in this third set will replace its parent if the offspring has lower objective function than its predecessor. The type of convex optimization method applied to the second set of offspring may also be applied to other parameters, such as the bias vector b. For example, if the Solis and Wets bias term is included in the search string, then the first set of offspring is instantiated with b = 0, while a member of the second set of offspring will have a bias vector determined using bo = 0.5 * (b; + bj), thereby taking the average of the bias vectors from two randomly selected parents. The other Solis and Wets parameters are instantiated in a similar manner, as are the structural parameters (i.e., model order, in this study). Although the Solis and Wets method could be repeatedly applied to the offspring, and has been done so with success, it is speculated that the different offspring strategies offer a more robust search as well as help to maintain diversity.</p><p>The average cost from 10 trials using the hybrid approach on the Bohachevsky function is shown in Fig. <ref type="figure">6</ref>. The hybrid technique achieves an accuracy of 10 orders of magnitude within 50 generations (this corresponds to a maximum of 7550 function evaluations). In order to ascertain which optimization procedure was being utilized, a histogram was generated from two sample optimization runs on the Bohachevsky response surface as shown in Fig. <ref type="figure">7</ref>. These runs contained 10 parent vectors and two sets of 10 offspring vectors generated via normal perturbations and blending, respectively. One run was made with fixed variance perturbation vectors [ -N(0,I); the second trial was conducted with the perturbation variance proportional to the cost function E N N ( 0 , J . I). When N ( 0, J . I) perturbations were incorporated, the perturbation technique was the predominant beneficial search mode. When N(0,I) perturbations were used, the Solis and Wets search technique provided most of the optimization capability. The averaging method rarely yielded the lowest cost member in the population.</p><p>Before dismissing the blending approach as inadequate, some comments should be made regarding these results. It is expected that the top members (say, vectors 1-5) of the population will tend to be the best if, only by default, better solutions are not found. The larger perturbations will generate points outside the small diameter of the global well as observed in the &lt; -N ( 0 , I) section of the histogram. This is also true the Solis and Wets random optimization method. This function has a unique global minimum at x = (1,l) and is referred to as a "banana valley" because it contains a steep valley along x2 = z:. Figure <ref type="figure" target="#fig_7">8</ref> shows the average and best results from 10 trials for both the Solis and Wets technique and the hybrid approach outlined above. In an effort to compare the search processes based on an equivalent number of maximum function evaluations, each generation equals a maximum of 150 function evaluations for the Solis and Wets method and a maximum of 150 function evaluations for the hybrid approach. Both average curves show optimization was still occurring after the maximum number of generations or iterations had been reached and the experiment was arbitrarily halted. These results compare favorably with generic EP results <ref type="bibr">[5]</ref> where it is reported that it took an average of 86 generations (over 20 trials) to achieve an accuracy of loglo(f(x)) &lt; -4. It should be noted that the results generated from the Solis and Wets method, by itself, are also comparable. Now that the capabilities of the hybrid stochastic search have been demonstrated on well-known response surfaces, the next step is to determine its effectiveness in evolving simple recurrent perceptron structures similar to those shown in Fig. <ref type="figure">1</ref>.</p><p>in some respect to the Solis and Wets optimization procedure, since it was instantiated with a unit variance and discrete III. EVOLVING RECURRENT PERCEFTRONS changes occur to the variance based on the performance of the search vector. When the Bohachevsky function was artificially elevated so that the global minimum had the corresponding cost f(O.0) = 10, the histograms for the two methods were virtually identical. Since subsequent investigations in evolving perceptron architecture relied heavily on the blending approach, the conclusion is drawn that implementing a variety of stochastic methods within EP provides a robust approach for the optimization of problems whose response surface is not well known. Incidentally, both of the runs that generated the histograms in Fig. <ref type="figure">7</ref> yielded nearly identical levels of cost after 1000 generations.</p><p>The Rosenbrock [38] function f(x) = 100(s? -I C ~) ~</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+</head><p>(1 -.cl)* was chosen for comparing the hybrid approach to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivation</head><p>The recursive structures shown in Fig. <ref type="figure">1</ref> are referred to as recurrent perceptrons because they incorporate nonlinearities on the output of a recursive linear combiner. The recurrent perceptron structure is inspired by recursive adaptive filters and the discrete time equation that models linear time-invariant (LTI) system dynamics m-1 n-1 where 5 represents the input to the system and y is the system output. While much is known about the stability, controllability, and observability of LTI systems, as well as methods for generating models of such systems, the same cannot be said where y is the estimate of the system output. The nonlinear series-parallel model is a transversal structure that utilizes the actual system outputs. Further, its linear counterpart is preferable for generating stable adaptive laws [39]. As stability is paramount when generating recursive filters, stable filters were always evolved using the hybrid stochastic search method implemented in this investigation.</p><p>The recurrent perceptron structures investigated in this study are characterized by the following difference equations</p><formula xml:id="formula_5">y(k + 1) =f[rc(k), z ( k -I), x(k -a), . . . , Class I: d k -m + 11, Y(k), Y(k -11, y ( k -2 ) , . . . , y ( k -n + 1 ) ] ' . . , z ( k -m + l), y(k), y(k -l), y ( k -2 ) , . . . , y ( k -n + 1 ) ] + g [ z ( k ) , z ( k -l),z(k -2 ) , . . . , 4 k -m + I), Y(k), v ( k -11, y(k -a),... , y ( k -+ I)] Class II: y(k + I) = f [ z ( k ) , z ( k -I ) , x ( k -2 ) ,</formula><p>where f and g are not necessarily the same mapping. The Class I is similar to the Model IV discrete time plant model given by Narendra and Parthasarathy 1391 for nonlinear system identification and control, except that the nonlinear transformation in [39] is implemented with a multi-layer perceptron and the nonlinearity in this paper is accomplished using a single perceptron. Class I1 is similar to the Model I11 discrete time plant model given in [39], if the evolutionary search process yields an f that is dependent only on previous outputs [y <ref type="bibr">(k)</ref>.y(k -I), . . . , y ( kn + l)] and a g that is dependent only on past inputs [ ~( k ) .</p><p>x ( k -I), . . . , x ( km + I)]. The selection of these models in <ref type="bibr">[39]</ref> was "motivated by the models that have been used in the adaptive systems literature for the identification and control of linear systems and can be considered their generalization to nonlinear systems."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Formulation</head><p>The recurrent perceptron model structure shown in Fig. <ref type="figure">l(a</ref>) is characterized by the Class I difference equation and can be described by</p><formula xml:id="formula_6">/m-1 n-1 \ y(k + 1) = f [ a p ( k -i ) + bZY(k -i ) + )</formula><p>where the search strategy must determine the order of the feedforward terms, m, the order of the feedback terms, n, as well as the feedforward coefficients, ai, the feedback coefficients, b j , and the bias a. The IIR synapses proposed by Back and Tsoi 1401 and the neurons used by Li and Haykin <ref type="bibr" target="#b20">[22]</ref> have the same structure as this nonlinear parallel model.</p><p>Recalling that polynomials can also be used to approximate any static mapping f : Rm + R" to an arbitrary degree of accuracy, and that the sigmoid function can be expressed as an inverted polynomial series leads to the suggestion that other nonlinear mappings that can also be expressed by polynomial series are equally applicable for use as activation functions <ref type="bibr" target="#b39">[41]</ref>, <ref type="bibr" target="#b40">[42]</ref>. The stochastic search method used for training does not explicitly incorporate knowledge of the activation function (just I/O observations), so any activation function can be implemented without regard for continuity constraints. By virtue of their smoothness, continuous activation functions tend to possess good function approximation properties. The search may even be conducted over a set of candidate mapping functions F such that f E F thereby incorporating the selection of the activation function( s) in the evolutionary optimization process.</p><p>The objective function for each perceptron is similar to Akaike's minimum information theoretical criterion (AIC) estimate <ref type="bibr" target="#b41">[43]</ref> as employed by Preistley 1441 for evaluating autroregressive moving-average (ARMA) models</p><formula xml:id="formula_7">AIC(m, n) = Nln(82) + 2(m + n + 1)</formula><p>where N is the effective number of observations. An additional factor of 1 is added to the number of fitted parameters ( m + n ) to account for the bias term a. The MLE of the innovation variance <ref type="bibr" target="#b42">[44]</ref> is determined according to N-1 k=O N where the observation error is given by 6 ( k ) = y(k) -y(k). To prevent the search process from driving the number of parameters to zero and stalling at a large MSE, the modification to the model order can take one of three states <ref type="bibr">( -l , O , +l)</ref>. Approximately 20% of the time, either of the conditions (-1, + 1) existed for a randomly selected tappeddelay line. Thus, if there are four tapped-delay lines, each line is being modified about 5% of the time. If a large number of tapped-delay lines are employed, then the percentage of time that any of the lines are affected may be increased to maintain a similar modification ratio.</p><p>If direct linear feedthrough <ref type="bibr" target="#b43">[45]</ref> capabilities are desired to be ~ present in parallel with the nonlinear contributions, then the perceptron structure can be reformulated as a combination of linear and nonlinear recurrencies. This combined structure corresponds to the Class I1 model where g is a linear functional as shown in <ref type="bibr">Fig. l(b)</ref> and is expressed by</p><formula xml:id="formula_8">[ i=o i=O / where -10000 m-1 n-1 $ L ( k + 1) = U i X ( k -i ) + bi$(k -i ) + a! -20000 i=O i=O -30000 and 0 U m 2 -40000 -50000 9-1 &amp;v( IC + 1) = f 1 C i X ( k -2) + 1 diG(IC -i) + p r1 i=O i=O</formula><p>If this structure or its variants are used, then the AIC score lutionary model building procedure can be iteratively applied to the residuals as discussed by Priestley <ref type="bibr" target="#b42">[44]</ref>. Deterministic training can also be applied to the evolved model in an effort to "fine tune" the model coefficients. Deterministic training was usually not applied to the nonlinear models generated in this work, either during or after the training process, and may potentially have yielded slightly better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Deterministic Training</head><p>More deterministic methods may be used to update the perceptron weights while the model structure is evolving, or they may be applied to the results of the stochastic search as a post-processing check to ensure local optimality. The recurrent perceptron model corresponding to </p><formula xml:id="formula_9">O(k + 1) = n p ( k -i) + hiO(k -i ) i=O i=O</formula><p>where the maximum window size was limited to five samples. A N ( 0 , l ) random forcing function was used to generate SO 000 samples, SO00 of which were used for training purposes. The search population consisted of 10 parents, each generating a single offspring using EP perturbations, as well as another set of 10 offspring by averaging randomly chosen parents.</p><p>The optimization process took place over SO0 generations as shown in Fig. <ref type="figure">9</ref>. The resulting model does not incorporate the forcing function, but instead relies only on past observations of the pendulum displacement as given by where</p><formula xml:id="formula_10">W T = [U0 U1 . ' . U,-1 bo bl . ' . bn-la] ZT = [xk ICkpl . . . z ~-~+ ~ Y k Yk-l . . . Yk-n+l 1 1</formula><p>If the objective function is given by the instantaneous squaredoutput, then a straightforward gradient approach yields the well-known stochastic approximation weight update equation w,,, = w + vekf'(wTz)z</p><p>error Ek = e: = ( ~kgk)2 where zk is the desired e ( k + 1) = 0*87220(k) f 0.78580(k -1) -0.41270(k -2) -0.31900(k -3 ) + sin(O.O6870(k))</p><p>Note that this approximation can be reduced to a purely Tsoi and Back <ref type="bibr" target="#b38">[40]</ref> have derived a multi-layer perceptron version of this update scheme for nonlinear FIR and IIR perceptrons. <ref type="bibr">Williams and Zipser [46]</ref> have also formulated a batch update scheme with an arbitrary lag window for recurrent multi-layer perceptrons.</p><p>IV. PREDICTION RESULTS linear system because of the small coefficient on the sin argument. The simulated system is almost linear by virtue of the small displacements and angular velocities. This model has a MSE=1.54 .</p><p>for the training data shown in Fig. <ref type="figure" target="#fig_12">10</ref>. A test set was generated using r ( k ) = 0.5cos(2~IC/1000) with the resulting MSE=3.69 .</p><p>on the testing data shown in Fig. <ref type="figure" target="#fig_13">11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . The Sunspot Series</head><p>The second set of experiments was conducted on Wolf's sunspot series for the years 1700-1988. These numbers are indicative of the average relative number of sunspots observed each day of the year and serve as a standard benchmark for time-series modeling [12], [13], <ref type="bibr" target="#b38">[40]</ref> where the objective is to generate a single-step prediction based on past observations. Consistent with Weigend et al. where J = 1, B = 0.1, and K = 1. For simplicity, the system was simulated using Euler integration with a stepsize of [13] employ the Optimal Brain Damage method of Le Cun et al. <ref type="bibr" target="#b46">[48]</ref> to generate a pruned network or nonlinear subset model with 5 inputs that are not fully-connected to 3 hidden units in a two layer feedforward network. Priestley [a] describes a variety of more traditional time-series models for the sunspot data set. These include autoregressive (AR), ARMA, TAR, and bilinear models.</p><p>Poor results were usually obtained when using simple structures like that shown in Fig. <ref type="figure">l(a)</ref>, and reasonable results were usually found using the Class 11 type models for a variety of activation functions. Also, nonrecurrent models were evolved by using the evolutionary search process to determine the order of just the tapped-delay input lines. The maximum number of delays was arbitrarily set at mmax = nmaX = for the blending process and 10 utilizing normal perturbations where the standard deviation is proportional to the MSE of the network), 10 competitions, 0 l b = 0.0001, and nub = 1.0 and S f = 1. The initial order of the tapped-delay lines was randomly chosen.</p><p>To facilitate comparison with previous work done on the sunspot series, the average relative variance was determined for the evolved model. The average relative variance arv is given by 1121 and provides a normalized mean squared error (NMSE) metric for comparing the performance of different models. The NMSE is independent of the training set size and is unity in the event that the estimate is equivalent to the mean of the data, (i.e., li. = s). In the following text, the am set { a r v l , arv2, arv3) will refer to the average relative error corresponding to {training set, test set , test set <ref type="bibr">(1957-1979))</ref>.</p><p>When constrained as a linear system, a second-order transversal filter with a bias term as given by y k + l = 1.2605zk -0 . 4 9 1 5 ~k -~ -0.1321zk-2 + 0.0831 was evolved.</p><p>That is, the order of the feedback lines became zero. The evolved linear model has an urv = {0.1494,0.1732,0.4512}, which compares favorably with the ninth-order AR model given by Priestley with an urw = {0.1865,0.2235,0.4994}. It  </p><formula xml:id="formula_11">{ ~( k ) , x(k-l ) , z ( k -2 ) )</formula><p>as well as { ~( k -7),2(k -10)). (Neural network subset models were not investigated in this study but are achievable using EP as demonstrated in <ref type="bibr">[18]</ref>.) From this model structure, a least-squares estimate can be found by forming the normal equations from y = Hw or equivalently and solving for the weight vector WLS = (HTH)-lHTy. If this is done using the complete data set, a pure follower strategy results, since w L S = [I o o o ] ~. The follower strategy yields an arv = {0.2903,0.4268,0.9647). No improvement was found when a gradient search scheme was applied starting from the evolved weight coefficients. This yielded a slightly modified weight coefficient vector w = [1.2612 -0.4899 -0.1248 0.0791IT after a small number of iterations.</p><p>A transversal filter network was purposely evolved by disallowing feedback of the previous estimates into the network. The resulting network is equivalent to a single hidden layer network with two hidden units, one of which receives eight inputs and one of which receives only the last observation. The weights and biases for this network are given in Table <ref type="table" target="#tab_0">I</ref>. Each node utilizes a tanh activation function. The average relative variance for this network is given in Table <ref type="table" target="#tab_2">I11</ref> along with an, values for deterministically trained models. The better transversal networks that are known <ref type="bibr" target="#b10">[12]</ref>, [13] have three hidden nodes and utilize observations from an eleventh-order lag that corresponds to the average period of the data. The best model is only partially connected, thereby incorporating a subset of the actual time-series inputs.</p><p>A linear-nonlinear model incorporating a tanh nonlinearity and a bias term was evolved as given by This single-step sunspot predictor has an arv = (0.1260, 0.1140, 0.3630).</p><p>Using a structure similar to that of the transversal network, except this time with feedback connections to the hidden units, a recurrent network was evolved where the search determined not only the order of the input lines, but of the feedback lines as well. During the training process, the number of tapped-delay lines on one feedback loop became zero, thus resulting in a partially feedforward network and partially recurrent network. The weights for this structure are given in Table <ref type="table">11</ref>. Better results were not obtained on the sunspot data using this network or any of the other evolved recursive filter networks. The recurrent networks' an, values are given in Table <ref type="table">111</ref>, where the first 20 observations have been substituted for the estimated values. A plot of the single-step estimates generated from the recurrent network is shown in Fig. <ref type="figure" target="#fig_14">12</ref>(a), with the error line shown in Fig. <ref type="figure" target="#fig_14">12(b</ref>). Although better transversal networks have been generated, it is still suspected that recurrency might be appropriate for this data based upon the results discussed by Priestley. Better results might be obtained in evolving both the transversal and recurrent structures if the representation (number of hidden nodes) is increased and the complexity penalty for the number of terms is relaxed.  </p><formula xml:id="formula_12">$ N ( k + 1) = cos a g ( k -i ) + bi$(k -2) i=O ) (" i=O i=O q-1 r z +sin ciz(l~ -i) + dijj(k -i ) + a</formula><p>was postulated. After 5000 generations, the evolutionary search yielded a predictor of the form y k + l = sin(3.1476zk)+ 0.0274, thereby disregarding the cos node and the recurrent terms (the tapped-delay orders of m,n, and q went to zero). Fig. <ref type="figure" target="#fig_16">13</ref> shows the results of the evolved solution on 200 points generated from xo = 0.2. Upon inspection of the evolved solution, it was observed that y k + l = sin(7rzk) might serve as a suitable estimate. Figure <ref type="figure">14</ref> shows the performance of this estimate on the same 200 points used in Fig. <ref type="figure" target="#fig_16">13</ref>. Figure <ref type="figure" target="#fig_17">15</ref> gives the state space plot for each of the estimates and the actual quadratic mapping function. Table <ref type="table" target="#tab_1">I1</ref>  which is also reported in Table <ref type="table" target="#tab_3">IV</ref>.</p><p>This example illustrates the potential ability of the search to find nonrecurrent solutions when recurrent solutions are unnecessary. Weigend et al. report using three radial-basis function nodes to achieve this mapping without further elaboration. Investigations using backpropagation showed that a is a solution to this equation. A single-step predictor 'of the better solution can be found for 10 &lt; -N-&lt; 15 hidden units in AIC(N,) = Nln(6:) + 2(N,)</p><p>1.0 0.9</p><p>where N , is the number of weights and biases in the network.  of the training data to allow the transient effects due to the perceptron recurrencies to die out. This difference in the number of observations alters the AIC scores. Nevertheless, the arv values compare favorably with the results found in the recurrent network training evaluation done by Logar et al. <ref type="bibr" target="#b48">[50]</ref> for the Mackey-Glass equation with T = 17. The preditor can be made nonrecursive by letting y t y, which yields a MSE = 0.00088 and an arv = 0.0232 on the test set. However, if a transversal filter is desired, it is suspected that better results would be obtained by training the appropriate structure. This model performs poorly if forward projections are generated by replacing the observations with previous estimates so that y +-9. A two-step ahead predictor yields a MSE = 0.0070 on the test set, while a three-step ahead predictor is dramatically worse with a MSE = 5.1125 on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>This work has incorporated an efficient single-agent search strategy, the method of Solis and Wets, into the EP framework and augmented it with the simplest convex optimization  The hybrid method was applied to nonlinear IIR filters for single-step prediction tasks. Since the model structure was simultaneously determined along with the weighting coefficients, the evolved solutions did not always have recurrent structure (i.e., transversal filter structures sometimes resulted). Good single-step prediction ability was evolved using nonlinear mappings, even though the resulting models were dissimilar to the models (if any) that created the original data. The learning procedure had the most trouble with the noisy sunspot data, indicating that the representation may not be sufficient and/or additional work is warranted for systems with noisy output. Other types of information-based criteria, such as the minimum description length (MDL) modeling principle [51], can be used in lieu of the AIC as an objective function, and may yield better results, since the AIC is not a consistent estimator <ref type="bibr" target="#b50">[52]</ref>.</p><p>The simple structures investigated in this work demonstrated a reasonable degree of proficiency for the nonlinear timeseries problems studied. Similar AIC values were attained for a varied assortment of models of the same data sets. From these results, it is suspected that the joint parameter-function space of particular data sets may be dense in the number of acceptable solutions, some of which may be found by the relaxation scheme employed in this investigation. While it is evident that the hybrid stochastic optimization scheme provides an effective learning mechanism, the issue of what types of time-series representations can be effectively modeled using this approach has not been addressed in this investigation. By cascading and/or parallelizing recurrent perceptrons to generate multi-unit networks, as in traditional feedforward architectures, additional capabilities for more complex timeseries processing tasks may be achieved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1. (a) The nonlinear IIR filter structure. (b) The parallel linear-nonlinear IIR filter structure. Evolutionary programming can adapt any activation function, and, since the model order is determined during the search, transversal stmctures may result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, ) which minimizes the Bohachevsky [32] function The standard deviation was initialized as uo = 1.0, and x was initially sampled in the region x E [-25, 2512 for all the experiments conducted. The transcendental terms generate many local minima within the region x E [-1, 112 while the quadratic terms dominate the surface structure outside this interval. A unique global minimum exists at x = (0,O).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig. 2. A comparison of variants of the Solis and Wets random optimization method as applied to the Bohachevsky function and averaged over ten trials.It appears that higher accuracy is attained by allowing the variance of the random perturbations to expand and contract independent of the response surface height.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3.</head><label></label><figDesc>Reorder the population in descending order based on the number of wins generated from a stochastic competition process. Wins are generated by randomly selecting other members in the population xj and incrementing the win counter w; if J; &lt; Jj. 4. Generate offspring (XN . . . ~2 ~~1 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Global optimization via evolutionary programming. (a) The trajectory of the best member in the population at each generation is superimposed on the contour plot of the Bohachevsky function with Sf = 1, 50 parents, 20 competitions. (b) The cost of the best member in the population at each generation. Since EP is a stochastic optimization process, the trajectory shown in (a) will undoubtedly vary for each trial.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Augmenting the EP search strategy with bisection search where the offspring are generated by averaging two randomly selected parent vectors.Half of the offspring were generated by mutation, the other half by averaging pairs of randomly selected parent vectors, The bisection search is useful when combined with multi-agent stochastic methods that distribute the population about a global extremum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Optimization of the Bohachevsky function using the hybrid search strategy with 50 parent points. The second set of offspring has a fixed perturbation variance U = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Comparing optimization methods using Solis and Wets and the hybrid approach on the Rosenbrock response surface. Fifty parent points were used in the hybrid technique. Each generation corresponds to a maximum of 150 function evaluations for each method. The second set of offspring in the hybrid approach have a fixed perturbation variance of U = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>for nonlinear systems in general [39]. Nonlinear versions of the identification models (motivated by LTI dynamics) given inNarendra and Parthasarathy [39]  are described by nonlinear parallel model:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>model has been determined, the eve-Fig.9. Evolutionary optimization of the pendulum model. The lowest AIC score in the population is shown at each generation of the evolutionary search process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Fig. l(a) can be described by Y k + l = f ( W T Z ) 0.05. A linear-nonlinear series-parallel model was</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>[ 121, the data set was A. The Simple Pendulum velocity-squared damping term Consider the equation for a simple pendulum With a J ; + ~i l i l + Ksine = 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. (a). The desired output used in the training set. (b) The error for each point in the training time-series. The forcing function r -V(O, 1 ) was not incorporated in the resulting model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. (a). Test data for the pendulum model generated from ~( k ) = cos(Zrk/1000. (b). The error for the test time series.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. (a) The evolved recurrent model for the sunspot data. Training was done over years 1700-1920. The test set consists of years 1921-1988. The first 10 data training points were not included in the model evaluation criteria (this corresponds to the maximum model order) of the evolved filter. (b) The error trace for the evolved recurrent single-step sunspot predictor. The data was normalized by a factor of 200.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>contains representative AIC and MSE values for a 100 point sequence starting with the given initial condition. The initial error at 20 was neglected in these calculations because no observations have been made. For a large number of data points, the integral-squared error (ISE) represents a closed form solution to the MSE since n n " i = l i=l In the limit, the MSE approximation becomes the ISE that is defined on the unit interval [0, I] as ISE = ( ~k + l -?i.k+~)~dzk 1'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Logistic map test data and the evolved solution of the form Fig. 14. Logistic map test data and the estimate i k + l = sin(*zk) generated .?,+I = sin(3.1476zk) + 0.0274.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. The state-space plot for the logistic map. Observations generated from ak+l = 4 a k ( lzk) are denoted with an "0," the evolved solution estimate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Fig. 16. (a). The evolved solution on the training and test data generated from the Mackey-Glass equation. The first 500 points were in the training set, and the subsequent 500 points were used for the testing set. Every fifth observation point is shown by a solid square. (b). The error between the evolved solution and the Mackey-Glass dynamic equations for the time-series shown in Fig. 14.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I WEIGHT SET FOR THE EVOLVED TRANSVERSAL FILTER NETWORK Hidden unit 1 Hidden unit 2</head><label>I</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bias</cell><cell></cell></row><row><cell cols="2">output</cell><cell></cell><cell>-0.9448</cell><cell></cell><cell></cell><cell>-1.1872</cell><cell></cell><cell>0.5423</cell><cell></cell></row><row><cell></cell><cell>S k</cell><cell>'k-1</cell><cell>xk--2</cell><cell>x k -3</cell><cell>xk-4</cell><cell>x k -5</cell><cell>x k -6</cell><cell>xk--7</cell><cell>Bias</cell></row><row><cell>Hid unitl</cell><cell>-1.5332</cell><cell>1.7664</cell><cell>1.3729</cell><cell>0.3080</cell><cell>-0.2951</cell><cell>0.0252</cell><cell>-0.2966</cell><cell>-0.2740</cell><cell>1.1819</cell></row><row><cell>Hid unit2</cell><cell>-1.1093</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-0.2191</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I1 WEIGHTS FOR THE EVOLVED, RECURSIVE, FILTER NETWORK</head><label>I1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Hidden unit 1</cell><cell>Hidden unit 2</cell><cell>Input bias</cell><cell cols="2">Output bias</cell><cell>Input bias</cell></row><row><cell>output</cell><cell>-0.6550</cell><cell></cell><cell>1.0668</cell><cell>-0.2323</cell><cell>0.3079</cell><cell></cell><cell>-0.2323</cell></row><row><cell></cell><cell>x k</cell><cell>x k -1</cell><cell>x k -2</cell><cell>xk--3</cell><cell>xk-4</cell><cell>xk--5</cell><cell>x k -6</cell></row><row><cell>Hid unitl</cell><cell>-0.6512</cell><cell>0.5742</cell><cell>0.9500</cell><cell>0.0830</cell><cell>-0352</cell><cell>-0.0531</cell><cell>0.0065</cell></row><row><cell>Hid unit2</cell><cell>1.3000</cell><cell>0.3824</cell><cell>0.3040</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>X k -7</cell><cell>Xk--R</cell><cell>Y k</cell><cell>Yk-1</cell><cell>Yk--2</cell><cell>Y k -3</cell><cell>bias</cell></row><row><cell>Hid unit 1</cell><cell>-0.2252</cell><cell>-0.1251</cell><cell>0.5443</cell><cell>0.3283</cell><cell>-0.0391</cell><cell>0.3393</cell><cell>0.2483</cell></row><row><cell>Hid unit2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1042</cell></row><row><cell cols="4">is interesting to note that the subset model found by Svarer et</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">al. also includes the first three terms</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I11 COMPARISON OF NORMALIZED ERROR RESULTS OF PREVIOUS WORK ON THE SUNSPOT DATA SET WITH THE SOLUTION FOUND USING A RECURRENT STRUCTURE</head><label>I11</label><figDesc></figDesc><table><row><cell>Model</cell><cell>Train (1700-1920)</cell><cell>Test (1921-1955)</cell><cell>Test (1956-1979)</cell><cell>Number of parameters</cell></row><row><cell>Tong and Lim [44]</cell><cell>0.097</cell><cell>0.097</cell><cell>0.28</cell><cell>16</cell></row><row><cell>Weigend (\it et al.] [12]</cell><cell>0.082</cell><cell>0.086</cell><cell>0.35</cell><cell>43</cell></row><row><cell>Svarer (\it et al.) [13]</cell><cell>0.090</cell><cell>0.082</cell><cell>0.35</cell><cell>12-16</cell></row><row><cell>Transversal Net</cell><cell>0.0987</cell><cell>0.097 1</cell><cell>0.3724</cell><cell>14</cell></row><row><cell>Recurrent net</cell><cell>0.1006</cell><cell>0.0972</cell><cell>0.4361</cell><cell>22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV . PERFORMANCE OF SINGLE-STEP PREDI CTORS ON THE LQGISTIC MAP FOR 100 SAMPLES.</head><label>IV</label><figDesc></figDesc><table><row><cell>Predictor</cell><cell>xo</cell><cell>AIC</cell><cell>MSE</cell><cell>ISE</cell><cell>arv</cell></row><row><cell>i k + l =</cell><cell>0.2</cell><cell>-316.7</cell><cell>0.0004</cell><cell>0.0004</cell><cell>0.0032</cell></row><row><cell>sin(3.14761k) -I-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.0274</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>i k + l = sin(srk)</cell><cell>0.2</cell><cell>-213.7</cell><cell>0.0012</cell><cell>0.0013</cell><cell>0.0091</cell></row><row><cell>1-10-1 network</cell><cell>0.2</cell><cell>-117.1</cell><cell>0.00 17</cell><cell></cell><cell>0.0131</cell></row><row><cell>1.15-1 network</cell><cell>0.2</cell><cell>-303.4</cell><cell>0.0002</cell><cell></cell><cell>0.0015</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V THE</head><label>V</label><figDesc>PERFORMANCE m U L T S FOR THE NEXT-STEP AHEAD PREDICTOR ON THE MACKEY-GLASS EQUATION</figDesc><table><row><cell>Data set</cell><cell>No. of effective</cell><cell>AIC</cell><cell>MSE</cell><cell>a r v</cell></row><row><cell></cell><cell>observations</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training</cell><cell>450</cell><cell>-4406.1</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>O.ooOo5 0.0014 Test 500 -4594.4 0.00009 0.0025 capability</head><label></label><figDesc>, bisection search, to yield a hybrid multi-agent stochastic search technique. This hybrid method can enhance EP optimization efficiency while alleviating local minima problems associated with single-agent search techniques. A myriad of other local methods could also have been easily incorporated with the multiagent EP search procedure.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank Dr. A1 Gordon, program director for NRaD intemal research projects, and Lou Griffith for their support of this work. The authors would also like to thank David Fogel and the reviewers for their suggestions and many helpful comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New Pooulation</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Simulated Annealing and Boltzman Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Aarts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Korst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<title level="m">Adaptation in Natural and Artificial Systems. 2nd edition</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Walsh</surname></persName>
		</author>
		<title level="m">Artificialfntelligence Through Simulated Evolution</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An Evolutionary approach to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">System Identification though Simulated Evolution: A Machine Learning Approach to Modeling</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Porto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="487" to="493" />
			<date type="published" when="1990">1991. 1990</date>
			<publisher>Ginn Press</publisher>
			<pubPlace>Needham, MA</pubPlace>
		</imprint>
	</monogr>
	<note>Evolving neural networks</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive State Representation and Estimation using Recurrent Connectionist Networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks for Control</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Moller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hanazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">fEEE Trans. on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Nonlinear adaptive networks: a little theory, a few applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Bisset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Flake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>O'rouke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">J</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Thode</surname></persName>
		</author>
		<idno>LA-UR 91-273</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Los Alamos National Laboratory, Los Alamos, NM</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Prediction of chaotic time series using CNLS-NETexample: The Mackey-Glass equation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Glake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>O'rourke</surname></persName>
		</author>
		<idno>LA-UR-91-720</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Los Alamos, NM</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Los Alamos National Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Function approximation and time series prediction with neural networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Flake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qian</surname></persName>
		</author>
		<idno>LA-UR 90-21</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Los Alamos National Laboratory, Los Alamos, NM</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Predicting the future: A connectionist approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigned</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
		<idno>Stanford-PDP-90- 01 or PARC-SSL-90-20</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On design and evaluation of tapped-delay neural network architectures</title>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Con5 on Neural Networks</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simplifying neural networks by soft weight sharing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A hybrid technique to enhance the performance of recurrent neural networks for time series prediction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramamurti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Con&amp; on Neural Networks</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The cascade-correlation learning architecture</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fahlman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lebiere</surname></persName>
		</author>
		<idno>CMU-CS-90-100</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evolving neural networks: applications to a prediction problem</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saravanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Annual Conf. on Evolutionary Programming</title>
		<meeting><address><addrLine>La Jolla</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural network structure design by evolutionary programming</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Waagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Annual Conf. on Evolutionary Programming</title>
		<meeting><address><addrLine>La Jolla, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="79" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An evolutionary algorithm that constructs recurrent neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Angeline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>this issue</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using evolutionary programming for modeling: an ocean acoustic example</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Oceanic Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="340" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Applied Optimal Estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A cascaded recurrent neural network for real-time nonlinear adaptive filtering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. on Neural Networks</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A review of evolutionary artificial neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Journal of Intelligent Systems</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The stochastic direction set algorithm: A hybrid technique for finding function extrema</title>
		<author>
			<persName><forename type="first">D</forename><surname>Waagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Diercks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcdonnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Annual Con5 on Evolutionary Programming</title>
		<meeting><address><addrLine>La Jolla, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<title level="m">Optimization Theory and Applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random search techniques for optimization problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Kamopp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auromatica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="111" to="121" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Optimization Theory with Applications</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Pierre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Dover</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Genetic Algorithms + Data Structures = Evolution Programs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalwicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Random optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Matyas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="244" to="251" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Minimization by random search techniques</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Solis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Wets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="50" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A new approach for finding the global minimum of error function of neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Baba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="19" to="30" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generalized simulated anealing for function optimization</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">0</forename><surname>Bohachevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="218" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolutionary programming evolution strategies: similarities and differences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Annual Conf. on Evolutionary Programming</title>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Evolving Artificial Intelligence</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>San Diego</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Califomia</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A discussion of random methods for seeking maxima</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="244" to="251" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Continuous evolutionary programming: Analysis and experiments</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cybernetics and Systems</title>
		<imprint/>
	</monogr>
	<note>in review</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An automatic method for finding the greatest of least value of a function</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P C</forename><surname>Yip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Rosenbrcck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">World Congress on Neural Networks</title>
		<meeting><address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1960">1993. 1960</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">175</biblScope>
		</imprint>
	</monogr>
	<note>A fast universal training algorithm for neural networks</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Identification and control of dynamical systems using neural networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">FIR and IIR synapses, a new neural network architecture for time series modeling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of sigmoidal functions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics of Control, Signals, and Systems</title>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Supervised learning with Gaussian potentials</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks for Signal Processing</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</editor>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1974-12">Dec., 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Priestley</surname></persName>
		</author>
		<title level="m">Non-Linear and Non-Stationary Time Series Analysis</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural networks for process identification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Haesloop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Joint Conf. on Neural Networks</title>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A learning algorithm for continually running fully recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Threshold autoregression, limit cycles and cyclical data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Optimal brain damage</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Le Cun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufman</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="598" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Oscillation and chaos in physiological control systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mackey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A comparison of recurrent neural network learning algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Logar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Convin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J B</forename><surname>Oldham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Con&amp; on Neural Networks</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Stochastic complexity and modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1080" to="1100" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Inconsistency of the AIC rule for estimating the order of autoregressive models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="375" to="385" />
			<date type="published" when="1980">1980. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">McDonnell is a principal engineer at the Naval Command, Control, and Ocean Surveillance Center (NCCOSC), RDT&amp;E Div., where he is involved with teleoperated and autonomous robotic systems, neural network signal classification, and the design of neural network architectures by evolutionary search. He is an adjunct professor in the Mechanical Engineering Department at San Diego State University, where he teaches graduate-level courses in control systems and simulation</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Mcdonnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mr. McDonnell is a member of the Evolutionary Programming Society and serves as a committee member for the Annual Conferences in Evolutionary Programming. t D. Waagen received the B.S. in mathematics from the University of Utah in 1984, and the M.S. degree in statistics from San Diego State University in 1993. From 1985 to 1993, he has worked as a scientist for NCCOSC, RDT&amp;E Div</title>
		<meeting><address><addrLine>San Diego; San Diego, CA</addrLine></address></meeting>
		<imprint>
			<publisher>American Statistical Association and the Evolutionary Programming Society</publisher>
		</imprint>
	</monogr>
	<note>A&apos;87-S&apos;88-M&apos;89) received the B.S. degree from Texas A&amp;M in 1985 and is currently completing the requirements for the M.S. degree in Systems Science from the University of Califomia. His current interests are in the areas of nonparametric estimation, machine learning, and stochastic optimization</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
