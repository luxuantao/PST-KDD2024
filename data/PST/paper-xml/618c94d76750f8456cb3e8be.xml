<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating Query Focused Summaries from Query-Free Resources</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yumo</forename><surname>Xu</surname></persName>
							<email>yumo.xu@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generating Query Focused Summaries from Query-Free Resources</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The availability of large-scale datasets has driven the development of neural models that create generic summaries from single or multiple documents. In this work we consider query focused summarization (QFS), a task for which training data in the form of queries, documents, and summaries is not readily available. We propose to decompose QFS into (1) query modeling (i.e., finding supportive evidence within a set of documents for a query) and (2) conditional language modeling (i.e., summary generation). We introduce MARGE, a Masked ROUGE Regression framework for evidence estimation and ranking which relies on a unified representation for summaries and queries, so that summaries in generic data can be converted into proxy queries for learning a query model. Experiments across QFS benchmarks and query types show that our model achieves state-of-the-art performance despite learning from weak supervision. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The neural encoder-decoder framework has become increasingly popular in generic summarization <ref type="bibr" target="#b31">(See et al. 2017;</ref><ref type="bibr" target="#b11">Gehrmann et al. 2018;</ref><ref type="bibr" target="#b25">Liu and Lapata 2019a;</ref><ref type="bibr" target="#b9">Fabbri et al. 2019</ref>, inter alia) thanks to the availability of large-scale datasets containing hundreds of thousands of document-summary pairs. Training data of this magnitude is not readily available for query focused summarization (QFS; Dang 2005) which aims to create a short summary from a set of documents that answers a specific query. Existing corpora <ref type="bibr" target="#b27">(Nema et al., 2017;</ref><ref type="bibr" target="#b5">Dang, 2005;</ref><ref type="bibr" target="#b14">Hoa, 2006;</ref><ref type="bibr" target="#b3">Baumel et al., 2016)</ref> are relatively small for modern data-hungry neural architectures and have been mostly used for evaluation purposes.</p><p>A major bottleneck in leveraging generic summarization data for QFS is the absence of queries <ref type="bibr" target="#b27">(Nema et al., 2017)</ref>; the majority of existing datasets consist of document-summary pairs, while QFS summaries are expected to answer specific queries. Recent work <ref type="bibr" target="#b39">(Xu and Lapata, 2020;</ref><ref type="bibr" target="#b34">Su et al., 2020;</ref><ref type="bibr" target="#b18">Laskar et al., 2020)</ref> sidesteps this problem by resorting to distant supervision from query-relevant NLP resources including question answering <ref type="bibr" target="#b30">(Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b4">Chakraborty et al., 2020)</ref> and paraphrase identification <ref type="bibr" target="#b7">(Dolan and Brockett, 2005)</ref>. Such approaches incorporate query modeling in the summarization process but are even more data hungry compared to generic summarization ones, since they additionally require access to QA datasets which can be extremely costly to create <ref type="bibr" target="#b1">(Bajaj et al., 2016;</ref><ref type="bibr" target="#b17">Kwiatkowski et al., 2019)</ref>. Moreover, there is often a mismatch between queries in QA datasets and those in QFS scenarios <ref type="bibr" target="#b39">(Xu and Lapata, 2020)</ref>; the two types of queries are not identically distributed and it is practically infeasible to find appropriate query-related resources for all domains and topics.</p><p>In this work we do not assume access to any resources other than those available for generic summarization. We further decompose abstractive QFS into two subtasks: (1) query modeling (i.e., finding supportive evidence within a set of documents for a query) and (2) conditional language modeling (i.e., generating an abstractive summary based on found evidence). Under this formulation, we use generic summarization data not only for conditional language modeling, but also for learning an evidence ranking model. Inspired by the Cloze task and its applications in NLP <ref type="bibr" target="#b35">(Taylor, 1953;</ref><ref type="bibr" target="#b22">Lewis et al., 2019;</ref><ref type="bibr" target="#b20">Lee et al., 2019)</ref> was the most-donated book for t he f ourt h year running.</p><p>[MASK] was published in 2003, and within [MASK] had booted John Grisham from <ref type="bibr">[MASK]</ref> whose books were most often donated to <ref type="bibr">[MASK]</ref>. <ref type="bibr">[MASK]</ref> reported <ref type="bibr">[MASK]</ref> was the most-donated book for [MASK] running .</p><p>[MASK] hydroelectric projects are planned or in progress and</p><p>[MASK] problems are associated with them .</p><p>What hydroelectric projects are planned or in progress and what problems are associated with them?</p><p>Figure <ref type="figure">1</ref>: Overview of our abstractive QFS approach. Summaries and queries are rendered with Unified Masked Representation (UMR) for training and testing, respectively. The summarization framework consists of a query model and a controllable generator. The query model ranks sentences in the input document(s) which provide evidence to answer the query; the generator operates over evidence bearing sentences to generate the final summary.</p><p>duces a unified representation for summaries and queries, so that summaries in generic data can be converted into proxy queries for learning a query model. Based on the evidence selected by MARGE, we generate abstractive summaries whilst controlling their length and the extent to which the query influences their content. Our contributions in this work are threefold: we propose a weakly supervised system for abstractive QFS where no query-related resources are required; we discover a new type of connection between generic summaries and QFS queries, and provide a universal representation for them which allows generic summarization data to be exploited for QFS; we provide experimental results on QFS benchmarks, and show that across query types and domains our system achieves state-of-the-art results on both evidence ranking and abstractive QFS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The majority of previous QFS approaches have been extractive, operating over queries and document clusters from which they select query-relevant sentences to compose a summary. They mostly differ in the way centrality and relevance are estimated and incorporated, e.g., via manifold ranking <ref type="bibr" target="#b37">(Wan et al., 2007)</ref>, using a look-ahead strategy <ref type="bibr" target="#b0">(Badrinath et al., 2011)</ref>, uncertainty prediction <ref type="bibr" target="#b38">(Wan and Zhang, 2014)</ref>, or attention mechanisms <ref type="bibr">(Li et al., 2017a,b)</ref>. More recently <ref type="bibr" target="#b39">Xu and Lapata (2020)</ref> propose a coarse-to-fine framework that leverages distant supervision from question answering to extract summary-worthy content.</p><p>Abstractive QFS has received significantly less attention. This is due to generation models being particularly data-hungry <ref type="bibr" target="#b19">(Lebanoff et al., 2018;</ref><ref type="bibr" target="#b25">Liu and Lapata, 2019a)</ref> and the scarcity of QFS training data. The increasing availability of pre-trained models has prompted the development of pipeline-style frameworks for QFS which use resources from a wider range of NLP tasks. For example, <ref type="bibr" target="#b34">Su et al. (2020)</ref> fine-tune BART <ref type="bibr" target="#b21">(Lewis et al., 2020)</ref> on <ref type="bibr">CNN/DailyMail (Hermann et al., 2015)</ref>, a single-document summarization dataset, and generate abstracts for QFS by iteratively summarizing paragraphs to a budget. They learn a query model for paragraph selection based on a plethora of QA and machine reading datasets <ref type="bibr" target="#b33">(Su et al., 2019;</ref><ref type="bibr" target="#b30">Rajpurkar et al., 2016)</ref>. Similarly, Laskar et al. ( <ref type="formula">2020</ref>) fine-tune BERTSUM on CNN/DailyMail, and propose a three-stage system which uses supervision from QFS data (typically reserved for evaluation) and related QA and paraphrase identification tasks.</p><p>We also focus on abstractive QFS, however, we do not assume access to any additional training resources over and above generic summarization datasets, even for query modeling. Moreover, our system is able to generate long QFS abstracts all at once, instead of iteratively creating bullet-style summaries which often lack coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Let {(S, D)} denote a generic summarization dataset where D = {d 1 , d 2 , . . . , d M } is a collection of documents with corresponding summaries S. |D| = 1 for single-document summarization (SDS) and |D| &gt; 1 for multi-document summarization (MDS). In QFS, a query Q additionally specifies an information request, {(S, D, Q)}. It is often assumed (e.g., in DUC benchmarks) that Q consists of a short title (e.g., Amnesty International ), and a query narrative which is longer and more detailed (e.g., What is the scope of operations of Amnesty International and what are the international reactions to its activities? ).</p><p>In this work, we propose to decompose QFS into two sub-tasks, namely query modeling and conditional language modeling. The query model q θ (D|Q; θ) estimates whether textual units (e.g., sentences) within document cluster D are relevant to query Q, while p φ (S|D, Q; φ) generates summary S conditioned on evidence provided by the query model and (optionally) the query itself (see Figure <ref type="figure">1</ref>(b) for an illustration). When S ⊥ ⊥ Q, we have a query-agnostic conditional language model p φ (S|D; φ). Otherwise, the conditional language model is query-guided. Our query model is trained with distant supervision derived from generic summarization data which is easier to obtain (e.g., from online sources) compared to QA datasets which must be annotated from scratch (e.g., for different types of questions and domains). Although queries are not verbalized in generic summarization, we hypothesize that the summaries themselves constitute a response to latent queries.</p><p>So, how can we reverse-engineer the queries from the summaries? Inspired by the standard Cloze task <ref type="bibr" target="#b35">(Taylor, 1953)</ref> and its recent variants <ref type="bibr" target="#b22">(Lewis et al., 2019;</ref><ref type="bibr" target="#b20">Lee et al., 2019)</ref>, we render queries and summaries in a Unified Masked Representation (UMR) which enables summaries to serve as proxy queries for model training, as shown in Figure <ref type="figure">1(a)</ref>. We further assume that the answer to these queries can be found in sentences which form part of the document collection D. Although we do not know for certain what these sentences are we can assume that if they have a high ROUGE score against the reference summary they are likely to contain an answer. We therefore use ROUGE as a distant supervision signal, and train a model that takes a query and document sentence as input and estimates their relevance. At inference time, we also render actual queries in UMR and rank all sentences in the document collection with our trained model. The most relevant sentences serve as input to a conditional language model to generate query focused abstractive summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Query Modeling</head><p>As explained earlier, we train a query model q θ (D|Q; θ) on summary-sentence pairs via distant supervision. We use a summary-based proxy query UMR S during training and an actual query UMR Q during testing. In the following, we first describe how UMRs are obtained and then discuss how the query model is trained. for m ← M do 14:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MERGE(m)</head><p>Merge adjacent <ref type="bibr">[MASK]</ref> 15:</p><p>return M 16: end function Unified Masked Representation The intuition behind UMR is that a summary will encapsulate most salient information a user needs, while a query typically covers only a small fraction. We thus add one or more "placeholders" to the query to represent missing information the user actually seeks. We also identify such information in generic summaries for selective masking, to reduce the distributional shift during training.</p><p>The UMR for a summary is the concatenation of its sentential UMRs. To convert a sentence from natural language to UMR, we parse it with Open Information Extraction (Open IE; <ref type="bibr" target="#b32">Stanovsky et al. 2018</ref>) to a set of propositions consisting of verbs and their arguments. The latter are considered candidate information slots I. We initialize Algorithm 1, by replacing all such slots with a [MASK] token. We subsequently sample and reveal a set of slots subject to a budget constraint. We define the budget as B = γ * |I| where γ ∈ [0, 1] modulates the proportion of tokens to be revealed within I slots (and is optimized on the development set). Finally, in order to keep the representation of UMR S and UMR Q consistent (see next paragraph), we merge adjacent [MASK] tokens to one [MASK] resulting in a partially masked summary.</p><p>We mask QFS queries by considering their structure and lexical makeup. Queries in DUC benchmarks often contain interrogative words (e.g., how is A and what is B ) and request words (e.g., describe A and tell me B ). Following this observation, we manually collect a small set of such query words and replace them with <ref type="bibr">[MASK]</ref>. For queries with a title and a narrative, we first mask the narrative and then prepend "[MASK] T .", where T is a sequence of title tokens. Figure <ref type="figure">1(a)</ref> shows examples of a masked query and summary.</p><p>Evidence Ranking We represent sentences in a document collection and UMR queries with a pretrained BERT model <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref>. Specifically, we concatenate a UMR query and a candidate sentence to sequence "</p><formula xml:id="formula_0">[CLS] U [SEP] C [SEP]"</formula><p>where U is a sequence of tokens within a UMR query and C a sequence of tokens in a document sentence (we pad each sequence in a minibatch of L tokens). The [CLS] vector serves as input to a single layer neural network which estimates whether the sentence contains sufficient evidence to answer the query (see Figure <ref type="figure">1</ref>(b) right). We use the mean-square error to compute the loss and update the encoding parameters in BERT via standard backpropagation:</p><formula xml:id="formula_1">L(θ) = 1 |D| (S,C)∼D (y − ŷ(S, C; θ)) 2 . (1)</formula><p>where S, C is a summary-sentence pair sampled from collection D and y the training signal. Recall the summary is rendered as UMR S .</p><p>Previous work <ref type="bibr" target="#b25">(Liu and Lapata, 2019a</ref>) has used ROUGE-2 as training signal for paragraph ranking. However, sentences are significantly shorter than paragraphs, and we observe a number of instances with a ROUGE-2 score of 0. We therefore perform label smoothing and define y as the F1 interpolation of ROUGE-2 and ROUGE-1: y = R 2 (S, C) + λ * R 1 (S, C) where λ is optimized on the development set. At inference time, we use the trained model to compute the affinity score between UMR Q and all candidate sentences in D and rank them accordingly. The highest ranked sentences are deemed query-relevant and passed on to our summary generation model. <ref type="foot" target="#foot_1">2</ref>Query Narrative Expansion In some cases queries may be relatively short and narratives absent. This can be problematic for our setup since query proxies (in the form of summaries) are typically long and detailed. For datasets with short queries we automatically create query narratives in an unsupervised fashion. We employ LexRank <ref type="bibr" target="#b8">(Erkan and Radev, 2004)</ref> to select a subset of representative sentences under a word budget and concatenate them to form narratives (which we append to the original queries).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Query Focused Generation</head><p>We also leverage generic summarization datasets to fine-tune a pretrained language model for abstractive QFS. In experiments we employ the publicly released UNILMV2 <ref type="bibr" target="#b2">(Bao et al., 2020)</ref> to instantiate the controllable generator shown in Figure <ref type="figure">1(b)</ref>, however any other language model could have been used instead.</p><p>With Transformer <ref type="bibr" target="#b36">(Vaswani et al., 2017)</ref> as the backbone network, UNILMV2 is jointly pretrained for natural language understanding and generation. Specifically, a bidirectional model is employs an autoencoding objective (AE; identical to <ref type="bibr" target="#b6">Devlin et al. 2019)</ref>, while a partially autoregressive (PAR) sequence-to-sequence model decomposes the probability of masked tokens in input sequence x as:</p><formula xml:id="formula_2">p(x M | x \M ) = |M | i=1 m∈M i p(x m | x \M ≥i ) (2)</formula><p>where M is the uniformly-produced factorization order. The masked position set M i at the ith factorization step can be either a token or a n-gram block. x M is a set of x M i , and similarly, x \M is a set of x \M i . The pretraining loss is computed as</p><formula xml:id="formula_3">L AE + L PAR .</formula><p>At inference, UNILMV2 operates over sentences deemed relevant by the query model and decodes summaries autoregressively (see Figure <ref type="figure">1</ref>(b) left).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic MDS Data</head><p>The pre-trained language model can be fine-tuned on MDS datasets (e.g., Multi-News; Fabbri et al. 2019) which are perhaps better aligned with the QFS task since both MDS and QFS operate over document clusters. We additionally propose a way to create synthetic MDS datasets based on SDS data. This is advantageous for two reasons. Firstly, MDS resources are fairly limited compared to SDS data <ref type="bibr" target="#b42">(Zhang et al., 2018;</ref><ref type="bibr" target="#b19">Lebanoff et al., 2018)</ref>. And secondly, by construction, we can ensure various data characteristics which might be desirable (e.g., the number of topics represented in the document collection).</p><p>A challenge with leveraging SDS for QFS is the summary length <ref type="bibr" target="#b19">(Lebanoff et al., 2018)</ref>. Summaries in SDS datasets such as CNN/DailyMail <ref type="bibr" target="#b13">(Hermann et al., 2015)</ref>, are on average 30 tokens long. In contrast, query focused summaries can be as long as 250 tokens. We sidestep this problem by adopting a retrieval-based solution. Specifically, we first build a database with all summaries in the original dataset. For each sample (d i , s i ), we query the database with summary s i . We retrieve N i − 1 other summaries S i with the bigram hashing and TF-IDF matching method described in Chen et al. <ref type="bibr">(2017)</ref>. Then, we fetch their corresponding articles D i , and form the ith cluster as:</p><formula xml:id="formula_4">D * i = {d i } D i (3) ŝ * i = concat(s i , , s i,1 , . . . , s i,N i ), s i,n ∈ S i (4)</formula><p>where D * i are the source documents, and ŝ * i is a potentially redundant summary of them. We set N i to minimize the length difference between ŝ * i and our summary length requirement (e.g., 250 tokens). To obtain the final summary s * i , we eliminate redundancy by selecting sentences from the start of ŝ * i , skipping sentences that have high cosine similarity with those which have already been selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summarization Input</head><p>In generic MDS, the input to the summarization model is a long sequence, i.e., documents within a cluster are concatenated together and sentences in each document follow their original order <ref type="bibr" target="#b9">(Fabbri et al., 2019)</ref>. In QFS, information about absolute (document) position is lost after evidence ranking. As a result, there is a discrepancy between training and testing for our generation model. To mitigate this, we collect all sentences across documents for each training sample and rank them in descending order according to their ROUGE-2 score against the reference summary. The pretrained language model is fine-tuned against this evidence-ranked list of sentences. During inference, when actual queries are available, we instead use the top sentences ranked by our query model as input to summary generation.</p><p>Query Guidance Given that summarization input essentially consists of sentences that are highly relevant to the query, an obvious question concerns the usefulness of explicitly modeling the query during generation. We thus instantiate two conditional language models. For a query-guided summarizer p φ (S|D, Q; φ), we prepend UMRS S to the selected evidence during training and UMR Q at inference. While for a query-agnostic summarizer p φ (S|D; φ), we only consider the selected evidence as input to our summarizer and this setting is identical to generic MDS.</p><p>Length Control QFS tasks usually require summaries of a fixed length budget (e.g, 250 words), whereas summary length is bound to be variable </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Setup</head><p>Datasets We performed experiments on the DUC 2005-2007 QFS benchmarks and TD-QFS <ref type="bibr" target="#b3">(Baumel et al., 2016)</ref>. DUC benchmarks contain long query narratives while TD-QFS focuses on medical texts with short keyword queries. Statistics for both datasets are given in Table <ref type="table" target="#tab_2">1</ref>. We used DUC 2005 as a development set to optimize hyperparameters and select abstractive models, and evaluated performance on the other three datasets.</p><p>We used Multi-News <ref type="bibr" target="#b9">(Fabbri et al., 2019)</ref> and CNN/DailyMail <ref type="bibr" target="#b13">(Hermann et al., 2015)</ref> as our generic summarization datasets to train MARGE (for evidence ranking) and to fine-tune UNILMV2 (for summary generation). Data statistics are shown in Table <ref type="table" target="#tab_3">2</ref>. To create the training and development sets for optimizing MARGE, we sampled sentences from each dataset. Specifically, we took the first and last 20 sentences from each cluster in Multi-News and the first and last three sentences from each article in CNN/DailyMail. For fine-tuning UNILMV2, we used the original Multi-News and the synthetic multi-document version of CNN/DailyMail described in Section 5.</p><p>Implementation Details We used the publicly released BERT model<ref type="foot" target="#foot_2">3</ref> and fine-tuned it for ROUGE regression with a learning rate of 3×10 −5 and a batch size of 128 for 3 epochs on 8 GPUs (GTX 2080 Ti). We trained two summarization models on CNN/DailyMail and Multi-News, respectively, with the same hardware. For both models, we set the maximum input length to 768, and fine-tuned the publicly released UNILMV2 model<ref type="foot" target="#foot_3">4</ref> with a learning rate of 7 × 10 −<ref type="foot" target="#foot_4">5</ref> and a batch size of 16 for 40,000 steps with gradient accumulation every 4 steps. During decoding, we used beam search with beam size 5 and Trigram Blocking <ref type="bibr" target="#b28">(Paulus et al., 2018)</ref> to reduce redundancy. The cosine similarity threshold for redundancy removal was set to 0.6 and summary length was discretized to 10 bins. The λ parameter for label smoothing was set to 0.15. We set γ, the parameter which modulates the proportion of information slots to reveal during masking, to 0 (see Appendix for detailed analysis of γ and its effect on model performance).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>Our experiments evaluate both components of the proposed approach, namely query modeling and summary generation. We assess the evidence ranker and the effectiveness of the unified masking. We also compare our summaries against competitive abstractive and extractive systems using automatic and human-based evaluation. if it were an extractive summary, to better assess coverage and informativeness. We thus take the top sentences subject to a budget of 250 tokens, and remove redundancy by selecting sentences from the top and skipping sentences that have high cosine similarity (e.g., ≥ 0.6) with selected ones. We use ROUGE F1 to evaluate the resulting summaries so that precision is also taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We compare MARGE against Term Frequency, a simple but effective retrieval method that performs particularly well on DUC datasets <ref type="bibr" target="#b16">(Katragadda and Varma, 2009)</ref>. We also compare to two semantic matching models used for extractive QFS <ref type="bibr" target="#b39">(Xu and Lapata, 2020)</ref>: BERTQA which is trained on the joint set of WikiQA <ref type="bibr" target="#b40">(Yang et al., 2015)</ref> and TrecQA <ref type="bibr" target="#b41">(Yao et al., 2013)</ref>, and BERTMRC which is fine-tuned on SQuAD 2.0 <ref type="bibr" target="#b29">(Rajpurkar et al., 2018)</ref>. ORACLE uses reference summaries as queries to retrieve summary sentences. For summarization evaluation, we report upper bound performance (GOLD) which we estimated by comparing a (randomly selected) reference summary against the remaining three reference summaries. In addition, we compare to LEAD which returns all lead sentences of the most recent document (up to 250 words) and LEXRANK <ref type="bibr" target="#b8">(Erkan and Radev, 2004)</ref>, a widelyused unsupervised method based on Markov random walks on sentence-similarity graphs. 5  We summarize ranking and summarization results in Tables <ref type="table">3 and 4</ref> line, BERTQA, under both evaluation tasks. Without recourse to any question/answer annotations or dataset-specific retrieval methods, our model provides more informative input to the downstream generation task. As anticipated, query expansion (+EXPAND) gives a big boost on TD-QFS (which has short queries) leading to better coverage.  <ref type="bibr" target="#b18">(Laskar et al., 2020)</ref> a supervised abstractive system which represents the state of the art on DUC benchmarks. It first extracts relevant sentences for each document with a QA model, it then replaces some of these with reference summary sentences via a paraphrase model, and uses them to further fine-tune BERTSUM <ref type="bibr" target="#b26">(Liu and Lapata, 2019b)</ref>. In its supervised incarnation, two years' DUC datasets are used for training and one for testing. QUERY-SUM <ref type="bibr" target="#b39">(Xu and Lapata, 2020)</ref> is state-of-the-art extractive system which adopts a coarse-to-fine process for salience estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies</head><p>The second block compares our model with two distantly supervised approaches. BART-CAQ <ref type="bibr" target="#b34">(Su et al., 2020)</ref> uses an ensembled QA model to extract answer evidence, and fine-tuned BART <ref type="bibr" target="#b21">(Lewis et al., 2020)</ref> to iteratively generate summaries from paragraphs. PQSUM <ref type="bibr" target="#b18">(Laskar et al., 2020)</ref>, uses fine-tuned BERTSUM to generate summaries for each document in a cluster, and a QA model to rank summary sentences against the query. Table <ref type="table" target="#tab_7">7</ref> compares these models and our own in terms of their training requirements.</p><p>The third block presents the performance of UNILM fine-tuned on Multi-News and CNN/DailyMail following the standard setting in <ref type="bibr" target="#b2">Bao et al. (2020)</ref>. It uses no query guidance or length control. Documents are concatenated as input for training. During testing, sentences are selected with MARGE but ordered according to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>QA PI GS QFS BART-CAQ <ref type="bibr" target="#b34">(Su et al., 2020)</ref> PQSUM <ref type="bibr" target="#b18">(Laskar et al., 2020</ref><ref type="bibr">) PQSUM-WSL (Laskar et al., 2020)</ref> UNILM <ref type="bibr" target="#b2">(Bao et al., 2020</ref>) MARGESUM their original document position. The last block shows two variants of MARGESUM, optimized on Multi-News and a synthetic training set built from CNN/DailyMail. Both take as input sentences selected with MARGE-MN during inference.</p><p>As we can see, without requiring expensive QA data (see Table <ref type="table" target="#tab_7">7</ref>), MARGESUM-CD outperforms existing distantly supervised approaches. Its performance on DUC is on par with one of the strongest extractive systems, while on TD-QFS it is superior across metrics. Also note that MARGE trained on synthetic MDS data outperforms MARGESUM-MN. Compared to Multi-News, synthetic summaries cover more topics and are less redundant, which is suited to QFS where there are usually multiple sub-queries to answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies Table 8 presents the results of several ablation studies on MARGESUM-CD.</head><p>Replacing the input to the summarization component with sentences selected by BERTQA <ref type="bibr" target="#b39">(Xu and Lapata, 2020)</ref> significantly decreases performance, demonstrating that sentences selected by MARGE are useful to downstream abstractive summarization. Removing evidence ranking altogether (−Rank) leads to a large performance drop; this is expected since sentence position information from the original documents does not transfer well to QFS settings. Removing length control (−Length) also hurts performance as does the removal of query guidance (−Query) at inference time. Human Evaluation We also evaluated model summaries in a judgment elicitation study via Amazon Mechanical Turk. Native English speakers (self-reported) were asked to rate query-summary pairs on two dimensions: Succinctness (does the summary avoid unnecessary detail and redundant information?) and Coherence (does the summary make logical sense?). The ratings were obtained using a fivepoint Likert scale. In addition, participants were asked to assess the Relevance of the summary to the query. Crowdworkers read a summary and for each sentence decided whether it is relevant (i.e., it provides an answer to the query), irrelevant (i.e., it does not answer the query), and partially relevant (i.e., it is not clear it directly answers the query). Relevant sentences were awarded a score of 5, partially relevant ones a score of 2.5, and 0 otherwise. Sentence scores were averaged to obtain a relevance score for the whole summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DUC</head><p>Participants assessed summaries created by PQSUM-WSL, the state-of-the-art abstractive system, QUERYSUM, a state-of-the-art extractive system, UNILM-CD, and MARGESUM-CD. <ref type="foot" target="#foot_5">6</ref> We also randomly selected GOLD standard summaries to include as an upper bound. We sampled 20 querycluster pairs from DUC <ref type="bibr">(2006, 2007;</ref> 10 from each set), and 20 pairs from TD-QFS (5 from each cluster) and collected three responses per pair.</p><p>Table <ref type="table" target="#tab_9">9</ref> shows the human ratings for each system (we provide examples of summary output in Appendix C). Participants perceive MARGESUM-CD on par with PQSUM-WSL in terms of query relevance and summary succinctness, while significantly better than PQSUM-WSL and QUERY-SUM in terms of coherence. In fact, participants find summaries PQSUM-WSL summaries as incoherent as those created by the extractive QUERY-SUM; this is probably due to the fact that PQSUM-WSL first generates an abstractive summary for each document and then re-ranks the generated sentences. Therefore, final summary sentences are less related to each other. Summaries from our system are also considered significantly more relevant than UNILM-CD. Compared to PQSUM-WSL, although UNILM-CD is not good at producing relevant content, it maintains relatively higher coherence, demonstrating the effectiveness of training abstractive systems with synthetic data from SDS and generating long summaries at once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>In this work we proposed an abstractive framework for query focused summarization. We provided a unified mask representation for summaries and queries, which enables summaries to serve as proxy queries for model training. As a result, a query model can be trained with generic summarization data without relying on additional question-answering resources. Experimental results across datasets show that the proposed system yields state-of-the-art performance despite the weakly supervised setting, and produces more relevant and coherent summaries compared to existing approaches. In the future, we would like to push this low-resource approach even further and attempt to generate abstractive summaries without access to any summarization datasets. We show in the paper the top k retrieval performance of different models when k ∈ {10, 30}. In some cases, when top sentences are relatively short, the maximum input length to UNILM (which is set to 768) allows for more than 30 sentences to be selected. Therefore, in Table <ref type="table">3</ref>, we further show the top k retrieval performance of evidence rankers with larger k, set to k = 50. Results show that our model outperforms strong baseline systems, and we conclude that it consistently provides high quality content, under varied budgets (k ∈ {10, 30, 50}), to the downstream abstractive summarization task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Evidence Ranking Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>We report the full set of ROUGE results for evidence rankers on extractive summarization in the main paper in Table <ref type="table">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B The Effect of Reveal Ratio</head><p>We show how the mask reveal ratio γ affects model performance in Figure <ref type="figure" target="#fig_0">2</ref>. As we can see, performance on the ROUGE regression task improves as γ increases; this is not surprising, the task becomes easier when fewer tokens are masked; when γ = 1.0, simply counting lexical overlap can solve the task perfectly. However, model performance on the QFS development set <ref type="bibr">(DUC 2005)</ref> shows the opposite trend: actual queries seek information, instead of providing all the information needed. Therefore, the model is required to perform semantic matching <ref type="bibr" target="#b12">(Guo et al., 2016)</ref> to accurately estimate evidence scores. Based on our empirical results, a simple but effective strategy is to mask all information slots (i.e., potential arguments) and reveal the rest of the words (including verbs) in the summary to construct proxy queries for training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Abstractive Summarization Results</head><p>We report the full set of ROUGE results for abstractive summarization models in Table <ref type="table" target="#tab_3">12</ref>. We also show an example of system outputs in Table <ref type="table" target="#tab_13">13</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Datasets and Evaluation Package</head><p>Multi-News and CNN/Daily Mail are used to train the query model and abstractive summarization model described in this work, and they can be downloaded from https://github.com/ Alex-Fabbri/Multi-News and https://github. com/abisee/cnn-dailymail, respectively.</p><p>For evaluation purposes, the TD-QFS dataset is publicly available at https://www.cs.bgu.ac. il/~talbau/TD-QFS/dataset.html. DUC 2005-2007 benchmarks can be requested from NIST: https://www-nlpir.nist.gov/projects/duc/ data.html.</p><p>We computed ROUGE scores with pyrouge, a Python wrapper for the ROUGE summarization evaluation package: https://github.com/ bheinzerling/pyrouge.  The NIDA says it has no evidence to support the claim that EPO can cause liver damage. The drug was approved for use by the U.S. Olympic committee in 1996. The National Association of College Athletes (NAA) is calling for the drug to be banned from all U.S. sports. The NAA says it's time for the U.S. Olympic Committee (IOC) to ban EPO. The drug has been used by more than 200,000 athletes worldwide since it was approved in 1996. PQSUM: About 175,000 teen age girls in the United States have reported using anabolic steroids at least once within a year of the time surveyed a rise of 100 percent since 1991. In 1996 Samantha Reeves became the first female tennis player to have tested positive for steroids. The rise of steroid use in female athletes has led to a rise in women's steroid use. Over the years the number of female steroid related women in the U.S has increased There is no mistaking the dangers of steroids for women with documentation provided by trainers and coaches from the former east german sports empire. In 1996 women were banned from the olympics for a positive test of methandienone. The women involved suffered serious side effects from the drugs and that they knew of the potential danger. She was found to have steroid stanozolol in her system. In the last month Cuban sprinter Merlene Ottey withdrew from the world.championships after testing positive for nandrolone. Some were as young as 12 when they started taking the anabolic steroid pills. The drug use has been generally known since 1977.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><formula xml:id="formula_5">DUC 2006 DUC 2007 TD-QFS R-1 R-2 R-SU4 R-1 R-2 R-SU4 R-1 R-2 R</formula><formula xml:id="formula_6">-QFS R-1 R-2 R-SU4 R-1 R-2 R-SU4 R-1 R-2 R-SU4 PQSUM-WSL † (</formula><p>Pospelova would be the seventh athlete to test positive at the games. Such side effects of anabolic steroids are generally known as with all probability linked to doping. An over the counter supplement called andro raises testosterone and estrogen above normal levels and could be dangerous according to a harvard study by major league baseball and its players union. In 1996.</p><p>MARGESUM-CD: Penn State professor Charles Yesalis estimates the use of steroids among female athletes at 5 percent in swimming, 6 percent in basketball and 10 percent in track and field, a rise of 100 percent since 1991. The national institutes of drug abuse says 175,000 teenage girls in the united states have reported taking anabolic steroids at least once within a year of the time surveyed. The national institute on drug abuse provides information regarding trends, side effects and consequences of such use. Two Moroccan female athletes have been stripped of gold and bronze medals for using a muscle-building steroid in the first reported cases of doping at the Arab games for using the steroid nandrolone, a steroid that has been linked to liver cancer, heart disease and uncontrollable aggressiveness. Two medical experts testifying in the doping trial of a former east german sports doctor say the female swimmers they examined showed health damage linked to performance-enhancing drugs, including liver damage and excessive facial hair. The study, published in Wednesday's Journal of the American Medical Association, is the first to conclude that high doses of the steroids can elevate testosterone levels and that the hormone can be used as a performance-enhancing steroid, such as epitestosterone, as a marker the testosterone is 6 to 1 in the male sex hormone and 5 to 1 for the female steroid hormone epitestoterone -a metabolite that is used as an indicator of testosterone use -the female sex hormone. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model performance when reveal ratio γ is varied. Correlation refers to the average of Pearson's r correlation. The star marker denotes query-agnostic performance where all query tokens are masked, including information slots.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, we propose MARGE, a Masked ROUGE regression framework for evidence estimation and ranking. MARGE intro-The Da Vinci Code was published in 2003, and within six years Brown had booted John Grisham f rom t he No. 1 sl ot on t he l ist of writ ers whose books were most often donated t o Oxf am's 700 shops. -The Independent in 2012 reported Brown's best -sel l er</figDesc><table><row><cell>Masked Summary</cell></row></table><note>-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Multi-Document QFS dataset statistics.    in the training data. Inspired by<ref type="bibr" target="#b10">Fan et al. (2018)</ref>, we quantize summary length into discrete bins. We augment each training instance with this information, i.e., we prepend a length token (e.g.,[230]) to document sentences. At inference, we inform the model of the summary budget by prepending the expected length token (e.g.,[250]) to the sentences selected by the evidence ranker (see Figure1(b)).</figDesc><table><row><cell>Dataset</cell><cell cols="4">2005 2006 2007 TD-QFS</cell></row><row><cell>Domain</cell><cell cols="4">Cross Cross Cross Medical</cell></row><row><cell>Query Narrative</cell><cell cols="3">Long Long Long</cell><cell>Short</cell></row><row><cell>#Clusters</cell><cell>50</cell><cell>50</cell><cell>45</cell><cell>4</cell></row><row><cell>#Queries/Cluster</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>10</cell></row><row><cell>#Documents/Cluster</cell><cell>32</cell><cell>25</cell><cell>25</cell><cell>185</cell></row><row><cell>#Summaries/Query</cell><cell>4-9</cell><cell>4</cell><cell>4</cell><cell>3</cell></row><row><cell>#Words/Summary</cell><cell cols="3">250 250 250</cell><cell>250</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Training data for query modeling and summary generation. CNN/DM statistics for summary generation refer to synthetic MDS dataset proposed in this work (based on CNN/DM).</figDesc><table><row><cell>Query Modeling</cell><cell cols="2">Multi-News CNN/DM</cell></row><row><cell>#Sentence/Doc</cell><cell>20</cell><cell>3</cell></row><row><cell>#Train</cell><cell cols="2">1,615,508 1,719,210</cell></row><row><cell>#Validation</cell><cell>200,824</cell><cell>80,052</cell></row><row><cell>#Words/Proxy Query</cell><cell>111.7</cell><cell>26.0</cell></row><row><cell>#Masks/Proxy Query</cell><cell>35.6</cell><cell>8.1</cell></row><row><cell cols="3">Summary Generation Multi-News CNN/DM</cell></row><row><cell>#Clusters</cell><cell cols="2">44,972 287,227</cell></row><row><cell>#Documents/Cluster</cell><cell>2.8</cell><cell>4.1</cell></row><row><cell>#Words/Summary</cell><cell>257.2</cell><cell>261.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>shows the outcome of</cell></row><row><cell>various ablation studies which assess the effec-</cell></row><row><cell>tiveness of masking and how to best instantiate it.</cell></row><row><cell>Specifically, −Verb additionally treats verbs as in-</cell></row><row><cell>formation slots for sampling and masking; −Mask</cell></row><row><cell>removes masking entirely so that the whole sum-</cell></row><row><cell>mary is revealed; −Query removes the proxy query</cell></row><row><cell>(at training time) and the actual query (at infer-</cell></row><row><cell>ence time); this is to investigate whether our model</cell></row><row><cell>simply learns to judge sentence salience based on</cell></row><row><cell>its own features, instead of performing semantic</cell></row><row><cell>matching with the given query; −OpenIE removes</cell></row><row><cell>the dependency on Open IE and chooses words to</cell></row><row><cell>mask at random. Specifically, we randomly mask</cell></row><row><cell>15% words in summaries as in BERT (Devlin et al.,</cell></row><row><cell>2019) and merge adjacent [MASK] tokens. Perfor-</cell></row><row><cell>mance drops in all cases, especially when queries</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Training requirements for existing QFS models (QA, PI, GS, and QFS stand for question answering, paraphrase identification, generic summarization and query focused summarization).</figDesc><table><row><cell>Models</cell><cell cols="3">DUC 2006 DUC 2007 TD-QFS</cell></row><row><cell>MARGE-CD</cell><cell>15.1</cell><cell>16.9</cell><cell>20.9</cell></row><row><cell>BERTQA</cell><cell>↓1.0</cell><cell>↓2.2</cell><cell>↓6.1</cell></row><row><cell>−Rank</cell><cell>↓1.7</cell><cell>↓3.1</cell><cell>↓1.3</cell></row><row><cell>−Length</cell><cell>↓0.1</cell><cell>↓0.5</cell><cell>↓0.2</cell></row><row><cell>−Query</cell><cell>↓0.5</cell><cell>↓0.3</cell><cell>↓0.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Ablations for MARGESUM trained on CNN/Daily Mail (performance decrease denoted by ↓).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Human evaluation results on DUC (above) and TD-QFS (below): average Relevance, Succinctness, Coherence ratings; †: sig different from MARGESUM-CD; • : sig different from Gold (at p &lt; 0.05, using a pairwise t-test).</figDesc><table><row><cell></cell><cell>Rel</cell><cell>Suc</cell><cell>Coh</cell></row><row><cell>GOLD</cell><cell>3.05</cell><cell>3.29</cell><cell>3.35</cell></row><row><cell>PQSUM-WSL</cell><cell>2.95</cell><cell>3.27</cell><cell>2.93  †•</cell></row><row><cell>QUERYSUM</cell><cell>2.79</cell><cell>3.13</cell><cell>2.94  †•</cell></row><row><cell>UNILM-CD</cell><cell cols="2">2.43  †• 3.09</cell><cell>3.27</cell></row><row><cell cols="2">MARGESUM-CD 2.91</cell><cell>3.25</cell><cell>3.30</cell></row><row><cell>TD-QFS</cell><cell>Rel</cell><cell>Suc</cell><cell>Coh</cell></row><row><cell>GOLD</cell><cell>4.70</cell><cell>4.23</cell><cell>4.60</cell></row><row><cell>QUERYSUM</cell><cell>4.32</cell><cell cols="2">3.90 • 3.80  †•</cell></row><row><cell>UNILM-CD</cell><cell cols="2">3.63  †• 4.12</cell><cell>4.28</cell></row><row><cell cols="2">MARGESUM-CD 4.55</cell><cell>4.02</cell><cell>4.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Performance of evidence rankers on top retrieval. We report the ROUGE 2 recall score for the concatenation of the top 50 retrieved sentences.</figDesc><table><row><cell></cell><cell cols="3">DUC 2006 DUC 2007 TD-QFS</cell></row><row><cell>ORACLE</cell><cell>22.7</cell><cell>26.2</cell><cell>44.6</cell></row><row><cell>TERMFREQ</cell><cell>20.8</cell><cell>25.2</cell><cell>34.0</cell></row><row><cell>BERTQA</cell><cell>22.1</cell><cell>26.1</cell><cell>29.1</cell></row><row><cell>BERTMRC</cell><cell>22.3</cell><cell>25.2</cell><cell>23.2</cell></row><row><cell>MARGE-MN</cell><cell>25.9</cell><cell>31.8</cell><cell>29.4</cell></row><row><cell>+EXPAND</cell><cell>-</cell><cell>-</cell><cell>39.1</cell></row><row><cell>MARGE-CD</cell><cell>23.3</cell><cell>28.8</cell><cell>26.2</cell></row><row><cell>+EXPAND</cell><cell>-</cell><cell>-</cell><cell>26.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Steroid use among female athletes. Discuss the prevalence of steroid use among female athletes over the years. Include information regarding trends, side effects and consequences of such use. GOLD: Increasing numbers of female athletes use anabolic steroids. Among female college athletes, an estimated 5% in swimming, 6% in basketball and 10% in track and field have used steroids. The fastest growing group of users is adolescent females. New steroids are often marketed as dietary supplements and girls are unaware of what they are taking. A young tennis player tested positive for steroids after taking an "all natural" supplement later discovered to contain a variation on the banned steroid nandrolone. A former Olympic track coach believes at least 40% of the U.S. women's team in Seoul had used steroids at some time. Because of their naturally low testosterone levels, steroids have a more dramatic effect on women, boosting their levels up to 10 times. The health effects can be dramatic, including liver damage and tumors, elevated cholesterol, heart attacks, strokes, stunted growth in adolescents, infertility, uncontrollably violent behavior, chronic depression, deeper voices, excessive facial hair, and acne. Many East German female athletes were given steroids, often unbeknownst to them or their parents and suffered serious side-effects. Athletes who have tested positive for steroids include a Bulgarian triple jumper, a Romanian hammer thrower, a Russian runner, a Dominican high, a Jamaican sprinter, a Spanish pole vaulter, a German marathon runner, two Moroccan athletes, and two Chinese Taipei weightlifters. A number of female Chinese athletes have tested positive, including several swimmers and rowers. International organizations impose bans of between two months and life on athletes found guilty of using illegal steroids. UNILM-CD: At least 23 Chinese athletes, mostly women, have tested positive for steroid use since 1990. Such side-effects of anabolic steroids have been generally known since 1977. Some of the athletes were as young as 12 when they started taking the steroids. EPO is one of at least 20 steroids prohibited by the International Olympic Committee. The drug is legal and sold over-the-counter, but is banned by the National Olympic Committee, the National Football League and the National Collegiate Athletic Association. The National College Athletic Association (ACA) has banned EPO for life. EPO has been linked to a number of health problems, including liver damage and liver cancer. The ACA says EPO's use in the U.S.is safe, effective and safe to use. The National Institute of Drug Abuse (NIDA) is investigating the use of EPO in the United States.</figDesc><table><row><cell cols="2">Laskar et al., 2020) 43.5 10.8 16.5 44.7 12.4 17.7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">QUERYSUM  *  (Xu and Lapata, 2020) 41.6 9.5 15.3 43.3 11.6 16.8 44.3 16.1 20.7</cell></row><row><cell>BART-CAQ (Su et al., 2020)</cell><cell>38.3 7.7 12.9 40.5 9.2 14.4</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PQSUM (Laskar et al., 2020)</cell><cell>40.9 9.4 14.8 42.2 10.8 16.0</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>UNILM-MN</cell><cell cols="4">34.6 6.7 11.8 35.5 7.6 12.3 36.2 8.1 12.9</cell></row><row><cell>UNILM-CD</cell><cell cols="4">37.6 8.3 13.6 39.6 10.1 14.9 40.1 11.8 16.7</cell></row><row><cell>MARGESUM-MN</cell><cell cols="4">39.1 9.1 14.3 42.1 11.7 16.5 40.8 11.6 16.5</cell></row><row><cell>MARGESUM-CD</cell><cell cols="4">40.2 9.7 15.1 42.5 12.0 16.9 45.5 16.6 20.9</cell></row><row><cell cols="5">Table 12: Performance of abstractive summarization systems. R-1, R-2 and R-SU4 stand for the F1 score of</cell></row><row><cell>ROUGE 1, 2, and SU4, respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* / †: extractive/supervised method.Query:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>System outputs for cluster D0602C in DUC 2006. The gold summary answers the query covering four main aspects (denoted with different colors): (1) trend; (2) side-effects; (3) consequences of such use; (4) historical cases. Both outputs from MARGESUM-CD and PQSUM have a good coverage of the main query focuses. Compared to PQSUM, MARGESUM-CD produces a more coherent summary for the given query narrative with a more natural topic flow.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Our code and data is available at https://github. com/yumoxu/marge.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">The Cloze task has been also employed in recent work in generic summarization<ref type="bibr" target="#b15">(Huang et al., 2020)</ref>. In comparison, we address a different research question (i.e., query modeling vs. summary evaluation) based on a different formulation (masked ROUGE regression vs. multiple-choice QA).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://github.com/huggingface/pytorch-transformers</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://github.com/microsoft/unilm</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">To examine ranking performance, we exclude multi-stage frameworks like<ref type="bibr" target="#b39">Xu and Lapata (2020)</ref> that rerank the evidence with additional modules (e.g., centrality).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">We are grateful to Md Tahmid Rahman Laskar for providing us with the output of their PQSUM-WSL system. We include PQSUM-WSL only for human evaluation on DUC since it was not evaluated on TD-QFS<ref type="bibr" target="#b18">(Laskar et al., 2020)</ref> and system output is not available.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers for their valuable feedback. We acknowledge the financial support of the European Research Council (Lapata; award number 681760). This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via contract FA8650-17-C-9118. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation therein.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving query focused summarization using look-ahead strategy</title>
		<author>
			<persName><forename type="first">Rama</forename><surname>Badrinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Venkatasubramaniyan</surname></persName>
		</author>
		<author>
			<persName><surname>Veni Madhavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd European Conference on Advances in Information Retrieval</title>
				<meeting>the 33rd European Conference on Advances in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="641" to="652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<title level="m">MS MARCO: A human generated machine reading comprehension dataset</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">UniLMv2: Pseudo-masked language models for unified language model pre-training</title>
		<author>
			<persName><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songhao</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37rd International Conference on Machine Learning</title>
				<meeting>the 37rd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="642" to="652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Topic concentration in query focused summarization datasets</title>
		<author>
			<persName><forename type="first">Tal</forename><surname>Baumel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
				<meeting>the 30th AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2573" to="2579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BioMedBERT: A pre-trained biomedical language model for qa and ir</title>
		<author>
			<persName><forename type="first">Souradip</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaba</forename><surname>Bisong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shweta</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riley</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Mosconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
				<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Adam Fisch, Jason Weston; Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2020. 2017</date>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
	<note>Proceedings of the 55th Annual Meeting of the</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overview of duc</title>
		<author>
			<persName><forename type="first">Trang</forename><surname>Hoa</surname></persName>
		</author>
		<author>
			<persName><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Document Understanding Conference</title>
				<meeting>the 2005 Document Understanding Conference<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
				<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis</addrLine></address></meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Minnesota</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName><forename type="first">B</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Paraphrasing</title>
				<meeting>the Third International Workshop on Paraphrasing<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-News: A large-scale multi-document summarization dataset and abstractive hierarchical model</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Richard Fabbri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianwei</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1074" to="1084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Controllable abstractive summarization</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</title>
				<meeting>the 2nd Workshop on Neural Machine Translation and Generation<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bottom-up abstractive summarization</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4098" to="4109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
				<meeting>the 25th ACM International on Conference on Information and Knowledge Management<address><addrLine>Indianapolis, Indiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomáš</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
				<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of duc</title>
		<author>
			<persName><forename type="first">Hoa</forename><surname>Td</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Document Understanding Conference</title>
				<meeting>the 2006 Document Understanding Conference<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward</title>
		<author>
			<persName><forename type="first">Luyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5094" to="5107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Queryfocused summaries or query-biased summaries?</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Katragadda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing</title>
				<meeting>the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing<address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">WSL-DS: Weakly supervised learning with distant supervision for query focused multi-document abstractive summarization</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Tahmid Rahman Laskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enamul</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">Xiangji</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
				<meeting>the 28th International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5647" to="5654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adapting the neural encoder-decoder framework from single to multi-document summarization</title>
		<author>
			<persName><forename type="first">Logan</forename><surname>Lebanoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiqiang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4131" to="4141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">Marjan Ghazvininejad,. 2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unsupervised question answering by cloze translation</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04980</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cascaded attention based unsupervised information distillation for compressive summarization</title>
		<author>
			<persName><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussells, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017a</date>
			<biblScope unit="page" from="2081" to="2090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Salience estimation via variational auto-encoders for multi-document summarization</title>
		<author>
			<persName><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th AAAI Conference on Artificial Intelligence</title>
				<meeting>the 31th AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017b</date>
			<biblScope unit="page" from="3497" to="3503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hierarchical transformers for multi-document summarization</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019a</date>
			<biblScope unit="page" from="5070" to="5081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Text summarization with pretrained encoders</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019b</date>
			<biblScope unit="page" from="3730" to="3740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Diversity driven attention model for query-based abstractive summarization</title>
		<author>
			<persName><forename type="first">Preksha</forename><surname>Nema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirban</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaraman</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1063" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A deep reinforced model for abstractive summarization</title>
		<author>
			<persName><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Learning Representations, Vancouver</title>
				<meeting>the 6th International Conference on Learning Representations, Vancouver</meeting>
		<imprint>
			<publisher>Canada</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Supervised open information extraction</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="885" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalizing question answering system with pretrained language model fine-tuning</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeondey</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering</title>
				<meeting>the 2nd Workshop on Machine Reading for Question Answering<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="203" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">CAiRE-COVID: A question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farhad</forename><surname>Bin Siddique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elham</forename><surname>Barezi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on NLP for COVID-19</title>
				<meeting>the 1st Workshop on NLP for COVID-19</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>EMNLP 2020</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cloze Procedure&quot;: A new tool for measuring readability</title>
				<imprint>
			<date type="published" when="1953">1953</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="415" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Manifold-ranking based topic-focused multidocument summarization</title>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
				<meeting>the 20th International Joint Conference on Artificial Intelligence<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2903" to="2908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">CTSUM: extracting more certain summaries for news articles</title>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th international ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
				<meeting>the 37th international ACM SIGIR Conference on Research &amp; Development in Information Retrieval<address><addrLine>New York, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="787" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Coarse-to-fine query focused multi-document summarization</title>
		<author>
			<persName><forename type="first">Yumo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3632" to="3645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for open-domain question answering</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Answer extraction as sequence tagging with tree edit distance</title>
		<author>
			<persName><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter</title>
				<meeting>the 2013 Conference of the North American Chapter<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural single-document summarization model for abstractive multi-document summarization: A pilot studyadapting</title>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Natural Language Generation</title>
				<meeting>the 11th International Conference on Natural Language Generation<address><addrLine>Tilburg University</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="381" to="390" />
		</imprint>
	</monogr>
	<note>The Netherlands</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
