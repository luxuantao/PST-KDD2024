<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Language Model Cascades</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-21">21 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
							<email>&lt;ddohan@google.com&gt;</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Winnie</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Alphabet, X, the Moonshot Factory</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Bieber</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raphael</forename><forename type="middle">Gontijo</forename><surname>Lopes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rif</forename><forename type="middle">A</forename><surname>Saurous</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Language Model Cascades</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-21">21 Jul 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2207.10342v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prompted models have demonstrated impressive few-shot learning abilities. Repeated interactions at test-time with a single model, or the composition of multiple models together, further expands capabilities. These compositions are probabilistic models, and may be expressed in the language of graphical models with random variables whose values are complex data types such as strings. Cases with control flow and dynamic structure require techniques from probabilistic programming, which allow implementing disparate model structures and inference strategies in a unified language. We formalize several existing techniques from this perspective, including scratchpads / chain of thought, verifiers, STaR, selection-inference, and tool use. We refer to the resulting programs as language model cascades.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Language models (LMs) have demonstrated impressive few-shot learning abilities <ref type="bibr" target="#b3">(Brown et al., 2020;</ref><ref type="bibr" target="#b5">Chowdhery et al., 2022)</ref>. This has led to a number of proposals to use LMs as the basis of informal reasoning, including scratchpads <ref type="bibr" target="#b14">(Nye et al., 2021)</ref>, chain of thought prompting <ref type="bibr" target="#b24">(Wei et al., 2022;</ref><ref type="bibr" target="#b23">Wang et al., 2022)</ref>, learned verifiers <ref type="bibr" target="#b6">(Cobbe et al., 2021)</ref>, selection-inference <ref type="bibr" target="#b8">(Creswell et al., 2022)</ref>, and bootstrapping <ref type="bibr" target="#b27">(Zelikman et al., 2022)</ref>. They have also been applied in formal mathematics settings to guide theorem provers <ref type="bibr" target="#b17">(Polu &amp; Sutskever, 2020)</ref>. These methods involve prompting to encourage step-bystep reasoning, repeated interactions with a single LM, or multiple LMs linked together, with the models being fine-tuned or prompted in different ways.</p><p>In this position paper, we argue that a useful unifying framework for understanding and extending this disparate body of work is in terms of probabilistic programming languages (PPL) extended to work with strings, instead of more atomic data types like integers and floats. That is, we use a PPL to define a joint probability model on stringvalued random variables, parameterized using LMs, and then condition this model on string-valued observations in order to compute a posterior over string-valued unknowns, which we can then infer. We call such a probabilistic program a language model cascade. We show that this framework captures many recent approaches, and also allows us to tackle more complex multi-step reasoning problems. By implementing many disparate model structures and inference strategies in a single framework, we hope that language model cascades will enable the development of generic procedures to perform inference, tune parameters, and choose prompts based on end-to-end objectives.<ref type="foot" target="#foot_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>There is a rich prior literature on probabilistic programming languages (PPLs), which extend probabilistic graphical models to support more complex joint distributions whose size and "shape" can itself be stochastic (e.g., a graph unrolled for a random number of iterations, until a data-dependent stopping criterion is met). PPLs extend traditional programming languages with the ability to sample from distributions and observe values of variables based on data (i.e. condition the model). The semantics of sample and observe vary depending on the inference algorithm. For more details, see van de <ref type="bibr" target="#b22">Meent et al. (2018)</ref>.</p><p>Recently there has been an explosion of interest in large language models, such as GPT-3 <ref type="bibr" target="#b3">(Brown et al., 2020)</ref> and PaLM <ref type="bibr" target="#b5">(Chowdhery et al., 2022)</ref>. These can be used for tasks such as "zero-shot" question-answering. In this setting, we provide the question Q as a prompt to the LM, and then sample answers from the model, which we denote by p(A|Q, ?), where ? are the pre-trained model parameters. Alternatively, we can compute the MAP answer, Language Model Cascades ? = argmax A p(A|Q, ?).</p><p>To ensure the model "does the right thing", we can provide a small training set of question-answer pairs, D = {(Q m , A m ) : m = 1 : M } pairs. This can be provided as extra context to the model, provided in the text prompt, followed by sampling from p(A|Q, D, ?). We refer to this as "few-shot prompting". We can also fine-tune the model parameters on D to get ? ? , and then sample from p(A|Q, ? ? ).</p><p>We can improve performance by introducing an additional auxiliary "thought" variable, and then extend the model to have the form p(A, T |Q) = p(A|T, Q)p(T |Q), where each conditional is computed using an LM which includes its conditioning variables as a part of its input. Work on scratchpads <ref type="bibr" target="#b14">(Nye et al., 2021)</ref> and chain of thought <ref type="bibr" target="#b24">(Wei et al., 2022)</ref> illustrate this, and finetune or prompt the LM to produce this auxiliary thought before answering.</p><p>We typically condition this on a small set D S of (A m , T m , Q m ) triples, and optionally a larger set D L of (A m , Q m ) pairs. We then compute a distribution over answers to a test question using</p><formula xml:id="formula_0">p(A|Q) = T p(A|Q, T )p(T |Q)<label>(1)</label></formula><p>where p(?) = p(?|D L , D S , ?) is the prior predictive distribution. (Scratchpad creates its prior predictive by finetuning, while Chain of Thought adds D S to the LM prompt.)</p><p>In practice, we cannot sum over all possible strings T in Equation (1). The most common approach is to compute the MAP estimate T = argmax p(T ) using beam search, and then to approximate the sum over T with this single value. More recently, Self Consistency <ref type="bibr" target="#b23">(Wang et al., 2022)</ref> proposed to sample multiple values for T using forward sampling of (A, T ) given Q, and then taking the answer A that is most common in this set<ref type="foot" target="#foot_1">2</ref> .</p><p>PromptChainer <ref type="bibr">(Wu et al., 2022)</ref> proposes a visual interface for composing language models together, specifying control flow and prompting strategies for each node in a chain. Nodes may query language models or external systems. Socratic models <ref type="bibr" target="#b28">(Zeng et al., 2022)</ref> extends model chaining to the multimodal setting and demonstrates zeroshot abilities on tasks for which no single model exists.</p><p>The Eliciting Latent Knowledge proposal (ELK, 2022) suggests making latent variables explicit, modelled using a Bayesian network, to improve interpretability and safety for advanced AI systems.</p><p>Ortega et al. ( <ref type="formula">2021</ref>) explains a formalism for LM finetuning with causal graphical models in order to extend the pre-dictive capabilities of AI agents towards more adaptive behaviour. They focus on analysing an auto-regressive action (random variable) prediction scheme in the interactive setting of RL where a model is simultaneously a generator and predictor of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Cascades</head><p>In this section, we show how to create cascades of LMs to tackle various language-based reasoning problems  <ref type="bibr" target="#b10">Kochurov et al. (2019)</ref>. A pretrained LM is used to parameterize all conditional distributions. A cascade supports arbitrary control flow and recursion. While the current presentation is in terms of few-shot prompting of causal language models, we emphasize that the ideas are immediately applicable to finetuned models, masked LM setting, and other complex data types including images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Scratchpads and Chain of thought</head><p>As our first example, we show how to represent a chain of thought <ref type="bibr" target="#b14">(Nye et al., 2021;</ref><ref type="bibr" target="#b24">Wei et al., 2022)</ref> as shown in Figure <ref type="figure">1</ref> and subsequent graphical model figures; refer to the corresponding probabilistic programs in Appendix A. We condition the A node not just on the test question Q, but also on previous (Q m , T m , A m ) triples, which constitute the few-shot prompting part of the model. This is denoted by the shaded nodes inside the plate. Inference can be implemented by ancestral sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Semi-supervised learning</head><p>In Section 3.1, we provided a manually created set (Q m , T m , A m ) triples, where the "thoughts" or "rationalizations" were provided. A more scalable approach is to define a small set D S of such "supervised" triples, but then to provide a larger set D L of (Q m , A m ) pairs, which are eas-</p><formula xml:id="formula_1">Q m T m A m M Q T A Figure 1. Question-Thought-Answer model.</formula><p>def qta(): q = yield S('question') t = yield S('thought', question=q) a = yield S('answer', question=q, thought=t) return a ier to gather. We can augment the pairs in D L by adding the hidden T m variable to get a semi-supervised setup, shown in Figure <ref type="figure">3</ref>.</p><formula xml:id="formula_2">Q T A Q m T m A m M Figure 3</formula><p>. QTA model with hidden thoughts.</p><p>The Self-Taught Reasoner (STaR) <ref type="bibr" target="#b27">(Zelikman et al., 2022)</ref> proposes a procedure for fine-tuning LMs in the chainof-thought type setting. We can interpret their method as a stochastic EM-like procedure in the cascade of Figure <ref type="figure">3</ref>. In particular, they first fine-tune on the "fully observed" dataset</p><formula xml:id="formula_3">D S = {(Q m , T m , A m )}.</formula><p>Then they impute the unknown T i values in the "partially observed" dataset D L = {(Q m , T m =?, A m )} during the "E" step by doing rejection sampling on p(T, A|Q m ) until finding a thought which leads to the known correct answer. If sampling (T, A) given the question fails to find the correct answer, they sample thoughts from p(T |Q m , A m ). This uses a recognition network to approximately sample from the posterior distribution over thoughts given the known correct answer. They call this approach "rationale generation with rationalization". They then update the parameters in the "M" step based on these imputed thoughts. By interpreting the rationale generation at this higher level of abstraction, we open up the possibility of applying this tuning method to other types of cascades.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Selection-Inference</head><p>Selection Inference <ref type="bibr" target="#b8">(Creswell et al., 2022</ref>) is a recent example of multiple interacting LM modules. It proposes splitting reasoning into: the selection module which selects a subset of facts given a question, and the inference module which infers new facts given this subset.</p><p>It may be represented by the model in Figure <ref type="figure">4</ref>. Here S is the selection of a subset of "facts" from a pre-specified set of facts, and I is an inference driven by that fact.</p><p>The S and I nodes can be iterated to do multistep reasoning. The model is "trained" by giving it examples,</p><formula xml:id="formula_4">D = {(Q m , {F mj }, S m , I m , A m ) : m = 1 : M }, as part of the prompt. Q F FACTS S I A Figure 4</formula><p>. Selection inference as a cascade. Here S is the selected subset of facts and I is an inference driven by this subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Verifiers</head><p>Although adding explicit "thought" variables to a model has been found to improve performance, models still arrive at incorrect answers, or the correct answer for an erroneous reason. An intuitive way to improve model performance is to train it to judge whether an answer and thought are likely to be "valid". <ref type="bibr" target="#b6">Cobbe et al. (2021)</ref> propose using a separate model as a verifier to filter solutions to reasoning tasks.</p><p>We can create a "labeled" training set of the form</p><formula xml:id="formula_5">D = {(Q m , T m , A m , V m },</formula><p>where we add a "verification" label V m ? {0, 1}, representing whether the thought T m is a valid form of reasoning for deriving A m from Q m , and A m is the correct answer. This can be particularly helpful in settings where there may be more than one way of deriving the answer. The verifiers may be used to reject incorrect examples in ancestral sampling, and the thought generator may itself be conditioned on the verifiers being correct by finetuning or prompting, reminiscent of RL as inference <ref type="bibr" target="#b12">(Levine, 2018)</ref> and goal-conditioned policies such as decision-transformer <ref type="bibr" target="#b4">(Chen et al., 2021)</ref>.</p><formula xml:id="formula_6">Language Model Cascades Q T 1 T 2 T 3 A V 1 V 2 V 3</formula><p>Figure <ref type="figure">5</ref>. Verifier model. The small double-ringed nodes are deterministic buffer nodes that concatenate their inputs, accumulating all past strings. All other nodes are stochastic. The verifiers are observed to take on the "correct" value.</p><p>We can extend this to N -step reasoning as follows (where we drop conditioning on D for brevity):</p><formula xml:id="formula_7">p(A|Q, V1:N = 1) ? T 1:N p(A, T1:N , V1:N = 1 | Q),</formula><p>where</p><formula xml:id="formula_8">p(A, T1:N , V1:N = 1|Q) = N t=1 p(Tt|T1:t-1, Q)p(Vt = 1|T1:t, Q) ? p(A|T1:N , Q).</formula><p>We can represent this as shown in Figure <ref type="figure">5</ref>.</p><p>To see why such a verification model can be useful, consider (for simplicity) the case where N = 1. Suppose we have trained the model to generate valid thoughts and answers by giving it suitable training examples, and then we generate K samples (T k , V k , A k ) ? p(T, V, A|Q, D).</p><p>We can then rank the samples for validity by computing r k = p(V k = 1|A k , Q, D), and then picking the A k with largest score r k . <ref type="bibr" target="#b6">Cobbe et al. (2021)</ref> train the verifier to predict a binary correctness label. <ref type="bibr" target="#b19">Scheurer et al. (2022)</ref> incorporates natural language feedback, and finds that learning is significantly more sample efficient. Preliminary evidence suggests that LMs are capable of critiquing their own chain of reasoning in language, in which case the verifier produces natural language and p(V 1:N = 1|Q, A, T 1:N ) becomes the likelihood of the verifier taking on a particular string value, such as p(V 1:N = "The reasoning and solution are correct."|...). <ref type="bibr" target="#b18">Saunders et al. (2022)</ref> study model generated critiques in the context of summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Tool-use</head><p>The applications discussed so far involve iterating a language model, within some control flow, without external feedback. There are many tasks of interest in which a model is interacting with external systems. <ref type="bibr" target="#b6">Cobbe et al. (2021)</ref> has an LM use a calculator to solve math tasks, while <ref type="bibr" target="#b13">Nakano et al. (2021)</ref> put an LM in a loop with a web browser to answer questions. Using PPLs to represent these probabilistic models allows easily representing these cases, by writing the call to the external tool, such as the calculator, directly into the program. Then techniques from simulation based inference, for example, can be applied to do inference in such situations <ref type="bibr" target="#b7">(Cranmer et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Twenty questions</head><p>In this section, we discuss experimental results using cascades to solve the "Twenty Questions" task from BigBench <ref type="bibr">(BIG-bench collaboration, 2021)</ref>. This task involves a conversation between two agents, Alice and Bob. Both agents are presented with the rules of the game, and Alice is additionally presented with a concept (e.g. 'apple') to describe. Bob has to guess the concept by asking a series of questions B t of the form "Is it X?", to which Alice answers A t ? {'Yes.', 'No.'}. We repeat this process until Bob guesses correctly, or we hit the limit of T rounds. This can be thought of as a pair of interacting Markov chains, which exchange strings, until some final end state is reached, as illustrated in Figure <ref type="figure" target="#fig_1">6</ref>. The goal is to infer what questions Bob should ask to guess the concept as quickly as possible. This can be cast as a reinforcement learning problem with string-valued actions, or equivalently as an inference problem where we condition on the goal state that A T = 'yes' for the soonest possible T (c.f., planning as inference <ref type="bibr" target="#b12">(Levine, 2018)</ref>).</p><formula xml:id="formula_9">CONCEPT RULES B 1 B 2 A 1 A 2 . . .</formula><p>In our current preliminary experiments, we use a forward sampling approach (aka ancestral sampling), in which we sample 50 conversations per concept with temperature 1.0.</p><p>We consider a trial successful if the target concept appears in B t . (i.e., Bob guesses the right answer). We reject a sampling chain early if it is "malformed" (e.g., Bob generates a response that is not a question).</p><p>Bob's turn starts with 'Is the concept' which we complete with the LM. Then we let Alice generate an answer; we post-process Alice's response by replacing all mentions of the true concept with the generic word "concept", to prevent information leakage. Using the LaMDA 137B large LM <ref type="bibr" target="#b20">(Thoppilan et al., 2022)</ref>, we find that the model is able to solve 29% of the tasks. See Appendix B for more details.</p><p>Language Model Cascades</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>We have shown how probabilistic programming provides a flexible formalism for composing models together to define complex probabilistic models over strings, placing many existing algorithms in a unified framework. While this suggests the possibility of applying a variety of existing inference and train-time techniques to the resulting models, the present work does not evaluate methods beyond rejection sampling.</p><p>We can also cast many planning and RL tasks in our framework, by using the perspective of control as inference.</p><p>While we restrict presentation to the string setting, the ideas presented here are applicable to multimodal settings as well, allowing us to combine image and text models into a larger system.</p><p>A challenge applying cascades in practice is the difficulty of probabilistic inference in models with string-valued variables. Previous work in particle based inference for probabilistic programs provides some hope in this direction <ref type="bibr" target="#b21">(Tolpin et al., 2016)</ref>.</p><p>The core technical challenge is efficient inference, as is usually the case with PPLs. A key insight, which we intend to explore in future work, is that we can emulate posterior inference by training the LM to "fill in the blanks", corresponding to the unknown variables. A similar idea is explored in foundation posteriors <ref type="bibr">(Wu &amp; Goodman, 2022)</ref>, applied to Stan probabilistic programs, demonstrating that LMs are applicable to numerical data types as well. In other words, we can use LMs as proposal distributions, or guide networks. We also intend to explore fine-tuning methods, going beyond the few-shot prompting approach described here.</p><p>Recent advances in program synthesis suggest the possibility of probabilistic program induction <ref type="bibr" target="#b11">(Lake et al., 2015;</ref><ref type="bibr" target="#b9">Goodman et al., 2014)</ref> to search for cascades which solve a target task, rather than assuming a fixed probabilistic program structure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Chain of thought cascade in Python. Each yield S(...) statement samples a string from an LM. The name of the random variable is provided as the first argument to S.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Twenty questions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. A cascade is a probabilistic program that includes string-valued random variables, sampled from an LM. For example, Figure 2 is a simple cascade for question answering. Each of the yield expressions return a string distributed according to the language model S. 3 This program defines a joint distribution over the variables question, thought, and answer. Programs with complex control flow and observations are included in Appendix A.</figDesc><table /><note><p><p><p><p><p>We implement cascades as a trace-based probabilistic programming language embedded in Python via effect handlers, inspired by</p><ref type="bibr" target="#b2">Bingham et al. (2018)</ref></p>;</p><ref type="bibr" target="#b16">Phan et al. (2019)</ref></p>, and via coroutines, inspired by</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>An implementation is available at model-cascades.github.io</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>This bucketing is practical because most standard benchmarks have answers that are just a couple words.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The first argument to S defines a unique name for the random variable, and the remaining arguments conditions the LM on a string prefix. A variable may be marked as observed within the program, S('varname', obs='observed value'), or at inference time</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>B.2. ExamplesAlice Prompt: X 0 Hello Alice, I am Bob. X 1 Hello Bob X 2 Hello Alice, we are going to play twenty questions. I will think of a concept and Bob will ask you a series of questions to which you will respond to 'Yes' or 'No' until Bob is able to guess the concept I am thinking. X 1 Sounds good. What is the concept? X 2 The concept is 'love'. X 1 The concept is love ? Perfect, I got it. Bob, what is your first question? Bob Prompt: X 0 Hello Alice, I am Bob. X 1 Hello Bob, we are going to play twenty questions. I will think of a concept and you will ask me a series of questions to which I will respond to each question with a 'Yes' or 'No', until you are able to guess the concept I am thinking. What is your first question? Common Conversation: X 0 Hello Alice, I am Bob. X 1 Hello Bob, we are going to play twenty questions. I will think of a concept and you will ask me a series of questions to which I will respond to each question with a 'Yes' or 'No', until you are able to guess the concept I am thinking. What is your first question? X 0 Is the concept a vegetable? X 1 No X 0 Is the concept a mineral? X 1 No X 0 Is the concept an animal? X 1 No X 0 Is the concept an instrument? X 1 No X 0 Is the concept an abstract concept such as love or happiness? SUCCESS!</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Acknowledgements</head><p>We thank <rs type="person">Alex Gray</rs>, <rs type="person">Andreas Stuhlm?ller</rs>, <rs type="person">Ben Poole</rs>, <rs type="person">Du Phan</rs>, <rs type="person">Ellen Jiang</rs>, <rs type="person">Maarten Bosma</rs>, <rs type="person">Matt Hoffman</rs>, <rs type="person">Michael Terry</rs>, <rs type="person">Sharad Vikram</rs>, <rs type="person">Sherry Tongshuang Wu</rs>,and <rs type="person">Tuan Anh Le</rs> for helpful discussions.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Language Model Cascades A. Implementation A.1. Inference Given a program representing a probabilistic model, inference reifies specific unobserved values conditioned on observed values. The simplest inference algorithm is ancestral sampling (aka forward sampling). The basic inference API is: infer(question_thought_answer_critique, seed=0, # Specify observed variables: observe={'question': 'Alice made 37 dollars selling ...', 'critique': 'The reasoning and arithmetic are correct.'}, # Specify few-shot examples: examples=[{'question': 'example question 1', 'thought': 'example thought 1', 'answer': 'example answer 1', 'critique': 'example critique 1'}, ...])</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Code examples</head><p>In each example below, S is a string distribution. It consists of turning the input values into a prompt, together with any examples provided as few-shot examples to the 'infer' method, and sampling until some stopping criterion.</p><p>The basic question answering graph directly generates the answer given the question:</p><p>def question_answer(): q = yield S('question') a = yield S('answer', question=q) return a</p><p>Chain of thought introduces a latent thought before producing an answer: def question_thought_answer(): q = yield S('question') t = yield S('thought', question=q) a = yield S('answer', question=q, thought=t) return a</p><p>Self critique introduces a step in which the model critiques its own reasoning in natural language:</p><p>def question_thought_answer_critique(): q = yield S('question') t = yield S('thought', question=q) a = yield S('answer', question=q, thought=t) c = yield S('critique', question=q, thought=t, answer=a) return a</p><p>A sentence-level verifier may be used to critique individual steps of reasoning. Furthermore, when to halt generation may itself be a random variable:</p><p>def qta_verifier(max_steps=3): q = yield S('question')   X 0 Is the concept something that is a natural entity? X 1 NO X 0 Is the concept something that was invented or is man made? X 1 the concept is concept which is something that was invented so i will answer the question with 'yes' X 0 Is the concept a device? X 1 Yes X 0 Is the concept a computer? X 1 The concept is not about a computer X 0 Is the concept a piece of clothing? X 1Yes X 0 Is the concept a shirt? X 1 no :: the concept concept is not a shirt X 0 Is the concept pants? X 1 No X 0 Is the concept shoes? SUCCESS!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Model Cascades</head><p>Example of wrong answer. Alice Prompt: X 0 Hello Alice, I am Bob. X 1 Hello Bob X 2 Hello Alice, we are going to play twenty questions. I will think of a concept and Bob will ask you a series of questions to which you will respond to 'Yes' or 'No' until Bob is able to guess the concept I am thinking. X 1 Sounds good. What is the concept? X 2 The concept is 'television'. X 1 The concept is television ? Perfect, I got it. Bob, what is your first question? Bob Prompt: X 0 Hello Alice, I am Bob. X 1 Hello Bob, we are going to play twenty questions. I will think of a concept and you will ask me a series of questions to which I will respond to each question with a 'Yes' or 'No', until you are able to guess the concept I am thinking. What is your first question? Common Conversation: X 0 Is the concept an animal, vegetable or mineral? X 1 neither, i already know the answer, it's concept X 0 Is the concept something used? X 1 Yes X 0 Is the concept a game? X 1 Yes X 0 Is the concept played with a board? X 1 No X 0 Is the concept from the Monopoly board? X 1 No (to be alternated) X 0 Is the concept from the Monopoly board? X 1 No X 0 Is the concept something that is kept in the box? X 1 No X 0 Is the concept a card? X 1 No X 0 Is the concept something that can be held? X 1 no (concept can't be held) X 0 Is the concept money? X 1 No REJECT! Bob did not get "television" in ten rounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Code for twenty questions</head><p>This code example demonstrates more directly constructing the prompt for for a task, rather than relying on automatic prompting.</p><p>def twenty_questions_program(concept, max_questions): alice_prompt = get_prompt_from_alice(concept, max_questions) bob_prompt = get_prompt_from_bob(concept, max_questions) common_conversation = "" # iterate over rounds of questions and answers for round_number in range(1, max_questions + 1): current_turn = "\nX 0 Is the concept" # Bob"s generates question.  <ref type="bibr">Helsinki, Finland (estimated)</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">ARC&apos;s first technical report: Eliciting latent knowledge -AI alignment forum</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">BIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabilities of lan-guage models</title>
		<ptr target="https://github.com/google/BIG-bench/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In preparation</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Bingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jankowiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Karaletsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szerlip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Horsfall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><surname>Pyro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-10">October 2018</date>
			<publisher>Deep universal probabilistic programming</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><surname>Others</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Decision transformer: Reinforcement learning via sequence modeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-06">June 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">PaLM: Scaling language modeling with pathways</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-04">April 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2110.14168</idno>
		<ptr target="https://arxiv.org/abs/2110.14168" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The frontier of simulation-based inference</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Louppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U. S. A</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="30055" to="30062" />
			<date type="published" when="2020-12">December 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Selection-Inference: Exploiting large language models for interpretable logical reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-05">May 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Concepts in a probabilistic language of thought</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gerstenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014 2014</date>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">PyMC4: Exploiting coroutines for implementing a probabilistic programming framework</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kochurov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2019 Workshop Program Transformations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Model Cascades</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Reinforcement learning and control as probabilistic inference: Tutorial and review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Browser-assisted question-answering with human feedback</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Button</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><surname>Webgpt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-12">December 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Show your work: Scratchpads for intermediate computation with language models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-11">November 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Shaking the foundations: delusions in sequence models for interaction and control</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Del?tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grau-Moya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Degrave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perolat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.10819</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Composable effects for flexible and accelerated probabilistic programming in NumPyro</title>
		<author>
			<persName><forename type="first">D</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jankowiak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-12">December 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName><forename type="first">S</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-09">September 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Self-critiquing models for assisting human evaluators</title>
		<author>
			<persName><forename type="first">W</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2206.05802" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Training language models with language feedback</title>
		<author>
			<persName><forename type="first">J</forename><surname>Scheurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-04">April 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Language models for dialog applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghafouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Menegali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pickett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Soraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zevenbergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoffman-John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Aroyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butryna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kuzmina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fenton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aguera-Arcas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Lamda</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.08239" />
		<imprint>
			<date type="published" when="2022-01">January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Design and implementation of probabilistic programming language anglican</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tolpin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van De Meent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Wood</surname></persName>
		</author>
		<idno>CoRR, abs/1608.05263</idno>
		<ptr target="http://arxiv.org/abs/1608.05263" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">An introduction to probabilistic programming</title>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Van De Meent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-09">September 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Self-Consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-03">March 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-01">January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Foundation posteriors for approximate probabilistic inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-05">May 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Chaining large language model prompts through visual programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Donsbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><surname>Promptchainer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.06566" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><surname>Star</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14465</idno>
		<title level="m">Bootstrapping reasoning with reasoning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Socratic models: Composing Zero-Shot multimodal reasoning with language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-04">April 2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
