<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Image Decomposition Via the Combination of Sparse Representations and a Variational Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-06-24">June 24, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">J.-L</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
							<email>jstarck@cea.fr</email>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Elad</surname></persName>
							<email>elad@cs.technion.ac.il</email>
						</author>
						<author>
							<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
							<email>donoho@stat.stanford.edu</email>
						</author>
						<author>
							<persName><forename type="middle">M</forename><surname>Elad</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">DAPNIA/SEDI-SAP</orgName>
								<orgName type="institution">CEA-Saclay</orgName>
								<address>
									<addrLine>Service d&apos;Astrophysique</addrLine>
									<postCode>F-91191</postCode>
									<settlement>Gif sur Yvette</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">The Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<addrLine>Sequoia Hall</addrLine>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Image Decomposition Via the Combination of Sparse Representations and a Variational Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-06-24">June 24, 2004</date>
						</imprint>
					</monogr>
					<idno type="MD5">90612941485F6FE6608A1468C828FB13</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Basis Pursuit Denoising</term>
					<term>Total Variation</term>
					<term>Sparse Representations</term>
					<term>Piecewise Smooth</term>
					<term>Texture</term>
					<term>Wavelet</term>
					<term>Local DCT</term>
					<term>Ridgelet</term>
					<term>Curvelet</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The separation of image content into semantic parts plays a vital role in applications such as compression, enhancement, restoration, and more. In recent years several pioneering works suggested such a separation based on variational formulation, and others using independent component analysis and sparsity. This paper presents a novel method for separating images into texture and piecewise smooth (cartoon) parts, exploiting both the variational and the sparsity mechanisms. The method combines the Basis Pursuit Denoising (BPDN) algorithm and the Total-Variation (TV) regularization scheme. The basic idea presented in this paper is the use of two appropriate dictionaries, one for the representation of textures, and the other for the natural scene parts, assumed to be piecewise-smooth. Both dictionaries are chosen such that they lead to sparse representations over one type of image-content (either texture or piecewise smooth). The use of the BPDN with the two augmented dictionaries leads to the desired separation, along with noise removal as a by-product. As the need to choose proper dictionaries is generally hard, a TV regularization is employed to better direct the separation process and reduce ringing artifacts.</p><p>We present a highly efficient numerical scheme to solve the combined optimization problem posed in our model, and show several experimental results that validate the algorithm's performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>The task of decomposing signals into their building atoms is of great interest for many applications. The typical assumption made in such problems is that the given signal is a linear mixture of several source signals of a more coherent origin. These kinds of problems have drawn a lot of research attention in last years. Independent Component Analysis (ICA), sparsity methods, and variational calculus, have all been used for the separation of signal mixtures with varying degrees of success (see for example <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>).</p><p>A classic example is the cocktail party problem where a sound signal containing several concurrent speakers is to be decomposed into the separate speakers. In image processing a parallel situation is encountered in cases of photographs containing transparent layers due to reflection.</p><p>An interesting decomposition application -separating texture from non-texture parts in images -has been recently studied by several researchers. The importance of such separation is for applications in image compression, image analysis, synthesis and more (see for example <ref type="bibr" target="#b5">[6]</ref>). A variational-based method was proposed recently by Vese and Osher <ref type="bibr" target="#b2">[3]</ref>, and later followed by others <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b4">[5]</ref>. Their approach uses a recently introduced mathematical model for texture content <ref type="bibr" target="#b8">[9]</ref> that extends the notion of Total-Variation <ref type="bibr" target="#b9">[10]</ref>.</p><p>A different methodology towards the same separation task is proposed in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b3">[4]</ref>. The work in <ref type="bibr" target="#b1">[2]</ref> describes a novel image compression algorithm based on image decomposition to cartoon and texture layers using the wavelet-packet transform. The work presented in <ref type="bibr" target="#b3">[4]</ref> shows a separation based on the matching pursuit algorithm and an MRF modeling.</p><p>We will return to these works and give a more detailed description of their contribution, and their relation to the work presented here.</p><p>In this paper we focus on the same decomposition problem -texture and natural (piecewise smooth) additive ingredients. Figure <ref type="figure" target="#fig_0">1</ref> presents the desired behavior of the separation task at hand for a typical example. In this work we aim at separating these two parts on a pixel-by-pixel basis, such that if the texture appears on parts of the spatial support of the image, the separation should succeed in finding a masking map as a by-product of the separation. The approach we take for achieving the separation starts with the Basis-Pursuit denoising (BPDN) algorithm, extending results from previous work <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. The core idea here is to choose two appropriate dictionaries, one for the representation of texture, and the other for the natural scene parts. Both dictionaries are to be chosen such that each leads to sparse representations over the images it is serving, while yielding non-sparse representations on the other content type. Thus, when amalgamated to one dictionary, the BPDN is expected to lead to the proper separation, as it seeks for the overall sparsest solution, and this should align with the sparse representation for each part. We show experimentally how indeed the BPDN framework leads to a successful separation. Further more, we show how to strengthen the BPDN paradigm, overcoming ringing artifacts by leaning on the Total-Variation (TV) regularization scheme.</p><p>The rest of the paper is organized as follows: Section 2 presents the separation method, how the BPDN is used, and how TV is added to obtain a further improvement. In Section 3 we discuss the choice of the dictionaries for the texture and the natural scene parts. Section 4 addresses the numerical scheme for solving the separation problem efficiently.</p><p>We present several experimental results in Section 5. Relation to prior art relevant to this work is presented in Section 6, and conclusion is given in Section 7. Two appendices in this paper give detailed presentation a numerical algorithm that is found useful here, and an initial theoretical study of the separation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Separation of Images -Basics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model Assumption</head><p>Assume that the input image to be processed is of size N × N. We represent this image as a 1D vector of length N 2 by simple reordering. For such images X t that contain only pure texture content we propose an over-complete representation matrix T t ∈ M N 2 ×L (where typically L N 2 ) such that solving</p><formula xml:id="formula_0">α opt t = Arg min α t α t 0 subject to: X t = T t α t<label>(1)</label></formula><p>for any texture image X leads to a very sparse solution. The notation u 0 is the 0 -norm of the vector u, effectively counting the number of non-zeros in it. We further assume that T t is such that if the texture appears in parts of the image and otherwise zero, the representation is still sparse, implying that the dictionary employs a multi-scale and local analysis of the image content. The definition in (1) is essentially an overcomplete transform of X t , yielding a representation α t , such that sparsity is maximized.</p><p>We further require that when this forward transform with T t is applied to images containing no texture and pure piecewise-smooth content, the resulting representations are non-sparse. Thus, the dictionary T t plays a role of a discriminant between content types, preferring the texture over the natural part. A possible measure of fidelity of the chosen dictionary is the functional</p><formula xml:id="formula_1">T opt t = Arg min Tt k α opt t (k) 0 j α opt n (j) 0<label>(2)</label></formula><p>where:</p><formula xml:id="formula_2">α opt t (k) = Arg min α t α t 0 subject to: X t (k) = T t α t , k = 1, 2, . . . α opt n (j) = Arg min α n α n 0 subject to: X n (j) = T t α n , j = 1, 2, . . .</formula><p>This functional of the dictionary is measuring the relative sparsity between a family of textured images {X t (k)} k and a family of natural content images {X n (j)} j . This, or a similar measure, could be used for the design of the proper choice of T t , but in this paper we take a different approach, as will be discussed shortly.</p><p>Similar to the above, assume that for images containing piecewise smooth content, X n , we have a different dictionary T n , such that their content is sparsely represented by the above definition. Again, we assume that beyond the sparsity obtained by T n for natural images, we can further assume that texture images are represented very inefficiently (i.e. non-sparsely), and also assume that the analysis applied by this dictionary is of multi-scale and local nature, enabling it to detect pieces of the desired content.</p><p>For an arbitrary image X containing both texture and piecewise smooth content (overlayed, side-by-side, or both), we propose to seek the sparsest of all representations over the augmented dictionary containing both T t and T n . Thus we need to solve</p><formula xml:id="formula_3">{α opt t , α opt n } = Arg min {α t , α n } α t 0 + α n 0 subject to: X = T t α t + T n α n .<label>(3)</label></formula><p>This optimization task is likely to lead to a successful separation of the image content, such that T t α t is mostly texture and T n α n is mostly piecewise smooth. The reason for this expectation relies on the assumptions made earlier about T t and T n being very efficient in representing one content type and being highly non-effective in representing the other.</p><p>While sensible from the point of view of the desired solution, the problem formulated in Equation ( <ref type="formula" target="#formula_3">3</ref>) is non-convex and hard to solve. Its complexity grows exponentially with the number of columns in the overall dictionary. The Basis Pursuit (BP) method <ref type="bibr" target="#b10">[11]</ref> suggests the replacement of the 0 -norm with an 1 -norm, thus leading to a solvable optimization problem (Linear Programming) of the form</p><formula xml:id="formula_4">{α opt t , α opt n } = Arg min {α t , α n } α t 1 + α n 1 subject to: X = T t α t + T n α n .<label>(4)</label></formula><p>Interestingly, recent work have shown that for sparse enough solutions, the BP simpler form is accurate, also leading to the sparsest of all representations <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. More about this relationship is given in Appendix II, where we analyze theoretically bounds on the success of such separation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Complicating Factors</head><p>The above description is sensitive, and this sensitivity may hinders the success of the overall separation process. There are two complicating factors, both has to do with the assumptions made above:</p><p>• Assumption: The image is decomposed cleanly into texture and natural (piecewise smooth) parts. For an arbitrary image this assumption is not true as it may also contain additive noise that is not represented well both by T t and T n . Generally speaking, any deviation from this assumption may lead to a non-sparse pair of vectors {α opt t , α opt n }, and with that, due to the change from 0 to 1 , to a complete failure of the separation process.</p><p>• Assumption: The chosen dictionaries are appropriate. It is very hard to propose a dictionary that leads to sparse representations for a wide family of signals. A chosen dictionary may be inappropriate either because it does not lead to a sparse representation for the proper signals, and if this is the case, then for such images the separation will fail. More complicating scenario is obtained for dictionaries that does not discriminate well between the two phenomena we desire to separate. Thus, if for example, we have a dictionary T n that indeed leads to sparse representations for natural scenes, but also known to lead to sparse representations for some texture content, clearly, such a dictionary could not be used for a successful separation. Put more generally we may ask whether such dictionaries exist.</p><p>A solution for the first problem could be obtained by relaxing the constraint in Equation (4) to become an approximate one. Thus, in the new form we propose solution of</p><formula xml:id="formula_5">{α opt t , α opt n } = Arg min {α t , α n } α t 1 + α n 1 + λ X -T t α t -T n α n 2 2 .<label>(5)</label></formula><p>Thus, if an additional content exist in the image so that it is not represented sparsely by both dictionaries, the above formulation will tend to allocate this content to be the residual X -T t α t -T n α n . This way, not only we manage to separate texture from natural scene parts, but also succeed in removing an additive noise as a by-product. This new formulation is familiar by the name Basis Pursuit Denoising, shown in <ref type="bibr" target="#b10">[11]</ref> to perform well for denoising tasks. We should note here that the choice of 2 as the error norm is intimately related to the assumption that the residual behaves like a white zero-mean Gaussian noise. Other norms can be similarly introduced to account for different noise models, such as Laplacian ( <ref type="formula" target="#formula_0">1</ref>), uniformly distributed noise ( ∞ ), and others.</p><p>As for the second problem mentioned above, we propose here an underlying model to describe image content, but we do not and cannot claim that this model is universal and will apply to all images. There are certainly some images for which our model would not work well. We do believe that the proposed model holds true for a relatively large class of images, and the experimental results to follow indeed support this belief.</p><p>Still, even if the above-described model is feasible, the problem of choosing the proper dictionaries remains open and difficult. This matter will be discussed in the next section.</p><p>Suppose we have chosen T n and T t , both generally well suited for the separation task.</p><p>By adding external forces that direct the images T n α n and T t α t to better suite their expected content, these forces will fine-tune the dictionaries to achieve their task. As an example for such successful external force, adding a TV penalty <ref type="bibr" target="#b9">[10]</ref> to Equation (5) can direct the image T n α n to fit the piecewise smooth model. This leads to</p><formula xml:id="formula_6">{α opt t , α opt n } = Arg min {α t , α n } α t 1 + α n 1 (6) +λ X -T t α t -T n α n 2 2 + γT V {T n α n }.</formula><p>The expression T V {T n α n } is essentially computing the image X n = T n α n (supposed to be piecewise smooth), and applying the TV-norm on it (computing its absolute gradient field and summing it with an 1 -norm). Penalizing with TV, we force the image T n α n to be closer to a piecewise smooth image, and thus support the separation process. This idea already appeared in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, where TV was used to damp ringing artifacts near edges, caused by the oscillations of the curvelet atoms. We note that combining TV with wavelet has also been done for similar reasons in <ref type="bibr" target="#b19">[20]</ref>, although in a different fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Different Problem Formulation</head><p>Assume that each of the chosen dictionaries can be composed into a set of unitary matrices such that</p><formula xml:id="formula_7">T t = [T(1) t , T(2) t , . . . , T(L t ) t ] T n = [T(1) n , T(2) n , . . . , T(L n ) n ]</formula><p>and</p><formula xml:id="formula_8">T(1) H t T(1) t = T(2) H t T(2) t = • • • = T(L t ) H t T(L t ) t = T(1) H n T(1) n = T(2) H n T(2) n = • • • = T(L n ) H n T(L n ) n = I,</formula><p>where T H is the Hermite adjoint (conjugate and transpose) of T. In such a case we could slice α t and α n into L t and L n parts correspondingly, and obtain a new formulation of the problem min</p><formula xml:id="formula_9">{α(k)t} L t k=1 , {α(j)n} Ln j=1 Lt k=1 α(k) t 1 + Ln j=1 α(j) n 1 (7) +λ X - Lt k=1 T(k) t α(k) t - Ln j=1 T(j) n α(j) n 2 2 +γT V    Ln j=1 T(j) n α(j) n    .</formula><p>In the above formulation the representation vector pieces α(j) n and α(k) t are supposed to be sparse. Defining X(k) t = T(k) t α(k) t and similarly X(j) n = T(j) n α(j) n , we can reformulate the problem as min</p><formula xml:id="formula_10">{X(k)t} L t k=1 , {X(j)n} Ln j=1 Lt k=1 T(k) H t X(k) t 1 + Ln j=1 T(j) H n X(j) n 1 (8) +λ X - Lt k=1 X(k) t - Ln j=1 X(j) n 2 2 + γT V    Ln j=1 X(j) n   </formula><p>and the unknowns become images, rather then representation coefficients. For this problem structure there exist a fast numerical solver called Block-Coordinate Relaxation Method, based on the shrinkage method <ref type="bibr" target="#b20">[21]</ref>. This solver (see Appendix I for details) requires only the use of matrix-vector multiplications with the unitary transforms and their adjoints.</p><p>See <ref type="bibr" target="#b21">[22]</ref> for more details. We will return to this form of solution when we discuss numerical algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Summary of Method</head><p>In order to translate the above idea into a practical algorithm we should answer three major questions: (i) Is there a theoretical backup to the heuristic claims made here? (ii)</p><p>How should we choose the dictionaries T t and T n ? and (iii) How should we numerically solve the obtained optimization problem in a traceable way? These three questions are addressed in the coming sections. The theoretical grounds for the separation is briefly discussed in Appendix II. The choice of dictionaries in the topic of the next section, and the numerical considerations follow that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Candidate Dictionaries</head><p>Our approach towards the choice of T t and T n is to pick known transforms, and not design those optimally as we hinted earlier as a possible method. We choose transforms known for representing well either texture or piecewise smooth behaviors. For numerical reasons, we restrict our choices to the dictionaries T t and T n that have a fast forward and inverse implementation. In making a choice for a transform, we use experience of the user applying the separation algorithm, and the choices made may vary from one image to another. We shall start with a brief description of our candidate dictionaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dictionaries for Piecewise Smooth Content</head><p>A.1 Bi-Orthogonal Wavelet Transforms (OWT)</p><p>Previous work has established that the wavelet transform is well suited for the effective (sparse) representation of natural scene <ref type="bibr" target="#b20">[21]</ref>. The application of the OWT to image compression using the 7-9 filters and the zero-tree coding leads to impressive results over the JPEG <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>.</p><p>The OWT implementation requires O(n 2 ) operations for an image with n×n pixels, both for the forward and the inverse transforms. Represented as a matrix-vector multiplication, this transform is a square matrix, either unitary, or non-unitary with accompanying inverse matrix of a similar simple form. The OWT presents only a fixed number of directional elements independent of scales, and there is no highly anisotropic elements <ref type="bibr" target="#b25">[26]</ref>. Therefore, we naively expect the OWT to be non-optimal for detection of highly anisotropic features.</p><p>Moreover, the OWT is non-shift invariance -a property that may cause difficulties in our analysis.</p><p>The undecimated version (UWT) of the OWT is certainly the most popular transform for data filtering. It is obtained by skipping the decimation, implying that this is an overcomplete transform represented as a matrix with more columns than rows. The redundancy factor (ratio between number of columns to number of rows) is 3J + 1 -where J is the number of resolution layers. With the over-completeness comes the desired shift invariance property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 The isotropic à trous algorithm</head><p>This transform decomposes an n × n image I as a superposition of the form I(x, y) = c J (x, y) + J j=1 w j (x, y), where c J is a coarse or smooth version of the original image I and w j represents 'the details of I' at scale 2 -j (see <ref type="bibr" target="#b26">[27]</ref>). Thus, the algorithm outputs J + 1 sub-band arrays of size n × n. This wavelet transform is very well adapted to the detection of isotropic features, and this explains the reason of its success for astronomical image processing, where the data contain mostly (quasi-)isotropic objects, such stars or galaxies <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 The Local Ridgelet Transform</head><p>The ridgelet transform is the application of a 1D-wavelet to the angular slices of the Radon transform <ref type="bibr" target="#b25">[26]</ref>. Such transform has been shown to be optimal for representing global lines in an image. To detect line segments, a partitioning must be introduced <ref type="bibr" target="#b28">[29]</ref>, and a ridgelet transform is to be applied per each block. In such a case, the image is decomposed into 50%-overlapping blocks of side-length b pixels. The overlap is introduced in order to avoid blocking artifacts. For a n × n image, we count 2n/b such blocks in each direction. The partitioning introduces redundancy (over-completeness), as each pixel belongs to 4 neighboring blocks. The ridgelet transform requires O(n 2 log 2 n) operations.</p><p>More details on the implementation of the digital ridgelet transform can be found in <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 The Curvelet Transform</head><p>The curvelet transform, proposed in <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b29">[30]</ref>, enables the directional analysis of an image in different scales. The idea is to first decompose the image into a set of wavelet bands, and to analyze each band with a local ridgelet transform. The block size is changed at each scale level, such that different levels of the multi-scale ridgelet pyramid are used to represent different sub-bands of a filter bank output. The side-length of the localizing windows is doubled at every other dyadic sub-band, hence maintaining the fundamental property of the curvelet transform, which says that elements of length about 2 -j/2 serve for the analysis and synthesis of the j-th sub-band [2 j , 2 j+1 ]. The curvelet transform is also redundant, with a redundancy factor of 16J + 1 whenever J scales are employed. Its complexity is of the O(n 2 log 2 n), as in ridgelet. This method is best for the detection of anisotropic structures of different lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dictionaries for texture Content</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 The (Local) Discrete Cosine Transform (DCT)</head><p>The DCT is a variant of the Discrete Fourier Transform, replacing the complex analysis with real numbers by a symmetric signal extension. The DCT is an orthonormal transform, known to be well suited for first order Markov stationary signals. Its coefficients essentially represents frequency content, similar to the ones obtained by Fourier analysis. When dealing with non-stationary sources, DCT is typically applied in blocks. Such is indeed the case in the JPEG image compression algorithm. Choice of overlapping blocks is preferred for analyzing signals while preventing artefact. In such a case we get again an overcomplete transform with redundancy factor of 4 for an overlap of 50%. A fast algorithm with complexity of n 2 log 2 n exists for its computation. The DCT is appropriate for a sparse representation of either smooth or periodic behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 The Gabor Transform</head><p>The Gabor transform is quite popular among researchers working on texture content. This transform is essentially a localized DFT, where the localization is obtained by windowing portions of the signal in an overlapping fashion. The amount of redundancy is controllable. For a proper choice of the overlap and the window, both the forward and the inverse transforms can be applied with complexity of n 2 log 2 n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Numerical Considerations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Numerical Scheme</head><p>Returning to the separation process as posed in Equation ( <ref type="formula">6</ref>), we need to solve an optimization problem of the form</p><formula xml:id="formula_11">{α opt t , α opt n } = Arg min {α t , α n } α t 1 + α n 1 (9) +λ X -T t α t -T n α n 2 2 + γT V {T n α n }.</formula><p>Instead of solving this optimization problem, finding two representation vectors {α opt t , α opt n }, let us reformulate the problem so as to get the texture and the natural part images, X t and X n , as our unknowns. The reason behind this change is the obvious simplicity gained by searching shorter vectors -representation vectors are far longer than the image they represent for overcomplete dictionaries as the ones we use here.</p><p>Define X t = T t α t and X n = T n α n . Given X t , we can recover α t as α t = T + t X t + r t where r t is an arbitrary vector in the null-space of T t , and T + t is the Moore-Penrose pseudoinverse of T t . Note that for tight frames, this matrix is the same (up to a constant) as the Hermite adjoint one, and thus its computation is relatively easy. Put these back into <ref type="bibr" target="#b5">(6)</ref> we obtain</p><formula xml:id="formula_12">{X opt t , X opt n } = Arg min {X t , X n , r t , r n } T + t X t + r t 1 + T + n X n + r n 1 (10) + λ X -X t -X n 2 2 + γT V {X n } Subject to: T t r t = 0 , T n r n = 0.</formula><p>The term T + t X t is an overcomplete linear transform of the image X t . for this texture part. Similarly, T + n X n is an overcomplete linear transform of the natural part. In our attempt to replace the representation vectors as unknowns, we see that we have a pair of residual vectors to be found as well. If we choose (rather arbitrarily at this stage) to assign those vectors as zeros we obtain the problem</p><formula xml:id="formula_13">{X opt t , X opt n } = Arg min {X t , X n } T + t X t 1 + T + n X n 1 (11) + λ X -X t -X n 2 2 + γT V {X n }.</formula><p>We can justify the choice r t = 0, r n = 0 in several ways:</p><p>Bounding function: Since ( <ref type="formula">11</ref>) is obtained from (10) by choosing r t = 0, r n = 0, we necessarily get that the value of (10) (after optimization) is upper bounded by the value of <ref type="bibr" target="#b10">(11)</ref>. Thus, in minimizing ( <ref type="formula">11</ref>) instead, we guarantee that the true function to be minimized is of even lower value.</p><p>Relation to the Block-Coordinate-Relaxation algorithm: Comparing (11) to the case discussed in Equation ( <ref type="formula">8</ref>), we see a close resemblance. If we assume that the dictionaries involved contain just one unitary, we get a complete equivalence between solving <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref>. In a way we may refer to the approximation we have made here as a method to generalize the block-coordinate-relaxation method for the non-unitary case.</p><p>Relation to MAP: The expression written as penalty function in <ref type="bibr" target="#b10">(11)</ref> has a Maximal-A-Posteriori estimation flavor to it. It suggests that the given image X is known to originate from a linear combination of the form X t + X n , contaminated by Gaussian noise -this part comes from the likelihood function X -X t -X n 2 2 . For the texture image part there is the assumption that it comes from a Gibbs distribution of the form Const•exp (-β t T + t X t 1 ). As for the natural part, there is a similar assumption about the existence of a prior of the form Const • exp (-β n T + n X n 1 -γ n T V {X n }). While different from our original point of view, these assumptions are reasonable and not far from the Basis Pursuit approach.</p><p>The bottom line to all this discussion is that we have chosen an approximation to our true minimization task, and with it managed to get a simplified optimization problem, for which an effective algorithm can be proposed. Our minimization task is thus given by min</p><formula xml:id="formula_14">{X t , X n } T + t X t 1 + T + n X n 1 + λ X -X t -X n 2 2 + γT V {X n } . (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>The algorithm we use is based on the Block-Coordinate-Relaxation method <ref type="bibr" target="#b21">[22]</ref> (see Appendix I), with some required changes due to the non-unitary transforms involved, and the additional TV term. The algorithm is given below:</p><p>1. Initialize L max , number of iterations per layer N , and threshold δ = λ • L max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Perform N times:</head><p>Part A -Update of X n assuming X t is fixed:</p><p>-Calculate the residual R = X -X t -X n .</p><p>-Calculate the curvelet transform of X n + R and obtain α n = T + n (X n + R). -Soft threshold the coefficient α n with the δ threshold and obtain αn .</p><p>-Reconstruct X n by X n = T n αn .</p><p>Part B -Update of X t assuming X n is fixed:</p><formula xml:id="formula_16">-Calculate the residual R = X -X t -X n .</formula><p>-Calculate the local DCT transform of X t + R and obtain α t = T + t (X t + R). -Soft threshold the coefficient α t with the δ threshold and obtain αt .</p><p>-Reconstruct X t by X t = T t αt .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part C -TV Consideration:</head><p>-Apply the TV correction by</p><formula xml:id="formula_17">X n = X n -µγ ∂T V {X n } ∂X n .</formula><p>-The parameter µ is chosen either by a line-search minimizing the overall penalty function, or as a fixed step-size of moderate value that guarantees convergence.</p><p>3. Update the threshold by δ = δλ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">If δ &gt; λ, return to</head><p>Step 2. Else, finish.</p><p>The algorithm for minimizing <ref type="bibr" target="#b11">(12)</ref>. Here T n is the curvelet transform, and T t is the local DCT<ref type="foot" target="#foot_1">1</ref> .</p><p>In the above algorithm, soft threshold is used due to our formulation of the 1 sparsity penalty term. However, as we have explained earlier, the 1 expression is merely a good approximation for the desired 0 one, and thus, replacing the soft by a hard threshold towards the end of the iterative process may lead to better results.</p><p>We chose this numerical scheme over the Basis Pursuit interior-point approach in <ref type="bibr" target="#b10">[11]</ref>,</p><p>because it presents two major advantages: (i) We do not need to keep all the transformations in memory. This is particularly important when we use redundant transformations such the un-decimated wavelet transform or the curvelet one. Also, (ii) We can add different constraints on the components. Here we applied only the T V constraint on one of the components, but other constraints, such as positivity, can easily be added as well.</p><p>Our method allows us to build easily a dedicated algorithm which takes into account the a priori knowledge we have on the solution for a specific problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. TV and Undecimated Haar Transform</head><p>A link between the TV and the undecimated Haar wavelet soft thresholding has been studied in <ref type="bibr" target="#b32">[33]</ref>, arguing that in the 1D case the TV and the undecimated single resolution Haar are equivalent. When going to 2D, this relation does not hold anymore, but the two approaches share some similarities. Whereas the TV introduces translation-and rotationinvariance, the undecimated 2D Haar presents translation-and scale-invariance (being multi-scale). In light of this interpretation, we can change the part C in the algorithm as described below. This method is expected to lead to similar results to the ones obtained with the regular TV. -The parameter µ is chosen as before.</p><p>Alternative Stage C -Replacement of the TV by undecimated Haar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Noise Consideration</head><p>The case of noisy data can be easily considered in our framework, and merged into the algorithm such that we get a three-way separation to texture, natural part, and additive noise -X = X t + X n + N . We can normalize both transforms T + t and T + n such that for a given noise realization N with zero-mean and a unit standard deviation, α n = T + n N and α t = T + t N have also a standard deviation equals to 1. Then, only the last step of the algorithm changes. By replacing the stopping criterion δ &gt; λ by δ &gt; kσ, where σ is the noise standard deviation and k ≈ 3, 4. This ensures that coefficients with an absolute value lower than kσ will never be taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Image Decomposition</head><p>We start the description of our experiments with a synthetically generated image composed of a natural scene and a texture, where we have the ground truth parts to compare with. We implement the proposed algorithm with the curvelet transform (five resolution levels) for the natural scene part, and a global DCT transform for the texture. We have used the soft thresholding Haar as a replacement to the TV, as described in previous section. The parameter γ has been fixed to 2. The overall algorithm converges in a matter of 10 -20 iterations. Due to the inefficient implementation of the curvelet transform, the overall run-time of this algorithm is 30 minutes. Recent progress made in the implementation of the curvelet is expected to reduce this run-time by more than one order of magnitude.</p><p>In this example, we got better results if the very low frequency components of the image are first subtracted from it, and then added to X n after the separation. The reason for this is the evident overlap that exists between the two dictionaries -both considers the low-frequency content to belong to them as both can represent it efficiently. Thus, by removing this content prior to the separation we avoid separation ambiguity. Also, by returning this content later to the curvelet part, we use our expectation to see the low frequencies as belonging to the piecewise smooth image.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> shows the original image (co-addition of the texture part and the natural part), the low frequency component, the texture reconstructed component X t and the natural scene part X n . As we can see, the separation is reproduced rather well. Figure <ref type="figure" target="#fig_3">3</ref> shows the results of the second experiment where the separation is applied on the above combined image after being contaminated by additive noise (σ = 10). As we can, the presence of noise does not deteriorate the separation algorithm's performance, and the noise is separated as well.</p><p>We have also applied our method to the Barbara (512x512) image. We have used the curvelet transform with the five resolution levels, and overlapping DCT transform with a block size 32×32. The parameter γ has been fixed to 0.5. Here, we have used the standard TV regularization implementation. Figure <ref type="figure" target="#fig_5">4</ref> shows the Barbara image, the reconstructed cosine component X t and the reconstructed curvelet component X n . Figure <ref type="figure" target="#fig_6">5</ref> shows a magnified part of the face. For comparison, the separated components reconstructed by</p><p>Vese-Osher approach <ref type="bibr" target="#b2">[3]</ref> are also shown.</p><p>We note here that in general the comparison between different image separation methods should be done with respect to the application in mind. Here we consider the separation itself as the application and thus the results are compared by visually inspecting the outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Non Linear Approximation</head><p>The efficiency of a given decomposition can be estimated by a non-linear approximation (NLA) scheme, where sparsity is a measure of success. An NLA-curve is obtained by reconstructing the image from the m-first best terms of the decomposition. For example, using the wavelet expansion of a function f (smooth away from a discontinuity across a  m -1 2 , m → ∞ <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. Using the algorithm described in the previous section, we decompose the image X into two components X t and X n using the overcomplete transforms T t and T n . While the decomposition is (very) redundant, the exact overall representation X may require a relatively small number of coefficients due to the promoted sparsity, and this essentially yield a better NLA-curve.</p><p>Figure <ref type="figure" target="#fig_7">6</ref> presents the NLA-curves for the image Barbara using (i) the wavelet transform (OWT), (ii) the DCT, and (iii) the results of the algorithm discussed here, based on the OWT-DCT combination. Denoting the wavelet transform as T + n and the DCT one as T + t , the representation we use includes the m largest coefficients from {α t , α n } = {T + t X t , T + n X n }. Using these m values we reconstruct the image by Xm = T t αt + T t αn . The curves in Figure <ref type="figure" target="#fig_7">6</ref> show the representation error standard deviation as a function of m (i.e. E(m) = σ(X -Xm )). We see that for m &lt; 15 %, the combined representation leads to a better non linear approximation curve than both the DCT and the OWT alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Applications</head><p>The ability to separate the image as we show has many applications. We sketch here two such simple experiments to illustrate the importance of a successful separation.</p><p>Edge detection is a crucial processing step in many computer-vision applications. When the texture is highly contrasted, most of the detected edges are due the texture rather than the natural part. By separating first the two components we can detect the true object's edges. Figure <ref type="figure" target="#fig_8">7</ref> shows the edges detected by the Canny algorithm on both the original image and the curvelet reconstructed component (see Figure <ref type="figure" target="#fig_2">2</ref>). Figure <ref type="figure" target="#fig_9">8</ref> shows a galaxy imaged with the GEMINI-OSCIR instrument at 10 µ. The data is contaminated by a noise and a stripping artifact (assumed to be the texture in the image) due to the instrument electronics. As the galaxy is isotropic, we have preferred to use the isotropic wavelet transform instead of the curvelet transform. Figure <ref type="figure" target="#fig_9">8</ref> summarizes the results of the separation where we see a successful isolation of the galaxy, the textured disturbance, and the additive noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Prior Art</head><p>This work was primarily inspired by the image separation work by Vese and Osher <ref type="bibr" target="#b2">[3]</ref>.</p><p>However, there have been several other attempts to achieve such separation for various needs. We list here some of those works, present briefly their contributions, and relate them to our algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Variational Separation Paradigm</head><p>Whereas piecewise smooth images u are assumed to belong to the Bounded-Variation (BV ) family of functions u ∈ BV (R 2 ), texture is known to behave differently. A different approach has recently been proposed for separating the texture v from the signal f (= u+v) <ref type="bibr" target="#b2">[3]</ref>, based on a model proposed by Meyer <ref type="bibr" target="#b8">[9]</ref>. Similar attempts and additional contributions in this line are reported in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b35">[36]</ref>. This model suggests that a texture image v is to belong to a different family of functions denoted as v ∈ BV * (R 2 ). This notation implies the</p><formula xml:id="formula_18">of two functions g 1 , g 2 ∈ L ∞ (R 2 ) such that v(x, y) = ∂ x g 1 (x, y) + ∂ y g 2 (x, y). The BV * norm is defined using the two functions g 1 , g 2 as v BV * = (|g 1 (x)| 2 + |g 2 (x)| 2 ) 1 2</formula><p>∞ . Based on this model, a variational minimization problem was set by Vese and Osher to recover u, g 1 , g 2 from a given mixture f . This approach essentially searches for the solution of inf</p><formula xml:id="formula_19">(u, g 1 , g 2 ) u BV + λ v BV * + λ f -u -v 2 2<label>(13)</label></formula><p>A numerical algorithm to solve this problem is described in <ref type="bibr" target="#b2">[3]</ref>, with encouraging simulation results.</p><p>Although the approach we take is totally different, it bares some similarities in spirit to the above described method. Referring to our formulation in <ref type="bibr" target="#b11">(12)</ref> with the choice γ = 0, min</p><formula xml:id="formula_20">{X t , X n } T + n X n 1 + T + t X t 1 + λ X -X t -X n 2 2 . (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>we see the following connections (note that equivalence is not claimed here):</p><p>• Based on our previous discussion on the relation between the TV and the undecimated Haar, we can propose Hu 1 as a replacement to u BV . Here, H is the undecimated Haar transform (i.e. = T + n in our original notations). Thus there is a similarity between the effects of the first terms in both <ref type="bibr" target="#b12">(13)</ref> and <ref type="bibr" target="#b13">(14)</ref>.</p><p>• We may argue that images with sparse representations in the DCT domain (local with varying block sizes and block overlap) present strong oscillations and therefore could be considered as textures, belonging to the Banach space BV * (R 2 ). This suggests that v BV * could also be approximated by an 1 norm term Dv 1 where D is the DCT transform (i.e. D = T + t in our notations). This leads to a similarity between the second terms in the two optimization problems ( <ref type="formula" target="#formula_19">13</ref>) and ( <ref type="formula" target="#formula_20">14</ref>).</p><p>• The third expression is exactly the same in ( <ref type="formula" target="#formula_19">13</ref>) and ( <ref type="formula" target="#formula_20">14</ref>). Thus, we see a close relation between our model and the one proposed by Meyer as adopted and used by Vese and Osher. However, there are also major differences that should be • In our implementation we do not use the undecimated Haar with just one resolution, but rather use the complete pyramid. The variational approach can also have a multi-scale treatment by adopting spatially adaptive and resolution adaptive coefficient λ in <ref type="bibr" target="#b12">(13)</ref>, although this change is far from trivial.</p><p>• We have replaced the Haar with more effective transforms such as the curvelet. Several reasons justify such a change. Among them is the fact that curvelet better succeeds in detecting noisy edges.</p><p>• method does not search for the implicit g 1 , g 2 supposed to be the origin of the texture, but rather searches directly the texture part by an alternative and simpler model based on the local DCT.</p><p>• We should note that the methodology presented in the paper is not limited to the separation of texture and piecewise-smooth parts of an image. The basic idea of separation of signals to different content types, leaning on the idea that each of the ingredients have a sparse representation with a proper choice of a dictionary. This may lead to other applications, and different implementations. We leave this for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Compression via Separation</head><p>A pioneering work described in <ref type="bibr" target="#b1">[2]</ref> proposes a separation of cartoon from texture for efficient image compression. This algorithm relies on vast experience gathered on similar decompositions applied to audio signals <ref type="bibr" target="#b36">[37]</ref>. Our algorithm is very similar in spirit to the approach taken in <ref type="bibr" target="#b1">[2]</ref>, namely, use of different dictionaries for effective (sparse) representation of each content type, and pursuit that seeks the sparsest of all representations. Still there are several major differences worth mentioning:</p><p>• While our algorithm uses curvelet, ridgelet, and several other types of over-complete transforms, the chosen dictionaries in <ref type="bibr" target="#b1">[2]</ref> are confined to be orthonormal wavelet packets (optimized per the task). This choice is crucial for the compression to follow, but cause loss of sparsity in the representations.</p><p>• Our separation approach is parallel, seeking jointly a decomposition of the image into the two ingredients. The numerical implementation uses "Sardy-Like" sequential transforms followed by soft thresholding, but applied iteratively, the algorithm gets closer to the basis pursuit result, which is essentially a parallel decomposition technique. The algorithm in <ref type="bibr" target="#b1">[2]</ref> is sequential, pealing the cartoon content and then treating the reminder as texture.</p><p>• The proposed method in <ref type="bibr" target="#b1">[2]</ref> does not care about the visual quality of the separation.</p><p>The main issue is final compression performance, and not getting two semantically pleasing images of texture and cartoon. The algorithm presented here, on the other hand, is all about getting pleasing images to a human viewer. This is why we add TV penalty treating ringing artifacts.</p><p>• A large portion of our work came as a direct consequence to the theoretical study we have done on the basis pursuit performance limits (see Appendix II). When we assume sparsity under the chosen dictionaries, we can immediately invoke the uniqueness result, that says that the original sparsity pattern is indeed the sparsest one possible. When we employ the basis pursuit for numerically getting the result, we lean on the equivalence result promising that if indeed the combination is sparse enough, BP will find it well. The work in <ref type="bibr" target="#b1">[2]</ref> claims of success are leaning on the actual obtained compression results.</p><p>Very recent similar attempt to exploit separation for image compression is reported in <ref type="bibr" target="#b4">[5]</ref>. The authors use the variational paradigm for achieving the separation, and then consider compression of each content type separately, as in <ref type="bibr" target="#b1">[2]</ref>.</p><p>The separation algorithm presented in <ref type="bibr" target="#b3">[4]</ref> is proposed for a general analysis of image content and not compression. However, it bares some similarities to both the algorithm in <ref type="bibr" target="#b1">[2]</ref> and the one presented in this paper. As in <ref type="bibr" target="#b1">[2]</ref>, the decomposition of the image content is sequential: The first stage extracts the sketchable content (similar to the piecewise smooth content, but different) , and this is achieved by the matching pursuit algorithm, applied with a trained dictionary of local primitives. The second stage represents the nonsketchable (texture) content and is based on Markov Random Field (MRF) representation.</p><p>The goal of the proposed separation in <ref type="bibr" target="#b3">[4]</ref> is somewhat different than the one discussed here, as it focuses on a sparse description of the sketched image. This is in contrast to the method proposed here where sparsity is desired and found across all content types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. Discussion</head><p>In this paper we have presented a novel method for separating an image into its texture and piecewise smooth ingredients. Our method is based on the ability to represent these content types as sparse combinations of atoms of predetermined dictionaries. The proposed approach is a fusion of the Basis Pursuit algorithm and the Total-Variation regularization scheme, both merged in order to direct the solution towards a successful separation.</p><p>This paper offers a theoretical analysis of the separation idea with the Basis Pursuit algorithm, and shows that a perfect decomposition of image content could be found in principle. While the theoretical bounds obtained for a perfect decomposition are rather weak, they serve both as a starting point for future research, and as a motivating results</p><p>for the practical sides of the work.</p><p>In going from the pure theoretic view to the implementation, we manage to extend the model to treat additive noise -essentially any content in the image that does not fit well with either texture or piecewise-smooth contents. We also changed the problem formulation, departing from the Basis Pursuit, and getting closer to a Maximum A-Posteriori estimation method. The new formulation leads to smaller memory requirements, and additive constraints can be easily added. This gives more flexibility for specific applications.</p><p>Simulation results show consistent promising results.</p><p>which in turn, can be written as min α(1),α(2),...,α(N )</p><formula xml:id="formula_22">N n=1 |α(n)| + λ[α(n) -z t (n)] 2 . (I-5)</formula><p>This function is a sum of N (the dimension of α(k 0 )) scalar and independent convex optimization problems. The term z t (n) represents the n th entry of the inverse transform (T(k 0 )) of the vector Z. The solution for this problem is given by the shrinkage operator mentioned above <ref type="bibr" target="#b20">[21]</ref>.</p><p>This property is the source of the simple numerical scheme of the Block-Coordinate-Relaxation Method. The idea is to sweep through the vectors α(k) one at a time repeatedly, fixing all others, and solving for each.</p><p>Property 2: Sweeping sequentially through k and updating α(k) as in Property 1, the Block-Coordinate-Relaxation Method is guaranteed to converge to the optimal solution of (I-1).</p><p>Proof: The proof is given in <ref type="bibr" target="#b21">[22]</ref>, along with practical implementation ideas. 2</p><p>Appendix II -Theoretic Analysis of the Separation Task</p><p>In this Appendix we aim to show that the separation as described in this paper has strong theoretical justification roots. Those lean on some very recent results in the study of the Basis Pursuit performance. The presented material in this appendix is deliberately brief, with the intention to present a more extensive theoretical study in a separate paper.</p><p>We start with Equation (3) that stands as the basis for the separation process. This equation could also be written differently as ¿From <ref type="bibr" target="#b13">[14]</ref> we recall the definition of the Spark:</p><p>Definition 1: Given a matrix A, its Spark (σ A = Spark{A}) is defined as the minimal number of columns from the matrix that form a linearly dependent set.</p><p>Based on this we have the following result in <ref type="bibr" target="#b13">[14]</ref> that gives a guarantee for global optimum of (II-1) based on a sparsity condition:</p><p>Theorem 1: If a candidate representation α all satisfies α all 0 &lt; Spark{T all }/2, then this solution is necessarily the global minimum of (II-1).</p><p>Based on this result it is clear that the higher the value of the Spark, the stronger this result is. Immediate implication from the above is the following observation, referring to the success of the separation process:</p><p>Corollary 1: If the image X = X t +X n is built such that X t = T t α t and X n = T n α n , and α t 0 + α n 0 &lt; Spark{T all }/2 is true, then the global minimum of (II-1) is necessarily the desired separation.</p><p>Proof: The proof is simple deduction from Theorem 1. 2</p><p>Actually, a stronger claim could be given if we assume a successful choice of dictionaries T t and T n . Let us define a variation of the Spark that refers to the interface between atoms from two dictionaries:</p><p>Definition 2: Given two matrices A and B with the same number of rows, their Inter-Spark (σ A↔B = Spark{A, B}) is defined as the minimal number of columns from the concatenated matrix [A, B] that form a linearly dependent set, and such that columns from both matrices participate in this combination.</p><p>An important feature of our problem is that the goal is the successful separation of content of an incoming image and not finding the true sparse representation per each part. Thus, a stronger claim can be made:</p><p>Corollary 2: Suppose the image X = X t + X n is built such that X t = T t α t and X n =</p><p>T n α n . If α t 0 + α n 0 &lt; σ Tt↔Tn /2 and α t 0 , α n 0 &gt; 0 (i.e., there is a mixture of the two), then if the global minimum of (II-1) satisfies α opt t 0 , α opt n 0 &gt; 0, it is necessarily the successful separation.</p><p>Proof: Given a mixture of columns from the two dictionaries, by the definition of the Inter-Spark it is clear that if there are fewer than σ Tt↔Tn /2 non-zeros in such combination, it must be the unique sparsest solution. The new bound is higher than Spark{T all }/2 and therefore this result is stronger.</p><p>2</p><p>So far we concentrated on Equation (II-1) which stands as the ideal (but impossible)</p><p>for this case in <ref type="bibr" target="#b14">[15]</ref> due to the construction of the overall dictionary as a combination of two unitary matrices. Thus, the better bound is ( √ 2 -0.5))/M = 7.3. Both these bounds are overlayed on the empirical results in the figure, and as can be seen, Basis Pursuit succeeds well beyond the bound. Moreover, this trend is expected to strengthen as the signal size grows, since than the worst-case-scenarios (for which the bounds refer to) become of smaller probability and of less affect on the average result. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example of separations of texture from piecewise smooth contents in images.</figDesc><graphic coords="3,86.23,351.57,142.07,142.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>-</head><label></label><figDesc>Apply the TV correction by using the undecimated Haar wavelet transform H and a soft thresholding: o Calculate the undecimated Haar wavelet transform of X n and obtain αh . o Soft threshold the coefficient α h with the γ threshold o Reconstruct X n by X n = H -1 αh .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The original combined image (top left), its low frequency content (top right), the separated texture part (bottom left), and the separated natural part (bottom right).</figDesc><graphic coords="17,145.91,192.32,154.74,154.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The original noisy image (top left), the separated texture part (top right), the separated natural part (bottom left), and the residual noise component (bottom right).</figDesc><graphic coords="18,145.91,192.32,154.74,154.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>C 2 2 m</head><label>22</label><figDesc>curve), the best m-terms approximation f W m obeys f -f m 2 -1 , m → ∞, while a Fourier expansion it is f -f F m 2 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The original Barbara image (top). the separated texture (bottom left), and the separated natural part (bottom right).</figDesc><graphic coords="19,130.69,205.30,170.52,170.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Top: reconstructed DCT and curvelet components by our method. Bottom: v and u components using Vese's algorithm.</figDesc><graphic coords="20,132.75,204.48,169.17,169.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Standard deviation of the error of reconstructed Barbara image versus the m largest coefficients used in the reconstruction. Full line -DCT transform, dotted line -orthogonal wavelet transform, and dashed line -our signal/texture decomposition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Left: detected edges on the original image. Right: detected edges on the curvelet reconstruct component.</figDesc><graphic coords="22,132.75,33.65,169.84,169.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The original image (top left), the reconstructed wavelet component (top right), the DCT reconstructed component (bottom left), and the residual noise (bottom right).</figDesc><graphic coords="23,132.99,200.95,169.84,169.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>all α all .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Empirical probability of success of the Basis Pursuit algorithm for separation of sources. Per every sparsity combination, 100 experiments are performed and the success rate is computed. Theoretical bounds are also drawn for comparison.</figDesc><graphic coords="30,209.23,165.32,208.79,208.79" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>June 24, 2004   DRAFT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>If the texture is the same on the whole image, then a global DCT should be preferred to a local one.June</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>24, 2004  DRAFT   </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Prof. Stanley Osher and Prof. Luminita Vese for helpful discussions, and for sharing their results to be presented in this paper.</p><p>It is interesting to note that very recent attempts by several research groups managed to quantify the average behavior of the basis pursuit in probabilistic terms. A pioneering work by Candes, Romberg, and Tao <ref type="bibr" target="#b37">[38]</ref> established one such important result, and several others follow, although none is published yet.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix I -The Block-Coordinate-Relaxation Method</head><p>In Section II-C we have seen an alternative formulation to the separation task, built on the assumption that the involved dictionaries are concatenations of unitary matrices. Thus, we need to minimize <ref type="bibr" target="#b6">(7)</ref>, given (after a simplification) as</p><p>.</p><p>(I-1)</p><p>Note that we have discarded the TV part for the discussion given here. We also simply assume that the unknowns α(k) contain both the texture and the piecewise-smooth parts.</p><p>Minimizing such a penalty function was shown by Bruce, Sardy and Tseng <ref type="bibr" target="#b21">[22]</ref> to be quite simple, as it is based on the shrinkage algorithm due to Donoho and Johnston <ref type="bibr" target="#b20">[21]</ref>.</p><p>In what follows we briefly describe this algorithm and its properties.</p><p>Property 1: Referring to (I-1) as a function of {α(k)} k 0 , assuming all other unknowns as known, there is a closed-form solution for the optimal {α(k)} k 0 , given by</p><p>Due to the fact that T(k 0 ) is unitary and the fact that the 2 norm is unitary invariant we can rewrite this penalty term as min</p><p>tool for the separation. An interesting question is why should the 1 replacement succeed in the separation as well.</p><p>In order to answer this question we have to define first the Mutual Incoherence:</p><p>Definition 3: Given a matrix A, its Mutual -Incoherence{A} = M A is defined as the maximal off-diagonal entry in the absolute Gram matrix |A H A|.</p><p>The Mutual Incoherence is closely related to the Spark, and thus one can similarly define a similar notion of Inter-M A . We have the following result in <ref type="bibr" target="#b13">[14]</ref>:</p><p>Theorem 2: If the solution α opt all of (II-1) satisfies α opt all 0 &lt; (1/M T all + 1)/2, then the 1 minimization alternative is guaranteed to find it.</p><p>For the separation task, this Theorem implies that the separation via ( <ref type="formula">4</ref>) is successful if it is based on sparse enough ingredients:</p><p>and α t 0 + α n 0 &lt; (1/M T all + 1)/2 is true, then the solution of (4) leads to the global minimum of (II-1) and this is necessarily the desired separation.</p><p>Proof: The proof is simple deduction from Theorem 2.</p><p>2</p><p>We should note that the bounds given here are quite restrictive and does not reflect truly the much better empirical results. The above analysis is coming form a worst-case point of view (e.g., see the definition of the Spark), as opposed to the average case we expect to encounter empirically. Nevertheless, the ability to prove perfect separation in a stylized application without noise and with restricted success is of great benefit as a proof of concept.</p><p>In order to demonstrate the gap between theoretical results and empirical evidence in Basis Pursuit separation performance, figure <ref type="figure">9</ref> presents a simulation of the separation task for the case of signal X of length 64, a dictionary built as the combination of the Hadamard unitary matrix (assumed to be T t ) and the identity matrix (assumed to be T n ).</p><p>We randomly generate sparse representations with varying number of non-zeros in the two parts of the representation vector (of length 128), and present the empirical probability (based on averaging 100 experiments) to recover correctly the separation.</p><p>For this case, Corollary 3 suggest that the number of non-zero in the two parts should be smaller than 0.5 • (1 + 1/M) = (1 + √ 64)/2 = 4.5. Actually a better result exists</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Blind source separation by sparse decomposition in a signal dictionary</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="863" to="882" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multilayered image representation: Application to image compression</title>
		<author>
			<persName><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Averbuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1072" to="1080" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling textures with total variation minimization and oscillating patterns in image processing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="553" to="577" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A mathematical theory of primal sketch and sketchability</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the Ninth IEEE International Conference on Computer Vision (ICCV)<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image decomposition: Application to textured images and sar images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Matei</surname></persName>
		</author>
		<idno>ISRN I3S/RR-2004-02-FR</idno>
	</analytic>
	<monogr>
		<title level="j">INRIA -Project ARIANA</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Sophia Antipolis</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simultaneous structure and texture image inpainting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="882" to="889" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image decomposition: Application to textured images and sar images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Blanc-Feraud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<idno>ISRN I3S/RR-2003-01-FR</idno>
	</analytic>
	<monogr>
		<title level="j">INRIA -Project ARIANA</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Sophia Antipolis</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dual norms and image decomposition models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INRIA -Project ARIANA</title>
		<imprint>
			<biblScope unit="volume">5130</biblScope>
			<date type="published" when="2004">2004</date>
			<pubPlace>Sophia Antipolis</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep. ISRN</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Oscillating patterns in image processing and non linear evolution equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">University Lecture Series</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2002">2002</date>
			<publisher>AMS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nonlinear total variation noise removal algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Atomic decomposition by basis pursuit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saunder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="33" to="61" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Astronomical image representation by the curvelet tansform</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomy and Astrophysics</title>
		<imprint>
			<biblScope unit="volume">398</biblScope>
			<biblScope unit="page" from="785" to="800" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Uncertainty Principles and Ideal Atomic Decomposition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2845" to="2862" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Maximal sparsity representation via l1 minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Proc. Nat. Aca. Sci</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="2197" to="2202" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A generalized uncertainty principle and sparse representation in pairs of bases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2558" to="2567" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Some remarks on nonlinear approximation with schauder bases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">East J. on Approx</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="285" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Very high quality image restoration</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Candès</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE conference on Signal and Image Processing: Wavelet Applications in Signal and Image Processing IX</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Laine</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Unser</surname></persName>
		</editor>
		<editor>
			<persName><surname>Aldroubi</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2001-08-04">1-4 August. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">New multiscale transforms, minimum total variation synthesis: Applications to edge-preserving image reconstruction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1516" to="1543" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wavelets and curvelets for image deconvolution: a combined approach</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2279" to="2283" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Minimizing the total variation under a general convex constraint for image restoration</title>
		<author>
			<persName><forename type="first">F</forename><surname>Malgouyres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1450" to="1456" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ideal spatial adaptation via wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="425" to="455" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Block coordinate relaxation methods for nonparametric signal de-noising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE -The International Society for Optical Engineering</title>
		<meeting>the SPIE -The International Society for Optical Engineering</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3391</biblScope>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Image coding using wavelet transform</title>
		<author>
			<persName><forename type="first">M</forename><surname>Antonini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="205" to="220" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Embedded image coding using zerotrees of wavelet coefficients</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="3445" to="3462" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new, fast, and efficient image codec based on set partitioning in hierarchival trees</title>
		<author>
			<persName><forename type="first">A</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ridgelets: the key to high dimensional intermittency?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London A</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page" from="2495" to="2509" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Image Processing and Data Analysis: The Multiscale Approach</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bijaoui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
		<title level="m">Astronomical Image and Data Analysis</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Harmonic analysis of neural netwoks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="197" to="218" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The curvelet transform for image denoising</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="131" to="141" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Digital curvelet transform: strategy, implementation and experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Aerosense 2000, Wavelet Applications VII</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Szu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Campbell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Buss</surname></persName>
		</editor>
		<meeting>Aerosense 2000, Wavelet Applications VII</meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">4056</biblScope>
			<biblScope unit="page" from="12" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Curvelets -a surprisingly effective nonadaptive representation for objects with edges</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Curve and Surface Fitting: Saint-Malo</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Rabut</surname></persName>
		</editor>
		<editor>
			<persName><surname>Schumaker</surname></persName>
		</editor>
		<meeting><address><addrLine>Nashville, TN</addrLine></address></meeting>
		<imprint>
			<publisher>Vanderbilt University Press</publisher>
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the equivalence of soft wavelet shrinkage, total variation diffusion, total variation regularization, and sides</title>
		<author>
			<persName><forename type="first">G</forename><surname>Steidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mrzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2003">2003</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, University of Bremen</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Recovering edges in ill-posed inverse problems: Optimality of curvelet frames</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wavelets, approximation, and compression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="59" to="73" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Texture preserving variational denoising using an adaptive fidelity term</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sochen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLSM</title>
		<meeting>VLSM<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adapted waveform analysis and denoising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Majid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Progress in Wavelet Analysis and Applications</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Roques</surname></persName>
		</editor>
		<imprint>
			<publisher>Editions Frontières</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="63" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Romberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>draft -personal communication</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
