<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Protein sequence design with deep generative models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-04-12">April 12, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zachary</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Chemistry and Chemical Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<addrLine>1200 E California Blvd</addrLine>
									<postCode>91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kadina</forename><forename type="middle">E</forename><surname>Johnston</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Division of Biology and Biological Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<addrLine>1200 E California Blvd</addrLine>
									<postCode>91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frances</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Chemistry and Chemical Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<addrLine>1200 E California Blvd</addrLine>
									<postCode>91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Division of Biology and Biological Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<addrLine>1200 E California Blvd</addrLine>
									<postCode>91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Kevin</forename><forename type="middle">K</forename><surname>Yang</surname></persName>
							<email>yang.kevin@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research New England</orgName>
								<address>
									<addrLine>1 Memorial Drive</addrLine>
									<postCode>02142</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Protein sequence design with deep generative models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-04-12">April 12, 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2104.04457v1[q-bio.QM]</idno>
					<note type="submission">Preprint submitted to Current Opinion in Chemical Biology</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep learning</term>
					<term>Generative models</term>
					<term>Protein engineering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Protein engineering seeks to identify protein sequences with optimized properties. When guided by machine learning, protein sequence generation methods can draw on prior knowledge and experimental efforts to improve this process. In this review, we highlight recent applications of machine learning to generate protein sequences, focusing on the emerging field of deep generative methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Proteins are the workhorse molecules of natural life, and they are quickly being adapted for human-designed purposes. These macromolecules are encoded as linear chains of amino acids, which then fold into dynamic 3dimensional structures that accomplish a staggering variety of functions. To improve proteins for human purposes, protein engineers have developed a variety of experimental and computational methods for designing sequences that fold to desired structures or perform desired functions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. A developing paradigm, machine learning-guided protein engineering, promises to leverage the information obtained from wet-lab experiments with data-driven models to more efficiently find desirable proteins <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref> .</p><p>Much of the early work has focused on incorporating discriminative models trained on measured sequence-fitness pairs to guide protein engineering <ref type="bibr" target="#b4">[5]</ref>. However, methods that can take advantage of unlabeled protein sequences are improving the protein engineering paradigm. These methods rely on the metagenomic sequencing and subsequent deposition in databases such as UniProt <ref type="bibr" target="#b7">[8]</ref>, and continued development of these databases are essential for furthering our understanding of biology.</p><p>Additionally, while studies incorporating knowledge of protein structure are becoming increasingly powerful <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>, they are beyond the scope of this review, and we focus on deep generative models of protein sequence. For further detail on protein structure design, we encourage readers to consult Huang and Ovchinnikov's review in this issue of Current Opinion in Chemical Biology.</p><p>In discriminative modeling, the goal is to learn a mapping from inputs to labels by training on known pairs. In generative modeling, the goal is to learn the underlying data distribution, and a deep generative model is simply a generative model parameterized as a deep neural network. Generative models of proteins perform one or more of three fundamental tasks:</p><p>1. Representation learning: generative models can learn meaningful representations of protein sequences. 2. Generation: generative models can learn to sample protein sequences that have not been observed before. 3. Likelihood learning: generative models can learn to assign higher probability to protein sequences that satisfy desired criteria.</p><p>In this review, we discuss three applications of deep generative models in protein engineering roughly corresponding to the above tasks: (1) the use of learned protein sequence representations and pretrained models in downstream discriminative learning tasks, an important improvement to an established framework for protein engineering; (2) protein sequence generation using generative models; and (3) optimization by tuning generative models so that higher probability is assigned to sequences with some desirable property. Where possible, these methods are introduced with case studies that have validated generated sequences in vitro. Figure <ref type="figure" target="#fig_0">1</ref> summarizes these three applications of generative models. Additionally, we provide an overview of common deep generative models for protein sequences, variational autoencoders (VAEs), generative adversarial networks (GANs), and autoregressive models in Appendix A for further background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Fine-tuning on downstream tasks</head><p>An established framework for applying machine learning to guide protein engineering is through the training and application of discriminative regression models for specific tasks, which is better reviewed elsewhere <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Early examples of this approach were developed by Fox <ref type="bibr" target="#b13">[14]</ref> and Liao <ref type="bibr" target="#b14">[15]</ref> in learning the relationship between enzyme sequence and cyanation or hydrolysis activity, respectively. Briefly, in this approach, sequence-function experimental data are used to train regression models. These models are then used as estimates for the true experimental value, and can be used to search through and identify beneficial sequences in silico.</p><p>Learned representations have the potential to be more informative than one-hot encodings of sequence or aminoacid physico-chemical properties. They encode discrete protein sequences in a continuous and compressed latent space, where further optimization can be performed. Ideally, these representations capture contextual information <ref type="bibr" target="#b15">[16]</ref> that simplifies downstream modeling. However, these representations do not always outperform simpler representations given sufficient training data <ref type="bibr" target="#b16">[17]</ref>.</p><p>For example, in BioSeqVAE, the latent representation was learned from 200,000 sequences between 100 and 1000 amino acids in length obtained from SwissProt <ref type="bibr" target="#b17">[18]</ref>. The authors demonstrate that a simple random forest classifier from scikit-learn <ref type="bibr" target="#b18">[19]</ref> can be used to learn the relationship between roughly 60,000 sequences (represented by the outputs of the VAE encoder) and their protein localization and enzyme classification (by Enzyme Commission number) in a downstream fine-tuning task. By optimizing in latent space for either property through the downstream models and decoding this latent representation to a protein sequence, the authors generate examples that have either one or both desired properties. Although the authors did not validate the generated proteins in vitro, they did observe sequence homology between their designed sequences and natural sequences with the desired properties.</p><p>While the previous study used the output from a pretrained network as a fixed representation, another approach is to fine-tune the generative network for the new task. Autoregressive models are trained to predict the next token in a sequence from the previous tokens (Appendix A). When pretrained on large databases of protein sequence, they have stronger performance than other architectures on a variety of downstream discriminative tasks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b10">11]</ref>. There are few examples of experimental validation in this space, likely due to the delay in physically verifying computational predictions. However, Biswas and coauthors demonstrated that a double fine-tuning scheme results in discriminative models that can find improved sequences after training on very few measured sequences <ref type="bibr" target="#b22">[23]</ref>. First, they train an autoregressive model on sequences in UniRef50 <ref type="bibr" target="#b23">[24]</ref>. They then fine-tune the autoregressive model on evolutionarily-related sequences. Finally, they use the activations from the penultimate layer to represent each position of an input protein sequence in a simple downstream model (in a second round of fine-tuning), showing promising results on two tasks: improving the fluorescence activity of Aequorea victoria green fluorescent protein (avGFP) and optimizing TEM-1 β-lactamase. After training on just 24 randomly-selected sequences, this approach consistently outperforms one-hot encodings with 5 to 10 times the hit rate (defined as the fraction of proposed sequences with activity greater than wild type). The authors show that the pre-trained representation separates functional and nonfunctional sequences, allowing the final discriminator to focus on distinguishing the best sequences from mediocre but functional ones. While the previous work randomly identify the initial set for model training, Wittmann demonstrates an approach which chooses the most informative sets of sequences for further optimized evolution <ref type="bibr" target="#b24">[25]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Protein sequence generation</head><p>In addition to improving function predictions in downstream modeling, generative models can also be used to generate novel functional protein sequences. Here, we describe recent successful examples of sequences generated by VAEs, GANs, and autoregressive models.</p><p>Hawkins and coauthors generate functional luciferases from two VAE architectures <ref type="bibr" target="#b25">[26]</ref>: 1) by computing the alignment first and training a VAE (MSA VAE) on the aligned sequences and 2) by introducing an autoregressive component to the decoder to learn the unaligned sequences (AR VAE). Motivated by a similar model used for text generation <ref type="bibr" target="#b26">[27]</ref>, the decoder of the AR VAE contains an up-sampling component, which converts the compressed representation to the length of the output sequence, and an autoregressive component. Both models were trained with roughly 70,000 luciferase sequences (∼360 residues) and were quite successful: 21/23 and 18/24 variants generated with the MSA VAE and AR VAE (respectively) showed measurable activity.</p><p>The authors of ProteinGAN successfully trained a generative adversarial network to generate functional malate dehydrogenases <ref type="bibr" target="#b27">[28]</ref>. In one of the first published validations of GAN-generated sequences, after training with nearly 17,000 unique sequences (average length: 319), 24% of 20,000 sequences generated by ProteinGAN display near wild-type level activity, including a variant with 106 mutations to the closest known sequence. Interestingly, although the positional entropy of the final set of sequences closely matched that of the initial input, the generated sequences expand into new structural domains as classified by CATH <ref type="bibr" target="#b28">[29]</ref>, suggesting structural diversity in the generated results.</p><p>Riesselman and coauthors applied autoregressive models to generate single domain antibodies (nanobodies) <ref type="bibr" target="#b29">[30]</ref>. As the nanobody's complementarity-determining region is difficult to align due to its high variation, an autoregressive strategy is particularly advantageous because it does not require sequence alignments. With 100,000s of antibody sequences, the authors trained a residual dilated convolutional network over 250,000 updates. While other (recurrent) architectures were tested to capture longer range information, exploding gradients were encountered, as is common in these architectures. After training, the authors generated over 37 million new sequences by sampling amino acids at each new position in the sequence. Further clustering, diversity selection, and removal of motifs that may make expression more challenging (such as glycosylation sites and sulfur residues) enabled the researchers to winnow this number below 200,000, for which experimental results are pending.</p><p>Wu et al. applied the Transformer encoder-decoder model <ref type="bibr" target="#b30">[31]</ref> to generating signal peptides for industrial enzymes <ref type="bibr" target="#b31">[32]</ref>. Signal peptides are short (15-30 amino acid) sequences prepended to target protein sequences that signal the transport of the target sequence. After training with 25,000 pairs of target and signal peptide sequences, we generated signal peptide sequences to test in vitro, finding that roughly half of the generated sequences resulted in secreted and functional enzymes in Bacillus subtilis.</p><p>While this work suffices as early experimentally verified examples, there are many improvements that can be made, such as introducing information upon which to condition generation. Sequences are typically designed for a specific task, and task-specific information can be incorporated in the training process <ref type="bibr" target="#b32">[33]</ref>. For example, a VAE decoder can be conditioned on the identity of the metal cofactors bound <ref type="bibr" target="#b33">[34]</ref>. After training on 145,000 enzyme examples in MetalPDB <ref type="bibr" target="#b34">[35]</ref>, the authors find a higher fraction of desired metal-binding sites observed in generated sequences. Additionally, 11% of 1000 sequences generated for recreating a removed copper-binding site identified the correct binding amino acid triad. The authors also applied this approach to design specific protein folds, validating their results with Rosetta and molecular dynamics simulations. In ProGen, Madani and co-authors condition an autoregressive sequence model on protein metadata, such as a protein's functional and/or organismal annotation <ref type="bibr" target="#b35">[36]</ref>. While this work does not have functional experimental validation, after training on 280 million sequences and their annotations from various databases, the authors show that computed energies from Rosetta <ref type="bibr" target="#b36">[37]</ref> of the generated sequences are similar to that of natural sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization with Generative Models</head><p>While much of the existing work is designed to generate valid sequences, eventually, the protein engineer expects improved sequences. An emerging approach to this optimization problem is to optimize with generative models <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b40">40]</ref>. Instead of generating viable examples, this framework trains models to generate optimized sequences by placing higher probability on improved sequences (Figure <ref type="figure" target="#fig_0">1 C</ref>).</p><p>One approach to optimization is to bias the data fed to a GAN. Amimeur and coauthors trained Wasserstein GANs <ref type="bibr" target="#b41">[41]</ref> on 400,000 heavy or light chain sequences from human antibodies to generate regions of 148 amino acids of the respective chain <ref type="bibr" target="#b40">[40]</ref>. After initial training, by biasing further input data on desired properties (length, size of a negatively-charged region, isoelectronic point, and estimated immunogenicity), the estimated properties of the generated examples shift in the desired direction. While it is not known what fraction of the 100,000 generated constructs is functional from the experimental validation, extensive biophysical characterization of two of the successful designs show promising signs of retaining the designed properties in vitro. An alternative study developing a Feedback GAN (FBGAN) framework extends this by iteratively generating sequences from a GAN, scoring them with an oracle, and replacing the lowest-scoring members of the training set with the highest-scoring generated sequences <ref type="bibr" target="#b42">[42]</ref>.</p><p>Fortunately, this optimization can be enforced algorithmically. The Design by Adaptive Sampling algorithm <ref type="bibr" target="#b43">[43]</ref> improves the iterative retraining scheme by using a probabilistic oracle and weighting generated sequences by the probability that they are above the Q th percentile of scores from the previous iteration. This allows the optimization to become adaptively more stringent and guarantees convergence under some conditions. The authors validate this approach on synthetic ground truth data by training models (of a different type) on real biological data. They then show that generated sequences outperform traditional evolutionary methods (and the previously mentioned FBGAN) when restricted to a budget of 10,000 sequences. The current iteration of this work, Conditioning by Adaptive Sampling (CbAS), improves this approach by avoiding regions too far from the training set for the oracle <ref type="bibr" target="#b44">[44]</ref>, while other approaches focus the oracle as design moves between regions of sequence space <ref type="bibr" target="#b45">[45]</ref> or emphasize sequence diversity in generations <ref type="bibr" target="#b46">[46]</ref>.</p><p>Another approach <ref type="bibr" target="#b39">[39]</ref> for model-based optimization has roots in reinforcement learning (RL) <ref type="bibr" target="#b47">[47]</ref>. The RL framework is typically applied when a decision maker is asked to choose an action that is available given the current state. From this action, the state changes through the transition function with some reward. When a given state and action are independent of all previous states and actions (the Markov property), the system can be modeled with Markov decision processes. This requirement is satisfied by interpreting the protein sequence generation as a process where the sequence is generated from left to right. At each time step, we begin with the sequence as generated to that point (the current state), the select the next amino acid (the action), and add that amino acid to the sequence (the transition function). The reward remains 0 until generation is complete, and the final reward is the fitness measurement for the generated sequence. The action (the next amino acid) is decided by a policy network, which is trained to output a probability over all available actions based on the sequence thus far and the expected future reward. Notably, the transition function is simple (adding an amino acid), so only the reward function needs to be approximated.</p><p>The major challenge under the RL framework is then determining the expected reward. To tackle this issue, Angermueller and coauthors use a panel of machine learning models, each learning a surrogate fitness function f j based on available data from each round of experimentation <ref type="bibr" target="#b39">[39]</ref>. The subset of models from this panel that pass some threshold accuracy (as empirically evaluated by cross validation) is selected for use in estimating the reward, and the policy network is then updated based on the estimated reward. Thus, this algorithm enables using a panel of models to potentially capture various aspects of the fitness landscape, but only uses the models that have sufficient accuracy to update the policy network. The authors also incorporate a diversity metric by including a term in the expected reward for a sequence that counts the number of similar sequences previously explored. The authors applied this framework to various biologically motivated synthetic datasets, including an antimicrobial peptide (8 -75 amino acids) dataset as simulated with random forests. With eight rounds testing up to 250 sequences each, the authors obtained higher fitness values compared to other methods, including CbAS and FBGAN. However, the authors also show that the proposed sequence diversity quickly drops, and only the diversity term added to the expected reward prevents it from converging to zero.</p><p>While significant work has been invested in optimizing protein sequences with generative models, this direction is still in its infancy, and it is not clear which approach or framework has general advantages, particularly as many of these approaches have roots in non-biological fields. In the future, balancing increased sequence diversity against staying within each model's trusted regions of sequence space <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b46">46]</ref> or other desired protein properties will be necessary to broaden our understanding of protein sequence space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Future Directions</head><p>Machine learning has shown preliminary success in protein engineering, enabling researchers to access optimized sequences with unprecedented efficiency. These approaches allow protein engineers to efficiently sample sequence space without being limited to nature's repertoire of mutations. As we continue to explore sequence space, expanding from the sequences that nature has kindly prepared, there is hope that we will find diverse solutions for myriad problems <ref type="bibr" target="#b48">[48]</ref>.</p><p>Many of the examples presented required testing many protein variants, and many of the advances in machine learning have been driven by data collection as well. For example, a large contribution to the current boom in deep learning can be traced back to ImageNet, a database of well-annotated images used for classification tasks <ref type="bibr" target="#b49">[49]</ref>. For proteins, a well-organized biannual competition for protein structure prediction known as CASP (Critical Assessment of Protein Structure Prediction) <ref type="bibr" target="#b50">[50]</ref> enabled machine learning to push the field forward <ref type="bibr" target="#b51">[51]</ref>. A large database of protein sequences also exists <ref type="bibr" target="#b7">[8]</ref> with reference clusters provided <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b23">24]</ref>. However, these sequences are rarely coupled to fitness measurements and if so, are collected in diverse experimental conditions. While databases like ProtaBank <ref type="bibr" target="#b53">[53]</ref> promise to organize data collected along with their experimental conditions, protein sequence design for diverse functions has yet to experience its ImageNet moment.</p><p>Fortunately, a wide variety of tools are being developed for collecting large amounts of data, including deep mutational scanning <ref type="bibr" target="#b54">[54]</ref> and methods involving continuous evolution <ref type="bibr" target="#b55">[55,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b57">57]</ref>. These techniques contain their own nuances and data artifacts that must be considered <ref type="bibr" target="#b58">[58]</ref>, and unifying across studies must be done carefully <ref type="bibr" target="#b60">[59]</ref>. While these techniques currently apply to a subset of desired protein properties that are robustly measured, such as survival, fluorescence, and binding affinity, we must continue to develop experimental techniques if we hope to model and understand more complex traits such as enzymatic activity.</p><p>In the meantime, machine learning has enabled us to generate useful protein sequences on a variety of scales. In low-to medium-throughput settings, protein engineering guided by discriminative models enables efficient identification of improved sequences through the learned surrogate fitness function. In settings with larger amounts of data, deep generative models have various strengths and weaknesses that may be leveraged depending on design and experimental constraints. By integrating machine learning with rounds of experimentation, data-driven protein engineering promises to maximize the efforts from expensive lab work, enabling protein engineers to quickly design useful sequences. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: During unsupervised training (A), a generative decoder learns to generate proteins similar to those in the unsupervised training set from embedding vectors. The embeddings can then be used as inputs to a downstream modeling task (B). The decoder can be used to generate new functional sequences (C), or the entire generative model can be tuned to generate functional sequences optimized for a desired property (D).</figDesc><graphic url="image-1.png" coords="3,100.24,187.30,394.80,427.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure A. 2 :</head><label>2</label><figDesc>Figure A.2: (A) Variational Autoencoders (VAEs) are tasked with encoding sequences in a structured latent space. Samples from this latent space may then be decoded to functional protein sequences. (B) Generative Adversarial Networks (GANs) have two networks locked in a Nash equilibrium: the generative network generates synthetic data that look real, while the discriminative network discerns between real and synthetic data. (C) Autoregressive models predict the next amino acid in a protein given the amino-acid sequence up to that point.</figDesc><graphic url="image-2.png" coords="10,144.55,154.37,306.18,483.59" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors wish to thank members Lucas Schaus and Sabine Brinkmann-Chen for feedback on early drafts. This work is supported by the Camille and Henry Dreyfus Foundation (ML-  and the NSF Division of Chemical, Bioengineering, Environmental, and Transport Systems (1937902).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Appendix: Deep Generative Models of Protein Sequence</head><p>Here, we describe three popular generative models, variational autoencoders, generative adversarial networks, and autoregressive models, and provide examples of their applications to protein sequences. These models are summarized in Figure A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A.1. Variational Autoencoders</head><p>To provide an intuitive introduction to Variational Autoencoders, we first introduce the concept of autoencoders <ref type="bibr" target="#b61">[60,</ref><ref type="bibr" target="#b62">61,</ref><ref type="bibr" target="#b63">62]</ref>, which are comprised of an encoder and a decoder. The encoder, q(z|x), maps each input x i into a latent representation z i . This latent representation is comparatively low dimension to the initial encoding, creating an information bottleneck that forces the autoencoder to learn a useful representation. The decoder, p(x|z), reconstructs each input x i from its latent representation z i . During training, the goal of the model is to maximize the probability of the data p(x), which can be determined by marginalizing over z:</p><p>p(z) is the prior over z, which is usually taken to be normal(0, 1). Direct evaluation of the integral in Equation A.1 is intractable and is instead bounded using variational inference. It can be shown that a lower bound of p(x) can be written as the following <ref type="bibr" target="#b61">[60]</ref>:</p><p>where D KL is the Kullback-Leibler divergence, which can be interpreted as a regularization term that measures the amount of lost information when using q to represent p, and the first expectation E term represents reconstruction accuracy. VAEs are trained to maximize this lower bound on log p(x), thus learning to place high probability on the training examples. The encoder representation can be used for downstream prediction tasks, and the decoder can be used to generate new examples, which will be non-linear interpolations of the training examples. Intuitively, the prior over z enables smooth interpolation between points in the latent representation, enforcing structure in an otherwise arbitrary representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A.2. Generative Adversarial Networks</head><p>Generative Adversarial Networks (GANs) are comprised of a generator network G that maps from random noise to examples in the data space and an adversarial discriminator D that learns to discriminate between generated and real examples <ref type="bibr" target="#b64">[63]</ref>. As the generator learns to generate examples that are increasingly similar to real examples, the discriminator must also learn to distinguish between them. This equilibrium can be written as a minimax game between the Generator G and Discriminator D, where the loss function is:</p><p>where the discriminator is trained to maximize the probability D(x) when x comes from a distribution of real data, and minimize the probability that the data point is real (D(G(z))) when the data is generated (G(z)). GANS do not perform representation learning or density estimation, but on image data they usually generate more realistic examples than VAEs <ref type="bibr" target="#b65">[64,</ref><ref type="bibr" target="#b66">65]</ref>. However, the Nash equilibrium between the generator and discriminator networks can be notoriously difficult to obtain in practice <ref type="bibr" target="#b67">[66,</ref><ref type="bibr" target="#b68">67]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A.3. Autoregressive models</head><p>An emerging class of models from language processing has developed from self-supervised learning of sequences. After masking portions of sequences, deep neural networks are tasked with generating the masked portions correctly, as conditioned on the unmasked regions. In the autoregressive setting, models are tasked with generating subsequent tokens based on previously generated tokens. The probability of a sequence can then be factorized as a product of conditional distributions:</p><p>Alternately, the masked language model paradigm takes examples where some sequence elements have been replaced by a special mask token and learns to reconstruct the original sequence by predicting the identity of the masked tokens conditioned on the rest of the sequence:</p><p>Autoregressive models learn by maximizing the probability of the training sequences. They can be used to generate new sequences, and depending on the architecture, they can usually provide a learned contextual representation for every position in a sequence. While masked language models are not strictly autoregressive, they often use the same model architectures as autoregressive generative models, and so we include them here.</p><p>The main challenge is in capturing long-range dependencies. Three popular architectures, dilated convolution networks, recurrent neural networks (RNNs), and Transformer-based models, take different approaches. Dilated convolution networks include convolutions with defined gaps in the filters in order to capture information across larger distances <ref type="bibr" target="#b69">[68,</ref><ref type="bibr" target="#b70">69]</ref>. RNNs attempt to capture positional information directly in the model state <ref type="bibr" target="#b71">[70,</ref><ref type="bibr" target="#b72">71]</ref>, and an added memory layer is introduced in Long Short-Term Memory (LSTM) networks to account for long-range interactions <ref type="bibr" target="#b73">[72,</ref><ref type="bibr" target="#b74">73,</ref><ref type="bibr" target="#b75">74]</ref>. Finally, Transformer networks are based on the attention mechanism, which computes a soft probability contribution over all positions in the sequence <ref type="bibr" target="#b76">[75,</ref><ref type="bibr" target="#b77">76]</ref>. They were also developed for language modeling to capture all possible pairwise interactions <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b78">77,</ref><ref type="bibr" target="#b79">78,</ref><ref type="bibr" target="#b80">79]</ref>. Notably, Transformer networks are also used for autoencoding pretraining, where tokens throughout the sequence (regardless of order) are masked and reconstructed <ref type="bibr" target="#b78">[77]</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exploring protein fitness landscapes by directed evolution</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrm2805</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Molecular Cell Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="866" to="876" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Directed evolution: bringing new chemistry to life</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<idno type="DOI">10.1002/anie.201708408</idno>
	</analytic>
	<monogr>
		<title level="j">Angewandte Chemie International Edition</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="4143" to="4148" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The coming of age of de novo protein design</title>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Boyken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Baker</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature1994</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">537</biblScope>
			<biblScope unit="issue">7620</biblScope>
			<biblScope unit="page" from="320" to="327" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computational design of protein function</title>
		<author>
			<persName><forename type="first">M</forename><surname>Garcia-Borrás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Houk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jiménez-Osés</surname></persName>
		</author>
		<idno type="DOI">10.1039/9781788010139-00087</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Tools for Chemical Biology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">87</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Machine-learning-guided directed evolution for protein engineering</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-019-0496-6</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="687" to="694" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Machine learning in enzyme engineering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mazurenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Prokop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Damborsky</surname></persName>
		</author>
		<idno type="DOI">10.1021/acscatal.9b04321</idno>
	</analytic>
	<monogr>
		<title level="j">ACS Catalysis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1210" to="1223" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Biosystems design by machine learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Volk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lourentzou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1021/acssynbio.0c00129</idno>
	</analytic>
	<monogr>
		<title level="j">ACS Synthetic Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1514" to="1533" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Uniprot: a worldwide hub of protein knowledge</title>
		<author>
			<persName><forename type="first">U</forename><surname>Consortium</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="D506" to="D515" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative models for graph-based protein design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ingraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15794" to="15805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Ramanet: Computational de novo helical protein backbone design using a long short-term memory generative adversarial neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sabban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Markovsky</surname></persName>
		</author>
		<idno type="DOI">10.12688/f1000research.22907.1</idno>
		<imprint>
			<date type="published" when="2020">F1000Research 9 (298. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning protein sequence embeddings using information from structure</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bepler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protein sequence design with a learned potential</title>
		<author>
			<persName><forename type="first">N</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Derry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1101/2020.01.06.895466</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">This paper is a clear demonstration of the efficacy of learned embeddings for both proteins and small molecules, and additionally shows how modeled uncertainty enables the identification of improved sequences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Berger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cels.2020.09.007</idno>
	</analytic>
	<monogr>
		<title level="j">Cell Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="461" to="477" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Leveraging uncertainty in machine learning accelerates biological discovery and design</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving catalytic function by ProSAR-driven enzyme evolution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Mundorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gavrilovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Whitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Sheldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Huisman</surname></persName>
		</author>
		<idno type="DOI">10.1038/nbt1286</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="338" to="344" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Engineering proteinase K using machine learning and synthetic genes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Govindarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Ness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Minshull</surname></persName>
		</author>
		<idno type="DOI">10.1186/1472-6750-7-16</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Biotechnology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">16</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A deep dive into machine learning models for protein engineering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Sherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Svetnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Johnston</surname></persName>
		</author>
		<idno type="DOI">10.1021/acs.jcim.0c00073</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="2773" to="2790" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Is transfer learning necessary for protein landscape prediction?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shanehsazzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/2011.03443" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia Martin</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1903.00458" />
		<title level="m">How to hallucinate functional proteins</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unified rational protein engineering with sequence-based deep representation learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Alley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Khimulya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alquraishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Church</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1315" to="1322" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences, bioRxiv *An early example of modern protein language modeling, which applied the BERT training objective to protein sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rives</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="DOI">10.1101/622803</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating protein transfer learning with tape</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9686" to="9698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Low-n protein engineering with data-efficient deep learning, bioRxiv **An excellent example leveraging learned embeddings for protein engineering, enabling improved variants to be identified after training on as little as 24 variants</title>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Khimulya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Alley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Esvelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Church</surname></persName>
		</author>
		<idno type="DOI">10.1101/2020.01.23.917682</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Uniref clusters: a comprehensive and scalable alternative for improving sequence similarity searches</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Suzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Mcgarvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Consortium</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btu739</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="926" to="932" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Machine learning-assisted directed evolution navigates a combinatorial epistatic fitness landscape with minimal screening burden</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Wittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<idno type="DOI">10.1101/2020.12.04.408955</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating functional protein variants with variational autoencoders</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hawkins-Hooker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Depardieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Couairon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bikard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">e1008736</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Semeniuta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barth</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1702.02390" />
		<title level="m">A hybrid convolutional variational autoencoder for text generation</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Expanding functional protein sequence spaces using generative adversarial networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Repecka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jauniskis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Karpus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rembeza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rokaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zrimec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poviloniene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laurynenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Viknander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Abuajwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cath: Expanding the horizons of structure-based functional annotations for genome sequences</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sillitoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Lees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ashford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tolulope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Scholes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Senatorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bujan</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gky1097</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="D280" to="D284" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Accelerating protein design using autoregressive generative models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Riesselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-E</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Kollasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcmahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Manglik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Marks</surname></persName>
		</author>
		<idno type="DOI">10.1101/757252</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Signal peptides generated by attention-based neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Liszka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Batzilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Weiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<idno type="DOI">10.1021/acssynbio.0c00219</idno>
	</analytic>
	<monogr>
		<title level="j">ACS Synthetic Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2154" to="2161" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3483" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Design of metalloproteins and novel protein folds using variational autoencoders</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Greener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-018-34533-1</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Metalpdb: a database of metal sites in biological macromolecular structures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Andreini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lorenzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosato</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkx989</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="D312" to="D319" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Progen: Language modeling for protein generation, arXiv *This paper also uses modern language modeling methods to learn protein information, including metadata such as protein function and organism</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="DOI">10.1101/2020.03.07.982272</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The rosetta all-atom energy function for macromolecular modeling and design</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Alford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leaver-Fay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Jeliazkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>O'meara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Dimaio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Shapovalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Renfrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Mulligan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kappel</surname></persName>
		</author>
		<idno type="DOI">10.1021/acs.jctc.7b00125</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Theory and Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3031" to="3048" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Conditioning by adaptive sampling for robust design</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="773" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">This work develops an algorithm for identifying optimized protein sequences using a probabilistic oracle that accounts for the oracle&apos;s bias</title>
		<author>
			<persName><forename type="first">**</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Model-based reinforcement learning for biological sequence design, International Conference on Learning Representations **This work begins a series of publications in optimizing sequences with a framework inspired by Reinforcement Learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Angermueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Colwell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Designing feature-controlled humanoid antibody discovery libraries using generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Amimeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Shaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Ketchem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Citters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Siska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sprague</surname></persName>
		</author>
		<idno type="DOI">10.1101/2020.04.12.024844</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wasserstein</forename><surname>Gan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1701.07875" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Feedback gan for dna optimizes protein functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-019-0017-4</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="111" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1810.03714" />
		<title level="m">Design by adaptive sampling</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1901.10060" />
	</analytic>
	<monogr>
		<title level="m">Conditioning by adaptive sampling for robust design</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Fannjiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/2006.08052" />
		<title level="m">Autofocused oracles for model-based design</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">) (2020) 49-62, **This work develops another approach to generating optimized sequences, with an additional capability of generating diversified sequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bogard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seelig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
	<note>A generative neural network for maximizing fitness and diversity of synthetic dna and protein sequences</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Protein promiscuity and its implications for biotechnology</title>
		<author>
			<persName><forename type="first">I</forename><surname>Nobeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Favia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Thornton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nbt1519</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="167" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A large-scale experiment to assess protein structure prediction methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Moult</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Judson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fidelis</surname></persName>
		</author>
		<idno type="DOI">10.1002/prot.340230303</idno>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Improved protein structure prediction using potentials from deep learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jumper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Žídek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bridgland</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-019-1923-7</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Uniref: comprehensive and non-redundant uniprot reference clusters</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Suzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcgarvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mazumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btm098</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1282" to="1288" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Protabank: A repository for protein design and engineering data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Ary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Chica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Olafson</surname></persName>
		</author>
		<idno type="DOI">10.1002/pro.3406</idno>
	</analytic>
	<monogr>
		<title level="j">Protein Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1113" to="1124" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep mutational scanning: a new style of protein science</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fields</surname></persName>
		</author>
		<idno type="DOI">10.1038/nmeth.3027</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">801</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A system for the continuous directed evolution of biomolecules</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Esvelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature09929</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">472</biblScope>
			<biblScope unit="issue">7344</biblScope>
			<biblScope unit="page" from="499" to="503" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The developing toolkit of continuous directed evolution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Podracky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41589-020-0532-y</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Chemical Biology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="619" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Automated continuous evolution of proteins in vivo</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Arzumanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1021/acssynbio.0c00135</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ACS Synthetic Biology</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F.-E</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Systematic auditing is essential to debiasing machine learning in biology</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Eid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Elmarakeby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fornelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Elhefnawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Van Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><surname>Lage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications Biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Exploring amino acid functions in a deep mutational landscape</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dunham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beltrao</surname></persName>
		</author>
		<idno type="DOI">10.1101/2020.05.26.116756</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1312.6114" />
		<title level="m">Auto-encoding variational Bayes</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1401.4082" />
		<title level="m">Stochastic backpropagation and approximate inference in deep generative models</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1606.05908" />
		<title level="m">Tutorial on variational autoencoders</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1406.2661" />
	</analytic>
	<monogr>
		<title level="m">Generative adversarial networks</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V D</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1511.01844" />
	</analytic>
	<monogr>
		<title level="m">A note on the evaluation of generative models</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1606.00704" />
	</analytic>
	<monogr>
		<title level="m">Adversarially learned inference</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
	<note>Improved techniques for training gans</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Which training methods for gans do actually converge?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1801.04406" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1511.07122" />
	</analytic>
	<monogr>
		<title level="m">Multi-scale context aggregation by dilated convolutions</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V D</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1609.03499" />
	</analytic>
	<monogr>
		<title level="m">Wavenet: A generative model for raw audio</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Černocký</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
		<title level="m">Eleventh Annual Conference of the International Speech Communication Association</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Recurrent neural network based language model</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1406.1078" />
	</analytic>
	<monogr>
		<title level="m">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1409.0473" />
		<title level="m">Neural machine translation by jointly learning to align and translate</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1508.04025" />
	</analytic>
	<monogr>
		<title level="j">arXiv</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1810.04805" />
	</analytic>
	<monogr>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1910.03771" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
