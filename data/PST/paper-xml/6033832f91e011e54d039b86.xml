<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">E(n) Equivariant Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Victor</forename><forename type="middle">Garcia</forename><surname>Satorras</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emiel</forename><surname>Hoogeboom</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
						</author>
						<title level="a" type="main">E(n) Equivariant Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Although deep learning has largely replaced hand-crafted features, many advances are critically dependent on inductive biases in deep neural networks. An effective method to restrict neural networks to relevant functions is to exploit the symmetry of problems by enforcing equivariance with respect to transformations from a certain symmetry group. Notable examples are translation equivariance in Convolutional Neural Networks and permutation equivariance in Graph Neural Networks <ref type="bibr" target="#b2">(Bruna et al., 2013;</ref><ref type="bibr" target="#b6">Defferrard et al., 2016;</ref><ref type="bibr" target="#b13">Kipf &amp; Welling, 2016a)</ref>.</p><p>Many problems exhibit 3D translation and rotation symmetries. Some examples are point clouds <ref type="bibr" target="#b30">(Uy et al., 2019)</ref>, 3D molecular structures <ref type="bibr" target="#b22">(Ramakrishnan et al., 2014)</ref> or N-body particle simulations <ref type="bibr" target="#b12">(Kipf et al., 2018)</ref>. The group corresponding to these symmetries is named the Euclidean group: SE(3) or when reflections are included E(3). It is often desired that predictions on these tasks are either equivariant or invariant with respect to E(3) transformations.</p><p>1 UvA-Bosch Delta Lab, University of Amsterdam, Netherlands.</p><p>Correspondence to: Victor Garcia Satorras &lt;v.garciasatorras@uva.nl&gt;, Emiel Hoogeboom &lt;e.hoogeboom@uva.nl&gt;, Max Welling &lt;m.welling@uva.nl&gt;.</p><p>Preliminary work. Under review. Recently, various forms and methods to achieve E(3) or SE(3) equivariance have been proposed <ref type="bibr" target="#b29">(Thomas et al., 2018;</ref><ref type="bibr" target="#b8">Fuchs et al., 2020;</ref><ref type="bibr" target="#b7">Finzi et al., 2020;</ref><ref type="bibr" target="#b16">Köhler et al., 2020)</ref>. Many of these works achieve innovations in studying types of higher-order representations for intermediate network layers. However, the transformations for these higher-order representations require coefficients or approximations that can be expensive to compute. Additionally, in practice for many types of data the inputs and outputs are restricted to scalar values (for instance temperature or energy, referred to as type-0 in literature) and 3d vectors (for instance velocity or momentum, referred to as type-1 in literature).</p><p>In this work we present a new architecture that is translation, rotation and reflection equivariant (E(n)), and permutation equivariant with respect to an input set of points. Our model is simpler than previous methods in that it does not require the spherical harmonics as in <ref type="bibr" target="#b29">(Thomas et al., 2018;</ref><ref type="bibr" target="#b8">Fuchs et al., 2020)</ref> while it can still achieve competitive or better results. In addition, equivariance in our model is not limited to the 3-dimensional space and can be scaled to larger dimensional spaces without a significant increase in computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2102.09844v1 [cs.LG] 19 Feb 2021</head><p>We evaluate our method in modelling dynamical systems, representation learning in graph autoencoders and predicting molecular properties in the QM9 dataset. Our method reports the best performance in all three experiments achieving state-of-the-art-results on several regression targets of the QM9 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>In this section we introduce the relevant materials on equivariance and graph neural networks which will later complement the definition of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Equivariance</head><p>Let T g : X − → X be a set of transformations on X for the abstract group g ∈ G. We say a function φ : X − → Y is equivariant to g if there exists an equivalent transformation on its output space S g : Y − → Y such that:</p><formula xml:id="formula_0">φ(T g (x)) = S g (φ(x))<label>(1)</label></formula><p>As a practical example, let φ(•) be a non-linear function, x = (x 1 , . . . , x M ) ∈ R M ×n an input set of M point clouds embedded in a n-dimensional space, φ(x) = y ∈ R M ×n the transformed set of point clouds, T g a translation on the input set T g (x) = x + g and S g an equivalent translation on the output set S g (y) = y + g. If our transformation φ : X − → Y is translation equivariant, translating the input set T g (x) and then applying the function φ(T x (x)) on it, will deliver the same result as first running the function y = φ(x) and then applying an equivalent translation to the output T g (y) such that Equation 1 is fulfilled and φ(x+g) = φ(x) + g. In this work we explore the following three types of equivariance on a set of particles x:</p><p>1. Translation equivariance. Translating the input by g ∈ R n results in an equivalent translation of the output.</p><p>Let x+g be shorthand for (x 1 +g, . . . , x M +g). Then y + g = φ(x + g) 2. Rotation (and reflection) equivariance. For any orthogonal matrix Q ∈ R n×n , let Qx be shorthand for (Qx 1 , . . . , Qx M ). Then rotating the input results in an equivalent rotation of the output Qy = φ(Qx). 3. Permutation equivariance. Permuting the input results in the same permutation of the output P (y) = φ(P (x)) where P is a permutation on the row indexes.</p><p>Note that velocities v ∈ R M ×n are unaffected by translations, but they transform equivalently under rotation (2) and permutation (3). Our method introduced in Section 3 will satisfy the three above mentioned equivariant constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Graph Neural Networks</head><p>Graph Neural Networks are permutation equivariant networks that operate on graph structured data <ref type="bibr" target="#b2">(Bruna et al., 2013;</ref><ref type="bibr" target="#b6">Defferrard et al., 2016;</ref><ref type="bibr" target="#b13">Kipf &amp; Welling, 2016a)</ref>. Given a graph G = (V, E) with nodes v i ∈ V and edges e ij ∈ E we define a graph convolutional layer following notation from <ref type="bibr" target="#b9">(Gilmer et al., 2017)</ref> as:</p><formula xml:id="formula_1">m ij = φ e (h l i , h l j , a ij ) m i = j∈N (i) m ij h l+1 i = φ h (h l i , m i )<label>(2)</label></formula><p>Where h l i ∈ R nf is the nf-dimensional embedding of node v i at layer l. a ij are the edge attributes. N (i) represents the set of neighbors of node v i . Finally, φ e and φ h are the edge and node operations respectively which are commonly approximated by Multilayer Perceptrons (MLPs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Equivariant Graph Neural Networks</head><p>In this section we present Equivariant Graph Neural Networks (EGNNs). Following the notation from background Section 2.2, we consider a graph G = (V, E) with nodes v i ∈ V and edges e ij ∈ E. In addition to the feature node embeddings h i ∈ R nf we now also consider a n-dimensional coordinate x i ∈ R n associated with each of the graph nodes. Our model will preserve equivariance to rotations and translations on these set of coordinates x i and it will also preserve equivariance to permutations on the set of nodes V in the same fashion as GNNs.</p><p>Our Equivariant Graph Convolutional Layer (EGCL) takes as input the set of node embeddings h l = {h l 0 , . . . , h l M −1 }, coordinate embeddings x l = {x l 0 , . . . , x l M −1 } and edge information E = (e ij ) and outputs a transformation on h l+1 and x l+1 . Concisely: h l+1 , x l+1 = EGCL[h l , x l , E]. The equations that define this layer are the following:</p><formula xml:id="formula_2">m ij = φ e h l i , h l j , x l i − x l j 2 , a ij<label>(3)</label></formula><formula xml:id="formula_3">x l+1 i = x l i + j =i x l i − x l j φ x (m ij )<label>(4)</label></formula><formula xml:id="formula_4">m i = j∈N (i) m ij (5) h l+1 i = φ h h l i , m i<label>(6)</label></formula><p>Notice the main differences between the above proposed method and the original Graph Neural Network from equation 2 are found in equations 3 and 4. In equation 3 we now input the relative squared distance between two coordinates x l i − x l j 2 into the edge operation φ e . The embeddings h l i , h l j , and the edge attributes a ij are also provided as input to the edge operation as in the GNN case. In our case the edge attributes will incorporate the edge values a ij = e ij , but they could also include additional edge information.</p><p>In Equation <ref type="formula" target="#formula_3">4</ref>we update the position of each particle x i as a vector field in a radial direction. In other words, the position of each particle x i is updated by the weighted sum of all relative differences (x i −x j ) ∀j . The weights of this sum are provided as the output of the function φ x : R nf → R 1 that takes as input the edge embedding m ij from the previous edge operation and outputs a scalar value. This equation is the main difference of our model compared to standard GNNs and it is the reason why equivariances 1, 2 are preserved (proof in Appendix A). Despite its simplicity, this equivariant operation is very flexible since the embedding m ij can carry information from the whole graph and not only from the given edge e ij .</p><p>Finally, equations 5 and 6 follow the same updates than standard GNNs. Equation 5 just aggregates all the incoming messages from neighbor nodes N (i) to node v i and Equation 6 performs the node operation φ v which takes as input the aggregated messages m i , the node emedding h l i and outputs the updated node embedding h l+1 i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Analysis on E(n) equivariance</head><p>In this section we analyze the equivariance properties of our model for E(3) symmetries (i.e. properties 1 and 2 stated in section 2.1). In other words, our model should be translation equivariant on x for any translation vector g ∈ R n and it should also be rotation and reflection equivariant on x for any orthogonal matrix Q ∈ R n×n . More formally our model satisfies:</p><formula xml:id="formula_5">Qx l+1 + g, h l+1 = EGCL(Qx l + g, h l )</formula><p>We provide a formal proof of this in Appendix A. Intuitively, let's consider a h l feature which is already E(n) invariant, then we can see that the resultant edge embedding m ij from Equation 3 will also be E(n) invariant, because in addition to h l , it only depends on squared distances</p><formula xml:id="formula_6">x l i − x l j 2 ,</formula><p>which are E(n) invariant. Next, Equation 4 computes x l+1 i by a weighted sum of differences (x i − x j ) which is added to x i , this transforms as a type-1 vector and preserves equivariance (see Appendix A). Finally the last two equations 5 and 6 that generate the next layer node-embeddings h l+1 remain E(n) invariant since they only depend on h l and m ij which, as we saw above, are E(n) invariant. Therefore the output h l+1 is E(n) invariant and x l+1 is E(n) equivariant to x l . Inductively, a composition of EGCLs will also be equivariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Extending EGNNs for vector type representations</head><p>In this section we propose a slight modification to the presented method such that we explicitly keep track of the particle's momentum. In some scenarios this can be useful not only to obtain an estimate of the particle's velocity at every layer but also to provide an initial velocity value in those cases where it is not 0. We can include momentum to our proposed method by just replacing Equation 4 of our model with the following equation:</p><formula xml:id="formula_7">v l+1 i = φ v h l i v l i + j =i x l i − x l j φ x (m ij ) x l+1 i = x l i + v l+1 i (7)</formula><p>Note that this extends the EGCL layer as</p><formula xml:id="formula_8">h l+1 , x l+1 , v l+1 = EGCL[h l , x l , v l , E].</formula><p>The only difference is that now we broke down the coordinate update (eq. 4) in two steps, first we compute the velocity v l+1 i and then we use this velocity to update the position x l i . The velocity v l is scaled by a new function φ v : R N → R 1 that maps the node embedding h l i to a scalar value. Notice that if the initial velocity is set to zero (v (0) i = 0), both equations 4 and 7 become exactly the same for the first layer l = 0 and they become equivalent for the next layers since φ v just re-scales all the outputs of φ x from the previous layers with a scalar value. We proof the equivariance of this variant of the model in Appendix B.1. This variant is used in experiment 5.1 where we have to provide the initial velocity of the system, and predict a relative position change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Inferring the edges</head><p>Given a point cloud or a set of nodes, we may not always be provided with an adjacency matrix. In those cases we can assume a fully connected graph where all nodes exchange messages with each other, in other words, the neighborhood operator N (i) from equation 5 would include all other nodes of the graph except for i. This fully connected approach may not scale well to large graphs where we may want to locally limit the exchange of messages to avoid an overflow of information.</p><p>Similarly to <ref type="bibr" target="#b27">(Serviansky et al., 2020;</ref><ref type="bibr" target="#b12">Kipf et al., 2018)</ref> we present a simple solution to infer the relations/edges of the graph in our model. We can re-write the aggregation operation from our model (eq. 5) in the following way:</p><formula xml:id="formula_9">m i = j∈N (i) m ij = j =i e ij m ij<label>(8)</label></formula><p>Where e ij takes value 1 if there is an edge between nodes (i, j) and 0 otherwise. Notice this doesn't modify yet the original equation used in our model, it is just a change in notation. Now we can choose to approximate the relations e ij with the following function e ij = φ inf (m ij ), where φ inf : R nf → [0, 1] 1 resembles a linear layer followed by a sigmoid function that takes as input the current edge embedding and outputs a soft estimation of its edge value. This modification doesn't change the E(n) properties of the model since we are only operating on the messages m ij which are already</p><formula xml:id="formula_10">E(n) invariant. GNN Radial Field TFN Schnet EGNN Edge m ij = φe(h l i , h l j , a ij ) m ij = φ rf ( r l ij )r l ij m ij = k W lk r l ji h lk i m ij = φ cf ( r l ij )φs(h l j ) m ij = φe(h l i , h l j , r l ij 2 , a ij ) mij = r l ij φx(m ij ) Agg . m i = j∈N (i) m ij m i = j =i m ij m i = j =i m ij m i = j =i m ij m i = j∈N (i) m ij mi = j =i mij Node h l+1 i = φ h (h l i , m i ) x l+1 i = x l i + m i h l+1 i = w ll h l i + m i h l+1 i = φ h (h l i , m i ) h l+1 i = φ h h l i , m i x l+1 i = x l i + mi Non-equivariant E(n)-Equivariant SE(3)-Equivariant E(n)-Invariant E(n)-Equivariant</formula><p>Table <ref type="table">1</ref>. Comparison over different works from the literature under the message passing framework notation. We created this table with the aim to provide a clear and simple way to compare over these different methods. The names from left to right are: Graph Neural Networks <ref type="bibr" target="#b9">(Gilmer et al., 2017)</ref>; Radial Field from Equivariant Flows <ref type="bibr" target="#b15">(Köhler et al., 2019)</ref>; Tensor Field Networks <ref type="bibr" target="#b29">(Thomas et al., 2018)</ref>; Schnet <ref type="bibr" target="#b26">(Schütt et al., 2017b)</ref>; and our Equivariant Graph Neural Network. The difference between two points is written rij = (xi − xj).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Group equivariant neural networks have demonstrated their effectiveness in a wide variety of tasks <ref type="bibr" target="#b4">(Cohen &amp; Welling, 2016;</ref><ref type="bibr">2017;</ref><ref type="bibr" target="#b32">Weiler &amp; Cesa, 2019;</ref><ref type="bibr" target="#b23">Rezende et al., 2019;</ref><ref type="bibr" target="#b24">Romero &amp; Cordonnier, 2021)</ref>. Recently, various forms and methods to achieve E(3) or SE(3) equivariance have been proposed. <ref type="bibr" target="#b29">Thomas et al. (2018)</ref>; <ref type="bibr" target="#b8">Fuchs et al. (2020)</ref> utilize the spherical harmonics to compute a basis for the transformations, which allows transformations between higherorder representations. A downside to this method is that the spherical harmonics need to be recomputed which can be expensive. Currently, an extension of this method to arbitrary dimensions is unknown. <ref type="bibr" target="#b7">Finzi et al. (2020)</ref> parametrize transformations by mapping kernels on the Lie Algebra. For this method the neural network outputs are in certain situations stochastic, which may be undesirable. <ref type="bibr" target="#b15">Köhler et al. (2019)</ref>; <ref type="bibr" target="#b16">Köhler et al. (2020)</ref> propose an E(n) equivariant network to model 3D point clouds, but the method is only defined for positional data on the nodes without any feature dimensions.</p><p>Another related line of research concerns message passing algorithms on molecular data. <ref type="bibr" target="#b9">(Gilmer et al., 2017)</ref> presented a message passing setting (or Graph Neural Network) for quantum chemistry, this method is permutation equivariant but not translation or rotation equivariant. <ref type="bibr" target="#b17">(Kondor et al., 2018)</ref> extends the equivariance of GNNs such that each neuron transforms in a specific way under permutations, but this extension only affects its permutation group and not translations or rotations in a geometric space. Further works <ref type="bibr" target="#b26">(Schütt et al., 2017b;</ref><ref type="bibr">a)</ref> build E(n) invariant message passing networks by considering the relative distances between points. <ref type="bibr" target="#b0">(Anderson et al., 2019;</ref><ref type="bibr" target="#b19">Miller et al., 2020)</ref> additionally include SO(3) equivariance in its intermediate layers for modelling the behavior and properties of molecular data. Our method is also framed as a message passing framework but in contrast to these methods it also achieves E(n) equivariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relationship with existing methods</head><p>In Table <ref type="table">1</ref> the EGNN equations are detailed together with some of its closest methods from the literature under the message passing notation from <ref type="bibr" target="#b9">(Gilmer et al., 2017)</ref>. This table aims to provide a simple way to compare these different algorithms. It is structured in three main rows that describe i) the edge ii) aggregation and iii) node update operations.</p><p>The GNN algorithm is the same as the previously introduced in section 2.1. Our EGNN algorithm is also equivalent to the description in section 3 but notation has been modified to match the (edge, aggregation, node) format. In all equations r l ij = (x i − x j ) l . Notice that except the EGNN, all algorithms have the same aggregation operation and the main differences arise from the edge operation. The algorithm that we call "Radial Field" is the E(n) equivariant update from <ref type="bibr" target="#b15">(Köhler et al., 2019)</ref>. This method is E(n) equivariant, however its main limitation is that it only operates on x and it doesn't propagate node features h among nodes. In the method φ rf is modelled as an MLP. Tensor Field Networks (TFN) <ref type="bibr" target="#b29">(Thomas et al., 2018)</ref> instead propagate the node embeddings h but it uses spherical harmonics to compute its learnable weight kernel W k : R 3 → R (2 +1)×(2k+1) which preserves SE(3) equivariance but is expensive to compute an limited to the 3 dimensional space. The SE(3) Transformer <ref type="bibr" target="#b8">(Fuchs et al., 2020)</ref> (not included in this table), can be interpreted as an extension of TFN with attention. Schnet <ref type="bibr" target="#b26">(Schütt et al., 2017b)</ref> can be interpreted as an E(n) invariant Graph Neural Network where φ cf receives as input relative distances and outputs a continuous filter convolution that multiplies the neighbor embeddings h. Our EGNN differs from these other methods in terms that it performs two different updates in each of the table rows, one related to the embeddings h and another related to the coordinates x, these two variables exchange information in the edge operation. In summary the EGNN can retain the flexibility of GNNs while remaining E(n) equivariant as the Radial Field algorithm and without the need to compute expensive operations (i.e. spherical harmonics).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Modelling a dynamical system -N-body system</head><p>In a dynamical system a function defines the time dependence of a point or set of points in a geometrical space. Modelling these complex dynamics is crucial in a variety of applications such as control systems <ref type="bibr" target="#b3">(Chua et al., 2018)</ref>, model based dynamics in reinforcement learning <ref type="bibr" target="#b20">(Nagabandi et al., 2018)</ref>, and physical systems simulations <ref type="bibr" target="#b11">(Grzeszczuk et al., 1998;</ref><ref type="bibr" target="#b31">Watters et al., 2017)</ref>. In this experiment we forecast the positions for a set of particles which are modelled by simple interaction rules, yet can exhibit complex dynamics.</p><p>Similarly to <ref type="bibr" target="#b8">(Fuchs et al., 2020)</ref>, we extended the Charged Particles N-body experiment from <ref type="bibr" target="#b12">(Kipf et al., 2018)</ref> to a 3 dimensional space. The system consists of 5 particles that carry a positive or negative charge and have a position and a velocity associated in 3-dimensional space. The system is controlled by physic rules: particles are attracted or repelled depending on their charges. This is an equivariant task since rotations and translations on the input set of particles result in the same rotation and translation throughout the entire trajectory.</p><p>Dataset: We sampled 3.000 trajectories for training, 2.000 for validation and 2.000 for testing. Each trajectory has a duration of 1.000 timesteps. For each trajectory we are provided with the initial particle positions p (0) = {p Implementation details: In this experiment we used the extension of our model that includes velocity from section 3.2. We input the position p (0) as the first layer coordinates x 0 of our model and the velocity v (0) as the initial velocity in Equation <ref type="formula">7</ref>, the norms v (0) i are also provided as features to h 0 i . The charges are input as edge attributes a ij = c i c j . The model outputs the last layer coordinates x L as the estimated positions. We compare our method to its non equivariant Graph Neural Network (GNN) cousin, and the equivariant methods: Radial Field <ref type="bibr" target="#b15">(Köhler et al., 2019)</ref>, Tensor Field Networks and the SE(3) Transformer. All algorithms are composed of 4 layers and have been trained under the same conditions, batch size 100, 10.000 epochs, Adam optimizer, the learning rate was tuned independently for each model. We used 64 features for the hidden layers in the Radial Field, the GNN and our EGNN. As non-linearity we used the Swish activation function <ref type="bibr" target="#b21">(Ramachandran et al., 2017)</ref>. For TFN and the SE(3) Transformer we swept over different number of vector types and features and chose those that provided the best performance. Further implementation de-tails are provided in Appendix C.1. A Linear model that simply considers the motion equation p (t) = p (0) + v (0) t is also included as a baseline. Since some methods may be more expensive than others we also provide the forward pass time in seconds for each of the models for a batch of 100 samples in a GTX 1080 Ti GPU. Results As shown in Table <ref type="table" target="#tab_0">2</ref> our model significantly outperforms the other equivariant and non-equivariant alternatives while still being efficient in terms of running time. It reduces the error with respect to the second best performing method by a 33%. In addition it doesn't require the computation of spherical harmonics which makes it more time efficient than Tensor Field Networks and the SE(3) Transformer. Analysis for different number of training samples: We want to analyze the performance of our EGNN in the small and large data regime. In the following, we report on a similar experiment as above, but instead of using 3.000 training samples we generated a new training partition of 50.000 samples and we sweep over different amounts of data from 100 to 50.000 samples. We compare the performances of our EGNN vs its non-equivariant GNN counterpart and the Radial Field algorithm. Results are presented in Figure <ref type="figure" target="#fig_2">2</ref>. Our method outperforms both Radial Field and GNNs in the small and large data regimes. This shows the EGNN is more data efficient than GNNs since it doesn't require to generalize over rotations and translations of the data while it ensembles the flexibility of GNNs in the larger data regime. Due to its high model bias, the Radial Field algorithm performs well when data is scarce but it is unable to learn the subtleties of the dataset as we increase the training size. In summary, our EGNN benefits from both the high bias of E(n) methods and the flexibility of GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Graph Autoencoder</head><p>A Graph Autoencoder can learn unsupervised representations of graphs in a continuous latent space <ref type="bibr" target="#b14">(Kipf &amp; Welling, 2016b;</ref><ref type="bibr" target="#b28">Simonovsky &amp; Komodakis, 2018)</ref>. In this experiment section we use our EGNN to build an Equivariant Graph Autoencoder. We will explain how Graph Autoencoders can benefit from equivariance and we will show how our method outperforms standard GNN autoencoders in the provided datasets. This problem is particularly interesting since the embedding space can be scaled to larger dimensions and is not limited to a 3 dimensional Euclidean space.</p><p>Similarly to the work of <ref type="bibr" target="#b14">(Kipf &amp; Welling, 2016b</ref>) further extended by section 3.3 in <ref type="bibr" target="#b18">(Liu et al., 2019)</ref>, our graph auto-encoder z = q(G) embeds a graph G into a set of latent nodes z = {z 1 , . . . z M } ∈ R M ×n , where M is the number of nodes and n the embedding size per node. Notice this reduces the memory complexity to store the graphs from O(M 2 ) to O(M ) with respect to the number of nodes. This differs from <ref type="bibr" target="#b28">(Simonovsky &amp; Komodakis, 2018)</ref> which embeds the graph in a single vector z ∈ R K , which causes the reconstruction to be computationally very expensive since the nodes of the decoded graph have to be matched again to the ground truth.</p><p>More specifically, we will compare our Equivariant Graph Auto-Encoder in the task presented in <ref type="bibr" target="#b18">(Liu et al., 2019)</ref> where a graph G = (V, E) with node features H ∈ R M ×nf and adjacency matrix A ∈ {0, 1} M ×M is embedded into a latent space z = q(H, A) ∈ R M ×n . Following <ref type="bibr" target="#b14">(Kipf &amp; Welling, 2016b;</ref><ref type="bibr" target="#b18">Liu et al., 2019)</ref>, we are only interested in reconstructing the adjacency matrix A since the datasets we will work with do not contain node features. The decoder g(•) proposed by <ref type="bibr" target="#b18">(Liu et al., 2019)</ref> takes as input the embedding space z and outputs the reconstructed adjacency matrix Â = g(z), this decoder function is defined as follows:</p><formula xml:id="formula_11">Âij = g e (z i , z j ) = 1 1 + exp(w z i − z j 2 + b)<label>(9)</label></formula><p>Where w and b are its only learnable parameters and g e (•) is the decoder edge function applied to every pair of node embeddings. It reflects that edge probabilities will depend on the relative distances among node embeddings. The training loss is defined as the binary cross entropy between the estimated and the ground truth edges</p><formula xml:id="formula_12">L = ij BCE( Âij , A ij ).</formula><p>The symmetry problem: The above stated autoencoder may seem straightforward to implement at first sight but in some cases there is a strong limitation regarding the symmetry of the graph. Graph Neural Networks are convolutions on the edges and nodes of a graph, i.e. the same function is applied to all edges and to all nodes. In some graphs (e.g. those defined only by its adjacency matrix) we may not have input features in the nodes, such that the difference among nodes relies only on their edges or neighborhood topology. Therefore, if the neighborhood of two nodes is exactly the same, their encoded embeddings will be the same too. A clear example of this is a cycle graph (an example of a 4 nodes cycle graph is provided in Figure <ref type="figure" target="#fig_3">3</ref>). When running a Graph Neural Network encoder on a node featureless cycle graph, we will obtain the exact same embedding for each of the nodes, which makes it impossible to reconstruct the edges of the original graph from the node embeddings. The cycle graph is a severe example where all nodes have the exact same neighborhood topology but these symmetries can be present in different ways for other graphs with different edge distributions or even when including node features if these are not unique. An ad-hoc method to break the symmetry of the graph introduced by <ref type="bibr" target="#b18">(Liu et al., 2019)</ref>. This method introduces noise sampled from a Gaussian distribution into the input node features of the graph h 0 i ∼ N (0, σI). This noise allows different representation for all node embeddings and as a result the graph can be decoded again, but it comes with a drawback, the network has to generalize over the new introduced noise distribution. Our Equivariant Graph Autoencoder will remain translation and rotation equivariant to this sampled noise which we find makes the generalization much easier. In our case we will simply input this noise as the input coordinates x 0 ∼ N (0, σI) ∈ R M ×n of our EGNN which will output an equivariant transformation of them x L , this output will be used as the embedding of the graph (i.e. z = x L ) which is the input to the decoder from Equation <ref type="formula" target="#formula_11">9</ref>.</p><p>Dataset: We generated community-small graphs <ref type="bibr" target="#b33">(You et al., 2018;</ref><ref type="bibr" target="#b18">Liu et al., 2019)</ref>   The GNN is not able to successfully auto-encode sparse graphs (small pe values) for the Erdos&amp;Renyi dataset even when training and testing on the same small subset. <ref type="bibr" target="#b33">(You et al., 2018)</ref>. These graphs contain 12 ≤ M ≤ 20 nodes. We also generated a second dataset using the Er-dos&amp;Renyi generative model <ref type="bibr" target="#b1">(Bollobás &amp; Béla, 2001)</ref> sampling random graphs with an initial number of 7 ≤ M ≤ 16 nodes and edge probability p e = 0.25. We sampled 5.000 graphs for training, 500 for validation and 500 for test for both datasets. Each graph is defined as and adjacency matrix A ∈ {0, 1} M ×M .</p><p>Implementation details: Our Equivariant Graph Auto-Encoder is composed of an EGNN encoder followed by the decoder from Equation <ref type="formula" target="#formula_11">9</ref>. The graph edges A ij are input as edge attributes a ij in Equation <ref type="formula" target="#formula_2">3</ref>. The noise used to break the symmetry is input as the coordinates x 0 ∼ N (0, σI) ∈ R M ×n in the first layer and h 0 is initialized as ones since we are working with featureless graphs. As mentioned before, the encoder outputs an equivariant transformation on the coordinates which is the graph embedding and input to the decoder z = x L ∈ R M ×n . We use n = 8 dimensions for the embedding space. We compare the EGNN to its GNN cousin, we also compare to Noise-GNN which is an adaptation of our GNN to match the setting from <ref type="bibr" target="#b18">(Liu et al., 2019)</ref>, and we also include the Radial Field algorithm as an additional baseline. All four models have 4 layers, 64 features for the hidden layers, the Swish activation function as a non-linearity and they were all trained for 100 epochs using the Adam optimizer and learning rate 1e −4 . More details are provided in Appendix C.2. Since the number of nodes is larger than the number of layers, the receptive field of a GNN may not comprise the whole graph which can make the comparison unfair with our EGNN. To avoid this limitation, all models exchange messages among all nodes and the edge information is provided as edge attributes a ij = A ij in all of them.</p><p>Results: In the table from Figure <ref type="figure" target="#fig_4">5</ref> we report the Binary Cross Entropy loss between the estimated and ground truth edges, the % Error which is defined as the percentage of wrong predicted edges with respect to the total amount of potential edges, and the F1 score of the edge classification, all numbers refer to the test partition. We also include a "Baseline" that predicts all edges as missing Âij = 0. The standard GNN seems to suffer from the symmetry problem and provides the worst performance. When introducing noise (Noise-GNN), both the loss and the error decrease showing that it is actually useful to add noise to the input nodes. Finally, our EGNN remains E(n) equivariant to this noise distribution and provides the best reconstruction with a 0.11% error in the Erdos&amp;Renyi dataset and close to optimal 0.05% in the Community Small dataset.</p><p>Overfitting the training set: We explained the symmetry problem and we showed the EGNN outperforms other methods in the given datasets. Although we observed that adding noise to the GNN improves the results, it is difficult to exactly measure the impact of the symmetry limitation in these results independent from other factors such as generalization from the training to the test set. In this section we conduct an experiment where we train the different models in a subset of 100 Erdos&amp;Renyi graphs and embedding size n = 16 with the aim to overfit the data. We evaluate the methods on the training data. In this experiment the GNN is unable to fit the training data properly while the EGNN can achieve perfect reconstruction and Noise-GNN close to perfect. We sweep over different p e sparsity values from 0.1 to 0.9 since the symmetry limitation is more present in very sparse or very dense graphs. We report the F1 scores of this experiment in the right plot of Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>In this experiment we showed that E(n) equivariance improves performance when embedding graphs in a continuous space as a set of nodes in dimension n. Even though this is a simple reconstruction task, we think this can be a useful step towards generating graphs or molecules where often graphs (i.e. edges) are decoded as pairwise distances or similarities between nodes e.g. <ref type="bibr" target="#b14">(Kipf &amp; Welling, 2016b;</ref><ref type="bibr" target="#b18">Liu et al., 2019;</ref><ref type="bibr" target="#b10">Grover et al., 2019)</ref>, and these metrics (e.g. eq. 9) are E(n) invariant. Additionally this experiment also showed that our method can successfully perform in a E(n) equivariant task for higher dimensional spaces where n &gt; 3.  </p><formula xml:id="formula_13">Task α ∆ε ε HOMO ε LUMO µ C ν G H R 2 U U 0 ZPVE</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Molecular data -QM9</head><p>The QM9 dataset <ref type="bibr" target="#b22">(Ramakrishnan et al., 2014)</ref> has become a standard in machine learning as a chemical property prediction task. The QM9 dataset consists of small molecules represented as a set of atoms (up to 29 atoms per molecule), each atom having a 3D position associated and a five dimensional one-hot node embedding that describe the atom type (H, C, N, O, F). The dataset labels are a variety of chemical properties for each of the molecules which are estimated through regression. These properties are invariant to translations, rotations and reflections on the atom positions.</p><p>Therefore those models that are E(3) invariant are highly suitable for this task.</p><p>We imported the dataset partitions from <ref type="bibr" target="#b0">(Anderson et al., 2019)</ref>, 100K molecules for training, 18K for validation and 13K for testing. A variety of 12 chemical properties were estimated per molecule. We optimized and report the Mean Absolute Error between predictions and ground truth.</p><p>Implementation details: Our EGNN receives as input the 3D coordinate locations of each atom which are provided as x 0 i in Equation 3 and an embedding of the atom properties which is provided as input node features h 0 i . Since this is an invariant task and also x 0 positions are static, there is no need to update the particle's position x by running Equation <ref type="formula" target="#formula_3">4</ref>as we did in previous experiments. Consequently, we tried both manners and we didn't notice any improvement by updating x. When not updating the particle's position (i.e. skipping Equation <ref type="formula" target="#formula_3">4</ref>), our model becomes E(3) invariant, which is analogous to a standard GNN where all relative squared norms between pairs of points x i − x j 2 are inputted to the edge operation (eq. 3). Additionally, since we are not provided with an adjacency matrix and molecules can scale up to 29 nodes, we use the extension of our model from Section 3.3 that infers a soft estimation of the edges. Our EGNN network consists of 7 layers, 128 features per hidden layer and the Swish activation function as a non-linearity. A sum-pooling operation preceded and followed by two layers MLPs maps all the node embed-dings h L from the output of the EGNN to the estimated property value. Further implementation details are reported in Appendix. C. We compare to NMP <ref type="bibr" target="#b9">(Gilmer et al., 2017)</ref>, Schnet <ref type="bibr" target="#b26">(Schütt et al., 2017b)</ref>, Cormorant <ref type="bibr" target="#b0">(Anderson et al., 2019)</ref>, L1Net <ref type="bibr" target="#b19">(Miller et al., 2020)</ref>, LieConv <ref type="bibr" target="#b7">(Finzi et al., 2020)</ref>, TFN <ref type="bibr" target="#b29">(Thomas et al., 2018)</ref> and SE(3)-Tr. <ref type="bibr" target="#b8">(Fuchs et al., 2020)</ref>.</p><p>Results are presented in Table <ref type="table" target="#tab_3">3</ref>. Our method reports state of the art in 9 out of 12 property predictions, and it is the second best performing method for the remaining 3 properties. Perhaps, surprisingly, we outperform other equivariant networks that consider higher order representations while in this task, we are only using type-0 representations (i.e. relative distances) to define the geometry of the molecules. In Appendix D we prove that when only positional information is given (i.e. no velocity or higher order type features), then the geometry is completely defined by the norms in-between points up to E(n)-transformations, in other words, if two collections of points separated by E(n) transformations are considered to be identical, then the relative norms between points is a unique identifier of the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Equivariant graph neural networks are receiving increasing interest from the natural and medical sciences as they represent a new tool for analyzing molecules and their properties. In this work, we presented a new E(n) equivariant deep architecture for graphs that is computationally efficient, easy to implement, and significantly improves over the current state-of-the-art on a wide range of tasks. We believe these properties make it ideally suited to make a direct impact on topics such as drug discovery, protein folding and the design of new materials, as well as applications in 3D computer vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Equivariance Proof</head><p>In this section we prove that our model is translation equivariant on x for any translation vector g ∈ R n and it is rotation and reflection equivariant on x for any orthogonal matrix Q ∈ R n×n . More formally, we will prove the model satisfies:</p><formula xml:id="formula_14">Qx l+1 + g, h l+1 = EGCL(Qx l + g, h l )</formula><p>We will analyze how a translation and rotation of the input coordinates propagates through our model. We start assuming h 0 is invariant to E(n) transformations on x, in other words, we do not encode any information about the absolute position or orientation of x 0 into h 0 . Then, the output m ij of Equation 3 will be invariant too since the distance between two particles is invariant to translations</p><formula xml:id="formula_15">x l i + g − [x l j + g] 2 = x l i − x l j 2</formula><p>, and it is invariant to rotations and reflections</p><formula xml:id="formula_16">Qx l i − Qx l j 2 = (x l i − x l j ) Q Q(x l i − x l j ) = (x l i − x l j ) I(x l i − x l j ) = x l i − x l j</formula><p>2 such that the edge operation becomes invariant:</p><formula xml:id="formula_17">m i,j = φ e h l i , h l j , Qx l i + g − [Qx l j + g] 2 , a ij = φ e h l i , h l j , x l i − x l j 2 , a ij</formula><p>The second equation of our model (eq. 4) that updates the coordinates x is E(n) equivariant. Following, we prove its equivariance by showing that an E(n) transformation of the input leads to the same transformation of the output. Notice m ij is already invariant as proven above. We want to show:</p><formula xml:id="formula_18">Qx l+1 i + g = Qx l i + g + j =i Qx l i + g − [Qx l j + g] φ x (m i,j )</formula><p>Derivation.</p><formula xml:id="formula_19">Qx l i + g + j =i Qx l i + g − Qx l j − g φ x (m i,j ) = Qx l i + g + Q j =i x l i − x l j φ x (m i,j ) = Q   x l i + j =i x l i − x l j φ x (m i,j )   + g = Qx l+1 i + g</formula><p>Therefore, we have proven that rotating and translating x l results in the same rotation and translation on x l+1 at the output of Equation <ref type="formula" target="#formula_3">4</ref>.</p><p>Furthermore equations 5 and 6 only depend on m ij and h l which as saw at the beginning of this proof, are E(n) invariant, therefore the output of Equation 6 h l+1 will be invariant too. Thus concluding that a transformation Qx l + g on x l will result in the same transformation on x l+1 while h l+1 will remain invariant to it such that Qx l+1 + g, h l+1 = EGCL(Qx l + g, h l ) is satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Re-formulation for velocity type inputs</head><p>In this section we write down the EGNN transformation layer h l+1 , x l+1 , v l+1 = EGCL[h l , x l , v l , E] that can take in velocity input and output channels. We also prove it remains E(n) equivariant.</p><formula xml:id="formula_20">m ij = φ e h l i , h l j , x l i − x l j 2 , a ij v l+1 i = φ v h l i v l i + j =i x l i − x l j φ x (m ij ) x l+1 i = x l i + v l+1 i m i = j∈N (i) m ij h l+1 i = φ h h l i , m i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Equivariance proof for velocity type inputs</head><p>In this subsection we prove that the velocity types input formulation of our model is also E(n) equivariant on x. More formally, for any translation vector g ∈ R n and for any orthogonal matrix Q ∈ R n×n , the model should satisfy:</p><formula xml:id="formula_21">h l+1 , Qx l+1 + g, Qv l+1 = EGCL[h l , Qx l + g, Qv l , E]</formula><p>In Appendix A we already proved the equivariance of our EGNN (Section 3) when not including vector type inputs. In its velocity type inputs variant we only replaced its coordinate updates (eq. 4) by Equation <ref type="formula">7</ref>that includes velocity. Since this is the only modification we will only prove that Equation 7 re-written below is equivariant.</p><formula xml:id="formula_22">v l+1 i = φ v h l i v l i + j =i x l i − x l j φ x (m ij ) x l+1 i = x l i + v l+1 i</formula><p>First, we prove the first line preserves equivariance, that is we want to show:</p><formula xml:id="formula_23">Qv i = φ v h l i Qv l i + j =i Qx l i + g − [Qx l j + g] φ x (m ij )</formula><p>Derivation.</p><formula xml:id="formula_24">φ v h l i Qv l i + j =i Qx l i + g − [Qx l j + g] φ x (m ij ) = Qφ v h l i v l i + Q j =i x l i − x l j φ x (m ij ) (10) = Q   φ v h l i v l i + j =i x l i − x l j φ x (m ij )   (11) = Qv l+1 i (12)</formula><p>Finally, it is straightforward to show the second equation is also equivariant, that is we want to show Qx l+1 i + g = Qx l i + g + Qv l+1 i Derivation.</p><formula xml:id="formula_25">Qx l i + g + Qv l+1 i = Q x l i + v l+1 i + g = Qx l+1 i + g</formula><p>Concluding we showed that an E(n) transformation on the input set of points results in the same transformation on the output set of points such that h l+1 , Qx l+1 + g, Qv l+1 = EGCL[h l , Qx l + g, Qv l , E] is satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation details</head><p>In this Appendix section we describe the implementation details of the experiments. First, we describe those parts of our model that are the same across all experiments. Our EGNN model from Section 3 contains the following three main learnable functions.</p><p>• The edge function φ e (eq. 3) is a two layers MLP with two Swish non-linearities:</p><formula xml:id="formula_26">Input − → {LinearLayer() − → Swish() − → LinearLayer() − → Swish() } − → Output.</formula><p>• The coordinate function φ x (eq. 4) consists of a two layers MLP with one non-linearity: Input − → {LinearLayer() − → Swish() − → LinearLayer() } − → Output</p><p>• The node function φ h (eq. 6) consists of a two layers MLP with one non-linearity and a residual connection:</p><formula xml:id="formula_27">Input − → {LinearLayer() − → Swish() − → LinearLayer() − → Addition(Input) } − → Output</formula><p>These functions are used in our EGNN across all experiments. Notice the GNN (eq. 2) also contains and edge operation and a node operation φ e and φ h respectively. We use the same functions described above for both the GNN and the EGNN such that comparisons are as fair as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Implementation details for Dynamical Systems Dataset</head><p>In the dynamical systems experiment we used a modification of the Charged Particle's N-body (N=5) system from <ref type="bibr" target="#b12">(Kipf et al., 2018)</ref>. Similarly to <ref type="bibr" target="#b8">(Fuchs et al., 2020)</ref>, we extended it from 2 to 3 dimensions customizing the original code from (https://github.com/ethanfetaya/NRI) and we removed the virtual boxes that bound the particle's positions. The sampled dataset consists of 3.000 training trajectories, 2.000 for validation and 2.000 for testing. Each trajectory has a duration of 1.000 timesteps. We actually generated trajectories of 5.000 time steps and sliced them from timestep 3.000 to timestep 4.000 such that the initial conditions are more realistic than the Gaussian Noise initialization from which they are initialized.</p><p>In our second experiment, we sweep from 100 to 50.000 training samples, for this we just created a new training partition following the same procedure as before but now generating 50.000 trajectories instead. The validation and test partition remain the same from last experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>All models are composed of 4 layers, the details for each model are the following.</p><p>• EGNN: For the EGNN we use its variation that considers vector type inputs from Section 3.2. This variation adds the function φ v to the model which is composed of two linear layers with one non-linearity: Input − → {LinearLayer() − → Swish() − → LinearLayer() } − → Output. Functions φ e , φ x and φ h that define our EGNN are the same than for all experiments and are described at the beginning of this Appendix C.</p><p>• GNN: The GNN is also composed of 4 layers, its learnable functions edge operation φ e and node operation φ h from Equation 2 are exactly the same as φ e and φ h from our EGNN introduced in Appendix C. We chose the same functions for both models to ensure a fair comparison. In the GNN case, the initial position p 0 and velocity v 0 from the particles is passed through a linear layer and inputted into the GNN first layer h 0 . The particle's charges are inputted as edge attributes a ij = c i c j . The output of the GNN h L is passed through a two layers MLP that maps it to the estimated position.</p><p>• Radial Field: The Radial Field algorithm is described in the Related Work 4, its only parameters are contained in its edge operation φ rf () which in our case is a two layers MLP with two non linearities Input − → {LinearLayer() − → Swish() − → LinearLayer() − → Tanh } − → Output. Notice we introduced a Tanh at the end of the MLP which fixes some instability issues that were causing this model to diverge in the dynamical system experiment. We also augmented the Radial Field algorithm with the vector type inputs modifications introduced in Section 3.2. In addition to the norms between pairs of points, φ rf () also takes as input the particle charges c i c j .</p><p>• Tensor Field Network: We used the Pytorch implementation from https://github.com/FabianFuchsML/se3-transformerpublic. We swept over different hyper paramters, degree ∈ {2, 3, 4}, number of features ∈ {12, 24, 32, 64, 128}. We got the best performance in our dataset for degree 2 and number of features 32. We used the Relu activation layer instead of the Swish for this model since it provided better performance.</p><p>• SE(3) Transformers: For the SE(3)-Transformer we used code from https://github.com/FabianFuchsML/se3transformer-public. Notice this implementation has only been validated in the QM9 dataset but it is the only available implementation of this model. We swept over different hyperparamters degree ∈ {1, 2, 3, 4}, number of features ∈ 16, 32, 64 and divergence ∈ {1, 2}, along with the learning rate. We obtained the best performance for degree 3, number of features 64 and divergence 1. As in Tensor Field Networks we obtained better results by using the Relu activation layer instead of the Swish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other implementation details</head><p>In Table <ref type="table" target="#tab_0">2</ref> all models were trained for 10.000 epochs, batch size 100, Adam optimizer, the learning rate was fixed and independently chosen for each model. All models are 4 layers deep and the number of training samples was set to 3.000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Implementation details for Graph Autoneoders</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>In this experiment we worked with Community Small <ref type="bibr" target="#b33">(You et al., 2018)</ref> and Erdos&amp;Renyi <ref type="bibr" target="#b1">(Bollobás &amp; Béla, 2001</ref>) generated datasets.</p><p>• Community Small: We used the original code from <ref type="bibr" target="#b33">(You et al., 2018)</ref> (https://github.com/JiaxuanYou/graph-generation) to generate a Community Small dataset. We sampled 5.000 training graphs, 500 for validation and 500 for testing.</p><p>• Erdos&amp;Renyi is one of the most famous graph generative algorithms. We used the "gnp random graph(M , p)" function from (https://networkx.org/) that generates random graphs when povided with the number of nodes M and the edge probability p following the Erdos&amp;Renyi model. Again we generated 5.000 graphs for training, 500 for validation and 500 for testing. We set the edge probability (or sparsity value) to p = 0.25 and the number of nodes M ranging from 7 to 16 deterministically uniformly distributed. Notice that edges are generated stochastically with probability p, therefore, there is a chance that some nodes are left disconnected from the graph, "gnp random graph(M , p)" function discards these disconnected nodes such that even if we generate graphs setting parameters to 7 ≤ M ≤ 16 and p = 0.25 the generated graphs may have less number of nodes.</p><p>Finally, in the graph autoencoding experiment we also overfitted in a small partition of 100 samples (Figure <ref type="figure" target="#fig_4">5</ref>) for the Erdos&amp;Renyi graphs described above. We reported results for different p values ranging from 0.1 to 0.9. For each p value we generated a partition of 100 graphs with initial number of nodes between 7 ≤ M ≤ 16 using the Erdos&amp;Renyi generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>All models consist of 4 layers, 64 features for the hidden layers and the Swish activation function as a non linearity. The EGNN is defined as explained in Section 3 without any additional modules (i.e. no velocity type features or inferring edges).</p><p>The functions φ e , φ x and φ h are defined at the beginning of this Appendix C. The GNN (eq. 2) mimics the EGNN in terms that it uses the same φ h and φ e than the EGNN for its edge and node updates. The Noise-GNN is exactly the same as the GNN but inputting noise into the h 0 features. Finally the Radial Field was defined in the Related Related work Section 4 which edge's operation φ rf consists of a two layers MLP: Input − → { Linear() − → Swish() − → Linear() } − → Output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other implementation details</head><p>All experiments have been trained with learning rate 1e −4 , batch size 1, Adam optimizer, 100 training epochs for the 5.000 samples sized datasets performing early stopping for the minimum Binary Cross Entropy loss in the validation partition.</p><p>The overfitting experiments were trained for 10.000 epochs on the 100 samples subsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Implementation details for QM9</head><p>For QM9 <ref type="bibr" target="#b22">(Ramakrishnan et al., 2014)</ref> we used the dataset partitions from <ref type="bibr" target="#b0">(Anderson et al., 2019)</ref>. We imported the dataloader from his code repository (https://github.com/risilab/cormorant) which includes his data-preprocessing. Additionally all properties have been normalized by substracting the mean and dividing by the Mean Absolute Deviation.</p><p>Our EGNN consists of 7 layers. Functions φ e , φ x and φ h are defined at the beginning of this Appendix C. Additionally, we use the module φ inf presented in Section 3.3 that infers the edges . This function φ inf is defined as a linear layer followed by a sigmoid: Input − → {Linear() − → sigmoid()} − → Output. Finally, the output of our EGNN h L is forwarded through a two layers MLP that acts node-wise, a sum pooling operation and another two layers MLP that maps the averaged embedding to the predicted property value, more formally: h L − → {Linear() − → Swish() − → Linear() − → Sum-Pooling() − → Linear() − → Swish() − → Linear} − → Property. The number of hidden features for all model hidden layers is 128.</p><p>We trained each property individually for a total of 1.000 epochs, we used Adam optimizer, batch size 96, weight decay 1e −16 , and cosine decay for the learning rate starting at at a lr=5e −4 except for the Homo, Lumo and Gap properties where its initial value was set to 1e −3 .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Example of rotation equivariance on a graph with a graph neural network φ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>R 5×3 , their initial velocities v (0) = {v (0) 1 , . . . v (0) 5 } ∈ R 5×3 and their respective charges c = {c 1 , . . . c 5 } ∈ {−1, 1} 5 . The task is to estimate the positions of the five particles after 1.000 timesteps. We optimize the averaged Mean Squared Error of the estimated position with the ground truth one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Mean Squared Error in the N-body experiment for the Radial Field, GNN and EGNN methods when sweeping over different amounts of training data.</figDesc><graphic url="image-1.png" coords="5,330.84,389.46,187.20,139.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Visual representation of a Graph Autoencoder for a 4 nodes cycle graph. The bottom row illustrates that adding noise at the input graph breaks the symmetry of the embedding allowing the reconstruction of the adjacency matrix.</figDesc><graphic url="image-2.png" coords="6,342.54,344.58,163.80,80.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. In the Table at the left we report the Binary Cross Entropy, % Error and F1 scores for the test partition on the Graph Autoencoding experiment in the Community Small and Erdos&amp;Renyi datasets. In the Figure at the right, we report the F1 score when overfitting a training partition of 100 samples in the Erdos&amp;Renyi dataset for different values of sparsity pe. The GNN is not able to successfully auto-encode sparse graphs (small pe values) for the Erdos&amp;Renyi dataset even when training and testing on the same small subset.</figDesc><graphic url="image-3.png" coords="7,344.34,67.06,192.45,114.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Mean Squared Error for the future position estimation in the N-body system experiment, and forward time in seconds for a batch size of 100 samples running in a GTX 1080Ti GPU.</figDesc><table><row><cell></cell><cell>MSE</cell><cell>Forward time (s)</cell></row><row><cell>Linear</cell><cell>0.0819</cell><cell>.0001</cell></row><row><cell>SE(3) Transformer</cell><cell>0.0244</cell><cell>.1346</cell></row><row><cell>Tensor Field Network</cell><cell>0.0155</cell><cell>.0343</cell></row><row><cell cols="2">Graph Neural Network 0.0107</cell><cell>.0032</cell></row><row><cell>Radial Field</cell><cell>0.0106</cell><cell>.0039</cell></row><row><cell>EGNN</cell><cell>0.0071</cell><cell>.0062</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>by running the original code from</figDesc><table><row><cell></cell><cell cols="3">Community Small</cell><cell></cell><cell>Erdos&amp;Renyi</cell><cell></cell></row><row><cell>Encoder</cell><cell cols="2">BCE % Error</cell><cell>F1</cell><cell cols="2">BCE % Error</cell><cell>F1</cell></row><row><cell>Baseline</cell><cell>-</cell><cell>31.79</cell><cell>.0000</cell><cell>-</cell><cell>25.13</cell><cell>0.000</cell></row><row><cell>GNN</cell><cell>6.75</cell><cell>1.29</cell><cell cols="2">0.980 14.15</cell><cell>4.62</cell><cell>0.907</cell></row><row><cell cols="2">Noise-GNN 3.32</cell><cell>0.44</cell><cell cols="2">0.993 4.56</cell><cell>1.25</cell><cell>0.975</cell></row><row><cell cols="2">Radial Field 9.69</cell><cell>1.23</cell><cell cols="2">0.981 6.28</cell><cell>1.51</cell><cell>0.970</cell></row><row><cell>EGNN</cell><cell>2.18</cell><cell>0.05</cell><cell cols="2">0.999 1.65</cell><cell>0.11</cell><cell>0.998</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Mean Absolute Error for the molecular property prediction benchmark in QM9 dataset.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Sometimes invariant features are all you need.</head><p>Perhaps surprisingly we find our EGNNs outperform other equivariant networks that consider higher-order representations. In the typical story of equivariance, forcing features to be invariant destroys information and impedes performance. However, in this section we proof that when only positional information is given (i.e. no velocity-type features) then the geometry is completely defined by the invariant distance norms in-between points, without loss of relevant information. As a consequence, it is not necessary to consider higher-order representation types of the relative distances, not even the relative difference as vector. To be precise, note that these invariant features still need to be permutation equivariant, they are only E(n) invariant.</p><p>To be specific, we want to show that for a collection of points {x i } M i=1 the norm of in-between distances 2 (x i , x j ) are a unique identifier of the geometry, where collections separated by an E(n) transformations are considered to be identical. We want to show invariance of the norms under E(n) transformations and uniqueness: two point collections are identical (up to E(n) transform) when they have the same distance norms.</p><p>Invariance. Let {x i } be a collection of M points where x i ∈ R n and the 2 distances are 2 (x i , x j ). We want to show that all 2 (x i , x j ) are unaffected by E(n) transformations.</p><p>Proof. Consider an arbitrary E(n) transformation R n → R n : x → Qx + t where Q is orthogonal and t ∈ R n is a translation. Then for all i, j:</p><p>This proves that the 2 distances are invariant under E(n) transforms.</p><p>Uniqueness. Let {x i } and {y i } be two collection of M points each where all in-between distance norms are identical, meaning 2 (x i , x j ) = 2 (y i , y j ). We want to show that x i = Qy i + t for some orthogonal Q and translation t, for all i.</p><p>Proof. Subtract x 0 from all {x i } and y 0 from all {y i }, so xi = x i − x 0 and ỹi = y i − y 0 . As proven above, since translation is an E(n) transformation the distance norms are unaffected and:</p><p>So without loss of generality, we may assume that x 0 = y 0 = 0. As a direct consequence ||x i || 2 = ||y i || 2 . Now writing out the square:</p><p>And since ||x i || 2 = ||y i || 2 , it follows that x T i x j = y T i y j or equivalently written as dot product x i , x j = y i , y j . Notice that this already shows that angles between pairs of points are the same.</p><p>At this moment, it might already be intuïtive that the collections of points are indeed identical. To finalize the proof formally we will construct a linear map A for which we will show that (1) it maps every x i to y i and (2) that it is orthogonal. First note that from the angle equality it follows immediately that for every linear combination:</p><p>Let V x be the linear span of {x i } (so V x is the linear subspace of all linear combinations of {x i }). Let {x ij } d j=1 be a basis of V x , where d ≤ n. Recall that one can define a linear map by choosing a basis, and then define for each basis vector where it maps to. Define a linear map A from V x to V y by the transformation from the basis x ij to y ij for j = 1, ..., d. Now pick any point x i and write it in its basis x i = j c j x ij ∈ V x . We want to show Ax i = y i or alternatively</p><p>Thus showing that Ax i = y i for all i = 1, . . . , M , proving (1). Finally we want to show that A is orthogonal, when restricted to V x . This follows since:</p><p>for the basis elements x i1 , ..., x i d . This implies that A is orthogonal (at least when restricted to V x ). Finally A can be extended via an orthogonal complement of V x to the whole space. This concludes the proof for (2) and shows that A is indeed orthogonal.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Hy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><surname>Cormorant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04015</idno>
		<title level="m">Covariant molecular neural networks</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Random graphs. Number 73</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bollobás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Béla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning in a handful of trials using probabilistic dynamics models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Calandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12114</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning, ICML</title>
				<editor>
			<persName><forename type="first">M</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting>the 33nd International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Steerable cnns</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations, ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12880</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">)-transformers: 3d roto-translation equivariant attention networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><surname>Se</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01212</idno>
		<title level="m">Neural message passing for quantum chemistry</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graphite: Iterative generative modeling of graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2434" to="2444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neuroanimator: Fast neural network emulation and control of physics-based models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual conference on Computer graphics and interactive techniques</title>
				<meeting>the 25th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="9" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04687</idno>
		<title level="m">Neural relational inference for interacting systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Equivariant flows: sampling configurations for multi-body systems with symmetric energies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Noé</surname></persName>
		</author>
		<idno>CoRR, abs/1910.00753</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Equivariant flows: exact likelihood generative learning for symmetric densities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Noé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02425</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Covariant compositional networks for learning graphs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02144</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph normalizing flows</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="13578" to="13588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Relevance of rotationally equivariant convolutions for predicting molecular properties</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Noé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.08461</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nagabandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Fearing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7559" to="7566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05941</idno>
		<title level="m">Searching for activation functions</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Lilienfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Equivariant hamiltonian flows</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Racanière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Toth</surname></persName>
		</author>
		<idno>CoRR, abs/1909.13739</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Group equivariant stand-alone self-attention for vision</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Cordonnier</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=JkfYjnOEo6M" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Quantum-chemical insights from deep tensor neural networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Arbabzadah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017">2017a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Schnet: A continuousfilter convolutional neural network for modeling quantum interactions</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08566</idno>
		<imprint>
			<date type="published" when="2017">2017b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning graphs from sets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Serviansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Segol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName><surname>Set2graph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Graphvae: Towards generation of small graphs using variational autoencoders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="412" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08219</idno>
		<title level="m">Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1588" to="1597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Visual interaction networks: Learning a physics simulator from video</title>
		<author>
			<persName><forename type="first">N</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4539" to="4547" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">General e(2)-equivariant steerable cnns</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cesa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><surname>Graphrnn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08773</idno>
		<title level="m">Generating realistic graphs with deep autoregressive models</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
