<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Text Is All You Need: Learning Language Representations for Sequential Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-05-23">23 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
							<email>j9li@eng.ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Wang</surname></persName>
							<email>mingww@amazon.com</email>
							<affiliation key="aff1">
								<address>
									<settlement>Amazon</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Title Wireless Computer Mouse Compatible with MacBook Brand Amazon Basics Color Black</orgName>
								<address>
									<addrLine>315 235 822 Title 2020 MacBook Air Laptop M1 Chip Brand Apple</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><surname>Li</surname></persName>
							<email>jincli@amazon.com</email>
							<affiliation key="aff2">
								<address>
									<settlement>Amazon</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinmiao</forename><surname>Fu</surname></persName>
							<email>jinnmiaof@amazon.com</email>
							<affiliation key="aff3">
								<address>
									<settlement>Amazon</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Title Wireless Computer Mouse Compatible with MacBook Brand Amazon Basics Color Black</orgName>
								<address>
									<addrLine>315 235 822 Title 2020 MacBook Air Laptop M1 Chip Brand Apple</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Shen</surname></persName>
							<email>xinshen@amazon.com</email>
							<affiliation key="aff4">
								<address>
									<settlement>Amazon</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Title Wireless Computer Mouse Compatible with MacBook Brand Amazon Basics Color Black</orgName>
								<address>
									<addrLine>315 235 822 Title 2020 MacBook Air Laptop M1 Chip Brand Apple</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
							<email>jshang@eng.ucsd.edu</email>
							<affiliation key="aff5">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Title Wireless Computer Mouse Compatible with MacBook Brand Amazon Basics Color Black</orgName>
								<address>
									<addrLine>315 235 822 Title 2020 MacBook Air Laptop M1 Chip Brand Apple</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
							<email>jmcauley@eng.ucsd.edu</email>
							<affiliation key="aff6">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Title Wireless Computer Mouse Compatible with MacBook Brand Amazon Basics Color Black</orgName>
								<address>
									<addrLine>315 235 822 Title 2020 MacBook Air Laptop M1 Chip Brand Apple</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><surname>Li</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Conference acronym &apos;XX</orgName>
								<address>
									<postCode>03-05, 2018</postCode>
									<settlement>June, Woodstock</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><surname>Li</surname></persName>
							<affiliation key="aff8">
								<orgName type="department">Title Wireless Computer Mouse Compatible with MacBook Brand Amazon Basics Color Black</orgName>
								<address>
									<addrLine>315 235 822 Title 2020 MacBook Air Laptop M1 Chip Brand Apple</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Text Is All You Need: Learning Language Representations for Sequential Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-23">23 May 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2305.13731v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>sequential recommendation, language models</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sequential recommendation aims to model dynamic user behavior from historical interactions. Existing methods rely on either explicit item IDs or general textual features for sequence modeling to understand user preferences. While promising, these approaches still struggle to model cold-start items or transfer knowledge to new datasets. In this paper, we propose to model user preferences and item features as language representations that can be generalized to new items and datasets. To this end, we present a novel framework, named Recformer, which effectively learns language representations for sequential recommendation. Specifically, we propose to formulate an item as a "sentence" (word sequence) by flattening item key-value attributes described by text so that an item sequence for a user becomes a sequence of sentences. For recommendation, Recformer is trained to understand the "sentence" sequence and retrieve the next "sentence". To encode item sequences, we design a bi-directional Transformer similar to the model Longformer but with different embedding layers for sequential recommendation. For effective representation learning, we propose novel pretraining and finetuning methods which combine language understanding and recommendation tasks. Therefore, Recformer can effectively recommend the next item based on language representations. Extensive experiments conducted on six datasets demonstrate the effectiveness of Recformer for sequential recommendation, especially in low-resource and cold-start settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Information systems ? Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Sequential recommender systems model historical user interactions as temporally-ordered sequences to recommend potential items that users are interested in. Sequential recommenders <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> can capture both short-term and long-term preferences of users and hence are widely used in different recommendation scenarios.</p><p>Various methods have been proposed to improve the performance of sequential recommendation, including Markov Chains <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref>, RNN/CNN models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> and self-attentive models <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>. Traditional sequential recommendation models convert items into IDs and create item embedding tables for encoding. Item embeddings are learned from sequences of user interactions. To enrich item features, some approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref> incorporate item contexts such as item textual information or categorical features into ID embeddings. While ID-based methods are promising, they struggle to understand cold-start items or conduct cross-domain recommendations where models are trained and then applied to different recommendation scenarios. Item-specific IDs prevent models from learning transferable knowledge from training data for cold-start items and new datasets. As a result, item IDs limit the performance of sequential recommenders on cold-start items and we have to re-train a sequential recommender for continually added new items. Therefore, transferable recommenders can benefit both cold-start items and new-domain datasets.</p><p>To develop transferable recommender systems, previous studies usually assume shared information such as overlapping users/items <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr">39</ref>] and common features <ref type="bibr" target="#b28">[29]</ref> is available and then reduce the gap between source and target domains by learning either semantic mappings <ref type="bibr">[39]</ref> or transferable components <ref type="bibr" target="#b15">[16]</ref>. Such assumptions are rarely true in real applications because items in different domains (e.g., Laptops and T-shirts) usually contain different features for recommendation. Therefore, to have effective cross-domain transfer, recent works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref> leverage the generality of natural language texts (e.g., titles, descriptions of items) for common knowledge in different domains. The basic idea is to employ pre-trained language models such as BERT <ref type="bibr" target="#b5">[6]</ref> to obtain text representations and then learn the transformation from text representations to item representations. The knowledge of the transformation can be transferred across different domains and shows promising performance. However, such frameworks of learning transformation from language to items have several limitations: (1) Pre-trained language models are usually trained on a general language corpus (e.g., Wikipedia) serving natural language tasks that have a different language domain from item texts (e.g., concatenation of item attributes), hence text representations from pretrained language models for items are usually sub-optimal. (2) Text representations from pre-trained language models are not able to learn the importance of different item attributes and only provide coarse-grained (sentence-level) textual features but cannot learn fine-grained (word-level) user preferences for recommendations (e.g., find the same color in recent interactions for clothing recommendations). (3) Due to the independent training of pre-trained language models (by language understanding tasks, e.g., Masked Language Modeling) and transformation models (by recommendation tasks, e.g., next item prediction), the potential ability of models to understand language for recommendations has not been fully developed (by joint training).</p><p>With the above limitations in mind, we aim to unify the frameworks of natural language understanding and recommendations in an ID-free sequential recommendation paradigm. The pre-trained language models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> benefit various downstream natural language processing tasks due to their transferable knowledge from pre-training. The basic idea of this paper is to use the generality of language models through joint training of language understanding and sequential recommendations. To this end, there are three major challenges to be solved. First, previous text-based methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref> usually have their specific item texts (e.g., item descriptions, concatenation of item attributes). Instead of specific data types, we need to find a universal input data format of items for language models that is flexible enough to different kinds of textual item information. Second, it is not clear how to model languages and sequential transitions of items in one framework. Existing language models are not able to incorporate sequential patterns of items and cannot learn the alignment between items and item texts. Third, a training and inference framework is necessary to bridge the gap between natural languages and recommendations like how to efficiently rank items based on language models without trained item embeddings.</p><p>To address the above problems, we propose Recformer, a framework that can learn language representations for sequential recommendation. Overall, our approach takes a text sequence of historical items as input and predicts the next item based on language understanding. Specifically, as shown in Figure <ref type="figure" target="#fig_0">1</ref>, we first formulate an item as key-value attribute pairs which can include any textual information such as the title, color, brand of an item. Different items can include different attributes as item texts. Then, to encode a sequence of key-value attribute pairs, we propose a novel bi-directional Transformer <ref type="bibr" target="#b29">[30]</ref> based on Longformer structure <ref type="bibr" target="#b1">[2]</ref> but with different embeddings for item texts to learn item sequential patterns. Finally, to effectively learn language representations for recommendation, we design the learning framework for the model including pre-training, finetuning and inference processes. Based on the above methods, Recformer can effectively recommend the next items based on item text representations. Furthermore, the knowledge learned from training can be transferred to cold-start items or a new recommendation scenario.</p><p>To evaluate Recformer, we conduct extensive experiments on real-world datasets from different domains. Experimental results show that our method can achieve 15.83% and 39.78% (NDCG@10) performance improvements under fully-supervised and zero-shot sequential recommendation settings respectively. <ref type="foot" target="#foot_0">1</ref> Our contributions in this paper can be summarized as follows:</p><p>? We formulate items as key-value attribute pairs for the IDfree sequential recommendation and propose a novel bidirectional Transformer structure to encode sequences of key-value pairs. ? We design the learning framework that helps the model learn users' preferences and then recommend items based on language representations and transfer knowledge into different recommendation domains and cold-start items.</p><p>? Extensive experiments are conducted to show the effectiveness of our method. Results show that Recformer outperforms baselines for sequential recommendation and largely improves knowledge transfer as shown by zero-shot and cold-start settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head><p>In this section, we present Recformer which can learn language representations for sequential recommendation and effectively transfer and generalize to new recommendation scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Setup and Formulation</head><p>In the setting of sequential recommendation, we are given an item set I and a user's interaction sequence ? = {? 1 , ?  <ref type="figure">}</ref>, where ? ? and ? ? are words of ? and ? from a shared vocabulary in the language model and ? denotes the truncated length of text. An attribute dictionary ? ? can include all kinds of item textual information such as titles, descriptions, colors, etc. As shown in Figure <ref type="figure">2</ref>, to feed the attribute dictionary ? ? into a language model, we flatten key-value attribute pairs into ? ? = {?1, ?1, ?2, ?2, . . . , ? ? , ? ? } to obtain an item "sentence" as the input data. Unlike previous sequential recommenders <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b36">37]</ref> using both text and item IDs, in this study, we use only text for the sequential recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recformer</head><p>Figure <ref type="figure" target="#fig_1">3</ref> (a) shows the architecture of Recformer. The model has a similar structure as Longformer <ref type="bibr" target="#b1">[2]</ref> which adopts a multi-layer bidirectional Transformer <ref type="bibr" target="#b29">[30]</ref> with an attention mechanism that scales linearly with sequence length. We consider only computing efficiency for using Longformer but our method is open to other bidirectional Transformer structures such as BERT <ref type="bibr" target="#b5">[6]</ref> and BigBird <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Model Inputs.</head><p>As introduced in Section 2.1, for each item ? and corresponding attribute dictionary ? ? , we flatten the dictionary into an item "sentence" ? ? = {?1, ?1, ?2, ?2, . . . , ? ? , ? ? } where ? and ? are described by words, formally (?, ?) = {? ? 1 , . . . , ? ? ? , ? ? 1 , . . . , ? ? ? }. To encode a user's interaction sequence ? = {? 1 , ? 2 , . . . , ? ? }, we first reverse items in a sequence to {? ? , ? ?-1 , . . . , ? 1 } because intuitively recent items (i.e., ? ? , ? ?-1 , . . . ) are important for the next item prediction and reversed sequences can make sure recent items are included in the input data. Then, we use the item "sentences" to replace items and add a special token [CLS] at the beginning of sequences. Hence, model inputs are denoted as:</p><formula xml:id="formula_0">? = {[CLS],? ? ,? ?-1 , . . . ,? 1 } (1)</formula><p>where ? is a sequence of words containing all items and corresponding attributes the user interacted with in the historical interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Embedding</head><p>Layer. The target of Recformer is to understand the model input ? from both language understanding and sequential patterns in recommendations. The key idea in our work is to combine the embedding layers from language models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref> and self-attentive sequential recommenders <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>. Hence, Recformer contains four embeddings as follows:</p><p>? Token embedding represents the corresponding tokens. We denote the word token embedding by A ? R ? ? ?? , where ? ? is the number of words in our vocabulary and ? is the embedding dimension. Recformer does not have item embeddings as previous sequential recommenders and hence Recformer understands items in interaction sequences mainly based on these word token embeddings. The size of token embeddings is a constant for different recommendation scenarios; hence, our model size is irrelevant to the number of items. ? Token position embedding represents the position of tokens in a sequence. A word appearing at the ?-th position in the sequence ? is represented as B ? ? R ? . Similar to language models, token position embedding is designed to help Transformer understand the sequential patterns of words in ? . ? Token type embedding represents where a token comes from. Specifically, the token type embedding totally contains three vectors</p><formula xml:id="formula_1">C [CLS] , C Key , C Value ? R ? to represent if a to- ken comes from [CLS]</formula><p>, attribute keys, or attribute values respectively. Different types of tokens usually have different importance for the next item prediction. For example, because most items usually have the same attribute keys in a recommendation dataset, models with token type embedding will recognize repeated words from the same attribute keys. ? Item position embedding represents the position of items in a sequence. A word from attributes of the ?-th item in the sequence ? is represented as D ? ? R ? and D ? R ??? where ? is the maximum length of a user's interaction sequence ?. Same as previous self-attentive sequential recommenders <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>, the item position embedding is a key component for item sequential pattern learning. In Recformer, the item position embedding can also help the model learn the alignment between word tokens and items.</p><p>Therefore, given a word ? from the input sequence ? , the input embedding is calculated as the summation of four different embeddings followed by layer normalization <ref type="bibr" target="#b0">[1]</ref>:</p><formula xml:id="formula_2">E ? = LayerNorm(A ? + B ? + C ? + D ? )<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">E ? ? R ? . The embedding of model inputs ? is a sequence of E ? , E ? = [E [CLS] , E ? 1 , . . . , E ? ? ]<label>(3)</label></formula><p>where E ? ? R (?+1) ?? and ? is the maximum length of tokens in a user's interaction sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Item or Sequence Representations.</head><p>To encode E ? , we employ the bidirectional Transformer structure Longformer <ref type="bibr" target="#b1">[2]</ref> as our encoder. Because ? is usually a long sequence, the local windowed attention in Longformer can help us efficiently encode E ? .</p><p>As the standard settings in Longformer for document understanding, the special token [CLS] has global attention but other tokens use the local windowed attention. Hence, Recformer computes ?-dimensional word representations as follows:  where h ? ? R ? . Similar to the language models used for sentence representations, the representation of the first token h [CLS] is used as the sequence representation.</p><formula xml:id="formula_4">[h [CLS] , h ? 1 , . . . , h ? ? ] = Longformer([E [CLS] , E ? 1 , . . . , E ? ? ])<label>(4)</label></formula><p>In Recformer, we do not maintain an embedding table for items. Instead, we view the item as a special case of the interaction sequence with only one item. For each item ?, we construct its item "sentence" ? ? and use ? = {[CLS],? ? } as the model input to get the sequence representation h [CLS] as the item representation h ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Prediction.</head><p>We predict the next item based on the cosine similarity between a user's interaction sequence ? and item ?. Formally, after obtaining the sequence representation h ? and the item representation h ? as introduced in Section 2.2.3, we calculate the scores between ? and ? as follows:</p><formula xml:id="formula_5">? ?,? = h ? ? h ? ?h ? ? ? ?h ? ?<label>(5)</label></formula><p>where ? ?,? ? R is the relevance of item ? being the next item given ?.</p><p>To predict the next item, we calculate ? ?,? for all items 2 in the item set I and select item with the highest ? ?,? as the next item:</p><formula xml:id="formula_6">? ? = argmax ? ? I (? ?,? )<label>(6)</label></formula><p>where ? ? is the predicted item given user interaction sequence ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning Framework</head><p>To have an effective and efficient language model for the sequential recommendation, we propose our learning framework for Recformer including pre-training and two-stage finetuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Pre-training.</head><p>The target of pre-training is to obtain a highquality parameter initialization for downstream tasks. Different from previous sequential recommendation pre-training methods which consider only recommendations, we need to consider both language understanding and recommendations. Hence, to pre-train 2 For efficient calculation, we encode all items in advance for score calculation.</p><p>Recformer, we adopt two tasks: (1) Masked Language Modeling (MLM) and ( <ref type="formula" target="#formula_2">2</ref>) an item-item contrastive task. Masked Language Modeling (MLM) <ref type="bibr" target="#b5">[6]</ref> is an effective pre-training method for language understanding and has been widely used for various NLP pre-training tasks such as sentence understanding <ref type="bibr" target="#b7">[8]</ref>, phrase understanding <ref type="bibr" target="#b17">[18]</ref>. Adding MLM as an auxiliary task will prevent language models from forgetting the word semantics when models are jointly trained with other specific tasks. For recommendation tasks, MLM can also eliminate the language domain gap between a general language corpus and item texts. In particular, following BERT <ref type="bibr" target="#b5">[6]</ref>, the training data generator chooses 15% of the token positions at random for prediction. If the token is selected, we replace the token with (1) the [MASK] with probability 80%; (2) a random token with probability 10%; (3) the unchanged token with probability 10%. The MLM loss is calculated as:</p><formula xml:id="formula_7">m = LayerNorm(GELU(W ? h ? + b ? ))<label>(7)</label></formula><formula xml:id="formula_8">? = Softmax(W 0 m + b 0 )<label>(8)</label></formula><formula xml:id="formula_9">L MLM = - | V | ?? ?=0 ? ? log(? ? )<label>(9)</label></formula><p>where</p><formula xml:id="formula_10">W ? ? R ? ?? , b ? ? R ? , W 0 ? R | V | ?? , b 0 ? R | V |</formula><p>, GELU is the GELU activation function <ref type="bibr" target="#b9">[10]</ref> and V is the vocabulary used in the language model. Another pre-training task for Recformer is the item-item contrastive (IIC) task which is widely used in the next item prediction for recommendations. We use the ground-truth next items as positive instances following previous works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">27]</ref>. However, for negative instances, we adopt in-batch next items as negative instances instead of negative sampling <ref type="bibr" target="#b13">[14]</ref> or fully softmax <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">27]</ref>. Previous recommenders maintain an item embedding table, hence they can easily retrieve item embeddings for training and update embeddings. In our case, item embeddings are from Recformer, so it is infeasible to re-encode items (from sampling or full set) per batch for training. In-batch negative instances <ref type="bibr" target="#b2">[3]</ref>  </p><formula xml:id="formula_11">? ? ? Evaluate(?, I ? , ? valid ) 16: if ? ? &gt; ? then 17: ? ? ? ? 18: ? ? ? ? 19:</formula><p>end if 20: end for 21: return ? ? , I ? truth items of other instance sequences in the same batch as negative items. Although it is possible to provide false negatives, false negatives are less likely in the pre-training dataset with a large size. Furthermore, the target of pre-training is to provide high-quality initialized parameters and we have the finetuning with accurate supervision for downstream tasks. Therefore, we claim that inbatch negatives will not hurt the recommendation performance but have much higher training efficiency than accurate supervision. Formally, the item-item contrastive loss is calculated as:</p><formula xml:id="formula_12">L IIC = -log ? sim(h ? ,h + ? )/? ? ? B ? sim(h ? ,h ? )/? (<label>10</label></formula><formula xml:id="formula_13">)</formula><p>where sim is the similarity introduced in Equation ( <ref type="formula" target="#formula_5">5</ref>); h + ? is the representation of the ground truth next item; B is the ground truth item set in one batch and ? is a temperature parameter.</p><p>At the pre-training stage, we use a multi-task training strategy to jointly optimize Recformer:</p><formula xml:id="formula_14">L PT = L IIC + ? ? L MLM (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>where ? is a hyper-parameter to control the weight of MLM task loss.</p><p>The pre-trained model will be fine-tuned for new recommendation scenarios. The learning task used in finetuning is item-item contrastive learning which is the same as pre-training but with fully softmax instead of in-batch negatives. Formally, the finetuning loss is calculated as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Two</head><formula xml:id="formula_16">L FT = -log ? sim(h ? ,I + ? )/? ? ? I ? sim(h ? ,I ? )/?<label>(12)</label></formula><p>where I ? is the item feature of item ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Discussion</head><p>In this section, we briefly compare Recformer to other sequential recommendation methods to highlight the novelty of our method.</p><p>Traditional sequential recommenders such as GRU4Rec <ref type="bibr" target="#b10">[11]</ref>, SASRec <ref type="bibr" target="#b13">[14]</ref> and BERT4Rec <ref type="bibr" target="#b26">[27]</ref> rely on item IDs and corresponding trainable item embeddings to train a sequential model for recommendations. These item embeddings are learned from sequential patterns of user interactions. However, as mentioned in <ref type="bibr" target="#b19">[20]</ref>, these approaches suffer from data sparsity and can not perform well with cold-start items.</p><p>To reduce the dependence on item IDs, some context-aware sequential recommenders such as UniSRec <ref type="bibr" target="#b11">[12]</ref>, S<ref type="foot" target="#foot_1">3</ref> -Rec <ref type="bibr" target="#b37">[38]</ref>, ZESRec <ref type="bibr" target="#b6">[7]</ref> are proposed to incorporate side information (e.g., categories, titles) as prior knowledge for recommendations. All of these approaches rely on a feature extractor such as BERT <ref type="bibr" target="#b5">[6]</ref> to obtain item feature vectors and then fuse these vectors into item representations with an independent sequential model. As we discussed in Section 1, these feature-based methods also have some limitations.</p><p>In this paper, we explore conducting sequential recommendations in a new paradigm that learns language representations for the next item recommendations. Instead of trainable item embeddings or fixed item features from language models, we bridge the gap between natural language understanding and sequential recommendation to directly learn representations of items and user sequences based on words. We expect the generality of natural language can improve the transferability of recommenders in order to benefit new domain adaptation and cold-start item understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>In this section, we empirically show the effectiveness of our proposed model Recformer and learning framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>3.1.1 Datasets. To evaluate the performance of Recformer, we conduct pre-training and finetuning on different categories of Amazon review datasets <ref type="bibr" target="#b21">[22]</ref>. The statistics of datasets after preprocessing are shown in Table <ref type="table" target="#tab_4">1</ref>.</p><p>For pre-training, seven categories are selected as training data including "Automotive", "Cell Phones and Accessories", "Clothing Shoes and Jewelry", "Electronics", "Grocery and Gourmet Food", "Home and Kitchen", "Movies and TV ", and one category "CDs and Vinyl" is left out as validation data. Datasets from these categories are used as source domain datasets.</p><p>For finetuning, we select six categories including "Industrial and Scientific", "Musical Instruments", "Arts, Crafts and Sewing", "Office Products", "Video Games", "Pet Supplies", as target domain datasets to evaluate Recformer.</p><p>For both pre-training and finetuning, we use the five-core datasets provided by the data source and filter items whose title is missing. Then we group the interactions by users and sort them by timestamp ascendingly. Note that we do not merge the same users in different categories. Following previous work <ref type="bibr" target="#b11">[12]</ref>, we select item attributes title, categories and brand as key-value attribute pairs for items.</p><p>3.1.2 Baselines. We compare three groups of works as our baselines which include methods with only item IDs; methods using item IDs and treating item text as side information; and methods using only item texts as inputs.</p><p>(1) ID-Only methods:</p><p>? GRU4Rec <ref type="bibr" target="#b10">[11]</ref> adopts RNNs to model user action sequences for session-based recommendations. We treat each user's interaction sequence as a session. ? SASRec <ref type="bibr" target="#b13">[14]</ref> uses a directional self-attentive model to capture item correlations within a sequence.</p><p>? BERT4Rec <ref type="bibr" target="#b26">[27]</ref> employs a bi-directional self-attentive model with the cloze objective for modeling user behavior sequences. ? RecGURU <ref type="bibr" target="#b15">[16]</ref> proposes to pre-train sequence representations with an autoencoder in an adversarial learning paradigm. We do not consider overlapped users for this method in our setting.</p><p>(2) ID-Text methods:</p><p>? FDSA <ref type="bibr" target="#b36">[37]</ref> uses a self-attentive model to capture item and feature transition patterns. ? S 3 -Rec <ref type="bibr" target="#b37">[38]</ref> pre-trains sequential models with mutual information maximization to learn the correlations among attributes, items, subsequences, and sequences.</p><p>(3) Text-Only methods:</p><p>? ZESRec <ref type="bibr" target="#b6">[7]</ref> encodes item texts with a pre-trained language model as item features. We pre-train this method on our pretraining dataset and finetune the model on six downstream datasets.</p><p>? UniSRec <ref type="bibr" target="#b11">[12]</ref> uses textual item representations from a pretrained language model and adapts to a new domain using an MoE-enhance adaptor. We initialize the model with the pre-trained parameters provided by the authors and finetune the model on target domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Evaluation Settings.</head><p>To evaluate the performance of sequential recommendation, we adopt three widely used metrics NDCG@N, Recall@N and MRR, where N is set to 10. For data splitting of finetuning datasets, we apply the leave-one-out strategy <ref type="bibr" target="#b13">[14]</ref> for evaluation: the most recent item in an interaction sequence is used for testing, the second most recent item for validation and the remaining data for training. We rank the ground-truth item of each sequence among all items for evaluation and report the average scores of all sequences in the test data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overall Performance</head><p>We compare Recformer to baselines on six datasets across different recommendation domains. Results are shown in Table <ref type="table" target="#tab_6">2</ref>.</p><p>For baselines, ID-Text methods (i.e., FDSA and S 3 -Rec) achieve better results compared to ID-Only and Text-Only methods in general. Because ID-Text methods include item IDs and content features, they can learn both content-based information and sequential patterns from finetuning. Comparing Text-Only methods and ID-Only methods, we can find that on the Scientific, Instruments, and Pet datasets, Text-Only methods perform better than ID-Only methods.</p><p>A possible reason is that the item transitions in these three datasets are highly related to item texts (i.e., title, brand, category) hence text-only methods can recommend the next item based on content similarity.</p><p>Our proposed method Recformer, achieves the best overall performance on all datasets except the Recall@10 of Instruments. Recformer improves the NDCG@10 by 15.83% and MRR by 15.99% on average over the second best results. Different from baselines, Recformer learns language representations for sequential recommendation without pre-trained language models or item IDs. With two-stage finetuning, Recformer can be effectively adapted to downstream domains and transferred knowledge from pre-training can consistently benefit finetuning tasks. The results illustrate the effectiveness of the proposed Recformer and we will conduct further detailed analysis for different components in the following sections.  Table <ref type="table">3</ref>: Performance of models compared between in-set items and cold-start items on four datasets. N@10 and R@10 stand for NDCG@10 and Recall@10 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Low-Resource Performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SASRec UniSRec Recformer</head><p>Dataset Metric In-Set Cold In-Set Cold In-Set Cold Scientific N@10 0.0775 0.0213 0.0864 0.0441 0.1042 0.0520 R@10 0.1206 0.0384 0.1245 0.0721 0.1417 0.0897 Instruments N@10 0.0669 0.0142 0.0715 0.0208 0.0916 0.0315 R@10 0.1063 0.0309 0.1094 0.0319 0.1130 0.0468 Arts N@10 0.1039 0.0071 0.1174 0.0395 0.1568 0.0406 R@10 0.1645 0.0129 0.1736 0.0666 0.1866 0.0689 Pet N@10 0.0597 0.0013 0.0771 0.0101 0.0994 0.0225 R@10 0.0934 0.0019 0.1115 0.0175 0.1192 0.0400 transfer learned knowledge to downstream tasks based on language understanding. Experimental results are shown in Table <ref type="table">3</ref>. We can see that Text-Only methods significantly outperform SASRec, especially on datasets with a large size (i.e., Arts, Pet). Because of randomly initialized cold-start item representations, the performance of SASRec is largely lower on cold-start items than in-set items. Hence, IDonly methods are not able to handle cold-start items and applying text is a promising direction. For Text-only methods, Recformer greatly improves performance on both in-set and cold-start datasets compared to UniSRec which indicates learning language representations is superior to obtaining text features for recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Ablation Study.</head><p>We analyze how our proposed components influence the final sequential recommendation performance. The results are shown in Table <ref type="table" target="#tab_8">4</ref>. We introduce the variants and analyze their results respectively.</p><p>We first test the effectiveness of our proposed two-stage finetuning. In variant (1) w/o two-stage finetuning, we do not update item feature matrix I and only conduct finetuning based on I from pre-trained parameters. We find that compared to (0) Recformer, (1) has similar results on Scientific but has a large margin on Instruments since the pre-trained model has better pre-trained item representations on Scientific compared to Instruments (shown in Figure <ref type="figure">4</ref>). Hence, our proposed two-stage finetuning can effectively improve the sub-optimal item representations from pre-training and further improve performance on downstream datasets.</p><p>Then, we investigate the effects of freezing/trainable word embeddings and item embeddings. In our default setting (1), we freeze the item feature matrix I and train word embeddings of Recformer. In variants (2)(3)(4), we try to train the item feature matrix or freeze word embeddings. Overall, on the Scientific dataset, the model with fixed item embeddings performs better than the model with trainable item embeddings, whereas on the Instruments dataset, our model performs well when item embeddings are trainable. The divergence can be eliminated by our two-stage finetuning strategy.</p><p>Variant (5) w/o pre-training finetunes Recformer from scratch. We can see that (0) Recformer significantly outperforms Variant (5) in both datasets because without pre-training, the item feature matrix I is not trained and cannot provide informative supervision during finetuning even if we update I by two-stage finetuning. These results show the effectiveness of pre-training.</p><p>Finally, we explore the effectiveness of our proposed model structure (i.e., item position embeddings and token type embeddings). Variant (6) removes the two embeddings and results show that the model in <ref type="bibr" target="#b5">(6)</ref> causes performance decay on the instruments dataset  which indicates the two embeddings are necessary when the gap between pre-training and finetuning is large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Pre-training</head><p>Steps vs. Performance. We investigate the zeroshot sequential recommendation performance on downstream tasks over different pre-training steps and results on four datasets are shown in Figure <ref type="figure" target="#fig_4">6</ref>. The pre-training of natural language understanding usually requires a large number of training steps to achieve a promising result. However, we have a different situation in sequential recommendation. From Figure <ref type="figure" target="#fig_4">6</ref>, we can see that most datasets already achieve their best performance after around 4,000 training steps and further pre-training may hurt the knowledge transferability on downstream tasks. We think there are two possible reasons: (1) We initialize most parameters from a Longformer model pre-trained by the MLM task. In this case, the model already has some essential knowledge of natural languages. The domain adaptation from a general language understanding to the item text understanding for recommendations should be fast. ( <ref type="formula" target="#formula_2">2</ref>) Even if we include seven categories in the training data, there is still a language domain difference between pre-training data and downstream data since different item categories have their own specific vocabularies. For instance, the category Electronics has quite different words in item text compared to the Pets category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK 4.1 Sequential Recommendation</head><p>Sequential recommendation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">27]</ref> aims to predict the next item based on historical user interactions. Proposed methods model user interactions as a sequence ordered by their timestamps. Due to the ability to capture the long-term preferences and short-term dynamics of users, sequential recommendation methods show their effectiveness for personalization and attract a lot of studies. Early works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref> apply the Markov Chain to model item-item transition relations based on matrix factorization. For deep learning methods, Convolutional Sequence Embedding (Caser) <ref type="bibr" target="#b27">[28]</ref> views the embedding matrix of previous items as an "image" and applies convolutional operations to extract transitions. GRU4Rec <ref type="bibr" target="#b10">[11]</ref> introduces Gated Recurrent Units (GRU) <ref type="bibr" target="#b4">[5]</ref> to model user sequential patterns. With the development of the Transformer <ref type="bibr" target="#b29">[30]</ref>, recent studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref> widely use self-attention model for sequential recommendation. Although these approaches achieve promising performance, they struggle to learn transferable knowledge or understand cold-start items due to the dependence on IDs and item embeddings which are specific to items and datasets. Recently, researchers attempt to employ textual features as transferable item representations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref>. These methods first obtain item features by encoding item texts with language models and then learn transferable item representations with an independent sequential model. Independent language understanding and sequential pattern learning still limit the capacity of the model to learn user interactions based on languages. In this paper, we explore unifying the language understanding and sequential recommendations into one Transformer framework. We aim to have a sequential recommendation method that can effectively model cold-start items and learn transferable sequential patterns for different recommendation scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Transfer Learning for Recommendation</head><p>Data sparsity and cold-start item understanding issues are challenging in recommender systems and recent studies <ref type="bibr" target="#b32">[33,</ref><ref type="bibr">39,</ref><ref type="bibr">40]</ref> explore transferring knowledge across different domains to improve the recommendation at the target domain. Previous methods for knowledge transfer mainly rely on shared information between the source and target domains including common users <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35]</ref>, items <ref type="bibr" target="#b25">[26,</ref><ref type="bibr">39]</ref> or attributes <ref type="bibr" target="#b28">[29]</ref>. To learn common item features from different domains, pre-trained language models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref> provide high-quality item features by encoding item texts (e.g., title, brand). Based on pre-trained item features, several methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref> are proposed to learn universal item representations by applying additional layers. In this work, we have the same target as previous transfer learning for recommendation (i.e., alleviate data sparsity and cold-start item issues). However, instead of relying on common users, items and attributes or encoding items with pre-trained language models, we directly learn language representations for sequential recommendation and hence transfer knowledge based on the generality of natural languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose Recformer, a framework that can effectively learn language representations for sequential recommendation. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Input data comparison between item ID sequences for traditional sequential recommendation and key-value attribute pair sequences used in Recformer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The overall framework of Recformer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3. 3 . 1</head><label>31</label><figDesc>Zero-Shot. To show the effectiveness of pre-training, we evaluate the zero-shot recommendation performance of three Text-Only methods (i.e., UniSRec, ZESRec, Recformer) and compare results to the average scores of three ID-Only methods fully trained on downstream datasets. The zero-shot recommendation setting requires models to learn knowledge from pre-training datasets and directly test on downstream datasets without further training. Hence, traditional ID-based methods cannot be evaluated in this Scientific Arts Instruments Office Games Pet 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: Performance (NDCG@10) of three Text-Only methods under the zero-shot setting. Fully-Supervised denotes the average scores of three classical ID-Only methods (i.e., SAS-Rec, BERT4Rec, GRU4Rec) trained with all training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Recformer zero-shot recommendation performance (NDCG@10 and Recall@10) over different pretraining steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>are using ground Algorithm 1: Two-Stage Finetuning 1 Input: ? train , ? valid , I, ? 2 Hyper-parameters: ? epoch 3 Output: ? ? , I ? 1: ? ? initialized with pre-trained parameters 2: ? ? metrics are initialized with 0 Stage 1 3: for ? in ? epoch do ? ? ? Evaluate(?, I, ? valid ) ? ? ? ? 13: for ? in ? epoch do ? ? Train(?, I ? , ? train )</figDesc><table><row><cell>4:</cell><cell>I ? Encode(?, I)</cell></row><row><cell>5:</cell><cell>? ? Train(?, I, ? train )</cell></row><row><cell>6:</cell><cell></cell></row><row><cell>7:</cell><cell>if ? ? &gt; ? then</cell></row><row><cell>8:</cell><cell>? ? , I ? ? ?, I</cell></row><row><cell>9:</cell><cell>? ? ? ?</cell></row><row><cell>10:</cell><cell>end if</cell></row><row><cell cols="2">11: end for</cell></row><row><cell></cell><cell>Stage 2</cell></row><row><cell>12: 14:</cell><cell></cell></row><row><cell>15:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>-Stage Finetuning. Similar to pre-training, we do not maintain an independent item embedding table. Instead, we encode items by Recformer. However, in-batch negatives cannot provide accurate supervision in a small dataset because it is likely to have false negatives which undermine recommendation performance.To solve this problem, we propose two-stage finetuning as shown in Algorithm 1. The key idea is to maintain an item feature matrix I ? R | I | ?? . Different from the item embedding table, I is not learnable and all item features are encoded from Recformer. As shown in Algorithm 1, our proposed finetuning method has two stages. In stage 1, I is updated (line 4) per epoch,3 whereas, in stage 2 we freeze I and update only parameters in model ?. The basic idea is that although the model is already pre-trained, item representations from the pre-trained model can still be improved by further training on downstream datasets. It is expensive to re-encode all items in every batch hence we re-encode all items in every epoch to update I (line 4) and use I as supervision for item-item contrastive learning (line 5). After obtaining the best item representations, we re-initialize the model with the corresponding parameters (line 12) and start stage 2. Since I keeps updating in stage 1, the supervision for finetuning is also changing. In this case, the model is hard to be optimized to have the best performance. Therefore, we freeze I and continue training the model until achieving the best performance on the validation dataset.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets after preprocessing. Avg. n denotes the average length of item sequences.</figDesc><table><row><cell>Datasets</cell><cell>#Users</cell><cell>#Items</cell><cell>#Inters.</cell><cell cols="2">Avg. n Density</cell></row><row><cell cols="4">Pre-training 3,613,906 1,022,274 33,588,165</cell><cell>9.29</cell><cell>9.1e-6</cell></row><row><cell>-Training</cell><cell>3,501,527</cell><cell cols="2">954,672 32,291,280</cell><cell>9.22</cell><cell>9.0e-6</cell></row><row><cell>-Validation</cell><cell>112,379</cell><cell>67,602</cell><cell>1,296,885</cell><cell>11.54</cell><cell>1.7e-4</cell></row><row><cell>Scientific</cell><cell>11,041</cell><cell>5,327</cell><cell>76,896</cell><cell>6.96</cell><cell>1.3e-3</cell></row><row><cell>Instruments</cell><cell>27,530</cell><cell>10,611</cell><cell>231,312</cell><cell>8.40</cell><cell>7.9e-4</cell></row><row><cell>Arts</cell><cell>56,210</cell><cell>22,855</cell><cell>492,492</cell><cell>8.76</cell><cell>3.8e-4</cell></row><row><cell>Office</cell><cell>101,501</cell><cell>27,932</cell><cell>798,914</cell><cell>7.87</cell><cell>2.8e-4</cell></row><row><cell>Games</cell><cell>11,036</cell><cell>15,402</cell><cell>100,255</cell><cell>9.08</cell><cell>5.9e-4</cell></row><row><cell>Pet</cell><cell>47,569</cell><cell>37,970</cell><cell>420,662</cell><cell>8.84</cell><cell>2.3e-4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The temperature parameter ? is 0.05 and the weight of MLM loss ? is 0.1. Other than token type embedding and item position embedding in Recformer, other parameters are initialized with pre-trained parameters of Longformer 5 before pre-training. The batch size is 64 for pre-training and 16 for finetuning. We optimize Recformer with Adam optimizer with learning rate 5e-5 and adopt early stop with the patience of 5 epochs to prevent overfitting. For baselines, we use the suggested settings introduced in<ref type="bibr" target="#b11">[12]</ref>.</figDesc><table /><note><p><p><p><p><p>3.1.4 Implementation Details. We build Recformer based on Longformer implemented by Huggingface</p>4 </p>. For efficient computing, we set the size of the local attention windows in Longformer to 64. The maximum number of tokens is 32 for each attribute and 1,024 for each interaction sequence (i.e., ? in Equation (</p>1</p>)). The maximum number of items in a user sequence is 50 for all baselines and Recformer.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of different recommendation models. The best and the second-best performance is bold and underlined respectively. Improv. denotes the relative improvement of Recformer over the best baselines.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">ID-Only Methods</cell><cell></cell><cell cols="2">ID-Text Methods</cell><cell></cell><cell cols="2">Text-Only Methods</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Improv.</cell></row><row><cell>Dataset</cell><cell>Metric</cell><cell cols="5">GRU4Rec SASRec BERT4Rec RecGURU FDSA</cell><cell>S 3 -Rec</cell><cell cols="3">ZESRec UniSRec Recformer</cell><cell></cell></row><row><cell></cell><cell>NDCG@10</cell><cell>0.0826</cell><cell>0.0797</cell><cell>0.0790</cell><cell>0.0575</cell><cell>0.0716</cell><cell>0.0451</cell><cell>0.0843</cell><cell>0.0862</cell><cell>0.1027</cell><cell>19.14%</cell></row><row><cell>Scientific</cell><cell>Recall@10</cell><cell>0.1055</cell><cell>0.1305</cell><cell>0.1061</cell><cell>0.0781</cell><cell>0.0967</cell><cell>0.0804</cell><cell>0.1260</cell><cell>0.1255</cell><cell>0.1448</cell><cell>10.96%</cell></row><row><cell></cell><cell>MRR</cell><cell>0.0702</cell><cell>0.0696</cell><cell>0.0759</cell><cell>0.0566</cell><cell>0.0692</cell><cell>0.0392</cell><cell>0.0745</cell><cell>0.0786</cell><cell>0.0951</cell><cell>20.99%</cell></row><row><cell></cell><cell>NDCG@10</cell><cell>0.0633</cell><cell>0.0634</cell><cell>0.0707</cell><cell>0.0468</cell><cell>0.0731</cell><cell>0.0797</cell><cell>0.0694</cell><cell>0.0785</cell><cell>0.0830</cell><cell>4.14%</cell></row><row><cell>Instruments</cell><cell>Recall@10</cell><cell>0.0969</cell><cell>0.0995</cell><cell>0.0972</cell><cell>0.0617</cell><cell>0.1006</cell><cell>0.1110</cell><cell>0.1078</cell><cell>0.1119</cell><cell>0.1052</cell><cell>-</cell></row><row><cell></cell><cell>MRR</cell><cell>0.0707</cell><cell>0.0577</cell><cell>0.0677</cell><cell>0.0460</cell><cell>0.0748</cell><cell>0.0755</cell><cell>0.0633</cell><cell>0.0740</cell><cell>0.0807</cell><cell>6.89%</cell></row><row><cell></cell><cell>NDCG@10</cell><cell>0.1075</cell><cell>0.0848</cell><cell>0.0942</cell><cell>0.0525</cell><cell>0.0994</cell><cell>0.1026</cell><cell>0.0970</cell><cell>0.0894</cell><cell>0.1252</cell><cell>16.47%</cell></row><row><cell>Arts</cell><cell>Recall@10</cell><cell>0.1317</cell><cell>0.1342</cell><cell>0.1236</cell><cell>0.0742</cell><cell>0.1209</cell><cell>0.1399</cell><cell>0.1349</cell><cell>0.1333</cell><cell>0.1614</cell><cell>15.37%</cell></row><row><cell></cell><cell>MRR</cell><cell>0.1041</cell><cell>0.0742</cell><cell>0.0899</cell><cell>0.0488</cell><cell>0.0941</cell><cell>0.1057</cell><cell>0.0870</cell><cell>0.0798</cell><cell>0.1189</cell><cell>12.49%</cell></row><row><cell></cell><cell>NDCG@10</cell><cell>0.0761</cell><cell>0.0832</cell><cell>0.0972</cell><cell>0.0500</cell><cell>0.0922</cell><cell>0.0911</cell><cell>0.0865</cell><cell>0.0919</cell><cell>0.1141</cell><cell>17.39%</cell></row><row><cell>Office</cell><cell>Recall@10</cell><cell>0.1053</cell><cell>0.1196</cell><cell>0.1205</cell><cell>0.0647</cell><cell>0.1285</cell><cell>0.1186</cell><cell>0.1199</cell><cell>0.1262</cell><cell>0.1403</cell><cell>9.18%</cell></row><row><cell></cell><cell>MRR</cell><cell>0.0731</cell><cell>0.0751</cell><cell>0.0932</cell><cell>0.0483</cell><cell>0.0972</cell><cell>0.0957</cell><cell>0.0797</cell><cell>0.0848</cell><cell>0.1089</cell><cell>12.04%</cell></row><row><cell></cell><cell>NDCG@10</cell><cell>0.0586</cell><cell>0.0547</cell><cell>0.0628</cell><cell>0.0386</cell><cell>0.0600</cell><cell>0.0532</cell><cell>0.0530</cell><cell>0.0580</cell><cell>0.0684</cell><cell>8.92%</cell></row><row><cell>Games</cell><cell>Recall@10</cell><cell>0.0988</cell><cell>0.0953</cell><cell>0.1029</cell><cell>0.0479</cell><cell>0.0931</cell><cell>0.0879</cell><cell>0.0844</cell><cell>0.0923</cell><cell>0.1039</cell><cell>0.97%</cell></row><row><cell></cell><cell>MRR</cell><cell>0.0539</cell><cell>0.0505</cell><cell>0.0585</cell><cell>0.0396</cell><cell>0.0546</cell><cell>0.0500</cell><cell>0.0505</cell><cell>0.0552</cell><cell>0.0650</cell><cell>11.11%</cell></row><row><cell></cell><cell>NDCG@10</cell><cell>0.0648</cell><cell>0.0569</cell><cell>0.0602</cell><cell>0.0366</cell><cell>0.0673</cell><cell>0.0742</cell><cell>0.0754</cell><cell>0.0702</cell><cell>0.0972</cell><cell>28.91%</cell></row><row><cell>Pet</cell><cell>Recall@10</cell><cell>0.0781</cell><cell>0.0881</cell><cell>0.0765</cell><cell>0.0415</cell><cell>0.0949</cell><cell>0.1039</cell><cell>0.1018</cell><cell>0.0933</cell><cell>0.1162</cell><cell>11.84%</cell></row><row><cell></cell><cell>MRR</cell><cell>0.0632</cell><cell>0.0507</cell><cell>0.0585</cell><cell>0.0371</cell><cell>0.0650</cell><cell>0.0710</cell><cell>0.0706</cell><cell>0.0650</cell><cell>0.0940</cell><cell>32.39%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Performance w.r.t. Cold-Start Items. In this section, we simulate this scenario by splitting a dataset into two parts, i.e., an in-set dataset and cold-start dataset. Specifically, for the in-set dataset, we make sure all test items appear in the training data and all other test items (never appearing in training data) will be sent to the cold-start dataset. We train models on in-set datasets and test on both in-set and cold-start datasets. In this case, models never see the cold-start items during training and item embedding tables do not contain cold-start items. We compare the ID-only method SASRec and the Text-only method UniSRec to Recformer. For ID-based SASRec, we substitute items appearing only once in the training set with a cold token and after training, we add this cold token embedding to cold-start item embeddings to provide prior knowledge6 . For UniSRec, cold-start items are represented by item texts and encoded by BERT which is identical to seen items. Recformer directly encode item texts to represent cold-start items.</figDesc><table><row><cell>3.3.2 Low-Resource. We conduct experiments with SASRec, UniS-</cell></row><row><cell>Rec and Recformer in low-resource settings. In this setting, we</cell></row><row><cell>train models on downstream datasets with different ratios of train-</cell></row><row><cell>ing data and results are shown in Figure 5. We can see that methods</cell></row><row><cell>with item text (i.e., UniSRec and Recformer) outperform ID-only</cell></row><row><cell>method SASRec especially when less training data is available. This</cell></row><row><cell>indicates UniSRec and Recformer can incorporate prior knowl-</cell></row><row><cell>edge and do recommendations based on item texts. In low-resource</cell></row><row><cell>settings, most items in the test set are unseen during training for</cell></row><row><cell>SASRec. Therefore, the embeddings of unseen items are randomly</cell></row><row><cell>initialized and cannot provide high-quality representations for rec-</cell></row><row><cell>ommendations. After being trained with adequate data, SASRec</cell></row><row><cell>could rapidly improve its performance. Recformer achieves the</cell></row><row><cell>best performance over different ratios of training data. On the Sci-</cell></row><row><cell>entific dataset, Recformer outperforms other methods by a large</cell></row><row><cell>margin with 1% and 5% of training data.</cell></row><row><cell>3.4 Further Analysis</cell></row><row><cell>3.4.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Ablation study on two downstream datasets. The best and the second-best scores are bold and underlined respectively.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scientific</cell><cell>Instruments</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Variants</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NDCG@10 Recall@10 MRR NDCG@10 Recall@10 MRR</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(0) Recformer</cell><cell></cell><cell></cell><cell></cell><cell>0.1027</cell><cell>0.1448</cell><cell>0.0951</cell><cell>0.0830</cell><cell>0.1052</cell><cell>0.0807</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">(1) w/o two-stage finetuning</cell><cell></cell><cell>0.1023</cell><cell>0.1442</cell><cell>0.0948</cell><cell>0.0728</cell><cell>0.1005</cell><cell>0.0685</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">(1) + (2) freezing word emb. &amp; item emb.</cell><cell>0.1026</cell><cell>0.1399</cell><cell>0.0942</cell><cell>0.0728</cell><cell>0.1015</cell><cell>0.0682</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">(1) + (3) trainable word emb. &amp; item emb.</cell><cell>0.0970</cell><cell>0.1367</cell><cell>0.0873</cell><cell>0.0802</cell><cell>0.1015</cell><cell>0.0759</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">(1) + (4) trainable item emb. &amp; freezing word emb.</cell><cell>0.0965</cell><cell>0.1383</cell><cell>0.0856</cell><cell>0.0801</cell><cell>0.1014</cell><cell>0.0760</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(5) w/o pre-training</cell><cell></cell><cell></cell><cell></cell><cell>0.0722</cell><cell>0.1114</cell><cell>0.0650</cell><cell>0.0598</cell><cell>0.0732</cell><cell>0.0584</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">(6) w/o item position emb. &amp; token type emb.</cell><cell>0.1018</cell><cell>0.1427</cell><cell>0.0945</cell><cell>0.0518</cell><cell>0.0670</cell><cell>0.0501</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Scientific</cell><cell cols="2">Instruments</cell><cell></cell><cell>Arts</cell><cell>Games</cell></row><row><cell></cell><cell>0.08</cell><cell></cell><cell></cell><cell></cell><cell>0.12</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.10</cell><cell></cell></row><row><cell>NDCG@10</cell><cell>0.04 0.06</cell><cell></cell><cell></cell><cell>Recall@10</cell><cell>0.06 0.08</cell><cell></cell></row><row><cell></cell><cell>0.02</cell><cell></cell><cell></cell><cell></cell><cell>0.02 0.04</cell><cell></cell></row><row><cell></cell><cell>0.00</cell><cell>0</cell><cell cols="2">2000 4000 6000 8000 10000 Pretraining Steps</cell><cell>0.00</cell><cell>0</cell><cell>Pretraining Steps 2000 4000 6000 8000 10000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>To recommend the next item based on languages, we first formulate items as key-value attribute pairs instead of item IDs. Then, we propose a novel bi-directional Transformer model for sequence and item representations. The proposed structure can learn both natural languages and sequential patterns for recommendations. Furthermore, we design a learning framework including pretraining and finetuning that helps the model learn to recommend based on languages and transfer knowledge into different recommendation scenarios. Finally, extensive experiments are conducted to evaluate the effectiveness of Recformer under full-supervised and low-resource settings. Results show that Recformer largely outperforms existing methods in different settings, especially for the zero-shot and cold-start items recommendation which indicates Recformer can effectively transfer knowledge from training. An ablation study is conducted to show the effectiveness of our proposed components.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code will be released upon acceptance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Updating means encoding all items with Recformer.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://huggingface.co/docs/transformers/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://huggingface.co/allenai/longformer-base-4096</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>We try to provide a reasonable method for ID-based baselines with cold-start items.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Layer Normalization</title>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Ryan Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>ArXiv abs/1607.06450</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Longformer: The Long-Document Transformer</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno>ArXiv abs/2004.05150</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On Sampling Strategies for Neural Network-based Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intent Contrastive Learning for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Yong-Guang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</title>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?aglar</forename><surname>G?l?ehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>ArXiv abs/1412.3555</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>ArXiv abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Zero-Shot Recommender Systems</title>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Hao Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernie</forename><surname>Deoras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<idno>ArXiv abs/2105.08318</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SimCSE: Simple Contrastive Learning of Sentence Embeddings</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 16th International Conference on Data Mining (ICDM</title>
		<imprint>
			<date type="published" when="2016">2016. 2016. 2016</date>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>arXiv: Learning</idno>
		<title level="m">Gaussian Error Linear Units (GELUs)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Session-based Recommendations with Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Bal?zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linas</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domonkos</forename><surname>Tikk</surname></persName>
		</author>
		<idno>CoRR abs/1511.06939</idno>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards Universal Sequence Representation Learning for Recommender Systems</title>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanlei</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CoNet: Collaborative Cross Networks for Cross-Domain Recommendation</title>
		<author>
			<persName><forename type="first">Guangneng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Self-Attentive Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM) (2018)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">RecGURU: Adversarial Learning of Generalized User Representations for Cross-Domain Recommendation</title>
		<author>
			<persName><forename type="first">Chenglin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqiang</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beibei</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural Attentive Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining</title>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.426</idno>
		<ptr target="https://doi.org/10.18653/v1/2022.acl-long.426" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6159" to="6169" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Time Interval Aware Self-Attention for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Coarse-to-Fine Sparse Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soo-Min</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>ArXiv abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects</title>
		<author>
			<persName><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Improving Language Understanding by Generative Pre-Training</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno>ArXiv abs/1910.10683</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Factorizing personalized Markov chains for next-basket recommendation</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relational learning via collective matrix factorization</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Ajit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>BERT</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cross-domain collaboration recommendation</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>ArXiv abs/1706.03762</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">PTUM: Pre-training User Model from Unlabeled User Behaviors via Self-supervision</title>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<idno>ArXiv abs/2010.01494</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">UPRec: User-Aware Pre-training for Recommender Systems</title>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyu</forename><surname>Lin</surname></persName>
		</author>
		<idno>ArXiv abs/2102.10989</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Contrastive Cross-domain Recommendation in Matching</title>
		<author>
			<persName><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shukai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyu</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Simple Convolutional Generative Network for Next Item Recommendation</title>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Arapakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">One Person, One Model, One World: Learning Continual User Representation without Forgetting</title>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoxiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beibei</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Big Bird: Transformers for Longer Sequences</title>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guru</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinava</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Onta??n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qifan</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Ahmed</surname></persName>
		</author>
		<idno>ArXiv abs/2007.14062</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Feature-level Deeper Self-Attention Network for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Tingting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengpeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajie</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanfeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename></persName>
		</author>
		<title level="m">S3-Rec: Self-Supervised Learning for</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
