<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automated Learning of Muscle-Actuated Locomotion Through Control Abstraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Radek</forename><surname>Grzeszczuk</surname></persName>
							<email>fradekjdtg@cs.toronto.edu</email>
						</author>
						<author>
							<persName><forename type="first">Demetri</forename><surname>Terzopoulos</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>1 10 King&apos;s College Road</addrLine>
									<postCode>M5S 1A4</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automated Learning of Muscle-Actuated Locomotion Through Control Abstraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">46630F617335D40EEB443C2FD90D0BAD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>learning</term>
					<term>locomotion</term>
					<term>control</term>
					<term>artificial life</term>
					<term>physicsbased modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a learning technique that automatically synthesizes realistic locomotion for the animation of physics-based models of animals. The method is especially suitable for animals with highly flexible, many-degree-of-freedom bodies and a considerable number of internal muscle actuators, such as snakes and fish. The multilevel learning process first performs repeated locomotion trials in search of actuator control functions that produce efficient locomotion, presuming virtually nothing about the form of these functions. Applying a short-time Fourier analysis, the learning process then abstracts control functions that produce effective locomotion into a compact representation which makes explicit the natural quasi-periodicities and coordination of the muscle actions. The artificial animals can finally put into practice the compact, efficient controllers that they have learned. Their locomotion learning abilities enable them to accomplish higher-level tasks specified by the animator while guided by sensory perception of their virtual world; e.g., locomotion to a visible target. We demonstrate physics-based animation of learned locomotion in dynamic models of land snakes, fishes, and even marine mammals that have trained themselves to perform "SeaWorld" stunts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The animation of animals in motion is an alluring but difficult problem. With the advent of visually realistic models of humans and lower animals, even small imperfections in the locomotion patterns can be objectionable. The most promising approach to achieving a satisfactory level of authenticity is to develop physically realistic artificial animals that employ internal actuators, or muscles, to closely approximate the movements of natural animal bodies. As these animal models become increasingly complex, however, animators can no longer be expected to control them manually. Sophisticated models must eventually assume the responsibility for their own sensorimotor control. Like real animals, they should be capable of learning to control themselves.</p><p>This paper addresses a natural question: Is it possible for a physics-based, muscle-actuated model of an animal to learn from first principles how to control its muscles in order to locomote in a natural fashion? Unlike prior work on motion synthesis, we target state-of-the-art animate models of at least the level of realism and complexity of the snakes and worms of Miller <ref type="bibr" target="#b7">[8]</ref> or the fish of Tu and Terzopoulos <ref type="bibr" target="#b16">[17]</ref>. In both of these cases, the muscle controllers that produce locomotion were carefully hand crafted using knowledge gleaned from the biomechanics literature <ref type="bibr" target="#b6">[7]</ref> and long hours of experimentation. Our goal in this paper is to devise algorithms that can provide such animal models the ability to learn how to locomote automatically, in a way that is inspired by the remarkable ability of real animals to acquire locomotion skills through action and perception.</p><p>At the foundation of our approach lies the notion that natural locomotion patterns are energetically efficient. This allows us to formalize the problem of learning realistic locomotion as one of optimizing a class of objective functionals, for which there are various solution techniques. We formulate a bottom-up, multilevel strategy for learning muscle controllers. At the early stages of the learning process,the animate model has no a priori knowledge about how to locomote. It is as if the animal had a fully functional body,but no motor control center in its "brain". Through practice-repeated locomotion trials with different muscle actions-the animal learns how to locomote with increasing effectiveness, by remembering actions that improve its motor skills as measured by the objective functional. Repeated improvements eventually produce life-like locomotion.</p><p>When basic locomotive skill is achieved, the animate models abstract the low-level muscle control functions that they have learned and train themselves to perform some specific higher-level motor tasks. The learning algorithm abstracts detailed muscle control functions into a highly compact representation. The representation now emphasizes the natural quasi-periodicities of effective muscle actions and makes explicit the coordination among multiple muscles that has led to effective locomotion. Finally, the artificial animals can put into practice the compact, efficient controllers that they have learned in order to accomplish the sorts of tasks that animators would have them do.</p><p>We are particularly interested in realistic motion synthesis for three dimensional models of animals that are highly deformable and can move continuously within their virtual worlds. Plates 1-5 show frames from animations of animal models that we have created, which have learned to locomote and perform interesting motor tasks automatically. We use spring-mass systems to construct our models, following the work of <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref>. This results in biomechanical models with numerous degrees of freedom and many parameters to control. The reader should peruse <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref> to become familiar with the details of the models.</p><p>An example will serve to illustrate the challenges of controlling highly deformable body models: Fig. <ref type="figure" target="#fig_0">1</ref> illustrates a biomechanical model of a Sonoral coral snake <ref type="bibr" target="#b3">[4]</ref> that we use in one of our animations (Plate 1). The body consists of 10 segments. Each segment has two pairs of longitudinal muscle springs that are under the active control of the snake's brain. All other springs are passive dynamic elements that maintain the structural integrity of the body. The snake can actuate its body by varying the rest lengths of the 40 muscle springs over time. To simplify matters slightly, paired muscles on either side in each segment are actuated synchronously, and this yields a total of 20 actuators. Clearly, it is counterproductive to provide the animator direct control over so many actuators. Instead, we would like the snake to train itself to control its body. We will develop algorithms that will enable its brain to exercise its body until it discovers the actuator coordination needed to achieve efficient serpentine locomotion. The snake will monitor the progress of the learning cycle using an objective functional that incorporates sensory feedback about its actions.</p><p>An advantage of our approach from the point of view of the animator is its generality. In principle, it is applicable to all animate models motivated by internal muscles, whether highly deformable, or articulate. In this paper, we demonstrate its power using 4 different, highly deformable animal body models in varied media-terra firma, water, and air (see Appendix A). Another advantage is that the approach allows us to equip our models with sensors that enable them to perceive their environment. Sensory perception is modeled through the objective functional to be optimized. The sensory contribution to the objective functional represents the animal's perception of the degree to which its goal has been achieved. Making the artificial animal perceptually aware allows it to handle tasks that depend on dynamic events in the environment and gives the animator a potent tool with which to control the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>The issue of control is central to physics-based animation research. Optimal control methods formulate the control problem in terms of an objective functional which must be minimized over a time interval, subject to the differential equations of motion of the physical model <ref type="bibr" target="#b0">[1]</ref>. The "spacetime constraints" method <ref type="bibr" target="#b18">[19]</ref> has attracted a certain following (e.g., <ref type="bibr" target="#b2">[3]</ref>), but it is problematic because, in principle, it treats physics as a penalty constraint (that can be "stretched like a spring") and, in practice, the need to symbolically differentiate the equations of motion renders it impractical for all but the simplest physical models.</p><p>We pursue a different approach toward locomotion control that is suitable for complex physical models. The approach is inspired by the "direct dynamics" technique which was described in the control literature by Goh and Teo <ref type="bibr" target="#b4">[5]</ref> and earlier references cited therein. Direct dynamics prescribes a generate-and-test strategy that optimizes a control objective functional through repeated forward dynamic simulation and motion evaluation.</p><p>The direct dynamics technique was developed further to control articulated musculoskeletal models in <ref type="bibr" target="#b9">[10]</ref> and it has seen application in the mainstream graphics literature to the control of planar articulated figures <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b8">9]</ref>. Pandy et al. <ref type="bibr" target="#b9">[10]</ref> search the model actuator space for optimal controllers, but they do not perform global optimization. Van de Panne and Fiume <ref type="bibr" target="#b17">[18]</ref> use simulated annealing for global optimization. Their models are equipped with simple sensors that probe the environment and use the sensory information to influence control decisions. Ngo and Marks' <ref type="bibr" target="#b8">[9]</ref> stimulus-response control algorithm presents a similar approach. They apply the genetic algorithm to find optimal controllers. The genetic algorithm is also used in the recent work of Sims <ref type="bibr" target="#b14">[15]</ref>. Risdale <ref type="bibr" target="#b13">[14]</ref> reports an early effort at controller synthesis for articulated figures from training examples using neural networks.</p><p>A characteristic of prior methods that tends to limit them to relatively simple planar models with few actuators is that they attempt to tackle the control problem at only a single level of abstraction. Typically, they deal with the control problem at an abstract level, say, in terms of a small number of controller network weights <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b14">15]</ref> or whole body motions <ref type="bibr" target="#b8">[9]</ref>. We advocate a multilevel controller learning technique that can handle complex models even though it seeks, based on first principles, optimal muscle actuation functions in a very concrete representation that makes the weakest possible assumptions. Thus the learning process is bootstrapped essentially from scratch. Earlier versions of our work were presented in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Overview</head><p>We describe our multilevel learning technique in the following two sections. Section 2 presents the strategy for learning low level controllers. Low level control learning is time consuming because of the high dimensionality of the search space. It is therefore prudent to reuse controllers. To this end, Section 3 presents the strategy for abstracting high level controllers. The abstraction step dramatically reduces dimensionality, stores the reduced description in the animal's memory, and permits the control problems to be defined in terms of higher level motor goals. This approach leads naturally to reusable solutions. We search for good low level control solutions for a set of simple tasks and use them as building blocks to achieve higher level goals. Section 4 presents a thorough experimental evaluation of our learning approach and more results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Learning Low Level Control</head><p>Our low-level learning technique repeatedly generates a controller, applies it to drive a short-time forward simulation of the dynamic body model, and measures its effectiveness at producing locomotion using an objective functional. Typically, this low-level motor learning cycle is lengthy (as it can be in real animals, such as humans). However, it is simple and ultimately quite effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Biomechanical Models, Muscles, Actuators, Controllers</head><p>The biomechanical models that we employ are constructed of nodal masses and springs, as is detailed in Appendix A. Their dynamics is specified by the Lagrangian equations of motion</p><formula xml:id="formula_0">mi ẍi + i ẋi + X j2N i f s ij = fi<label>(1)</label></formula><p>where node i has mass mi, position xi(t) = xi(t);yi(t); zi(t)], velocity ẋ, and damping factor i, and where fi is an external force.</p><p>Spring Sij, which connects node i to neighboring nodes j 2 Ni, exerts the force f s ij (t) = ?(cijeij + ij ėij)rij=jjrij jj on node i (and it exerts the force ?f s ij on node j), where cij is the elastic constant, ij is the damping constant, and eij(t) = jjrijjj?lij is the deformation of the spring with separation vector rij(t) = xj ? xi.</p><p>The natural length of the spring is lij.</p><p>Some of the springs in the biomechanical model play the role of contractile muscles. Muscles contract as their natural length lij decreases under the autonomous control of the motor center of the artificial animal's brain <ref type="bibr" target="#b16">[17]</ref>. To dynamically contract a muscle, the brain must supply an activation function a(t) to the muscle. This continuous time function has range 0; 1], with 0 corresponding to a fully relaxed muscle of length l r ij and 1 to a fully contracted muscle of length l c ij . More specifically, for a muscle spring, lij = al c ij + (1 ? a)l r ij .</p><p>Typically, individual muscles form muscle groups, called actuators, that are activated in unison. Referring to Fig. <ref type="figure" target="#fig_0">1</ref> for example, the 40 muscles in the snake model are grouped pairwise in each segment to form 10 left actuators and 10 right actuators. Each actuator i is activated by a scalar actuation function ui(t), whose range is again normalized to 0; 1]. The actuation function transforms straightforwardly into activation functions for each muscle in the actuator. Thus, to control the snake's body we must specify the actuation functions u(t) = u1(t); : : : ; ui(t); : : : ; uN(t)] 0 , where N = 20.</p><p>The continuous vector-valued function of time u(t) is called the controller and its job is to produce locomotion. Controllers may be stored within the artificial animal's motor control center.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Objective Functional</head><p>A continuous objective functional E provides a quantitative measure of the progress of the locomotion learning process. The functional is the weighted sum of a term Eu that evaluates the controller u(t) and a term Ev that evaluates the motion v(t) that the controller produces in a time interval t0 t t1, with smaller values of E indicating better controllers u. Mathematically,</p><formula xml:id="formula_1">E(u(t)) = Z t 1 t 0 ? 1Eu (u(t)) + 2Ev (v(t)) dt; (2)</formula><p>where 1 and 2 are scalar weights. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates this schematically. It is important to note that the complexity of our models precludes the closed-form evaluation of E. As the figure indicates, to compute E, the artificial animal must first engage u(t) to produce a motion v(t) with its body (in order to evaluate term Ev). This is done through forward simulation of the biomechanical model over the time interval t0 t t1 using the controller u(t).</p><p>We may want to promote a preference for controllers with certain qualities via the controller evaluation term Eu. For example, we can guide the optimization of E by discouraging large, rapid fluctuations of u, since chaotic actuations are usually energy inefficient. We encourage lower amplitude, smoother controllers through the function</p><formula xml:id="formula_2">Eu = 1 2 1 du dt 2 + 2 d 2 u dt 2 2 ;<label>(3)</label></formula><p>with weighting factors 1 and 2. The two component terms in <ref type="bibr" target="#b2">(3)</ref> are potential energy densities of linear and cubic variational splines in time, respectively. The former penalizes actuation amplitudes, while the latter penalizes actuation variation. The distinction between good and bad control functions also depends on the goals that the animal must accomplish. In our learning experiments we used trajectory criteria Ev such as the final distance to the goal, the deviation from a desired speed, etc. These and other criteria will be discussed shortly in conjunction with specific experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Time and Frequency Domain Discrete Controllers</head><p>To solve the low level control problem, we must optimize the objective functional (2). This cannot be done analytically. We convert this continuous optimal control problem to an algebraic parameter optimization problem <ref type="bibr" target="#b4">[5]</ref> by parameterizing the controller through discretization using basis functions. Mathematically, we express</p><formula xml:id="formula_3">ui(t) = M X j=1 u j i B j (t);<label>(4)</label></formula><p>where the u j i are scalar parameters and the B j (t), 1 j M are (vector-valued) temporal basis functions. There are two qualitatively different choices of basis functions-local and global.</p><p>In the local discretization, the parameters u j i are nodal variables and the B j (t) can be spline basis functions. The simplest case is when the u j i are evenly distributed in the time interval and the B j (t) are tent functions centered on the nodes with support extending to nearest neighbor nodes, so that u(t) is the linear interpolation of the nodal variables (Fig. <ref type="figure" target="#fig_3">3</ref>, top). Smoother B-splines can be used in a similar fashion. Since the nodal parameters are naturally ordered in a time sequence, we will refer to locally discretized controllers as time domain controllers.  sinusoidal basis functions B j (t) = cos(! j t + j ).</p><formula xml:id="formula_4">1 u 2 u 1 u u 1 u 1 u 2 2 u 2 u 2 2 1 u (t) u (t)</formula><formula xml:id="formula_5">u1(t) = u 1 1 B 1 + u 2 1 B 2 + u 3 1 B 3 + u 4 1 B 4 + u 5 1 B 5 + u 6 1 B 6 + u 7 1 B 7 + u 8 1 B 8 + u 9 1 B 9 u2(t) = u 1 2 B 1 + u 2 2 B 2 + u 3 2 B 3 + u 4 2 B 4 + u 5 2 B 5 + u 6 2 B 6 + u 7 2 B 7 + u 8 2 B 8 + u 9 2 B 9</formula><p>In the global discretization, the support of the B j (t) covers the entire temporal domain t0 t t1. A standard choice is sinusoidal basis functions B j (t) = cos(! j t + j ) where ! j is the angular frequency and j is the phase, and the parameters u j i are amplitudes (Fig. <ref type="figure" target="#fig_3">3,</ref><ref type="figure">bottom</ref>). We will refer to controllers discretized globally using sinusoidal bases of different frequencies and phases as frequency domain controllers.</p><p>The time domain and frequency domain representations offer different benefits and drawbacks. The time domain controller yields a faster low-level learning rate. This issue is discussed in detail in Section 4.1. The frequency domain controller, on the other hand, does not require a change of basis during the abstraction process described in Section 3. It can also sometimes be extended arbitrarily in time since it favors periodicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Optimization of the Discrete Objective Function</head><p>Since u(t) has N basis functions, the discretized controller is represented using NM parameters. Substituting (4), into the continuous objective functional (2), we approximate it by the discrete objective function E( u 1 1 ; : : : ; u M N ] 0 ).</p><p>Learning low level control amounts to using an optimization algorithm to iteratively update the parameters of a time domain or frequency domain controller so as to maximize the discrete objective function and produce increasingly better locomotion. We have used both simulated annealing and the simplex method to optimize the objective function. The reader should refer to a text such as <ref type="bibr" target="#b11">[12]</ref> for details about these optimization methods.</p><p>Simulated annealing has three features that make it particularly suitable for our application. First, it is applicable to problems with a large number of variables yielding search spaces large enough to make exhaustive search prohibitive. Second, it does not require gradient information about the objective function. Analytic gradients are not directly attainable in our situation since evaluating E requires a forward dynamic simulation of the animal. Third, it avoids getting trapped in local suboptima of E. In fact, given a sufficiently slow annealing schedule, it will find a global optimum of the objective functional. Robustness against local suboptima can be important in obtaining control functions that produce realistic motion. The benefit of using the simplex method over simulated annealing in some cases is its faster convergence rate. On the other hand, since it is a local optimization technique, strictly speaking, it can be applied successfully only to the class of optimization problems in which the topography of E is globally convex. Section 4.1 will describe in more detail the advantages and pitfalls of both methods when applied to the low level learning problem.</p><p>All of the biomechanical models described in Appendix A have demonstrated the ability to learn effective low level time domain locomotion controllers. Plates 1, 2, and 3 show frames from animations with controllers that have been learned by the snake, ray, and shark models, which produce natural and effective locomotion. Plate 3 illustrates a race among four sharks that have learned for different durations. The shark that is furthest from the camera has learned how to locomote for the shortest period of time, which yields muscle control functions that are essentially random and achieve negligible locomotion. Sharks closer to the camera have learned for progressively longer periods of time. The closest shark, which locomotes the best wins the race.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Abstracting High Level Control</head><p>It is time consuming to learn a good solution for a low level controller because of the high dimensionality of the problem (large NM), the lack of gradient information to accelerate the optimization of the objective functional, and the presence of suboptimal traps that must be avoided. Consequently, it is costly to produce animation by perpetually generating new controllers. The learning procedure must be able to abstract compact higher level controllers from the low level controllers that have been learned, retain the abstracted controllers, and apply them to future locomotion tasks.</p><p>The process of abstraction takes the form of a dimensionality reducing change of representation. More specifically, it seeks to compress the many parameters of the discrete controllers to a compact form in terms of a handful of basis functions. Natural, steady-state locomotion patterns tend to be quasi-periodic and they can be abstracted very effectively without substantial loss. The natural choice, therefore, is to represent abstracted controllers using the global sinusoidal basis functions discussed earlier. For the frequency domain controller, the dimensionality reduction is achieved trivially by retaining all basis functions whose amplitudes u j i exceed a low threshold and suppressing those below threshold. This results in a small set of significant basis functions with associated amplitudes that constitute the abstracted controller. To abstract a time domain controller, we apply the fast Fourier transform (FFT) <ref type="bibr" target="#b11">[12]</ref> to the parameters of the time domain controller and then suppress the below-threshold amplitudes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Using Abstracted Controllers</head><p>Typically, our artificial animals are put through a "basic training" regimen of primitive motor tasks that it must learn, such as locomoting at different speeds and executing turns of different radii. They learn effective low level controllers for each task and retain compact representations of these controllers through controller abstraction. The animals subsequently put the abstractions that they have learned into practice to accomplish higher level tasks, such as target tracking or leaping through the air. To this end, abstracted controllers are concatenated in sequence, with each controller slightly overlapping the next. To eliminate discontinuities, temporally adjacent controllers are smoothly blended together by linearly fading and summing them over a small, fixed region of overlap, approximately 5% of each controller (Fig. <ref type="figure" target="#fig_6">4</ref>). Currently we use abstracted controllers in two ways. In one scenario, the animated model has learned a repertoire of abstracted controllers that it applies in a greedy fashion to navigate in the direction of a target. It modifies its locomotion strategy periodically by invoking the abstracted controller that gives it the greatest immediate gain over the subsequent time interval. For example, Fig. <ref type="figure">5</ref> shows a path generated by the shark model using this method as it is presented with a series of targets. The shark has learned six basic abstracted controllers to accomplish this task: do-nothing, gostraight, sharp-turn-left, sharp-turn-right, wide-turn-left, and wideturn-right. It then discovered how to sequence these controllers, and for what durations to apply them in order to locomote to successive targets indicated by black dots. The circles on the path in Fig. <ref type="figure">5</ref> indicate positions where the shark reevaluated its current strategy. Changes in the path's direction indicate that the shark has switched to a different controller which provides a bigger immediate gain. Plate 4 shows rendered frames from the locomotion animation with the targets rendered as red buoys. This method is inexpensive and can be made to work in real time. Unfortunately, the greedy strategy is bound to fail on a problem that requires careful planning.  The second method overcomes the limitations of the greedy strategy by learning composite abstracted controllers that accomplish complex locomotion tasks. Consider the spectacular stunts performed by marine mammals that elicit applause at theme parks like "SeaWorld". We can treat a leap through the air as a complex task that can be achieved using simpler tasks; e.g., diving deep beneath a suitable leap point, surfacing vigorously to gain momentum, maintaining balance during the ballistic flight through the air, and splashing down dramatically with a belly flop.</p><p>We have developed an automatic learning technique that constructs a macro jump controller of this sort as an optimized sequence of basic abstracted controllers. The optimization process is, in principle, similar to the one in low level learning. It uses simulated annealing for optimization, but rather than optimizing over nodal parameters or frequency parameters, it optimizes over the selection, ordering, and duration of abstracted controllers. Thus the animal model applying this method learns effective macro controllers of the type shown at the bottom of Fig. <ref type="figure" target="#fig_6">4</ref> by optimizing over a learned repertoire of basic abstracted controllers illustrated at the top of the figure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Composing Macro Controllers</head><p>We first train the artificial dolphin so that it learns controllers for 5 basic motor tasks: turn-down, turn-up, turn-left, turn-right, and move-forward. We then give it the task of performing a stunt like the one described above and the dolphin discovers a combination of controllers that accomplishes the stunt. In particular, it discovers that it must build up momentum by thrusting from deep in the virtual pool of water up towards the surface and exploit this momentum to leap out of the water. Plate 5(a) shows a frame as the dolphin exits the water. The dolphin can also learn to perform tricks while in the air. Plate 5(b) shows it using its nose to bounce a large beach-ball off a support. The dolphin can learn to control the angular momentum of its body while exiting the water and while in ballistic flight so that it can perform aerial spins and somersaults. Plate 5(c) shows it in the midst of a somersault in which it has just bounced the ball with its tail instead of its nose. Plate 5(d) shows the dolphin right after splashdown. In this instance it has made a dramatic bellyflop splash. By discovering controllers that enable it to control its body in these complex ways, the dolphin can amuse and entertain the animator, who would be hard pressed to design similar controllers by hand for a physics-based model with as many control parameters as the dolphin model has.</p><p>To train the dolphin to perform a variety of stunts we introduced additional "style" terms into the objective function that afford extra control on the animal's trajectory in the air. For example, a simple jump was learned by optimizing over the maximum height at some point in time. In order to train the dolphin to jump a hurdle, we introduced a term to control its orientation as it clears the hurdle-at the apex of its trajectory, it should be in a horizontal orientation and it should face downward upon reentry. The somersault controller was discovered by adding a term that encouraged maximum angular velocity of the body in flight. We can maximize or minimize the area of the animal's body that hits the water upon reentry for crowddrenching splashes or for high scores from the judges for a clean dive.</p><p>Different style terms can, in principle, be added indefinitely to the control function. The only limitation seems to be the increasing complexity of the optimization. We have noted that although it can produce some interesting results, simulated annealing is not especially well suited to this kind of optimization problem. We suspect that this is due to the combinatorial nature of the problem and the fact that simulated annealing does not take advantage of partial solutions that it finds along the way, but instead starts with a new set of parameters at every iteration of the optimization process. Unfortunately, at a high level of abstraction sometimes even small changes in the set of parameters produce drastically different trajectories. Genetic algorithms may perform better on such problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Additional Experiments and Results</head><p>This section presents a more thorough experimental study of our approach and reports additional results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance of the Optimizers</head><p>Fig. <ref type="figure">6</ref>(a) compares the performance of the simplex method and simulated annealing in seeking optimal time and frequency domain controllers for the shark model given the task of locomoting to a specified goal location; i.e., Ev = jjdgjj<ref type="foot" target="#foot_0">2</ref> , where dg is the separation vector between the nose node of the shark and the goal point.</p><p>The term Eu (3) in the objective functional (2) was disabled for these tests ( 2 = 0). For simplicity, the 4 muscles in each segment were grouped into a single actuator (N = 3 actuators total), with the left muscle pair receiving contraction signals that are exactly out of phase with the right muscle pair. A time interval was discretized using M = 15 parameters; hence, the dimensionality of the search space was NM = 45. Both methods converge to good time domain controllers. The simplex method yields a final objective functional value of Eo = 0:49 after approximately 500 iterations. Simulated annealing finds a slightly better solution, Eo = 0:42, but only after 3500 iterations.</p><p>For frequency domain controllers, the results differ substantially. Simulated annealing performs almost as well as for the time domain controller, yielding an objective function value of Eo = 0:52 after 3500 iterations. 2 However, the simplex method does much worseit fails to get below Eo = 0:65. Fig. <ref type="figure">6(b-c</ref>) compares the convergence for simulated annealing on both types of controllers. The results are better for the objective function represented in the time domain (Fig. <ref type="figure">6(b)</ref>) than for the frequency domain representation (Fig. <ref type="figure">6(c)</ref>). For the time domain representation we need approximately 700 iterations to get very close to the global minimum. The number of iterations for the frequency domain representation is much greater.</p><p>The above results suggest that it is much harder to optimize the objective using frequency domain controllers. To understand why, we plotted E against pairs of randomly chosen parameters u j i (labeled x and y in the plots), using both time and frequency domain representations. We stepped the selected parameters through a range of values while keeping the other parameters constant and evaluated the objective function repeatedly to obtain a 3D surface plot (each repetition required a forward simulation of the locomotion). The plot in Fig. <ref type="figure">7</ref>(a) reveals the simple convex topography of E for time domain controllers, while the plot in Fig. <ref type="figure">7</ref>(b) reveals the much more irregular, nonconvex topography of E for frequency domain controllers.</p><p>Evidently, small changes in the local basis functions of the time domain controller produce small, well-behaved changes in the value of the objective function. By contrast, small changes in the global basis functions of the frequency domain controller produce relatively larger, more irregular changes in the value of the objective function.</p><p>The many local minima in the topography of the objective function associated with the frequency domain controller lead to failure of the simplex method and they present more of a challenge to simulated annealing. The convex structure of the objective function associated with the time domain controller allows both annealing and simplex to converge very quickly. Moreover, they often yield better time domain controllers than frequency domain controllers. We conclude that the time domain controller representation is a worthwhile one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Influencing Controllers via the Objective Functional</head><p>In Section 2.2 we discussed how the term Eu in (2) that evaluates controllers allows us to influence the motion. For example, we can discourage chaotic motions. This section investigates the effect of different Eu terms in more detail. Again, we employ the shark with the same goal Ev as in the previous section. Fig. <ref type="figure" target="#fig_8">8(a)</ref> shows the results obtained with the time domain representation for 2 = 0, hence the discrete term Eu = 1=2h 2 (u j+1 i ? u j i ) 2 , where h is the timestep between nodal parameters. The objec- tive function was evaluated for 1 = 0:0; 0:1; 0:2 (top to bottom). As the value of 1 increases, both the amplitude and the frequency 1. Usually 0:9, but Fig. <ref type="figure">6(b-c</ref>) shows the results obtained with different schedules. The maximum number of steps before the temperature drop is 10N M and the minimum number of accepted perturbations before the temperature drop is NM For N = 15 it takes about one hour on an SGI Indigo workstation to get a solution for each control function. At each step the values of all parameters are perturbed randomly. The perturbation is bounded by 10% of the range of admissible values. So, for example, if the maximum contraction of the muscle is 20% of its relaxed length, each perturbation will be at most 2%. The bound on the perturbation remains fixed over the annealing process. This yields much faster convergence than if we decreased the magnitude of the perturbation with temperature. of the learned actuation functions drop and the shark learns locomotion controllers that result in less energy expenditure. Fig. <ref type="figure" target="#fig_8">8(b)</ref> shows the results obtained with 1 = 0, hence the discrete term Eu = 2=2h 4 (u j+1 i ? 2u j i + u j?1 i ) 2 with 2 = 0:0; 0:002; 0:006 (top to bottom). As the value of increases, the amplitude of the learned actuation functions remains constant and only the frequency decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Abstracted Learning Results</head><p>Next, we report results for the shark and the snake in abstracting learned time domain controllers for straight locomotion and left turns. Right turn controllers were obtained by swapping signals sent to left and right actuators.</p><p>To obtain good abstracted controllers for the shark, it was sufficient for both straight motion and left turn to retain the single dominant mode of the FFT. Fig. <ref type="figure" target="#fig_9">9</ref>(a) shows learned controllers for the shark swimming straight. In this experiment, the left and right muscle pairs in each segment constitute independent actuators, but note how the animal has learned to actuate its left muscles approximately out of phase with those on the right side. The posterior segment muscles contract with roughly half the frequency of the other muscles and the muscles on either side of the body are activated in sequence with a slight phase shift. For the swim left It suffices to use two primary modes of the Fourier transform to get an effective abstracted controller for the turning snake. For straight locomotion (Fig. <ref type="figure" target="#fig_9">9(c</ref>)) it is difficult to interpret the time domain actuation functions. However, if we look at the learned abstracted controller for straight locomotion, we can clearly see that the main modes have the same frequency, but their phase is shifted slightly, as expected. When a real snake turns, it first coils itself in the direction of the turn then switches back to its normal serpentine mode of locomotion. This pattern is revealed in the automatically learned turn controller shown in Fig. <ref type="figure" target="#fig_9">9(d)</ref>. First, all the muscles on the right side of the body relax and all the muscles on the left side contract. Then they resume their action for straight serpentine locomotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Biomechanical Model Structure and Simulation</head><p>Animals such as snakes, worms, fishes, and marine mammals, with highly flexible bodies are well suited to mechanical modeling using spring-mass systems. All of our animal body models consist of an internal biomechanical model with contractile muscles coupled to an external, texture-mapped, NURBS surface display model. Fig. <ref type="figure" target="#fig_0">1</ref> shows the spring-mass system for the coral snake (Micruroides euryxanthus), which is similar to the one in <ref type="bibr" target="#b7">[8]</ref>. Plate 1 shows the display model. The muscle springs can contract to 30% of their relaxed length. The body mass is distributed evenly among all nodes. Fig. <ref type="figure" target="#fig_5">10</ref> shows the spring-mass system for the Leopard shark (Triakis semifasciata) <ref type="bibr" target="#b1">[2]</ref>, which is similar to the fish model in <ref type="bibr" target="#b16">[17]</ref>. Plates 3 and 4 show the display model. The 4 posterior muscles can contract to 10% of their relaxed length; the 8 other muscles to 20%. The figure specifies the nodal mass distribution.</p><p>We model a Heaviside's dolphin (Cephalorhynchus heavisidii) <ref type="bibr" target="#b10">[11]</ref> (Plate 5 shows the display model) straightforwardly by turning the shark spring-mass system on its side, such that the muscles serve as caudal (tail) fin elevator and depressors. We equip the dolphin with functional pectoral fins that allow it to roll, pitch, and yaw in the water (see <ref type="bibr" target="#b16">[17]</ref> for details about fins).</p><p>Fig. <ref type="figure" target="#fig_5">11</ref> shows the spring-mass system for the Kuhl's stingray (Dasyatis kuhlii) <ref type="bibr" target="#b12">[13]</ref>. Plate 2 shows the display model. Four left and 4 right elevator muscles and an equal number of depressor muscles are capable of flexing the wings by contracting to 20% of their relaxed length. Mass is distributed evenly among all the nodes.</p><p>To model snake locomotion, we use directional friction against the ground which generates reaction forces that move the body forward, as described in <ref type="bibr" target="#b7">[8]</ref>. To model marine animal locomotion, we compute hydrodynamic reaction forces acting on each of the model's faces, as described in <ref type="bibr" target="#b16">[17]</ref>. These forces produce external nodal forces fi in the equations of motion <ref type="bibr" target="#b0">(1)</ref>.</p><p>We use a stable, efficient semi-implicit Euler method <ref type="bibr" target="#b11">[12]</ref> to numerically integrate these ODEs. It is implicit in the internal forces on the lhs of (1) and explicit in the external forces fi.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The snake biomechanical model consists of nodal masses (points) and springs (lines). It has twenty independent actuators (muscle springs): ten on the left side of the body and ten on the right side. Each actuator comprises a pair of synchronous muscles. The numbers along the body indicate nodal masses in cross sectional planes. The cross-springs, shown in only one segment, maintain the structural integrity of the body.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The objective function guiding the optimization is a weighted sum of terms that evaluate the trajectory and the control function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Simple time domain controller (top) with two control functions u1(t) and u2(t). Each function is a piecewise linear polynomial generated by 9 control points. Simple frequency domain controller (bottom) with two control functions, each a sum of 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: Higher level controller for jumping out of water is constructed from a set of abstracted basic controllers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Plate 1 :</head><label>1</label><figDesc>Locomotion pattern learned by the artificial snake. Plate 2: Locomotion pattern learned by the artificial ray. Plate 3: Shark race illustrates the progress of learning (see text).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Plate 4 :</head><label>4</label><figDesc>Target tracking using abstracted controllers (see text).Plate 5: SeaWorld tricks learned by the artificial dolphin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: (a) Performance comparison of the simplex method and of simulated annealing. Convergence rate of simulated annealing on the time domain controller (b) and on the frequency controller (c) with cooling rates: T0 = 0:8, T1 = 0:85, and T2 = 0:9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Influence of Eu on controller: (a) 2 = 0; (b) 1 = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Learned controller for the swim straight (a) and the left turn (b) for the shark. Learned controller for the straight motion (c) and the left turn (d) for the snake. For each part: (top) learned time domain controller (dotted lines indicate actuator functions for left side of body, solid lines indicate actuator functions for right side); (center) primary modes of controller FFT (radius of circles indicates mode amplitudes, radial distances from center of surrounding circle indicate frequencies, angular positions within surrounding circle indicate phases); (bottom) abstracted controller obtained by retaining primary modes.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We start the simulated annealing procedure at the temperature T0 = 0:5. The annealing schedule is T i+1 = Ti where 0</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Xiaoyuan Tu, who developed the original fish biomechanical model, for her software and cooperation, and Geoffrey Hinton for valuable discussions. This work was made possible by a grant from the Natural Sciences and Engineering Research Council of Canada. DT is a fellow of the Canadian Institute for Advanced Research.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Motion interpolation by optimal control</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Brotman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Netravali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="309" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Sharks of North American Waters</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Castro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Texas Unviersity Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interactive spacetime control for animation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="293" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Venomous Reptiles of North America</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Ernst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Smithsonian Institution Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Control parameterization: A unified approach to optimal control problems with general constraints</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Teo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated learning of muscle based locomotion through control abstraction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. of Comp. Sci., Univ. of Toronto</title>
		<imprint>
			<date type="published" when="1994-01">January 1994</date>
			<pubPlace>Toronto, ON</pubPlace>
		</imprint>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring Biomechanics: Animals in Motion</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Mcneill</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American Library</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The motion dynamics of snakes and worms</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S P</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marks</surname></persName>
		</author>
		<title level="m">Spacetime constraints revisited. Proc. ACM SIGGRAPH</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A parameter optimization approach for the optimal control of large-scale musculoskeletal systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Pandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ASME</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">450</biblScope>
			<date type="published" when="1992-11">November 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heaviside&apos;s dolphin</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Abernethy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Marine Mammals</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="289" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Flannery</surname></persName>
		</author>
		<title level="m">Numerical Recipes: The Art of Scientific Computing, Second Edition</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fishes of the Great Barrier Reef and Coral Sea</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Rendal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Steene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Univ. of Hawaii Press</publisher>
			<pubPlace>Honolulu, HI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Connectionist modeling of skill dynamics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Risdale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization and Computer Animation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="66" to="72" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evolving virtual creatures</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Artificial fishes: Autonomous locomotion, perception, behavior, and learning in a simulated physical world</title>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="327" to="351" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Artificial fishes: Physics, locomotion, perception, behavior</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sensor-actuator networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van De Panne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fiume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="335" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spacetime constraints. Proc. ACM SIG-GRAPH</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="159" to="167" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
