<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Out of Hand for Hardware? Within Reach for Software! Zhihong Luo</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">U</forename><forename type="middle">C</forename><surname>Berkeley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emmanuel</forename><surname>Amaro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Ousterhout</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sylvia</forename><surname>Ratnasamy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><surname>Shenker</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhihong</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Silvery</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">VMware Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">UC San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">UC Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">UC Berkeley</orgName>
								<orgName type="institution" key="instit2">ICSI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Out of Hand for Hardware? Within Reach for Software! Zhihong Luo</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3593856.3595898</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CPU stall</term>
					<term>coroutine</term>
					<term>profile-guided yield instrumentation</term>
					<term>asymmetric concurrency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Events that take 10s to 100s of ns like cache misses increasingly cause CPU stalls. However, hiding the latency of these events is challenging: hardware mechanisms suffer from the lack of flexibility, whereas prior software mechanisms fall short due to large overhead and limited event visibility. In this paper, we argue that with a combination of two emerging techniques -light-weight coroutines and sample-based profiling, hiding these events in software is within reach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Software and its engineering ? Coroutines; Compilers; Software system structures; Concurrency control.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To avoid wasting processor cycles while waiting for the result of some long event, an effective strategy is to hide the event latency by concurrently executing independent instructions. Applying this strategy to either hardware or software, people have arrived at satisfactory solutions to events with durations at both ends of the spectrum: for events that take a very small amount of time (e.g., less than 10 ns), such as L1 misses and complex arithmetic instructions, hardware mechanisms like out-of-order executions can efficiently detect them and  instantaneously interleave instructions to minimize CPU stalls <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b58">59]</ref>; for events that run for sufficiently long (e.g., over 1 ?s), such as disk I/O and using offboard accelerators (e.g., GPU), software mechanisms like OS process scheduling offer great flexibility with reasonable overhead and provide functionalities like on-demand scaling of concurrency and fine-grained control over application performance <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b63">64]</ref>.</p><p>However, the solution is less clear for events with durations in the middle of the spectrum, ranging from 10s to 100s of ns, such as L2 cache misses, memory accesses and operations with onboard accelerators. Events in this range account for a significant portion of CPU stalls -some widely-used modern applications lose more than 60% of all processor cycles due to memory-bound CPU stalls <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>, and are getting prevalent -there is an increasing number of onboard accelerators in modern server processors <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b31">32]</ref>. For these events, hardware mechanisms like simultaneous multithreading (SMT) (e.g., Intel's Hyper-threading) suffer from limitations due to their lack of flexibility, which is manifested in two aspects: limited degrees of concurrency and negative impacts to application performance. In terms of degrees of concurrency, modern CPUs have only 2 to 8 threads per physical core, which is insufficient for SMT to fully hide the latency of events like memory accesses <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b52">53]</ref>, especially for applications that have large memory footprints and thus frequently incur cache misses (e.g., data analytics <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71]</ref>). In terms of application performance, SMT is known to likely lead to significantly increased latencies <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b67">68]</ref>. This is because SMT focuses solely on multiplexing instruction streams to best utilize core resources, without explicitly managing the impacts to application performance, which the hardware has little visibility to. While there are proposals <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b66">67]</ref> that mitigate these issues by redesigning the hardware (e.g., supporting a large number of software-controlled hardware threads), these proposals require significant hardware changes and are thus not feasible today.</p><p>Since relying on hardware to handle events of medium durations is unsatisfactory, how about hiding them in software? Unlike hardware mechanisms, software mechanisms have the flexibility to support high degrees of concurrency and minimize negative impacts to application latency: the former is due to using software contexts, and the latter is due to controlling application performance while hiding events for CPU efficiency. However, hiding these events in software is highly challenging due to software's lack of efficiency, in the form of large switching overhead and limited event visibility. In terms of switching overhead, for traditional threads of executions like OS processes and kernel threads, context switches take several hundreds of nanoseconds or even a few microseconds <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b37">38]</ref>, which is prohibitively expensive for hiding the target events. In terms of event visibility, a software mechanism must be able to detect the presence of an event in order to hide it, which is challenging for events like cache misses that are not exposed to software.</p><p>Fortunately, we see a way forward by mitigating the aforementioned inefficiency of software mechanisms via a novel combination of two emerging techniques: light-weight coroutines <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b62">63]</ref> and sample-based profiling <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b65">66]</ref>. First, by adopting cooperative multitasking, light-weight coroutines support fast context switchings that take only several nanoseconds <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b35">36]</ref>, allowing us to interleave coroutine executions with low overhead. Second, sample-based profiling leverages hardware performance counters available in modern CPUs to sample hardware events of interest in production with negligible overhead. The profiled information is then used to guide instrumentation of coroutines, so that an instrumented coroutine will appropriately yield to hide the latency of events. Fundamentally speaking, sample-based profiling provides software with the much needed visibility to hardware events, while allowing flexibility based on application characteristic. Note that both techniques require no changes to existing hardware and are getting adopted in production systems <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b71">72]</ref>, which makes them ideal building blocks for easily deployable software mechanisms.</p><p>To demonstrate the feasibility of this idea, we present a design proposal targeting L2/L3 cache misses, where we walk through the set of important design choices that one needs to make as they try to leverage light-weight coroutines and profile-guided instrumentations. Our proposed mechanism is carefully designed to meet three properties that we believe can facilitate adoption of the mechanism: transparent interface, general applicability and controllable latency. We elaborate on the rationale underlying our design choices in the hope of showing that our proposed design not only fulfills the desired properties, but more importantly exhibit many other possibilities future work can explore and investigate.</p><p>In the rest of this paper, we elaborate on the enabling techniques of our proposal ( ?2), present a design for hiding L2/L3 cache misses ( ?3) and discuss open questions ( ?4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ENABLING TECHNIQUES</head><p>In our proposal, we leverage two enabling techniques to mitigate the aforementioned drawbacks of software mechanisms -light-weight coroutines to reduce switching overhead and sample-based profiling to obtain event visibility. Next, we elaborate on how they improve upon prior techniques and how these improvements facilitate our proposal. Light-weight coroutines: coroutines are generalized subroutines whose execution can be suspended and resumed. Context switches of coroutines are orders of magnitudes cheaper than traditional threads of executions like processes and kernel threads. Being a user-space mechanism that resides in a single process, coroutine context switch requires no expensive system calls nor changes to the virtual memory mapping. Moreover, since the coroutine context switch is effected by a visible yield function call, it only needs to preserve a subset of registers (including instruction and stack pointer), defined by the calling convention, of the current coroutine and restore those registers of the resumed coroutine <ref type="bibr" target="#b35">[36]</ref>. Thanks to these merits, recent coroutine implementations have brought the context switch latency down to less than 10 ns (e.g., 9 ns for Boost's fcontext_t <ref type="bibr" target="#b5">[6]</ref>). Moreover, there have been efforts on leveraging compiler support to further reduce the overhead <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b45">46]</ref>. For instance, a compiler might determine a fewer number of registers that need to be preserved across a particular context switch. As we will discuss later, by instrumenting coroutines based on profiled data, our proposal is amenable to these compiler-side optimizations.</p><p>With the low switching overhead of coroutine, there have been recent works that interleave coroutine executions to hide memory accesses for pointer-based data structures in databases <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b52">53]</ref>. However, they do not address the issue of limited event visibility. Instead, they ask developers to decide where these events may happen (e.g., loads that cause cache misses) and hard code event handlers at these locations (e.g., issuing a prefetch instruction before switching to a different coroutine) at development time. This approach however requires significant engineering efforts -inferring the presence of short events is challenging and error-prone even for domain experts, and hinders wide adoption -manual rewriting is needed for legacy code. Moreover, as we will discuss in ?3.3, yields inserted by developers are too sparse to allow fine-grained control over application performance. Sample-based profiling: profile-guided optimizations (PGO), also called feedback-driven optimizations (FDO), is a compiler optimization technique that uses runtime information collected via profiling for improving program performance.</p><p>PGO has been proved highly effective for code optimizations <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b60">61]</ref>. Early efforts on PGO relied on instrumentation based profiling, which requires instrumenting the application to collect profile information. However, this approach not only complicates the build process, but also incurs significant CPU and memory overhead. More importantly, instrumentation-based profiling cannot easily support our proposal, because it is hard to obtain visibility into hardware events like L2/L3 cache misses with only instrumentation. Fortunately, to increase the adoption of PGO in production environments, recent work has instead focused on samplebased profiling <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b65">66]</ref>, which relies on sampling using hardware performance counters available in modern CPUs, such as Intel's Precise Event Based Sampling (PEBS) <ref type="bibr" target="#b0">[1]</ref> and Last Branch Records (LBR) <ref type="bibr" target="#b34">[35]</ref>. Sample-based profiling requires no special build and incurs negligible run time overhead, both of which allows sample-based PGO to be widely deployed in production environments <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. Most importantly, as we will elaborate later, sample-based profiling allows us to conveniently gather information on hardware events, e.g., where and how frequently these events occur, which is then used for hiding these events in software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A PROPOSAL</head><p>To illustrate how one can hide the latency of short events by intelligently combining light-weight coroutines and samplebased profiling, we next propose the design of an easily deployable software mechanism targeting L2/L3 cache misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Requirements</head><p>With a focus on deployability, we distill three requirements that we believe can facilitate adoption of the mechanism. Transparent interface: the software mechanism should be transparent to both applications and developers. It should require no additional rewriting effort from the developer and should be applicable to any code structured in coroutines. General applicability: the software mechanism should be applicable to a wide range of applications and implementations. Therefore, the mechanism must not depend on features or assumptions specific to certain programming languages, application domains, data structures etc. to properly function. Controllable latency: the software mechanism should allow fine-grained control over application latency. It can thus be used with latency-sensitive applications to simultaneously achieve low latency and high CPU efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Profile-guided yield instrumentation</head><p>The proposed software mechanism follows the same procedure as prior systems that leverage PGO, which involves three logical steps: (i) running the original code (structured in coroutines) in production environments and collecting statistics about CPU stalls due to L2/L3 cache misses with sample-based profiling mechanism, (ii) instrumenting the coroutines so that they prefetch and yield to hide potential cache misses according to the profiled data and (iii) using the finalized code to interleave executions of instrumented coroutines at run time. Next, we elaborate on the set of design choices we make to enable transparent interface and general applicability in steps (i) and (ii). After that, we will introduce how we ensure controllable latency by supporting asymmetric concurrency in steps (ii) and (iii). Hardware events to sample: for profiling, we first need to decide the set of hardware events to sample, so that the profiled data is useful to our mechanism. For hiding L2/L3 cache misses that cause CPU stalls, the ideal event would have informed us the number of stalled cycles due to L2/L3 cache miss for different load instructions. Unfortunately, to the best of our knowledge, such an event is not supported in today's CPUs. <ref type="foot" target="#foot_0">1</ref> To mitigate this issue, we propose to sample multiple events and combine their results, instead of relying on a single event. Specifically, we propose to sample both (i) load instructions that cause L2/L3 cache misses and (ii) the stalled cycles. We learn from (i) the set of load instructions that induce cache misses and correlate that with instructions causing CPU stalls from (ii), which leads us to load instructions that likely cause CPU stalls. Additional events can also be included to filter out stalls due to other reasons (e.g., front-end stalls due to slow instruction fetching).</p><p>Besides the set of hardware events, there are other parameters to configure as well, such as the sampling frequency and the size of the in-memory buffer that temporarily stores sampled profiles. For these parameters, their corresponding trade-offs (e.g., higher sampling frequency expedites profile collections at the cost of higher run time overhead) have been extensively studied in prior work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b49">50]</ref>, and our proposal can follow the established practices here. Instrumentation level: after sampling hardware events in step (i), a key design decision we need to make for step (ii) is at what level in the compilation pipeline we perform instrumentation, ranging from source code <ref type="bibr" target="#b8">[9]</ref>, to the compiler's intermediate representations (IR) <ref type="bibr" target="#b9">[10]</ref>, to the post-linked binary <ref type="bibr" target="#b49">[50]</ref>. Operating at each level comes with its pros and cons, and prior works on PGO make different choices depending on their needs. In our case, we propose to instrument at the binary level for the following two reasons. First, by instrumenting at the binary level, our mechanism can be applied to any application or implementation, as it does not require access to the source code nor restrict developers to any specific programming languages. Second, operating at the binary level allows us to surgically instrument at the correct locations. Specifically, since sample-based profiling collects data at the binary level, it is known that the closer a level is to the binary representation, the higher the accuracy with which the profiled data can be mapped back to that representation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b49">50]</ref>. To see this, consider a function that is inlined at multiple locations. If the profiled data indicates that instrumentation is needed at one of the locations but not others, we can easily do that at the binary level, but will have difficulty retrofitting the data back to higher-level representations and correctly instrumenting at that level if function inlining has not been performed yet.</p><p>While instrumenting at the binary level brings benefits in terms of applicability and accuracy, it does suffer from some limitations. One of them is relinquishing potential optimization opportunities along the compilation pipeline. Fortunately, as we will discuss next, operating at the binary level still permits optimizations that can significantly improve the performance of our mechanism. Another general concern is the inability to perform operations that require high-level semantic information. Fortunately, the logic of instrumenting yields to hide L2/L3 cache misses is independent from the application logic or program structure. Yield instrumentation: after deciding the sampled hardware events and the instrumentation level, we next discuss design problems that are directly related to instrumenting yields to hide L2/L3 cache misses. We will not go into details of the procedures in the instrumentation pipeline, such as disassembly and control flow graph (CFG) construction, for which our mechanism should be similar to existing binary optimizers <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. Instead, we elaborate on three aspects specific to our use case: the conditions under which a yield will be inserted at a location, the operations to instrument at these locations, and optimizations to reduce overhead.</p><p>In terms of the conditions to insert yields, there is a tradeoff: aggressive instrumentation minimizes CPU stalls due to uninstrumented cache misses, at the risk of incurring unnecessary overhead if a load turns out to be a cache hit. To make better decisions in the face of this trade-off, we propose to quantitatively model the gain and the cost of instrumenting at a specific load instruction. This requires some statistics that are either estimated from the collected profiles (e.g., the likelihood of cache misses for a load instruction) or extracted from the machine characteristics (e.g., the average latency of an L2/L3 cache miss). Based on the statistics and modelling, one could then decide whether to place yields based on different policies. A simple policy, for example, is to instrument yields if the likelihood of cache misses is above a threshold.</p><p>Once we decide to yield at a specific load instruction, the following operations are instrumented: (i) prefetching the requested cache line before yielding, (ii) saving registers to memory and setting the stack pointer and the program counter to the ones of the next coroutine and (iii) restoring registers from the memory (since the coroutine is resumed at this point). These instrumentations ensure that the coroutine can correctly yield to a different one to hide the cache misses. Various optimizations could then be applied to reduce the overhead due to instrumentations. One potential optimization is to identify registers whose values will be used later via a register liveness analysis <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b51">52]</ref> and only preserve the values of these registers. This directly translates to less switching overhead. Another interesting optimization is yield coalescing, which is applicable when instrumenting multiple independent and adjacent loads. Specifically, instead of inserting a yield for every load, we could issue prefetches all together and instrument only a single yield to amortize the switching overhead. Independence of adjacent loads can be determined via dependence analysis <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Asymmetric concurrency</head><p>Profile-guided yield instrumentation, as we described above, hopefully allows us to hide L2/L3 cache misses in a way that is transparent to developers and applicable to a wide range of applications. However, it does not support finegrained control over application latency. To see this, consider a case where we need to ensure low latency of a high-priority coroutine, while improving CPU efficiency by interleaving with executions of other coroutines. To support this use case, what we need is for other coroutines to yield back to the highpriority coroutine as soon as they have run for long enough to hide the latency of L2/L3 cache misses. However, the instrumentation mechanism described so far, which we call primary instrumentation, places yields only at locations that likely have cache misses. As a consequence, adjacent yields can be arbitrarily far apart depending on the application, preventing a coroutine from timely relinquishing the CPU.</p><p>Fundamentally speaking, our proposal has to reconcile two seemingly conflicting needs: sparse instrumentation (i.e., only inserting yields to hide cache misses) for improving CPU efficiency with minimal overhead, and dense instrumentation for managing the latency impact on yielded coroutines. As a solution, we propose to support asymmetric concurrency, which consists of two components. First, after primary instrumentation, we add a scavenger instrumentation phase, where we strategically place additional yields to ensure appropriate distance between adjacent yields. These yields are conditional, hence can be turned on and off to alter the mode of a coroutine at run time. Second, at run time, we leverage coroutines in scavenger mode to hide cache misses, while incurring minimal latency overhead to coroutines in primary mode. Considering the previously discussed case, we can now achieve both high CPU efficiency and low latency of the high-priority coroutine by running the high-priority coroutine in the primary mode and other coroutines in the scavenger mode. Next, we elaborate on the challenges associated with these two components and discuss our proposals. Scavenger instrumentation: at this phase, the user provides a target inter-yield interval that is bounded but sufficient to hide L2/L3 cache misses (e.g., 100 ns), and our goal is to ensure that adjacent yields are separated approximately this far. Achieving this goal with only static analysis is challenging: the latency of a basic block is hard to predict <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b53">54]</ref> and there can be multiple paths of vastly different lengths between two basic blocks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b40">41]</ref>. Inspired by efforts in trace scheduling <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b38">39]</ref>, a technique that uses profiling information for static instruction scheduling, we propose to leverage profiling for scavenger instrumentation as well. Specifically, profiling mechanisms like Intel's LBR can extract information like the latency of a basic block and the common paths in the program <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. With profiled data, we could first insert yields to ensure timely yielding in the common case, then augment it with additional yields to bound the worst-case inter-yield interval based on static analysis.</p><p>After the scavenger phase, we now have the final instrumented binary, which contains both primary yields for hiding cache misses and (conditional) scavenger yields for timely yielding. Scavenger yields are carefully placed to ensure appropriate inter-yield distances, whereas primary yields may be too close to or far from each other as their locations are determined by the application memory access patterns. Dual-mode execution: at run time, we propose dual-mode execution: (i) a primary coroutine yields to scavenger coroutines in the face of a potential cache miss, and (ii) scavenger coroutines will yield back to the primary once they have run for long enough to hide the cache miss. For (ii), our mechanism should scale up the number of scavenger coroutines on demand. Specifically, in the normal case, a single scavenger coroutine is sufficient -the coroutine will run for some time until it encounters a yield instrumented at the scavenger phase, at which point the coroutine can directly yield back to the primary coroutine. In other cases, multiple scavenger coroutines may need to be invoked before returning to the primary. This is because a scavenger coroutine may encounter a yield that was instrumented at the primary phase for hiding cache misses too early, in which case it will instead yield to another scavenger to consume more cycles. For example, for a coroutine that performs pointer chasing, when operating in the scavenger mode, it has to rely on other scavenger coroutines in order to fully utilize the CPU.</p><p>To summarize, we believe that some form of asymmetric concurrency is critical for ensuring low latency with high CPU efficiency. With our proposed design, we hope to shed light on the design space that future work can explore, which likely involves co-design of offline profiling, profile-guided instrumentation and runtime control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>Now that we have proposed a way of hiding short events in software, we discuss two important questions: (i) if we could make changes to the hardware, what would the final solution look like? and (ii) how could our proposal coexist with software mechanisms designed for other purposes?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Hardware support</head><p>To make our proposal feasible, we have restricted ourselves to techniques supported by today's hardware. An interesting question is then: what if we lift this restriction and envision a hardware-software co-design? To approach this question, we proceed with a software-centric view and look for the minimal hardware support that will significantly benefit our proposal. For this, we re-examine the two aspects that software mechanisms fall short in, i.e., large switching overhead and limited event visibility, and discuss to what extent additional hardware support will be helpful to our proposal.</p><p>For switching overhead, we conjecture that it is not the most critical issue, given the possible software optimizations that could further reduce the overhead of coroutine switching <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b45">46]</ref>. Specifically, while switching software contexts requires storing/restoring register states to/from memory, it supports high degrees of concurrency and fine-grained control, both of which are hard to obtain in hardware without a significant hardware redesign. Moreover, since our proposal targets events that last for 10s to 100s of ns, the sub-10 ns overhead of coroutine switching is acceptable.</p><p>In contrast, we believe that event visibility is the aspect that should receive more attention, where significant improvement may be achievable with modest hardware changes. Solely relying on profile-guided instrumentation for detecting and hiding events is sub-optimal due to its static nature -whether a coroutine will yield at a location or not is determined offline. Therefore, hardware support to expose events, e.g., indicating whether a cache line is in L1/L2 cache, could be highly useful here, as it allows yields to be conditional on whether targeted events actually happen. While condition checking adds some overhead, profile-guided instrumentation can mitigate this issue by placing conditional yields only at locations that often but not always incur target events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Software integration</head><p>Runtime scheduling: an interesting question is how to integrate our proposed mechanism with existing coroutine schedulers <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b71">72]</ref> whose logic is agnostic to short events. One approach is to run our mechanism on the side of the scheduler and have the scheduler perform only a minimal set of additional tasks to support event hiding. For example, the scheduler could expose the set of coroutines in its ready queue, so that our mechanism knows that they can be switched to when hiding events. A different approach is to have the scheduler explicitly consider these short events when scheduling tasks. This is conceptually similar to how I/O events receive special treatment in OS process scheduling. This approach could be appealing when performing fine-grained scheduling of very short (e.g., ?s-scale) tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b48">49]</ref>. Coroutine isolation: there are two categories of isolation mechanisms suitable for coroutines: software-based fault isolation (SFI) and language-based isolation. SFI establishes a logical protection domain by inserting dynamic checks before memory and control-transfer instructions <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b68">69]</ref>. Language-based isolation relies on safe high-level languages for isolation through a combination of static and dynamic checks <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b56">57]</ref>. Language-based isolations can have lower runtime overhead by adopting restricted memory models and performing most of the checks at compile time <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b41">42]</ref>. However, adopting language-based isolations requires more engineering efforts, due to the need of developing based on restricted memory models and rewriting legacy code. Since our proposal is applicable to different programming languages, it can co-exist with either isolation mechanism. An interesting question is whether a co-design of SFI and our proposal can help reduce the runtime overhead of SFI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>With light-weight coroutines and sample-based profiling, hiding short events that last only 10s to 100s of ns in software is becoming feasible. By walking through a design proposal, we shed light on the challenges that arise from leveraging these two techniques, and hopefully offer some promising directions towards addressing these challenges.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Hiding events of different durations: existing hardware and software mechanisms and our proposal; OoOE: out-oforder executions, SMT: simultaneous multithreading.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A similar and supported event is stalled cycles while there are L2/L3 cache miss demand loads. However, this event does not indicate causal relationship between cache misses and stalls, and is not precise meaning that the exact instructions (loads in our case) that caused the event are unavailable.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Quantitative evaluation of intel pebs overhead for online system-noise analysis</title>
		<author>
			<persName><forename type="first">Soramichi</forename><surname>Akiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takahiro</forename><surname>Hirofuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Runtime and Operating Systems for Supercomputers ROSS 2017</title>
		<meeting>the 7th International Workshop on Runtime and Operating Systems for Supercomputers ROSS 2017</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A dynamic multithreading processor</title>
		<author>
			<persName><forename type="first">Haitham</forename><surname>Akkary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Driscoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 31st Annual ACM/IEEE International Symposium on Microarchitecture</title>
		<meeting>31st Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="226" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Memory hierarchy for web search</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Utpal</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dependence analysis</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="1997">1997</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rock you like a hurricane: Taming skew in large scale analytics</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Bindschaedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmina</forename><surname>Malicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Schiper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashvin</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
		<meeting>the Thirteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Performance of Boost context switch</title>
		<ptr target="https://www.boost.org/doc/libs/1_79_0/libs/context/doc/html/context/performance.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An infrastructure for adaptive dynamic optimization</title>
		<author>
			<persName><forename type="first">Derek</forename><surname>Bruening</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Code Generation and Optimization</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003. 2003. 2003</date>
			<biblScope unit="page" from="265" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Isolation in Rust: What is Missing?</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Burtsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Appel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Detweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaofeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerd</forename><surname>Zellweger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Workshop on Programming Languages and Operating Systems</title>
		<meeting>the 11th Workshop on Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Profile-guided automatic inline expansion for C programs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pohua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">Y</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Mei W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="349" to="369" />
			<date type="published" when="1992">1992. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications</title>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Xinliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Symposium on Code Generation and Optimization</title>
		<meeting>the 2016 International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Taming hardware event samples for precise and versatile feedback directed optimizations</title>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Vachharajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Hundt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Eranian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weimin</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="376" to="389" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A VLIW architecture for a trace scheduling compiler</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Nix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">J</forename><surname>O'donnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">B</forename><surname>Papworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">K</forename><surname>Rodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on computers</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="967" to="979" />
			<date type="published" when="1988">1988. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coz: Finding code that counts with causal profiling</title>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Curtsinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emery</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
		<meeting>the 25th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="184" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Context switch overheads for Linux on ARM platforms</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Francis M David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><forename type="middle">H</forename><surname>Carlyle</surname></persName>
		</author>
		<author>
			<persName><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 workshop on Experimental computer science</title>
		<meeting>the 2007 workshop on Experimental computer science</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">When Idling is Ideal: Optimizing Tail-Latency for Highly-Dispersed Datacenter Workloads with Persephone</title>
		<author>
			<persName><surname>Hm Demoulin</surname></persName>
		</author>
		<author>
			<persName><surname>Fried</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symposium on Operating Systems Principles (SOSP)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Compiler support for lightweight context switching</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Servesh</forename><surname>Muralidharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Gregg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization (TACO)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Kotlin coroutines: design and implementation</title>
		<author>
			<persName><forename type="first">Roman</forename><surname>Elizarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Belyaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marat</forename><surname>Akhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilmir</forename><surname>Usmanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software</title>
		<meeting>the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="68" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A state of the art review of intelligent scheduling</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Hossein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fazel</forename><surname>Zarandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Akbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadat</forename><surname>Asl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahabeddin</forename><surname>Sotudian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="501" to="593" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ait: Worst-case execution time prediction by static program analysis</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Ferdinand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reinhold</forename><surname>Heckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Building the Information Society: IFIP 18th World Computer Congress Topical Sessions 22-27</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004-08">2004. August 2004</date>
			<biblScope unit="page" from="377" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Trace scheduling: A technique for global microcode compaction</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on computers</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="478" to="490" />
			<date type="published" when="1981">1981. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neptune: Scheduling suspendable tasks for unified stream/batch applications</title>
		<author>
			<persName><forename type="first">Panagiotis</forename><surname>Garefalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Karanasos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Pietzuch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM symposium on cloud computing</title>
		<meeting>the ACM symposium on cloud computing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="233" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Propeller: Profile Guided Optimizing Large Scale LLVMbased Relinker</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/google/llvm-propeller" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CoroBase: coroutine-oriented main-memory database engine</title>
		<author>
			<persName><forename type="first">Yongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianzheng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="431" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Joel</forename><surname>Hruska</surname></persName>
		</author>
		<ptr target="https://www.extremetech.com/computing/133121-maximized-performance-comparing-the-effects-of-hyper-threading-software-updates" />
		<title level="m">Maximized performance: Comparing the effects of Hyper-Threading, software updates</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A case against (most) context switches</title>
		<author>
			<persName><forename type="first">Jack Tigar</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kostis</forename><surname>Kaffes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mazi?res</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Hot Topics in Operating Systems</title>
		<meeting>the Workshop on Hot Topics in Operating Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="17" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/overview.html" />
		<title level="m">Intel Accelerator Engines</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Apt-get: Profile-guided timely software prefetching</title>
		<author>
			<persName><forename type="first">Saba</forename><surname>Jamilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Tanvir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Kasikci</surname></persName>
		</author>
		<author>
			<persName><surname>Litz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth European Conference on Computer Systems</title>
		<meeting>the Seventeenth European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="747" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploiting coroutines to attack the&quot; killer nanoseconds</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farooq</forename><surname>Umar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Minhas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gor</forename><surname>Levandoski</surname></persName>
		</author>
		<author>
			<persName><surname>Nishanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1702" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">RustBelt: Securing the foundations of the Rust programming language</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacques-Henri</forename><surname>Jourdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robbert</forename><surname>Krebbers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Dreyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Programming Languages</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>POPL</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Shinjuku: Preemptive scheduling for ?second-scale tail latency</title>
		<author>
			<persName><forename type="first">Kostis</forename><surname>Kaffes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">Tigar</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Belay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mazi?res</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th USENIX Symposium on Networked Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="345" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Profiling a warehouse-scale computer</title>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual International Symposium on Computer Architecture</title>
		<meeting>the 42nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Kennedy</surname></persName>
		</author>
		<ptr target="https://www.servethehome.com/intel-xeon-sapphire-rapids-shows-built-in-accelerators-at-innovation-2022/" />
		<title level="m">Intel Xeon Sapphire Rapids Shows Built-in Accelerators at Innovation 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">I-spy: Context-driven conditional instruction prefetching with coalescing</title>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Advanced usage of last branch records</title>
		<author>
			<persName><forename type="first">Andi</forename><surname>Kleen</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/680996/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">An introduction to last branch records</title>
		<author>
			<persName><forename type="first">Andi</forename><surname>Kleen</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/680985/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">fiber_handle-fibers without scheduler</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Kowalke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Goodspeed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Language-Based Security: Invited Lecture</title>
		<author>
			<persName><forename type="first">Dexter</forename><surname>Kozen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Foundations of Computer Science 1999: 24th International Symposium, MFCS&apos;99</title>
		<meeting><address><addrLine>Szklarska Por?ba, Poland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999-09-06">1999. September 6-10, 1999</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="284" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Quantifying the cost of context switch</title>
		<author>
			<persName><forename type="first">Chuanpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 workshop on Experimental computer science</title>
		<meeting>the 2007 workshop on Experimental computer science</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The multiflow trace scheduling compiler</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><forename type="middle">M</forename><surname>Freudenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">J</forename><surname>Karzes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Lichtenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Nix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S O'</forename><surname>Donnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>Ruttenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="51" to="142" />
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Language-based isolation of untrusted Javascript</title>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Maffeis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Taly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 22nd IEEE Computer Security Foundations Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="77" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimal basic block instruction scheduling for multiple-issue processors using constraint programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><surname>Van Beek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal on artificial intelligence tools</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="37" to="54" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The rust language</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">S</forename><surname>Matsakis</surname></persName>
		</author>
		<author>
			<persName><surname>Klock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGAda Ada Letters</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="103" to="104" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient and exact data dependence analysis</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Dror E Maydan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><forename type="middle">S</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 1991 conference on Programming language design and implementation</title>
		<meeting>the ACM SIGPLAN 1991 conference on Programming language design and implementation</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Revisiting coroutines</title>
		<author>
			<persName><forename type="first">Ana</forename><surname>L?cia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Ierusalimschy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems (TOPLAS)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Register liveness analysis of executable code</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-12">1998. Dec. 1998</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, The University of Arizona</orgName>
		</respStmt>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">C++ Extensions for Coroutines</title>
		<author>
			<persName><forename type="first">Gor</forename><surname>Nishanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the applicability of PEBS based online memory access tracking for heterogeneous memory management at scale</title>
		<author>
			<persName><forename type="first">Aleix</forename><surname>Roca Nonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balazs</forename><surname>Gerofi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Bautista-Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Memory Centric High Performance Computing</title>
		<meeting>the Workshop on Memory Centric High Performance Computing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
	<note>Dominique Martinet, Vicen? Beltran Querol, and Yutaka Ishikawa</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Optimizing function placement for large-scale data-center applications</title>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertrand</forename><surname>Maher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads</title>
		<author>
			<persName><forename type="first">Amy</forename><surname>Ousterhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Belay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="361" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bolt: a practical binary optimizer for data centers and beyond</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Nell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Lightning bolt: powerful, fast, and scalable binary optimization</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laith</forename><surname>Sakka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM SIGPLAN International Conference on Compiler Construction</title>
		<meeting>the 30th ACM SIGPLAN International Conference on Compiler Construction</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Register liveness analysis for optimizing dynamic binary translation</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Krall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Scholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth Working Conference on Reverse Engineering</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Interleaving with coroutines: a practical approach for robust index joins</title>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Psaropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Legler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ailamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="230" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Guest editorial: A review of worst-case execution-time analysis</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Puschner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="115" to="128" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Applications of thread prioritization in SMT processors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Raasch</surname></persName>
		</author>
		<author>
			<persName><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Multithreaded Execution And Compilation</title>
		<meeting>of the Workshop on Multithreaded Execution And Compilation</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Google-wide profiling: A continuous profiling infrastructure for data centers</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Gang Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Tune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvius</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName><surname>Hundt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE micro</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="65" to="79" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A languagebased approach to security</title>
		<author>
			<persName><forename type="first">Fred</forename><forename type="middle">B</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Morrisett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Informatics: 10 Years Back, 10 Years Ahead</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="86" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Adapting software fault isolation to contemporary CPU architectures</title>
		<author>
			<persName><forename type="first">David</forename><surname>Sehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cliff</forename><forename type="middle">L</forename><surname>Biffle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Khimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Egor</forename><surname>Pasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bennet</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Schimpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Modern processor design: fundamentals of superscalar processors</title>
		<author>
			<persName><forename type="first">John</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mikko</forename><forename type="middle">H</forename><surname>Lipasti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Waveland Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Operating system concepts</title>
		<author>
			<persName><forename type="first">Abraham</forename><surname>Silberschatz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">L</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">B</forename><surname>Galvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Overcoming the challenges to feedbackdirected optimization (keynote talk)</title>
		<author>
			<persName><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIG-PLAN workshop on Dynamic and adaptive compilation and optimization</title>
		<meeting>the ACM SIG-PLAN workshop on Dynamic and adaptive compilation and optimization</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Softsku: Optimizing server architectures for microservice diversity@ scale</title>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Dhanotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture</title>
		<meeting>the 46th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Efficient coroutines for the Java platform</title>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>W?rthinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Wimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on the Principles and Practice of Programming in Java</title>
		<meeting>the 8th International Conference on the Principles and Practice of Programming in Java</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="20" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Operating systems internals and design principles</title>
		<author>
			<persName><forename type="first">William</forename><surname>Stallings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Prentice-Hall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Principles and implementation techniques of software-based fault isolation</title>
		<author>
			<persName><forename type="first">Gang</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Privacy and Security</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="137" to="198" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Collecting performance data with PAPI-C</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Terpstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heike</forename><surname>Jagode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haihang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Dongarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tools for High Performance Computing 2009: Proceedings of the 3rd International Workshop on Parallel Tools for High Performance Computing</title>
		<meeting><address><addrLine>Dresden</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2010. September 2009</date>
			<biblScope unit="page" from="157" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Handling long-latency loads in a simultaneous multithreading processor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffery</forename><forename type="middle">A</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 34th ACM/IEEE International Symposium on Microarchitecture. MICRO-34</title>
		<meeting>34th ACM/IEEE International Symposium on Microarchitecture. MICRO-34</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="318" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Performance insights to Intel? hyper-threading technology</title>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Valles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Drysdale</surname></persName>
		</author>
		<ptr target="https://software.intel.com/enus/articles/performance-insights-to-intel-hyper-threadingtechnology" />
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Efficient software-based fault isolation</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Wahbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Lucco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">E</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth ACM symposium on Operating systems principles</title>
		<meeting>the fourteenth ACM symposium on Operating systems principles</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="203" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Spark: Cluster computing with working sets</title>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><surname>Stoica</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">95</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Riffle: Optimized shuffle service for large-scale data analytics</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ergin</forename><surname>Seyfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avery</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
		<meeting>the Thirteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The demikernel datapath os architecture for microsecond-scale datacenter systems</title>
		<author>
			<persName><forename type="first">Irene</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Raybuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyush</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Olynyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><forename type="middle">S</forename><surname>Navarro Leija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashlie</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">Kornfeld</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujay</forename><surname>Jayakar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles</title>
		<meeting>the ACM SIGOPS 28th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="195" to="211" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
