<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic variational preferences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-04-19">19 April 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Maccheroni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Istituto di Metodi Quantitativi and IGIER</orgName>
								<orgName type="institution">Università Bocconi</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Massimo</forename><surname>Marinacci</surname></persName>
							<email>massimo.marinacci@unito.it</email>
							<affiliation key="aff1">
								<orgName type="department">Dipartimento di Statistica e Matematica Applicata and Fondazione Collegio Carlo Alberto</orgName>
								<orgName type="institution">Università di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aldo</forename><surname>Rustichini</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Economics</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic variational preferences</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-04-19">19 April 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">6863C4FA30CEF3540D4BD32336F935F9</idno>
					<idno type="DOI">10.1016/j.jet.2005.12.011</idno>
					<note type="submission">Received 1 August 2005; final version received 26 December 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>JEL classification: C61</term>
					<term>D81 Ambiguity aversion</term>
					<term>Model uncertainty</term>
					<term>Recursive utility</term>
					<term>Robust control</term>
					<term>Time consistency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce and axiomatize dynamic variational preferences, the dynamic version of the variational preferences we axiomatized in [F. Maccheroni, M. Marinacci, A. Rustichini, Ambiguity aversion, robustness, and the variational representation of preferences, Mimeo, 2004], which generalize the multiple priors preferences of Gilboa and Schmeidler [Maxmin expected utility with a non-unique prior, J. Math. Econ.  18 (1989) 141-153], and include the Multiplier Preferences inspired by robust control and first used in macroeconomics by Hansen and Sargent (see [L.P. Hansen, T.J. Sargent, Robust control and model uncertainty, Amer. Econ. Rev. 91 (2001) 60-66]), as well as the classic Mean Variance Preferences of Markovitz and Tobin. We provide a condition that makes dynamic variational preferences time consistent, and their representation recursive. This gives them the analytical tractability needed in macroeconomic and financial applications. A corollary of our results is that Multiplier Preferences are time consistent, but Mean Variance Preferences are not.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the Multiple Priors (MP) model, agents rank acts h using the criterion</p><formula xml:id="formula_0">V (h) ≡ inf p∈C E p [u (h)] , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where C is a closed and convex subset of the set of all probabilities on states. This model has been axiomatized by Gilboa and Schmeidler <ref type="bibr" target="#b8">[9]</ref> with the goal of modelling ambiguity averse agents, who exhibit the Ellsberg-type behavior first observed in the seminal paper of Ellsberg <ref type="bibr" target="#b4">[5]</ref>.</p><p>The non-singleton nature of C reflects the limited information available to agents, which may not be enough to quantify their beliefs with a single probability, and is instead compatible with a non-singleton set C of probabilities.</p><p>On the other hand, the cautious attitude featured by MP agents can also be viewed as the result of the effect that an adversarial influence, which we may call "Nature", has on the realizations of the state. Under this view, Nature chooses a probability p over states with the objective of minimizing agents' utility, conditional on their choice of an act and under the constraint that the probability p has to be chosen in a fixed set C. This interpretation of the MP model provides an intuitive notion of ambiguity aversion, which can be regarded as the agents' diffidence for any lack of precise definition of the uncertainty involved in a choice, something that provides room for the malevolent influence of Nature. <ref type="foot" target="#foot_0">1</ref>In a recent paper, <ref type="bibr" target="#b20">[21]</ref>, we extended the MP representation by generalizing Nature's constraint. Specifically, in our extension the constraint on Nature is given by a cost c (p) associated with the choice of probability, and agents rank acts according to the criterion:</p><formula xml:id="formula_2">V (h) ≡ inf p∈ E p [u (h)] + c (p) , (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where c is a closed and convex function on . Preferences represented by <ref type="bibr" target="#b1">(2)</ref> are called variational preferences (VP), and the function c is their ambiguity index. In <ref type="bibr" target="#b20">[21]</ref>, we axiomatize the representation (2) and we discuss in detail its ambiguity interpretation. The VP representation generalizes the MP representation, which is the special case where there is an infinite cost for choosing outside the set C, with the cost being constant (and hence, without loss of generality, zero) inside that set. In other words, the cost for Nature in the MP model is given by the indicator function C : → [0, ∞] of C, defined as</p><formula xml:id="formula_4">C (p) ≡ 0 if p ∈ C, ∞ if p / ∈ C, (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>and it is immediate to see that</p><formula xml:id="formula_6">inf p∈ E p [u (h)] + C (p) = inf p∈C E p [u (h)] .</formula><p>The notion of ambiguity aversion has found an important application in the last years in the literature, pioneered by Hansen and Sargent (see, e.g., <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> for details and references), that applies the idea of robust control to agents' choices in macroeconomic models. While the initial definition of robust control was different from that of ambiguity aversion, the intuition is closely related: an agent prefers a robust control if he is not confident that his (probabilistic) model of the uncertainty is correct, and so he wants to avoid the possibility that a small error in the formulation of the stochastic environment produces a large loss. Ambiguity aversion comes up because the agents' information is too limited to be represented by a single probabilistic model.</p><p>In the multiplier preferences model, the most important choice model used in this macroeconomic literature (see <ref type="bibr" target="#b10">[11]</ref>), the constraint on Nature is represented by a cost c based on a reference probability q ∈ : Nature can deviate away from q, but the larger the deviation, the higher the cost. In particular, this cost is assumed to be proportional to the relative entropy R (p q) between the chosen probability p and the reference probability q; that is, c (p) ≡ R (p q) , where &gt; 0. Multiplier preferences are, therefore, the special case of VP given by</p><formula xml:id="formula_7">V (h) ≡ inf p∈ E p [u (h)] + R (p q) ,</formula><p>and their analytical tractability is important in deriving optimal policies.</p><p>Even though the motivation behind multiplier preferences is similar to that used for MP preferences, formally multiplier preferences are not MP preferences. In fact, in <ref type="bibr" target="#b20">[21]</ref> we show that they are an example of divergence preferences, a special class of VP featuring tractable cost functions, but which are not MP preferences. VP are, therefore, the generalization needed in order to encompass both MP and multiplier preferences, as discussed at length in <ref type="bibr" target="#b20">[21]</ref>.</p><p>In view of applications, however, the static analysis of <ref type="bibr" target="#b20">[21]</ref> is insufficient and a dynamic extension is required. This is the purpose of the present paper, in which we introduce and axiomatize dynamic VP.</p><p>The first observation to make is that, while in a static environment acts are functions from states to consequences, in a dynamic environment they are functions from times and states to consequences. We impose on acts the usual measurability conditions ensuring that agents' choices are consistent with the information they have. As a result, agents' evaluations are conditional to time and state, and they are modelled by a family of (conditional) preferences t, indexed by time and state pairs (t, ). In the main results of the paper, Proposition 1 and Theorem 1, we provide necessary and sufficient conditions guaranteeing that agents' preferences at time t are represented by the preference functional</p><formula xml:id="formula_8">V t (h) ≡ inf p∈ ⎛ ⎝ E p ⎡ ⎣ t -t u (h ) G t ⎤ ⎦ + c t (p |G t ) ⎞ ⎠ , (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>and we show what restrictions on c t guarantee time consistency. <ref type="foot" target="#foot_1">2</ref> Under time consistency the representation (4) becomes recursive, and so it has the analytical tractability required in applications.</p><p>Besides tractability, time consistency has also an intuitive appeal. In fact, suppose that two acts are the same in every contingency up to the present period, and the first is preferred to the second according to the conditional preference in the next period in every state. Then time consistency requires that the first act should be preferred to the second in the present period. Equivalently, think of a plan as a sequence of conditional choices, so that the choice of a plan in the current period includes a plan of choices in all future periods, conditional on all future contingencies. Then, an agent is time consistent if he never formulates a plan of future choices that he wants to revise later in some event that is conceivable today.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">The no-gain condition and Bayesian updating</head><p>Our present work extends to the VP setting the recent dynamic version of the MP model provided by Epstein and Schneider <ref type="bibr" target="#b5">[6]</ref>. These authors give a condition, called rectangularity, that guarantees time consistency of MP preferences. Since rectangularity is a restriction on the sets of probabilities from which Nature can select at every time and state, it is natural that our corresponding condition is formulated as a restriction on cost functions.</p><p>Specifically, our condition is given by <ref type="bibr" target="#b10">(11)</ref> of Theorem 1. To facilitate the exposition, we present it in a simplified form, dropping the time index (the reader may think of this as the condition for the two-period version of the model). The agent has a partition G over the set of possible states (see the picture in Section 2.2). Nature has a cost c in the first period, so that c (q) is Nature's cost of choosing the probability q over the states. To each event G in this partition a new, second period, cost c G is associated. The announced condition requires that</p><formula xml:id="formula_10">c (q) = inf {p:p(G)=q(G) ∀G∈G} ⎡ ⎣ G∈G q(G)c G (q G ) + c (p) ⎤ ⎦ ,<label>(5)</label></formula><p>where q(G) ≡ ∈G q( ), is the discount factor, and</p><formula xml:id="formula_11">q G ( ) ≡ q( )/q (G) if ∈ G, 0 otherwise. (<label>6</label></formula><formula xml:id="formula_12">)</formula><p>The condition has a simple interpretation. The choice of probability by Nature over two periods can be thought of as consisting of two steps. The first period choice is a choice of probability over the events that realize in the first period. The second period choice is a choice of probability over states in every event, conditional on that event.</p><p>Nature can make this choice in a time consistent way: choose q in the first period, pay the appropriate cost c (q), wait for the realization of the second period event G, do nothing, pay nothing, and get the probability q G on the states in the event G. The total cost of this is the term in the l.h.s. of <ref type="bibr" target="#b4">(5)</ref>.</p><p>Alternatively, Nature can achieve the same result in a time inconsistent way, with total cost given by the r.h.s. of <ref type="bibr" target="#b4">(5)</ref>. Nature can choose today a probability p that induces the same probability over events in the second period as q does. This constraint is described by the condition p(G) = q(G) for every event G. Nature pays for its choice p the appropriate cost, which is the term c (p) in the r.h.s. of <ref type="bibr" target="#b4">(5)</ref>. After the realization of the event G, the probability over states in that event would be p G . Nature can now change the conditional probability to q G , and again pay the appropriate cost, represented by the term c G (q G ) in the r.h.s. of <ref type="bibr" target="#b4">(5)</ref>. Overall, in this second more indirect way, Nature achieves the same result as in the first choice: a probability q(G) of every event G in the first period, and a conditional probability q G if G obtains.</p><p>Condition <ref type="bibr" target="#b4">(5)</ref> requires that this second, time inconsistent and convoluted, choice is not less costly for Nature. A simple way of stating our main result is therefore the following: a decision maker is dynamically consistent if and only if (he thinks that) Nature is dynamically consistent. <ref type="foot" target="#foot_2">3</ref>In view of all this, we call <ref type="bibr" target="#b4">(5)</ref>, and more generally <ref type="bibr" target="#b10">(11)</ref> of Theorem 1, a "no-gain condition". We will formally prove that the no-gain condition generalizes rectangularity, and it coincides with it when cost functions are indicators C .</p><p>Eq. ( <ref type="formula" target="#formula_10">5</ref>) provides a link between cost functions in different periods. One important aspect of this link is that in the second period the probability over states conditional on the event G is the conditional probability q G as defined by <ref type="bibr" target="#b5">(6)</ref>, namely according to Bayes' Rule. This link extends to VP the connection between time consistency and Bayes' Rule.</p><p>As well known, Subjective Expected Utility preferences are time consistent if and only if their subjective beliefs are updated according to Bayes' Rule. This result is generalized in <ref type="bibr" target="#b5">[6]</ref> to MP preferences by showing that they are time consistent if and only if their sets of subjective beliefs are rectangular and updating is done belief by belief (prior by prior in the terminology of the MP model) according to Bayes' Rule. Our Theorem 1 further generalizes all these results by showing that VP are time consistent if and only if their cost functions satisfy the no-gain condition and updating is done according to Bayes' Rule.</p><p>Moreover, the recursive structure of the no-gain condition makes it possible to construct by backward induction cost functions that satisfy it. This is shown by Theorem 2, which thus provides a way to construct via ( <ref type="formula" target="#formula_8">4</ref>) examples of VP that are time consistent. Some papers have recently studied related issues, in particular dynamic aspects of the MP model. We already mentioned Epstein and Schneider <ref type="bibr" target="#b5">[6]</ref>, which is in turn closely related to Wang <ref type="bibr" target="#b30">[31]</ref>. Some aspects of their work have been extended by Ghirardato et al. <ref type="bibr" target="#b7">[8]</ref> and Hayashi <ref type="bibr" target="#b14">[15]</ref>. More recently, Hanany and Klibanoff <ref type="bibr" target="#b9">[10]</ref> proposed a dynamic version of the MP model that is dynamically consistent but does not satisfy Consequentialism, while Siniscalchi <ref type="bibr" target="#b27">[28]</ref> focused on dynamic MP models that relax Dynamic Consistency. Finally, Ozdenoren and Peck <ref type="bibr" target="#b24">[25]</ref> have studied some dynamic games against Nature that lead to ambiguity averse behavior, thus providing a game-theoretic underpinning of the game against Nature interpretation of ambiguity we discussed above and in <ref type="bibr" target="#b20">[21]</ref>.</p><p>The paper is organized as follows. Section 2 introduces the setup and notation, Section 3 presents the axioms needed for our derivation, whereas Section 4 contains the main results of the paper. Section 5 illustrates the main results with two important classes of VP, the MP preferences of Gilboa and Schmeidler <ref type="bibr" target="#b8">[9]</ref> and the multiplier preferences of Hansen and Sargent <ref type="bibr" target="#b10">[11]</ref>. Finally, Section 6 illustrates the analytical tractability of dynamic VP by showing their convenient differential properties. All proofs are collected in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Information</head><p>Time is discrete and varies over T ≡ {0, 1, . . ., T }. In our results we model information as an event tree {G t } t∈T , given and fixed throughout, which is defined on a finite space . The elements of this tree are partitions G t of consisting of non-empty sets, with G 0 ≡ { }, G t+1 finer than G t for all t &lt; T , and G T ≡ {{ } : ∈ }; in particular, G t ( ) is the element of G t that contains . For non-triviality, we assume T , | | 2.</p><p>The main interpretation we have in mind for this standard modelling of information is as follows. Given an underlying (and possibly unverifiable) state space S, endowed with a -algebra , observations are generated by a sequence of random variables {Z t } t&gt;0 taking values on finite observation spaces t . Each random variable Z t : S → t is -measurable and for convenience we assume that they are surjective, so that all elements of t can be viewed as observations generated by Z t .</p><p>The sample space T t=1 t is denoted by , and its points = ( 1 , . . ., T ) are the possible observation paths generated by the sequence {Z t }. Given t ∈ T , denote by { 1 , . . ., t } the cylinder</p><formula xml:id="formula_13">{ 1 } × • • • × { t } × t+1 × • • • × T .</formula><p>The event tree {G t } records the building up of observations and it is given by G 0 ≡ { }, are called predictive distributions and they represent the agent's (subjective) probability that ( t+1 , . . ., T ) will be observed after having observed ( 1 , . . ., t ). <ref type="foot" target="#foot_3">4</ref> Using the standard notation for conditional probabilities, the predictive distributions are given by the collection {p (•|G t )} t&gt;0 .</p><formula xml:id="formula_14">G t ≡ {{</formula><p>Observe that in the literature on MP preferences, the probabilities p : 2 → [0, 1] are often called priors and the conditional probabilities p (•|G t ) are called the Bayesian updates of the priors. This terminology is, however, a bit confusing as in Statistics priors are often probabilities on parameters (and posteriors are their Bayesian updates given observations). Here, no parametric representation is assumed for the probabilities p : 2 → [0, 1], and so we prefer not to use the term prior for them.</p><p>We now illustrate these notions with few examples.</p><p>Example 1. Suppose that observations are given by heads and tails from a given coin. We can set t = {0, 1} for each t = 1, . . ., T , so that = {0, 1} T is the sample space. A possible p ∈ ( ) is the one that assigns equal probability to all observation paths ; that is, p ( ) ≡ 2 For example, if T = 3, we have = {0, 1} 3 and consists of 2 3 states. This case can be illustrated with a simple binomial tree and the above probability p is such that p ( ) = 1 8 for all ∈ , while its predictive distributions are</p><formula xml:id="formula_15">p ( 3 | 1 , 2 ) = 1 2 and p ( 2 , 3 | 1 ) = 1 4 .</formula><p>In the next examples we assume that t = Z for all t, so that = Z T . For instance, in the previous example we had Z = {0, 1}. </p><formula xml:id="formula_16">: t-1 × 2 Z → [0, 1] for t 2, where ( t-1 , •) : 2 Z → [0, 1]</formula><p>is a probability measure on Z for each t-1 ∈ t-1 . Given an initial probability distribution 0 on 2 Z , p is uniquely determined by as follows:</p><formula xml:id="formula_17">p ( ) ≡ 0 ( 1 ) T i=2 ( i-1 , i ) ∀ ∈ , so that, p ( t+1 , . . ., T | 1 , . . ., t ) = T i=t+1 ( i-1 , i ) . (<label>8</label></formula><formula xml:id="formula_18">)</formula><p>Also in this Markov example information matters for prediction. In particular, <ref type="bibr" target="#b7">(8)</ref> shows that here the relevant information is given by t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Consumption streams</head><p>The acts among which agents choose are here given by consumption processes. Formally, acts are X-valued adapted processes of the form h = (h 0 , h 1 , . . ., h T ), where each h t : → X is G tmeasurable and takes values on a convex consumption set X. For example, X = R or X = (R), the set of all finitely supported probability measures on R (in both these cases R is interpreted as the set of monetary prizes).</p><p>Denote by H the set of all acts; we equivalently write h t ( ) or h (t, ) to denote consumption at time t if obtains (and sometimes h (t, G) to denote consumption at time t if G ∈ G t occurs). Notice that in our finite setting acts can be regarded as functions defined on t∈T G t , that is, on the set of all nodes.</p><p>We can identify H with the set of all maps h :</p><formula xml:id="formula_19">→ X T such that h ( ) = h if G ( ) = G</formula><p>; in this perspective h ( ) is the element (h 0 ( ) , h 1 ( ) , . . ., h T ( )) ∈ X T for any given . For all ∈ [0, 1], and all h, h ∈ H we set</p><formula xml:id="formula_20">h + (1 -) h (t, ) ≡ h (t, ) + (1 -) h (t, ) ∀ (t, ) ∈ T × .</formula><p>If the values of an act y ∈ H depend only on time but not on state, that is, for every fixed t</p><formula xml:id="formula_21">y (t, ) = y t, = y t ∀ , ∈ ,</formula><p>with a little abuse of notation we write y = (y 0 , y 1 , . . ., y T ) ∈ X T . Moreover, if </p><formula xml:id="formula_22">y 0 = • • • = y T = x,</formula><formula xml:id="formula_23">h 0 ( ) = h 0 ∀ , ∈ , h 1 ( ) = h 1 ∀ , ∈ with 1 = 1 , . . . h t ( ) = h t ∀ , ∈</formula><p>with ( 1 , . . ., t ) = 1 , . . ., t , . . . In other words, h 0 is a constant, h 1 only depends on the first observation, and h t only depends on the first t observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Notation</head><p>We close by introducing some notation, which is usually a bit heavy in dynamic settings. If p ∈ ( ), we denote by p |G t its restriction to the algebra A (G t ) generated by G t , and by p (• |G t ) the conditional probability given G t . <ref type="foot" target="#foot_4">5</ref> As we already observed, the conditional probabilities p (• |G t ) are called predictive distributions.</p><p>For all t ∈ T , ( , G t ) denotes the set of all probabilities on A (G t ), hence ( , G t ) = p |G t : p ∈ ( ) . In particular, ( , G T ) = ( ).</p><p>For each E ∈ A (G t ), we set</p><formula xml:id="formula_24">(E, G t ) ≡ {p ∈ ( , G t ) | p (E) = 1 } , ++ (E, G t ) ≡ p ∈ ( , G t ) p (G) &gt; 0 ∀G ∈ G t : G ⊆ E p (G) = 0 ∀G ∈ G t : G E .</formula><p>Denoting by supp p the support { ∈ : p ( ) &gt; 0} of p ∈ ( ), for each subset E of we have</p><formula xml:id="formula_25">(E) = {p ∈ ( ) : supp p ⊆ E} and ++ (E) = {p ∈ ( ) : supp p = E} .</formula><p>In particular, (G t ( )) is the set of all predictive distributions that can be obtained by conditioning on G t ( ) from probabilities p ∈ ( ) such that p (G t ( )) &gt; 0, while ++ (G t ( )) is the subset of (G t ( )) derived under the further condition that p ∈ ( ) be such that p &gt; 0 for all ∈ G t ( ). Similarly, for each E ∈ A (G t ) we have</p><formula xml:id="formula_26">(E, G t ) = p |G t : p ∈ (E)</formula><p>and</p><formula xml:id="formula_27">++ (E, G t ) = p |G t : p ∈ ++ (E) .</formula><p>If the vector space M ( , G t ) of all measures on A (G t ) is endowed with the product topology, then ++ (E, G t ) is the relative interior of the convex set (E, G t ) (see <ref type="bibr" target="#b25">[26]</ref>, to which we refer for the Convex Analysis terminology and notation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Axioms</head><p>Let the binary relations t, on H represent the agent's preferences at any time-state node. Next are stated several properties (axioms) of the preference relation, which will be used in the sequel.</p><p>Axiom 1 (Conditional preference-CP). For each (t, ) ∈ T × :</p><formula xml:id="formula_28">(i) t, coincides with t, if G t ( ) = G t . (ii) If h ,</formula><p>= h , for all t and ∈ G t ( ), then h ∼ t, h .</p><p>(i) says that preferences orderings are "adapted" and allows to write t,G if G ∈ G t . (ii) states that at time t in event G only "continuation acts" matter for choice.</p><p>Axiom 2 (Variational preferences-VP). For each (t, ) ∈ T × : (i) t, is complete and transitive. (ii) For all h, h ∈ H and y, y ∈ X T , and for all ∈ (0, 1)</p><formula xml:id="formula_29">, if h + (1 -)y t, h + (1 -)y, then h + (1 -)y t, h + (1 -)y . (iii) For all h, h , h ∈ H, the sets { ∈ [0, 1] : h + (1 -)h t, h } and { ∈ [0, 1] : h t, h + (1 -)h } are closed. (iv) For all h, h ∈ H, if h 0 , h 1 , . . ., h T t, h 0 , h 1 , . . ., h T for all ∈ , then h t, h . (v) For all h, h ∈ H, if h ∼ t, h , then h + (1 -) h t,</formula><p>h for all ∈ (0, 1). (vi) There exist x t, x in X such that for all ∈ (0, 1) there is x ∈ X satisfying either</p><formula xml:id="formula_30">x t, x + (1 -) x or x + (1 -) x t, x.</formula><p>The requirement here is that at every time-state node the agent has (unbounded) VP; see Maccheroni et al. <ref type="bibr" target="#b20">[21]</ref> for a discussion of (i)-(vi).</p><p>Axiom 3 (Risk preference-RP). For any y ∈ X T and all x, x , x , x ∈ X, if</p><formula xml:id="formula_31">y -{ , +1} , x, x t, y -{ , +1} , x , x</formula><p>holds for some (t, ) ∈ T × and some t, then it holds for all (t, ) ∈ T × and all t. 6   This is a standard stationarity axiom.</p><p>Axiom 4 (Dynamic consistency-DC). For each (t, ) ∈ T × with t &lt; T , and all h, h ∈ H, if h = h for all t and h t+1, h for all ∈ , then h t, h .</p><p>As Epstein and Schneider <ref type="bibr">[6, p. 6]</ref> observe "According to the hypothesis, h and h are identical for times up to t, while h is ranked (weakly) better in every state at t + 1. 'Therefore', it should be ranked better also at (t, ). A stronger and more customary version of the axiom would require the same conclusion given the weaker hypothesis that</p><formula xml:id="formula_32">h t ( ) = h t ( ) and h t+1, h for all ∈ G t ( ) .</formula><p>In fact, given CP, the two versions are equivalent." Again, we refer to <ref type="bibr" target="#b5">[6]</ref> for a discussion of dynamic consistency, which might be sometimes controversial in the presence of ambiguity. 7  A state</p><formula xml:id="formula_33">∈ is t, -null if h = h for all = implies h ∼ t, h .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Axiom 5 (Full support-FS).</head><p>No state in is 0, -null.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The representation</head><p>We first extend to the current dynamic setting the notion of ambiguity index c we used in the static setting of <ref type="bibr" target="#b20">[21]</ref>. A dynamic ambiguity index is a family {c t } t∈T of functions c t : × ( ) → [0, ∞] such that for all t ∈ T :</p><formula xml:id="formula_34">(i) c t (•, p) : → [0, ∞] is G t -measurable for all p ∈ ( ), 8 (ii) c t ( , •) : ( ) → [0, ∞] is grounded, 9 closed and convex, with dom c t ( , •) ⊆ (G t ( ))</formula><p>and dom c t ( ,</p><formula xml:id="formula_35">•) ∩ ++ (G t ( )) = ∅, for all ∈ .</formula><p>Observe that the effective domains of the c t ( , •) consist of predictive distributions, that is, of the conditional probabilities on the nodes G t ( ). In the terminology more used in the MP model, we would call them the Bayesian updates of the original priors p ∈ ( ).</p><p>In our first result we characterize a dynamic version ofVP that do not necessarily satisfy dynamic consistency. Notice that in <ref type="bibr" target="#b8">(9)</ref> we consider ++ ( ) in order to have well-defined conditional probabilities p G t ( ) . Proposition 1. The following statements are equivalent:</p><formula xml:id="formula_36">(a) t,</formula><p>satisfy CP, VP, RP, and for each (t, ) ∈ T × no state in G t ( ) is t, -null. 6 Notation: y -{ , +1} , x, x ≡ y 0 , . . ., y -1 , x, x , y +2 , . . ., y T if &lt; T and y 0 , . . ., y T -1 , x otherwise. 7 Inspection of our proofs shows that the weaker version of DC in which is replaced by ∼ is enough to obtain the results of the following section. 8 Equivalently, c t ( ,</p><formula xml:id="formula_37">•) = c t , • for all , ∈ such that G t ( ) = G t . 9 That is, min p∈ ( ) c t ( , p) = 0.</formula><p>(b) There exist a scalar &gt; 0, an unbounded affine function u : X → R, and a dynamic ambiguity index {c t } such that, for each (t, ) ∈ T × , t, is represented by</p><formula xml:id="formula_38">V t ( , h) ≡ inf p∈ ++ ( ) ⎛ ⎝ t -t u (h ) dp G t ( ) + c t , p G t ( ) ⎞ ⎠ ∀h ∈ H. (9)</formula><p>Moreover, , u , c t represents t, in the sense of (9) if and only if = , u = au + b for some a &gt; 0 and b ∈ R, and c t = {ac t }.</p><p>As a result, for all t ∈ T and all h ∈ H, the preference functional</p><formula xml:id="formula_39">V t (•, h) is a G t -measurable random variable V t (h) = inf p∈ ++ ( ) ⎛ ⎝ E p ⎛ ⎝ t -t u (h ) |G t ⎞ ⎠ + c t (p |G t ) ⎞ ⎠ .</formula><p>We call dynamic VP the (families of) preferences satisfying CP, VP, RP, and such that no state in G t ( ) is t, -null. It is natural to wonder what restriction on the dynamic ambiguity index would characterize the dynamic VP that satisfy dynamic consistency. This condition, which we have called the "no-gain condition" in the Introduction, is given in the next theorem, which is the main result of the paper.</p><p>Theorem 1. The following statements are equivalent:</p><formula xml:id="formula_40">(a) t,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>satisfy CP, VP, RP, FS, and DC. (b)</head><p>There exists a scalar &gt; 0, an unbounded affine function u : X → R, and a dynamic ambiguity index {c t } such that, for each (t, ) ∈ T × , t, is represented by</p><formula xml:id="formula_41">V t ( , h) ≡ inf p∈ ++ ( ) ⎛ ⎝ t -t u (h ) dp G t ( ) + c t , p G t ( ) ⎞ ⎠ ∀h ∈ H (10) and c t ( , q) = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p), (<label>11</label></formula><formula xml:id="formula_42">)</formula><p>for all q ∈ (G t ( )) and all t &lt; T .</p><p>Moreover, , u , c t represents t, in the sense of <ref type="bibr" target="#b9">(10)</ref> if and only if = , u = au+b for some a &gt; 0 and b ∈ R, and c t = {ac t }.</p><p>Therefore, dynamic VP satisfy dynamic consistency if and only if their dynamic ambiguity index has the recursive structure <ref type="bibr" target="#b10">(11)</ref>, that is, if and only if the no-gain condition is satisfied and updating is done according to Bayes' Rule.</p><p>In turn, <ref type="bibr" target="#b10">(11)</ref> delivers the recursive representation</p><formula xml:id="formula_43">V t ( , h) = u (h t ( )) + min r∈ ( ,G t+1) V t+1 (h) dr + t ( , r)<label>(12)</label></formula><p>of the agent's preference functional V t , where</p><formula xml:id="formula_44">t ( , r) = min p∈ (G t ( )):p |G t+1 =r c t ( , p) ∀r ∈ ( , G t+1 )<label>(13)</label></formula><p>(see Lemma 6 in the Appendix).</p><p>In view of all this, we call recursive VP, the dynamic VP satisfying dynamic consistency, and we call recursive ambiguity indexes their dynamic ambiguity indexes, that is, the dynamic indexes satisfying the no-gain condition <ref type="bibr" target="#b10">(11)</ref> for some &gt; 0.</p><p>Recall from the Introduction that the recursive formula <ref type="bibr" target="#b10">(11)</ref> has a transparent interpretation under the game against Nature interpretation of our setting, in which {c t } is a dynamic cost for Nature. In fact, <ref type="bibr" target="#b10">(11)</ref> suggests that the cost for Nature of choosing q at time t in state can be decomposed as the sum of: the discounted expected cost of choosing q's conditionals at time t + 1, 10 plus the cost t , q |G t+1 of inducing q |G t+1 as one-period-ahead marginal. By ( <ref type="formula" target="#formula_41">11</ref>) and ( <ref type="formula" target="#formula_43">12</ref>), both Nature's costs and agent's preferences are recursive.</p><p>As <ref type="bibr" target="#b11">(12)</ref> shows, in our recursive representation, the evolution of ambiguity aversion is determined by how the functions t ( , •) depend on t and . This will emerge clearly in the next section. Here, we observe that in applications some special specification of such dependence can be useful. For example, in the standard setup = Z T discussed in Section 2.1 we can assume a Markovian structure, where t ( ) depends on only through the last observation, or an independent structure, where t ( ) does not depend on t and (see Example 6 below).</p><p>Behaviorally, these dependence structures can be characterized by suitable stationarity requirements on the preferences t, .</p><p>Finally, after the completion of an earlier version of this paper, we learned of independent work by Detlefsen and Scandolo <ref type="bibr" target="#b0">[1]</ref>, who arrive at a condition related to <ref type="bibr" target="#b10">(11)</ref> in studying conditions for the time consistency of risk measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Going backward</head><p>A main advantage of the recursive structure of the no-gain condition <ref type="bibr" target="#b10">(11)</ref> is that it permits the construction by backward induction of recursive ambiguity indexes, and so of recursive VP via <ref type="bibr" target="#b11">(12)</ref> and <ref type="bibr" target="#b12">(13)</ref>.</p><p>The next result provides the key ingredient for the desired backward induction construction Proposition 2. Let {c t } be a dynamic ambiguity index. For all t &lt; T and ∈ , set 11</p><formula xml:id="formula_45">t ( , r) ≡ min p∈ (G t ( )):p |G t+1 =r c t ( , p) ∀r ∈ ( , G t+1 ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The family t t&lt;T of functions</head><formula xml:id="formula_46">t : × ( , G t+1 ) → [0, ∞] is such that for all t &lt; T : (i) t (•, r) : → [0, ∞] is G t -measurable for all r ∈ ( , G t+1 ). (ii) t ( , •) : ( , G t+1 ) → [0, ∞] is grounded, closed and convex, with dom t ( , •) ⊆ (G t ( ) , G t+1 ) and dom t ( , •) ∩ ++ (G t ( ) , G t+1 ) = ∅, for all ∈ . 10 In fact, G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) = c t+1 q G t+1 dq.</formula><p>11 Here, we adopt the convention that the minimum over the empty set is ∞.</p><p>The index t ( , r) can be interpreted as the cost for Nature of inducing r as one-period-ahead marginal, as suggested by ( <ref type="formula" target="#formula_43">12</ref>) and <ref type="bibr" target="#b12">(13)</ref>. Since the properties of t ( , •) on ( , G t+1 ) are analogous to those of a static (or dynamic) ambiguity index on the set of the agent's subjective beliefs, we call one-period-ahead ambiguity index a family t t&lt;T of functions that satisfies conditions (i) and (ii) of Proposition 2.</p><p>Next we characterize recursive ambiguity indexes by means of one-period-ahead ones, thus giving the desired backward induction construction of recursive ambiguity indexes. Here, C is the indicator function defined in (3) and, given ∈ , d is the Dirac probability assigning mass 1 to . </p><formula xml:id="formula_47">c t ( , q) = ⎧ ⎪ ⎨ ⎪ ⎩ G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + t , q |G t+1 ∀q ∈ (G t ( )) , ∞ ∀ q ∈ ( ) \ (G t ( )) .</formula><p>In this case, t is unique and satisfies <ref type="bibr" target="#b12">(13)</ref>.</p><p>The important implication is (b) ⇒ (a), which allows to construct any recursive ambiguity index by backward induction: it suffices to specify at any non-terminal node G = G t ( ) a grounded, closed and convex function G on the set of all probabilities on the branches springing from G.</p><p>This decomposition of cost functions in one-period-ahead components is a key feature of our derivation. The next example illustrates this feature by showing what happens in a binomial tree if we take at each non-terminal node the relative Gini concentration index 2 (p q), defined in <ref type="bibr" target="#b18">(19)</ref>, as one-period-ahead ambiguity index. Example 6. Consider Example 1 with T = 2, that is, = {0, 1} 2 . We have</p><formula xml:id="formula_48">G 1 = {{0} , {1}} and G 2 = {{0, 0} , {0, 1} , {1, 0} , {1, 1}} , where {0} = {(0, 0) , (0, 1)} and {1} = {(1, 0) , (1, 1)}. Hence, ( , G 1 ) = {(r, 1 -r) : r ∈ [0, 1]} , ({0} , G 2 ) = ({0}) = {(r, 1 -r) : r ∈ [0, 1]} , ({1} , G 2 ) = ({1}) = {(r, 1 -r) : r ∈ [0, 1]} ,</formula><p>and ( , G 2 ) = ( ). Let q ∈ ( ) be the uniform distribution with q ( ) = 1  4 for all ∈ , and set ( )</p><formula xml:id="formula_49">≡ 2 2 + 2 (1 -) 2 -1 for each ∈ [0, 1]. Define 0 ( , p) ≡ 2 p q |G 1 = (p (0)) ∀p ∈ ( , G 1 ) , 1 ({0} , p) ≡ 2 p q {0} = (p (0, 0)) if p ∈ ({0}) , ∞ otherwise, and 1 ({1} , p) ≡ 2 p q {1} = (p (1, 0)) if p ∈ ({1}) , ∞ otherwise.</formula><p>By Theorem 2, using these one-period-ahead ambiguity indexes we can construct a recursive dynamic index, given by</p><formula xml:id="formula_50">c 1 ({0} , p) = 1 ({0} , p) , c 1 ({1} , p) = 1 ({1} , p) ,</formula><p>and where we set p ij = p (i, j ) for i, j ∈ {0, 1} and we adopt the convention 0 (0/0) = 0.</p><formula xml:id="formula_51">c 0 ( , p) = p ({0}) c 1 {0} , p {0} + p ({1}) c 1 {1} , p {1} + 0 ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Special cases</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Multiple prior preferences</head><p>We now show that Epstein and Schneider's <ref type="bibr" target="#b5">[6]</ref>'s characterization of dynamic MP preferences is a special case of ours, modulo some minor differences (they do not assume unboundedness and assume a slightly stronger version of dynamic consistency).</p><p>MP preferences are the special class of VP satisfying the certainty independence condition of Gilboa and Schmeidler <ref type="bibr" target="#b8">[9]</ref>. In the present dynamic setting, this amounts to consider: MP(ii) For all h, h ∈ H, y ∈ X T , and ∈ (0, 1), h t, h if and only if h+ <ref type="bibr">(1-)</ref></p><formula xml:id="formula_52">y t, h + (1 -)y,</formula><p>which is a stronger version of VP(ii) (in <ref type="bibr" target="#b20">[21]</ref> we discuss the different behavioral implications of these two axioms). Under the stronger MP(ii), the ambiguity index c t ( ) becomes an indicator function, and the no-gain condition (11) coincides with rectangularity, which is the condition that <ref type="bibr" target="#b5">[6]</ref> used to characterize recursive MP preferences.</p><formula xml:id="formula_53">Corollary 1. Let t,</formula><p>be a family of dynamic VP. The following statements are equivalent:</p><formula xml:id="formula_54">(a) t,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>satisfy MP(ii).</head><p>(b) For every t and , there exists a closed and convex subset C t ( ) of ( ) such that c t ( ) = C t ( ) . In this case, condition <ref type="bibr" target="#b10">(11)</ref> is equivalent to</p><formula xml:id="formula_55">C t ( ) = ⎧ ⎨ ⎩ G∈G t+1 p G r (G) : p G ∈ C t+1 (G) ∀G ∈ G t+1 and r ∈ C t ( ) |G t+1 ⎫ ⎬ ⎭ , (<label>14</label></formula><formula xml:id="formula_56">)</formula><p>for all ∈ and t &lt; T , where C t+1 (G) = C t+1 for all ∈ G, and C t ( ) |G t+1 is the set of restrictions to the algebra generated by G t+1 of the probabilities in C t ( ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Multiplier preferences</head><p>Given p, q ∈ ( ), the relative entropy (or Kullback-Leibler distance) of p w.r.t. q is</p><formula xml:id="formula_57">R (p q) ≡ ⎧ ⎨ ⎩ ∈ p ( ) log p ( ) q ( ) if p&gt;q, ∞ otherwise,</formula><p>with the convention 0 ln (0/a) = 0 for all a 0. Analogously, if p, q ∈ ( , G), where G is a partition of , the relative entropy of p w.r.t. q on G is</p><formula xml:id="formula_58">R G (p q) ≡ ⎧ ⎨ ⎩ G∈G p (G) log p (G) q (G) if p&gt;q, ∞ otherwise,</formula><p>again with the convention 0 ln (0/a) = 0 for all a 0. Given a reference probabilistic model q ∈ ++ ( ), we call dynamic multiplier preferences the family of preferences on H represented for every t and by</p><formula xml:id="formula_59">V t ( , h) ≡ inf p∈ ++ ( ) t -t u (h ) dp G t ( ) + -t R p G t ( ) q G t ( ) ∀h ∈ H. (<label>15</label></formula><formula xml:id="formula_60">)</formula><p>The name is inspired by the robust control approach of Hansen and Sargent <ref type="bibr" target="#b10">[11]</ref>. <ref type="foot" target="#foot_5">12</ref> They interpret as a coefficient of uncertainty aversion, an interpretation we formalize and discuss in <ref type="bibr" target="#b20">[21]</ref>. Observe that, by a classical variational formula (see <ref type="bibr">[4, p.</ref> 34]), we can equivalently write <ref type="bibr" target="#b14">(15)</ref> as</p><formula xml:id="formula_61">V t ( , h) = --t log ⎛ ⎝ exp ⎛ ⎝ - t u (h ) ⎞ ⎠ dq G t ( ) ⎞ ⎠ , (<label>16</label></formula><formula xml:id="formula_62">)</formula><p>a very convenient expression in calculations.</p><p>Next we show that dynamic multiplier preferences are recursive VP and their (recursive) ambiguity index is</p><formula xml:id="formula_63">c t ( , p) = -t R p G t ( ) q G t ( ) (<label>17</label></formula><formula xml:id="formula_64">)</formula><p>for all t ∈ T , ∈ , and p ∈ ( ).</p><p>Theorem 3. For all q ∈ ++ ( ), &gt; 0, unbounded affine u : X → R, and &gt; 0, the dynamic multiplier preferences represented by <ref type="bibr" target="#b14">(15)</ref> are recursive VP with ambiguity index given by <ref type="bibr" target="#b16">(17)</ref>.</p><p>In particular,</p><formula xml:id="formula_65">V t ( , h) = u (h t ( )) + min r∈ ( ,G t+1) V t+1 (h) dr+ -t R G t+1 r q G t ( ) |G t+1 , (<label>18</label></formula><formula xml:id="formula_66">)</formula><p>for each h ∈ H, ∈ , and t &lt; T .</p><p>The recursive formulation <ref type="bibr" target="#b17">(18)</ref> is especially important because it makes it possible to use standard dynamic programming tools in studying optimization problems involving dynamic multiplier preferences. This class of dynamic VP is therefore very tractable, something important for applications.</p><p>The recursive nature of multiplier preferences was already observed by Hansen and Sargent (see <ref type="bibr">[11, p. 64]</ref>). 13 The contribution of Theorem 3 is to show that this is a very special case of the general recursive representation given in Theorems 1 and 2. As a result, Theorem 3 provides the proper theoretical underpinning for this crucial property of multiplier preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Mean-variance preferences</head><p>We conclude by observing that Theorem 3 does not hold when we replace the relative entropy with a general convex statistical distance (see <ref type="bibr" target="#b19">[20]</ref>). For example, consider the relative Gini concentration index (or 2 -distance)</p><formula xml:id="formula_67">2 (p q) ≡ ⎧ ⎨ ⎩ ∈ (p ( )) 2 q ( ) -1 if p&gt;q, ∞ otherwise.<label>(19)</label></formula><p>In <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23]</ref> we show that 2 2 (p q) is the ambiguity index associated with the classic meanvariance preferences. For example, for f : → R the domain of monotonicity of such preferences we have</p><formula xml:id="formula_68">f dq - 1 2 Var (f ) = min p∈ ( ) f dp + 2 2 (p q) ,</formula><p>where q ∈ ++ ( ) is again a reference probability.</p><p>It is easily seen that the dynamic ambiguity index given by</p><formula xml:id="formula_69">c t ( , p) ≡ 2 -t 2 p G t ( ) q G t ( )</formula><p>is not recursive in general, and so the dynamic VP represented by</p><formula xml:id="formula_70">V t ( , h) ≡ inf p∈ ++ ( ) ⎛ ⎝ t -t u (h ) dp G t ( ) + 2 -t 2 p G t ( ) q G t ( ) ⎞ ⎠</formula><p>are not dynamically consistent. 13 Skiadas <ref type="bibr" target="#b28">[29]</ref> studies the recursive structure of a continuous time version of a robust control preference functional.</p><p>It is possible, however, to construct a dynamically consistent version of (monotone) meanvariance preferences along the lines of Example 6 by using the relative Gini concentration index as a one-period-ahead ambiguity index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Differential properties</head><p>Optimization problems are pervasive in economic applications and the differential properties of the involved preference functionals play a key role in their resolution. For this reason we now study the differential properties of our recursive variational preference functionals, and we show that their analytical tractability is adequate for applications.</p><p>This extends to the dynamic setting of this paper what we established in <ref type="bibr" target="#b20">[21]</ref>, where we showed that in the static case variational preference functionals have nice differentiability properties.</p><p>Throughout the section we assume that X is the set of all monetary lotteries (i.e., the set of all finitely supported probability measures on R). Formally, X = (R). An act f is monetary if f (t, ) is a degenerate lottery for every (t, ) ∈ T × , and we denote by F the subset of H consisting of all monetary acts. 14  In this section we consider a recursive variational preference functional V t ( , •) : H → R, as given by Theorem 1. We also make the standard assumption that the associated utility function u is concave (thus reflecting risk aversion) and strictly increasing on R.</p><p>Like Epstein and Wang <ref type="bibr" target="#b6">[7]</ref>, for ∈ , t &lt; T , and f ∈ F, we call one-period-ahead directional derivative of V t ( ,</p><formula xml:id="formula_71">•) at f, the functional V t ( , f ; •) : E t → R defined by V t ( , f ; e) ≡ lim ↓0 V t ( , f + e) -V t ( , f ) ∀e ∈ E t ,</formula><p>where E t is the subspace of F consisting of all processes e such that e = 0 if = t, t + 1. These processes represent current and one-period-ahead consumption perturbations.</p><p>The functional V t ( , •) is differentiable on F if and only if u is differentiable on R and t ( , •) is essentially strictly convex. 15 In particular,</p><formula xml:id="formula_72">•) is (one-period-ahead Gateaux) differentiable at f if V t ( , f ; •) is linear on E t . In this case, V t ( , f ; •) is the (Gateaux) differential of V t ( , •) at f. Theorem 4. Let ∈ and t &lt; T . Then, V t ( ,</formula><formula xml:id="formula_73">V t ( , f ; e) = u (f t ( )) e t ( ) + e t+1 u (f t+1 ) d ∀f ∈ F, e ∈ E t , (<label>20</label></formula><formula xml:id="formula_74">)</formula><p>where</p><formula xml:id="formula_75">{ } = arg min r∈ ( ,G t+1) V t+1 (f ) dr + t ( , r) .</formula><p>This result provides a full characterization of differentiability for the recursive variational preference functional V t ( , •), and it provides an explicit formula for evaluating the differential V t ( , f ; •).</p><p>Observe that the strict convexity of t ( , •) holds, under a mild condition, for all divergence preferences, a large class of VP we introduced in <ref type="bibr" target="#b20">[21]</ref> and that includes multiplier preferences. 14 Here, we are making the usual identification of z ∈ R with d z ∈ X. Moreover, throughout this section, primed letters denote "derivatives". 15 For a formal definition of essential strict convexity, see <ref type="bibr">[26, p. 253</ref>]. Needless to say, a strictly convex functional is a fortiori essentially strictly convex.</p><p>For example, by Theorem 3 (and by some well-known properties of the relative entropy, see <ref type="bibr">[4, p. 34]</ref>), formula <ref type="bibr" target="#b19">(20)</ref> takes the following neat form for dynamic multiplier preferences:</p><formula xml:id="formula_76">V t ( , f ; e) = u (f t ( )) e t ( ) + e t+1 u (f t+1 ) exp -( t+1 / )V t+1 (f ) dq G t ( ) exp -( t+1 / )V t+1 (f ) dq G t ( )</formula><p>for each f ∈ F and e ∈ E t . As V t ( , •) is concave, the powerful theory of superdifferentials can be used when V t ( , •) is not differentiable. Besides its intrinsic interest, this is also important conceptually as points of non-differentiability, the so-called "kinks", play an important role in some applications of the MP model and of the closely related Choquet expected utility model (see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b23">24]</ref>).</p><p>Denote by M (G t ( ) , G t+1 ) the set of all measures on A (G t+1 ) that vanish on each sub-</p><formula xml:id="formula_77">set of G t ( ) c . A one-period-ahead supergradient of V t ( ) at f is an element (k, m) of R × M (G t ( ) , G t+1 ) such that V t ( , f ; e) ke t ( ) + e t+1 dm ∀e ∈ E t .</formula><p>The superdifferential *V t ( , f ) of V t ( , •) at f is the set of all one-period-ahead supergradients at f. The superdifferential</p><formula xml:id="formula_78">*V t ( , f ) is a singleton if and only if V t ( , •) is differentiable at f; in this case, *V t ( , f ) = V t ( , f ; •) .</formula><p>The following result is the superdifferential version of Theorem 4.</p><p>Theorem 5. For all ∈ , t &lt; T , and f ∈ F, *V t ( , f ) consists of all pairs u (f t ( )) , u (f t+1 ) d <ref type="bibr" target="#b20">(21)</ref> such that u (f t ( )) ∈ *u (f t ( )), u (f t+1 ) is a G t+1 -measurable selection of *u (f t+1 ), and ∈ arg min r∈ ( ,G t+1) V t+1 (f ) dr + t ( , r) . <ref type="foot" target="#foot_6">16</ref>Eq. ( <ref type="formula">21</ref>) provides an explicit formula for the superdifferential *V t ( , f ), which is equivalent to <ref type="bibr" target="#b19">(20)</ref> when *V t ( , f ) is a singleton, that is, when V t ( , •) is differentiable at f. Theorem 5 generalizes Epstein and Wang [7, Lemma 1], and we expect that this result can be used to extend their asset pricing analysis to recursive VP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>Ambiguity adverse behavior is pervasive, and the theory of ambiguity aversion has found applications in macroeconomics, finance, even political analysis.</p><p>A widely accepted theory has been so far the theory of MP of <ref type="bibr" target="#b8">[9]</ref>. Different approaches, mostly found under the name of robust preferences, have made desirable an extension of this theory to include a larger class of behaviors. The extension, in the static case, has been provided by the theory of VP introduced by <ref type="bibr" target="#b20">[21]</ref>. This is, however, a theory of static choice, while most of the applications we have mentioned are in dynamic environments: hence, a further extension to the intertemporal problem is desirable. This paper provides such a theory.</p><p>Our main results can be summarized as follows. The first, Proposition 1, characterizes the intertemporal preferences that have a variational representation, the so-called dynamic VP (intuitively, variational decision makers can be viewed as making their choices "as if" they think they are facing a malevolent opponent, which we call Nature).</p><p>The second result, Theorem 1, characterizes the dynamic preferences that are time consistent. In particular, a variational decision maker is dynamically consistent if and only if he thinks that Nature is also dynamically consistent.</p><p>The third result, Theorem 2, provides a decomposition of the cost function into one step ahead costs, paid by Nature in every period. This decomposition makes it possible to use recursive analysis in studying the dynamic choice problem of a decision maker with VP.</p><p>The fourth result, Theorem 3, is an application of Theorem 1 and it shows that the dynamic consistency of the widely used multiplier preferences introduced by Hansen and Sargent is a consequence of our general Theorems 1 and 2.</p><p>The final results, Theorem 4 and 5, show that recursive VP have nice differential properties, something crucial for their use in the optimization problems that arise in most economic applications.</p><p>We close by observing that, though in the paper we assumed both and T finite, we expect that the extension to the infinite case can be carried out in standard ways. Moreover, even though in our representation theorems we consider standard discounted utility, some results can be extended to include hyperbolic discounting. For example, this can be done by weakening Axiom 3 along the lines of Hayashi <ref type="bibr" target="#b13">[14]</ref>. However, the motivation behind hyperbolic discounting is very different from model uncertainty and for this reason here we prefer to use standard discounting in order to better focus the paper. </p><formula xml:id="formula_79">(a) If , ∈ R are such that |G = |G , then J ( ) = J ( ); (b) J ( + ) = J ( ) + (G) if , ∈ R and is constant on G; (c) J ( 1 G c ) = 0 for all ∈ R ; 20 (d) dom J * ⊆ (G).</formula><p>Next lemma is the first important step towards the proof of Proposition 1. </p><formula xml:id="formula_80">( ) → [0, ∞], such that dom c t ( , •) ⊆ (G t ( )) and c t ( , •) = c t , • if G t ( ) = G t</formula><p>, &gt; 0, and an unbounded affine u : X → R such that: for every t and , t, is represented by V t ( , •), where</p><formula xml:id="formula_81">V t ( , h) ≡ min p∈ ( ) ⎛ ⎝ t -t u (h ) dp + c t ( , p) ⎞ ⎠ ∀h ∈ H. (<label>22</label></formula><formula xml:id="formula_82">)</formula><p>Moreover, ¯ , ū, { ct ( , •)} represent t, in the sense of (22</p><formula xml:id="formula_83">) iff ¯ = , ū = au + b for some a &gt; 0 and b ∈ R and { ct ( , •)} = {ac t ( , •)}.</formula><p>Finally, if |G t ( )| &gt; 1, the following facts are equivalent:</p><formula xml:id="formula_84">(i) for all h ∈ H, V t ( , h) = inf p∈ri (G t ( )) ⎛ ⎝ t -t u (h ) dp + c t ( , p) ⎞ ⎠ ;<label>(23)</label></formula><p>18 co I denotes the closed and convex hull of I, J * the concave conjugate of J. 19 ri C denotes the relative interior of C, dom I the effective domain of I. 20 For every A ⊆ , 1 A is the vector defined by 1 A ( )</p><formula xml:id="formula_85">≡ 1 if ∈ A, 1 A ( ) ≡ 0 if / ∈ A. (ii) no state in G t ( ) is t, -null; (iii) dom c t ( , •) ∩ ri (G t ( )) = ∅.</formula><p>Notice that ( <ref type="formula" target="#formula_81">22</ref>) can be rewritten as</p><formula xml:id="formula_86">V t ( , h) = min p∈ (G t ( )) ⎛ ⎝ t -t u (h ) dp + c t ( , p) ⎞ ⎠ ∀h ∈ H. (<label>24</label></formula><formula xml:id="formula_87">) Moreover, if |G t ( )| = 1, G t ( ) is a singleton { }, (G t ( )) = ri (G t ( ))</formula><p>and (iii) is automatically satisfied, in this case both ( <ref type="formula" target="#formula_81">22</ref>) and ( <ref type="formula" target="#formula_84">23</ref>) collapse to</p><formula xml:id="formula_88">V t ( , h) = t -t u (h ( )).</formula><p>For the rest of the paper, we indifferently write c t ( , •), c t ( ), or c t, , and</p><formula xml:id="formula_89">V t ( , •), V t ( ) or V t, .</formula><p>Proof. (a) ⇒ (b). A variation on the proof of Lemma A.1 of <ref type="bibr" target="#b5">[6]</ref> (see also <ref type="bibr" target="#b29">[30]</ref>) delivers the first two steps:</p><p>Step 1: There exist &gt; 0 and an unbounded affine u : X → R such that, for all (t, ) ∈ T × , t, on X T is represented by U t (y) ≡ t -t u (y ) for all y ∈ X T .</p><p>Step 2: For all (t, ) ∈ T × , and all h ∈ H there exists y = y (t, , h) ∈ X T (indeed constant) such that y ∼ t, h.</p><p>Then it is easy to check that:</p><p>Step 3: For all (t, ) ∈ T × , the correspondence V t, : H → R, defined by V t, (h) ≡ U t (y) if h ∼ t, y ∈ X T , is a well-defined function that represents t, on H.</p><p>Each h ∈ H can be regarded as a function h : → X T , and U t : X T → R is an affine function for every t ∈ T . Set U t (h) ≡ U t • h. By definition, U t (h) : → R and U t (h) ≡ U t h = t -t u h for all ∈ . In particular, if y , = y for all ∈ T and all ∈ , then U t (y) = t -t u (y ) = U t (y 0 , . . ., y T ) for all ∈ . 21  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Moreover, U t h + (1 -) h = U t (h) + (1 -) U t h for all h, h ∈ H and ∈ [0, 1]</head><p>. Up to a cardinal transformation of u, we can assume u (X) ∈ R, R + , R ++ , R -, R --. For the rest of the proof the case u (X) = R ++ is considered (the arguments we use can be easily adapted to the remaining ones).</p><p>Step 4. For all t ∈ T , {U t (h) : h ∈ H} = u (X) .</p><p>Proof of the Step. The inclusion ⊆ is trivial. If t &lt; T and ∈ u (X) , there exists &gt; 0 such that -∈ u (X) , choose x ∈ X such that u x = T &gt; t -t -1 . For all ∈ , there exists x ( ) ∈ X such that u x ( ) 21 The identification between acts with consequences depending only on time (and not on state) and elements of X T corresponds here to the equivalence between constant functions on and real numbers.</p><formula xml:id="formula_90">= t-T -. Set h , ≡ x if &lt; T , x ( ) if = T .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This delivers, U t h =</head><formula xml:id="formula_91">t -t u h = T &gt; t -t u x + T -t u x ( ) = u x T &gt; t -t + -=</formula><p>for all ∈ ; as wanted. If t = T , set = 0 and choose x arbitrarily.</p><p>Step 5: For all (t, ) ∈ T × , the correspondence I t, : u (X) → R, defined by I t, ( ) ≡ V t, (h) if = U t (h) for some h ∈ H, is a well-defined, monotonic, and normalized function.</p><p>Proof of the Step. If h and h in H are such that = U t (h) = U t h , for all ∈ we have</p><formula xml:id="formula_92">t -t u h = t -t u h and h ∼ t, h</formula><p>. By VP(iv), h ∼ t, h and V t, (h) = V t, h . This implies that I t, is a well-defined function since for every ∈ u (X) there is h ∈ H such that = U t (h). Monotonicity is proved along the same lines. As to normalization, if b ∈ u (X), take Step 6: Let (t, ) ∈ T × . For every ∈ u (X) and for every b ∈ R such that +b ∈ u (X) ,</p><formula xml:id="formula_93">x b ∈ X such that u x b = t -t -</formula><formula xml:id="formula_94">I t, ( + b) = I t, ( ) + b. Proof of the Step. Let = U t h , = U t h ∈ u (X) , b = U t x , b = U t x ∈ u (X), VP(ii) guarantees that for all ∈ (0, 1), h + (1 -)x ∼ t, h + (1 -)x implies h + (1 -)x ∼ t, h + (1 -)x , i.e. V t, h + (1 -)x = V t, h + (1 -)x implies V t, h + (1 -)x = V t, h + (1 -)x , hence I t, U t h + (1 -)x = I t, U t h + (1 -)x implies that I t, U t h + (1 -)x = I t, U t h + (1 -) x , and, finally, I t, + (1 -)b = I t, + (1 -)b implies I t, + (1 -)b = I t, + (1 -)b . Replacing with / ∈ u (X) , with / ∈ u (X) , b with b / (1 -) ∈ u (X), b with b / (1 -) ∈ u (X), it follows that I t, + b = I t, + b implies I t, + b = I t, + b<label>(25)</label></formula><p>for all , ∈ u (X) , b , b ∈ u (X). Let ∈ u (X) , then min ∈ u (X), but I t, is monotonic and normalized, thus I t, ( ) I t, min = min ∈ u (X), and hence, I t, ( ) ∈ u (X). Let b &gt; 0, there is &gt; 0 such that -∈ u (X) and I t, ( ) -∈ u (X). By normalization and (25), I t, ((</p><formula xml:id="formula_95">-) + ) = I t, ( ) = I t, I t, ( ) -+ implies I t, ( + b) = I t, (( -) + ( + b)) = I t, I t, ( ) -+ ( + b) = I t, ( ) + b. If b &lt; 0, then I t, ( ) = I t, (( + b) -b) = I t, ( + b) -b, as wanted.</formula><p>Moreover, from VP(v), it immediately follows that:</p><p>Step 7: Let (t, ) ∈ T × . For every , ∈ u (X) such that I t, ( ) = I t, , and every ∈ (0, 1), I t, + (1 -) I t, ( ).</p><p>Steps 5-7 and the results we prove in <ref type="bibr" target="#b21">[22]</ref> imply that: for all (t, ) ∈ T × , I t, is a concave and normalized niveloid on u (X) . The restriction of its concave conjugate to ( ), I * t, (p) ≡ inf ∈u(X)</p><p>, p -I t, ( ) for all p ∈ ( ), is the unique concave and upper semicontinuous function I # t, on ( ) such that I t, ( ) = min p∈ ( ) , p -I # t, (p) for all ∈ u (X) . Moreover, the correspondence J t, : R → R, defined by J t, ( )</p><formula xml:id="formula_96">≡ I t, ( + b) -b if ∈ R and b ∈ R is such that + b ∈ u (X)</formula><p>, is a normalized concave niveloid and its concave conjugate J * t, coincides with I * t, on ( ) and takes value -∞ on R \ ( ). <ref type="foot" target="#foot_8">22</ref> In particular J t, ( ) = min p∈ ( ) , p -I * t, (p) for all ∈ R . (See <ref type="bibr" target="#b21">[22]</ref> for details.) By CP(i), if</p><formula xml:id="formula_97">G t ( ) = G t</formula><p>, we can choose I t, = I t, and set c t, (p) ≡ -I * t, (p) = -J * t, (p) for all p ∈ ( ) and all (t, ) ∈ T × . Then c t, : ( ) → [0, ∞] is grounded, closed, and convex for all (t, )</p><formula xml:id="formula_98">∈ T × ; c t, = c t, if G t ( ) = G t ; for all (t, ) ∈ T × , t, is represented by V t, (h) = I t, (U t (h)) = J t, (U t (h)) = min p∈ ( ) U t (h) , p -I * t, (p) , that is, V t ( , h) = min p∈ ( ) ⎛ ⎝ ∈ p t -t u h + c t ( , p) ⎞ ⎠ .</formula><p>Step 8:</p><formula xml:id="formula_99">Let (t, ) ∈ T × . If 1 , 2 ∈ R and 1 |G t ( ) = 2 |G t ( ) , then J t, 1 = J t, 2 .</formula><p>Proof of the Step. It suffices to show that: if 1 , 2 ∈ u (X) and 1</p><formula xml:id="formula_100">|G t ( ) = 2 |G t ( ) , then I t, 1 = I t, 2 . For i = 1, 2, define h i , ≡ x if &lt; T , x i ( ) if = T like in Step 4, with the precaution of choosing x 1 ( ) = x 2 ( ) if ∈ G t ( ) (this is possible since 1 = 2 ). By construction, h 1 , = h 2 , for all t and ∈ G t ( ).</formula><p>CP(ii) implies h 1 ∼ t, h 2 and I t,</p><formula xml:id="formula_101">1 = I t, U t h 1 = V t, h 1 = V t, h 2 = I t, 2 ,</formula><p>as wanted.</p><p>By Lemma 3, dom c t, = dom J * t, ⊆ (G t ( )). This concludes the proof of (a) ⇒ (b). (b) ⇒ (a) and the uniqueness properties of ( , u, {c t ( , •)}) can be easily checked (though the verification is a bit long).</p><p>Step 9: Let (t, ) ∈ T × be such that</p><formula xml:id="formula_102">|G t ( )| &gt; 1. A state ∈ G t ( ) is t, -null if and only if dom c t, ⊆ G t ( ) \ . Proof of the Step. We show that if ∈ G t ( ) is t, -null, then J t, 1 = J t, 2 for every 1 , 2 ∈ R such that 1 |G t ( )\{ } = 2 |G t ( )\{ } . By Lemma 3, dom c t, = dom J * t, ⊆ G t ( ) \</formula><p>. Again, it is sufficient to show it for 1 , 2 ∈ u (X) . For i = 1, 2, define</p><formula xml:id="formula_103">h i , ≡ x if &lt; T , x i ( ) if =T , and g i , ≡ ⎧ ⎨ ⎩ x if &lt; T , x i ( ) if =T and = , x if =T and = ,</formula><p>where x and x i ( ) are defined like in Step 4, with the precaution of choosing</p><formula xml:id="formula_104">x 1 ( ) = x 2 ( ) if ∈ G t ( ) \ (this is possible since 1 = 2</formula><p>). Since g 1 , = g 2 , for all t and ∈ G t ( ), CP(ii) implies g 1 ∼ t, g 2 , while t, -nullity of implies h i ∼ t, g i for i = 1, 2. Therefore, h 1 ∼ t, h 2 , and I t,</p><formula xml:id="formula_105">1 = I t, U t h 1 = V t, h 1 = V t, h 2 = I t, 2 .</formula><p>The converse is easily checked.</p><p>Therefore, if a state in G t ( ) is t, -null, then dom c t, ⊆ G t ( ) \ , and Proof. Assume, per contra, that there exist • ∈ and t</p><formula xml:id="formula_106">V t ( , h) = ∞ = inf p∈ri (G t ( )) t -t u (h ) dp + c t, (p) for some (indeed all) h ∈ H. That is, (i) ⇒ (ii). Conversely, if V t ( , h) = inf p∈ri (G t ( )) t -t u (h ) dp + c t</formula><formula xml:id="formula_107">• ∈ T such that |G t • ( • )| &gt; 1 and G t • ( • ) contains a t • , • -null state. W.l.o.g., • is t • , • -null. By FS, t • &gt; 0 and h = h for all = • implies h ∼ t • , • h . (<label>26</label></formula><formula xml:id="formula_108">)</formula><p>Clearly,</p><formula xml:id="formula_109">|G t • -1 ( • )| |G t • ( • )| &gt; 1. Next we show that • is t • -1, • -null.</formula><p>In a finite number of steps this leads to an absurd. Assume that h , = h , for all ∈ T , for all = • . By <ref type="bibr" target="#b25">(26)</ref> and CP(i),</p><formula xml:id="formula_110">h ∼ t • , h for all ∈ G t • ( • ). Moreover, if ∈ G t • -1 ( • ) \G t • ( • ), then G t • ( ) does not contain • , and h , = h , for all ∈ T and all ∈ G t • ( ). By CP(ii), h ∼ t • , h for all ∈ G t • -1 ( • ) \G t • ( • ). Therefore, h ∼ t • , h for all ∈ G t • -1 ( • ). Since |G t • -1 ( • )| &gt; 1 and h t • -1 is G t • -1 measurable, choose ∈ G t • -1 ( • ) -{ • } to obtain h (t • -1, • ) = h t • -1, = h t • -1, = h (t • -1, • ) and conclude h (t • -1, • ) = h (t • -1, • ) and h ∼ t • , h for all ∈ G t • -1 ( • ), DC implies that h ∼ t • -1, • h . That is, • is t • -1, • -null as wanted. A.1. Proof of Proposition 1 Axiom 6 (Strong full support-SFS). For each (t, ) ∈ T × , no state in G t ( ) is t, -null.</formula><p>For technical reasons we prove a slightly more general version of Proposition 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 3. The following statements are equivalent:</head><p>(a)  </p><formula xml:id="formula_111">⇒ (a), if G t ( ) is not a singleton, no state in G t ( ) is t, -null. Let G t ( ) be a singleton { }. Then (G t ( )) = {d }, and V t ( , h) = t -t u (h ( )) for all h ∈ H. Since u is unbounded, there are x 1 , x 2 ∈ X such that u x 1 &gt; u x 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consider the acts</head><formula xml:id="formula_112">h i , ≡ x 1 if , = (T , ) , x i if , = (T , ) , h 1 = h 2 for all = .</formula><p>If where t, -null, we would have</p><formula xml:id="formula_113">h 1 ∼ t, h 2 , but V t , h 1 = t -t u x 1 &gt; T &gt; t -t u x 1 + T -t u x 2 = V t , h 2 . Therefore, is not t, -null.</formula><p>Since for every t and , ri (G t ( )) = p G t ( ) : p ∈ ri ( ) , ( <ref type="formula" target="#formula_84">23</ref>) is equivalent to</p><formula xml:id="formula_114">V t ( , h) = inf p∈ri ( ) ⎛ ⎝ t -t u (h ) dp G t ( ) + c t , p G t ( ) ⎞ ⎠ ∀h ∈ H. (<label>27</label></formula><formula xml:id="formula_115">)</formula><p>Consider the G t measurable functions</p><formula xml:id="formula_116">V t (•, h) : → R and c t (•, p) : → [0, ∞],<label>(27)</label></formula><p>becomes</p><formula xml:id="formula_117">V t (•, h) = inf p∈ri ( ) ⎛ ⎝ E p ⎛ ⎝ t -t u (h ) |G t ⎞ ⎠ (•) + c t (•, p |G t (•)) ⎞ ⎠ ∀h ∈ H, (<label>28</label></formula><formula xml:id="formula_118">)</formula><p>or</p><formula xml:id="formula_119">V t (h) = inf p∈ri ( ) ⎛ ⎝ E p ⎛ ⎝ t -t u (h ) |G t ⎞ ⎠ + c t (p |G t ) ⎞ ⎠ ∀h ∈ H. (<label>29</label></formula><formula xml:id="formula_120">)</formula><p>By Lemma 5, if</p><formula xml:id="formula_121">t,</formula><p>satisfies CP, VP, RP, DC and FS, then it admits this representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Dynamic consistency</head><p>Lemma 6. Let t, be a family of preferences on H for which there exists a scalar &gt; 0, an unbounded affine function u : X → R, and a dynamic ambiguity index {c t }, such that: for each (t, ) ∈ T × , t, is represented by</p><formula xml:id="formula_122">V t ( , h) ≡ min p∈ (G t ( )) ⎛ ⎝ t -t u (h ) dp + c t ( , p) ⎞ ⎠ ∀h ∈ H.</formula><p>The following statements are equivalent:</p><formula xml:id="formula_123">(a) t,</formula><p>satisfies DC.</p><p>(b) For all t &lt; T , ∈ , and q ∈ (G t ( )),</p><formula xml:id="formula_124">c t ( , q) = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p). (<label>30</label></formula><formula xml:id="formula_125">)</formula><p>(c) For all t &lt; T and ∈ ,</p><formula xml:id="formula_126">c t ( , •) = co t ( , •) , (<label>31</label></formula><formula xml:id="formula_127">)</formula><p>where t ( , q) <ref type="figure">,</ref><ref type="figure">p</ref>) for all t &lt; T , ∈ , and h ∈ H.</p><formula xml:id="formula_128">≡ G∈G t+1 G⊆G t ( ) q(G)c t+1 (G, q G ) + inf p∈ri (G t ( )):p |G t+1 =q |G t+1 c t ( , p), for all q ∈ ri (G t ( )). (d) V t ( , h) =u (h t ( )) + min r∈ ( ,G t+1) V t+1 (h) dr+ min p∈ (G t ( )):p |G t+1 =r c t (</formula><p>Proof. Like in the proof of Lemma 4, up to a cardinal transformation of u, we can assume u (X) ∈ R, R + , R ++ , R -, R --. For the rest of the proof the case u (X) = R ++ is considered (the arguments we use can be easily adapted to the remaining ones). For all t ∈ T ,</p><formula xml:id="formula_129">∈ , ∈ R , y ∈ X T define J t ( , ) ≡ min p∈ (G t ( )) ( , p + c t ( , p)) = inf p∈ri (G t ( )) ( , p + c t ( , p))<label>(32)</label></formula><p>and</p><formula xml:id="formula_130">U t (y) ≡ V t ( , y) = t -t u (y ). Then J t : R → R (G t ), where R (G t )</formula><p>is the set of all G t -measurable functions. Notice that the second equality in (32) coincides with the property dom c t ( ,</p><formula xml:id="formula_131">•) ∩ ri (G t ( )) = ∅ of dynamic ambiguity indexes; u (X) = {U t • h : h ∈ H} (see Lemma 4); V t ( , h) = J t ( , U t • h) for all (t, , h) ∈ T × × H and if t &lt; T U t • h = u • h t + (U t+1 • h) and V t (h) = u • h t + J t ( (U t+1 • h)) . 23<label>(33)</label></formula><p>Step 1: Let t &lt; T and ∈ , J t ( , ) = min r∈ ( ,G t+1) dr 24   Proof of the Step. Denote by G = G 1 , . . ., G g the set of all elements of G t+1 contained in G t ( ), and by G the set (G t ( ) , G t+1 ) (brutally, the probabilities on</p><formula xml:id="formula_132">+ min p∈ (G t ( )):p |G t+1 =r c t ( , p)) = inf r∈ ++ (G t ( ),G t+1 ) dr + inf p∈ri (G t ( )):p |G t+1 =r c t ( , p) for all ∈ R (G t+1 ).</formula><formula xml:id="formula_133">G t+1 with sup- port in G 1 , . . ., G g ). For all = G∈G t+1 G 1 G ∈ R (G t+1 ), J t ( , ) = min p∈ (G t ( )) ∈ p( ) ( ) + c t, (p) = min p∈ (G t ( )) g i=1 G i p (G i ) + c t, (p) = min r∈ G min p∈ (G t ( )):p |G t+1 =r g i=1 G i p (G i ) +c t, (p) = min r∈ G g i=1 r (G i ) G i + min p∈ (G t ( )):p |G t+1 =r c t, (p) the observation that if r ∈ ( , G t+1 ) \ G there is G ∈ G t+1 23 In fact, for all ∈ , (U t • h) ( ) = u (h t ( )) + t+1 -t u (h ( )) = (u • h t ) ( ) + t+1 -(t+1) u (h ( )) = (u • h t ) ( ) + U t+1 (h ( )) = (u • h t ) ( ) + U t+1 • h ( ) and V t ( , h) = J t ( , U t • h) = J t, U t+1 • h + u • h t = J t, U t+1 • h + u • h t 1 G t ( ) = J t, U t+1 • h + u (h t ( )) 1 G t ( ) = J t, U t+1 • h + u (h t ( )) = J t, U t+1 • h + u (h t ( ))</formula><p>. 24 With the convention that the minimum over the empty set is ∞.</p><p>such that G G t ( ) with r (G) &gt; 0, and hence there is no p ∈ (G t ( )) such that p |G t+1 = r delivers the first equality. The second is proved in the same way.</p><p>Step 2. Let t &lt; T and ∈ . The function t ( , 24   is closed, convex, grounded, and dom t ( , <ref type="figure">r</ref>) . Hence, J t ( , 0) = 0 implies that min r∈ ( ,G t+1) t ( , r) = 0, and t ( , •) is grounded. Let r, s ∈ G and ∈ (0, 1), then t ( , r</p><formula xml:id="formula_134">•) : ( , G t+1 ) → [0, ∞], defined by t ( , r) ≡ min p∈ (G t ( )):p |G t+1 =r c t ( , p) ∀r ∈ ( , G t+1 )</formula><formula xml:id="formula_135">•) ⊆ (G t ( ) , G t+1 ). Proof of the Step. If r ∈ ( , G t+1 ) \ (G t ( ) , G t+1 ), there is G ∈ G t+1 such that G G t ( ) with r (G) &gt; 0, then there is no p ∈ (G t ( )) such that p |G t+1 = r and t ( , r) = ∞. Therefore, dom t ( , r) ⊆ (G t ( ) , G t+1 ) = G. For ∈ R (G t+1 ), by Step 1, J t ( , ) = min r∈ ( ,G t+1) dr + t ( ,</formula><formula xml:id="formula_136">+ (1 -) s) = min p∈ (G t ( )):p |G t+1 = r+(1-)s c t ( , p) min p,q∈ (G t ( )) p |G t+1 =r,q |G t+1 =s c t ( , p + (1 -) q) min p,q∈ (G t ( )) p |G t+1 =r,q |G t+1 =s ( c t ( , p) + (1 -) c t ( , q)) = t ( , r) + (1 -) t ( , s). Therefore, t ( , •) is convex. Let b ∈ R and r n ∈ G,</formula><p>be such that r n → r and t ( , r n ) b for all n 1. For all n there exists pn such that t ( ,</p><formula xml:id="formula_137">r n ) = min p n ∈ (G t ( )):p n |G t+1 =r n c t ( , p n ) c t ( , pn ) b and pn |G t+1 = r n . Take a convergent subsequence pn j → p of pn , since c t ( , •) is closed c t ( , p) b, moreover, p (G) = lim j pn j (G) = lim j r n j (G) = r (G) for all G ∈ G t+1 . In turn this implies t ( , r) c t ( , p) b and t ( , •) is closed.</formula><p>This implies that:</p><p>Step 3: Let t &lt; T and ∈ . The function t ( , •) : ( ) → [0, ∞] defined by t ( , q) ≡ t , q |G t+1 for all q ∈ ( ) is grounded, closed and convex with dom t ( , •) ⊆ (G t ( )).</p><p>Step 4: Let t &lt; T and ∈ . The function t ( , •) :</p><formula xml:id="formula_138">(G t ( )) → [0, ∞] defined by t ( , q) ≡ G∈G t+1 q(G)&gt;0</formula><p>q(G)c t+1 (G, q G ) for all q ∈ (G t ( )), is closed and convex.</p><p>Proof of the Step. For later use (in the proof of Theorem 2) we just assume that c t+1 satisfies (i) and (ii) of the definition of dynamic ambiguity index (not that {c t } is an ambiguity index itself). We show that t ( , •) is the closure of its convex restriction t ( , <ref type="bibr">(G, •)</ref>. Therefore, choosing {q (G) : G ∈ G} such that G∈G q (G) = 1 and q (G) &gt; 0 for all G ∈ G, the probability r ≡ G∈G q (G) p G ∈ dom t, and t, is proper. <ref type="foot" target="#foot_9">25</ref> Take p ∈ ri dom t, and q ∈ (G t ( )). If G ∈ G t+1 and q (G) &gt; 0 then G ⊆ G t ( ). In this case, the function f ( ) ≡ G has strictly positive first derivative w.r.t. in (0, 1) and lim ↑1 f ( ) = 1; since p ∈ ri dom t, , then p G ∈ dom c t+1 (G, •), and [26, Corollary 7.5.1] implies lim ↑1 c t+1,G ( q <ref type="bibr">(q)</ref> for all q ∈ (G t ( )).</p><formula xml:id="formula_139">•) to ri (G t ( )). Let G ≡ {G ∈ G t+1 : G ⊆ G t ( )}. For all q, p ∈ ri (G t ( )), ∈ (0, 1), and G ∈ G, let G ≡ q (G)+(1 -) p (G) and G ≡ q (G) / G ∈ (0, 1). This delivers ( q + (1 -) p) G = G q G +(1 -G ) p G and then t, ( q + (1 -) p) = G∈G G c t+1,G ( q + (1 -) p) G = G∈G G c t+1,G ( G q G + (1 -G ) p G ) G∈G G G c t+1,G (q G ) + (1 -G ) c t+1,G (p G ) = G∈G q (G) c t+1,G (q G ) + (1 -) p (G) c t+1,G (p G ) = t, (q) + (1 -) t, (p), hence t, is convex. For all G ∈ G, there is p G ∈ ri (G) ∩ dom c t+1</formula><formula xml:id="formula_140">+ (1 -) p) G = lim ↑1 c t+1,G ( G q G + (1 -G ) p G ) = lim ↑1 c t+1,G (f ( ) q G + (1-f ( )) p G ) = c t+1,G (q G ). Else if G ∈ G and q (G) = 0, then ( q + (1 -) p) G = p G for all ∈ (0, 1), and hence lim ↑1 c t+1,G ( q + (1 -) p) G = lim ↑1 c t+1,G (p G ) = c t+1,G (p G ), with c t+1,G (p G ) &lt; ∞ since p G ∈ dom c t+1 (G, •). Then, by [26, Theorem 7.5], co t, (q) = lim ↑1 t, ((1 -) p + q) = lim ↑1 G∈G ( q + (1 -) p) (G)c t+1,G ( q + (1 -) p) G = G∈G t+1 q(G)&gt;0 q (G) c t+1,G (q G ) = t,</formula><p>Step 5: Let t &lt; T , ∈ and DC be satisfied. If 1 , 2 ∈ R and J t+1,</p><formula xml:id="formula_141">1 = J t+1, 2 for all ∈ G t ( ), then J t, 1 = J t, 2 .</formula><p>Proof of the Step. First assume 1 , 2 ∈ u (X) . There exists</p><formula xml:id="formula_142">&gt; 0 such that i -∈ u (X) , choose x ∈ X such that u x = T &gt; t -t -1</formula><p>. For all ∈ , there exists x i ( ) ∈ X such that u x i ( ) = 1-T +t i -. Consider the acts h 1 , h 2 defined by 2 , as wanted.</p><formula xml:id="formula_143">h i , ≡ x if &lt; T , x i ( ) if = T . It is easy to check that there is k ∈ R such that U t h i = i and U t+1 h i = i +k for all ∈ and i = 1, 2. Then V t+1, h 1 = J t+1, U t+1 h 1 =J t+1, 1 +k = J t+1, 1 + k, and V t+1, h 2 = J t+1, 2 + k for all ∈ . For all ∈ G t ( ), J t+1, 1 = J t+1, 2 , then h 1 ∼ t+1, h 2 ; moreover h 1 = h 2 for all t, then DC implies h 1 ∼ t, h 2 and J t, 1 = J t, U t h 1 = V t, h 1 = V t, h 2 = J t,</formula><p>Finally, if 1 , 2 ∈ R are such that J t+1, 1 = J t+1, 2 for all ∈ G t ( ), there exist 1 , 2 ∈ u (X) and b ∈ R such that i = i +b, then J t+1, 1 = J t+1, 2 for all ∈ G t ( ). Therefore, J t,</p><formula xml:id="formula_144">1 = J t, 1 + b = J t, 1 + b = J t, 2 + b = J t, 2 .</formula><p>Step 6: Let t &lt; T . If</p><formula xml:id="formula_145">t,</formula><p>satisfies DC, then J t ( J t+1 ( )) = J t ( ) for all ∈ R .</p><p>Proof of the Step. Choose ∈ , and remember that J t+1 ( )</p><formula xml:id="formula_146">= G∈G t+1 J t+1 (G, ) 1 G ∈ R (G t+1 ). For all ∈ G t ( ), dom c t+1, ⊆ G t+1 , then J t+1 , = J t+1 , J t+1, ( ) 1 =J t+1 , J t+1 G t+1 , 1 G t+1 ( ) = J t+1</formula><p>, J t+1 ( ) , then, by Step 5, J t ( , ) = J t ( , J t+1 ( )). The proof is concluded by the observation that this is true for all ∈ .</p><p>Step 7: t, satisfies DC if and only if J t ( J t+1 ( )) = J t ( ) for all t &lt; T and ∈ R .</p><p>Proof of the Step. By the previous step we just have to prove necessity. Let ∈ and t &lt; T . Assume 1 , 2 ∈ R are such that J t+1, </p><formula xml:id="formula_147">1 J t+1, 2 for all ∈ G t ( ), then J t, 1 = J t, J t+1 1 = J t, J t+1 1 1 G t ( ) J t, J t+1 2 1 G t ( ) = J t, J t+1 2 = J t</formula><formula xml:id="formula_148">U t+1 • h 1 = V t+1, h 1 V t+1, h 2 = J t+1, U t+1 • h 2 for all ∈ , whence (set i = U t+1 • h i , i = 1, 2) J t, U t+1 • h 1 J t, U t+1 • h 2 . But h 1 t = h 2 t , then, by (33), V t , h 1 = J t, U t+1 • h 1 + u h 1 t ( ) J t, U t+1 • h 2 + u h 2 t ( ) = V t , h 2 , i.e. V t , h 1 V t , h 2 .</formula><p>Step 8: (a) ⇔ (d).</p><p>Proof of the Step. By Step 7,</p><formula xml:id="formula_149">t,</formula><p>satisfies DC iff <ref type="bibr">Step 1,</ref><ref type="bibr">and (33)</ref>.</p><formula xml:id="formula_150">J t, ( J t+1 ( )) = J t, ( ) for all t &lt; T, ∈ R , ∈ iff J t, ( J t+1 ( + b)) = J t, ( ( + b)) for all t &lt; T , ∈ u (X) , b ∈ R, ∈ iff J t, ( J t+1 ( )) + b = J t, ( ) + b for all t &lt; T , ∈ u (X) , b ∈ R, ∈ iff J t, ( J t+1 ( )) = J t, ( ) for all t &lt; T , ∈ u (X) , ∈ iff J t, ( J t+1 (U t+1 • h)) = J t, ( (U t+1 • h)) for all t &lt; T , h ∈ H, ∈ iff J t, ( V t+1 (h)) + u (h t ( )) = J t, ( (U t+1 • h)) + u (h t ( )) for all t &lt; T , h ∈ H, ∈ iff min r∈ ( ,G t+1) V t+1 (h) dr + min p∈ (G t ( )):p |G t+1 =r c t ( , p) +u (h t ( )) = V t ( , h) for all t &lt; T , h ∈ H, ∈ , by G t+1 measurability of V t+1 (h),</formula><p>Step 9: For all t &lt; T , ∈ , and ∈ R</p><formula xml:id="formula_151">J t, ( J t+1 ( )) = min q∈ (G t ( )) ⎛ ⎜ ⎜ ⎝ , q + G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p) ⎞ ⎟ ⎠ . (<label>34</label></formula><formula xml:id="formula_152">)</formula><p>Proof of the Step. Denote by G = G 1 , . . ., G g the set {G ∈ G t+1 : G ⊆ G t ( )}. By Steps 1 and 2, J t, ( J t+1 ( ))</p><formula xml:id="formula_153">= J t ⎛ ⎝ , G∈G t+1 J t+1 (G, ) 1 G ⎞ ⎠ = min r∈ ( ,G t+1) ⎛ ⎝ G∈G t+1 r (G) J t+1 (G, ) + min p∈ (G t ( )):p |G t+1 =r c t ( , p) ⎞ ⎠ = min r∈ G g i=1 r (G i ) J t+1 (G i , ) + t ( , r) = min r∈ G ⎛ ⎝ g i=1 r(G i ) min p i ∈ (G i ) ⎡ ⎣ ¯ ∈ p i ( ¯ ) ( ¯ ) + c t+1 (G i , p i ) ⎤ ⎦ + t ( , r) ⎞ ⎠ = min r∈ G ⎛ ⎝ g i=1 min p i ∈ (G i ) r(G i ) ⎡ ⎣ ¯ ∈ p i ( ¯ ) ( ¯ ) + c t+1 (G i , p i ) ⎤ ⎦ + t ( , r) ⎞ ⎠ = min r∈ G ⎛ ⎝ g i=1 min p i ∈ (G i ) ⎡ ⎣ ¯ ∈ r(G i )p i ( ¯ ) ( ¯ ) + r(G i )c t+1 (G i , p i ) ⎤ ⎦ + t ( , r) ⎞ ⎠ = min r∈ G ⎛ ⎝ min p 1 ∈ (G 1 ),...,p g ∈ (Gg) g i=1 ⎡ ⎣ ¯ ∈ r(G i )p i ( ¯ ) ( ¯ ) + r(G i )c t+1 (G i , p i ) ⎤ ⎦ + t ( , r) ⎞ ⎠ = min r∈ G ⎛ ⎝ min p 1 ∈ (G 1 ),...,p g ∈ (Gg) ⎛ ⎝ g i=1 ⎡ ⎣ ¯ ∈ r(G i )p i ( ¯ ) ( ¯ ) + r(G i )c t+1 (G i , p i ) ⎤ ⎦ + t ( , r) ⎞ ⎠ ⎞ ⎠ = min r∈ G ⎛ ⎝ min p 1 ∈ (G 1 ),...,p g ∈ (Gg) ⎛ ⎝ g i=1 ¯ ∈ r(G i )p i ( ¯ ) ( ¯ ) + g i=1 r(G i )c t+1 (G i , p i ) + t ( , r) ⎞ ⎠ ⎞ ⎠ = min r∈ G ⎛ ⎝ min p 1 ∈ (G 1 ),...,p g ∈ (Gg) ⎛ ⎝ ¯ ∈ g i=1 r(G i )p i ( ¯ ) ( ¯ ) + g i=1 r(G i )c t+1 (G i , p i ) + t ( , r) ⎞ ⎠ ⎞ ⎠ = min r∈ G,p 1 ∈ (G 1 ),...,p g ∈ (Gg) ⎛ ⎝ ¯ ∈ g i=1 r(G i )p i ( ¯ ) ( ¯ ) + g i=1 r(G i )c t+1 (G i , p i ) + min p∈ (G t ( )):p |G t+1 =r c t ( , p) ⎞ ⎠ = min q∈ (G t ( )) ⎛ ⎜ ⎜ ⎝ ¯ ∈ q( ¯ ) ( ¯ ) + i=1,...,g q(G i )&gt;0 q(G i )c t+1 (G i , q G i ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p) ⎞ ⎟ ⎠ .</formula><p>Last equality holds since (G t ( )) = g i=1 r(G i )p i : r ∈ G, p i ∈ (G i ) ∀i = 1, . . ., g , and q ∈ (G t ( )) can be written as q = i=1,...,g r(G i )p i with r ∈ G and p i ∈ (G i ) if and only if r = q |G t+1 and p i = q G i , for all i = 1, . . ., g with q (G i ) = r (G i ) &gt; 0 (clearly p i can be chosen arbitrarily in</p><formula xml:id="formula_154">(G i ) if q (G i ) = r (G i ) = 0).</formula><p>Steps 7 and 9 imply that t, satisfies DC iff for all t &lt; T , ∈ , and ∈ R ,</p><formula xml:id="formula_155">J t, ( ) = min q∈ (G t ( )) ⎛ ⎜ ⎜ ⎝ , q + G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p) ⎞ ⎟ ⎟ ⎠ .</formula><p>Eq. ( <ref type="formula" target="#formula_129">32</ref>) and Lemma 1 guarantee that this is equivalent to c t ( , •) = co t ( , •) + t ( , •) where t ( , •) and t ( , •) are defined in Steps 4 and 3. These steps also guarantee closure and convexity of t ( , •) and t ( , •). That is, (a) ⇔ (b).</p><p>(a) ⇔ (c) can be proved in a similar way.</p><p>Remark 1. In particular, for a dynamic ambiguity index {c t } conditions (b) and (c) of Lemma 6 are equivalent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Proof of Theorem 1</head><p>(a) ⇒ (b) By Proposition 3 and Lemma 5 there exists a scalar &gt; 0, an unbounded affine function u : X → R, and a dynamic ambiguity index {c t }, such that: for each (t, ) ∈ T × , t, is represented by V t ( , h) = inf p∈ ++ ( ) t -t u (h ) dp G t ( ) + c t , p G t ( ) for all h ∈ H. Lemma 6 guarantees that (11) holds.</p><p>(b) ⇒ (a) Assume that there exists a scalar &gt; 0, an unbounded affine function u : X → R, and a dynamic ambiguity index {c t }, such that: for each (t, ) ∈ T × , t, is represented by V t ( , h) = inf p∈ ++ ( ) t -t u (h ) dp G t ( ) + c t , p G t ( ) for all h ∈ H. By Proposition 1, t, satisfies CP, VP, RP, and FS, and so, by <ref type="bibr" target="#b10">(11)</ref> and Lemma 6, t, satisfies DC.</p><p>Uniqueness of the representation follows again from Proposition 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Proof of Proposition 2</head><p>(i) is trivial.</p><p>Step 2 of the proof of Lemma 6 shows that t ( , •) is grounded, closed and convex, with dom t ( , •) ⊆ (G t ( ) , G t+1 ), for all t &lt; T and all ∈ . It only remains to show that and dom t ( ,</p><formula xml:id="formula_156">•) ∩ ++ (G t ( ) , G t+1 ) = ∅. Take p • ∈ ri (G t ( )) ∩ dom c t ( , •), then r • = p • |G t+1 ∈ ++ (G t ( ) , G t+1 ) and t ( , r • ) = min p∈ (G t ( )):p |G t+1 =r • c t ( , p) c t ( , p • ) &lt; ∞.</formula><p>A.5. Proof of Theorem 2 (b) ⇒ (a) The proof that {c t } is a dynamic ambiguity index is by backward induction. Clearly, c T satisfies (i) and (ii) of the definition of dynamic ambiguity index. Next we assume that c t+1 (0 t &lt; T ) satisfies (i) and (ii) of the definition of dynamic ambiguity index, and show that c t satisfies them.</p><p>By assumption, c t+1 : × ( ) → [0, ∞] is such that: Clearly, for all ∈ , the function c t ( , •) appearing in (b) is well defined (since c t+1 satisfies (i)) and c t ( ,</p><formula xml:id="formula_157">•) = c t , • if G t ( ) = G t .</formula><p>Step 4 of the proof of Lemma 6 shows that for all ∈ the function t ( , •) : (G t ( )) → [0, ∞] defined by t ( , q) ≡ G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) for all q ∈ (G t ( )) is closed and convex. Since q → q |G t+1 is affine (and continuous) from ( ) to , G t,+1 and t ( , •) : ( , G t+1 ) → [0, ∞] is grounded, closed and convex, with effective domain in (G t ( ) , G t+1 ), then q → t , q |G t+1 is closed and convex on ( ) and its effective domain is contained in (G t ( )). We conclude that, for all ∈ , the function c t ( , •) appearing in (b) is closed and convex, from ( ) to [0, ∞], with dom c t ( , •) ⊆ (G t ( )).</p><p>Next we show that c t ( , •) is grounded. Choose arbitrarily ∈ , there exists r ∈ ( , G t+1 ) such that r (G t ( )) = 1 and t ( , r) = 0; moreover, for all G ∈ G t+1 there exists p</p><formula xml:id="formula_158">G ∈ (G) such that c t+1 (G, p G ) = 0, set q ≡ G∈G t+1 r (G) p G to obtain c t ( , q) = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + t , q |G t+1 = G∈G t+1 r(G)&gt;0 r(G)c t+1 (G, p G ) + t ( , r) = 0.</formula><p>It remains to show that ri (G t ( )) ∩ dom c t ( , •) = ∅ for all ∈ . Choose arbitrarily ∈ , there exists r ∈ ++ (G t ( ) , G t+1 ) such that t ( , r) &lt; ∞; moreover, for all G ∈ G t+1 there exists p G ∈ ri (G) such that c t+1 (G, p G ) &lt; ∞, set q ≡ G∈G t+1 r (G) p G to obtain q ∈ ri (G t ( )) and c t ( , q) = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + t , q |G t+1 = G∈G t+1 r(G)&gt;0 r(G)c t+1 (G, p G ) + t ( , r) &lt; ∞. This concludes the proof that {c t } is a dynamic ambiguity index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Moreover, notice that min p∈ (G t ( )):p</head><formula xml:id="formula_159">|G t+1 =q |G t+1 G∈G t+1 p(G)&gt;0 p(G)c t+1 (G, p G ) = 0 for all ∈ , t &lt; T , and q ∈ (G t ( )) (it is enough to take, for all G ∈ G t+1 , p G ∈ (G) such that c t+1 (G, p G ) = 0 and set p ≡ G∈G t+1 q (G) p G ). Therefore, G∈G t+1 q(G)&gt;0 q(G)c t+ (G, q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p) = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 ⎛ ⎜ ⎜ ⎝ G∈G t+1 p(G)&gt;0 p(G)c t+1 (G, p G ) + t , p |G t+1 ⎞ ⎟ ⎟ ⎠ = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + t , q |G t+1 + min p∈ (G t ( )):p |G t+1 =q |G t+1 ⎛ ⎜ ⎜ ⎝ G∈G t+1 p(G)&gt;0 p(G)c t+1 (G, p G ) ⎞ ⎟ ⎟ ⎠ = G∈G t+1 q(G)&gt;0 q(G)c t+1 (G, q G ) + t , q |G t+1 = c t ( , q) ∀ ∈ , t &lt; T , q ∈ (G t ( )) .</formula><p>Hence {c t } satisfies condition <ref type="bibr" target="#b10">(11)</ref> and it is a recursive ambiguity index. Finally, the above equalities deliver t , q |G t+1 = min p∈ (G t ( )):p |G t+1 =q |G t+1 c t ( , p) for all ∈ , t &lt; T , and q ∈ (G t ( )), which implies (13) for r ∈ (G t ( ) , G t+1 ). If r / ∈ (G t ( ) , G t+1 ), then t ( , r) = ∞ = min p∈ (G t ( )):p |G t+1 =r c t ( , p) (the first equality descending from the definition of one-period-ahead ambiguity index, the second from the convention we adopted for minima over the empty set). We can conclude that ( <ref type="formula" target="#formula_44">13</ref>) holds for all r ∈ ( , G t+1 ) and that t is unique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6. Proof of Corollary 1</head><p>It is easy to see that the effect of MP(ii) on the representation provided by Proposition 1 is guaranteeing that, for every t ∈ T and ∈ , c t ( , p) = C t ( ) (p), for a closed and convex subset C t ( ) ⊆ ( ).</p><p>The relation dom c t, ⊆ (G t ( )) implies C t ( ) ⊆ (G t ( )). Denote by G = {G 1 , . . ., G g the set of all elements of G t+1 contained in G t ( ), and write indifferently C i or C t+1 (G i ). Let ∈ and t &lt; T . Condition <ref type="bibr" target="#b10">(11)</ref> is equivalent to</p><formula xml:id="formula_160">C t ( ) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ q ∈ (G t ( )) G∈G t+1 q(G)&gt;0 q(G) C t+1 (G) (q G ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 C t ( ) (p) = 0 ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭ = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ q ∈ (G t ( )) i=1,...,g q(G i )&gt;0 q(G i ) C i (q G i ) + min p∈ (G t ( )):p |G t+1 =q |G t+1 C t ( ) (p) = 0 ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭ = ⎧ ⎪ ⎨ ⎪ ⎩ i=1,...,g r(G i )p i r ∈ G, p i ∈ (G i ) ∀i = 1, . . ., g, i=1,...,g r(G i )&gt;0 r(G i ) C i (p i )+ min p∈ (G t ( )):p |G t+1 =r C t ( ) (p)=0 ⎫ ⎪ ⎬ ⎪ ⎭ = ⎧ ⎨ ⎩ i=1,...,g r(G i )p i r ∈ G, p i ∈ (G i ) ∀i = 1, . . ., g, C i (p i ) = 0 for all i s.t. r (G i ) &gt; 0, C t ( ) (p) = 0 for some p ∈ (G t ( )) : p |G t+1 = r ⎫ ⎬ ⎭ = ⎧ ⎨ ⎩ i=1,...,g r(G i )p i r ∈ G, p i ∈ (G i ) ∀i = 1, . . ., g, p i ∈ C i for all i = 1, . . ., g, r ∈ C t ( ) |G t+1 ⎫ ⎬ ⎭ = ⎧ ⎨ ⎩ i=1,...,g r(G i )p i p i ∈ C t+1 (G i ) for all i = 1, . . ., g, r ∈ C t ( ) |G t+1 ⎫ ⎬ ⎭ = ⎧ ⎨ ⎩ G∈G t+1 p G r (G) p G ∈ C t+1 (G) ∀G ∈ G t+1 and r ∈ C t ( ) |G t+1 ⎫ ⎬ ⎭ .</formula><p>A.7. Proof of Theorem 3 W.l.o.g., set = 1 and denote by q • the reference probability of the statement. The properties of the relative entropy (see, e.g., <ref type="bibr" target="#b19">[20]</ref>) guarantee that {c t } (as defined by ( <ref type="formula" target="#formula_63">17</ref>)) is a dynamic ambiguity index. By Theorem 1, we only have to show that {c t } satisfies <ref type="bibr" target="#b10">(11)</ref> or the equivalent <ref type="bibr" target="#b30">(31)</ref>, see Remark 1.</p><p>Next we show that, for all t &lt; T , ∈ , and q ∈ ri (G t ( )),</p><formula xml:id="formula_161">c t, (q) = G∈G t+1 G⊆G t ( ) q(G)c t+1,G (q G ) + inf p∈ri (G t ( )):p |G t+1 =q |G t+1 c t, (p). (<label>35</label></formula><formula xml:id="formula_162">) For all p ∈ ri (G t ( )), c t, (p) = 1 t ∈G t ( ) p G t ( ) log p G t ( )( ) q • G t ( ) ( ) = 1 t ∈G t ( ) p log p q • G t ( ),</formula><p>where p ≡ p and q</p><formula xml:id="formula_163">• G t ( ), ≡ q • G t ( ) . For all G ∈ G t+1 such that G ⊆ G t ( ) and all p ∈ ri (G), c t+1,G (p) = 1 t+1 ∈G p G, log p G, q • G, = 1 t+1 ∈G p log p q • G t ( ) G, . To simplify the notation, set S = G t ( ), q = q • S , G = {G ∈ G t+1 : G ⊆ G t ( )} (notice that G is a partition of S). Choose arbitrarily q ∈ ri (G t ( )), t+1 c t+1,G (q G ) = s∈G q s q(G) log q s q(G) q(G) qs = 1 q(G)</formula><p>s∈G q s log q s qs + 1 q(G) s∈G q s log q(G) q(G) = 1 q(G) s∈G q s log q s qs -log q(G) q(G) . Then, for all q ∈ ri (G t ( )), </p><formula xml:id="formula_164">G∈G t+1 G⊆G t ( ) q(G)c t+1,G (q G ) = G∈G q(G) 1 t+1 1 q(G) s∈G q s log q s qs -log q(G) q(G) = 1 t G∈G s∈G q s log q s qs -G∈G q(G) log q(G) q(G) = 1 t s∈S q s log q s qs -1 t G∈G q(G) log q(G) q(G) , i.e. G∈G t+1 G⊆G t ( ) q(G)c t+1,G (q G ) = c t, (q) - 1 t G∈G q(G) log q (G) q (G) . (<label>36</label></formula><formula xml:id="formula_165">p s = q (G) ∀G ∈ G. (<label>37</label></formula><formula xml:id="formula_166">)</formula><p>We solve the easier problem</p><formula xml:id="formula_167">⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ inf s∈S p s log p s qs , sub, s∈G p s = q (G) ∀G ∈ G (38)</formula><p>and observe that the solution p • is unique, it is a strictly positive vector (this is also required for the existence of log</p><formula xml:id="formula_168">p • s qs ), s∈S p • s = G∈G s∈G p • s = G∈G q (G) = 1</formula><p>, and obviously the constant t has no effect. Thus, p • is the solution of problem (37). The Lagrangian of problem (38) is L (p, ) = s∈S p s log p s qs -G∈G G s∈G p sq (G) , denoting by G (s) the element of G containing s, the first-order conditions are</p><formula xml:id="formula_169">⎧ ⎨ ⎩ log p s qs + 1 -G(s) = 0 ∀s ∈ S, s∈G p s = q (G) ∀G ∈ G,<label>(39)</label></formula><p>simple manipulation yields</p><formula xml:id="formula_170">p s = qs exp G(s) -1 ∀s ∈ S, s∈G p s = q (G) ∀G ∈ G,<label>(40)</label></formula><p>then the observation that G (s) = G (w) for all s ∈ G (w) implies</p><formula xml:id="formula_171">p s = qs exp G(s) -1 ∀s ∈ S, s∈G(w) qs exp G(w) -1 = q (G (w)) ∀w ∈ S,<label>(41)</label></formula><p>and</p><formula xml:id="formula_172">⎧ ⎪ ⎨ ⎪ ⎩ exp G(w) -1 = q (G (w)) q (G (w)) ∀w ∈ S, p s = qs q (G (s)) q (G (s)) ∀s ∈ S. (<label>42</label></formula><formula xml:id="formula_173">)</formula><p>The solution is</p><formula xml:id="formula_174">⎧ ⎪ ⎨ ⎪ ⎩ • G = 1 + log q (G) q (G) ∀G ∈ G, p • s = qs q (G (s)) q (G (s)) ∀s ∈ S,<label>(43)</label></formula><p>which plugged into the value function </p><formula xml:id="formula_175">• s qs = 1 t s∈S qs q(G(s)) q(G(s)) log q(G(s)) q(G(s)) = 1 t G∈G s∈G qs q(G)</formula><p>q(G) log q(G) q(G) , finally inf p∈ri (G t ( )):p |G t+1 =q |G t+1 c t, (p) = 1</p><p>t G∈G q (G) log q (G) q (G) (44) which together with Eq. (36) delivers Eq. (35).</p><p>Setting, for all t &lt; T , ∈ , and q ∈ ( ),  </p><p>Since Eq. ( <ref type="formula" target="#formula_176">45</ref>) is a fortiori true if p / ∈ (G t ( )), condition (31) holds, as wanted.</p><p>To complete the proof we need to prove <ref type="bibr" target="#b17">(18)</ref>. Let c t, (p) ≡ -t R p G t ( ) q • G t ( ) for all (t, , p) ∈ T × × ( ). Fix ∈ and t &lt; T . Step 4 of the proof of Lemma 6 shows that there is a suitable p ∈ ri ( (G t ( ))) such that for all q ∈ (G t ( )) G∈G t+1 q(G)&gt;0 q (G) c t+1,G (q G ) = lim Moreover, by definition of c t, , ∞ &gt; c t, (q) = lim ↑1 c t, ( q + (1 -) p). Since {c t } is a recursive ambiguity index we have t, q |G t+1 = c t, (q) -G∈G t+1 q(G)&gt;0 q (G) ct + 1, G (q G ), since both summands are finite, t, q |G t+1 = lim ↑1 c t, (q p) -G∈G (q p) (G) c t+1,G (q p) G , where q p = q + (1 -) p, but q p ∈ ri ( (G t ( ))) and Eq. (36) delivers</p><formula xml:id="formula_177">t, q |G t+1 = lim ↑1 1 t G∈G t+1 G⊆G t ( ) ( q + (1 -) p) (G) log ( q + (1 -) p) (G) q • G t ( ) (G) = 1 t G∈G q(G)&gt;0 q (G) log q (G) q • G t ( ) (G) = 1 t G∈G t+1 q (G) log q (G) q • G t ( ) (G)</formula><p>, for all q ∈ (G t ( )). By Proposition 2, t, q |G t+1 = ∞ if q ∈ ( ) \ (G t ( )). Therefore, t, (r) = -t R G t+1 r q • G t ( ) |G t+1 for all r ∈ ( , G t+1 ). By <ref type="bibr" target="#b11">(12)</ref>, this implies <ref type="bibr" target="#b17">(18)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.8. Proofs of Theorems 4 and 5</head><p>We first prove Theorem 5. Choose ∈ , t &lt; T , and f ∈ F. First observe that if e and ē belong to E t , e (t, ) = ē (t, ), and e t + 1, = ē t + 1, for all ∈ G t ( ), then, by CP, V t ( , f + e) = V t ( , f + ē). Therefore, *V t ( , f ) = {(k, m) ∈ R × M (G t <ref type="bibr">( )</ref>  Denote by G = G 1 , . . ., G g the set of all elements of G t+1 contained in G t ( ), by G (resp. M (G)) the set (G t ( ) , G t+1 ) (resp. M (G t ( ) , G t+1 )), by f = f 0 , f 1 , . . ., f g the vector f t ( ) , f t+1 (G 1 ) , . . ., f t+1 G g for all f ∈ F, by m = m 1 , . . ., m g the vector m (G 1 ) , . . ., m G g for all m ∈ M (G), and by = 1 , . . ., g the vector ( (G 1 ) , . . ., G g .</p><p>Notice that e → e defines a linear isomorphism between E (t, ) and R g+1 , and set for all e = e 0 , . . ., e g ∈ R g+1 F e 0 , . . ., e g = V t ( , f + e) = u (f t ( ) + e t ( )) Moreover, (k, m) ∈*V t ( , f ) iff lim ↓0 -1 V t ( , f + e) -V t ( , f ) ke t ( )+ e t+1 dm for all e ∈ E (t, ) iff lim ↓0 -1 F ( e) -F 0 ke 0 + g i=1 m i e i for all e ∈ R g+1 iff (k, m) belongs to the superdifferential of Convex Analysis *F 0 of F at 0.</p><formula xml:id="formula_178">+ min</formula><p>For each j = 0, 1, . . ., g, consider:</p><p>• the concave function j : R g+1 → R defined by j ( e) ≡ j u f j + e j + j for all e ∈ R g+1 , with the convention 0 ≡ 0, 0 ≡ 1, j ≡ if j = 1, . . ., g; • the row vector A j corresponding to the projection on the jth component;</p><p>• the function j u + j j : R → R.</p><p>Then j ( e) = j u + j j • A j + f j ( e) and, by [16, Vol. I, Theorem VI.4.2.1],</p><p>* j ( e) = A T j * j u + j j A j + f j ( e)</p><formula xml:id="formula_179">= A T j j *u f j + e j = ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ ⎡ ⎢ ⎢ ⎢ ⎢ ⎣ 0 • • • j u f j + e j • • • 0 ⎤ ⎥ ⎥ ⎥ ⎥ ⎦ u f j + e j ∈ *u f j + e j ⎫ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎭ .</formula><p>Consider the function : R g+1 → R defined by ( v) ≡ v 0 + min r∈ G g i=1 v i r i + t ( , r) . It is easy to check that is concave, monotonic, and</p><formula xml:id="formula_180">* ( v) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ ⎡ ⎢ ⎢ ⎣ 1 1 • • • g ⎤ ⎥ ⎥ ⎦ ∈ arg min r∈ G g i=1 v i r i + t ( , r) ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭ .</formula><p>For all e ∈ R g+1 , F ( e) = 0 ( e) , 1 ( e) , . . ., g ( e) and, setting 0 = 1, [16, Vol. I, Theorem VI.4.3.1] delivers: The proof of Theorem 4 starts with the observation that, for every ∈ , t &lt; T , and f ∈ F, V t ( , f ; •) is linear iff F 0; • is linear iff *F 0 is a singleton iff *V t ( , f ) is a singleton. If u is differentiable and t ( ) is essentially strictly convex, then <ref type="bibr" target="#b25">[26,</ref><ref type="bibr">Theorem 26.3]</ref>  is differentiable, and hence and F are differentiable. Conversely, if u is not differentiable, just take f ∈ R g+1 with f 0 a point of non-differentiability of u to find a non-singleton *F 0 .</p><formula xml:id="formula_181">*F ( 0) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ g i=0 i ⎡ ⎢ ⎢ ⎢ ⎢ ⎣ 0 • • • i u (f i ) • • • 0 ⎤ ⎥ ⎥ ⎥ ⎥ ⎦ ∈ arg min r∈ G g i=1 u (f i ) + i r i + t ( , r) u (f i ) ∈ *u (f i ) ∀i = 0, . . ., g ⎫ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎭ = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ ⎡ ⎢ ⎢ ⎣ u (f 0 ) u (f 1 ) 1 • • • u f g g ⎤ ⎥ ⎥ ⎦ ∈ arg min</formula><p>Then differentiability of V t ( ) implies differentiability of u. If t ( ) is not essentially strictly convex, then (again by <ref type="bibr" target="#b25">[26,</ref><ref type="bibr">Theorem 26.3]</ref>) the functional I defined by (47) is not differentiable, and there exists v u (f i ) + i r i + t ( , r) , moreover u (z) = 0 for all z ∈ R (u is strictly monotonic, concave, and differentiable), and hence</p><formula xml:id="formula_182">⎡ ⎢ ⎢ ⎢ ⎣ u (f 0 ) u (f 1 ) 1 . . . u f g g ⎤ ⎥ ⎥ ⎥ ⎦ and ⎡ ⎢ ⎢ ⎢ ⎣ u (f 0 ) u (f 1 ) ¯ 1 . . . u f g ¯ g ⎤ ⎥ ⎥ ⎥ ⎦</formula><p>are two distinct elements of *F 0 , which is absurd.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 2 .</head><label>2</label><figDesc>Let {c t } t∈T be a family of functions from × ( ) to [0, ∞]. The following statements are equivalent: (a) {c t } is a recursive ambiguity index. (b) There exist &gt; 0 and a one-period-ahead ambiguity index t such that, for all ∈ , c T ( , •) = {d } , and for all t &lt; T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(Lemma 1 . 18 Lemma 2 . 19 Lemma 3 .</head><label>1182193</label><figDesc>I ( ) I ( ) for all , ∈ R such that ) and vertically invariant (I ( + b) = I ( ) + b for all ∈ R and b ∈ R). We will use the following lemmas: Let J : R → R be concave, C ⊆ R and I : C → [-∞, ∞]. The following statements are equivalent: (a) J ( ) = inf ∈C ( , + I ( )) for all ∈ R ; (b) I : C → (-∞, ∞] is proper and co I = -J * . Let C be a convex compact subset of R , and I : C → (-∞, ∞] a proper closed and convex function. Then inf ∈ri C I ( ) = min ∈C I ( ) iff ri C ∩ dom I = ∅ iff inf ∈ri C I ( ) &lt; ∞. Let J : R → R be a concave normalized niveloid, and G ⊆ . The following statements are equivalent:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Lemma 4 .</head><label>4</label><figDesc>The following statements are equivalent: (a) t, satisfy CP, VP, and RP. (b) There exists a family {c t ( , •) : (t, ) ∈ T × } of grounded, closed and convex functions c t ( , •) :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>1 b, and the constant act x b to obtain U t x b = t -t u x b = b for all ∈ , then b1 = U t x b (where x b is regarded as a constant act) and I t, (b1 ) = V t, x b = U t x b , x b , . . ., x b = b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Moreover, ¯ , ū, { ct } represent t, in the sense of (b) iff ¯ = , ū = au + b for some a &gt; 0 and b ∈ R and { ct } = {ac t }. Proof. (a) ⇔ (b) immediately descends from Lemma 4. (c) ⇒ (a) is trivial. (b) ⇒ (c). Since (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) ⇒ (b) is an immediate consequence of the definition of recursive ambiguity index and Proposition 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(i) c t+1 (•, p) : → [0, ∞] is measurable w.r.t. G t+1 for all p ∈ ( ), (ii) c t+1 ( , •) : ( ) → [0, ∞] is grounded, closed and convex, with dom c t ( , •) ⊆ (G t+1 ( ))and dom c t+1 ( , •) ∩ ++ (G t+1 ( )) = ∅, for all ∈ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>↑1 t, (( 1 -</head><label>1</label><figDesc>) q + p) = lim ↑1 c t, ((1 -) q + p) = c t, (p) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1 -</head><label>1</label><figDesc>) p) (G) c t+1,G ( q+ (1 -) p) G .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>r∈ G V t+1 (f + e) dr + t ( , r) = u (f 0 + e 0 ) + min r∈ G u f t+1 + e t+1 + dr + t ( , r) = u (f 0 + e 0 ) + min r∈ G g i=1 u (f i + e i ) + i r i + t ( ,r) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>i ) + i r i + t ( , r) u (f i ) ∈ *u (f i ) ∀i = 0, . . ., g u (f t ( )) , m m (G) = u (f t+1 (G)) (G) ∀G ∈ G t+1 , ∈ arg min r∈ G u f t+1 + dr + t ( , r) , u (f t ( )) ∈ *u (f t ( )) , u (f t+1 (G)) ∈ *u (f t+1 (G)) ∀G ∈ G t+1 ⎫ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎭ ,which together with (46) (i.e. u (f t+1 ) + = V t+1 (f )) delivers (21), and concludes the proof of Theorem 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>= l is the probability of having l successes among t ∈ T trials. Some algebra shows that here the predictive distributions are given by p ( t+1 , . . ., T | 1 , . . ., t ) =</figDesc><table><row><cell>where p</cell><cell cols="4">t i=1 i T</cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>l+k</cell><cell>t</cell><cell>l+k t</cell><cell>,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>l</cell><cell>l</cell></row><row><cell cols="6">where l = t i=1 i and k = T i=t+1 i . Because of exchangeability, only the quantities l and</cell></row><row><cell cols="6">k matter for the predictive distributions. Here information, as recorded by l and k, is relevant for</cell></row><row><cell>prediction.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Example 4. Finally, suppose that p ∈ ( ) makes the sequence {Z t } a homogeneous Markov</cell></row><row><cell cols="5">chain with transition function</cell></row><row><cell cols="6">Example 2. Consider a p ∈ ( ) that makes the sequence {Z t } i.i.d., with common marginal distribution : 2 Z → [0, 1]. In this case, p is a product probability on 2 uniquely determined</cell></row><row><cell cols="2">by as follows:</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>T</cell><cell></cell><cell></cell></row><row><cell cols="2">p ( ) ≡</cell><cell></cell><cell cols="2">( i ) ∀ ∈ .</cell></row><row><cell></cell><cell cols="2">i=1</cell><cell></cell><cell></cell></row><row><cell cols="5">The predictive distributions are given by</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>T</cell></row><row><cell cols="5">p ( t+1 , . . ., T | 1 , . . ., t ) =</cell><cell>( i ) ,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>i=t+1</cell></row><row><cell cols="6">that is, p ( t+1 , . . ., T | 1 , . . ., t ) = p ( t+1 , . . ., T ). Hence, information is irrelevant for</cell></row><row><cell>prediction.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Example 3. Consider a p ∈ ( ) that makes the sequence {Z t } exchangeable, i.e.,</cell></row><row><cell cols="5">p ( 1 , . . ., T ) = p i 1 , . . ., i T</cell><cell>(7)</cell></row><row><cell cols="6">for all permutations i 1 , . . ., i T . For simplicity, suppose Z = {0, 1} and set</cell></row><row><cell>t l ≡</cell><cell>t l</cell><cell>p</cell><cell>t i=1</cell><cell>i = l ,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>the act is called constant and, with another little abuse of notation, we denote it by x.</figDesc><table><row><cell>Example 5. Suppose as in Example 1 that = {0, 1} T .A consumption process h = (h 0 , h 1 , . . .,</cell></row><row><cell>h T ) is such that</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>, (p)) for some h ∈ H, then, by Lemma 2, ri (G t ( )) ∩ dom c t, = ∅. If, per contra, dom c t, If t, satisfy CP, FS, and DC, then for each t and , no state in G t ( ) is t, -null, provided |G t ( )| &gt; 1.</figDesc><table><row><cell>is not contained in</cell><cell>G t ( ) \</cell><cell>for some</cell><cell cols="3">∈ G t ( ), then for all</cell><cell>∈ G t ( ) there</cell></row><row><cell cols="2">exists p ∈ dom c t, with</cell><cell cols="2">∈ supp p , then |G t ( )| -1</cell><cell>∈G t ( )</cell><cell>p ∈ ri (G t ( )) ∩</cell></row><row><cell cols="3">dom c t, , which is absurd. Then dom c t, ⊆</cell><cell>G t ( ) \</cell><cell cols="2">for some</cell><cell>, which must be</cell></row><row><cell cols="6">t, -null. This is (ii) ⇒ (i). The equivalence between (i) and (iii) descends immediately from</cell></row><row><cell>Lemma 2.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Lemma 5.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Let h 1 , h 2 ∈ H be such that h 1 = h 2 for all t and h 1 t+1, h 2 , for all ∈ , we want to show that h 1 t, h 2 . Since h 1 t+1, h 2 , for all ∈ , then J t+1,</figDesc><table><row><cell>,</cell><cell>2 , i.e. J t,</cell><cell>1</cell><cell>J t,</cell><cell>2 .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>)</head><label></label><figDesc>Moreover, for all q ∈ ri (G t ( )), inf p∈ri (G t ( )):p |G t+1 =q |G t+1 c t, (p) = inf p∈ri (S):p |G =q |G c t, (p) is the value of the problem</figDesc><table><row><cell>⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨</cell><cell>inf sub,</cell><cell>1 t</cell><cell>s∈S</cell><cell>p s log</cell><cell>p s qs</cell><cell>,</cell></row><row><cell>⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩</cell><cell cols="4">p s &gt; 0 ∀s ∈ S, s∈S p s = 1,</cell><cell></cell><cell></cell></row></table><note><p>s∈G</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>1   </figDesc><table><row><cell></cell><cell></cell><cell>t</cell><cell>s∈S p s log p s qs delivers inf p∈ri (G t ( )):p |G t+1 =q |G t+1</cell><cell>c t,</cell></row><row><cell>(p) = 1 t</cell><cell>s∈S p • s log</cell><cell>p</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>|G t+1 =q |G t+1 c t, (p) if q ∈ ri (G t ( ))∞ otherwise the function t, coincides with the closed and convex function c t, on ri ( (G t ( ))). Take q ∈ ri dom t,G t ( ) = ri ( (G t ( ))), by<ref type="bibr" target="#b25">[26,</ref> Theorem 7.5], for all p ∈ (G</figDesc><table><row><cell>t, (q) =</cell><cell>⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩</cell><cell>G∈G t+1 G⊆G t ( ) + p∈ri (G q(G)c t+1,G (q G ) inf</cell></row></table><note><p>t ( )):p t ( )), co t, (p) = lim</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>, G t+1 ) : V t ( , f ; e) ke t ( ) + e t+1 dm for all e ∈ E (t, )} where E (t, ) is the set of all {G t }adapted processes e such that e , = 0 if = t, t + 1 or / ∈ G t ( ). For all e ∈ E (t, ): If t = T -1, then V t+1 , f + e = V T , f + e = u f T , where the last equality descends from CP and the fact that f + e = f for all t + 2. G t+1 -measurability of V t+1 (•, f + e), f t+1 , and e t+1 implies G t+1 -measurability of the function defined by = min p∈ ( ,G t+2)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>+</cell></row><row><cell>e T</cell><cell cols="3">for all ∈ ; set</cell><cell></cell><cell cols="2">= 0 for all ∈ , and get V t+1</cell><cell>, f + e = u f t+1</cell><cell>+</cell></row><row><cell>e t+1</cell><cell>+</cell><cell></cell><cell cols="2">. Else V t+1</cell><cell cols="2">, f + e = u f t+1</cell><cell>+ e t+1</cell><cell>+ min p∈ ( ,G t+2) (</cell></row><row><cell cols="4">V t+2 (f + e) dp + t+1</cell><cell cols="2">, p = u f t+1</cell><cell>+ e t+1</cell><cell>+min p∈ ( ,G t+2)</cell><cell>V t+2 (f )</cell></row><row><cell cols="2">dp + t+1</cell><cell cols="2">, p for all</cell><cell cols="3">∈ V t+2 (f ) dp+</cell></row><row><cell>t+1</cell><cell cols="2">, p for all</cell><cell cols="3">∈ . Also, in this case,</cell></row><row><cell></cell><cell>V t+1</cell><cell cols="3">, f + e = u f t+1</cell><cell>+ e t+1</cell><cell>+</cell><cell>∀ ∈ .</cell><cell>(46)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>guarantees that I v 1 , . . ., v g ≡ min</figDesc><table><row><cell></cell><cell>g</cell><cell></cell></row><row><cell>r∈ G</cell><cell>i=1</cell><cell>v i r</cell></row></table><note><p>i + t ( , r) ∀ v 1 , . . ., v g ∈ R g (47)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>• 1 , . . ., v • g ∈ R g such that there are two different and ¯ ∈ *I v • 1 , . . ., v • g = arg min r∈ G g i=1 v • i r i + t ( , r) . Since u (R) is unbounded, there are f ∈ F and b ∈ R such that u (f i ) + i = v •i +b for i = 1, . . ., g. Then , ¯ ∈ arg min r∈ G</figDesc><table><row><cell>g</cell></row><row><cell>i=1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>As Hart et al.[13, p. 352]  write "In Gilboa and Schmeidler<ref type="bibr" target="#b8">[9]</ref> it is shown that preferences . . . are represented by functionals of the form f → min q∈Q s u (f (s)) q (s), for some closed convex set Q ⊂ (S). So the ambiguity averse decision maker behaves 'as if' there were an opponent who could partially influence occurrence of states to his disadvantage (i.e., think of the opponent as choosing q ∈ Q)."  Though not yet firmly established, this informed opponent interpretation has found some support in recent experimental findings in the psychological and neuroscience literatures (see<ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b26">27]</ref>).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Here, is a discount factor and G t represents the information available to the agents at time t.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>This dynamically consistent behavior of Nature reminds of the Principle of Least Action, a fundamental idea in theoretical physics, which for example lies at the heart of both classical and quantum mechanics. In its meta-theoretic form, this principle says that Nature is thrifty in all its actions, and so it acts in the simplest possible way. The dynamic consistency of Nature can be viewed as a form of this important meta-theoretic principle because (5) describes the simplest possible way for Nature to end up with a probability q(G) of every event G in the first period, and a conditional probability q G if G obtains.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>We write p ( 1 , . . ., t ) and t+1 , . . ., T in place of p ({ 1 , . . ., t })and 1 ×• • •× t × t+1 ×• • •×{ T }.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Notice that for all ∈ with p (G t ( )) = 0, p (• |G t ) ( ) = p G t ( ) , as defined by<ref type="bibr" target="#b5">(6)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_5"><p>Clearly, the functionals t V t ( , h) = inf p∈ ++ ( ) t u (h ) dp G t ( ) + R p G t ( ) q G t ( ) represent the same preferences.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_6"><p>Here *u (z) is the superdifferential of u at z, while u f t+1 d is the measure with density u f t+1 with respect to .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_7"><p>1 is the constant vector (1, 1, . . ., 1). Sometimes we will write b instead of b1 .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_8"><p>J t, is the unique vertically invariant function that extends I t, to R .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_9"><p>Notice that for all G ∈ G, r (G) = q (G) and r G = p G .</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Erio Castagnoli, Larry Epstein, Gino Favero, Salvatore Modica, Sergio Segre, Claudio Tebaldi, several seminar audiences, and, especially, Thomas Sargent and three anonymous referees for some very helpful comments. Part of this research was done while the first two authors were visiting in Spring 2004 the Department of Economics of Boston University and CERMSEM (Université Paris 1), which they thank for their hospitality. They also gratefully acknowledge the financial support of the Ministero dell'Istruzione, dell'Università e della Ricerca. Rustichini gratefully acknowledges the financial support of the National Science Foundation (Grant # 0136556).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Proofs and related material</head><p>An important tool for the proofs is Convex Analysis, we refer the reader to <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b15">16]</ref> for notation, definitions, and results.</p><p>Here, we just remind that a function</p><p>identically ∞ and there is an affine function minorizing it. Niveloids are comprehensively studied in Dolecki and Greco <ref type="bibr" target="#b1">[2]</ref> and Maccheroni et al. <ref type="bibr" target="#b21">[22]</ref>. When R ∈ R, R + , R ++ , R -, R --and C = R , I is a niveloid if and only if I is monotonic</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Conditional and dynamic convex risk measures</title>
		<author>
			<persName><forename type="first">K</forename><surname>Detlefsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scandolo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Mimeo</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Dolecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName><surname>Niveloids</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topological Methods Nonlinear Anal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Uncertainty aversion, risk aversion, and the optimal choice of portfolio</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Werlang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="197" to="204" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A Weak Convergence Approach to the Theory of Large Deviations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dupuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Ellis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Risk, ambiguity, and the Savage axioms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ellsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quart. J. Econ</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="643" to="669" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recursive multiple-priors</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intertemporal asset pricing under Knightian uncertainty</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="283" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ambiguity from the differential viewpoint</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ghirardato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maccheroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marinacci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICER WP</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Maxmin expected utility with a non-unique prior</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmeidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Econ</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="141" to="153" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Updating preferences with multiple priors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hanany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Klibanoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Mimeo</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sargent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robust control and model uncertainty</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="60" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust control and model misspecification</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sargent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Turmuhambetova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint/>
	</monogr>
	<note>this symposium</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A neo 2 Bayesian foundation of the maxmin value for two-person zero-sun games</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Modica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmeidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Game Theory</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="347" to="358" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quasi-stationarity cardinal utility and present bias</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="343" to="352" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Intertemporal substitution, risk aversion, and ambiguity aversion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="933" to="956" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<title level="m">Convex Analysis and Minimization Algorithms, vols. I</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">II</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tranel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural systems responding to degrees of uncertainty in human decision-making</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">310</biblScope>
			<biblScope unit="page" from="1680" to="1683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the robustness and possible accounts of ambiguity aversion</title>
		<author>
			<persName><forename type="first">G</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Gerritsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psych</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="149" to="172" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The role of competition and knowledge in the Ellsberg task</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kühberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Behavioral Dec. Making</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="181" to="191" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Liese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vajda</surname></persName>
		</author>
		<title level="m">Convex Statistical Distances</title>
		<meeting><address><addrLine>Teubner, Leipzig</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Ambiguity aversion, robustness, and the variational representation of preferences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Maccheroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marinacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Mimeo</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Niveloids and their extensions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Maccheroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marinacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Mimeo</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Portfolio selection with monotone mean-variance preferences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Maccheroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marinacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Mimeo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ambiguity aversion and incompleteness of financial markets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mukerji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Tallon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econ. Stud</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="883" to="904" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Ambiguity aversion, games against Nature, and dynamic consistency</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ozdenoren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Mimeo</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Emotion and reason in making decisions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">310</biblScope>
			<biblScope unit="page" from="1624" to="1625" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dynamic choice under ambiguity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Mimeo</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust control and recursive utility</title>
		<author>
			<persName><forename type="first">C</forename><surname>Skiadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Finance Stochastics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="475" to="489" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A note on recursive multiple priors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wakai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Mimeo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Conditional preferences and updating</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="286" to="321" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
