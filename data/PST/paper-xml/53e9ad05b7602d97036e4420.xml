<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Image Super-Resolution using Gradient Profile Prior</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Microsoft Research Asia Xi&apos;an</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>P. R. China, P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zongben</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Microsoft Research Asia Xi&apos;an</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>P. R. China, P. R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Image Super-Resolution using Gradient Profile Prior</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5D89049650E786682BCC08125CA5E09C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose an image super-resolution approach using a novel generic image prior -gradient profile prior, which is a parametric prior describing the shape and the sharpness of the image gradients. Using the gradient profile prior learned from a large number of natural images, we can provide a constraint on image gradients when we estimate a hi-resolution image from a low-resolution image. With this simple but very effective prior, we are able to produce state-of-the-art results. The reconstructed hiresolution image is sharp while has rare ringing or jaggy artifacts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of single image super-resolution is to estimate a hi-resolution (HR) image from a low-resolution (LR) input. There are mainly three categories of approach for this problem: interpolation based methods, reconstruction based methods, and learning based methods. The interpolation based methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b18">18]</ref> are simple but tend to blur the high frequency details. The reconstruction based methods <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b2">3]</ref> enforce a reconstruction constraint which requires that the smoothed and down-sampled version of the HR image should be close to the LR image. The learning based methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b31">31]</ref> "hallucinate" high frequency details from a training set of HR/LR image pairs. The learning based approach highly relies on the similarity between the training set and the test set. It is still unclear how many training examples are sufficient for the generic images.</p><p>To design a good image super-resolution algorithm, the essential issue is how to apply a good prior or constraint on the HR image because of the ill-posedness of the image super-resolution. Generic smoothness prior <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b10">11]</ref> and edge smoothness prior <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b27">27]</ref> are two widely used priors.</p><p>In this paper, we propose a novel generic image priorgradient profile prior for the gradient field of the natural im- age. The gradient profile is a 1-D profile along the gradient direction of the zero-crossing pixel in the image. The gradient profile prior is a parametric distribution describing the shape and the sharpness of the gradient profiles in natural image. One of our observations is that the shape statistics of the gradient profiles in natural image is quit stable and invariant to the image resolution. With this stable statistics, we can learn the statistical relationship of the sharpness of the gradient profile between the HR image and the LR image. Using the learned gradient profile prior and relationship, we are able to provide a constraint on the gradient field of the HR image. Combining with the reconstruction constraint, we can recover a hi-quality HR image.</p><p>978-1-4244-2243-2/08/$25.00 ©2008 IEEE</p><p>The advantages of the gradient profile prior are as follows: 1) unlike previous generic smoothness prior and edge smoothness prior, the gradient profile prior is not a smoothness constraint. Therefore, both small scale and large scale details can be well recovered in the HR image; 2) the common artifacts in super-resolution, such as ringing artifacts, can be avoided by working in the gradient domain.</p><p>Our work is motivated by recent progresses on natural image statistics. The gradient magnitudes generally obey a heavy tailed distribution e.g., a Laplacian distribution <ref type="bibr" target="#b12">[13]</ref>. This kind of "sparseness prior" has been successfully applied to super-resolution <ref type="bibr" target="#b28">[28]</ref>, denoising <ref type="bibr" target="#b23">[23]</ref> [24], inpainting <ref type="bibr" target="#b17">[17]</ref>, transparency separation <ref type="bibr" target="#b16">[16]</ref> and deblurring <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">15]</ref>. However, the sparseness prior only considers the marginal distribution of image gradients (e.g., intensity difference between two adjacent pixels) over the whole image. In this work, our gradient profile prior considers the distribution of the image gradients along local image structures.</p><p>Fattal <ref type="bibr" target="#b6">[7]</ref> also proposed an edge statistics for image upsampling. The proposed statistics is the distribution of local intensity continuity in the HR image conditional on edge features in the LR image. Different from his non-parametric statistics, firstly, the gradient profile prior is a generic, parametric image prior for the gradient field of the natural image; secondly, our prior is stable to the image resolution. It is a good property for image super-resolution.</p><p>In section 2, we will introduce the gradient profile prior. Then we apply the gradient profile prior to image superresolution in section 3. We show experimental results in section 4 and conclude the paper in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Gradient Profile Prior</head><p>Previous natural image statistics characterizes the marginal distribution of the image gradients over the whole image. The spatial information is discarded. Instead, we study the image gradients along local image structures and the statistical dependency of the image gradients between the HR image and the LR image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Gradient profile and its sharpness</head><p>Denote the image gradient as ∇I = m • -→ N , where m is the gradient magnitude and -→ N is the gradient direction. In the gradient field, we denote the zero crossing pixel which is the local maximum on its gradient direction as edge pixel.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> (a) are two image blocks containing two edges with different sharpness. Figure <ref type="figure" target="#fig_0">1</ref> (b) are corresponding gradient (magnitude) maps. The pixel x 0 in Figure <ref type="figure" target="#fig_0">1 (b</ref>) is a zero crossing or edge pixel. Starting from x 0 , we trace a path along the gradient directions (two-sides) pixel by pixel until the gradient magnitude does not decrease anymore. We call the 1-D path p(x 0 ) as gradient profile. Figure <ref type="figure" target="#fig_0">1</ref> (c) are 1D curves of two gradient profiles.</p><p>We measure the sharpness of the gradient profile using the square root of the variance (second moment):</p><formula xml:id="formula_0">σ(p(x 0 )) = x∈p(x0 ) m ′ (x)d 2 (x, x 0 )<label>(1)</label></formula><p>where m ′ (x) = m(x)</p><p>s ∈p (x 0 ) m(s) and d(x, x 0 ) is the curve length of the gradient profile between x and x 0 . The sharper image gradient profile, the smaller the variance σ is. We call this variance as the profile sharpness. Profile sharpness estimation. Individually estimating the sharpness for each gradient profile is not robust due to the noise. To have a better estimation, we apply a global optimization to enforce the consistency of neighboring profiles as follows.</p><p>First, we construct a graph on all edge pixels. The graph node is the edge pixel and the graph edge is the connection between two neighboring edge pixels within a pre-defined distance (5 pixels in this paper). The edge weight w ij for each clique of two connected nodes i and j is defined as,</p><formula xml:id="formula_1">w i, j = exp(-ζ 1 • |∇u i -∇u j | 2 -ζ 2 • d(i, j ) 2 ),<label>(2)</label></formula><p>where the first term in the exponent is the gradient similarity, and the second term is Euclidean distance between i and j. For each node i, we individually estimate its sharpness σi using Equation ( <ref type="formula" target="#formula_0">1</ref>). Then, we minimize the following energy to estimate the sharpness of all edge pixels:</p><formula xml:id="formula_2">E({σ i }) = i [(σ i -σi ) 2 + γ • j∈N (i) w i, j • (σ i -σ j ) 2 ],</formula><p>(3) where N (i) are neighboring nodes of the node i. This energy can be effectively minimized because it is an Gaussian MRF model, in which γ = 5, ζ 1 = 0. 15, and ζ 2 = 0. 08 in our implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Gradient profile prior</head><p>Next, we investigate the regularity of the gradient profiles in natural image. We fit the distribution of the gradient profile by a general exponential family distribution, i.e. Generalized Gaussian Distribution (GGD) <ref type="bibr" target="#b30">[30]</ref>, which is defined as,</p><formula xml:id="formula_3">g(x; σ, λ ) = λα(λ) 2σΓ( 1 λ ) exp{-[α(λ)| x σ |] λ },<label>(4)</label></formula><p>where Γ(•) is gamma function and α(λ) = Γ( 3 λ )/ Γ( 1 λ ) is the scaling factor which makes the second moment of GGD equal to σ 2 . Therefore, σ can be directly estimated using the second moment of the profile. λ is the shape parameter which controls the overall shape of the distribution. The Average KL divergences between the fitted gradient profiles and 1 million gradient profiles by varying the shape parameter λ. The optimal λ is near 1.6 on four data sets with different resolutions. distribution g(x; σ, λ ) is a Gaussian distribution if λ = 2, and a Laplacian distribution if λ = 1.</p><p>To fit the distribution, we collect an image set containing 1,000 natural images downloaded from professional photography forums. All images are in the original resolution without down-sampling or up-sampling. For each image, we randomly select 1,000 gradient profiles to construct a data set Ω 1 which consists of 1 million gradient profiles. We also construct other three profile data sets Ω 2 , Ω 3 and Ω 4 from the down-sampled versions of the original resolution images with the down-sampling factors of 2, 3, and 4.</p><p>Using Kullback-Leibler (KL) divergence to measure the fitting error, we estimate the optimal λ * by</p><formula xml:id="formula_4">λ * = argmin λ { p∈Ω KL(p, g (•; σ p , λ ))},<label>(5)</label></formula><p>where σ p is the variance (estimated using Equation (3)) of p, which is one profile in the set Ω. We compute the average KL divergences on four profile sets Ω 1 , Ω 2 , Ω 3 , and Ω 4 by varying the shape parameterλ, as shown in Figure <ref type="figure">2</ref>. As we can see, the optimal shape parameter is about 1. 6 for all down-sampling factors. The shape parameter λ is stable across different resolutions, which means that the gradient profile distribution is resolution independent in natural image.</p><p>We use Pearson's χ 2 hypothesis-test to measure the goodness of our fitted distributions. The χ 2 hypothesis-test for a gradient profile p(x 0 ) is defined as</p><formula xml:id="formula_5">χ 2 (p) = x∈p(x0 ) [m(x) -E(x)] 2 E(x) ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_6">E(x) = g(d(x, x 0 )) s ∈p (x 0 ) g(d(s, x 0 )) • s∈p(x0 ) m(s).</formula><p>For significance level κ and degrees of freedom n -1 (n is the number of pixels in p), if χ 2 (p) &lt; χ 2 (κ, n -1) , the hypothesis that the gradient profile follows the fitted gradi-ent profile prior cannot be rejected. For the common significance level κ = 0. 01, the average differences between the values of χ 2 on the gradient profiles and corresponding values of χ 2 (κ, n -1) are -2.22, -1.90, -1.50, -1.20 on four date sets Ω 1 , Ω 2 , Ω 3 , Ω 4 . All average differences are significantly smaller than zero, which means the gradient profiles in natural image are well fitted by our gradient profile prior.</p><p>To verify whether the parameter λ = 1. 6 is independent on our collected data or not, we repeat the above experiments on two different image sources. One is 500 images randomly downloaded from Flickr image site. The other is 500 images from a home photo gallery taken with 4 different digital cameras. Again, the obtained optimal shape parameters are stable and between 1.55 and 1.65, which means the generalized gaussian distribution with λ = 1. 6 is a good generic prior for the natural image and independent on the image resolution. Based on this very nice statistics, we only need to study the relationship of the gradient profile sharpness σ between two different resolutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Relationship of gradient profile sharpness between HR image and LR image</head><p>Similar to previous methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b6">7]</ref>, we study the relationship of gradient profile sharpness between the upsampled image I u l and the HR image I h , in order to avoid the shifting problem of the zero-crossing pixels in scale space <ref type="bibr" target="#b32">[32]</ref>. In our implementation, the up-sampled image I u l is the bicubic interpolation<ref type="foot" target="#foot_0">1</ref> of the LR image I l .</p><p>For each gradient profile in the up-sampled image I u l , we extract its corresponding gradient profile in the HR image I h . Because the edge pixels are not exactly aligned in two images, we find the best matched edge pixels by measuring the distance and direction. For each edge pixel e l in I u l , the best matched edge pixel e h in I h is found by:</p><formula xml:id="formula_7">e h = argmin e∈N (e l ) {||e -e l || + 2|| -→ N (e) - -→ N (e l )||}<label>(7)</label></formula><p>where N (e l ) is the 5 × 5 neighbors of e l in the HR image.</p><p>To compute the statistics, we quantize the sharpness σ into a number of bins. The width of bin is 0.1. For all LR gradient profiles whose sharpness value falls in the same bin, we calculate the expectation of sharpness of the corresponding HR gradient profiles. Figure <ref type="figure">3</ref> shows three fitted curves of computed expectations for the up-sampling factors of 2, 3, and 4. X-axis is the sharpness of the (upsampled) LR gradient profile and Y-axis is expected sharpness of the hi-resolution gradient profile.</p><p>There are two basic observations from Figure <ref type="figure">3</ref>: 1) the HR gradient profile is sharper than the LR gradient profile because the bicubic interpolation blurs the profile; 2) the higher the up-sampling factor, the larger the sharpness difference between the HR gradient profile and the LR gradient profile is. Notice that three curves converge together when the sharpness is below 1.0 in Figure <ref type="figure">3</ref>. One possible reason is due to the inaccuracy of our sharpness estimation. The sharpness estimation for the small scale edge is sensitive to the noise. Also, the introduced image aliasing in the LR image by down-sampling may result in over-estimated sharpness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Gradient Prior for Image Super-Resolution</head><p>In this section, we apply the gradient profile prior to image super-resolution. Given a LR image, the gradient profile prior can provide constraints on the gradient field of the HR image: 1) the shape parameter of gradient profiles in the HR image is close to the value 1.6; 2) the sharpness relationship of gradient profiles between two resolutions follows the statistical dependency learned in the previous section. To enforce these constraints, we propose a simple approach as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Gradient field transformation</head><p>We propose a gradient field transformation approach to approximate the HR gradient field by transforming the LR gradient field using the gradient profile prior.</p><p>First, we study how to transform a gradient profile p l = {λ l , σ l } in the up-sampled image I u l to a gradient profile p h = {λ h , σ h } in the HR image I h . We compute the ratio  between two gradient profiles, i.e.</p><formula xml:id="formula_8">r(d) = g(d; σ h , λ h ) g(d; σ l , λ l ) = c • exp{-( α(λ h ) • |d| σ h ) λ h + ( α(λ l ) • |d| σ l ) λ l },<label>(8)</label></formula><p>where</p><formula xml:id="formula_9">c = λ h •α(λ h )•σ l •Γ(1/ λ l ) λ l •α(λ l )•σ h •Γ(1/ λ h )</formula><p>and d is the curve distance to the edge pixel along the gradient profile. Thus, the HR gradient profile p h can be estimated by multiplying LR gradient profile p l by the transform ratio. The shape parameters λ h and λ l are set to the learned values in Section 2, the sharpness σ l is estimated from the image I u l and the sharpness σ h is set as the expected value of σ l using the relationship we learned in section 2.3.</p><p>Second, using the ratio computed in (8), we can transform the LR gradient field ∇I u l to the HR gradient field ∇I T h by</p><formula xml:id="formula_10">∇I T h (x) = r(d(x, x 0 )) • ∇I u l (x),<label>(9)</label></formula><p>where x 0 is the edge pixel of the gradient profile passing through x, and d(x, x 0 ) is the distance between x and x 0 along gradient profile. In our implementation, to find the gradient profile passing through x, we trace from x along the direction (gradient direction or minus gradient direction) with increasing gradient magnitude until reach an edge pixel x 0 (in a threshold distance, e.g., 1 pixel), then adjust the gradient of x by <ref type="bibr" target="#b8">(9)</ref>. Figure <ref type="figure" target="#fig_4">4</ref> (a) shows an illustration of gradient transformation. Figure <ref type="figure" target="#fig_4">4 (b-e</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">HR Image reconstruction</head><p>We use the transformed gradient field as the gradient domain constraint for the HR image reconstruction. Given the LR image I l , in order to reconstruct the HR image I h , we minimize the following energy function by enforcing the constraints in both image domain and gradient domain:</p><formula xml:id="formula_11">E(I h |I l , ∇I T h ) = E i (I h |I l ) + βE g (∇I h |∇I T h ),<label>(10)</label></formula><p>where E i (I h |I l ) is the reconstruction constraint in the image domain and E g (∇I h |∇I T h ) is the gradient constraint in the gradient domain.</p><p>The reconstruction constraint measures the difference between the LR image I l and the smoothed and down-sampled version of HR image I h , i.e.</p><formula xml:id="formula_12">E i (I h |I l ) = |(I h * G) ↓ -I l | 2 . (<label>11</label></formula><formula xml:id="formula_13">)</formula><p>where G is a spatial filter, * is the convolution operator, and ↓ is the down-sampling operation. We use a gaussian filter for the spatial filter G. The kernel standard variance is set to 0.8, 1.2 and 1.6 for the up-sampling factors of 2, 3 and 4.</p><p>The gradient constraint requires that the gradient field of the recovered HR image should be close to the transformed HR gradient field ∇I T h :</p><formula xml:id="formula_14">E g (∇I h |F ) = |∇I h -∇I T h | 2 ,<label>(12)</label></formula><p>where ∇I h is the gradient of I h . Using this constraint, we encourage the gradient profiles in I h has a desired statistics which we learned from the natural images.</p><p>The energy <ref type="bibr" target="#b9">(10)</ref> can be minimized by a gradient descent algorithm:</p><formula xml:id="formula_15">I t+1 h = I t h -τ • ∂E(I h ) ∂I h ,</formula><p>where   The global optimum can be obtained because the energy (10) is a quadratic function. We set the step size τ to 0.2, parameter β = 0. 5 and use the up-sampled image I u l as the initial value of I h .</p><formula xml:id="formula_16">∂E(I h ) ∂I h = ((I h * G) ↓ -I l ) ↑ * G -β • (∇ 2 I h -∇ 2 I T h ).<label>(13)</label></formula><p>Figure <ref type="figure">5</ref> gives a real example of our method. Figure <ref type="figure">6</ref> also shows an example on a synthetic image. Our approach can reconstruct a very sharp HR image guided by a transformed gradient field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We test our approach on a variety of images. For the color images, we only perform image super-resolution on the grayscale channel because the human are more sensitive to the brightness information. The color channels are upsampled using the bicubic interpolation.</p><p>In Figure <ref type="figure" target="#fig_9">7</ref>, we compare our approach with bicubic interpolation, sharpened bicubic interpolation, back-projection <ref type="bibr" target="#b14">[14]</ref>, and reconstruction from the transformed gradient field by solving poisson equations. The result of bicubic interpolation is over-smooth, for example the region in the rectangle. The sharpened bicubic interpolation and backprojection introduce ringing or jaggy artifacts, especially along salient edges. The result of reconstruction from the transformed gradient field is sharp and with rare artifacts, but the color is not close to the ground truth HR image. By combing gradient constraint and reconstruction constraint, our final result is the best.</p><p>Figure <ref type="figure" target="#fig_10">8</ref> shows the comparison of our approach with learning based method <ref type="bibr" target="#b9">[10]</ref> and alpha channel superresolution <ref type="bibr" target="#b5">[6]</ref>. The result of learning based method is sharp in appearance. However, high frequency artifacts are also introduced from the training samples, for example the artifacts around the nose. The salient edges in alpha channel super-resolution result are sharp, but the small scale edges, for example flecks on the face, are not well recovered. That's because it's hard to estimate alpha channel value for the edges with weak contrast and large blur. Compared with these results, our approach can recover both large scale edges and small scale details, and introduce minimal additional artifacts.   factor of 8 and one example with up-sampling factor of 16, in which the HR results are produced by repeatedly running our super-resolution algorithm with up-sampling factor of 2. In Figure <ref type="figure" target="#fig_12">9</ref>, the image regions in the blue rectangles are magnifed by nearest neighbor interpolation for better illustration. All of the results show that our method can reliably recover the image details and produce sharp edges with minimal additional artifacts.</p><p>We also compute RMS and ERMS <ref type="bibr" target="#b26">[26]</ref> to qualitatively measure the super-resolution results of Monarch (Figure <ref type="figure">5</ref>), Lena (Figure <ref type="figure" target="#fig_9">7</ref>) and Head (Figure <ref type="figure" target="#fig_10">8</ref>). The measurements are listed in Table <ref type="table" target="#tab_0">1</ref>. Our model outperforms the bicubic and back-projection with lower RMS and ERMS. The computation costs for Monarch (original resolution is 399 × 423), Lena (original resolution is 500 × 500) and Head (original resolution 280 × 280) are 7.4s, 8.7s, and 3.5s on a 3.0 GHz PC. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Discussion</head><p>In this paper, we have established a gradient profile prior for natural image. Using this prior, a gradient field constraint is enforced for the problem of image super-resolution. The gradient constraint helps to sharpen the details and suppress ringing or jaggy artifacts along edges. Encouraging results are obtained on a variety of natural and synthetic images.  For noisy input LR image, estimating the gradient profile might be inaccurate due to the noise. One possible solution is to denoise the LR image first, then add the up-sampled noises back after the image super-resolution, see Figure <ref type="figure" target="#fig_16">11</ref> for an example. In the future, we are planning to extend the proposed method to video super-resolution. We are also interested in applying the gradient profile prior to other image reconstruction applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Gradient profile. (a) two edges with different sharpness. (b) gradient maps (normalized and inverted magnitude) of two rectangular regions in (a). p(x0 ) is a gradient profile passing through the edge pixel (zero crossing pixel) x0 , by tracing along gradient directions (two sides) pixel by pixel until the gradient magnitude does not decrease at x1 and x2 . (c) 1D curves of two gradient profiles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4 Figure 2 .</head><label>42</label><figDesc>Figure 2. Average KL divergences between the fitted gradient profiles and 1 million gradient profiles by varying the shape parameter λ. The optimal λ is near 1.6 on four data sets with different resolutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 Figure 3 .</head><label>43</label><figDesc>Figure 3. Expected sharpness of the gradient profiles in HR image with respect to sharpness of the corresponding profiles in upsampled image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Gradient field transformation. (a) left and middle subfigures illustrate a gradient profile passing through x and x0 in the up-sampled image. The gradient of x is transformed to its HR version (right) by multiplying a ratio r(d(x, x 0 )) . (b) and (c) are an up-sampled image and its gradient field. (d) and (e) are transformed gradient field and reconstructed image by solving poisson equation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>) gives a real example. Figure 4 (c) is the gradient field of the up-sampled image in Figure 4 (b). Figure 4 (d) is the transformed gradient field and Figure 4 (e) is the reconstructed image by solving poisson equations. The recovered image is sharp and with rare ringing artifacts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Figure 5. HR image reconstruction (3X). (a) LR image (nearest neighbor interpolation) and gradient field of its up-sampled image (bicubic interpolation). (b) result of back-projection and it's gradient field, (c) our result and transformed gradient field for HR image. (d) ground truth image and its gradient field. Compared with the gradient field of result by back-projection, the transformed gradient field is much closer to the ground truth gradient field of HR image. Our reconstructed result has rare jaggy or ringing artifacts.</figDesc><graphic coords="5,108.04,396.11,59.11,60.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>sharpened bicubic (d) back-projection (f) our result (g) ground truth (a) input (e) gradient reconstruction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Super-resolution comparison (3X). Gradient reconstruction is obtained by solving poisson equations on the transformed gradient field. Both of gradient reconstruction result (e) and our result (f) contain much less ringing artifacts, especially along the image edges. But our result (f) is closer to the ground truth by enforcing the reconstruction constraint. See text for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Super-resolution comparison (4X) of learning based method<ref type="bibr" target="#b9">[10]</ref>, alpha channel super-resolution<ref type="bibr" target="#b5">[6]</ref>, and our approach. Both large scale edges and small scale details (on the face) are recovered in our result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Figure 5 (a) are input LR image and the gradient field of bicubic upsampled image. Figure 5 (d) are ground truth HR image and its gradient field. Figure 5 (b) are back-projection[14] result using the reconstruction constraint only. Notice the ringing artifacts in both image and gradient field. The bottom image in Figure 5 (c) is our transformed gradient field.As we can see, it is much closer to the ground truth gradient field shown in Figure5 (d). The top image in Figure5 (c) is our final reconstructed HR image using both image and gradient constraints. The ringing artifacts are substantially suppressed by the gradient constraint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9</head><label>9</label><figDesc>Figure 9 and 10 show four examples with up-sampling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Super-resolution results with up-sampling factors of 8 and 16.</figDesc><graphic coords="7,60.00,71.97,475.20,279.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. More super-resolution results with up-sampling factor of 8. The left image is the LR image, and the right image is our result.</figDesc><graphic coords="7,57.24,372.92,222.00,265.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Super-resolution on a noisy image (4X). Noisy LR image is denoised by non-local denoising method<ref type="bibr" target="#b3">[4]</ref>, then the denoised image is up-sampled by the proposed method, and the noises are up-sampled by bilinear interpolation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Super-resolution quality measurement. bicubic back-projection our method test images RMS ERMS RMS ERMS RMS ERMS</figDesc><table><row><cell cols="2">Monarch 16.4 26.0 13.6</cell><cell>21.3</cell><cell>13.2 20.9</cell></row><row><cell>Lena</cell><cell>8.8 11.5 8.2</cell><cell>10.8</cell><cell>7.8 10.1</cell></row><row><cell>Head</cell><cell>8.7 10.9 8.6</cell><cell>10.6</cell><cell>8.4 10.3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that the statistic of shape parameter λ in the up-sampled image may be slightly influenced by the bicubic interpolation. However, we found that the optimal λ value for the up-sampled image is still stable. They are 1.63, 1.68, and 1.69 for the up-sampling factors</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>of 2, 3, and 4 on our data sets.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers and area chairs for helping us to improve this paper. This work is performed when the first author visited Microsoft Research Asia. The first author and Zongben Xu were supported by the National Basic Research program (973 project) of China (No. 2007CB311002).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image up-sampling using total-variation regularization with a new observation model</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dubois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on IP</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1647" to="1659" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Limits on super-resolution and how to break them</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1167" to="1183" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Penrose pixels: Superresolution in the detector layout domain</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ben-Ezra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wilburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Super-resolution through neigbor embedding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Soft edge smoothness prior for alpha channel super resolution</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image upsampling via imposed edge statistics</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="95" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="787" to="794" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Example-based superresolution</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Pasztor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning low-level vision</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pasztor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Carmichael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="47" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Joint map registration and high-resolution image estimation using a sequence of undersampled images</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Armstrong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on IP</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1621" to="1633" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cubic splines for image interpolation and digital filtering</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on SP</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="508" to="517" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Statistics of natural images and models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Motion analysis for image enhancement: Resolution, occlusion and transparency</title>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="324" to="335" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image and depth from a conventional camera and depth from a conventional camera with a coded aperture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<idno>70:1 - 70:9</idno>
	</analytic>
	<monogr>
		<title level="j">ACM transcations on Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Seamless image stitching in the gradient domain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="377" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning how to inpaint from global image statistics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="305" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">New edge-directed interpolation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Orchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on IP</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1521" to="1527" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fundamental limits of reconstructionbased superresolution algorithms under local translation</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Face hallucination: Theory and practice</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="134" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Image magnification using levelset reconstruction</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Morse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schwartzwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="333" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Big little icons</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="24" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fields of experts: A framework for learning image priors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="860" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Steerable random fields</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Extraction of high-resolution frames from video sequences</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. IP</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="996" to="1011" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Image hallucination with primal sketch priors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Perceptually-inspired and edge-directed color image super-resolution</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1948" to="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Exploiting the sparse derivative prior for super-resolution and image demosaicing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Statistical and Computational Theories of Vision</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Image Interpolation and Resampling. Handbook of Medical Imaging, Processing and Analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Thevenaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Parametric generalized gaussian density estimation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Varanasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aazhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1404" to="1415" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Patch based blind image super resolution</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="709" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fingerprints theorems for zero crossings</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Am. A</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="683" to="692" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
