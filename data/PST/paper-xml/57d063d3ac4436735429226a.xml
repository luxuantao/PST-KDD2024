<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deploying Chains of Virtual Network Functions: On the Relation Between Link and Server Usage</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tung-Wei</forename><surname>Kuo</surname></persName>
							<email>twkuo@cs.nccu.edu.tw</email>
						</author>
						<author>
							<persName><roleName>Kate</roleName><forename type="first">Bang-Heng</forename><surname>Liou</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Ching-Ju</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Ming-Jer</forename><surname>Tsai</surname></persName>
							<email>mjtsai@cs.nthu.edu.tw</email>
						</author>
						<author>
							<persName><forename type="first">Tung-Wei</forename><surname>Kuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">T.-W</forename><surname>Kuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M.-J</forename><surname>Tsai</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chengchi University</orgName>
								<address>
									<postCode>11605</postCode>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Tsing Hua University</orgName>
								<address>
									<postCode>30013</postCode>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Phison Electronics Corporation, Inc</orgName>
								<address>
									<postCode>350</postCode>
									<settlement>Jhunan</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chiao Tung University</orgName>
								<address>
									<postCode>300</postCode>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Tsing Hua University</orgName>
								<address>
									<postCode>30013</postCode>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Institute of Communications Engineering</orgName>
								<orgName type="institution">National Tsing Hua University</orgName>
								<address>
									<postCode>30013</postCode>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deploying Chains of Virtual Network Functions: On the Relation Between Link and Server Usage</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0EBFFFE0572E32A7F3C41D6FD4ADFAC3</idno>
					<idno type="DOI">10.1109/TNET.2018.2842798</idno>
					<note type="submission">received March 19, 2017; revised February 2, 2018; accepted May 4, 2018; approved by IEEE/ACM TRANSACTIONS ON NETWORKING</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Network function virtualization</term>
					<term>network function deployment</term>
					<term>routing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, network function virtualization has been proposed to transform from network hardware appliances to software middleboxes. Normally, a demand needs to invoke several virtual network functions (VNFs) following the order determined by the service chain along a routing path. In this paper, we study the joint problem of the VNF placement and path selection to better utilize the network. We discover that the relation between the link and server usage plays a crucial role in the problem. Inspired by stress testing, we first propose a systematic way to elastically tune the link and server usage of each demand based on the network status and properties of demands. In particular, we compute a proper routing path length, and decide, for each VNF in the service chain, whether to use additional server resources or to reuse resources provided by existing servers. We then propose a chain deployment algorithm that follows the guidance of this link and server usage. Via simulations, we show that our design effectively adapts resource allocation to network dynamics and, hence, serves more demands than other heuristics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and NFV, e.g., AT&amp;T and Verizon <ref type="bibr" target="#b3">[4]</ref>. In particular, NFV enables an NF to be executed in virtual machines (VMs) hosted on commodity servers rather than special-purpose hardware <ref type="bibr" target="#b4">[5]</ref>. Such virtualization makes service deployment more flexible and scalable. The efficiency of a network, however, is highly affected by the deployment of these software middleboxes, or called Virtual Network Functions (VNFs), in the network, which is the focus of this work.</p><p>Network traffic usually needs to pass through several VNFs in a particular order. For instance, a flow might go through IDS, which detects suspicious requests, before the proxy server. This phenomenon is known as network function chaining or service chaining <ref type="bibr" target="#b5">[6]</ref>. Since VNFs might be deployed in virtual machines hosted by different physical servers, a service chain should traverse through those physical servers along a path. Hence, supporting service chains requires not only VMs but also link bandwidth, both are limited resources in a network. The problem of allocating resource and orchestrating NFs, i.e., NFV orchestration <ref type="bibr" target="#b6">[7]</ref>, has drawn much attention in recent years, and several NFV platforms, including Open-Stack <ref type="bibr" target="#b7">[8]</ref>, Open Source MANO <ref type="bibr" target="#b8">[9]</ref>, and OPNFV <ref type="bibr" target="#b9">[10]</ref>, also focus on this problem. In this paper, we aim to improve NFV orchestration by cherry-picking the relation between VM usage and link usage. Intuitively, different service chains that demand the same VNF can share the same VM running that VNF if the computational power of the VM is sufficient to support their demands <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. 1 Though such sharing improves VM utilization, it might consume more link bandwidth because these chains may need to go through a longer path in order to reach the shared VM. In this paper, we argue that the interplay between link usage and VM usage plays an important role in NFV orchestration, and we apply the idea to admission control, which has a huge impact on system capacity. Evidently, increasing the capacity of a system is a fundamental issue for many systems, including 5G networks and NFV service providers. Hence, we consider the following question: How should we jointly allocate link capacity and available VMs to service chains so as to maximize the served traffic demands? 2 1 If, for the sake of security or other reasons, it is inappropriate to let different service chains that demand the same VNF, say A, to share a VM that runs VNF A, we will treat VNF A on these service chains as different VNFs, e.g., A 1 , A 2 with A 1 = A 2 , to avoid insecure VM sharing. Throughout this paper, we will assume that the above renaming method has been used to preserve security while enabling VM sharing. 2 Our solution can be easily generalized to maximize the total utility of served demands.</p><p>To see why we should jointly allocate link capacity and available VMs, consider the following examples. When link capacity is very limited and, by contrast, the number of VMs is more than sufficient to support all traffic demands, we should route the demands on the shortest paths and just launch idle VMs along the shortest paths to configure the required VNFs. On the contrary, when links have plentiful capacity but only a few VMs are available, we should, instead, reuse as many VNFs as possible even if a longer path may be required to traverse through those shared VNFs. The above two extreme cases demonstrate that proper link and VM resource allocations are highly correlated with each other and, more importantly, change with the network status. While finding an efficient chain deployment for the aforementioned extreme network status might be simple, this problem is however challenging in general network statuses. This is because the relation between the link resource allocation (in terms of the path length) and the VM resource allocation (in terms of the number of reused VMs), referred to as the LV relation, is unsettled in efficient deployments.</p><p>Unfortunately, in this paper, we show that, finding a feasible resource allocation is NP-hard (Theorem 1). This hardness result makes it more difficult to find a good LV relation. To bypass this difficulty and to find a proper LV relation, we need a way to assess an LV relation without finding a corresponding resource allocation. To this end, we propose a mathematical program to answer the following questions: Q1) How to assess an LV relation for a given demand? Q2) How to efficiently find a proper LV relation for a given demand? Our idea of answering Q1 is inspired by stress testing. Stress testing (sometimes called torture testing) is a form of deliberately intense or thorough testing used to determine the stability of a given system or entity. It involves testing beyond normal operational capacity, often to a breaking point, in order to observe the results <ref type="bibr" target="#b12">[13]</ref>. At a high level, we assess an LV relation by how much stress it can handle, and the best LV relation should be able to handle the highest stress. Specifically, in this paper, higher stress for a system implies more admitted demands in the system, and a breaking point refers to the point where no more demands can be admitted in the system. In this paper, we will perform stress testing under different system configurations (i.e., under different LV relations) to find the best configuration. By the proposed mathematical program, we can efficiently approximate the result of stress testing, and thus, answer Q2.</p><p>After solving the mathematical program to obtain a proper LV relation as guidance, we then design a service chain deployment algorithm by dynamic programming to find a path and VNF placement whose link and VM usage approaches the LV relation obtained by stress testing. The evaluation via simulations demonstrates that our stress-testing-inspired chain deployment outperforms greedy-based and shortest-path-based heuristics. We also test our solution with different LV relations as the guidance for the deployment algorithm. The simulation results show that the deployment following the LV relation obtained by stress testing performs better than those following other LV relations, which reflects the effectiveness of the stress-testing-inspired mathematical program. The following are the contributions of this paper:</p><p>• We define the Joint VNF Placement and Path Selection (JVP) Problem and prove its NP-hardness (Section III). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we discuss research related to virtual network function deployment. For more information, curious readers may refer to the survey by Herrera and Botero on resource allocation in NFV environments, which covers topics broader than virtual network function deployment <ref type="bibr" target="#b13">[14]</ref>. We will also consider research that is not covered in <ref type="bibr" target="#b13">[14]</ref> but is closely related to ours. More importantly, we use a taxonomy different from the one in <ref type="bibr" target="#b13">[14]</ref> to better understand the difference between our work and others. Basically, all the research on virtual network function deployment considers a set of demands (service chains) as inputs and allocates resource to these demands. Most research relies on Mixed Integer Linear Program (MILP) to solve the problem as it is usually NP-hard to find a feasible solution. Some of the research proposes heuristics to solve the MILP. We categorize the related work into two groups based on the objective. The first is to serve all the input demands (service chains) and to minimize a certain cost function, e.g., Capital Expenditures (CAPEX), link utilization, server utilization, or some combination of the above. By minimizing the cost function, the hope is to allocate resource efficiently. The second is admission control, in which serving all the demands is extremely difficult, if not impossible. Hence, the goal becomes to maximize the admitted demands. Our work falls into the second category.</p><p>There is a substantial volume of research in the first group <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b32">[33]</ref>. As described above, these works try to optimize some objective function subject to the constraints that all input demands are served. However, feasible solutions that can serve all the demands may not exist. Hence, these solutions are best suitable for the case where feasible resource allocation is guaranteed to exist in advance. Moreover, as efficient resource allocation is found by means of optimizing the objective function, it is critical to consider the link utilization and server utilization jointly as a single objective function. However, it is unclear how to capture the interplay between server utilization and link utilization in the objective function. Hence, some works simply consider link utilization alone <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> or server utilization alone <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b31">[32]</ref> in the objective function. While some works indeed consider both link utilization and server utilization <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b32">[33]</ref>, the objective function is simply a weighted sum of link utilization and server utilization, or the maximum between link utilization and server utilization (link utilization and server utilization have equal weights). In these works, the weights are either fixed or are leaved for the system operator to decide. As we have stated in Section I, the relation between link and server usage varies with the system status. Hence, the selection of weights should be adapted to the system status. Unlike these works, our work directly resolves the LV relation, which may provide some guidance to the weight selection.</p><p>The works in the second group then focus on admission control, where the goal is to maximize the served demands <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b41">[42]</ref>. The work by Lukovszki and Schmid <ref type="bibr" target="#b33">[34]</ref> and the work by Mijumbi et al. <ref type="bibr" target="#b34">[35]</ref>, however, do not consider link bandwidth constraint in resource allocation. Other works then consider both server capacity constraints and link capacity constraints at the same time <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b35">[36]</ref>- <ref type="bibr" target="#b41">[42]</ref>. The major difference between the problem studied in our work and these works is that in these works, the resource in a physical server can be partitioned arbitrarily so that each part fits the demand (virtual network function) perfectly. On the other hand, we consider networks in which physical servers are partitioned into VM slots in advance, which is a common setting in data center networks, and much research also adopts such an environment, e.g., <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b42">[43]</ref>. In this kind of environment, we do not directly allocate resources like CPUs and RAMs to a VNF. Instead, we allocate VM slots to a VNF, and one VM slot is only allocated to one VNF. Details of the settings can be found in Section III. Considering VM slots makes the LV relation even more complicated. This is because one more constraint is now associated with server utilization in such an environment. That is, the number of VM slots in a server is limited. This additional constraint explicitly poses an upper bound on the number of VNFs deployed in a server. In this paper, we will consider networks with such predetermined VM slots, which is common in data center networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. JOINT VNF PLACEMENT AND PATH SELECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Definition</head><p>We model a network as an edge-weighted vertex-weighted directed graph G = (V, E), in which V is the set of physical nodes in the network, e.g., switches and servers. c e is the link capacity of edge (link) e ∈ E and c v is the number of virtual machines (VMs) that can be hosted on physical node v ∈ V . In this paper, we assume that the bandwidth between VMs on the same server is large enough to support the highest possible amount of traffic among VMs on the same server. We collect all the VMs hosted on different servers as a set M . Each VM m ∈ M has a limited computational capability c m , which can be specified by system operators or measured in real systems. For example, c m can be measured by the supportable number of instructions per second (IPS) bounded by memory or CPU resources of VM m. Say the system supports a set of VNFs F . We assume that each VM m can run at most one VNF f ∈ F , while different VMs might support the same VNF. For example, by default, a VM in Google Cloud Platform hosts one application <ref type="bibr" target="#b43">[44]</ref>. Moreover, some experiments also indicate that the performance drops when a VM hosts multiple NFs <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. Finally, several NFV platforms, including OpenStack, Open Source MANO, and OPNFV, assume that each NF is a monolithic VM <ref type="bibr" target="#b46">[47]</ref>. Let v(m) and f (m) be the server hosting VM m and the VNF deployed in m, respectively.</p><p>Say we are given a set of demands D = {d 1 , d 2 , • • • }. Let o i ∈ V and t i ∈ V represent the source and destination vertex of d i , respectively. Each demand d i ∈ D requests for going through a chain of services S i = (s i,1 , s i,2 , • • • ), and we define |S i | as the length of the service chain S i . Each demand d i has a traffic rate R i (bytes/second), and each s i,j (the j th service request of demand d i ) consumes a VM's computational load L(s i,j ) (e.g., IPS). To obtain the traffic rate and the computational load, we can first admit the demand temporarily, and then obtain the required information by some monitoring services. Most cloud services now include monitoring APIs, and the design of monitoring systems is left outside the scope of this paper. We similarly use the notation f (s i,j ) to denote the VNF requested by s i,j , and assume that a demand can request the same VNF more than once in the chain. That is, f (s i,j ) could be the same with f (s i,j ) for any j and j . We further assume that each s ∈ S i can only be served by a single VM. However, to better utilize resources, we allow different service requests to share a single VM if its computational capability c m is sufficient <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>.</p><p>Given a set of demands, this paper investigates the Joint VNF Placement and Path Selection (JVP) Problem, which jointly determines the solutions of the following problems: 1) Path selection and admission control (p i ): For each accepted demand d i , we have to find a routing path p i for it. Otherwise, we set p i = ∅ if d i is rejected. 2) VNF assignment and placement (m(s i,j ), I(s i,j ), f (m)):</p><p>If a demand d i is accepted, we have to assign each service request s i,j ∈ S i to a VM hosted on a certain vertex (server) along the selected path p i . To formally express this assignment, we let m(s i,j ) denote the VM to which s i,j is assigned. We further define VNF placement as I(s i,j ), which indicates the index of the physical server in path p i that hosts the VM m(s i,j ). In particular, if s i,j is assigned to a VM m hosted by the k th vertex along path p i , then we define m(s i,j ) = m and I(s i,j ) = k.</p><p>In addition, this implies that we should place the requested VNF f (s i,j ) on VM m, i.e., f (m) = f (s i,j ). JVP's goal is to maximize the sum rate of the admitted demands, i.e., max di:pi =∅ R i . In this paper, we also consider the objective function of maximizing the total utility of the admitted demands, i.e., max di:pi =∅ U i , where U i is the utility associated with demand d i . We have the following constraints.</p><p>Path Constraint: If demand d i is accepted, then p i is a path connecting from o i to t i .</p><p>Link Capacity Constraint: The selected routing path p i should carry a flow of rate R i , and all flows in the network need to satisfy the capacity constraint of each link. Since S i might be deployed on a path with loops (e.g., a path traversing through several VMs hosted on the same server), we should consider the total link bandwidth consumed by the path. That is, di∈D δ e (p i )R i ≤ c e , ∀e ∈ E, where δ e (p i ) is the number of times that the path p i traverses through link e.</p><p>VNF Placement Constraint: Each VM can at most support one VNF, but can be shared by multiple demands. This means that, if multiple services are assigned to the same VM, those services must request the same VNF. Namely, if m(s i,j ) = m(s i ,j ), then f (s i,j ) = f (s i ,j ), ∀i, i , j, j .</p><p>VM Capacity Constraint: Each VM m can only support a number of demands, limited by its computational capability. More specifically, si,j :m(si,j )=m L(s i,j ) ≤ c m , ∀m ∈ M . Chaining Constraint: The path p i of an accepted demand d i must be able to traverse through VNFs following the order specified in S i , i.e., I(s i,j ) ≤ I(s i,j ), ∀s i,j , s i,j ∈ S i , j &lt; j .</p><p>JVP is an extremely difficult problem. In fact, even finding a non-trivial feasible solution of JVP for a single demand is NP-hard. To see this, we first introduce an NP-hard problem, called the edge-disjoint path (EDP) problem <ref type="bibr" target="#b47">[48]</ref>. Given a directed graph and two pairs of vertices (o 1 , t 1 ) and (o 2 , t 2 ), the EDP problem asks to connect these two pairs from o i to t i via edge-disjoint paths. We then reduce the NP-hard EDP problem to our JVP problem. In particular, given the graph G in the EDP problem, we construct the graph G in the JVP problem as follows. Initially, G = G. We then add a node r, which hosts the only VM in G , and add two directed edges (t 1 , r) and (r, o 2 ) in G . All the edges in G have a link capacity R. The only demand d originates from o 1 and terminates at t 2 with a demanding rate R, and only requests a single VNF service. It is then easy to see that the EDP problem has a feasible solution if, and only if, the JVP problem has a feasible solution with an objective value greater than 0. We then have the following theorem.</p><p>Theorem 1: It is NP-hard to find a feasible solution, whose objective value is greater than 0, of the JVP problem. Thus, if P = N P , then there is no polynomial time approximation algorithm for the JVP problem with bounded ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. An Overview of Our Solution</head><p>Since it is difficult to find the solution for all the demands as a whole, we, instead, consider each demand sequentially, and decide whether and how to serve it. Therefore, as considering a demand d i , some link/VM resources might have been allocated to some other demands d i , i &lt; i. A side benefit of such sequential deployment is that this is especially suitable for solving the online version of the JVP problem, where demands may arrive at different times.</p><p>Intuitively, deploying a chain on a shorter path consumes less link bandwidth, but might also reduce VM reuse opportunities. On the contrary, reusing more VMs might lead to a longer path, which consumes more link bandwidth. Hence, there exists a dilemma of saving more link bandwidth or reusing more VMs. We refer to the number of services in S i that reuse existing VMs as the reuse factor. To allocate resource for a demand d i , we first find a proper path length and a proper reuse factor for d i by a mathematical program that simulates stress testing. The proper path length and the proper reuse factor then form an LV relation guide. We then design a usage-guided deployment algorithm to find a routing path and VNF assignment whose resource consumption approaches the LV relation guide.</p><p>The Roadmap of Our Solution (Fig. <ref type="figure" target="#fig_0">1</ref>):</p><p>1) Sort the demands. We first apply the mathematical program to each demand on the initial network. We then use the output of the mathematical program to sort the demands (Section IV-C). Note that, for the online version of our problem, we do not sort the demands, and we process each demand immediately once it arrives. We first find an incomplete resource allocation that jointly optimizes the path length and reuse factor. This is achieved by integrating a greedy heuristic and a dynamic program (Section V-A). So far, the path may not reach the destination yet, and some trailing services in the service chain may still not be assigned to VMs. We then complete the resource allocation by assigning these trailing services to empty VMs and extend the routing path to the destination. If the path length exceeds that in the LV relation guide, we reject the demand (Section V-B). Finally, we increase the reuse factor (Section V-C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OBTAINING THE LV RELATION GUIDE BY STRESS TESTING</head><p>In this section, the goal is to find a proper path length and a proper reuse factor for a given demand d i , i.e., the LV relation guide for d i . Obviously, the LV relation guide should adapt to the current network status. Since the path length is closely related to the reuse factor x, we will further define a proper path length l(x) as a function of a given reuse factor x. As mentioned in Section I, we find the LV relation guide by answering Q1 and Q2 with the help of stress testing. In this section, we first answer Q1 formally by stress testing.</p><p>Next, we answer Q2 by a mathematical program that can approximate the result of stress testing efficiently. We then discuss the design of function l(x). Finally, we show how to sort the demands and refine the LV relation guide in Sections IV-C and IV-D, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Solving Q1 by Stress Testing</head><p>Because the path length is modeled as a function of reuse factor, we only need to focus on assessing a reuse factor. Intuitively, if x is an efficient reuse factor for demand d, then we should be able to solve the JVP problem optimally by letting d reuse x VMs. However, assessing a reuse factor by this idea is almost as difficult as the JVP problem. Hence, we approximate the best reuse factor for d. Specifically, we consider a stress testing system whose initial status is identical to the current network status. The stress is generated by introducing an excessive number of demands. These introduced demands are all identical to d and all use the same reuse factor. In other words, we treat the reuse factor as a system-wide configuration to simplify the problem and amplify the impact of the choice for the reuse factor. We are interested in the result of the above stress test, i.e., the maximum number of demands that can be admitted in the above system. The desired reuse factor is the one that yields the best result. To get the result of the above stress test, we ask the following question: if there exist an infinite number of identical demands d, each assigned the same reuse factor x, then what is the maximum number of demands that can be served in the system?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Approximating the Result of Stress Testing by a Mathematical Program</head><p>In fact, the above problem is still NP-hard (since finding a feasible resource allocation is NP-hard). <ref type="foot" target="#foot_0">3</ref> Therefore, we design a method to solve this problem without really deploying demands. Intuitively, the total link capacity imposes an upper bound of the solution. Similarly, the number of VMs in the system also imposes an upper bound. The high-level idea of the following mathematical problem is then to model these two upper bounds and to find the smaller one between these two bounds.</p><formula xml:id="formula_0">maximize n subject to n • R i • l(x) ≤ C l (1a) (ST ) n • (|S i | -x) ≤ C em (1b) x ∈ {0, 1, 2, • • • , x}<label>(1c)</label></formula><p>In ST , given a reuse factor x for each served demand, we try to find the approximate maximum number of demands n that can be served in the system. Specifically, the system is modeled as a residual graph G , which is obtained from G by excluding links with remaining capacity less than R i and then deleting all the vertices that o i cannot reach. This approximate result n is obtained by considering two resource constraints. Eq. (1a) restricts that the total bandwidth resources used by the served demands cannot exceed C l , the total remaining link capacity of G . Then, Eq. (1b) ensures that the number of empty VMs assigned to the served demands is no larger than C em , the number of empty VMs in G . Eq. (1c) gives the search range of x. Intuitively, the upper bound of the reuse factor can be set to x = |S i |. This is, however, an overestimate because some service requests might never find a reusable VM. Hence, we define S i as the set of services that have reuse opportunities. Specifically, we set S i = S i initially, and remove any s i,j from S i if there exists no reusable VM that runs VNF f (s i,j ) and is reachable from o i . The upper bound can then be tightly set to x = |S i |. Since there are only (x + 1) possible values of x, we can solve n with respect to each possible x, and find the optimal x in ST , denoted as x * . Hence, x * is the best reuse factor obtained by approximating the result of stress testing. x * and l(x * ) then define the LV relation guide and will be used as guidance for the deployment algorithm in Section V.</p><p>Relating x With l(x): While ST is easy to solve, a difficult problem remains unsolved: how to estimate the relation between l(x) and x? We start by giving a high-level intuition of how we estimate l(x) for any given x, and then describe the detailed derivation. If a service chain is deployed on a path reusing x existing VMs, the path can be partitioned into (x + 1) sub-paths. To save link bandwidth, ideally, we should pick the shortest path in G as the sub-path to connect any two consecutive reused VMs (or o i and t i ). However, since the rest of services that are not served by any reusable VM can only be deployed in empty VMs, the servers along the shortest sub-paths might not have sufficient empty VMs to support those services. Hence, we might extend the shortest sub-paths to locate more empty VMs, and should further consider additional link resources required for this detour. The above intuition can be expressed as follows:</p><formula xml:id="formula_1">l(x)= |π oi,ti | + l Δ [|S i | -n e,oi,ti ] + , x= 0 (x + 1)l r + l Δ [|S i |-x-(x+1)n e ] + , x &gt; 0,<label>(2)</label></formula><p>where |π oi,ti | is the length of the shortest path π oi,ti from o i to t i on G , l Δ is the average distance between any two empty/reusable VMs, where one must be empty, n e,oi,ti is the number of empty VMs on π oi,ti , l r is the average distance between any two reusable VMs (here o i and t i are also deemed as reusable VMs), n e is the average number of empty VMs between any two reusable VMs, and [•] + max(•, 0). We discuss our derivation in two cases: x = 0 and x &gt; 0. In both cases, the first term in Eq. ( <ref type="formula" target="#formula_1">2</ref>) is the total (estimated) length of the x + 1 shortest sub-paths, and the second term is the total number of extra links used to extend the sub-paths for reaching empty VMs. When no VM is reused (x = 0), it is easy to estimate l(x) since we can find the shortest path π oi,ti and count the number of available empty VMs n e,oi,ti . However, when x &gt; 0, we do not explicitly know which VMs are reused before deployment, and can only estimate the average shortest distance, l r , and the average number of empty VMs, n e , between two reusable VMs.</p><p>To finalize our derivation, it is then sufficient to estimate l r and n e . To do so, we generate</p><formula xml:id="formula_2">|S i | vertex sets, U j , 1 ≤ j ≤ |S i |</formula><p>, each of which collects all the vertices (servers) that host reusable VMs serving VNF f (s i,j ). That is,</p><formula xml:id="formula_3">U j = {v(m) : m ∈ M, f (m) = f (s i,j ), L(s i,j ) ≤ c m }.</formula><p>Recall that S i is obtained from excluding the services that cannot find any reusable VM from S i , so U j must be nonempty. We further introduce U 0 = {o i } and</p><formula xml:id="formula_4">U |S i |+1 = {t i }.</formula><p>To meet the chaining constraint, a feasible path for d i needs to go through any vertex in U j in an ascending order of j. For ease of description, we define, for each j, a set</p><formula xml:id="formula_5">P j = {(v, v ) : v ∈ U j , v ∈ U j+1 , π v,v = ∅} to</formula><p>include any pairs of reachable vertices, one in U j and the other in U j+1 . By reachable, we mean that there exist a path from v to v on G . Then, the average distance between any two reusable VMs, l r , can be estimated by the average length of the shortest paths</p><formula xml:id="formula_6">π v,v between (v, v ) ∈ P j , ∀0 ≤ j ≤ |S i |. l r = 1 |S i | + 1 0≤j≤|S i | (v,v )∈Pj |π v,v | |P j | . (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>Likewise, we have</p><formula xml:id="formula_8">n e = 1 |S i | + 1 0≤j≤|S i | (v,v )∈Pj n e,v,v |P j | , (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>where n e,v,v is the number of empty VMs on π v,v .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Sorting Demands According to the Result of Stress Testing</head><p>Recall that, to solve the JVP problem, we sequentially process each demand</p><formula xml:id="formula_10">d i , i = 1, • • • , |D|.</formula><p>The performance of such sequential deployment closely depends on the order of the demands that are processed. Intuitively, to increase the total size of the admitted demands, we would like to process beneficial demands first. Hence, we sort the demands in the descending order of n * i R i , where n * i is the optimal n outputted by ST for demand d i on the initial network, and then consider each demand in order. The rationale behind this sorting is that a larger n * i implies that the demand d i requires fewer resources and a higher R i results in a higher performance improvement. Similarly, if the goal is to maximize the total utility of admitted demands, then we sort the demands in the descending order of n * i U i , where U i is the utility associated with demand d i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Refining the LV Relation Guide</head><p>ST attempts to find an LV relation guide that enables us to accept as many demands as possible. However, in reality, we may not have so many demands in total, and, as a result, the resources could eventually be underutilized. As we will see in the next section, we reject a demand when we cannot find a resource allocation that follows the LV relation guide. Thus, conservative LV relation guides may lead to unnecessary rejections. To avoid conservative LV relation guides, our intuition is that we should not waste the system resource. In other words, the total LV relation guide of all demands should fully utilize the total resource. Therefore, we scale up the path length guide of every demand (by multiplying the path length guide by a factor, SF ) so that the resulting total link consumption guide of all demands (i.e., di∈D R i (SF •l(x * i )), where l(x * i ) is the path length guide of demand d i outputted by ST ) equals the total link capacity of the system (i.e., e∈G c e ). Moreover, we do not want to reduce the path length guide after scaling. Thus, SF cannot be less than one. SF is called the stretch factor, and can be determined by the following equation. 4</p><formula xml:id="formula_11">SF = max ( e∈G c e di∈D R i • l(x * i ) , 1)<label>(5)</label></formula><p>Let</p><formula xml:id="formula_12">l * i = SF • l(x * i )</formula><p>be the new path length guide for demand d i . For the online problem, because we cannot compute the total link consumption guide of all demands, we set l * i = l(x * i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. THE USAGE-GUIDED DEPLOYMENT ALGORITHM</head><p>Given a demand d i and its LV relation guide (l * i , x * i ), the goal of our usage-guided deployment algorithm is to find a path and VNF assignment such that the selected path can reuse approximately x * i VMs and has a length close to l * i . If no such path exists, we reject d i . A naive way to find such a solution is to examine all the possible paths and assignments. This is however extremely computationally expensive, and can hardly be realized in practice. Hence, we, instead, incrementally find sub-paths that most efficiently reuse existing VMs under the given path length constraint, l * i , and concatenate those subpaths as the routing path (see Section V-A). If the resulting assignments cannot serve all the requested services in S i or the path has not reached the destination yet, we next find the last sub-path to complete the whole path and assignments (see Section V-B). Finally, if the resulting deployment still underutilizes the specified reuse factor x * i , we adjust the path and assignments so as to improve the reuse factor (see Section V-C). Note that, since we cannot use links with capacity less than R i , the following algorithms operate on the residual graph G , which is a subgraph of G. Specifically, whenever the routing path is extended or VNF assignments are updated, the remaining resources on G are updated accordingly and links with insufficient capacity are removed from G .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Finding Effective Sub-Paths Using Dynamic Programming</head><p>To deploy a demand d i , we find a shortest sub-path connecting from source o i to an intermediate vertex v, and iteratively find the next shortest sub-path from v to extend the path. Algorithm 1 shows the pseudo-code. Let pi,k denote the sub-path found in the k th iteration, and let p i,k denote the merged path until the k th iteration, namely 4 SF can be updated periodically (e.g., whenever ten more demands are processed by the deployment algorithm) by updating the total remaining link capacity in the numerator and the total link consumption guide of all demands that have not been processed by the deployment algorithm in the denominator.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Path-Extension</head><formula xml:id="formula_13">1 v 0 ← o i 2 p i,0 ← ∅, m(s i,j ) ← ∅, ∀s i,j ∈ S i //</formula><formula xml:id="formula_14">p ← p i,k-1 + π v k-1 ,v 7 if |p i,k-1 | + |π v k-1 ,v ,ti | &gt; l * i then</formula><formula xml:id="formula_15">v 0 = o i . Thus, pi,k = π v k-1 ,v k , where π v k-1 ,v k is the shortest path from v k-1 to v k on G .</formula><p>The high-level idea of our sub-path selection is to incrementally maximize the reuse factor under the path length constraint. Therefore, a preferred sub-path should possess the following two properties. First (Property A), since the final path length cannot exceed l * i , we need to ensure</p><formula xml:id="formula_16">|p i,k-1 | + |π v k-1 ,v k ,ti | ≤ l * i for all k, where π v k-1 ,v k ,ti is the concatenation of π v k-1 ,v k</formula><p>and the shortest path π v k ,ti that can support a flow of rate R i from v k to t i after subtracting the link resources occupied by π v k-1 ,v k (Line 7). The shortest path π v k ,ti is a conservative estimate to ensure that some path can connect v k to the destination. Second (Property B), a newly-added sub-path pi,k should improve the reuse factor, i.e., r(p i,k ) &gt; r(p i,k-1 ), where r(p) is the maximum number of services in S i that can be assigned to reusable VMs on path p (Line 9).</p><p>Following the above two properties, we iteratively merge the sub-paths, and terminate until no such sub-path can be found (Line 14). To find the most effective sub-path in iteration k, we try to optimize the reuse factor and the path length simultaneously. Hence, among all the possible intermediate vertices satisfying the two properties (Line 10), we extend the path to the one that maximizes</p><formula xml:id="formula_17">r(p i,k ) |p i,k | (Line 13).</formula><p>The remaining task is to calculate r(p i,k ). Note that the merged path p i,k in iteration k is only an incomplete path. Hence, we do not need to assign all the service requests in S i on path p i,k , but just need to assign a service sub-chain on p i,k . There are only |S i | + 1 possible service sub-chains, i.e., ∅, (s i,1 ), (s i,1 , s i,2 ), • • • , S i . To find r(p i,k ), we can simply try to deploy each possible sub-chain on p i,k , and check which sub-chain gives the maximum reuse factor on p i,k . This maximal reuse factor is then r(p i,k ). In particular, we should solve the following Single Demand Fixed Path Virtual Network Function Placement (SVP) problem: Given a demand d with source o, destination t, a service sub-chain S and a routing path p connecting o and t, find an assignment m(s j ) for each s j ∈ S on the given path p such that the reuse factor is maximized. We let SVP(p, S) represent an SVP problem instance of assigning S to VMs on path p. We further denote m * (p, S) = {m(s) : s ∈ S} as the solution of all the assignments, and set it to m * (p, S) = ∅ if there exists no feasible assignment.</p><p>We use dynamic programming to solve the SVP problem when the path has no loop. <ref type="bibr">Intuitively</ref> ) is infeasible. We can then use dynamic programming to solve the SVP problem for all the possible chain breaking indexes h, and output the solution that achieves the maximal reuse factor. Specifically, the dynamic program can be written as:</p><formula xml:id="formula_18">m * (p, S) = arg max m h :0≤h≤|S| r(m h ), where m h = ⎧ ⎪ ⎨ ⎪ ⎩ m * (p-(v |p| ), S), h = |S| m * ((v |p| ), S), h = 0 m * (p-(v |p| ), S h )⊕m * ((v |p| ), S h ), 0 &lt; h &lt; |S| (6)</formula><p>and r(m h ) is the reuse factor of the solution m h for SVP(p, S) and is set to -1 if m h is infeasible. Then, r(p i,k ) can be found by solving</p><formula xml:id="formula_19">S * = a r gm a x S∈{∅,(si,1),(si,1,si,2),••• ,Si} r(m * (p i,k , S)),<label>(7)</label></formula><p>and we get r(p i,k ) = r(m * (p i,k , S * )). Claim 1: Eq. ( <ref type="formula">6</ref>) is correct.</p><p>Proof: Please refer to the appendix. Two things are worth noting. First, any SVP problem on a single-vertex path is a base case of dynamic programming, which is easy to solve. In particular, to solve SVP((v), S), we can assign as many services in S as possible to the reusable VMs in v, and then assign the rest of services to as few empty VMs in v as possible. If all the services in S are assigned to VMs in v, we return the above assignments as m * ((v), S). Otherwise, the instance is infeasible, and we return m * ((v), S) = ∅. The solutions of those base cases can then be recursively combined to find the solution of any sub-instance in Eq. ( <ref type="formula">6</ref>). Second, a path with loops is allowed. Therefore, for a path p, if the last vertex v |p| is the same with some vertices in p-(v |p| ), the two sub-instances SVP(p-(v |p| ), S h ) and SVP((v |p| ), S h ) cannot be solved independently. Otherwise, the capacity of a VM might be over-provisioned to different services in the two sub-instances. To avoid this issue, we first solve SVP(p-(v |p| ), S h ), update the remaining VM resources based on its assignments, and then solve SVP((v |p| ), S h ) on the residual graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Making the Deployment Feasible</head><p>After executing Algorithm 1, we may still not be able to serve all the services in S i and reach the destination. In fact, only the services in S * solved in Eq. ( <ref type="formula" target="#formula_19">7</ref>) are assigned to VMs. Hence, we further propose an algorithm to locate empty VMs for those unserved services in S i (i.e.,</p><formula xml:id="formula_20">s i,|S * |+1 , s i,|S * |+2 , • • • , s i,|Si|</formula><p>), and find a bridging path p b between v k and t i to link these empty VMs, where v k is the last vertex of the path obtained by Algorithm 1, and t i is destination of demand d i . Algorithm 2 shows the pseudocode. Our goal is to minimize the length of p b . Initially, p b only contains v k (Line 1). We then deploy the first unserved service s ∈ S i on an empty VM m such that d 1 (m) = |π vL,v(m),ti | is minimized, where v L is the last vertex on p b , and v(m) is the server hosting m (Line 6). If several such VMs can be found, we choose the one that minimizes d 2 (m) = |π vL,v(m) | (Line 6). Let m * and v * be the chosen VM and the server hosting the chosen VM, respectively (Line 7). p b is thus extended to v * by |π vL,v * | (Line 12). We then set v L to v * , update the remaining resources, and remove links with insufficient capacity from G (Lines 13-14). The above procedure is repeated until the service chain is fully served or no empty VM can be reached, which leads to rejection of d i (Line 10). If the service chain is fully served, p b is then extended to t i by π vL,ti (Line 15), and the path for d i , p i , will be the concatenation of p i,k (obtained by Algorithm 1) and p b (Line 16). If |p i | exceeds the specified length l * i , we reject d i (Line 18).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Increasing the Reuse Factor</head><p>So far, the reuse factor might be less than x * i . To better reuse the VMs, for a service that has a reusable VM but is assigned to an empty VM, we can reassign it to a reusable VM and adjust the path accordingly. However, we should ensure that, after path adjustment, the path length is still no longer than l * i . Algorithm 3 shows the pseudo-code. The path adjustment is straightforward. Assume that we want to reassign a service s i,j to a reusable VM m. Then, the sub-path of p i from v(m(s i,j-1 )) to v(m(s i,j+1 )), denoted by pold (s i,j ), is replaced with the subpath π v(m(si,j-1)),v(m),v(m(si,j+1)) , denoted by pnew (s i,j , m). In addition, we want to keep the path as short as possible. Hence, we choose the service s and the reusable VM m for s such that Δ(s, m) = |p new (s, m)| -|p old (s)| is minimized. Let s * and m * be the chosen service and the chosen reusable VM, respectively (Line 7). We then reassign s * to the reusable VM m * by the above method (Lines 10-11). This process is performed repeatedly (Line 1) until all possible reassignments result in Algorithm 2 Bridging if the reuse factor = x * i then return p i , m(s i,j ), ∀s i,j ∈ S i overlong paths (Line 9) or the reuse factor equals the specified usage (Line 13).</p><formula xml:id="formula_21">1 p b ← v k , v L ← v k 2 for h←|S * | + 1 to |S i | do 3 // find an empty VM for s i,h 4 d min 1 ← ∞, d min 2 ← ∞ 5 forall the empty VM m do 6 if d 1 (m) &lt; d min 1 or (d 1 (m) = d min 1 and d 2 (m) &lt; d min 2 ) then 7 m * ← m, v * ← v(m) 8 d min 1 ← d 1 (m), d min 2 ← d 2 (m) 9 if d min 1 = ∞ then 10 Reject d i 11 return 12 m(s i,h ) ← m * , p b ← p b + π vL,v * 13 v L ← v *</formula><p>Implication of Theorem 1: A different approach to find the desired path and assignment is the following: iterate all the VNF assignments and find the corresponding desired path. Consider a simple example where the service chain only has one VNF, and the desired path length is large enough so that the path can be arbitrarily long. Moreover, assume that only one VM v in the current network hosts the VNF requested by the demand, and that the desired reuse factor is one. The proof of Theorem 1 actually implies that finding a feasible path visiting v for the demand is NP-hard. The intuition is that the path P 1 connecting the source to v and the path P 2 connecting v to the destination may use the same link. Hence, we cannot find P 1 and P 2 separately because the resulting flow may exceed some link capacity. Due to the hardness of the problem, to the best of our knowledge, we still need to iterate all possible paths to realize this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. NUMERICAL RESULTS</head><p>We conduct simulations to evaluate the performance of our design in three data center networks, Fat-tree <ref type="bibr" target="#b48">[49]</ref>, VL2 <ref type="bibr" target="#b49">[50]</ref>, and BCube <ref type="bibr" target="#b50">[51]</ref>, and one inter-data-center network, the network of Cogent, which is a real tier 1 Internet service provider <ref type="bibr" target="#b51">[52]</ref>. For each of the three data center networks, we generate 128 servers, each of which is connected to some edge switches. The number of switches may vary in different topologies of data centers. Each server and switch is represented as a vertex in the graph G, and we set the link capacity c e to 1 Gbps for each link in G. The vertex capability c v is set to 4 if v is a server, while is set to 0 if v is a switch. Cogent's network topology contains almost 190 access nodes with about 260 links and 40 Cogent data centers. Each access node and data center is represented by a vertex in the graph G. The capacity of each link is set to 10 Gbps, and c v = 100 if v is a data center and c v = 0, otherwise.</p><p>We assume that the capability of each VM is limited by its CPU power. The CPU of each VM is capable of executing 10 10 instructions per second, i.e., 10 4 MIPS <ref type="bibr" target="#b52">[53]</ref>. To generate the service chain of each demand, we first generate a set of VNFs F , which contains 30 distinct VNFs. We define the computational load of running a VNF f ∈ F with an input traffic rate R as L(f, R) (IPS). For each f ∈ F , we set L(f, R) = 10R and L(f, R) = 10R ln(R) with probabilities 90% and 10%, respectively. Then, L(s i,j ) is set to L(f (s i,j ), R i ). Each service chain S i is constructed by sequentially and uniformly randomly selecting VNFs from F . The length of a service chain is uniformly randomly chosen from 1 to 8. The rate of each demand R i follows the power law distribution <ref type="bibr" target="#b53">[54]</ref>, whose probability density function is</p><formula xml:id="formula_22">P [X = x] = Cx -α x ≥ x min 0 x &lt; x min ,</formula><p>where C = (α -1)x α-1 min , and x min is the minimum demand size. Like <ref type="bibr" target="#b53">[54]</ref>, we set α = 2.1. Unless stated otherwise, we use power law to generate 2000 demands with x min = 10 Mbps and 4000 demands with x min = 100 Mbps for the three data center center networks and the network of Cogent, respectively. The source and destination of each demand are chosen uniformly randomly from the vertices in the network.</p><p>We compare our design with the following heuristics.</p><p>• Shortest Path Heuristic (SPH): It deploys a demand along the shortest path between the source and the destination π oi,ti , and uses our dynamic programming, i.e., Eq. ( <ref type="formula">6</ref>), to solve SVP(π oi,ti , S i ) and assign services to VMs on π oi,ti . • Greedy on VM Reuse (GVR): It extends the routing path of d i iteratively on G and assigns each service s i,j ∈ S in order. s i,j is assigned to a reusable VM if possible; otherwise, it is assigned to an empty VM. Moreover, the selected reusable (empty) VM is the one closest to the VM serving its previous service, i.e., m(s i,j-1 ). Then, the final path is</p><formula xml:id="formula_23">(o i , v(m(s i,1 )), v(m(s i,2 )), • • • , v(m(s i,|Si| )), t i ). • Shortened Greedy Heuristic (SGH):</formula><p>The idea of SGH is similar to GVR, but SGH might use a shorter path. It also extends the routing path iteratively from the source to the destination. In the k th iteration, it finds the first unserved service that can be served by a reusable VM, say s i,j , and assigns it to the closest reusable VM m. Let v k denote the intermediate server that hosts m selected in iteration k, i.e., v k = v(m) and v 0 = o i . Then, we find the shortest sub-path π v k-1 ,v k on G , and assign each of the unserved services before s i,j , in order, to the first empty VM on π v k-1 ,v k . For all the comparison schemes, we also deploy demands sequentially, and sort the demands in the descending order of n * i R i . When the problem is to maximize the total utility of admitted demands, we sort the demands in the descending order of n * i U i , where U i is the utility associated with demand d i . A demand is rejected if the scheme cannot output a feasible solution for it. Like our solution, whenever the deployment is updated, these schemes also update the residual graph G accordingly. For each simulation, we output the average result of 10 different instances.</p><p>Impact of the Length of Service Chains: We first check how the comparison schemes adapt to different lengths of service chains. We test four ranges of lengths, <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, and <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. Specifically, we consider four types of demands D, and all the demands d i in the n th type of D have</p><formula xml:id="formula_24">|S i | ∈ [2n - 1, 2n].</formula><p>The results are shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Since a longer chain consumes more resources, the total size of accepted demands decreases as the length of the service chains increases. SPH performs worst in the three data center networks. This is because, in this simulation, the total rate of demands is relatively small, as compared to the link capacity, and, thus, the VM usage is more critical than the link usage. In the IEEE/ACM TRANSACTIONS ON NETWORKING  network of Cogent, because all the demands are large, SPH performs well by taking the shortest path to utilize the precious communication resource efficiently. Our solution outperforms all the heuristics, especially for the more challenging cases, i.e., demands with longer service chains. The gain comes from our ability of striking a balance between the reuse factor and the path length derived from ST . Also, we use dynamic programming to maximize the reuse factor of a path, and most efficiently utilize the VMs given the guide of link usage.</p><p>Impact of the Minimum Demand Size: We further check the performance of the comparison schemes as the minimum demand size, x min , varies from 1 Mbps to 128 Mbps and from 100 Mbps to 600 Mbps for the three data center networks and the network of Cogent, respectively. Fig. <ref type="figure" target="#fig_3">3</ref> plots the total size of the served demands. For the three data center networks, when the minimum demand size is small, SPH has the worst performance due to a reason similar to that in Fig. <ref type="figure" target="#fig_1">2</ref>. However, when the minimum demand size is large, SPH outperforms other heuristics. This is because link resources become more important than VM resources in such a setting. This also explains the result on the network of Cogent. These results show that SPH is more suitable to deal with bandwidth shortage, while GVR is more resilient to VM shortage. Note that SGH, which also tries to reuse as many VMs as possible, outperforms GVR when the minimum demand size is large. This is because SGH connects reusable VMs by shortest paths. Our design elastically tunes the LV relation according to network topologies and demand properties, and, hence, outperforms other heuristics in a diverse range of scenarios.</p><p>Impact of the Order of Demands: In Fig. <ref type="figure" target="#fig_4">4</ref>, all methods sort the demands in the descending order of R i . In Fig. <ref type="figure" target="#fig_3">3</ref>, we also show the performance of our solution without sorting demands. Two things are noteworthy. First, when most demand sizes are small, the order of demands has a very small impact on the performance. This is because under this setting, we can easily serve lots of demands regardless of the order of demands. However, when most demand sizes are large (comparing to the link capacity), the order of demands plays a crucial role in the performance. This is because, among all demands that have larger sizes, we should first serve demands that require less resource (e.g., demands with shorter paths). Our sorting strategy leverages the above idea and thus outperforms the other sorting strategies as the minimum demand size increases.</p><p>Performance of the Online Version of JVP: In this simulation, we consider a scenario where demands arrive at different times and we do not know all the demands in advance. In particular, we cannot sort the demands, and we need to process each demand immediately once it arrives. In addition, we cannot adjust the path length guide by the stretch factor. In this setting, because the number of demands that will arrive in the future is unknown, one might want to relax the usage guide and keep accepting demands until we run out of resource. Hence, we also consider a variation of our solution where we set the path length guide to infinity (referred to as "Ours (Unbounded)" in Fig. <ref type="figure">5</ref>). We set x min to 10 Mbps for data center networks and set x min to 400 Mbps for the network of Cogent. The result is shown in Fig. <ref type="figure">5</ref>. When the accumulated number of arrived demands is small, the above variation performs slightly better than our solution. However, because the variation consumes the communication resource aggressively, our solution outperforms the variation when the communication resource should be allocated conservatively, e.g., in the network of Cogent.</p><p>Effectiveness of Stress Testing: Next, we evaluate the effectiveness of ST , i.e., stress testing, and check whether the resulting LV relation guide can lead to efficient chain deployment. In particular, we apply our usage-guided deployment algorithm (the one described in Section V), but compare the results of following the link usage l(x * ) obtained by stress testing with those of following the link usage l = k|π oi,ti |, k = 2, 4 and 6. The VM usage is fixed to x * outputted by ST . We vary the minimum demand size, x min , from 1 Mbps to 128 Mbps and from 100 Mbps to 600 Mbps for the three data center networks and the network of Cogent, respectively. Fig. <ref type="figure">6</ref> shows the results. For the data center networks, when the minimum demand size is small, all the demands combined cannot fully utilize the link capacity of the network. Hence, we should allow longer paths so as to approach the given reuse factor. As a result, following a limited link usage 2|π oi,ti | produces the worst performance. On the other hand, for the network of Cogent, the link capacity of the network is insufficient to serve all the demands, even when the minimum demand size is small. In this case, we should avoid long paths. This explains why the guidance of a long link usage leads to a worse performance in this case. The results also verify that no single link usage is always appropriate for different network conditions. However, following link usage specified by ST produces a higher performance than following other usage in most of the cases. This means that ST can effectively adapt the relation between link and VM usage to network dynamics, and guide the deployment algorithm to better utilize the limited resources to support more demands.</p><p>Simulation Results for the Problem of Maximizing the Total Utility of Admitted Demands: Fig. <ref type="figure" target="#fig_6">7</ref> shows the result when the goal is to maximize the total utility of admitted demands. In this simulation, each demand d i is associated with a utility U i generated by the aforementioned power law distribution, where x min = 1. Similar to the previous result, when the minimum demand size is small, SPH has the worst performance. Moreover, the gap between the performances of SPH and other methods is larger in this simulation. One of the reasons is that, in previous simulations, influenced by the sorting strategy obtained by stress testing, all methods rarely process large demands after the early stage of deployment (e.g., after 20% of the input demands are processed). However, in this simulation, because large demands typically have small n * i , all methods process small demands first (unless some large demands have very high utilities). Thus, after the early stage of deployment, unprocessed demands may be too large for SPH to find reusable VMs with sufficient resource (since SPH only searches on the shortest path). However, other solution can extend the path to reach reusable VMs. Note that, when the minimum demand size is large, in order to increase the total utility, demands should take short paths to admit more demands. Thus, SPH performs well when the minimum demand size is large. Again, no matter what the minimum demand size is, our solution matches the best performance of the three comparison schemes.</p><p>The Ratio of the Optimum to Our Solution: In this simulation, we explore the gap between our solution and the optimum. The setting is identical to that of the simulation shown in Fig. <ref type="figure" target="#fig_3">3</ref>. Due to the hardness of our problem, we compute an upper bound of the optimum. For each problem instance, we construct a corresponding knapsack instance. Given a capacity and a set of objects S, where each object is associated with a weight and a utility, the knapsack problem asks for a subset of S whose total weight is no more than the capacity and the total utility is maximized. Given an instance of our problem, the capacity in the corresponding knapsack instance is the total link capacity of the system, C l . For each demand d i , we generate an object J i in the corresponding knapsack instance. Specifically, the utility of J i is R i , and the weight of J i is R i |π oi,ti |, where |π oi,ti | is the shortest path length between the source and the destination of d i . Obviously, if a set of demands can be admitted in our problem instance, then the set of the corresponding objects can be chosen in the corresponding knapsack instance. Thus, the optimum of the corresponding knapsack instance, OP T KP , is an upper bound of the optimum of our problem instance, OP T JV P . Because the knapsack problem is NP-hard, we calculate the optimum of the corresponding fractional knapsack problem, OP T F KP . In the fractional knapsack problem, an object can be chosen partially (e.g., if a half of an object with (utility, weight) = (200, 100) is chosen, then the total utility and total weight are increased by 100 and 50, respectively). Thus, OP T F KP is an upper bound of OP T KP (and thus an upper bound of OP T JV P ), and can be computed efficiently.</p><p>A common heuristic for the knapsack problem is to sort the objects in the descending order of the ratio of the utility to the weight (e.g.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ri</head><p>Ri|πo i ,t i | = 1 |πo i ,t i | in the constructed instance). The heuristic then considers each object sequentially and chooses an object if the remaining capacity is sufficient. Recall that we sort the demands in the descending order of n * i R i . If we only consider the constraint imposed by the total link capacity in ST , then n * i is equal to</p><formula xml:id="formula_25">C l |πo i ,t i |Ri . Therefore, for every demand d i , n * i R i = C l /|π oi,ti |.</formula><p>As a result, our sorting strategy degenerates to that of the common heuristic.</p><p>Fig. <ref type="figure" target="#fig_7">8</ref> shows the ratio of the upper bound to our performance. When the minimum demand size is small, our performance is very close to the optimum. The reason is that the demand size follows the power law distribution. Therefore, most demands have small sizes. Thus, we can gradually fill up the remaining capacity. Moreover, our solution sorts the demands in a reasonable way as the common heuristic does. The ratio is bigger in the network of Cogent. One of the reasons is that, OP T F KP is not a very tight upper bound in the network of Cogent. In the three data center networks, the networks are highly connected, and thus every link can be accessed easily from all nodes within a few hops. Therefore, the overall link resource in the system can be captured properly by the total link capacity. However, this is not the case in the network of Cogent since it is a cross-continental inter-data-center network where links are not distributed regularly. In other words, some links in the network of Cogent cannot be accessed easily from some distant nodes. Thus, it is over-optimistic to assume that all demands can access all the links (as it is assumed implicitly in the constructed knapsack instance). We remark that, due to Theorem 1, under the assumption that P = N P , for every polynomial-time algorithm of our problem, there exist instances such that the algorithm cannot admit any demand but the optimum can admit at least one demand. Hence, the worstcase ratio for every polynomial-time algorithm is infinity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DISCUSSION</head><p>In this work, we assume that the demand size remains the same after being served by a VNF. This might not always be true because some VNFs, e.g., firewall, might drop some packets or reshape the traffic. Our proposed solution can be generalized to deal with this traffic reshaping. The high-level idea of generalization is to consider the actual bandwidth consumption of each demand B(x), instead of just the required path length l(x). Specifically, in ST , R i l(x) in Eq. (1a) can be replaced with the total bandwidth consumption of each served demand B(x), which can be estimated using a similar way mentioned in Section IV-B. Also, the calculation of the stretch factor should be changed accordingly. Then, we can apply our deployment algorithm to again find a solution whose resource consumption approaches the given bandwidth usage B(x * ). The major modification we need to make is that, when combining m * (p-(v |p| ), S h ) and m * ((v |p| ), S h ) in dynamic programming, we should further check whether the capacity of link (v |p|-1 , v |p| ) is sufficient to support the demand after invoking s i,h . If not, the combined solution is infeasible.</p><p>So far, we assume that each NF is a VM. In practice, NFs can run inside containers, which are more lightweight than VMs <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr">[56]</ref>. Note that, to achieve better performance, an NF should have dedicated resource <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. For example, it is assumed in <ref type="bibr" target="#b32">[33]</ref> that NFs do not share CPU cores to avoid context switching overheads. (One exception is [56], since they focus on short-lived lightweight NFs.) In our model, an NF running as a container with dedicated resource is equivalent to an NF running as a VM. Moreover, even if the system is not partitioned into VMs in advance, we can treat each CPU as a VM in our problem model and then apply our solution. This method can also be used to solve the problem where NFs may share a VM provided that they do not share CPU cores.</p><p>In practice, a demand can be partitioned into smaller ones, and thus the network can be better utilized. We can model a partition of a demand d as a set of small demands P = { d1 , d2 , • • • , dk } such that if all demands in P are served, then d is served. We call a demand in P a slice of demand d.</p><p>To adapt our solution to demand partition, we need more inputs. First, because no universal way can be used to partition all types of traffics and VNFs, each input demand must be associated with its valid partition. If there are multiple ways to partition the demand, only the most fine-grained partition has to be given, i.e., the partition composed of the smallest slices. We can further merge different slices after resource allocation when applicable (e.g., the resources of different slices are from the same set of devices). Second, because we consider admission control, an additional input must be associated with each demand to indicate whether or not the demand can be partially admitted, i.e., only some slices are admitted. Given the above two additional inputs, we can then generalize our solution as follows: If a demand can be partially admitted, then we simply treat each slice as a demand in our original problem. If a demand d cannot be partially admitted, then we apply stress testing on d (not on the slices) to get the LV relation guide. We also sort the set of the original demands (not the set of slices). When we process a demand d, we then apply our DP-based deployment algorithm on each of its slices. Specifically, the LV relation guide for each slice is that of d. Therefore, the total link consumption guide of d is equal to the total link consumption guide of all slices. In addition, if the first slice can reuse x VMs, then it is easy for the next slice to reuse x VMs. If some slice is rejected (due to an overlong path), then all slices are rejected. Finally, note that it would be inefficient if we partition a demand into lots of tiny slices, since the overhead of partitioning and merging demands would be high. Therefore, we should avoid partitions that result in lots of arbitrarily small slices. As a result, the JVP problem is still NP-hard, even if demands can be partitioned (since finding a feasible solution for a slice is NP-hard).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we study the joint VNF placement and path selection problem. We show that this problem is NP-hard. To tackle this problem, we study the relation between the path length and the VM reuse factor, i.e., the LV relation. Specifically, we use the idea of stress testing to find a LV relation guide. Following this guidance, we then propose a chain deployment algorithm to find a solution whose path length and reuse factor approximately meet the guide. Via simulation, we show that our design outperforms other heuristics, which cannot manage the relation between link and server usage well across different types of networks. In contrast, our usage-guided deployment elastically adapts link and VM usage to different networks, and, hence, better utilizes the limited resources to serve a larger size of demands.</p><p>Two directions are worth studying in the future. First, the online version of our problem where the number of demands that will arrive in the future is unknown. To better reflect the reality, in the online problem, one can also consider the completion time of a demand or the trade-off between the total size of admitted demands and the elapsed time since the first demand arrives. Second, in the current solution, we do not leverage the relation between demands. In practice, the distributions of some properties of demands may be biased. For example, the distribution of the source and the destination or the distribution of NFs in a service chain may be biased. If some distribution is biased, one may design better solutions by leveraging the bias. For example, one can divide the demands into groups where similar demands belong to the same group (clustering), and then considers the resource allocation of demands in the same group jointly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>For ease of presentation, we set S h = S when h = |S| and set S h = S when h = 0. Consider |S| + 1 problems, SVP h (p, S), 0≤h≤|S|, each has one more constraint than that of SVP(p, S). The additional constraint is that the services assigned to VMs on p- <ref type="bibr">(v</ref>  We consider two cases of m * (p, S), feasible or infeasible. If m * (p, S) is infeasible, then all SVP h (p, S)s, 0 ≤ h ≤ |S|, have no feasible solution. Hence, by the first part of the proof, m h , 0 ≤ h ≤ |S|, is infeasible for SVP(p, S). Thus, Eq. ( <ref type="formula">6</ref>) holds for this case. For the case of m * (p, S) being feasible, since any feasible solution of SVP(p, S) must be feasible for some SVP h (p, S), 0 ≤ h ≤ |S|, m * (p, S) must be an optimal solution for some SVP h * (p, S). It is then sufficient to show that m h * is feasible and optimal for SVP h * (p, S). The feasibility of m h * clearly holds by the first part of the proof. We prove the optimality of m h * by contradiction. Assume that a better solution m exists. Then, compared with m h * , m must reuse more VMs in p-(v |p| ) or in (v |p| ), which contradicts to the optimality of m * (p-(v |p| ), S h * ) and m * ((v |p| ), S h * ).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The roadmap of our solution.</figDesc><graphic coords="4,317.51,58.85,240.02,230.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 )</head><label>2</label><figDesc>After sorting the demands, we then process each demand sequentially. For each demand d i : a) Obtain the LV relation guide for d i . This is done by applying the mathematical program to d i with respect to the current network status (Section IV-B). Unless we are considering the online problem, we further refine the LV relation guide (Section IV-D). b) Allocate resource for d i according to the LV relation guide.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Impact of the length of service chains on (a) Fat-Tree, (b) BCube, (c) VL2, and (d) the network of Cogent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Impact of the minimum demand size on (a) Fat-Tree, (b) BCube, (c) VL2, and (d) the network of Cogent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Impact of the minimum demand size on (a) Fat-Tree, (b) BCube, (c) VL2, and (d) the network of Cogent. All methods sort the demands in the descending order of R i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Performance of the online version of JVP on (a) Fat-Tree, (b) BCube, (c) VL2, and (d) the network of Cogent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Total utility on (a) Fat-Tree, (b) BCube, (c) VL2, and (d) the network of Cogent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The ratio of the optimum to our solution.</figDesc><graphic coords="12,44.87,54.89,256.46,123.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>We propose a stress-testing-inspired mathematical program to find a proper LV relation. Moreover, the mathematical program can be solved efficiently (Section IV).</figDesc><table><row><cell>• Using dynamic programming, we design a deploy-</cell></row><row><cell>ment algorithm that approaches a given LV relation</cell></row><row><cell>(Section V).</cell></row><row><cell>• We evaluate our solution in different types of data center</cell></row><row><cell>network topologies. The result demonstrates the superior-</cell></row><row><cell>ity of our solution over other greedy-based and shortest-</cell></row><row><cell>path-based heuristics (Section VI).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>initialize assignments 3 /* iteratively extend the path */ for k←1 to ∞ do ← 0 // initialize the reuse gain 5 /* test each intermediate vertex */ for v ∈ G do</figDesc><table><row><cell>6</cell></row></table><note><p><p>4</p>g *</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>← π v k-1 ,v k , p i,k ←p i,k-1 + pi,k</figDesc><table><row><cell>9</cell><cell>if r(p) ≤ r(p i,k-1 ) then continue</cell></row><row><cell>10</cell><cell>// v satisfies the Properties A and B</cell></row><row><cell>11</cell><cell>if r(p)/|p| &gt; g  *  then</cell></row></table><note><p>continue 8 Obtain assignments m * (p, S * ) and r(p) by Eqs. (6,7) 12 v k ←v , m()←m * (p, S * ), g * ←r(p)/|p| 13 pi,k 14 if g * = 0 then break 15 Update c e s based on p i,k and reconstruct G 16 Update remaining VM resources c m based on m() 17 return p i,k , m(s i,j ), ∀s i,j ∈ S * p i,k = k k =1 pi,k . 5 Also, v k represents the intermediate vertex reached by sub-path pi,k , and</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>, each instance SVP(p, S) can be partitioned into two sub-instances SVP(p-(v |p| ), S h ) and SVP((v |p| ), S h ), where v |p| is the last vertex on path p, and S h = (s 1 , • • • , s h ) and S h = (s h+1 , • • • , s |S| ) are the first and second parts of S, respectively, broken at service s h . Therefore, the basic idea of our dynamic programming is that, given any instance SVP(p, S), we recursively solve the two sub-instances SVP(p-(v |p| ), S h ) and SVP((v |p| ), S h ), and combine these two solutions as the solution of SVP(p, S). We use ⊕ to denote this combining operation. That is, m(p, S) = m(p-(v |p| ), S</figDesc><table /><note><p>h ) ⊕ m((v |p| ), S h ), and m(p, S) = ∅ if any of m(p-(v |p| ), S h ) and m((v |p| ), S h</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>14</head><label></label><figDesc>Update c m * and c e s and reconstruct G15 p b ← p b + π vL,ti 16 p i ← p i,k + p b 17 if |p i | &gt; l * i then</figDesc><table><row><cell>13</cell></row></table><note><p>18 Reject d i 19 return Algorithm 3 Increase-Reuse-Factor 1 while true do 2 Δ min ← ∞ 3 forall the s i,j ∈ S i that is assigned to an empty VM do 4 forall the reusable VM m for s i,j do 5 if Δ(s i,j , m) &lt; Δ min then 6 Δ min ← Δ(s i,j , m) 7 s * ← s i,j , m * ← m 8 p * new ← pnew (s i,j , m), p * old ← pold (s i,j ) 9 if |p i | + Δ min &gt; l * i then return p i , m(s i,j ), ∀s i,j ∈ S i 10 m old ← m(s * ), m(s * ) ← m * 11 Replace p * old with p * new in p i 12 Update c e s, c m(s * ) , c m old and reconstruct G</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>|p| ) are fixed to S h (if 1≤h≤|S|) or ∅ (if h=0). If SVP h (p, S) has a feasible solution, then both SVP(p-(v |p| ), S h ) (if h &gt; 0) and SVP((v |p| ), S h ) (if h &lt; |S|) have a feasible solution. Also note that the paths in these two problems do not overlap, and so do their service sub-chains. Thus, if m * (p-(v |p| ), S h ) and m * ((v |p| ), S h ) are feasible, then m h must be feasible for SVP(p, S) according to Eq. (6). Combining the above arguments, we get that, if SVP h (p, S) has a feasible solution, then m h is feasible for SVP h (p, S) and SVP(p, S). On the other hand, if SVP h (p, S) has no feasible solution, then at least one of SVP(p-(v |p| ), S h ) and SVP((v |p| ), S h ) has no feasible solution and, thereby, m h is not feasible for both SVP h (p, S) and SVP(p, S).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>In hindsight, we approximate the problem of finding the best reuse factor twice. The first time occurs when we simplify the problem (to get the problem formulation in Section IV-A). The second time occurs when we solve this simplified problem by ST .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>For simplicity, we use p 1 + p 2 to denote the concatenation of p 1 and p 2 , and use p 1p 2 to denote the operation of truncating p 2 from p 1 .</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deploying chains of virtual network functions: On the relation between link and server usage</title>
		<author>
			<persName><forename type="first">T.-W</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Liou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM)</title>
		<meeting>IEEE Int. Conf. Comput. Commun. (INFOCOM)</meeting>
		<imprint>
			<date type="published" when="2016-04">Apr. 2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey of enterprise middlebox deployments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ratnasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>At</surname></persName>
		</author>
		<idno>UCB/EECS-2012-24</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Elect. Eng. Comput. Sci., Univ. of California</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Berkeley, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Network Functions Virtualisation-Introductory White Paper</title>
		<ptr target="https://portal.etsi.org/nfv/nfv_white_paper.pdf" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">AT&amp;T and Verizon NFV and SDN Moves Seen as Industry-Leading</title>
		<author>
			<persName><forename type="first">D</forename><surname>Meyer</surname></persName>
		</author>
		<ptr target="https://www.rcrwireless.com/20160609/network-function-virtualization-nfv/att-verizon-nfv-sdn-moves-seen-industry-leading-tag2" />
		<imprint>
			<date type="published" when="2016-01">2016. Jan. 16. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ClickOS and the art of network function virtualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Symp. Netw. Syst. Design Implement</title>
		<meeting>USENIX Symp. Netw. Syst. Design Implement</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="459" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Problem Statement for Service Function Chaining, document IETF RFC 7498</title>
		<author>
			<persName><forename type="first">P</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nadeau</surname></persName>
		</author>
		<idno type="DOI">10.17487/RFC7498</idno>
		<ptr target="https://rfc-editor.org/rfc/rfc7498.txt" />
		<imprint>
			<date type="published" when="2015-04">Apr. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Orchestrating virtualized network functions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boutaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C M B</forename><surname>Duarte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Netw. Service Manage</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="725" to="739" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><surname>Openstack</surname></persName>
		</author>
		<ptr target="https://www.openstack.org/" />
		<imprint>
			<date type="published" when="2018">Jan. 16. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Open</forename><surname>Source</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mano</forename></persName>
		</author>
		<ptr target="https://osm.etsi.org/" />
		<imprint>
			<date type="published" when="2018-01-16">Jan. 16, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><surname>Opnfv</surname></persName>
		</author>
		<ptr target="https://www.opnfv.org/" />
		<imprint>
			<date type="published" when="2018">Jan. 16. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Coordinated allocation of service function chains</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Botero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Global Commun. Conf. (GLOBECOM)</title>
		<meeting>IEEE Global Commun. Conf. (GLOBECOM)</meeting>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Specifying and placing chains of virtual network functions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mehraghdam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Cloud Netw. (CloudNet)</title>
		<meeting>IEEE Int. Conf. Cloud Netw. (CloudNet)</meeting>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
			<biblScope unit="page" from="7" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<ptr target="https://en.wikipedia.org/wiki/Stress_testing" />
		<title level="m">Stress Testing-Wikipedia, the Free Encyclopedia</title>
		<imprint>
			<date type="published" when="2017-01">2017. Jan. 11. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Resource allocation in NFV: A comprehensive survey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Botero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Netw. Service Manage</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="518" to="532" />
			<date type="published" when="2016-09">Sep. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Virtual network functions placement and routing optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Addis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Belabed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bouet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Secci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Cloud Netw. (CloudNet)</title>
		<meeting>IEEE Int. Conf. Cloud Netw. (CloudNet)</meeting>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
			<biblScope unit="page" from="171" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient orchestration mechanisms for congestion mitigation in nfv: Models and algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Elias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Services Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="534" to="546" />
			<date type="published" when="2015-07">Jul. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On service chaining using virtual network functions in network-enabled cloud systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Habib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tornatore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf</title>
		<meeting>IEEE Int. Conf</meeting>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
			<biblScope unit="page" from="1" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Virtual network function embedding in real cloud environments</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bellavista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Netw</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="506" to="517" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bandwidth guaranteed virtual network function placement and scaling in datacenter networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Perform. Comput. Commun. Conf. (IPCCC)</title>
		<meeting>IEEE Int. Perform. Comput. Commun. Conf. (IPCCC)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">VNF-P: A model for efficient placement of virtualized network functions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">De</forename><surname>Turck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Netw. Service Manage. (CNSM)</title>
		<meeting>Int. Conf. Netw. Service Manage. (CNSM)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="418" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Network function placement for NFV chaining in packet/optical datacenters</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shirazipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Takacs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Lightw. Technol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1565" to="1570" />
			<date type="published" when="2015-04-15">Apr. 15, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Near optimal placement of virtual network functions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lewin-Eytan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Commun. (INFOCOM)</title>
		<meeting>IEEE Conf. Comput. Commun. (INFOCOM)</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr. 2015</date>
			<biblScope unit="page" from="1346" to="1354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Service-aware network function placement for efficient traffic handling in carrier cloud</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bagaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Taleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ksentini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Wireless Commun. Netw. Conf. (WCNC)</title>
		<meeting>IEEE Wireless Commun. Netw. Conf. (WCNC)</meeting>
		<imprint>
			<date type="published" when="2014-04">Apr. 2014</date>
			<biblScope unit="page" from="2402" to="2407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mobile core network virtualization: A model for combined virtual core network function placement and topology optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bauschert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Netw. Softwarization (NetSoft)</title>
		<meeting>IEEE Conf. Netw. Softwarization (NetSoft)</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr. 2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Server placement and assignment in virtualized radio access networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mijumbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Serrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Gorricho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rubio-Loyola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Davy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Netw. Service Manage. (CNSM)</title>
		<meeting>Int. Conf. Netw. Service Manage. (CNSM)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="398" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cost-based placement of vDPI functions in NFV infrastructures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bouet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leguay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Conan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IEEE Conf. Netw. Softwarization (NetSoft)</title>
		<meeting>1st IEEE Conf. Netw. Softwarization (NetSoft)</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr. 2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Combined virtual mobile core network function placement and topology optimization with latency bounds</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bauschert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Workshop Softw. Defined Netw</title>
		<meeting>Eur. Workshop Softw. Defined Netw</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Demand-aware network function placement</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tornatore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Lightw. Technol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2590" to="2600" />
			<date type="published" when="2016-06-01">Jun. 1, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimal network resource utilization in service function chaining</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE NetSoft Conf. Workshops (NetSoft)</title>
		<meeting>IEEE NetSoft Conf. Workshops (NetSoft)</meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Stratos: A network-aware orchestration layer for virtual middleboxes in clouds</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gember</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1305.0209" />
		<imprint>
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">E2: A framework for NFV applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palkar</surname></persName>
		</author>
		<idno type="DOI">10.1145/2815400.2815423</idno>
		<ptr target="http://doi.acm.org/10.1145/2815400.2815423" />
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Symp. Operat. Syst. Principles (SOSP)</title>
		<meeting>25th Symp. Operat. Syst. Principles (SOSP)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="121" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SIMPLE-fying middlebox policy enforcement using SDN</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">A</forename><surname>Qazi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2486001.2486022</idno>
		<ptr target="http://doi.acm.org/10.1145/2486001.2486022" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM Conf. (SIGCOMM)</title>
		<meeting>ACM SIGCOMM Conf. (SIGCOMM)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SDNFV: Flexible and dynamic software defined control of an application-and flow-aware data plane</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2988336.2988338</idno>
		<ptr target="http://doi.acm.org/10.1145/2988336.2988338" />
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Int. Middleware Conf</title>
		<meeting>17th Int. Middleware Conf<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Online admission control and embedding of service chains</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lukovszki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Colloquium Struct</title>
		<meeting>Int. Colloquium Struct</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="104" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Design and evaluation of algorithms for mapping and scheduling of irtual network functions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mijumbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Netw. Softwarization (NetSoft)</title>
		<meeting>IEEE Conf. Netw. Softwarization (NetSoft)</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr. 2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Piecing together the nfv provisioning puzzle: Efficient placement and chaining of virtual network functions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Luizelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IFIP/IEEE Int. Symp. Integr. Netw. Manage. (IM)</title>
		<meeting>IFIP/IEEE Int. Symp. Integr. Netw. Manage. (IM)</meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
			<biblScope unit="page" from="98" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Virtual network functions orchestration in wireless networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Riggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Netw. Service Manage. (CNSM)</title>
		<meeting>Int. Conf. Netw. Service Manage. (CNSM)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Elastic virtual network function placement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghaznavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Cloud Netw. (CloudNet)</title>
		<meeting>IEEE Int. Conf. Cloud Netw. (CloudNet)</meeting>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
			<biblScope unit="page" from="255" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Virtual function placement and traffic steering in flexible and dynamic software defined networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohammadkhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Local Metropolitan Area Netw</title>
		<meeting>IEEE Int. Workshop Local Metropolitan Area Netw</meeting>
		<imprint>
			<date type="published" when="2015-04">Apr. 2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Network service chaining with optimized network function embedding supporting service decompositions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sahhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Netw</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="492" to="505" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Scheduling wireless virtual networks functions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Riggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bradai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rasheed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Netw. Service Manag</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="240" to="252" />
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Service function chaining simplified</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghaznavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shahriar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boutaba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1601.00751" />
		<imprint>
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving the scalability of data center networks with traffic-aware virtual machine placement</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Commun. (INFOCOM)</title>
		<meeting>IEEE Conf. Comput. Commun. (INFOCOM)</meeting>
		<imprint>
			<date type="published" when="2010-03">Mar. 2010</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Google</forename><surname>Cloud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Platform</forename></persName>
		</author>
		<ptr target="https://cloud.google.com/" />
		<imprint>
			<date type="published" when="2018-01-11">Jan. 11, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Performance analysis of virtualized network functions on virtualized systems architectures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leivadeas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lambadaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kesidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CAMAD</title>
		<meeting>IEEE CAMAD</meeting>
		<imprint>
			<date type="published" when="2016-03">Mar. 2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Optimal virtualized network function allocation for an SDN enabled cloud</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leivadeas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lambadaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kesidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Standard Interfaces</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="266" to="278" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">OpenBox: A software-defined framework for developing, deploying, and managing network functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bremler-Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Harchol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hay</surname></persName>
		</author>
		<idno type="DOI">10.1145/2934872.2934875</idno>
		<ptr target="http://doi.acm.org/10.1145/2934872.2934875" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM Conf. (SIGCOMM)</title>
		<meeting>ACM SIGCOMM Conf. (SIGCOMM)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="511" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Inapproximability of edge-disjoint paths and low congestion routing on undirected graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="485" to="520" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">PortLand: A scalable fault-tolerant layer 2 data center network fabric</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Mysore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Special Interest Group Data Commun. (SIGCOMM)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">VL2: A scalable and flexible data center network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Special Interest Group Data Commun</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">BCube: A high performance, server-centric network architecture for modular data centers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Comput. Commun. Rev</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="63" to="74" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Cogent&apos;s Network Map</title>
		<ptr target="http://cogentco.com/en/network/network-map" />
		<imprint>
			<date type="published" when="2015-07-24">Jul. 24, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Computer organization and Design: The Hardware/Software Interface</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Morgan Kauffman</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Low-complexity multi-resource packet scheduling for network function virtualization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Commun. (INFOCOM)</title>
		<meeting>IEEE Conf. Comput. Commun. (INFOCOM)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1400" to="1408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">OpenNetVM: A platform for high performance network service chains</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="http://doi.acm.org/2940147.2940155" />
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Hot Topics Middleboxes Netw. Function Virtualization (HotMIddlebox)</title>
		<meeting>Workshop Hot Topics Middleboxes Netw. Function Virtualization (HotMIddlebox)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
