<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Disambiguation of Company names via Deep Recurrent Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-04-18">April 18, 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alessandro</forename><surname>Basile</surname></persName>
							<email>alessandro.basile@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Riccardo</forename><surname>Crupi</surname></persName>
							<email>riccardo.crupi@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michele</forename><surname>Grasso</surname></persName>
							<email>michele.grasso@earlymorning.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Early Morning S.r.l</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alessandro</forename><surname>Mercanti</surname></persName>
							<email>alessandro.mercanti@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniele</forename><surname>Regoli</surname></persName>
							<email>daniele.regoli@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Simone</forename><surname>Scarsi</surname></persName>
							<email>simone.scarsi@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuyi</forename><surname>Yang</surname></persName>
							<email>shuyi.yang@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><forename type="middle">Claudio</forename><surname>Cosentini</surname></persName>
							<email>andrea.cosentini@intesasanpaolo.com</email>
							<affiliation key="aff0">
								<orgName type="department">Data Science &amp; Artificial Intelligence</orgName>
								<orgName type="institution">Intesa Sanpaolo S.p.A</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Disambiguation of Company names via Deep Recurrent Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-18">April 18, 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2303.05391v2[cs.CL]</idno>
					<note type="submission">Preprint submitted to Elsevier</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine learning</term>
					<term>Natural Language Processing</term>
					<term>Named Entity Disambiguation</term>
					<term>Siamese Network</term>
					<term>Active Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Name Entity Disambiguation is the Natural Language Processing task of identifying textual records corresponding to the same Named Entity, i.e. real-world entities represented as a list of attributes (names, places, organisations, etc.). In this work, we face the task of disambiguating companies on the basis of their written names. We propose a Siamese LSTM Network approach to extract -via supervised learning -an embedding of company name strings in a (relatively) low dimensional vector space and use this representation to identify pairs of company names that actually represent the same company (i.e. the same Entity).</p><p>Given that the manual labelling of string pairs is a rather onerous task, we analyse how an Active Learning approach to prioritise the samples to be labelled leads to a more efficient overall learning pipeline.</p><p>With empirical investigations, we show that our proposed Siamese Network outperforms several benchmark approaches based on standard string matching algorithms when enough labelled data are available. Moreover, we show that Active Learning prioritisation is indeed helpful when labelling resources are limited, and let the learning models reach the out-of-sample performance saturation with less labelled data with respect to standard (random) data labelling approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A common information retrieval task with several applications is the association of company names from any internal or external source to a specific company registered in an internal database. A The contribution of this work is twofold: on the one hand, we propose a Siamese Recurrent Neural Network approach to the ask of disambiguating pairs of company names. We show, via experiments, that the proposed approach outperforms other baseline models and that is efficient in generalising to other domains. On the other hand, we use our proposed model in an Active Learning setting to demonstrate how to make human labelling more efficient by prioritising the samples to be labelled.</p><p>The rest of the paper is organised as follows: Section 2 is devoted to a discussion of relevant literature, in particular regarding NED and Active Learning. In Section 3 we detail the methodologies we use for the NED task: we describe both our proposed model and the baseline approaches we use as benchmark. Section 4 is devoted to describing how we implement the Active Learning setting. In Section 5 we thoroughly describe how we build the datasets that we use in the experiments. The latter are described in Section 6. Discussion of the insights derived from the experimental results is presented in Section 7, while Section 8 contains concluding remarks.</p><p>The python code implementation of the Siamese Neural Network model, of the Active Learning setting and of all the experiments, is available in open-source at github.com/rcrupi/SiameseDisambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Entity Disambiguation</head><p>Most classical approaches to strings pair matching leverage string similarity measures, quantifying how much two given strings are similar with a more or less sophisticate deterministic rule <ref type="bibr" target="#b10">(Cohen et al., 2003;</ref><ref type="bibr" target="#b9">Christen, 2006;</ref><ref type="bibr" target="#b26">Sun et al., 2015)</ref>. These methods are built on several background encodings of given strings, such as phonetic-based, character-based, or based on term frequency/inverse term frequency (tf-idf ) and hybrid versions of these <ref type="bibr" target="#b9">(Christen, 2006)</ref>. Other approaches try to employ also semantic knowledge to compute similarity <ref type="bibr" target="#b20">(Prasetya et al., 2018)</ref>.</p><p>More recently, methodologies based on learning the appropriate similarity function from a sample of data of the desired domain have become quite common. For instance, <ref type="bibr" target="#b19">Piskorski and Jacquet (2020)</ref> employ tf-idf vectors of n-grams as predictors for a Machine Learning (ML) classifier. The internal (learned) representation can then be exploited as an abstract vector summarising the information relevant to the task. Finally, a standard vector similarity function -such as cosine similarity -of the representations of two strings can be used to infer their task-specific distance.</p><p>In the domain of toponym matching -i.e. pairing of different strings representing the same realworld location - <ref type="bibr" target="#b22">Santos et al. (2018)</ref> have faced a problem very similar to the one we are discussing. They propose an approach based on a Siamese Deep Neural Network architecture <ref type="bibr" target="#b7">(Chicco, 2021)</ref> and benchmark it against several distance-based methodologies and several classifiers taking as input various pairwise string distances. They conclude that their approach is superior in terms of matching performance, even if less efficient in terms of computational time with respect to pure distance methods. <ref type="bibr" target="#b17">Neculoiu et al. (2016)</ref> propose a Siamese Deep Learning model as well, with the slightly different task of mapping strings to a predefined set of job names. This classification task is nevertheless approached by translating it into a NED framework and by learning a vector representation of strings, such that close vectors correspond to the same job class. They use two different loss terms for positive and negative matches: in particular, the loss term for negative samples is zero below a certain threshold, so as not to pay a cost for non-matching pairs that are increasingly dissimilar. Furthermore, they introduce some interesting data augmentation techniques, such as observations derived by adding some random typos and character-level deletion in positive pair samples. <ref type="bibr" target="#b2">Aghaebrahimian and Cieliebak (2020)</ref> also propose a Deep Learning approach to NED, while having as input, not the raw strings, but rather character-level tf-idf vectors of n-grams, similarly to <ref type="bibr" target="#b19">Piskorski and Jacquet (2020)</ref>. Moreover, they train the network in a contrastive fashion, i.e. by feeding input triplets with the observed string and both an actual string match (i.e. string representing the same entity -positive example) and a non-matching string (negative example).</p><p>We refer to <ref type="bibr" target="#b5">Barlaug and Gulla (2021)</ref> for a thorough review of Neural Networks-based approaches to the NED task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Active Learning</head><p>Entity Matching datasets are typically constructed through laborious human labelling. To increase the efficiency of such a procedure, techniques have been proposed to carefully prioritise the samples to be labelled. Against this background, Active Learning -i.e. the sub-field of ML with the characteristic that the learning algorithm is allowed to choose the data from which it learns <ref type="bibr" target="#b24">(Settles, 2009;</ref><ref type="bibr" target="#b3">Arora and Agarwal, 2007)</ref> -has been proven to be beneficial in the Entity Matching domain <ref type="bibr" target="#b15">(Meduri et al., 2020)</ref>. In particular, the selection criteria of candidate observations to be labelled are usually expressed in terms of informativeness and representativeness <ref type="bibr" target="#b29">(Zhou, 2018)</ref>. While representativeness-based approaches try to find a pattern of the unlabelled data, using graphs or clustering methods, informativeness-based approaches -such as Uncertainty sampling and query-by-committee -choose the instances to be labelled based on how uncertain they are to be classified. In particular, Query-by-Committee approaches propose to train several classifiers and define the uncertainty of a given observation based on the rate of disagreement on their predictions. They are sometimes referred to as the learner-agnostic approaches. Uncertainty sampling, on the other hand, given a specific classifier, employs the distance from the decision boundary as a proxy for uncertainty. It is therefore referred to as learner-aware approach.</p><p>While in <ref type="bibr" target="#b15">Meduri et al. (2020)</ref> the task is to disambiguate two instances on the basis of several different information sets (e.g. address, name, etc.), in this work we focus on company disambiguation based on string names only. A disambiguation task involving couples of words (e.g. <ref type="bibr">'principle', 'principal', and 'end', 'and')</ref> was faced in <ref type="bibr" target="#b4">Banko and Brill (2001)</ref>. In particular, they extract features from the words and apply a ML classifier to estimate their similarity. Active Learning (specifically query-by-committee) is then exploited to iteratively select batches from a pool of unlabelled samples. Half of the samples in each batch are selected randomly, while the other half are selected on the basis of their uncertainty.</p><p>Since Deep Learning requires huge amount of data, Active Learning is particularly well suited to limiting the data labelling but keeping high the performance <ref type="bibr" target="#b28">(Zhan et al., 2022)</ref>. In particular, in this work we adopt a modification of the "Least confidence" approach as query strategy <ref type="bibr" target="#b13">(Huang, 2021)</ref>.</p><p>Other works, such as <ref type="bibr" target="#b25">Sorscher et al. (2022)</ref>, suggest a self-supervised data pruning method. In contrast to Active Learning, data reduction is done in a single step. The self-supervised metric is based on the application of k-means over the embedding space of a pre-trained network: an instance far away from its cluster centroid is considered uncertain. Experiments in <ref type="bibr" target="#b25">Sorscher et al. (2022)</ref> suggest that the instances to be removed actually depend on the size of the starting dataset: if it is large enough, it is beneficial to include the most uncertain samples, whereas if it is small, it is preferable to include simplest (least uncertain) samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>In ML settings, a multiclass classification function C : X ? Y takes as input a feature vector x ? X from the input feature space X and outputs a class label y ? Y from a finite set of possible ? classes Y = {0, 1, 2, . . . , ? -1} <ref type="bibr" target="#b12">(Hastie et al., 2009)</ref>. Most families of ML classifiers actually learn to estimate the probabilities</p><formula xml:id="formula_0">P(y = ? | x), ? ? {0, 1, . . . , ?} .</formula><p>(1)</p><p>In the following, we label with ?i,? the estimated probability that the i-th sample belongs to the class ?. Being probabilities, the ?i,? are such that ?-1 ?=0 ?i,? = 1 and ?i,? ? [0, 1] ?? ? Y . The predicted class ?i is the one associated with the highest probability, namely ?i = argmax ??Y ?i,? .</p><p>The case with only two class labels ( ? = 2) -i.e. binary classification tasks -are usually formalised as:</p><formula xml:id="formula_1">C : X ? [0, 1],<label>(2)</label></formula><p>where the output ?i is an estimate of P(y i = 1 | x i ) and corresponds to the output (? i,0 , ?i,1 ) = (1 -?i , ?i ) in the generic multiclass setting.</p><p>In this work, we frame the string match problem as a binary classification task, where the components of the input feature vector x i are couples of strings x i = {a i , b i }, and the classifier estimates the probability ?i that the two strings correspond to the same company (we label 1 the matching class). Calling S the set of possible character symbols, we may formalise the string matching classifier as a function</p><formula xml:id="formula_2">C : S n ? S n ? [0, 1],<label>(3)</label></formula><p>where the integer n denotes the fixed (maximum) length of the strings to be analysed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Baseline methods</head><p>To determine how dissimilar two strings a and b ? S n are, in the following we shall make use either of a distance function -D(a, b) ? R + where 0 stands for identical strings and the higher the distance the more dissimilar a and b -or a similarity function -S(a, b) ? [0, 1], 1 denoting identical strings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Levenshtein</head><p>Widely used deterministic methods are the edit distance metrics. Generally speaking, they are based on counting the number of operations needed to transport a string onto another. The choice of the type of operations allowed determines the specific form of the distance. The most widely known edit-distance metric is the Levenshtein distance (sometimes referred to as the edit-distance), which calculates the distance as the number of insertions, deletions, and substitutions required to transform one string into another. The formula of the Levenshtein distance D Lev (a, b) between two strings a = a 0 a 1 a 2 . . . a m of length m and b = b 0 b 1 b 2 . . . b n of length n is given by the following recursion:</p><formula xml:id="formula_3">D Lev (a, b) = ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? m if n = 0, n if m = 0, D Lev ( a, b) if a 0 = b 0 , 1 + min ? ? ? D Lev ( a, b) D Lev (a, b) D Lev ( a, b)</formula><p>otherwise;</p><p>(4) where x denotes the string x without the first character (x 0 ), i.e. x = x 1 x 2 . . . x s .</p><p>A closely related edit-based distance is the InDel distance, which allows only insertions and deletions. It is easy to see that the InDel distance is equivalent to the Levenshtein distance where the substitution operation is assigned a cost of 2 (deletion + insertion). We call InDel Ratio the following normalised version of the InDel distance:</p><formula xml:id="formula_4">R ID (a, b) = 1 - D ID (a, b) |a| + |b| ,<label>(5)</label></formula><p>where D ID (a, b) denotes the InDel distance between a and b. We make use of the Python library TheFuzz to compute R ID (a, b), with the sole difference that TheFuzz expresses the ratio in percentage points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jaro-Winkler similarity</head><p>The Jaro-Winkler (JW) similarity (S JW ) is another edit-based metric emphasising both the amount of matching characters and their placement inside the two strings. Notice that this is a notion of similarity, i.e. S JW ? [0, 1], S JW (a, b) = 0 corresponding to no match at all between two strings a and b, and S JW (a, b) = 1 to exact match.</p><p>The Jaro-Winkler similarity is a variant of the Jaro similarity, that, for two strings a and b, is defined as</p><formula xml:id="formula_5">S J (a, b) = ? ? ? ? ? 0 if c = 0, 1 3 c |a| + c |b| + c -t c otherwise,<label>(6)</label></formula><p>with:</p><p>? c the number of matching characters. Two characters are considered a match when they are the same and they are no more than max(|a|,|b|)   2 -1 chars apart of one another,</p><p>? t is the number of transpositions counted as the number of matching characters found in the wrong order, divided by two.</p><p>The JW similarity extends the definition of the Jaro similarity by favouring strings with a matching prefix:</p><formula xml:id="formula_6">S JW (a, b) = S J (a, b) + p (1 -S J (a, b)) ,<label>(7)</label></formula><p>where is the length of the common prefix up to a maximum value, and p is a constant scaling factor determining the strength of the premium. The maximum value attributed to and the value of p should be chosen such that p ? 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jaccard similarity</head><p>While the edit-based metrics look at what is necessary to do to transform one string into another, the token-based metrics consider the strings as sets of tokens (i.e. the words or characters composing the strings) and search for the common tokens between two sets. A widely-used token-based similarity metric is the Jaccard similarity which is defined as the ratio of the intersection over the union of the token's sets A = {a 0 , a 1 , a 2 , . . . , a m } and B = {b 0 , b 1 , b 2 , . . . , b m } for the two strings a and b respectively (sometimes referred to as IoU -Intersection over Union), i.e.</p><formula xml:id="formula_7">S Jac = |A ? B| |A ? B| . (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>Notice that the Jaccard metric does not take into account the order of tokens, unlike the previously discussed edit-based metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Token Set Ratio</head><p>Another approach for string matching is represented by the approximate string matching algorithms <ref type="bibr" target="#b16">(Navarro, 2001</ref>) that leverage the basic notions of distance introduced so far, but take into account matching also at substring level. In particular, we make use of the so-called Token Set Ratio metric computed via TheFuzz Python library. It works as follows:</p><p>1. takes the unique words (i.e. substrings separated by whitespaces) for each string a and b, let us call them W a and W b , respectively: 2. builds the following word sets:</p><formula xml:id="formula_9">I ab = W a ? W b , W a\b = W a \ W b , W b\a = W b \ W a ;</formula><p>3. sorts alphabetically the sets and builds new strings s ab , s a\b , s b\a by joining with whitespaces the words in the corresponding (sorted) sets; 4. builds the new strings: c a joining s ab and s a\b with a whitespace, and analogously c b with s ab and s b\a ; 5. compute the similarity as</p><formula xml:id="formula_10">R TS (a, b) = max ? ? ? ? ? R ID (s ab , c a ) R ID (s ab , c b ) R ID (c a , c b ) .<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline classifier</head><p>To build a classifier based on the match algorithms just described, the strings are pre-processed by removing punctuation and capitalising the text. The five string match algorithms listed in Table <ref type="table" target="#tab_0">1</ref> score type range constitute our baseline methods and for each of the 5 string matching score listed in Table <ref type="table" target="#tab_0">1</ref>, we do the following:</p><formula xml:id="formula_11">Levenshtein distance D Lev (a, b) ? [0, max (|a|, |b|)] InDel similarity R ID (a, b) ? [0, 1] Jaro-Winkler similarity S JW (a, b) ? [0, 1] Token Set Ratio similarity R TS (a, b) ? [0, 1] Jaccard similarity S Jac (a, b) ? [0, 1]</formula><p>? pre-process the strings with the cleaning method,</p><p>? applies the selected string match algorithm to each pair of strings in the training dataset,</p><p>? train a Decision Stump -i.e. a Decision Tree with a single node -given as input the score just computed, and as label the match/non-match nature of each pair of strings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Random Forest classifier</head><p>The validity of string similarity algorithms presented so far depends on the use case. Therefore we use a Random Forest classifier which uses the five string match metrics listed in Tab. 1 as input features at the same time.</p><p>The Random Forest pipeline goes as follows:</p><p>? pre-process the strings with the same cleaning method as for the Baseline Trees,</p><p>? for each pair of strings in the training dataset, compute the 5 scores listed in Table <ref type="table" target="#tab_0">1</ref>,</p><p>? extract 2 additional features from each string: the number of characters and the number of words (i.e. substrings split with respect to whitespaces),</p><p>? train a Random Forest classifier with 9 features in input (5 matching scores + 2 ? number of words + 2 ? number of characters), and as label the match/non-match nature of each pair of strings.</p><p>The popular Scikit-Learn Python library <ref type="bibr" target="#b18">(Pedregosa et al., 2011)</ref> is used both for the Decision Stump of the Baseline classifiers and for the Random Forest implementations. The hyperparameters of the Random Forest are set to: max depth=3, n estimators=100, class weight='balanced'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Proposed Approach</head><p>We propose an approach based on Recurrent Neural Networks (RNNs) employing a Siamese strategy <ref type="bibr" target="#b6">(Bromley et al., 1993)</ref>, framing the learning problem as a binary classification of string pairs.</p><p>To keep the format of the input consistent, each string is preprocessed as follows: the strings are padded to a length of 300 chars<ref type="foot" target="#foot_0">2</ref> , using the heavy division sign as placeholder for padding. The string cleaning is in this case limited to the uppercase. The rationale is to leave as much information as possible to the Neural Network model to learn useful patterns. Each string is then tokenised character-wise and one-hot encoded with an alphabet of 63 symbols 3 (i.e. the placeholder plus 62 symbols for capital letters, numbers, punctuation, and whitespace), resulting in a 300 ? 63 input matrix.</p><p>Each input matrix, representing a string, is then processed by an Embedding Model (Figure <ref type="figure" target="#fig_0">1</ref>), composed of a 300 ? 63 embedding matrix (i.e. a matrix whose entries are learned via loss optimisation) followed by an LSTM layer with 16 nodes. Weights sharing is employed during learning between the encoding model of the two strings to force the two encoding models to be identical (which is indeed the origin of the name "siamese"), in such a way as to preserve the symmetry of the problem and to effectively learn a unique representation space for individual strings. Notice that we don't make use of the full sequence of hidden LSTM states (that would be a 300 ? 16 matrix) as output of the LSTM layer -i.e. the embedding representation of individual stringswe instead employ the hidden state corresponding to the last token in the string, that nevertheless implicitly contains information of all the hidden states along the sequence -this is indeed the main feature of RNN models<ref type="foot" target="#foot_2">4</ref> .</p><p>The two encodings thus generated are then employed to compute several vector distances -namely, L 1 , L 2 , L ? , cosine-based distance and the element-wise absolute difference. These results are then fed as inputs to a Feed-Forward Neural Network classifier, composed of two consecutive blocks, each consisting of a dense layer with ReLU activations, batch normalisation, and dropout. The final output is a single neuron with a sigmoid activation function, to get the classification score (Figure <ref type="figure" target="#fig_1">2</ref>).</p><p>Since every operation performed on the inputs has the commutative property, the whole model C s , composed by the ensamble of the encoding model and the prediction model, has commutative property, then given any two input strings a and b, we have C s (a, b) = C s (b, a) by design. Binary Crossentropy is used as loss function, as usual for binary classification tasks. We employ Nadam as optimisation algorithm, with parameter choice ? 1 = 0.8, ? 2 = 0.9 and a fixed learning rate = 10 -4 . Both the Embedding model and the downstream Feed-Forward classifier are implemented in Python via TensorFlow <ref type="bibr" target="#b0">(Abadi et al., 2015)</ref>.</p><p>The rationale for employing a Siamese approach is that of learning a high-level embedding of strings, where the similarity in the embedding space reflects the probability of being instances of the same entity.  <ref type="figure" target="#fig_0">1</ref>) to get a 16-dim vector representation each. These are used to compute several distances: L 1 , L 2 , L?, cosine and the element-wise absolute difference. This information is then concatenated -obtaining a 20-dim vector -and fed to two consecutive blocks, each composed of a dense layer with ReLU activations, batch normalisation, and dropout. The first block has a dense layer with 32 nodes, while the second block has a dense layer with 16 nodes. The final layer is a single neuron with a sigmoid activation function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Active Learning</head><p>In an ideal scenario, a predictive model can be built from labelled data in a fully supervised way: generally speaking, increasing the amount of labelled data improves the generalisation capacity of the learned model. However, in a real-world scenario, the number of labelled instances is often limited: the labelling process is often costly, time-consuming and oftentimes requires high-level domain knowledge. On the other hand, unlabelled data are in general much easier to collect and may be used to improve the predictive performance of the model.</p><p>Formally, in a classification setting, there are:</p><p>? a set of labelled instances (X l , y l ) (where X l represents features and y l denotes the corresponding labels);</p><p>? a set of not-labelled-yet instances X u .</p><p>If the labelling process is cost-effective, one could get the labels y u of not-labelled-yet instances X u , and then use a fully-supervised learning algorithm <ref type="bibr" target="#b23">(Sen et al., 2020)</ref>. In a completely opposite situation, where no additional labels can be collected, or at a prohibitive cost, semi-supervised methods have been proved to be effective (van Engelen and Hoos, 2020).</p><p>Oftentimes, the situation is in the middle: given the available resources, only a limited number of instances can be labelled. How to effectively exploit these labelling resources is the focus of Active Learning <ref type="bibr" target="#b24">(Settles, 2009;</ref><ref type="bibr" target="#b1">Aggarwal et al., 2014;</ref><ref type="bibr" target="#b21">Ren et al., 2022)</ref>: given the limited labelling capability, how to choose the subset X c ? X u to label in order to obtain the maximum performance gain? In practice, X c is chosen and constructed according to some query strategies in a multi-step procedure.</p><p>In our work, we adopt an uncertainty sampling strategy <ref type="bibr" target="#b24">(Settles, 2009)</ref> where, at each step, instances of X u on which the prediction of the most updated model is less certain are selected. These data points are removed from X u , labelled by domain experts and then added to (X l , y l ) in order to train an improved version of the classifier, with the rationale that, since the additional data points are picked near the decision boundary instead of being randomly selected, they contain more valuable information for the model learning.</p><p>Let x i ? X u be an unlabelled instance, we denote with (? i,0 , . . . , ?i,?-1 ) the probabilities estimated by the classifier over the ? classes, such that ? ?i,? = 1. Then, we can define the uncertainty as</p><formula xml:id="formula_12">unc(? i ) = 1 -max ? ?i,? .<label>(10)</label></formula><p>In the case of a binary classification setting (? = 2), it is equivalent to measuring the distance of the positive class predicted probability from 1 2 :</p><formula xml:id="formula_13">unc(? i ) = 1 2 - 1 2 -?i . (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>At each step of the training process, instances of X u are sorted according to the uncertainty defined above and the top B most uncertain samples are added to X l and removed from X u . A classifier is then trained on the updated version of X l .</p><p>Empirical evidence during experiments suggests that using directly the uncertainty defined in Equation ( <ref type="formula" target="#formula_12">10</ref>) is sub-optimal in balancing the exploration and exploitation threshold <ref type="bibr" target="#b4">(Banko and Brill, 2001)</ref>: feeding the learner with only uncertain most samples, especially at the beginning, could result in a batch of data too biased towards difficult instances, leading to poor generalisation capability. To prevent this, and alternatively to the strategy introduced by Banko and Brill (2001) -i.e. using batches composed of half of samples selected randomly and the other half selected on the basis of uncertainty -we propose to use the following noisy version of uncertainty:</p><formula xml:id="formula_15">unc ? (? i ) = unc(? i ) + i , i ? N (0, ?),<label>(12)</label></formula><p>where i are independent and identically distributed normal random variables and ? denotes the level of the noise we would like to introduce. The random noise introduced in Equation ( <ref type="formula" target="#formula_15">12</ref>) helps the learner to generalise better during the first stages of the Active Learning procedure.</p><p>In Algorithm 1 we formalise the entire procedure described above, while Figure <ref type="figure" target="#fig_2">3</ref> shows an illustrative representation.</p><p>Algorithm 1: Active Learning Procedure input : X 0 l (initial labelled instances) y 0 l (labels relative to X 0 l ) X 0 u (initial unlabelled instances) M (number of iterations) B 1 , B 2 , . . . , B M -1 (batch sizes) ? (noise for uncertainty) output: a trained classifier C M Train an initial classifier C 1 on (X 0 l , y 0 l ) for j = 1, . . . , M -1 do // Predict the probabilities over the instances, according to equation</p><formula xml:id="formula_16">(3) {? = C j (x) | x ? X j-1 u } // Compute unc? for each point in X j-1 u</formula><p>according to equations (11) and ( <ref type="formula" target="#formula_15">12</ref>)</p><formula xml:id="formula_17">unc?(?) = 1 2 -1 2 -? + // Select from X j-1</formula><p>u the B j instances with highest unc? X j c ? top B j instances with respect to unc? // Label the selected instances y j c ? domain expert labels relative to X j c // Update the set of labelled instances</p><formula xml:id="formula_18">X j l ? X j-1 l ? X j c y j l ? y j-1 l ? y j c // Update the set of unlabelled instances X j u ? X j-1 u \ X j c</formula><p>Train a classifier C j+1 on (X j l , y j l ) end Result: C M</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Data</head><p>The data employed in our analysis are extracted from two different domains, i.e. company registry and bank transfers. More specifically, the data consist of couples of strings being:</p><p>1. the company names (concatenated with the address) of the same entity as recorded in two different datasets obtained by external data providers. 2. the beneficiary names of the same entity as recorded in SWIFT<ref type="foot" target="#foot_3">5</ref> bank transfers.</p><p>The two sources are used independently, with the first used for training and testing and the second only for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data labelling</head><p>Each instance of the datasets used in the experiments consists of a pair of names and a binary target variable: we use the label 1 when the pair of names correspond to the same company, and label 0 otherwise. As stated in previous sections, the labelling process is time-consuming since it involves the identification of raw data usually with human annotation. To tackle this task, we adopt a 2-step strategy: we pre-label some couples of names with a rule-based criterion suggesting the target variable (match/non-match), and then we check the suggested labels manually. The rule to pre-label company string pairs is based on the domain of data we are considering.</p><p>Pre-labelling for company registry data Many companies are identified through the Legal Entity Identifier (LEI): aliases with the same LEI refer to the same company entity. We leverage this background to identify candidate couples with positive labels (same LEI) or with negative labels (different LEI). At the end of this process, these suggested labels are manually validated. We label 9,000 couples of names from the company registry data (with a 1:4 positive/negative label ratio). Figure <ref type="figure" target="#fig_4">4a</ref> displays the distribution of JW similarity relative to the 9,000 couples conditioned on the label matching.</p><p>It is worth noting that the pre-labelling strategy based on the LEI code goes beyond the simple string similarity between company names. Indeed, the LEI code can be used to identify named entities even when they undergo various types of legal transactions, such as mergers, acquisitions, consolidations, purchases and management acquisitions. In this case, the company name can vary after the legal transaction, while still referring to the same entity. Of course, these counter-intuitive positive matches are beyond the range of validity of the methods we are discussing in this workbased solely on the similarity of string names -but we decided to include some of them to test their limits. We discuss some of these examples in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-labelling strategies for bank transfer</head><p>In a bank transfer, funds are transferred from the bank account of one entity (the sender or payer) to another bank account (of the beneficiary or recipient). Beneficiaries with the same bank account (IBAN) refer to the same company and can be used to identify candidate couples with a positive label. More challenging is the construction of couples with negative labels, identified by recipients with different IBAN. The reason is that the same company may own more than one IBAN, and this requires a more detailed validation. With this strategy, we label 200 couples from the bank transfers (with a 1:1 positive/negative labels ratio).</p><p>We keep these data separate from the previously discussed 9,000 pairs, and we use them only for testing purposes, with the rationale of verifying the robustness of our approaches under domain shift scenarios (see Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Training and test sets</head><p>We adopt a stratified k-fold approach to split the data: we split the 9,000 labelled instances into 3 subsets S 1 , S 2 , and S 3 with equal size and taking care to maintain the same positive/negative ratio. At each iteration, we choose one of them as the test set S test and keep the union of the rest as a training set S L train .  From S L train we sample 1 3 of its elements to form a medium size training set S M train , and then we again sample 1 20 of instances contained in S M train to obtain a small size training set S S train . Therefore, we end with 3 training sets for each fold: S S train ? S M train ? S L train . These 3 training sets with increasing size are useful to analyse how the different approaches perform in relation to the amount of data they are given to learn from (see experiments described in Section 6 and the corresponding discussion in Section 7).</p><p>Analogously, we define different test sets: the randomly ordered test set S RO test = S test (i.e. the entire hold-out set available), and the JW ordered test set S JO test obtained by ranking S RO test instances according to their JW similarity<ref type="foot" target="#foot_4">6</ref> and taking the top 100 negative cases (i.e. non-matching pairs that are nevertheless mostly JW-similar) and the bottom 100 positive cases (i.e. matching pairs that are nevertheless mostly JW-dissimilar). The distribution of JW similarity of samples in S JO test conditioned on matching labels is shown in Figure <ref type="figure" target="#fig_4">4b</ref>.</p><p>To test the robustness of the methods presented in Section 3, we introduce a third test set S DS test in addition to S RO test and S JO test , extracted from a different data source. Namely, as anticipated at the beginning of Section 5, we extract pairs of company names from SWIFT bank transfer registry, where transaction payers write the beneficiary without any form of oversight. The dataset is balanced, with 100 positive examples obtained by matching recipients with the same IBAN and 100 negative cases obtained by random matching. We name this dataset the domain shifted test set.</p><p>We expect the S JO test and S DS test test sets to be particularly challenging for the string matching algorithms given in Section 3: indeed S JO test is, by design, a stress test for the single-feature based methods, and it can be used to estimate how effectively the Random Forest and the Siamese Network are able to generalise with respect to the baselines. The S DS test dataset instead is likely to be challenging for several reasons: it is drawn from a different dataset with respect to the training set; not only the beneficiary names may be affected by typos and all sorts of noise due to the free writing, but they are also not in a standardised form, i.e. they may contain additional information such as the company address<ref type="foot" target="#foot_5">7</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>Different modelling strategies (string distance metrics, Deep Neural Networks, Active Learning) have different (dis)advantages. In order to compare them fairly and point out the best scenario in which to apply each of them, we prepare two different experimental settings:</p><p>1. standard supervised classification setting, 2. Active Learning setting.</p><p>In each of these two settings, we run the experiments employing a 3-fold cross-validation strategy as described in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Supervised classification setting</head><p>We evaluate how the performances of the models presented in section 3 change as they are trained on training sets of different sizes (S L train , S M train and S S train ). Each of the training sets is used to train each of the following 7 models:</p><p>? 5 different Baseline Trees (see Section 3), based on Levenstein distance (D Lev ), InDel ratio (R ID ), Token Set Ratio (R TS ), Jaccard similarity (S Jac ), and JW similarity (S JW );</p><p>? a Random Forest classifier, introduced in Section 3.2;</p><p>? our proposed Siamese Network, introduced in Section 3.3.</p><p>Out-of-sample performance is evaluated on test sets S RO test , S JO test , and S DS test by computing the Balanced Accuracy (BA), thus giving equal weights to positive and negative classes, irrespective of actual class imbalances. More precisely, as argued in <ref type="bibr" target="#b8">Chicco et al. (2021)</ref>, BA is a good measure -preferable over, e.g. Matthews Correlation Coefficient (MCC) and F 1 score -when the aim is to compare classifiers across datasets with different class imbalances, and/or when the focus is to correctly classify the ground truth instances, which is exactly what we are doing.</p><p>Table <ref type="table" target="#tab_1">2</ref> summarises experimental results discussed in Section 7. We leave to Table <ref type="table">B</ref>.4 in the appendix additional metrics computed for the experiments (F 1 score and MCC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Active Learning setting</head><p>We then employ an Active Learning strategy -outlined in Section 4 and Algorithm 1 -to train both the Random Forest and the Siamese Neural Network. In our experiments, the initial labelled instances (X 0 l , y 0 l ) consist of 100 samples and correspond to S S train , while X 0 u consista of the residual 5900 couples, namely S L train \ S S train . We fix the ? parameter at 1/6 for all the experiments. The batch sizes are set in such a way that all instances are spanned with M = 9 iterations. More formally, for j = 1, 2, . . . , M -1, the batch size at the j-th iteration is</p><formula xml:id="formula_19">B j = ? ? ? ? ? 100 ? 2 j-1 j ? [1, 4], 800 j = 5, 6, 1400 j &gt; 6.</formula><p>This choice is motivated by the idea of better tracking the impact of the Active Learning approach: indeed, we expect the greater benefits to come in the very first phases, while the marginal benefit after having seen enough data will be negligible.</p><p>As mentioned in Section 4, the choice of the subset of unlabelled instances to be labelled (X j c ) lies at the heart of the Active Learning strategy. To benchmark this procedure, besides the Least Confident learner (LC) selecting X j c according to the uncertainty (Equation ( <ref type="formula" target="#formula_15">12</ref>)), we run the same experiment with a Random learner (R) picking the unlabelled samples in a purely random fashion. Therefore, we end up with a total of four learners. At the end of each iteration j, we evaluate their performance as follows:</p><p>1. pre-train batch test: we test the model C j on the next-to-be-labelled instances, i.e. X j c : we here expect poor results for the LC learners, since we are testing on most uncertain samples for the model C j (see Figure <ref type="figure" target="#fig_6">5a</ref>). 2. We train with respect to the new training set (X j l , y j l ), thus obtaining C j+1 . 3. We test C j+1 on:</p><p>? the batch samples X j c , and we refer to it as the post-train batch test (see Figure <ref type="figure" target="#fig_6">5b</ref>): we here expect good results, since it is an in-sample valuation; ? the updated unlabelled set X j u , i.e. all the remaining unlabelled instances, and we refer to it as the not-labelled-yet test (see Figure <ref type="figure" target="#fig_6">5c</ref>); ? the actual test set, namely S RO test (see Figure <ref type="figure" target="#fig_6">5d</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussion</head><p>Table <ref type="table" target="#tab_1">2</ref> summarises the results of the experiments in terms of BA. The following is a list of insights we can derive from its inspection.</p><p>The Random Forest model trained on the small dataset S S train has a good performance on the randomly ordered test set S RO test . This is likely due to the fact that the input features -described in Section 3.2 -are essentially string similarity measures, thus the pattern to be learned does not need a lot of observations. The downside is poor generalisation when more data are provided. Indeed, by increasing the training set size from S S train to S M train , less than 2% of BA is gained on the randomly ordered test set and no gain at all from S M train to S L train . Moreover, its performance drops by ? 27% and ? 24% in the JW ordered test and the domain shifted test, respectively.</p><p>The same thing is true -even more so -for the JW based classifier. In this case, the decision tree needs only to perform an optimal choice of the threshold to put on the JW similarity score. We can expect that the increase in size of the training set is only slightly changing this threshold, with a negligible impact on the out-of-sample performances. Then we can deduce that JW metric does not tend to overfit his domain and can generalise with acceptable performances. The same reasoning can be applied to the other string match models. In particular, the InDel ratio and the Token Set Ratio perform remarkably well with a small amount of data, again due to the simple rule to be learned by the classifier. Concerning the JW model, we can observe a poorer generalisation to new domains.</p><p>It is worth noticing that the drop in performance for the Baseline classifiers when switching from S RO test to S JO test and S DS test is slightly larger than for the Random Forest. This is reasonable given that the Random Forest may use the information coming from all of the similarity metric scores at the same time.</p><p>The Siamese model systematically outperforms other approaches on both medium and large training datasets. This demonstrates the ability of the Neural Network to avoid overfitting to the specific domain, to generalise across different distributions, and to learn an alias associated with a company that may differ significantly from a simple string match similarity (e.g. the pair "REF SRL" and "RENOVARE ENERGY FARM SRL").</p><p>Table <ref type="table" target="#tab_2">3</ref> shows several examples of matching and non-matching couples of company string names as they are classified by the Siamese model trained on S L train , with the corresponding estimated probability ?. In particular, the examples in Table <ref type="table" target="#tab_2">3</ref> are extracted by drawing from non-matching couples with high JW similarity, and from matching couples with low JW similarity. In this way, we expect to highlight some interesting and challenging sample couples. Indeed, one can see that the Siamese model is able to correctly classify company names expressed as acronyms (e.g. in "S.P.I.G.A." and "REF"). On the other hand, there are cases more difficult to explain, such as the correctly classified match for the couple ("RONDA", "TORO ASSICURAZIONI SPA") where the entity is indeed the same -TORO insurance actually merged into RONDA in 2004<ref type="foot" target="#foot_6">8</ref> but the company names are completely different. Further work is needed to explain the reasons behind such counter-intuitive matches of the Neural Network, and to find the patterns behind such classifications.</p><p>We reported false positive examples where the names are very similar but they actually belong to different companies, e.g. "E.U.R.O. S.R.L." and "EURO STEEL SRL/MILANO". The overconfidence of the prediction could be solved, e.g. by incorporating additional information, such as address, holding and legal form of the two companies.</p><p>As expected, most of the false negative samples -i.e. pairs representing the same entity but predicted to be non-matching -in Table <ref type="table" target="#tab_2">3</ref> can be related to situations in which the company names are (almost) completely different, but the entity is indeed the same, likely due to some legal transaction (merger, acquisition, consolidation, etc.) as discussed in Section 5.1.</p><p>Finally, the true negative examples show the remarkable capabilities of the Siamese model to correctly classify as different entities even pairs with very similar company names, such as "RECOS S.R.L." and "PECOS SRL", with very high confidence.</p><p>Figure <ref type="figure" target="#fig_6">5d</ref> shows the out-of-sample BA of the Siamese Network and the Random Forest when computed on S RO test at each Active Learning step. We can easily see that the Least Confident approach systematically outperforms the random choice for both models, confirming the value of Active Learning. However, while the Random Forest performance plateaus already before 400 samples, the Siamese needs up to 2,000: the Siamese Network has to leverage a larger amount of data to effectively learn patterns.</p><p>Figures 5a-5b can help us understand the mechanisms at play. Figure <ref type="figure" target="#fig_6">5a</ref> displays out-of-sample BA values on next-to-be-labelled batches: we expect poor performance for the Least Confident choice with respect to Random choice since in the former case we are selecting uncertain instances (i.e. difficult for the model) on purpose. Figure <ref type="figure" target="#fig_6">5b</ref>, on the other hand, displays BA values on batches just fed to the models: we here expect -in general -higher performances, being an in-sample evaluation. Interestingly, we see that the Least Confident choice has poor performance with respect to Random choice. This may be due to the fact that (at least a fraction of the) most uncertain observations remain indeed intrinsically difficult to classify, despite the training. This effect is more pronounced for the Random Forest, likely because it is largely based on similarity metrics. Notice that, as the number of samples seen by the model increases, this effect is less and less pronounced and finally reverts, indicating that residual samples are becoming easier to classify in the Least Confident approach.</p><p>Incidentally, we notice that comparing the performances of the model on a batch before and after the model has been trained on it, allows to define an early stopping rule. Namely, calling Acc pre and Acc post the BA of a model over a batch before and after it has been trained on it, respectively, we can define a threshold ? and interrupt the process when: |Acc post -Acc pre | &lt; ?. The rationale is that, if a model has about the same performances on a batch before and after having been trained on it, it means that it has already learned to generalise over unseen data. This rule can be applied, with an appropriate ?, both on the Least Confident and Random algorithm.</p><p>Finally, Figure <ref type="figure" target="#fig_6">5c</ref> shows the out-of-sample BA when computed on X u (i.e. all the unlabelled samples of the training set at that step) at each step of Algorithm 1. This plot confirms that the Least Confident approach chooses the instances in such a way that the remaining ones are simpler to be classified. This is especially true for Random Forest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>In our analysis, we have compared the performances of several supervised classifiers in the field of company name disambiguation.Providing pairs of company names as input, we consider two types of Machine Learning classifiers: Decision Stumps and Random Forest classifiers based on classical string similarity measures between the two names; a Neural Network classifier on top of a learned LSTM embedding space of strings.</p><p>The data are extracted from external company registry data and bank transfers. More specifically, we collect 9,000 couples of company names from external company registry data, and 200 couples of beneficiary names in bank transfers (the latter used only for testing purposes). All approaches are evaluated over three different test sets: a "randomly ordered" test set (RO), i.e. 3000 samples randomly chosen from the company registry dataset, a "Jaro-Winkler ordered" test set (JO), i.e. 200 instances drawn from RO in such a way that we select JW-dissimilar actual matches and JW-similar actual non-matches, and a "domain shift" test set (DS), i.e. 200 couples of beneficiary names taken from a (different) dataset of bank transfers.</p><p>The purpose of this work is twofold: on the one hand, we show that if enough data is available, the Siamese approach outperforms the other models and can be applied to other domains. Indeed, according to Table <ref type="table" target="#tab_1">2</ref>, the performance of the Baseline methods and the Random Forest barely improves when more data are provided for training. This is likely due to the fact that all the information extracted from string pairs is encoded in classical string similarity metrics for Baseline Trees and Random Forest.</p><p>On the contrary, increasing the size of the training set improves the performance of the Siamese model, as it can learn a more effective embedding space the more data it learns from. This demonstrates the Neural Network's capacity to generalise while avoiding overfitting to a specific domain. These features enable our Siamese Neural Network to learn its own concept of string similarity and appropriately detect aliases connected with a company that differ significantly from a basic string match similarity.</p><p>The other goal of our research is to demonstrate how to make human labelling more efficient by using an Active Learning strategy. Indeed, starting with a minimal training set of 100 labelled data, we show that training the model with subsequent batches of the most uncertain samples (Least Confident learner) is more efficient than training with randomly chosen instances.</p><p>One limitation of this work is the use of company names only for the goal of disambiguation. As previously said, it is possible that company names by themselves do not contain enough information to resolve all the matches, as in cases where completely different company names still refer to the same Entity. We leave to future work the extension to include additional information, such as addresses, legal forms, shareholding, etc. We also plan to perform a more thorough analysis of the architecture of the Siamese Recurrent Network, possibly using a Transformer approach for the input sequences <ref type="bibr" target="#b27">(Vaswani et al., 2017)</ref>. Given the effectiveness of the Active Learning procedure, we plan to use an unlabelled dataset of hundreds of thousands of Entity pairs to extract from them the most informative few thousand pairs to label, to analyse how the procedure here outlined scales with data availability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>deviation, respectively.</head><p>As can be seen from Figure A.6, the number of characters and the number of words of the two company names have negligible importance on the classifier. In particular, these features become less and less significant as more data are supplied for training. JW similarity is the most important feature used by the Random Forest classifier: the Random Forest trained on S S train attributes 40% of importance to JW similarity, and this further increases as the classifier is trained on more data, reaching almost 50% for the classifier trained on S L train . The importance of the remaining features does not change much with the training set size, with a contribution of ? 30% for the Token Set Ratio, ? 20% for the InDel ratio, ? 4% for the Levensthein, and ? 1% for the Jaccard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Supervised classification performances</head><p>As discussed in Section 6, Table <ref type="table" target="#tab_1">2</ref> shows the out-of-sample BA on the test sets S RO test , S JO test , and S DS test . The BA ensures a correct evaluation of the classifiers' performance by weighting the accuracy of the classifier on each class by the number of observations in that class. This gives a more accurate picture of the classifier's performance in each class, even when the classes are imbalanced.</p><p>Along with BA, other metrics are commonly used to assess the quality of a model; here we will discuss F 1 score and MCC. F 1 score is a very popular metric in the Machine Learning community since it combines precision and recall -often two paramount aspects for model evaluationinto a single metric. Indeed, it is defined as the weighted average of precision and recall. MCC is instead a measure of the correlation between predicted and actual binary class labels and it ranges between -1 -indicating a total disagreement between prediction and observation -and 1, indicating a perfect prediction. While the F 1 score and MCC consider both precision and recall, BA is the average of the recall over all classes. Therefore, also according to <ref type="bibr" target="#b8">Chicco et al. (2021)</ref>, BA may be preferable when correctly classifying the ground truth instances (recall) is more important then making correct predictions (precision).</p><p>For completeness, in Table <ref type="table">B</ref>.4 we extend the results of Table <ref type="table" target="#tab_1">2</ref> by including the F 1 score and the MCC.</p><p>Results from these additional metrics largely confirm the ones discussed for BA, namely the fact that the Siamese Network approach systematically outperforms all other methods as long as enough data are provided for learning. This is especially true for the most difficult test sets, namely  ). Mean values and corresponding standard deviation (in brackets) computed via stratified k-fold cross-validation approach are reported for all metrics. Contrary to the 5 baseline models, the Random Forest and the Siamese Neural Network performances improve with the size of the training set. Moreover, the Siamese Neural Network trained on medium and large datasets outperforms all other approaches. For each of the three metrics, bold figures are row-wise maximum values.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Embedding model. Schematic TensorFlow representation of the Embedding model described in Section 3.3. Each block denotes a TensorFlow layer, with input and output tensor dimensions. As usual in TensorFlow representations, the generic batch size is denoted with the symbol '?'.</figDesc><graphic url="image-1.png" coords="9,192.73,111.11,209.81,228.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Siamese architecture. Two input strings are processed by the same LSTM-based encoding model (see Figure1) to get a 16-dim vector representation each. These are used to compute several distances: L 1 , L 2 , L?, cosine and the element-wise absolute difference. This information is then concatenated -obtaining a 20-dim vector -and fed to two consecutive blocks, each composed of a dense layer with ReLU activations, batch normalisation, and dropout. The first block has a dense layer with 32 nodes, while the second block has a dense layer with 16 nodes. The final layer is a single neuron with a sigmoid activation function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Active Learning. Illustrative representation of the Active Learning procedure outlined in Algorithm 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Distribution of similarity over all string pairs. (b) Distribution of similarity on JW-ordered test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Similarity distribution over string pairs. Distribution of JW similarity conditioned on the label matching over (a) the 9,000 labelled instances and (b) JW-ordered test set. The continuous score is binned with size 0.05. In (a)the histogram shows that the negative (i.e. non-matching) samples are roughly normally distributed around 0.55, while the majority of positive (i.e. matching) samples have JW similarity between 0.8 and 1. In (b), on the contrary, the distributions of positive and negative pairs are largely overlapping, making it difficult to determine a threshold between the two classes, in particular with respect to the whole dataset.</figDesc><graphic url="image-2.png" coords="14,87.83,111.11,209.81,157.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Active Learning: pre-train batch test. (b) Active Learning: post-train batch test. (c) Active Learning: not-yet-labelled test. (d) Active Learning: randomly ordered test.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Active Learning performances. BA during the Active Learning procedure computed over: (a) next-to-be-labelled instances (X j-1 c ), (b) just-labelled instances (X j-1 c ), (c) all the remaining unlabelled instances (X j-1 u ), (d) the test set S RO test , as described in Section 6.2. On the x-axis we plot the number of labelled samples (log scale), starting from |X 0 l | = 100 up to |X M -2 l | = 4600 -i.e. before adding the remaining B M -1 samples in the last iteration. In the post-train case (b), the evaluation starts from |X 1 l | = 200 (i.e. after adding the first B 1 samples) up to the whole training dataset |X M -1 l | = 6000. The evaluation over S RO test (d) is done in all available steps, i.e. from 100 up to 6000 samples. BA of Random Forest and Siamese Network models both as Random learners and as Least Confident learners is reported. The mean and 95% normal confidence intervals are obtained by aggregating the BA over the 3 cross-validation folds.</figDesc><graphic url="image-6.png" coords="17,87.83,282.41,209.81,157.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>List of metrics used as features in the Baseline and Random Forest classifier.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Experimental results. Balanced Accuracy of the Random Forest, Siamese Neural Network, and the 5 singledistance Decision Trees, all trained with datasets of different sizes (small, medium, large) and tested on the three test sets discussed in Section 5.2, namely randomly ordered (S RO test ), JW-ordered (S JO test ) and domain shifted (S DS test ). Mean and standard deviation computed via stratified k-fold cross-validation are displayed. Contrary to the 5 baseline models, the performances of the Random Forest and the Siamese Neural Network improve with the size of the training set. Moreover, the Siamese Neural Network trained on medium and large datasets outperforms the other approaches. Bold figures denote row-wise maximum values.</figDesc><table><row><cell>training set size</cell><cell>test set type</cell><cell>Levenshtein</cell><cell>InDel Ratio</cell><cell>Token Set Ratio</cell><cell>Jaccard</cell><cell>JW</cell><cell>Random Forest</cell><cell>Siamese Network</cell></row><row><cell></cell><cell>RO</cell><cell cols="7">0.665 ? 0.045 0.855 ? 0.025 0.935 ? 0.005 0.577 ? 0.09 0.957 ? 0.003 0.951 ? 0.017 0.892 ? 0.042</cell></row><row><cell>small</cell><cell>JO</cell><cell cols="4">0.428 ? 0.061 0.505 ? 0.005 0.662 ? 0.006 0.438 ? 0.06</cell><cell cols="3">0.678 ? 0.016 0.678 ? 0.018 0.725 ? 0.044</cell></row><row><cell></cell><cell>DS</cell><cell>0.582 ? 0.05</cell><cell cols="4">0.717 ? 0.01 0.723 ? 0.015 0.533 ? 0.058 0.717 ? 0.003</cell><cell cols="2">0.718 ? 0.02 0.735 ? 0.013</cell></row><row><cell></cell><cell>RO</cell><cell cols="7">0.643 ? 0.014 0.878 ? 0.013 0.944 ? 0.007 0.523 ? 0.041 0.957 ? 0.003 0.965 ? 0.006 0.975 ? 0.002</cell></row><row><cell>medium</cell><cell>JO</cell><cell cols="7">0.473 ? 0.038 0.488 ? 0.029 0.652 ? 0.003 0.463 ? 0.064 0.675 ? 0.013 0.697 ? 0.013 0.867 ? 0.019</cell></row><row><cell></cell><cell>DS</cell><cell cols="3">0.535 ? 0.009 0.735 ? 0.009 0.743 ? 0.003</cell><cell>0.5 ? 0.0</cell><cell>0.715 ? 0.0</cell><cell cols="2">0.743 ? 0.008 0.773 ? 0.016</cell></row><row><cell></cell><cell>RO</cell><cell cols="4">0.641 ? 0.012 0.871 ? 0.014 0.944 ? 0.007 0.523 ? 0.04</cell><cell cols="3">0.956 ? 0.001 0.967 ? 0.004 0.976 ? 0.002</cell></row><row><cell>large</cell><cell>JO</cell><cell>0.495 ? 0.0</cell><cell>0.5 ? 0.0</cell><cell cols="3">0.652 ? 0.003 0.465 ? 0.061 0.687 ? 0.006</cell><cell cols="2">0.72 ? 0.023 0.903 ? 0.051</cell></row><row><cell></cell><cell>DS</cell><cell>0.53 ? 0.0</cell><cell cols="2">0.733 ? 0.012 0.743 ? 0.003</cell><cell>0.5 ? 0.0</cell><cell>0.715 ? 0.0</cell><cell cols="2">0.743 ? 0.003 0.777 ? 0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Representative examples. Illustrative examples of results of the Siamese Neural Network trained on the large training set S L train . Predicted matches/non-matches are shown (together with the positive class predicted probability ?) for actual matching and non-matching pairs. The examples ( a b ) are selected from the randomly ordered test set S RO test (i.e. from the external company registry datasets). The specific model used to obtain these examples incorrectly classifies the 1.17% of the positive cases and the 0.96% of the negative cases tested.</figDesc><table><row><cell></cell><cell></cell><cell>Predicted positives (? ? 0.5)</cell><cell>Predicted negatives (? &lt; 0.5)</cell><cell></cell></row><row><cell></cell><cell>?</cell><cell>company name pairs ( a b )</cell><cell>company name pairs ( a b )</cell><cell>?</cell></row><row><cell></cell><cell>0.97</cell><cell>S.P.I.G.A. S.R.L. SPIGA-SOCIETA' PRODUZIONE E IMPORTAZIONE GENERALI ALIMENTARI-SRL</cell><cell>FOGLIATA S.P.A. EDILCOS SRL</cell><cell>0.006</cell></row><row><cell></cell><cell>0.69</cell><cell>REF SRL RENOVARE ENERGY FARM SRL</cell><cell>CREARE IN FOSSATO SRL IN LIQUIDAZIONE WALD SRL</cell><cell>0.001</cell></row><row><cell>same entity</cell><cell>0.94</cell><cell>RONDA TORO ASSICURAZIONI SPA</cell><cell>UNIEURO S.P.A. SGM DISTRIBUZIONE SRL</cell><cell>0.002</cell></row><row><cell>(y = 1)</cell><cell>0.88</cell><cell>SEAWAYS AGENZIA MARITTIMA LE NAVI-SEAWAYS SRL</cell><cell>MANUFATTI EPIS SRL EPIS SANTINO SNC DI EPIS STEFANO EC</cell><cell>0.02</cell></row><row><cell></cell><cell>0.77</cell><cell>TOSCOSERVICE LOGSTICA E SEVIZI SOCIETA' COOPERATIVA IL GIRASOLE 2002-SC</cell><cell>DEA S.R.L. UNENDO ENERGIA SUD SRL</cell><cell>0.001</cell></row><row><cell></cell><cell>0.99</cell><cell>ARGO S.R.L. ARGO SAS DI DI BIAGI FILIPPO</cell><cell>GIULIANO VINCENZA G&amp;P SRL</cell><cell>0.05</cell></row><row><cell></cell><cell>0.99</cell><cell>E.U.R.O. S.R.L. EURO STEEL SRL/MILANO</cell><cell>EMMA SRL GEMMA SRL</cell><cell>0.07</cell></row><row><cell></cell><cell>0.91</cell><cell>G.T.M. S.R.L. GMC-SRL</cell><cell>SMV COSTRUZIONI SRL RM COSTRUZIONI SRL</cell><cell>0.001</cell></row><row><cell>different entity</cell><cell>0.56</cell><cell>MARPER S.R.L. MAVIT SRL</cell><cell>RECOS S.R.L. PECOS SRL</cell><cell>0.002</cell></row><row><cell>(y = 0)</cell><cell>0.71</cell><cell>MEA S.R.L. MAR -ALEO SRL</cell><cell>TEXERA SRL TER SRL</cell><cell>0.2</cell></row><row><cell></cell><cell>0.88</cell><cell>NUOVA REKORD S.R.L. NOVA LUX SRL/VERONA</cell><cell>MEPRA SPA PELMA SPA</cell><cell>0.02</cell></row><row><cell></cell><cell>0.99</cell><cell>FARMACIA WAGNER FARMACONSULT SRL</cell><cell>ALIMA SRL DALMA SRL</cell><cell>0.08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table B.4: Experimental results. Extension of Table 2. Balanced Accuracy (BA), F 1 -score and Matthews correlation coefficient (MCC) for the Random Forest, Siamese Neural Network, and for the 5 single-distance Decision Trees, all trained with datasets of different sizes (small, medium, large) and tested on the three test sets discussed in Section 5.2, namely randomly orderd (S RO test ), JW-ordered (S JO test ) and domain shifted (S DS test</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The longest string in our whole dataset has 124 chars. If longer strings are to be fed to the model, then a truncation to</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="300" xml:id="foot_1"><p>is implemented.3 Another possible approach is using the entire word as a single token. Experiments using this approach resulted in poor performances, because the model cannot properly handle cases of spelling errors or abbreviations</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We experimented the same architecture with a Bidirectional LSTM layer in place of a plain LSTM layer, but without any sign of improvement in performance, while on the other hand, the computational cost increased significantly.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Society for Worldwide Interbank Financial Telecommunications.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>As reported in the experiments (see Table2), the JW method performs better compared to the other baseline methodologies. Therefore, selecting test instances based on this metric is a way to check the robustness of ML approaches.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>This motivates the use of names and address in the data extracted from company registry data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>gazzettaufficiale (GU Parte Seconda n.83 del 8-4-2004).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Ilaria Penco</rs> for her assistance with the legal aspects of the manuscript. We thank <rs type="person">Andrea Barral</rs> for useful discussions on methodology and data curation. We also thank <rs type="person">Giacomo Di Prinzio</rs>, <rs type="person">Giulia Genta</rs> and <rs type="person">Nives Visentin</rs> from <rs type="person">Intesa Sanpaolo</rs>, and <rs type="person">Sandro Bellu</rs>, 20 <rs type="person">Indrit Gjonaj</rs>, <rs type="person">Andrea Giordano</rs> and <rs type="person">Gabriele Pellegrinetti</rs> from Tecnet Dati s.r.l., namely the team that developed the disambiguation project for <rs type="person">Intesa Sanpaolo</rs>, that inspired the research here presented.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Ranfom Forest feature importance</head><p>In this appendix, we analyse the importance of the features used by the Random Forest classifier. Decision trees are used to divide data into relevant categories based on optimal splits. As a measure of how far the model deviates from a pure division, Gini impurity calculates the likelihood that a randomly selected example will be erroneously categorised by a certain node. The Random Forest technique computes feature significance using the mean decrease impurity (MDI) or Gini importance, which is defined as the total node impurity weighted by the likelihood of reaching that node and averaged over all trees in the ensemble. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The bar plots in</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Man?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/.softwareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Active learning: A survey</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Data Classification. Chapman and Hall/CRC</publisher>
			<biblScope unit="page" from="599" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Named entity disambiguation at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aghaebrahimian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cieliebak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IAPR Workshop on Artificial Neural Networks in Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="102" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Active learning for natural language processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Language Technologies Institute School of Computer Science Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scaling to very very large corpora for natural language disambiguation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 39th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural networks for entity matching: A survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barlaug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Siamese neural networks: An overview. Artificial neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chicco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="73" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chicco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>T?tsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jurman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioData mining</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comparison of personal name matching: Techniques and practical issues</title>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth IEEE International Conference on Data Mining-Workshops (ICDMW&apos;06</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="290" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A comparison of string distance metrics for name-matching tasks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>IIWeb</publisher>
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey on semi-supervised learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Engelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-019-05855-6</idno>
		<idno>doi:10.1007/s10994-019-05855-6</idno>
		<ptr target="https://doi.org/10.1007/s10994-019-05855-6" />
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="373" to="440" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The elements of statistical learning: data mining, inference, and prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deepal: Deep active learning in python</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.15258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">E</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07699</idno>
		<title level="m">End-to-end neural entity linking</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comprehensive benchmark framework for active learning methods in entity matching</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Meduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarwat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1133" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A guided tour to approximate string matching</title>
		<author>
			<persName><forename type="first">G</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="31" to="88" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning text similarity with siamese recurrent networks, in: Proceedings of the 1st Workshop on Representation Learning for NLP</title>
		<author>
			<persName><forename type="first">P</forename><surname>Neculoiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Versteegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rotaru</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="148" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">TF-IDF Character N-grams versus word embedding-based models for fine-grained event classification: a preliminary study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Piskorski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jacquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Automated Extraction of Sociopolitical Events from News 2020</title>
		<meeting>the Workshop on Automated Extraction of Sociopolitical Events from News 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="26" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The performance of text similarity algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Prasetya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Wibawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advances in Intelligent Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="63" to="69" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey of deep active learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3472291</idno>
		<idno>doi:10.1145/3472291</idno>
		<ptr target="https://doi.org/10.1145/3472291" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Toponym matching through deep neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Murrieta-Flores</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Calado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Geographical Information Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="324" to="348" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Supervised classification algorithms in machine learning: A survey and review</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hajra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Emerging technology in modelling and graphics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="99" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Beyond neural scaling laws: beating power law scaling via data pruning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sorscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Morcos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.14486</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A comparative evaluation of string similarity metrics for ontology alignment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information &amp;Computational Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="957" to="964" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems 30</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.13450</idno>
		<title level="m">A comparative survey of deep active learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A brief introduction to weakly supervised learning</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National science review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
