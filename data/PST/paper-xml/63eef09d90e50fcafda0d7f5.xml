<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LEVER: Learning to Verify Language-to-Code Generation with Execution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ansong</forename><surname>Ni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Srini</forename><surname>Iyer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sida</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Victoria</forename><surname>Xi</surname></persName>
						</author>
						<author>
							<persName><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ver</forename><surname>Prob</surname></persName>
						</author>
						<title level="a" type="main">LEVER: Learning to Verify Language-to-Code Generation with Execution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The advent of pre-trained code language models (CodeLMs) has lead to significant progress in language-to-code generation. State-of-the-art approaches in this area combine CodeLM decoding with sample pruning and reranking using test cases or heuristics based on the execution results. However, it is challenging to obtain test cases for many real-world language-to-code applications, and heuristics cannot well capture the semantic features of the execution results, such as data type and value range, which often indicates the correctness of the program. In this work, we propose LEVER, a simple approach to improve language-to-code generation by learning to verify the generated programs with their execution results. Specifically, we train verifiers to determine whether a program sampled from the CodeLM is correct or not based on the natural language input, the program itself and its execution results. The sampled programs are reranked by combining the verification score with the CodeLM generation probability, and marginalizing over programs with the same execution results. On four datasets across the domains of table QA, math QA and basic Python programming, LEVER consistently improves over the base CodeLMs (4.6% to 10.9% with code-davinci-002) and achieves new state-of-the-art results on all of them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The ability of mapping natural language to executable code is the cornerstone of a variety AI applications such as database interfaces <ref type="bibr" target="#b37">(Pasupat &amp; Liang, 2015;</ref><ref type="bibr" target="#b62">Yu et al., 2018;</ref><ref type="bibr" target="#b46">Shi et al., 2020)</ref>, robotics control <ref type="bibr" target="#b68">(Zhou et al., 2021;</ref><ref type="bibr" target="#b48">Shridhar et al., 2020)</ref> and virtual assistants <ref type="bibr" target="#b0">(Agashe et al., 2019;</ref><ref type="bibr" target="#b25">Lai et al., 2022)</ref>. Recent advances on large language mod- ? Majority of the work done during an internship at Meta AI. * Equal contribution 1 Yale University 2 Meta AI. Correspondence to: Ansong Ni &lt;ansong.ni@yale.edu&gt;, Xi Victoria Lin &lt;victorialin@meta.com&gt;, Sida I. Wang &lt;sida@meta.com&gt;.</p><p>Preprint. Copyright 2023 by the author(s). els (LLMs) <ref type="bibr" target="#b4">(Brown et al., 2020;</ref><ref type="bibr" target="#b56">Wei et al., 2021;</ref><ref type="bibr" target="#b12">Chowdhery et al., 2022)</ref>, especially those pre-trained on code (CodeLMs) <ref type="bibr">(Chen et al., 2021a;</ref><ref type="bibr" target="#b17">Fried et al., 2022;</ref><ref type="bibr" target="#b34">Nijkamp et al., 2022;</ref><ref type="bibr">Li et al., 2022a)</ref>, have shown great promise in such tasks with in-context few-shot learning <ref type="bibr" target="#b45">(Shi et al., 2022;</ref><ref type="bibr">Chen et al., 2022a;</ref><ref type="bibr" target="#b65">Zhang et al., 2022</ref>). Yet their performance is still far from perfect <ref type="bibr">(Chen et al., 2021a)</ref>. Considering the computation cost to finetune such models, it is appealing to explore ways to improve them without changing their parameters.</p><p>A key observation is that while CodeLMs struggles with precision in the few-shot setting, it often produces the correct output when enough samples are drawn. Previous work have shown that majority voting and filtering by test cases can significantly boost their performance when samples are drawn at scale <ref type="bibr">(Chen et al., 2021a;</ref><ref type="bibr" target="#b2">Austin et al., 2021;</ref><ref type="bibr">Li et al., 2022a)</ref>. <ref type="bibr" target="#b43">Shen et al. (2021)</ref> and <ref type="bibr" target="#b13">Cobbe et al. (2021)</ref> further demonstrated the effectiveness of training a verifier and using the verification scores to rerank the candidate solutions for math world problems. Comparing to approaches that solely rely on execution consistency and error pruning, trained verifiers can make use of the rich semantic features in the model solutions, such as data types, value range, and variable attributes, which can be strong indicators of correctness of the programs. While <ref type="bibr" target="#b13">Cobbe et al. (2021)</ref> and subsequent work <ref type="bibr">(Li et al., 2022b;</ref><ref type="bibr" target="#b24">Kadavath et al., 2022)</ref> focus on verifying natural language solutions by LMs, a natural question is whether the same approach can be applied to program solutions.</p><p>In this work, we propose learning to verify (LEVER ? ? ) language-to-code generation by CodeLMs, with the help of execution. More specifically, we train a verifier that learns to distinguish and reject incorrect programs based on the joint representation of the natural language description, the program surface form and its execution result. We further combine the verification probability with the CodeLM generation probability and marginalize over programs with the same execution results. We use this aggregated probability as the reranking score and output the programs that execute to the most probable result.</p><p>We conduct extensive experiments on four different language-to-code benchmarks across domains of text-to-SQL semantic parsing, table QA, math reasoning and basic Python programming. Experiment results with three different CodeLMs show that LEVER consistently improves the execution accuracy of the generated programs. Notably, LEVER coupled with code-davinci-002 improves over strong baselines that use execution error pruning by 4.6% to 10.9%, and achieves the new state-of-the-art results on all four benchmarks, without using task-specific model architecture or prompting methods. Ablation studies show that execution results are crucial for the verification and LEVER also yields non-trivial improvements in lowresource and weakly-supervised settings. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Approach</head><p>We now introduce the detailed formulation and training procedures of LEVER. The key components are illustrated in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Language-to-Code Generation with CodeLMs</head><p>The input for a language-to-code task typically consists of the natural language (NL) description and optionally some programming context (e.g., data stores, assertions and so on). We denote such input as x. Given x, a generation model P (y|x) generates a program y which is later executed via an executor E(?) to obtain the result 2 E(y). For few-shot learning with large LMs, the generation is also often conditioned on a fixed set of m exemplars, {(x i , y i )} i&lt;m . Thus the few-shot language-to-code generation with CodeLMs</p><p>1 We will open source our experiment code for reproducibility: https://github.com/niansong1996/lever.</p><p>2 Some datasets such as Spider <ref type="bibr" target="#b62">(Yu et al., 2018)</ref> require the input values to be generated together with the programs, hence y * is directly executable. Others require the programs to be executable on separately provided test cases, e.g., MBPP <ref type="bibr" target="#b2">(Austin et al., 2021)</ref>. We adopt this notation for simplicity. can be formulated as:</p><formula xml:id="formula_0">P LM (y|x) = P (y| prompt(x, {(x i , y i )} i&lt;m )),<label>(1)</label></formula><p>where prompt(x, {(x i , y i )} i&lt;m ) is a string representation of the overall input. Greedy search is typically used to find the program with the (approximately) highest generation probability, i.e., ?greedy ? arg max y P LM (y|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Reranking of Program Candidates</head><p>The key observation motivating our method is that a reasonably large sample set from P LM (y|x) often includes the correct programs. This suggests that reranking of the program candidates may yield significant result improvement. The idea of discriminative reranking <ref type="bibr" target="#b44">(Shen et al., 2004;</ref><ref type="bibr" target="#b14">Collins &amp; Koo, 2005)</ref> is to learn a scoring function R(x, ?) that measures how likely ? is the best output for input x. Given R(?), the reranker outputs the program with the highest reranking score among the set of candidates S:</p><formula xml:id="formula_1">?rerank = arg max ??S R(x, ?)<label>(2)</label></formula><p>Next we introduce how we adopt a trained verifier to verify and rerank program candidates sampled from CodeLMs such that ?rerank is better than ?greedy .</p><p>Program Sampling from CodeLM. Given input x, instead of performing greedy search, we obtain k programs from P LM (y|x) with temperature sampling, i.e., {? i } k i=1 ? P LM (y|x). As the same programs may be sampled more than once, we perform deduplication to form a set of n unique program candidates S = {? i } n i=1 , where n ? k. We choose to do sampling instead of beam search mainly for two reasons: 1) recent work suggests that beam search for code generation typically results in worse performance due to degenerated programs <ref type="bibr" target="#b2">(Austin et al., 2021;</ref><ref type="bibr" target="#b65">Zhang et al., 2022)</ref>; and 2) beam search is not available or efficiently implemented for all CodeLMs that we test on (e.g., Codex).</p><p>Verification with Execution. We use a simple concatenation of the problem description x, candidate program ? and a representation of its execution results E(?) as the input to the reranker. Inspired by recent work <ref type="bibr" target="#b13">(Cobbe et al., 2021;</ref><ref type="bibr">Li et al., 2022b)</ref>, we parameterize our discriminative reranker as a verification (i.e., binary classification) model P ? (v|x, ?, E(?)), where v ? {0, 1}. In practice, the reranker can be implemented using any binary classification architecture. We report experiments using T5 <ref type="bibr" target="#b40">(Raffel et al., 2020)</ref> and RoBERTa <ref type="bibr" target="#b32">(Liu et al., 2019)</ref> in ?B.1.</p><p>Given an input x and a candidate program ? ? S, we obtain the reranking probability as the joint probability of generation and passing the verification:</p><formula xml:id="formula_2">P R (?, v =1 |x) = P LM (?|x) ? P ? (v =1 |x, ?, E(?)) (3)</formula><p>Execution Result Aggregation. Since programs with the same semantics may have different surface forms, we further aggregate the reranking probability of the programs in S that executes to the same result. In this way, we relax the dependency on the surface form and focus on the execution results instead. The final scoring function for reranking is therefore:</p><formula xml:id="formula_3">R(x, ?) = P R (E(?), v =1 |x) = y?S,E(y)=E(?) P R (y, v =1 |x)</formula><p>Since there might be several programs that share the same execution result of the highest probability, we break tie randomly in this case when outputting the programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Learning the Verifiers</head><p>The previous sections described how to use a verifier at inference time. Next we introduce its training process.</p><p>Training Data Creation. For language-to-code datasets, each example is typically a triplet of (x, y * , z * ), where z * = E(y * ) is the gold execution result and y * is the gold program. As annotating the programs requires domain expertise, for some datasets where the final results can be directly obtained, only z * but no y * is provided for learning <ref type="bibr" target="#b1">(Artzi &amp; Zettlemoyer, 2013;</ref><ref type="bibr" target="#b10">Cheng &amp; Lapata, 2018;</ref><ref type="bibr" target="#b19">Goldman et al., 2018)</ref>. This is known as the weakly-supervised setting. To gather training data, we obtain a set of n unique programs candidates ? = {? i } n i=1 for each input x in the training set, by first sampling k programs from P LM (?|x) and then remove all the duplicated programs, similarly as inference time. Then for each program candidate ? ? S, we obtain its binary verification label by comparing the ex- ecution result ? = E(?) with the gold<ref type="foot" target="#foot_0">3</ref> execution result z * , i.e., v = 1(? = z * ). For the datasets that contain the gold program y * , we append (x, y * , z * , v =1 ) as an additional verification training example, and we skip this step for the weakly-supervised datasets. This way, we create a set of verification training examples {(x, ?i , ?i , v i ) | ?i ? S} for each input x.</p><p>Learning Objective. Given this set of verification training examples, we formulate the loss for input x with the negative log-likelihood function, normalized by the number of program candidates</p><formula xml:id="formula_4">L ? (x, S) = - 1 |S| ? ?i?S log P ? (v i |x, ?i , ?i )<label>(4)</label></formula><p>The normalization step is important to prevent an example with a large number of unique program candidates to dominate learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>We conduct experiments on four language-to-code datasets across domains of semantic parsing, table QA, math reasoning and basic python programming. The main settings of these four datasets are shown in Table <ref type="table" target="#tab_0">1</ref>. More detailed settings for verification are in Table <ref type="table">8</ref> of the Appendix.</p><p>Spider <ref type="bibr" target="#b62">(Yu et al., 2018)</ref> is a semantic parsing dataset on generating SQL queries from natural language questions. With 7k parallel training data, it is also ideal for finetuning generators;</p><p>WikiTableQuestions (WikiTQ) <ref type="bibr" target="#b37">(Pasupat &amp; Liang, 2015</ref>) is a table question answering dataset, for which we attempt to solve by generating and executing SQL queries over the source tables. We use the preprocessed tables from <ref type="bibr" target="#b46">Shi et al. (2020)</ref> and adopt their annotated SQL queries for adding gold programs for the originally weakly-supervised dataset;</p><p>GSM8k <ref type="bibr" target="#b13">(Cobbe et al., 2021</ref>) is a benchmark for solving grade-school level math word problems. Following previous work <ref type="bibr" target="#b12">(Chowdhery et al., 2022;</ref><ref type="bibr">Chen et al., 2022b;</ref><ref type="bibr" target="#b18">Gao et al., 2022)</ref>, we approach this benchmark by generating Python programs from questions in NL, which should produce the correct answer upon execution. The original dataset only has natural language and not program solutions, thus it is weakly-supervised for language-to-code;</p><p>MBPP <ref type="bibr" target="#b2">(Austin et al., 2021)</ref> contains basic Python programming programs stated in natural language. Each example is equipped with 3 test cases to check the correctness of the programs. Following previous work <ref type="bibr" target="#b45">(Shi et al., 2022;</ref><ref type="bibr" target="#b65">Zhang et al., 2022)</ref>, we use the first test case as part of the prompt for the model to generate correct function signatures and use all three of them for evaluating correctness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">CodeLMs</head><p>We evaluate LEVER with three different CodeLMs:</p><p>Codex <ref type="bibr">(Chen et al., 2021a</ref>) is a family of CodeLMs of different sizes developed by OpenAI. Specifically, we use the code-davinci-002 API<ref type="foot" target="#foot_1">4</ref> through its official Python bindings.</p><p>InCoder <ref type="bibr" target="#b17">(Fried et al., 2022)</ref> is a family of CodeLMs up to 6B parameters trained on a large corpus of code with permissively licenses. We experiment with InCoder-6B and use it for left-to-right generation.</p><p>CodeGen <ref type="bibr" target="#b34">(Nijkamp et al., 2022)</ref> is a family of CodeLMs and we evaluate the CodeGen-16B-multi version. Although SQL files are not included in the training corpus for Code-Gen, we found it to still perform reasonably well on SQL generation tasks possibly because the SQL queries were mixed in with source files of other programming languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Baselines and Evaluation Metric</head><p>Baselines. We compare LEVER to the following baseline approaches for generating programs using CodeLMs.</p><p>Greedy: Select the most likely token per decoding step.</p><p>Maximum Likelihood (ML): From k sampled program candidates, select the program with the highest generation log-probability, i.e., log P LM (?|x) (or normalized generation log-probability as log P LM (?|x)/|?|). We determine empirically using the development set whether to use the normalized probability for each dataset. More details can be found in Appendix A.</p><p>Error Pruning + ML (EP + ML): Prune out the candidate programs with execution errors; then select the program with the maximum likelihood;</p><p>Error Pruning + Voting (EP + Voting): Take the majority vote on the execution results among the error-free programs, and select the most-voted execution result and its corresponding programs.</p><p>We focus on comparing with the EP+ML baseline, as it is a simple reranking method that exploits execution and yields competitive results consistently across different datasets and CodeLMs.</p><p>Evaluation metric. Following previous work <ref type="bibr" target="#b60">(Xie et al., 2022;</ref><ref type="bibr" target="#b31">Liu et al., 2021;</ref><ref type="bibr" target="#b33">Ni et al., 2022;</ref><ref type="bibr" target="#b65">Zhang et al., 2022)</ref>, we use execution accuracy as the main evaluation metric for all datasets, which measures the percentage of examples that yields the gold execution result or pass all test cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation Details</head><p>Verifier training. We create the verification training data by sampling from the CodeLMs on the training set, using the sampling budget described in Table <ref type="table" target="#tab_0">1</ref>. More statistics of the resulting training data can be found in Table <ref type="table">8</ref> in the Appendix. When learning the verifiers, as shown in Eq. 4, the training loss is computed by averaging over all the program samples for each example. As we batch the program samples for the same examples together, the effective batch size will also be multiplied by the sample size. This could be problematic when sample size gets large (up to 100 in our experiments) as they may not be able to fit into the GPU memory at once. Therefore, we down-sample the programs used for learning per example in each iteration. The random down-sampling happens at the beginning of every epoch of training so the verifiers are able to see different programs each epoch. Detailed batch sizes and downsampling factor can be found in Table <ref type="table">8</ref> in the Appendix.</p><p>Execution result representation. The input to the verifier is a concatenation of the task input, the candidate program and its execution results. For Spider and WikiTQ, we use the linearized resulting tables from SQL execution as the execution results. For GSM8k, we use the value of the variable named "answer" after executing the program as the execution results. For MBPP, we use the type and value (casted to string) returned by the functions. All execution errors are represented as "ERROR: [reason]", such as "ERROR: Time out". Examples of these verifier inputs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Dev</head><p>Previous Work without Finetuning <ref type="bibr" target="#b41">Rajkumar et al. (2022)</ref> 67.0 MBR-Exec <ref type="bibr" target="#b45">(Shi et al., 2022)</ref> 75.2 Coder-Reviewer <ref type="bibr" target="#b65">(Zhang et al., 2022)</ref> 74.5</p><p>Previous Work with Finetuning T5-3B <ref type="bibr" target="#b60">(Xie et al., 2022)</ref> 71.8 PICARD <ref type="bibr" target="#b42">(Scholak et al., 2021)</ref> 75.5 RASAT <ref type="bibr" target="#b38">(Qi et al., 2022)</ref> 80.5</p><p>This Work with code-davinci-002 Greedy 75.3 EP + ML 77.3 LEVER ? ? 81.9?0.1</p><p>Table <ref type="table">2</ref>: Execution accuracy on the Spider dataset. Standard deviation is calculated over three runs with different random seeds (same for the following tables when std is presented).</p><p>for different datasets can be found in Table <ref type="table" target="#tab_0">11</ref>.</p><p>Verifier model selection. We use the development set to choose the best verifier model. We select T5-base for Spider, T5-large for WikiTQ and MBPP, and RoBERTa-large for GSM8k as the base LM for the verifiers to use in the main experiments<ref type="foot" target="#foot_2">5</ref> . The selection process is detailed in ? B.1. For the T5 models <ref type="bibr" target="#b40">(Raffel et al., 2020)</ref>, we train them to output the token "yes/no" for each positive/negative example given the verifier input, and we take the probability of generating "yes" as the verification probability during inference.</p><p>For RoBERTa <ref type="bibr" target="#b32">(Liu et al., 2019)</ref>, we add a linear layer on top of the [CLS] head, following the standard practice of sequence classification with encoder-only models <ref type="bibr" target="#b15">(Devlin et al., 2019)</ref>.</p><p>The details of CodeLM sampling, few-shot prompt construction and dataset-specific setups can be found in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Main Results</head><p>We show the performance of LEVER coupled with Codex-Davinci and compare it with the state-of-the-art finetuning and few-shot performances from previous work for Spider (Table <ref type="table">2</ref>), WikiTQ (Table <ref type="table" target="#tab_1">3</ref>), GSM8k (Table <ref type="table" target="#tab_2">4</ref>) and MBPP (Table <ref type="table">5</ref>). In addition, we also evaluate LEVER with InCoder and CodeGen models on Spider and GSM8k (Table <ref type="table" target="#tab_3">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Effectiveness of LEVER.</head><p>LEVER consistently improves the performance of all CodeLMs on all tasks, yielding improvements of 6.6% (Spider) to 17.3% (WikiTQ) over the greedy decoding baselines for Codex-Davinci. For weaker models such as InCoder and CodeGen, we observe improvements up to 30.0% for Spider and 15.0% for GSM8k. Moreover, LEVER combined with Codex-Davinci also achieves new state-of-the-art results on all four datasets, with improvements ranging from 1.2% (WikiTQ) to 2.0% (MBPP). On the challenging textto-SQL dataset, Spider, where the previous state-of-the-art is achieved by finetuning a T5-3B model augmented with relational-aware self-attention, we achieved even better results with Codex-Davinci + LEVER, where the verifier is finetuned using a T5-base model. LEVER also improves the previous best results on Spider using InCoder and CodeGen, by 13.2% and 20.6%, respectively.</p><p>As LEVER is a simple method that combines few-shot LM generation with learned verifiers, it can potentially benefit more advanced prompting methods <ref type="bibr">(Li et al., 2022b;</ref><ref type="bibr" target="#b11">Cheng et al., 2022)</ref> or model architectures <ref type="bibr" target="#b38">(Qi et al., 2022;</ref><ref type="bibr" target="#b52">Wang et al., 2020)</ref>, which we leave as future work. Table <ref type="table">5</ref>: Execution accuracy on the MBPP dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablations with LEVER</head><p>We perform ablation study for LEVER with Codex-Davinci and compare with the baselines mentioned in ? 3.3, and the results are shown in Figure <ref type="figure" target="#fig_1">2</ref>. The same ablations are conducted for InCoder and CodeGen with results in Table <ref type="table" target="#tab_3">6</ref>.</p><p>In these results, we include an "Oracle" performance which is obtained by always selecting the correct program as long as they appear in the sample set.</p><p>Effect of including execution results. According to Figure <ref type="figure" target="#fig_1">2</ref>, the performance drops considerably on all four benchmarks when execution result is removed from the verifier input, indicating that the execution outcome is important for verifier training. The effect varies across different datasets.</p><p>While it causes an absolute performance drop of 6.6% and 5.6% for WikiTQ and MBPP, as the drop is smaller for Spider (3.0%) and GSM8k (1.2%). We found the code samples for WikiTQ and MBPP contain more execution errors, which explains why our approach is more effective on these two datasets. simple execution errors. More detailed quantitative analysis of when execution information helps is in Figure <ref type="figure" target="#fig_6">6</ref>.</p><p>Effect of execution result aggregation. Aggregating the programs with the same execution result is a simple and widely used technique <ref type="bibr">(Chen et al., 2022b;</ref><ref type="bibr" target="#b11">Cheng et al., 2022)</ref>. We find execution aggregation work well with LEVER on datasets with Python output, but only marginally benefit the SQL datasets. A probable reason is that the Python code structure is more flexible than that of the domain-specific languages as SQL. In the database querying domain, it is more likely for an incorrect program to execute to some trivial but wrong results (e.g., "0" or empty table). After aggregation, such incorrect results may accumulate enough probability mass to out-weight the correct one, leading to negative impact on the performance. Weakly-supervised settings. We also compare the performance of LEVER under fully-and weakly-supervised settings. Figure <ref type="figure" target="#fig_1">2</ref> and Table <ref type="table" target="#tab_3">6</ref> show that the performance of LEVER is largely preserved when the gold programs are not given and the weakly-supervised setting is used ( ?2.3), with an absolute performance drop up to 1.1%. This suggests that LEVER works well under the weakly-supervised settings, and the program itself is less informative for verification comparing to the execution results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training Example Scaling</head><p>We show how the performance of LEVER changes with fewer training examples in Figure <ref type="figure" target="#fig_2">3</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Sample Size Scaling</head><p>Since drawing samples from CodeLMs in may be costly computational-wise, here we study the how sample size during training and inference time affects the performance.</p><p>As we can see from Figure <ref type="figure" target="#fig_3">4a</ref>, during inference time, when lowering the sample size from 50 to 10 programs per example, the performance of LEVER drops by 1.8% (Spider) to 5.2% (WikiTQ). This indicates that the LEVER is sensitive to the sample size at inference time, which is expected as it also greatly affects oracle results (i.e., the upper-bound for reranking). In comparison, Figure <ref type="figure" target="#fig_3">4b</ref> shows that LEVER is highly insensitive to the sample size for providing training data, with the performance gap all below 1% for the three datasets. Overall, the results show that a higher sampling budget helps more at test time.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Transfer Learning between CodeLMs</head><p>One other way to avoid the cost of sampling from CodeLMs is to train verifiers using samples from one CodeLM and directly apply to the programs sampled from a different CodeLM, i.e., between CodeLM transfer, and we show the results of such on Spider and GSM8k in Table <ref type="table" target="#tab_6">7</ref>. From the results, we can first observe that LEVER still non-trivially improves the baseline performance most of the time, with the exception of transferring from InCoder and CodeGen to Codex on the GSM8k dataset. This suggests that the knowledge learned by the verifiers are generalizable to different CodeLM outputs. Moreover, we can see that the transfer typically works better when the percentage of positive labels are closer, as the transfer is more successful between the InCoder and CodeGen models than that with Codex. These results show between-CodeLM transfer as an interesting way to reduce the training data need for LEVER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Verifier and Generator Calibration</head><p>We study how well-calibrated are the verifier and generator in identifying correct programs. Ideally, correct program samples shall be given higher probabilities thus we should observe higher percentage of programs being correct when it is closer to the top. To this end, we sort the prediction scores of the verifier, the generator and LEVER (as in Eq. 3), and move the percentile threshold and measuring the percentage of correct programs in the top ranked programs. According to Figure <ref type="figure" target="#fig_4">5</ref>, the verifiers are generally better calibrated than the generators, especially when the threshold is in the lower percentiles. This indicates that it is easier for the verifiers to identify obvious mistakes in the programs with execution results as part of their input. Interestingly, when distinguishing between the top-ranked programs, the verifiers are poorly calibrated in three of the four tested datasets<ref type="foot" target="#foot_3">6</ref> . However, the generators are generally better calibrated in this region, and combining the probability of the verifier and the generator yields the best results on all four benchmarks. More specifically, on the GSM8k dataset, where the calibration of both models are quite poor for top-ranking programs, their joint probability is surprisingly well-calibrated, showing that the two models complement each other on this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Quantitative Analysis</head><p>We present a quantitative analysis on why LEVER successfully or failed to improve the performance of CodeLMs.</p><p>According to Figure <ref type="figure" target="#fig_6">6</ref>, when LEVER reranks a program to replace another with higher generation probability, it is oftentimes because the execution results provide crucial information such as execution errors, variable type and range. This is consistent with our findings in ? 4.2 about the importance of execution results for LEVER. It is also worth noticing that there are cases when LEVER is still able to rerank the correct program when the error-free execution results are of the same type and range with the greedy program, i.e., in "others" category. Our hypothesis is that this  is when the program itself becomes the main feature for the verifiers to exploit. In addition, when LEVER fails to rank correct programs to the top, the most common reason is that no correct program can be found in the samples (i.e., upper-bound is reached), which is especially the case for weaker CodeLMs. The second most common reason for LEVER to fail is that the execution results of the incorrect program upon reranking has the same type and range as the correct program in the samples. In this case, execution results do not provide rich information for the verifiers thus LEVER fails to improve CodeLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Language-to-Code Generation. Translating natural language to code is a long-standing challenge through all eras of artificial intelligence, including rule-based systems <ref type="bibr" target="#b58">(Woods, 1973;</ref><ref type="bibr" target="#b49">Templeton &amp; Burger, 1983)</ref>, structured prediction <ref type="bibr" target="#b63">(Zelle &amp; Mooney, 1996;</ref><ref type="bibr" target="#b64">Zettlemoyer &amp; Collins, 2005;</ref><ref type="bibr" target="#b20">Gulwani &amp; Marron, 2014)</ref> and deep learning <ref type="bibr" target="#b59">(Xiao et al., 2016;</ref><ref type="bibr" target="#b16">Dong &amp; Lapata, 2016;</ref><ref type="bibr" target="#b39">Rabinovich et al., 2017;</ref><ref type="bibr" target="#b66">Zhong et al., 2017;</ref><ref type="bibr" target="#b29">Lin et al., 2017)</ref>. Recently, pre-trained code language models <ref type="bibr">(Chen et al., 2021a;</ref><ref type="bibr" target="#b55">Wang et al., 2021;</ref><ref type="bibr" target="#b17">Fried et al., 2022;</ref><ref type="bibr" target="#b34">Nijkamp et al., 2022;</ref><ref type="bibr" target="#b36">OpenAI, 2022)</ref> have demonstrated surprisingly strong performance in this problem across programming languages <ref type="bibr" target="#b30">(Lin et al., 2018;</ref><ref type="bibr" target="#b62">Yu et al., 2018;</ref><ref type="bibr" target="#b2">Austin et al., 2021;</ref><ref type="bibr" target="#b13">Cobbe et al., 2021;</ref><ref type="bibr">Li et al., 2022a)</ref>. A number of approaches were proposed to refine CodeLM sample selection, including test case execution <ref type="bibr">(Li et al., 2022a)</ref>, cross-sample similarity <ref type="bibr">(Chen et al., 2021a;</ref><ref type="bibr">Li et al., 2022a;</ref><ref type="bibr" target="#b45">Shi et al., 2022)</ref> and maximum mutual information <ref type="bibr" target="#b65">(Zhang et al., 2022)</ref> based filtering. Our work proposes a learnable verification module to judge the sample output of CodeLMs to further improve their performance.</p><p>Code Generation with Execution. Previous code generation work have exploited execution results in different ways.</p><p>Weakly-supervised learning approaches <ref type="bibr" target="#b3">(Berant et al., 2013;</ref><ref type="bibr" target="#b37">Pasupat &amp; Liang, 2015;</ref><ref type="bibr" target="#b21">Guu et al., 2017)</ref> model programs as latent variables and use execution results to derive the supervision signal. Intermediate execution results were used to guide program search at both training <ref type="bibr" target="#b8">(Chen et al., 2019;</ref><ref type="bibr">2021b)</ref> and inference time <ref type="bibr" target="#b53">(Wang et al., 2018)</ref>. When sampling at scale, majority voting based on the execution results has been shown effective for candidate selection <ref type="bibr">(Li et al., 2022a;</ref><ref type="bibr" target="#b13">Cobbe et al., 2021)</ref>. <ref type="bibr" target="#b45">Shi et al. (2022)</ref> generalizes this principle by selecting samples that have the maximum concensus with other samples in the execution results. We propose to train a verification model to judge the correctness of code generation taking the execution results into account.</p><p>Learning to Verify. Previous work have shown the effectiveness of learned verifiers for sample filtering in domains such as math QA <ref type="bibr" target="#b43">(Shen et al., 2021;</ref><ref type="bibr" target="#b13">Cobbe et al., 2021)</ref> and commonsense QA <ref type="bibr">(Li et al., 2022b)</ref>, where the solution is mostly described in natural language. While it is more common to train the verifiers independently from the generator <ref type="bibr" target="#b13">(Cobbe et al., 2021;</ref><ref type="bibr">Li et al., 2022b)</ref> Discriminative Reranking. Discriminative reranking approaches have long been used to further improve the performance of sequence generation tasks, including summarization <ref type="bibr" target="#b51">(Wan et al., 2015)</ref>, machine translation <ref type="bibr" target="#b44">(Shen et al., 2004;</ref><ref type="bibr" target="#b26">Lee et al., 2021)</ref>, dialogue response generation <ref type="bibr" target="#b35">(Olabiyi et al., 2018)</ref> and more rencently, code generation <ref type="bibr" target="#b61">(Yin &amp; Neubig, 2019)</ref>. LEVER can be viewed as a discriminative reranking framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We propose LEVER, a simple approach for improving CodeLMs on language-to-code tasks, by learning separate verification models to judge the correctness of the generated programs, taking their execution results into consideration. We show that it is possible to train verifiers approximately 0.5% the size of the generators using supervised benchmark datasets. Instead of directly perform rejection sampling based on the verifier output, we show it is better to mix the generation and verfication probabilities for sample reranking. LEVER consistently improves the performance of CodeLMs on four language-to-code tasks, and achieves new state-of-the-art results on all of them. Further analysis suggest that the program execution results are crucial for verification and the proposed approach is generalizable across different CodeLMs. In future work, it would be interesting to explore verification models that work across tasks and domains, and turning large language models into few-shot program verifiers as their capabilities improve over time.</p><p>--Example:</p><p>--Database school_finance:</p><p>--   <ref type="table">Tourist_Attraction_Features</ref>: Tourist_Attraction_ID, Feature_ID --Question: Which transportation method is used the most often to get to tourist attractions? --SQL: SELECT How_to_Get_There FROM Tourist_Attractions GROUP BY How_to_Get_There ORDER BY COUNT( * ) DESC LIMIT 1</p><p>Table <ref type="table" target="#tab_0">15</ref>: The prompt we use for the Spider dataset for few-shot generation with CodeLMs (Part 3), continued from Table <ref type="table" target="#tab_1">13</ref> and Table <ref type="table" target="#tab_10">14</ref>.</p><p>--Translate natural language questions into SQL queries.</p><p>--Example:</p><p>--Database 204_126: --Table <ref type="table" target="#tab_13">main_table</ref>: id (1), agg (0), place (t1), place_number (1.0), player (larry nelson), country (united states)</p><p>, score (70-72-73-72=287), score_result (287), score_number (70), score_number1 (70), score_number2 (72), score_number3 (73), score_number4 (72), to_par (-1), to_par_number (-1.0), money_lrb_rrb (playoff), money_lrb_rrb_number (58750.0) --Question: what was first place 's difference to par ? --SQL: select to_par from main_table where place_number = 1 --Example:</p><p>--Database 204_522: --  <ref type="bibr">completed (31-05-1945), completed_number (31), completed_parsed (1945-05-31), completed_year (1945), completed_month (5), completed_day (31), fate (decommissioned 30-11-1945</ref>. scuttled off goto islands 01-04-1946) --Question: when was a boat launched immediately before ha-206 ? --SQL: select name from main_table where launched_parsed &lt; ( select launched_parsed from main_table where name = 'ha-206' ) order by launched_parsed desc limit 1 --Example:</p><p>--Database 204_877:</p><p>--Table <ref type="table" target="#tab_13">main_table</ref>: id (1), agg (0), place (1), place_number (1.0), position (mf), number (4), number_number (4.0), name (ryan hall), league_two (10), league_two_number (10.0), fa_cup (1), fa_cup_number (1.0), league_cup (0), league_cup_number (0.0), fl_trophy (3), fl_trophy_number (3.0), total (14), total_number (14.0) --Question: who scored more , grant or benyon ? --SQL: select name from main_table where name in ( 'anthony grant' , 'elliot benyon' ) order by total_number desc limit 1 --Example:</p><p>--Database 204_400: --Table <ref type="table" target="#tab_13">main_table</ref>: id (1), agg (0), district (1), district_number (1.0), senator (kenneth p. lavalle), party ( republican), caucus (republican), first_elected <ref type="bibr">(1976), first_elected_number (1976)</ref>, counties_represented ( suffolk), counties_represented_length (1) --Table t_counties_represented_list: m_id (1), counties_represented_list (suffolk) --Question: how many republicans were elected after 2000 ? --SQL: select count ( * ) from main_table where party = 'republican' and first_elected_number &gt; 2000</p><p>Table <ref type="table" target="#tab_3">16</ref>: The prompt we use for the WTQ dataset for few-shot generation with CodeLMs (Part 1).</p><p>LEVER: Learning to Verify Language-to-Code Generation with Execution --Example:</p><p>--Database 203_208: --Table <ref type="table" target="#tab_13">main_table</ref>: id (1), agg (0), team (dinamo minsk), location (minsk), venue (dinamo, minsk), capacity <ref type="bibr">(41040)</ref> , capacity_number (41040.0), position_in_1993_94 (1), position_in_1993_94_number (1.0) --Table t_venue_address: m_id (1), venue_address (dinamo) --Question: what is the number of teams located in bobruisk ? --SQL: select count ( team ) from main_table where location = 'bobruisk' --Example:</p><p>--Database 203_60: --Table <ref type="table" target="#tab_13">main_table</ref>: id (1), agg (0), outcome (winner), no (1), no_number (1.0), date <ref type="bibr">(20 july 1981), date_number (20), date_parsed (1981-07-20), date_year (1981)</ref>, date_month (7), date_day (20), championship (bastad, sweden), surface (clay), opponent_in_the_final (anders jarryd), score_in_the_final (6-2, 6-3), score_in_the_final_length (2) --Table t_championship_address: m_id (1), championship_address (bastad) --Table t_score_in_the_final_list: m_id (1), score_in_the_final_list (6-2) --Table t_score_in_the_final_list_first: m_id (1), score_in_the_final_list_first (6-2) --Table t_score_in_the_final_list_second: m_id (7), score_in_the_final_list_second (1-7) --Table t_score_in_the_final_list_first_number: m_id (1), score_in_the_final_list_first_number (6) --Table <ref type="table" target="#tab_0">t_score_in_the_final_list_first_number1</ref>: m_id (1), score_in_the_final_list_first_number1 (6) --Table <ref type="table">t_score_in_the_final_list_first_number2</ref>: m_id (1), score_in_the_final_list_first_number2 (2) --Table t_score_in_the_final_list_second_number: m_id (7), score_in_the_final_list_second_number (1) --Table <ref type="table" target="#tab_0">t_score_in_the_final_list_second_number1</ref>: m_id (7), score_in_the_final_list_second_number1 (1) --Table <ref type="table">t_score_in_the_final_list_second_number2</ref>: m_id (7), score_in_the_final_list_second_number2 (7) --Question: which month were the most championships played ? --SQL: select date_month from main_table group by date_month order by count ( * ) desc limit 1 --Example:</p><p>--Database 203_462: --Table <ref type="table" target="#tab_13">main_table</ref>: id (1), agg (0), year <ref type="bibr">(2006), year_number (2006)</ref>, division (4), division_number (4.0), league ( usl pdl), regular_season (4th, heartland), regular_season_length (2), playoffs (did not qualify), open_cup (did not qualify) --Table t_regular_season_list: m_id (1), regular_season_list (4th) --Question: what year was more successful , 2012 or 2007 ? --SQL: select year_number from main_table where year_number in <ref type="bibr">( 2012 , 2007 )</ref> order by regular_season limit 1 --Example:</p><p>--Database 204_139: --Question: are their any other airports that are type '' military/public '' besides eagle farm airport ? --  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The illustration of LEVER using text-to-SQL as an example. It consists of three steps: 1) Generation: sample programs from CodeLMs based on the task input and few-shot exemplars; 2) Execution: obtain the execution results with program executors; 3) Verification: using a learned verifier to output the probability of the program being correct based on the NL, program and execution results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of LEVER ? ? and baselines with Codex-Davinci. LEVER and its ablation results are in solid bars.</figDesc><graphic url="image-13.png" coords="6,55.44,67.06,486.01,146.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Verification vs. generation performance when decreasing the number of training examples for Spider. Data markers on the y-axis denote the EP+ML baseline. T5-base is used as the base model for LEVER. WikiTQ and GSM8k results can be found in Figure 7 in the Appendix.</figDesc><graphic url="image-20.png" coords="7,61.29,67.06,222.30,145.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: How sample size during training and inference time affects the performance, using Codex-Davinci as the CodeLM.</figDesc><graphic url="image-22.png" coords="7,307.44,246.26,238.14,115.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Calibration of the verifier, generator (Codex-Davinci), and their combined probability (used by LEVER).The sampled programs are first ranked by the model probabilities. The x-axis represents the percentage of samples excluded after thresholding, and the y-axis represents the percentage of correct programs in the remaining samples. Execution aggregation is not applied in this group of plots to ensure the scoring of different programs are independent.</figDesc><graphic url="image-23.png" coords="8,307.44,67.06,234.00,199.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) When LEVER reranks a correct program at the top but the greedy decoding fails. (b) When LEVER fails to rank a correct program at the top.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Quantitative analysis on when LEVER succeeds and fails to improve CodeLMs over greedy decoding.</figDesc><graphic url="image-25.png" coords="9,58.23,197.02,228.42,90.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>, Shen et al. (2021) jointly fine-tuned both at the same time. Previous work have also used different base LMs for the verifiers. Cobbe et al. (2021) uses GPT-3 (Brown et al., 2020) while Li et al. (2022b) uses DeBERTa<ref type="bibr" target="#b22">(He et al., 2020)</ref>. Besides taskspecific verifiers,<ref type="bibr" target="#b24">Kadavath et al. (2022)</ref> shows that large LMs can self-verify their output in a few-shot setting for a wide range of tasks.Chen et al. (2022a)  and other works<ref type="bibr" target="#b50">(Tufano et al., 2020;</ref> Li et al., 2022a)  use LMs to generate test cases instead of directly judging the correctness of the output programs. In comparison, the setting of LEVER is closer toLi et al. (2022b)  as we train the verifier separately and use a much smaller LM for it (approximately 0.5% of the generator parameter size). We report the first set of comprehensive evaluation on language-to-code tasks, making use of the program execution results 7 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of the datasets used in this work. * : About 80% examples in WikiTableQuestions are annotated with SQL by Shi et al. (2020). ? : 50/100 for InCoder and CodeGen for improving the upper-bound. ? : Only the first 2 of the 8 exemplars are used for InCoder and CodeGen due to limits of context length and hardware.</figDesc><table><row><cell></cell><cell></cell><cell>Spider</cell><cell cols="2">WikiTQ GSM8k</cell><cell>MBPP</cell></row><row><cell>Domain</cell><cell></cell><cell>Table</cell><cell>Table</cell><cell>Math</cell><cell>Basic</cell></row><row><cell></cell><cell></cell><cell>QA</cell><cell>QA</cell><cell>QA</cell><cell>Coding</cell></row><row><cell cols="2">Has program</cell><cell></cell><cell>*</cell><cell></cell><cell></cell></row><row><cell>Target</cell><cell></cell><cell>SQL</cell><cell>SQL</cell><cell>Python</cell><cell>Python</cell></row><row><cell></cell><cell></cell><cell cols="2">Data Statistics</cell><cell></cell><cell></cell></row><row><cell># Train</cell><cell></cell><cell>7,000</cell><cell>11,321</cell><cell>5,968</cell><cell>378</cell></row><row><cell># Dev</cell><cell></cell><cell>1,032</cell><cell>2,831</cell><cell>1,448</cell><cell>90</cell></row><row><cell># Test</cell><cell></cell><cell>-</cell><cell>4,336</cell><cell>1,312</cell><cell>500</cell></row><row><cell></cell><cell></cell><cell cols="3">Few-shot Generation Settings</cell><cell></cell></row><row><cell>Input</cell><cell>For-</cell><cell>Schema</cell><cell>Schema</cell><cell>NL</cell><cell>Assertion</cell></row><row><cell>mat</cell><cell></cell><cell>+ NL</cell><cell>+ NL</cell><cell></cell><cell>+ NL</cell></row><row><cell># Shots</cell><cell></cell><cell>8  ?</cell><cell>8</cell><cell>8</cell><cell>3</cell></row><row><cell cols="2"># Samples (train / test)</cell><cell>20/50  ?</cell><cell>50/50</cell><cell>50/100</cell><cell>100/100</cell></row><row><cell cols="2">Generation Length</cell><cell>128</cell><cell>128</cell><cell>256</cell><cell>256</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Execution accuracy on the WikiTQ dataset.</figDesc><table><row><cell>Methods</cell><cell>Dev</cell><cell>Test</cell></row><row><cell cols="2">Previous Work without Finetuning</cell><cell></cell></row><row><cell>Codex QA  *  (Cheng et al., 2022)</cell><cell>50.5</cell><cell>48.7</cell></row><row><cell>Codex SQL (Cheng et al., 2022)</cell><cell>60.2</cell><cell>61.1</cell></row><row><cell cols="2">Codex Binder (Cheng et al., 2022) 65.0</cell><cell>64.6</cell></row><row><cell cols="2">Previous Work with Finetuning</cell><cell></cell></row><row><cell>TaPEX  *  (Liu et al., 2021)</cell><cell>60.4</cell><cell>59.1</cell></row><row><cell>TaCube (Zhou et al., 2022)</cell><cell>61.1</cell><cell>61.3</cell></row><row><cell>OmniTab  *  (Jiang et al., 2022)</cell><cell>-</cell><cell>63.3</cell></row><row><cell cols="2">This Work with code-davinci-002</cell><cell></cell></row><row><cell>Greedy</cell><cell>49.6</cell><cell>53.0</cell></row><row><cell>EP + ML</cell><cell>52.7</cell><cell>54.9</cell></row><row><cell>LEVER ? ?</cell><cell cols="2">64.6?0.2 65.8?0.2</cell></row><row><cell>Methods</cell><cell>Dev</cell><cell>Test</cell></row><row><cell cols="2">Previous Work without Finetuning</cell><cell></cell></row><row><cell>PAL (Gao et al., 2022)</cell><cell>-</cell><cell>72.0</cell></row><row><cell>Codex + SC  Greedy</cell><cell>68.1</cell><cell>67.2</cell></row><row><cell>EP + ML</cell><cell>72.1</cell><cell>72.6</cell></row><row><cell>LEVER ? ?</cell><cell cols="2">84.1?0.2 84.5?0.3</cell></row></table><note><p><p>* : modeled as end-to-end QA without generating programs as a medium. ? (Wang et al., 2022) -78.0 PoT-SC (Chen et al., 2022b) -80.0 Previous Work with Finetuning Neo-2.7B + SS (Ni et al., 2022) 20.7 19.5 Neo-1.3B + SC (Welleck et al., 2022) -24.2 DiVeRSe * ? (Li et al., 2022b) -83.2</p>This Work with codex-davinci-002</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Execution accuracy on the GSM8k dataset.</figDesc><table /><note><p>* : finetuned model combined with Codex (similar to LEVER); ? : generating natural language solutions instead of programs.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 :</head><label>6</label><figDesc>Table6shows similar trends for InCoder-6B and CodeGen-16B on Spider and GSM8k. The smaller CodeLMs have worse few-shot performance and removing the execution information from the verifier often results in even greater performance drops. Moreover, we found that LEVER in general outperforms the EP+ML baseline, indicating that the verifiers can make use of clues beyond</figDesc><table><row><cell>Methods</cell><cell cols="2">InCoder-6B</cell><cell cols="2">CodeGen-16B</cell></row><row><cell></cell><cell cols="2">Spider GSM8k</cell><cell cols="2">Spider GSM8k</cell></row><row><cell>Previous work:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MBR-EXEC</cell><cell>38.2</cell><cell>-</cell><cell>30.6</cell><cell>-</cell></row><row><cell>Reviewer</cell><cell>41.5</cell><cell>-</cell><cell>31.7</cell><cell>-</cell></row><row><cell>Baselines:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Greedy</cell><cell>24.1</cell><cell>3.1</cell><cell>24.6</cell><cell>7.1</cell></row><row><cell>ML</cell><cell>33.7</cell><cell>3.8</cell><cell>31.2</cell><cell>9.6</cell></row><row><cell>EP + ML</cell><cell>41.2</cell><cell>4.4</cell><cell>37.7</cell><cell>11.4</cell></row><row><cell>EP + Voting</cell><cell>37.4</cell><cell>5.9</cell><cell>37.1</cell><cell>14.2</cell></row><row><cell>LEVER ? ?</cell><cell>54.1</cell><cell>11.9</cell><cell>51.0</cell><cell>22.1</cell></row><row><cell>-gold prog.</cell><cell>53.4</cell><cell>-</cell><cell>52.3</cell><cell>-</cell></row><row><cell>-exec. info</cell><cell>48.5</cell><cell>5.6</cell><cell>43.0</cell><cell>13.4</cell></row><row><cell>-exec. agg.</cell><cell>54.7</cell><cell>10.6</cell><cell>51.6</cell><cell>18.3</cell></row><row><cell>Oracle</cell><cell>71.6</cell><cell>48.0</cell><cell>68.6</cell><cell>61.4</cell></row></table><note><p>Results with InCoder and CodeGen as the CodeLMs, evaluated on the dev set with T5-base as the verifier. Previous work results were copied from Zhang et al. (2022).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Execution accuracy of training verifiers on the programs sampled from source CodeLM and apply to the target CodeLM. The best and second best performance per row is highlighted accordingly.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table School</head><label>School</label><figDesc></figDesc><table><row><cell>: School_id, School_name, Location, Mascot, Enrollment, IHSAA_Class, IHSAA_Football_Class, County</cell></row><row><cell>--Table budget: School_id, Year, Budgeted, total_budget_percent_budgeted, Invested, total_budget_percent_invested,</cell></row><row><cell>Budget_invested_percent</cell></row><row><cell>--Table endowment: endowment_id, School_id, donator_name, amount</cell></row><row><cell>--Question: Show the average, maximum, minimum enrollment of all schools.</cell></row><row><cell>--SQL:</cell></row><row><cell>SELECT avg(Enrollment) , max(Enrollment) , min(Enrollment) FROM School</cell></row><row><cell>--Example:</cell></row><row><cell>--Database cre_Docs_and_Epenses:</cell></row><row><cell>--Table Ref_Document_Types: Document_Type_Code, Document_Type_Name, Document_Type_Description</cell></row><row><cell>--Table Ref_Budget_Codes: Budget_Type_Code, Budget_Type_Description</cell></row><row><cell>--</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table Projects :</head><label>Projects</label><figDesc>Project_ID, Project_Details --Table Documents: Document_ID, Document_Type_Code, Project_ID, Document_Date, Document_Name, Document_Description, Other_Details --Table Statements: Statement_ID, Statement_Details --Table Documents_with_Expenses: Document_ID, Budget_Type_Code, Document_Details --Table Accounts: Account_ID, Statement_ID, Account_Details --Question: Return the ids and details corresponding to projects for which there are more than two documents.</figDesc><table><row><cell>--SQL:</cell></row><row><cell>SELECT T1.Project_ID , T1.Project_Details FROM Projects AS T1 JOIN Documents AS T2 ON T1.Project_ID = T2.Project_ID</cell></row><row><cell>GROUP BY T1.Project_ID HAVING count( * ) &gt; 2</cell></row><row><cell>--Example:</cell></row><row><cell>--Database local_govt_in_alabama:</cell></row><row><cell>--Table Services: Service_ID, Service_Type_Code</cell></row><row><cell>--Table Participants: Participant_ID, Participant_Type_Code, Participant_Details</cell></row><row><cell>--Table Events: Event_ID, Service_ID, Event_Details</cell></row><row><cell>--Table Participants_in_Events: Event_ID, Participant_ID</cell></row><row><cell>--Question: List the type of the services in alphabetical order.</cell></row><row><cell>--SQL:</cell></row><row><cell>SELECT Service_Type_Code FROM Services ORDER BY Service_Type_Code</cell></row><row><cell>--Example:</cell></row><row><cell>--Database cre_Theme_park:</cell></row><row><cell>--Table Ref_Hotel_Star_Ratings: star_rating_code, star_rating_description</cell></row><row><cell>--Table Locations: Location_ID, Location_Name, Address, Other_Details</cell></row><row><cell>--Table Ref_Attraction_Types: Attraction_Type_Code, Attraction_Type_Description</cell></row><row><cell>--Table Visitors: Tourist_ID, Tourist_Details</cell></row><row><cell>--Table Features: Feature_ID, Feature_Details</cell></row><row><cell>--Table Hotels: hotel_id, star_rating_code, pets_allowed_yn, price_range, other_hotel_details</cell></row><row><cell>--Table Tourist_Attractions: Tourist_Attraction_ID, Attraction_Type_Code, Location_ID, How_to_Get_There, Name,</cell></row><row><cell>Description, Opening_Hours, Other_Details</cell></row><row><cell>--Table Street_Markets: Market_ID, Market_Details</cell></row><row><cell>--Table Shops: Shop_ID, Shop_Details</cell></row><row><cell>--Table Museums: Museum_ID, Museum_Details</cell></row><row><cell>--Table Royal_Family: Royal_Family_ID, Royal_Family_Details</cell></row><row><cell>--Table Theme_Parks: Theme_Park_ID, Theme_Park_Details</cell></row><row><cell>--</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table Visits :</head><label>Visits</label><figDesc>Visit_ID, Tourist_Attraction_ID, Tourist_ID, Visit_Date, Visit_Details --Table Photos: Photo_ID, Tourist_Attraction_ID, Name, Description, Filename, Other_Details --TableStaff: Staff_ID, Tourist_Attraction_ID, Name, Other_Details --TableTourist_Attraction_Features: Tourist_Attraction_ID, Feature_ID --Question: Show the average price range of hotels that have 5 star ratings and allow pets.</figDesc><table><row><cell>--SQL:</cell></row><row><cell>SELECT avg(price_range) FROM Hotels WHERE star_rating_code = "5" AND pets_allowed_yn = 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 14 :</head><label>14</label><figDesc>The prompt we use for the Spider dataset for few-shot generation with CodeLMs (Part 2), continued from Table13. : Learning to Verify Language-to-Code Generation with Execution</figDesc><table><row><cell>--Example:</cell></row><row><cell>--Database insurance_fnol:</cell></row><row><cell>--Table Customers: Customer_ID, Customer_name</cell></row><row><cell>--Table Services: Service_ID, Service_name</cell></row><row><cell>--</cell></row></table><note><p>LEVER</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table Available_Policies :</head><label>Available_Policies</label><figDesc>Policy_ID, policy_type_code, Customer_Phone --Table Customers_Policies: Customer_ID, Policy_ID, Date_Opened, Date_Closed --Table First_Notification_of_Loss: FNOL_ID, Customer_ID, Policy_ID, Service_ID --Table Claims: Claim_ID, FNOL_ID, Effective_Date --Table Settlements: Settlement_ID, Claim_ID, Effective_Date, Settlement_Amount --Question: Find all the phone numbers.</figDesc><table><row><cell>--SQL:</cell></row><row><cell>SELECT Customer_Phone FROM available_policies</cell></row><row><cell>--Example:</cell></row><row><cell>--Database cre_Theme_park:</cell></row><row><cell>--Table Ref_Hotel_Star_Ratings: star_rating_code, star_rating_description</cell></row><row><cell>--Table Locations: Location_ID, Location_Name, Address, Other_Details</cell></row><row><cell>--Table Ref_Attraction_Types: Attraction_Type_Code, Attraction_Type_Description</cell></row><row><cell>--Table Visitors: Tourist_ID, Tourist_Details</cell></row><row><cell>--Table Features: Feature_ID, Feature_Details</cell></row><row><cell>--Table Hotels: hotel_id, star_rating_code, pets_allowed_yn, price_range, other_hotel_details</cell></row><row><cell>--Table Tourist_Attractions: Tourist_Attraction_ID, Attraction_Type_Code, Location_ID, How_to_Get_There, Name,</cell></row><row><cell>Description, Opening_Hours, Other_Details</cell></row><row><cell>--Table Street_Markets: Market_ID, Market_Details</cell></row><row><cell>--Table Shops: Shop_ID, Shop_Details</cell></row><row><cell>--Table Museums: Museum_ID, Museum_Details</cell></row><row><cell>--Table Royal_Family: Royal_Family_ID, Royal_Family_Details</cell></row><row><cell>--Table Theme_Parks: Theme_Park_ID, Theme_Park_Details</cell></row><row><cell>--</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table Visits :</head><label>Visits</label><figDesc>Visit_ID, Tourist_Attraction_ID, Tourist_ID, Visit_Date, Visit_Details --TablePhotos: Photo_ID, Tourist_Attraction_ID, Name, Description, Filename, Other_Details --TableStaff: Staff_ID, Tourist_Attraction_ID, Name, Other_Details --Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table main_table</head><label>main_table</label><figDesc></figDesc><table><row><cell>: id (1), agg (0), boat_count (4911), boat_count_number (4911), boat_count_minimum (4951),</cell></row><row><cell>boat_count_maximum (4955), name (ha-201), builder (sasebo naval arsenal), laid_down (01-03-1945),</cell></row><row><cell>laid_down_number (1), laid_down_parsed (1945-01-03), laid_down_year (1945), laid_down_month (1), laid_down_day</cell></row><row><cell>(3), launched (23-04-1945), launched_number (23), launched_parsed (1945-04-23), launched_year (1945),</cell></row><row><cell>launched_month (4), launched_day (23),</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Table main_table: id (1), agg (0), community (antil plains), airport_name (antil plains aerodrome), type ( military), coordinates (19 26'36''s 146 49'29''e/19.44333 s 146.82472 e) --SQL: select ( select count ( airport_name ) from main_table where type = 'military/public' and airport_name != 'eagle farm airport' ) &gt; 0</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 17 :</head><label>17</label><figDesc>The prompt we use for the WTQ dataset for few-shot generation with CodeLMs (Part 2).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>For datasets that provide multiple test cases, we label a program as correct if and only if its execution results match the ground truth program on all test cases.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://openai.com/api/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>We attempted using the CodeLM itself as the verifier in a few-shot manner, but the performance is inferior than the EP+ML baseline.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Our hypothesis is that the programs ranked at the top have very similar form and execution results (e.g., same type and range), making it hard for a small, though finetuned, model to discriminate.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>While Kadavath et al. (2022)  also reported self-verification results on HumanEval, their approach does not leverage execution results.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors would like to thank <rs type="person">Xi Ye</rs>, <rs type="person">Tianyi Zhang</rs>, <rs type="person">Mengzhou Xia</rs> and <rs type="person">Luke Zettlemoyer</rs> for the useful discussion and comments.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>CodeLM sampling. We use temperature sampling to obtain program candidates given the input formats and sampling hyperparameters as described in Table <ref type="table">8</ref>. We set the temperature as T = 0.6 for Codex and T = 0.8 for In-Coder and CodeGen, as the optimal temperatures for the best pass@k by referring to the original papers <ref type="bibr" target="#b17">(Fried et al., 2022;</ref><ref type="bibr" target="#b34">Nijkamp et al., 2022</ref>). An ablation study on sampling budget is reported in ?5.1.</p><p>Few-shot prompt construction. Dataset-specific setups. The detailed experiment setups for specific datasets are shown as Table <ref type="table">8</ref>. In particular, we use normalized probability for GSM8k and MBPP datasets as we find these two datasets can benefit from such normalization. We think this is because the Python programs have higher variance in length due to the flexible grammar and being more expressive. Moreover, the percentage of positive labels also denotes the "random" baseline, which is the expected execution accuracy by randomly picking  from the sampled programs. This provides the additional perspective of the ability of the CodeLMs, as well as the difficult of learning the verifiers for them.</p><p>Verifier Input Examples Here we show examples of the inputs to the verifiers for different datasets in Table <ref type="table">11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Ablation on Base LMs for Verification</head><p>In this work, we treat the choice of base models for the verifiers as a hyperparameter and use the best performing model for further experiments. Here we show the performance of all the base models we attempted on the four datasets, with results in Table <ref type="table">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Training Example Scaling for WTQ and GSM8k</head><p>Due to space limit, we are only able to show the ablation in number of training example for Spider. Here in Figure <ref type="figure">7</ref>, we show the results for WikiTQ and GSM8k as well. From the results, we can see that the learning of LEVER is also very data efficient on those two benchmarks, as non-trivial improvements can be observed even when we also report the performance of LEVER with previous work based on the official WikiTQ evaluator in Table <ref type="table">10</ref>.</p><p>From the results, we can see that LEVER still presents the state-of-the-art result under this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Case Study</head><p>Here we give some concrete examples to illustrate how LEVER work and when does it fail in Table 12. In the first example from the Spider dataset, we can see that program candidate ?2 selects from the wrong table, which results in an execution error. This is easily detected by the verifier thus put a low verification probability on such program. Meanwhile, the execution result ?1 from program ?1 seems much more likely to be the answer of the question to the verifier. In the second example from WikiTQ, however, the execution results ?1 and ?2 do not provide clear information as they are both county names. In this case, the verifier does not possess much more meaningful information than the generator, thus not able to identify the incorrect program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Prompts for Few-shot Generation</head><p>Finally, we append the full prompts we used for few-shot prompting the CodeLMs for Spider (Table <ref type="table">13</ref>, Table <ref type="table">14</ref>, Table <ref type="table">15</ref>), WikiTQ (Table <ref type="table">16</ref>, Table <ref type="table">17</ref>), GSM8k (Table <ref type="table">18</ref>), and MBPP (Table <ref type="table">19</ref>).       <ref type="bibr">( [25, 35, 22, 85, 14, 65, 75, 22, 58]</ref>,3)== <ref type="bibr">[85,</ref><ref type="bibr">75,</ref><ref type="bibr">65]</ref> """ Write a function to find the largest integers from a given list of numbers using heap queue algorithm. """ import heapq as hq def heap_queue_largest(nums,n): largest_nums = hq.nlargest(n, nums) return largest_nums ### Task End ### </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">JuICe: A large scale distantly supervised dataset for open domain context-based code generation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agashe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1546</idno>
		<ptr target="https://aclanthology.org/D19-1546" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="5436" to="5446" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Codet: Code generation with generated tests</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2207.10397" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P D O</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.12588</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Execution-guided neural program synthesis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1gfOiAqYm" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Latent execution for neural program synthesis beyond domain-specific languages</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Vaughan</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2021/hash/ba" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">W</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">December 6-14, 2021. 2021</date>
			<biblScope unit="page" from="22196" to="22208" />
		</imprint>
	</monogr>
	<note>d3aab2f6e667932daa3c5-Abstract. html</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weakly-supervised neural semantic parsing with a generative ranker</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="356" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Binding language models in symbolic languages</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nadkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02875</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Training verifiers to solve math word problems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discriminative reranking for natural language parsing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="70" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p16-1004</idno>
		<idno>doi: 10.18653</idno>
		<ptr target="https://doi.org/10.18653/v1/p16-1004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers. The Association for Computer Linguistics</publisher>
			<date type="published" when="2016">August 7-12, 2016. 2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aghajanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><surname>Incoder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.05999</idno>
		<title level="m">A generative model for code infilling and synthesis</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.10435</idno>
		<title level="m">Program-aided language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic parsing with abstract examples</title>
		<author>
			<persName><forename type="first">O</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Latcinnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1809" to="1819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nlyze: interactive programming by natural language for spreadsheet data analysis and manipulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marron</surname></persName>
		</author>
		<idno type="DOI">10.1145/2588555.2612177</idno>
		<ptr target="https://doi.org/10.1145/2588555.2612177" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Management of Data</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Dyreson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>?zsu</surname></persName>
		</editor>
		<meeting><address><addrLine>Snowbird, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014-06-22">2014. June 22-27, 2014. 2014</date>
			<biblScope unit="page" from="803" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">From language to programs: Bridging reinforcement learning and maximum marginal likelihood</title>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Decodingenhanced bert with disentangled attention</title>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Deberta</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006.03654" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Omnitab: Pretraining with natural and synthetic data for few-shot table-based question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter</title>
		<meeting>the 2022 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="932" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Language models (mostly) know what they know</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Conerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schiefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tran-Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>El-Showk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kravec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2207.05221" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><surname>.-T</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.11501</idno>
		<title level="m">Ds-1000: A natural and reliable benchmark for data science code generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Discriminative reranking for neural machine translation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7250" to="7264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Lago</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07814</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">On the advance of making language models better reasoners</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.02336</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Program synthesis from natural language using recurrent neural networks</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
		<idno>UW- CSE-17-03-01</idno>
		<imprint>
			<date type="published" when="2017-03">March 2017</date>
			<pubPlace>Seattle, WA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Washington Department of Computer Science and Engineering</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nl2bash: A corpus and semantic parser for natural language interface to the linux operating system</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation LREC 2018</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation LREC 2018<address><addrLine>Miyazaki (Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05">May, 2018. 2018</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Table pre-training via learning a neural sql executor</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ziyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><surname>Tapex</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Roberta</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1907.11692" />
		<title level="m">A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Learning from self-sampled correct and partially-correct programs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Inala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.14318</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A conversational paradigm for program synthesis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.13474</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Multi-turn dialogue response generation in an adversarial learning framework</title>
		<author>
			<persName><forename type="first">O</forename><surname>Olabiyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khazane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Mueller</surname></persName>
		</author>
		<idno>CoRR, abs/1805.11752</idno>
		<ptr target="http://arxiv.org/abs/1805.11752" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Optimizing language models for dialogue</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<author>
			<persName><surname>Chatgpt</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/chatgpt/" />
		<imprint>
			<date type="published" when="2022-11">November 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1142</idno>
		<ptr target="https://aclanthology.org/P15-1142" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07">July 2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Rasat: Integrating relational structures into pretrained seq2seq model for text-to-sql</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.06983</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Abstract syntax networks for code generation and semantic parsing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1105</idno>
		<ptr target="https://aclanthology.org/P17-1105" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="page" from="1139" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="140" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Evaluating the text-to-sql capabilities of large language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00498</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Parsing incrementally for constrained auto-regressive decoding from language models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Scholak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9895" to="9901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generate &amp; rank: A multi-task framework for math word problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.195</idno>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.195" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="2269" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Discriminative reranking for machine translation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004</title>
		<meeting>the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Natural language to code translation with execution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.11454</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the potential of lexico-logical alignments for semantic parsing to SQL queries</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">November 2020</date>
			<biblScope unit="page" from="1849" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<ptr target="https://aclanthology.org/2020.findings-emnlp.167" />
		<title level="m">URL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Alfred: A benchmark for interpreting grounded instructions for everyday tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="10737" to="10746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Problems in naturallanguage interface to DSMS with examples from EU-FID</title>
		<author>
			<persName><forename type="first">M</forename><surname>Templeton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Burger</surname></persName>
		</author>
		<idno type="DOI">10.3115/974194.974197</idno>
		<ptr target="https://aclanthology.org/A83-1002/" />
	</analytic>
	<monogr>
		<title level="m">1st Applied Natural Language Processing Conference, ANLP 1983, Miramar-Sheraton Hotel</title>
		<meeting><address><addrLine>Santa Monica, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983">February 1-3, 1983. 1983</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Unit test case generation with transformers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Svyatkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundaresan</surname></persName>
		</author>
		<idno>CoRR, abs/2009.05617</idno>
		<ptr target="https://arxiv.org/abs/2009.05617" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Multidocument summarization via discriminative summary reranking</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno>CoRR, abs/1507.02062</idno>
		<ptr target="http://arxiv.org/abs/1507.02062" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Rat-sql: Relation-aware schema encoding and linking for text-to-sql parsers</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7567" to="7578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Robust text-to-sql generation with execution-guided decoding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tatwawadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1807.03100" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.685</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.685" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="8696" to="8708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Generating sequences by learning to self-correct</title>
		<author>
			<persName><forename type="first">S</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00053</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Progress in natural language understanding: an application to lunar geology</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<idno type="DOI">10.1145/1499586.1499695</idno>
		<ptr target="https://doi.org/10.1145/1499586.1499695" />
	</analytic>
	<monogr>
		<title level="m">American Federation of Information Processing Societies: 1973 National Computer Conference</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AFIPS Press/ACM</publisher>
			<date type="published" when="1973-06-08">4-8 June 1973. 1973</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
	<note>AFIPS Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Sequence-based structured prediction for semantic parsing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gardent</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1127</idno>
		<ptr target="https://aclanthology.org/P16-1127" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08">August 2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1341" to="1350" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scholak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.05966</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1447</idno>
		<ptr target="https://aclanthology.org/P19-1447" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="4553" to="4559" />
		</imprint>
	</monogr>
	<note>Reranking for neural semantic parsing</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1425</idno>
		<ptr target="https://aclanthology.org/D18-1425" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11">October-November 2018</date>
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
		<ptr target="http://www.aaai.org/Library/AAAI/1996/aaai96-156.php" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth National Conference on Artificial Intelligence and Eighth Innovative Applications of Artificial Intelligence Conference, AAAI 96, IAAI 96</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Clancey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</editor>
		<meeting>the Thirteenth National Conference on Artificial Intelligence and Eighth Innovative Applications of Artificial Intelligence Conference, AAAI 96, IAAI 96<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press / The MIT Press</publisher>
			<date type="published" when="1996">August 4-8, 1996. 1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<ptr target="https://dslpitt.org/uai/displayArticleDetails.jsp?mmnu=1" />
	</analytic>
	<monogr>
		<title level="m">UAI &apos;05, Proceedings of the 21st Conference in Uncertainty in Artificial Intelligence</title>
		<meeting><address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2005">July 26-29, 2005. 2005</date>
			<biblScope unit="page" from="2" to="1209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.16490</idno>
		<title level="m">Coder reviewer reranking for code generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno>CoRR, abs/1709.00103</idno>
		<ptr target="http://arxiv.org/abs/1709.00103" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Tacube</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12682</idno>
		<title level="m">Pre-computing data cubes for answering numerical-reasoning questions over tabular data</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Hierarchical control of situated agents through natural language</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.08214</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
