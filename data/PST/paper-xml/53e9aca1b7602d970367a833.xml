<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Optimal Verification of Operations on Dynamic Sets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Charalampos</forename><surname>Papamanthou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
								<address>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roberto</forename><surname>Tamassia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
								<address>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Triandopoulos</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">RSA Laboratories</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Boston University</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Optimal Verification of Operations on Dynamic Sets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEE7E8FEB9E45BECF65363AAA5CA3A8A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the design of protocols for set-operation verification, namely the problem of cryptographically checking the correctness of outsourced set operations performed by an untrusted server over a dynamic collection of sets that are owned (and updated) by a trusted source. We present new authenticated data structures that allow any entity to publicly verify a proof attesting the correctness of primitive set operations such as intersection, union, subset and set difference. Based on a novel extension of the security properties of bilinear-map accumulators as well as on a primitive called accumulation tree, our protocols achieve optimal verification and proof complexity (i.e., only proportional to the size of the query parameters and the answer), as well as optimal update complexity (i.e., constant), while incurring no extra asymptotic space overhead. The proof construction is also efficient, adding a logarithmic overhead to the computation of the answer of a set-operation query. In contrast, existing schemes entail high communication and verification costs or high storage costs. Applications of interest include efficient verification of keyword search and database queries. The security of our protocols is based on the bilinear q-strong Diffie-Hellman assumption.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Providing integrity guarantees in third-party data management settings is an active area of research, especially in view of the growth in usage of cloud computing. In such settings, verifying the correctness of outsourced computations performed over remotely stored data becomes a crucial property for the trustworthiness of cloud services. Such a verification process should incur minimal overheads to the clients or otherwise the benefits of computation outsourcing are dismissed; ideally, computations should be verified without having to locally rerun them or to utilize too much extra cloud storage.</p><p>In this paper, we study the verification of outsourced operations on general sets and consider the following problem. Assuming that a dynamic collection of m sets S 1 , S 2 , . . . , S m is remotely stored at an untrusted server, we wish to publicly verify basic operations on these sets, such as intersection, union and set difference. For example, for an intersection query of t sets specified by indices 1 ≤ i 1 , i 2 , . . . , i t ≤ m, we aim at designing techniques that allow any client to cryptographically check the correctness of the returned answer I = S i1 ∩ S i2 ∩ . . . ∩ S it . Moreover, we wish the verification of any set operation to be operation-sensitive, meaning that the resulting complexity depends only on the (description and outcome of the) operation, and not on the sizes of the involved sets. That is, if δ = |I| is the answer size then we would like the verification cost to be proportional to t + δ, and independent of m or i |S i |; note that work at least proportional to t + δ is needed to verify any such query's answer. Applications of interest include keyword search and database queries, which boil down to set operations. Relation to verifiable computing. Recent works on verifiable computing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b18">16]</ref> achieve operation-sensitive verification of general functionalities, thus covering set operations as a special case. Although such approaches clearly meet our goal with respect to optimal verifiability, they are inherently inadequate to meet our other goals with respect to public verifiability and dynamic updates, both important properties in the context of outsourced data querying. Indeed, to outsource the computation as an encrypted circuit, the works in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b18">16]</ref> make use of some secret information which is also used by the verification algorithm, thus effectively supporting only one verifier; instead, we seek for schemes that allow any client (knowing only a public key) to query the set collection and verify the returned results. Also, the description of the circuit in these works is fixed at the initialization of the scheme, thus effectively supporting no updates in the outsourced data; instead, we seek for schemes that are dynamic. In other scenarios, but still in the secret-key setting, protocols for general functionalities and polynomial evaluation have recently been proposed in <ref type="bibr" target="#b11">[11]</ref> and <ref type="bibr" target="#b6">[6]</ref> respectively.</p><p>Aiming at both publicly verifiable and dynamic solutions, we study set-operation verification in the model of authenticated data structures (ADSs). A typical setting in this model, usually referred to as the three-party model <ref type="bibr" target="#b40">[36]</ref>, involves protocols executed by three participating entities. A trusted party, called source, owns a data structure (here, a collection of sets) that is replicated along with some cryptographic information to one or more untrusted parties, called servers. Accordingly, clients issue data-structure queries to the servers and are able to verify the correctness of the returned answers, based only on knowledge of public information which includes a public key and a digest produced by the source (e.g., the root hash of a Merkle tree). <ref type="foot" target="#foot_1">1</ref> Updates on the data structure are performed by the source and appropriately propagated by the servers. Variations of this model include: (i) a two-party variant (e.g., <ref type="bibr" target="#b34">[30]</ref>), where the source keeps only a small state (i.e., only a digest) and performs both the updates/queries and the verifications-this model is directly comparable to the model of verifiable computing; (ii) the memory checking model <ref type="bibr" target="#b7">[7]</ref>, where read/write operations on an array of memory cells is verified-however, the absence of the notion of proof computation in memory checking (the server is just a storage device) as well as the feature of public verifiability in authenticated data structures make the two models fundamentally different. <ref type="foot" target="#foot_2">2</ref>Achieving operation-sensitive verification. In this work, we design authenticated data structures for the verification of set operations in an operation-sensitive manner, where the proof and verification complexity depends only on the description and outcome of the operation and not on the size of the involved sets. Conceptually, this property is similar to the property of super-efficient verification that has been studied in certifying algorithms <ref type="bibr" target="#b25">[21]</ref> and certification data structures <ref type="bibr" target="#b22">[19,</ref><ref type="bibr" target="#b41">37]</ref>, which is achieved as well as in the context of verifiable computing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b18">16]</ref>, where an answer can be verified with complexity asymptotically less than the complexity required to produce it. Whether the above optimality property is achievable for set operations (while keeping storage linear) was posed as an open problem in <ref type="bibr" target="#b27">[23]</ref>. We close this problem in the affirmative.</p><p>All existing schemes for set-operation verification fall into the following two rather straightforward and highly inefficient solutions. Either short proofs for the answer of every possible set-operation query are precomputed allowing for optimal verification at the client at the cost of exponential storage and update overheads at the source and the server-an undesirable trade-off, as it is against storage outsourcing. Or integrity proofs for all the elements of the sets involved in the query are given to the client who locally verifies the query result: in this case the verification complexity can be linear in the problem size-an undesirable feature, as it is against computation outsourcing.</p><p>We achieve optimal verification by departing from the above approaches as follows. We first reduce the problem of verifying set operations to the problem of verifying the validity of some more primitive relations on sets, namely subset containment and set disjointness. Then for each such primitive relation we employ a corresponding cryptographic primitive to optimally verify its validity. In particular, we extend the bilinear-map accumulator to optimally verify subset containment (Lemmas 1 and 4), inspired by <ref type="bibr" target="#b36">[32]</ref>. We then employ the extended Euclidean algorithm over polynomials (Lemma 5) in combination with subset containment proofs to provide a novel optimal verification test for set disjointness. The intuition behind our technique is that disjoint sets can be represented by polynomials mutually indivisible, therefore there exist other polynomials so that the sum of their pairwise products equals to one-this is the test to be used in the proof. Still, transmitting (and processing) these polynomials is bandwidth (and time) prohibitive and does not lead to operation-sensitive verification. Bilinearity properties, however, allow us to compress their coefficients in the exponent and, yet, use them meaningfully, i.e., compute an internal product. This is why although a conceptually simpler RSA accumulator <ref type="bibr" target="#b4">[5]</ref> would yield a mathematically sound solution, a bilinear-map accumulator <ref type="bibr" target="#b32">[28]</ref> is essential for achieving the desired complexity goal.</p><p>We formally describe our protocols using an authenticated data structure scheme or ADS scheme (Definition 1). An ADS scheme consists of algorithms {genkey, setup, update, refresh, query, verify} such that: (i) genkey produces the secret and public key of the system; (ii) on input a plain data structure D, setup initializes the authenticated data structure auth(D); (iii) having access to the secret key, update computes the updated digest of auth(D); (iv) without having access to the secret key, refresh updates auth(D); (v) query computes cryptographic proofs Π(q) for answers α(q) to data structure queries q; (vi) verify processes a proof Π and an answer α and either accepts or rejects. Note that neither query nor verify have access to the secret key, thus modeling computation outsourcing and public verifiability. An ADS scheme must satisfy certain correctness and security properties (Definitions 2 and 3). We note that protocols in both the three-party and the two-party models can be realized via an ADS scheme.</p><p>Our main result, Theorem 1, presents the first ADS scheme to achieve optimal verification of the set operations intersection, union, subset and set difference, as well as optimal updates on the underlying collection of sets. Our scheme is proved secure under the bilinear extension of the q-strong Diffie-Hellman assumption (see, e.g., <ref type="bibr" target="#b8">[8]</ref>). Complexity model. To explicitly measure complexity of various algorithms with respect to number of primitive cryptographic operations, without considering the dependency on the security parameter, we adopt the complexity model used in memory checking <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b15">14]</ref>, which has been only implicitly used in ADS literature. The access complexity of an algorithm is defined as the number of memory accesses performed during its execution on the authenticated data structure that is stored in an indexed memory of n cells.<ref type="foot" target="#foot_3">3</ref> E.g., a Merkle tree <ref type="bibr" target="#b28">[24]</ref> has O(log n) update access complexity since the update algorithm needs to read and write O(log n) memory cells of the authenticated data structure, each cell storing exactly one hash value. The group complexity of a data collection (e.g., proof or ADS group complexity) is defined as the number of elementary data objects (e.g., hash values or elements in Z p ) contained in this collection. Note that although the access and group complexities are respectively related to the time and space complexities, the former are in principle smaller than the latter. This is because time and space complexities are counting number of bits and are always functions of the security parameter which, in turn, is always Ω(log n). Therefore time and space complexities are always Ω(log n), whereas access and group complexities can be O <ref type="bibr" target="#b0">(1)</ref>.</p><p>Finally, whenever it is clear from the context, we omit the terms "access" and "group".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work.</head><p>The great majority of authenticated data structures involve the use of cryptographic hashing <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b21">18,</ref><ref type="bibr" target="#b24">20,</ref><ref type="bibr" target="#b27">23,</ref><ref type="bibr" target="#b31">27,</ref><ref type="bibr" target="#b43">39]</ref> or other primitives <ref type="bibr" target="#b19">[17,</ref><ref type="bibr" target="#b35">31,</ref><ref type="bibr" target="#b36">32]</ref> to hierarchically compute over the outsourced data one or more digests. Most of these schemes incur verification costs that are proportional to the time spent to produce the query answer, thus they are not operation sensitive. Some bandwidth-optimal and operation-sensitive solutions for verification of various (e.g., range search) queries appear in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">19]</ref>. Despite the fact that privacy-related problems for set operations have been extensively studied in the cryptographic literature (e.g., <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b16">15]</ref>), existing work on the integrity dimension of set operations appears mostly in the database literature. In <ref type="bibr" target="#b27">[23]</ref>, the importance of coming up with an operation-sensitive scheme is identified. In <ref type="bibr" target="#b30">[26]</ref>, possibly the closest in context work to ours, set intersection, union and difference are authenticated with linear costs. Similar bounds appear in <ref type="bibr" target="#b42">[38]</ref>. In <ref type="bibr" target="#b33">[29]</ref>, a different approach is taken: In order to achieve operation-sensitivity, expensive pre-processing and exponential space are required (answers to all possible queries are signed). Finally, related to our work are non-membership proofs, both for the RSA <ref type="bibr" target="#b26">[22]</ref> and the bilinearmap <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">13]</ref> accumulators. A comparison of our work with existing schemes appears in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>We denote with k the security parameter and with neg(k) a negligible function. <ref type="foot" target="#foot_4">4</ref>The bilinear-map accumulator. Let G be a cyclic multiplicative group of prime order p, generated by element g ∈ G. Let also G be a cyclic multiplicative group of the same order p, such that there exists a pairing e : G × G → G with the following properties: (i) Bilinearity: e(P a , Q b ) = e(P, Q) ab for all P, Q ∈ G and a, b ∈ Z p ; (ii) Nondegeneracy: e(g, g) = 1; (iii) Computability: For all P, Q ∈ G, e(P, Q) is efficiently computable. We call (p, G, G, e, g) a tuple of bilinear pairing parameters, produced as the output of a probabilistic polynomial-time algorithm that runs on input 1 k .</p><p>In this setting, the bilinear-map accumulator <ref type="bibr" target="#b32">[28]</ref> is an efficient way to provide short proofs of membership for elements that belong to a set. Let s ∈ Z * p be a randomly chosen value that constitutes the trapdoor in the scheme. The accumulator primitive accumulates elements in Z p -{s}, outputting a value that is an element in G. For a set of elements X in Z p -{s} the accumulation value acc(X ) of X is defined as acc(X ) = g x∈X (x+s) . <ref type="foot" target="#foot_5">5</ref>Value acc(X ) can be constructed using X and g, g s , g s 2 , . . . , g s q (through polynomial interpolation), where q ≥ |X|. Subject to acc(X ) each element in X has a succinct membership proof. More generally, the proof of subset containment of a set S ⊆ Xfor |S| = 1, this becomes a membership proof-is the witness (S, W S,X ) where</p><formula xml:id="formula_0">W S,X = g x∈X -S (x+s) . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>Subset containment of S in X can be checked through relation e(W S,X , g x∈S (x+s) )</p><p>? = e (acc(X ), g) by any verifier with access only to public information. The security property of the bilinear-map accumulator, namely that computing fake but verifiable subset containment proofs is hard, can be proved using the bilinear q-strong Diffie-Hellman assumption, which is slightly stronger than the q-strong Diffie-Hellman assumption <ref type="bibr" target="#b8">[8]</ref>. <ref type="foot" target="#foot_6">6</ref>Assumption 1 (Bilinear q-strong Diffie-Hellman assumption). Let k be the security parameter and (p, G, G, e, g) be a tuple of bilinear pairing parameters. Given the elements g, g s , . . . , g s q ∈ G for some s chosen at random from Z * p , where q = poly(k), no probabilistic polynomial-time algorithm can output a pair (a, e(g, g) 1/(a+s) ) ∈ Z p ×G, except with negligible probability neg(k).</p><p>We next prove the security of subset witnesses by generalizing the proof in <ref type="bibr" target="#b32">[28]</ref>. Subset witnesses also appeared (independent of our work but without a proof) in <ref type="bibr" target="#b10">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1 (Subset containment).</head><p>Let k be the security parameter and (p, G, G, e, g) be a tuple of bilinear pairing parameters. Given the elements g, g s , . . . , g s q ∈ G for some s chosen at random from Z * p and a set of elements X in Z p -{s} with q ≥ |X |, suppose there is a probabilistic polynomial-time algorithm that finds S and W such that S X and e(W, g x∈S (x+s) ) = e(acc(X ), g). Then there is a probabilistic polynomial-time algorithm that breaks the bilinear q-strong Diffie-Hellman assumption.</p><p>Proof. Suppose there is a probabilistic polynomial-time algorithm that computes such a set S = {y 1 , y 2 , . . . , y } and a fake witness W. Let X = {x 1 , x 2 , . . . , x n } and y j / ∈ X for some 1 ≤ j ≤ . This means that e(W, g) y∈S (y+s) = e(g, g) (x1+s)(x2+s)... (xn+s) .</p><formula xml:id="formula_2">Note that (y j + s) does not divide (x 1 + s)(x 2 + s) . . . (x n + s). Therefore there exist polynomial Q(s) (computable in polynomial time) of degree n -1 and constant λ = 0, such that (x 1 + s)(x 2 + s) . . . (x n + s) = Q(s)(y j + s) + λ. Thus we have e(W, g) (yj +s) 1≤i =j≤ (yi+s) = e(g, g) Q(s)(yj+s)+λ ⇒ e(g, g) 1 y j +s = e(W, g) 1≤i =j≤ (yi+s) e(g, g) -Q(s) λ -1 .</formula><p>Thus, this algorithm can break the bilinear q-strong Diffie-Hellman assumption.</p><p>Tools for polynomial arithmetic. Our solutions use (modulo p) polynomial arithmetic.</p><p>We next present two results that are extensively used in our techniques, contributing to achieve the desired complexity goals. The first result on polynomial interpolation is derived using an FFT algorithm (see Preparata and Sarwate <ref type="bibr" target="#b38">[34]</ref>) that computes the DFT in a finite field (e.g., Z p ) for arbitrary n and performing O(n log n) field operations. We note that an n-th root of unity is not required to exist in Z p for this algorithm to work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2 (Polynomial interpolation with FFT [34]</head><p>). Let</p><formula xml:id="formula_3">n i=1 (x i + s) = n i=0 b i s i be a degree-n polynomial. The coefficients b n = 0, b n-1 , . . . , b 0 of the polynomial can be computed with O(n log n) complexity, given x 1 , x 2 , . . . , x n .</formula><p>Lemma 2 refers to an efficient process for computing the coefficients of a polynomial, given its roots x 1 , x 2 , . . . , x n . In our construction, we make use of this process a numbers of times, in particular, when, given some values x 1 , x 2 , . . . , x n to be accumulated, an untrusted party needs to compute g (x1+s)(x2+s)...(xn+s) without having access to s. However, access to g, g s , . . . , g s n (part of the public key) is allowed, and therefore computing the accumulation value boils down to a polynomial interpolation.</p><p>We next present a second result that will be used in our verification algorithms. Related to certifying algorithms <ref type="bibr" target="#b25">[21]</ref>, this result states that if the vector of coefficients b = [b n , b n-1 , . . . , b 0 ] is claimed to be correct, then, given the vector of roots x = [x 1 , x 2 , . . . , x n ], with high probability, vector b can be certified to be correct with complexity asymptotically less than O(n log n), i.e., without an FFT computation from scratch. This is achieved with the following algorithm: Authenticated data structure scheme. We now define our authenticated data structure scheme (ADS scheme), as well as the correctness and security properties it must satisfy.</p><formula xml:id="formula_4">Algorithm {accept, reject} ← certify(b, x, pk): The algorithm picks a random κ ∈ Z * p . If n i=0 b i κ i = n i=1 (x i + κ),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (ADS scheme).</head><p>Let D be any data structure that supports queries q and updates u. Let auth(D) denote the resulting authenticated data structure and d the digest of the authenticated data structure, i.e., a constant-size description of D. An ADS scheme A is a collection of the following six probabilistic polynomial-time algorithms: ) and the updated digest d h+1 ; 5. {Π(q), α(q)} ← query(q, D h , auth(D h ), pk): On input a query q on data structure D h , the authenticated data structure auth(D h ) and the public key, it returns the answer α(q) to the query, along with a proof Π(q); 6. {accept, reject} ← verify(q, α, Π, d h , pk): On input a query q, an answer α, a proof Π, a digest d h and the public key, it outputs either accept or reject.</p><p>Let {accept, reject} ← check(q, α, D h ) be an algorithm that decides whether α is a correct answer for query q on data structure D h (check is not part of the definition of an ADS scheme). There are two properties that an ADS scheme should satisfy, namely correctness and security (intuition follows from signature schemes definitions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2 (Correctness).</head><p>Let ASC be an ADS scheme {genkey, setup, update, refresh, query, verify}. We say that the ADS scheme ASC is correct if, for all k ∈ N, for all {sk, pk} output by algorithm genkey, for all D h , auth(D h ), d h output by one invocation of setup followed by polynomially-many invocations of refresh, where h ≥ 0, for all queries q and for all Π(q), α(q) output by query(q, D h , auth(D h ), pk), with all but negligible probability, whenever algorithm check(q, α(q), D h ) outputs accept, so does algorithm verify(q, Π(q), α(q), d h , pk). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Construction and Algorithms</head><p>In this section we present an ADS scheme for set-operation verification. The underlying data structure for which we design our ADS scheme is called sets collection, and can be viewed as a generalization of the inverted index <ref type="bibr" target="#b3">[4]</ref> data structure. Sets collection. The sets collection data structure consists of m sets, denoted with S 1 , S 2 , . . . , S m , each containing elements from a universe U. Without loss of generality we assume that the universe U is the set of nonnegative integers in the interval [m + 1, p -1] -{s}, <ref type="foot" target="#foot_7">7</ref> where p is k-bit prime, m is the number of the sets in our collection that has bit size O(log k), k is the security parameter and s is the trapdoor of the scheme (see algorithm genkey). A set S i does not contain duplicate elements, however an element x ∈ U can appear in more than one set. Each set is sorted and the total space needed is O(m + M ), where M is the sum of the sizes of the sets.</p><p>In order to get some intuition, we can view the sets collection as an inverted index. In this view, the elements are pointers to documents and each set S i corresponds to a term w i in the dictionary, containing the pointers to documents where term w i appears. In this case, m is the number of terms being indexed, which is typically in the hundreds of thousands, while M , bounded from below by the number of documents being indexed, is typically in the billions. Thus, the more general terms "elements" and "sets" in a sets collection can be instantiated to the more specific "documents" and "terms".</p><p>The operations supported by the sets collection data structure consist of updates and queries. An update is either an insertion of an element into a set or a deletion of an element from a set. An update on a set of size n takes O(log n) time. For simplicity, we assume that the number m of sets does not change after updates. A query is one of the following standard set operations: (i) Intersection:</p><formula xml:id="formula_5">Given indices i 1 , i 2 , . . . , i t , return set I = S i1 ∩ S i2 ∩ . . . ∩ S it ; (ii) Union: Given indices i 1 , i 2 , . . . , i t , return set U = S i1 ∪ S i2 ∪ . . . ∪ S it ;</formula><p>(iii) Subset query: Given indices i and j, return true if S i ⊆ S j and false otherwise; (iv) Set difference: Given indices i and j, return set D = S i -S j . For the rest of the paper, we denote with δ the size of the answer to a query operation, i.e., δ is equal to the size of I, U, or D. For a subset query, δ is O <ref type="bibr" target="#b0">(1)</ref>.</p><p>We next detail the design of an ADS scheme ASC for the sets collection data structure. This scheme provides protocols for verifying the integrity of the answers to set operations in a dynamic setting where sets evolve over time through updates. The goal is to achieve optimality in the communication and verification complexity: a query with t parameters and answer size δ should be verified with O(t + δ) complexity, and at the same time query and update algorithms should be efficient as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setup and Updates</head><p>We describe an ADS scheme ASC = {genkey, setup, update, refresh, query, verify} for the sets collection data structure and we prove that its algorithms satisfy the complexities of Table <ref type="table" target="#tab_0">1</ref>. We begin with the algorithms that are related to the setup and the updates of the authenticated data structure.</p><p>Algorithm {sk, pk} ← genkey(1 k ): Bilinear pairing parameters (p, G, G, e, g) are picked and an element s ∈ Z * p is chosen at random. Subsequently, an one-to-one function h(•) : G → Z * p is used. This function simply outputs the bit description of the elements of G according to some canonical representation of G. Finally the algorithm outputs sk = s and pk = {h(•), p, G, G, e, g, g}, where vector g contains values</p><formula xml:id="formula_6">g = g s , g s 2 , . . . , g s q ,</formula><p>where q ≥ max{m, max i=1,...,m {|S i |}}. The algorithm has O(1) access complexity.</p><p>Algorithm {D 0 , auth(D 0 ), d 0 } ← setup(D 0 , sk, pk): Let D 0 be our initial data structure, i.e., the one representing sets S 1 , S 2 , . . . , S m . The authenticated data structure auth(D 0 ) is built as follows. First, for each set S i its accumulation value acc(S i ) = g x∈S i (x+s) is computed (see Section 2). Subsequently, the algorithm picks a constant 0 &lt; &lt; 1. Let T be a tree that has l = 1/ levels and m leaves, numbered 1, 2, . . . , m, where m is the number of the sets of our sets collection data structure.</p><p>Since T is a constant-height tree, the degree of any internal node of it is O(m ). We call such a tree an accumulation tree, which was originally introduced (combined with different cryptography) in <ref type="bibr" target="#b36">[32]</ref>. For each node of the tree v, the algorithm recursively computes the digest d(v) of v as follows. If v is a leaf corresponding to set S i , where 1 ≤ i ≤ m, the algorithm sets d(v) = acc(S i ) (i+s) ; here, raising value acc(S i ) to exponent i + s, under the constraint that i ≤ m, is done to also accumulate the index i of set S i (and thus prove that acc(S i ) refers to S i ). If node v is not a leaf, then</p><formula xml:id="formula_7">d(v) = g w∈N (v) (h(d(w)+s)) ,<label>(3)</label></formula><p>where N (v) denotes the set of children of node v. The algorithm outputs all the sets S i as the data structure D 0 , and all the accumulation values acc(S i ) for 1 ≤ i ≤ m, the tree T and all the digests d(v) for all v ∈ T as the authenticated data structure auth(D 0 ). Finally, the algorithm sets d 0 = d(r) where r is the root of T , i.e., d 0 is the digest of the authenticated data structure (defined similarly as in a Merkle tree). <ref type="foot" target="#foot_8">8</ref>The access complexity of the algorithm is O(m + M ) (for postorder traversal of T and computation of acc(S i )), where M = m i=1 |S i |. The group complexity of auth(D 0 ) is also O(m + M ) since the algorithm stores one digest per node of T , T has O(m) nodes and there are M elements contained in the sets, as part of auth(D 0 ). Algorithm {D h+1 , auth(D h+1 ), d h+1 , upd} ← update(u, D h , auth(D h ), d h , sk, pk): We consider the update "insert element x ∈ U into set S i " (note that the same algorithm could be used for element deletions). Let v 0 be the leaf node of T corresponding to set S i . Let v 0 , v 1 , . . . , v l be the path in T from node v 0 to the root of the tree, where l = 1/ . The algorithm initially sets d (v 0 ) = acc(S i ) (x+s) , i.e., it updates the accumulation value that corresponds to the updated set (note that in the case where x is deleted from S i , the algorithm sets d (v 0 ) = acc(S i ) (x+s) -1 ). Then the algorithm sets</p><formula xml:id="formula_8">d (v j ) = d(v j ) (h(d (vj-1))+s)(h(d(vj-1))+s) -1 for j = 1, . . . , l ,<label>(4)</label></formula><p>where d(v j-1 ) is the current digest of v j-1 and d (v j-1 ) is the updated digest of v j-1 .<ref type="foot" target="#foot_9">9</ref> All these newly computed values (i.e., the new digests) are stored by the algorithm. The algorithm then outputs the new digests d (v j-1 ), j = 1, . . . , l, along the path from the updated set to the root of the tree, as part of information upd. Information upd also includes x and d (v l ). The algorithm also sets d h+1 = d (v l ), i.e., the updated digest is the newly computed digest of the root of T . Finally the new authenticated data structure auth(D h+1 ) is computed as follows: in the current authenticated data structure auth(D h ) that is input of the algorithm, the values d(v j-1 ) are overwritten with the new values d (v j-1 ) (j = 1, . . . , l), and the resulting structure is included in the output of the algorithm. The number of operations performed is proportional to 1/ , therefore the complexity of the algorithm is O(1). Algorithm {D h+1 , auth(D h+1 ), d h+1 } ← refresh(u, D h , auth(D h ), d h , upd, pk): We consider the update "insert element x ∈ U into set S i ". Let v 0 be the node of T corresponding to set S i . Let v 0 , v 1 , . . . , v l be the path in T from node v 0 to the root of the tree. Using the information upd, the algorithm sets d(v j ) = d (v j ) for j = 0, . . . , l, i.e., it updates the digests that correspond to the updated path. Finally, it outputs the updated sets collection as D h+1 , the updated digests d(v j ) (along with the ones that belong to the nodes that are not updated) as auth(D h+1 ) and d (v l ) (contained in upd) as d h+1 . <ref type="foot" target="#foot_10">10</ref>The algorithm has O(1) complexity as the number of performed operations is O(1/ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Authenticity of Accumulation Values</head><p>So far we have described the authenticated data structure auth(D h ) that our ADS scheme ASC will use for set-operation verifications. Overall, auth(D h ) comprises a set of m accumulation values acc(S i ), one for each set S i , i = 1, . . . , m, and a set of O(m) digests d(v), one for each internal node v of the accumulation tree T . Our proof construction and verification protocols for set operations (described in Section 3.3) make use of the accumulation values acc(S i ) (subject to which subset-containment witnesses can be defined), and therefore it is required that the authenticity of each such value can be verified. Tree T serves this exact role by providing short correctness proofs for each value acc(S i ) stored at leaf i of T , this time subject to the (global) digest d h stored at the root of T . We next provide the details related to proving the authenticity of acc(S i ).</p><p>The correctness proof Π i of accumulation value acc(S i ), 1 ≤ i ≤ m, is a collection of O(1) bilinear-map accumulator witnesses (as defined in Section 2). In particular, Π i is set to be the ordered sequence Π = (π 1 , π 2 , . . . , π l ), where π j is the pair of the digest of node v j-1 and a witness that authenticates v j-1 , subject to node v j , in the path v 0 , v 1 , . . . , v l defined by leaf v 0 storing accumulation value acc(S i ) and the root v l of T . Conveniently, π j is defined as π j = (β j , γ j ), where</p><formula xml:id="formula_9">β j = d(v j-1 ) and γ j = W vj-1(vj ) = g w∈N (v j )-{v j-1 } (h(d(w))+s) .</formula><p>(</p><formula xml:id="formula_10">)<label>5</label></formula><p>Note that π j is the witness for a subset of one element, namely h(d(v j-1 )) (recall, d(v 0 ) = acc(S i ) (i+s) ). Clearly, pair π j has group complexity O( <ref type="formula" target="#formula_0">1</ref>) and can be constructed using polynomial interpolation with O(m log m) complexity, by Lemma 2 and since v j has degree O(m ). Since Π i consists of O( <ref type="formula" target="#formula_0">1</ref>) such pairs, we conclude that the proof Π i for an accumulation value acc(S i ) can be constructed with O(m log m) complexity and has O(1) group complexity. The following algorithms queryTree and verifyTree are used to formally describe the construction and respectively the verification of such correctness proofs. Similar methods have been described in <ref type="bibr" target="#b36">[32]</ref>. Algorithm {Π i , α i } ← queryTree(i, D h , auth(D h ), pk): Let v 0 , v 1 , . . . , v l be the path of T from the node storing acc(S i ) to the root of T . The algorithm computes Π i by setting Π i = (π 1 , π 2 , . . . , π l ), where π j = (d(v j-1 ), W vj-1 (vj ) ) and W vj-1(vj ) is given in Equation <ref type="formula" target="#formula_10">5</ref>and computed by Lemma 2. Finally, the algorithm sets α i = acc(S i ).</p><p>Algorithm {accept, reject} ← verifyTree(i, α i , Π i , d h , pk): Let the proof be Π i = (π 1 , π 2 , . . . , π l ), where π j = (β j , γ j ). The algorithm outputs reject if one of the following is true: (i) e(β 1 , g) = e(α i , g i g s ); or (ii) e (β j , g) = e γ j-1 , g h(βj-1) g s for some 2 ≤ j ≤ l; or (iii) e(d h , g) = e γ l , g h(β l ) g s . Otherwise, it outputs accept. We finally provide some complexity and security properties that hold for the correctness proofs of the accumulated values. The following result is used as a building block to derive the complexity of our scheme and prove its security (Theorem 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 4. Algorithm queryTree runs with O(m log m) access complexity and outputs a proof of O(1) group complexity. Moreover algorithm verifyTree has O(1) access complexity. Finally, for any adversarially chosen proof Π</head><formula xml:id="formula_11">i (1 ≤ i ≤ m), if accept ← verifyTree(i, α i , Π i , d h , pk), then α i = acc(S i ) with probability Ω(1 -neg(k)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Queries and Verification</head><p>With the correctness proofs of accumulation values at hand, we complete the description of our scheme ASC by presenting the algorithms that are related to the construction and verification of proofs attesting the correctness of set operations. These proofs are efficiently constructed using the authenticated data structure presented earlier, and they have optimal size O(t + δ), where t and δ are the sizes of the query parameters and the answer. In the rest of the section, we focus on the detailed description of the algorithms for an intersection and a union query, but due to space limitations, we omit the details of the subset and the set difference query. We note, however, that the treatment of the subset and set difference queries is analogous to that of the intersection and union queries.</p><p>The parameters of an intersection or a union query are t indices i 1 , i 2 , . . . , i t , with 1 ≤ t ≤ m. To simplify the notation, we assume without loss of generality that these indices are 1, 2, . . . , t. Let n i denote the size of set S i (1 ≤ i ≤ t) and let N = t i=1 n i . Note that the size δ of the intersection or union is always O(N ) and that operations can be performed with O(N ) complexity, by using a generalized merge.</p><p>Intersection query. Let I = S 1 ∩ S 2 ∩ . . . ∩ S t = {y 1 , y 2 , . . . , y δ }. We express the correctness of the set intersection operation by means of the following two conditions:</p><formula xml:id="formula_12">Subset condition: I ⊆ S 1 ∧ I ⊆ S 2 ∧ . . . ∧ I ⊆ S t ;<label>(6)</label></formula><p>Completeness condition:</p><formula xml:id="formula_13">(S 1 -I) ∩ (S 2 -I) ∩ . . . ∩ (S t -I) = Ø . (<label>7</label></formula><formula xml:id="formula_14">)</formula><p>The completeness condition in Equation <ref type="formula" target="#formula_13">7</ref>is necessary since set I must contain all the common elements. Given an intersection I, and for every set S j , 1 ≤ i ≤ t, we define the degree-n j polynomial</p><formula xml:id="formula_15">P j (s) = x∈Sj-I (x + s) .<label>(8)</label></formula><p>The following result is based on the extended Euclidean algorithm over polynomials and provides our core verification test for checking the correctness of set intersection. Lemma 5. Set I is the intersection of sets S 1 , S 2 , . . . , S t if and only if there exist polynomials q 1 (s), q 2 (s), . . . , q t (s) such that q 1 (s)P 1 (s)+q 2 (s)P 2 (s)+. . .+q t (s)P t (s) = 1, where P j (s), j = 1, . . . , t, are defined in Equation <ref type="formula" target="#formula_15">8</ref>. Moreover, the polynomials q 1 (s), q 2 (s), . . . , q t (s) can be computed with O(N log 2 N log log N ) complexity.</p><p>Using Lemmas 2 and 5 we next construct efficient proofs for both conditions in Equations 6 and 7. In turn, the proofs are directly used to define the algorithms query and verify of our ADS scheme ASC for intersection queries.</p><p>Proof of subset condition. For each set S j , 1 ≤ j ≤ t, the subset witnesses W I,j = g Pj (s) = g x∈S j -I (x+s) are computed, each with O(n j log n j ) complexity, by Lemma 2. (Recall, W I,j serves as a proof that I is a subset of set S j .) Thus, the total complexity for computing all t required subset witnesses is O(N log N ), where N = t i=1 n i .<ref type="foot" target="#foot_11">11</ref> Proof of completeness condition. For each q j (s), 1 ≤ j ≤ t, as in Lemma 5 satisfying q 1 (s)P 1 (s) + q 2 (s)P 2 (s) + . . . + q t (s)P t (s) = 1, the completeness witnesses F I,j = g qj (s) are computed, by Lemma 5 with O(N log 2 N log log N ) complexity.</p><p>Algorithm {Π(q), α(q)} ← query(q, D h , auth(D h ), pk) (Intersection): Query q consists of t indices {1, 2, . . . , t}, asking for the intersection I of S 1 , S 2 , . . . , S t . Let I = {y 1 , y 2 , . . . , y δ }. Then α(q) = I, and the proof Π(q) consists of the following parts.</p><p>1. Coefficients b δ , b δ-1 , . . . , b 0 of polynomial (y 1 + s)(y 2 + s) . . . (y δ + s) that is associated with the intersection I = {y 1 , y 2 , . . . , y δ }. These are computed with O(δ log δ) complexity (Lemma 2) and they have O(δ) group complexity. 2. Accumulation values acc(S j ), j = 1, . . . , t, which are associated with sets S j , along with their respective correctness proofs Π j . These are computed by calling algorithm queryTree(j, D h , auth(D h ), pk), for j = 1, . . . , t, with O(tm log m) total complexity and they have O(t) total group complexity (Lemma 4). 3. Subset witnesses W I,j , j = 1, . . . , t, which are associated with sets S j and intersection I (see proof of subset condition). These are computed with O(N log N ) complexity and have O(t) total group complexity (Lemma 2). 4. Completeness witnesses F I,j , j = 1, . . . , t, which are associated with polynomials q j (s) of Lemma 5 (see proof of completeness condition). These are computed with O(N log 2 N log log N ) complexity and have O(t) group complexity (Lemma 5).</p><p>Algorithm {accept, reject} ← verify(q, α, Π, d h , pk) (Intersection): Verifying the result of an intersection query includes the following steps. ] and the answer α(q) = {y 1 , y 2 , . . . , y δ } as an input to algorithm certify(b, α(q), pk), in order to certify the validity of b δ , b δ-1 , . . . , b 0 . If certify outputs reject, the algorithm also outputs reject. <ref type="foot" target="#foot_12">12</ref> This step has O(δ) complexity (Lemma 3). 2. Subsequently, the algorithm uses the proof Π j to verify the correctness of acc(S j ), by running algorithm verifyTree(j, acc(S j ), Π j , d h , pk) for j = 1, . . . , t. If, for some j, verifyTree running on acc(S j ) outputs reject, the algorithm also outputs reject. This step has O(t) complexity (Lemma 4). 3. Next, the algorithm checks the subset condition:<ref type="foot" target="#foot_13">13</ref> e δ i=0 g s i bi , W I,j ? = e (acc(S j ), g) , for j = 1, . . . , t. (</p><p>If, for some j, the above check on subset witness W I,j fails, the algorithm outputs reject. This step has O(t + δ) complexity. 4. Finally, the algorithm checks the completeness condition:</p><formula xml:id="formula_17">t j=1 e (W I,j , F I,j ) ? = e(g, g) . (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>If the above check on the completeness witnesses F I,j , 1 ≤ j ≤ t, fails, the algorithm outputs reject. Or, if this relation holds, the algorithm outputs accept, i.e., it accepts α(q) as the correct intersection. This step has O(t) complexity.</p><p>Note that for Equation <ref type="formula" target="#formula_17">10</ref>, it holds t j=1 e (W I,j , F I,j ) = e(g, g) t j=1 qj (s)Pj (s) = e(g, g) when all the subset witnesses W I,j , all the completeness witnesses F I,j and all the sets accumulation values acc(S j ) have been computed honestly, since q 1 (s)P 1 (s)+ q 2 (s)P 2 (s) + . . . + q t (s)P t (s) = 1. This is a required condition for proving the correctness of our ADS scheme, as defined in Definition 2. We continue with the description of algorithms query and verify for the union query.</p><p>Union query. Let U = S 1 ∪S 2 ∪. . .∪S t = {y 1 , y 2 , . . . , y δ }. We express the correctness of the set union operation by means of the following two conditions:</p><p>Membership condition: ∀y i ∈ U ∃j ∈ {1, 2, . . . , t} : y i ∈ S j ;</p><p>(11)</p><formula xml:id="formula_19">Superset condition: (U ⊇ S 1 ) ∧ (U ⊇ S 2 ) ∧ . . . ∧ (U ⊇ S t ) . (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>The superset condition in Equation <ref type="formula" target="#formula_19">12</ref>is necessary since set U must exclude none of the elements in sets S 1 , S 2 , . . . , S t . We formally describe algorithms query and verify of our ADS scheme ASC for union queries.</p><p>Algorithm {Π(q), α(q)} ← query(q, D h , auth(D h ), pk) (Union): Query q asks for the union U of t sets S 1 , S 2 , . . . , S t . Let U = {y 1 , y 2 , . . . , y δ }. Then α(q) = U and the proof Π(q) consists of the following parts. ] and the answer U = α(q) = {y 1 , y 2 , . . . , y δ } as an input to algorithm certify(b, α(q), pk), in order to certify the validity of b δ , b δ-1 , . . . , b 0 . (2) Subsequently, the algorithm uses the proofs Π j to verify the correctness of acc(S j ), by using algorithm verifyTree(j, acc(S j ), Π j , d h , pk) for j = 1, . . . , t. If the verification fails for at least one of acc(S j ), the algorithm outputs reject. (3) Next, the algorithm verifies that each element y i , i = 1, . . . , δ, of the reported union belongs to some set S k , for some 1 ≤ k ≤ t (O(δ) complexity). This is done by checking that relation e(W yi,S k , g yi g s ) = e(acc(S k ), g) holds for all i = 1, . . . , δ; otherwise the algorithm outputs reject. (4) Finally, the algorithm verifies that all sets specified by the query are subsets of the union, by checking the following conditions:</p><p>e W Sj ,U , acc(S j ) ? = e δ i=0 g s i bi , g , for j = 1, . . . , t.</p><p>If any of the above checks fails, the algorithm outputs reject, otherwise, it outputs accept, i.e., U is accepted as the correct union.</p><p>Subset and set difference query. For a subset query (positive or negative), we use the property S i ⊆ S j ⇔ ∀y ∈ S i , y ∈ S j . For a set difference query we use the property</p><formula xml:id="formula_21">D = S i -S j ⇔ ∃F : F ∪ D = S i ∧ F = S i ∩ S j .</formula><p>The above conditions can both be checked in an operation-sensitive manner using the techniques we have presented before. We now give the main result in our work.</p><p>Theorem 1. Consider a collection of m sets S 1 , . . . , S m and let M = m i=1 |S i | and 0 &lt; &lt; 1. For a query operation involving t sets, let N be the sum of the sizes of the involved sets, and δ be the answer size. Then there exists an ADS scheme ASC = {genkey, setup, update, refresh, query, verify} for a sets collection data structure D with the following properties: (1) ASC is correct and secure according to Definitions 2 and 3 and based on the bilinear q-strong Diffie-Hellman assumption; <ref type="bibr" target="#b1">(2)</ref> The access complexity of algorithm (i) genkey is O( <ref type="formula" target="#formula_0">1</ref> </p><formula xml:id="formula_22">); (ii) setup is O(m + M ); (iii) update is O(1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Security, Protocols and Applications</head><p>In this section we give an overview of the security analysis of our ADS scheme, describe how it can be employed to provide verification protocols in the three-party <ref type="bibr" target="#b40">[36]</ref> and two-party <ref type="bibr" target="#b34">[30]</ref> authentication models, and finally discuss some concrete applications.</p><p>Security proof sketch. We provide some key elements of the security of our verification protocols focusing on set intersection queries. The security proofs of the other set operations share similar ideas. Let D 0 be a sets collection data structure consisting of m sets S 1 , S 2 , . . . , S m , 14 and consider our ADS scheme ASC = {genkey, setup, update, refresh, query, verify}. Let k be the security parameter and let {sk, pk} ← genkey(1 k ). The adversary is given the public key pk, namely {h(•), p, G, G, e, g, g s , . . . , g s q }, and unlimited access to all the algorithms of ASC, except for setup and update to which he only has oracle access. The adversary initially outputs the authenticated data structure auth(D 0 ) and the digest d 0 , through an oracle call to algorithm setup. Then the adversary picks a polynomial number of updates u i (e.g., insertion of an element x into a set S r ) and outputs the data structure D i , the authenticated data structure auth(D i ) and the digest d i through oracle access to update. Then he picks a set of indices q = {1, 2, . . . , t} (wlog), all between 1 and m and outputs a proof Π(q) and an answer I = I = S 1 ∩ S 2 ∩ . . . ∩ S t which is rejected by check as incorrect. Suppose the answer α(q) contains d elements. The proof Π(q) contains (i) Some coefficients b 0 , b 1 , . . . , b d ; (ii) Some accumulation values acc j with some respective correctness proofs Π j , for j = 1, . . . , t; (iii) Some subset witnesses W j with some completeness witnesses F j , for j = 1, . . . , t (this is, what algorithm verify expects for input).</p><p>Suppose verify accepts. Then: (i) By Lemma 3, b 0 , b 1 , . . . , b d are indeed the coefficients of the polynomial x∈I (x + s), except with negligible probability; (ii) By Lemma 4, values acc j are indeed the accumulation values of sets S j , except with negligible probability; (iii) By Lemma 1, values W j are indeed the subset witnesses for set I (with reference to S j ), i.e., W j = g Pj(s) , except with negligible probability; (iv) However, P 1 (s), P 2 (s), . . . , P t (s) are not coprime since I is incorrect and therefore I cannot contain all the elements of the intersection. Thus the polynomials P 1 (s), P 2 (s), . . . , P t (s) (Equation <ref type="formula" target="#formula_15">8</ref>) have at least one common factor, say (r + s) and it holds that P j (s) = (r + s)Q j (s) for some polynomials Q j (s) (computable in polynomial time), for all j = 1, . . . , t. By the verification of Equation 10 (completeness condition), we have</p><formula xml:id="formula_23">e(g, g) = t j=1 e (W j , F j ) = t j=1 e g Pj (s) , F j = t j=1 e g (r+s)Qj (s) , F j = t j=1 e g Qj (s) , F j (r+s) = ⎛ ⎝ t j=1 e g Qj (s) , F j ⎞ ⎠ (r+s) .</formula><p>Therefore we can derive an (r + s)-th root of e(g, g) as e(g, g)</p><formula xml:id="formula_24">1 r+s = t j=1 e g Qj (s) , F j .</formula><p>This means that if the intersection I is incorrect and all the verification tests are satisfied, we can derive a polynomial-time algorithm that outputs a bilinear q-strong Diffie-Hellman challenge (r, e(g, g) 1/(r+s) ) for an element r that is a common factor of the polynomials P 1 (s), P 2 (s), . . . , P t (s), which by Assumption 1 happens with probability neg(k). This concludes an ouline of the proof strategy for the case of intersection. Protocols. As mentioned in the introduction, our ADS scheme ASC can be used by a verification protocol in the three-party model <ref type="bibr" target="#b40">[36]</ref>. Here, a trusted entity, called source, owns a sets collection data structure D h , but desires to outsource query answering, in a trustworthy (verifiable) way. The source runs genkey and setup and outputs the authenticated data structure auth(D h ) along with the digest d h . The source subsequently signs the digest d h , and it outsources auth(D h ), D h , the digest d h and its signature to some untrusted entities, called servers. On input a data structure query q (e.g., an intersection query) sent by clients, the servers use auth(D h ) and D h to compute proofs Π(q), by running algorithm query, and they return to the clients Π(q) and the signature on d h along with the answer a(q) to q. Clients can verify these proofs Π(q) by running algorithm verify (since they have access to the signature of d h , they can verify that d h is authentic). When there is an update in the data structure (issued by the source), the source uses algorithm update to produce the new digest d h to be used in next verifications, while the servers update the authenticated data structure through refresh.</p><p>Additionally, our ADS scheme ASC can also be used by a non-interactive verification protocol in the two-party model <ref type="bibr" target="#b34">[30]</ref>. In this case, the source and the client coincide, i.e., the client issues both the updates and the queries, and it is required to keep only constant state, i.e., the digest of the authenticated data structure. Whenever there is an update by the client, the client retrieves a verifiable, constant-size portion of the authenticated data structure that is used for locally performing the update and for computing the new local state, i.e., the new digest. A non-interactive two-party protocol that uses an ADS scheme for a data structure D is directly comparable with the recent protocols for verifiable computing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b18">16]</ref> for the functionalities offered by the data structure D, e.g., computation of intersection, union, etc. Due to space limitations, we defer the detailed description of these protocols to the full version of the paper.</p><p>Applications. First of all, our scheme can be used to verify keyword-search queries implemented by the inverted index data structure <ref type="bibr" target="#b3">[4]</ref>: Each term in the dictionary corresponds to a set in our sets collection data structure which contains all the documents that include this term. A usual text query for terms m 1 and m 2 returns those documents that are included in both the sets that are represented by m 1 and m 2 , i.e., their intersection. Moreover, the derived authenticated inverted index can be efficiently updated as well. However, sometimes in keyword searches (e.g., keyword searches in the email inbox) it is desirable to introduce a "second" dimension: For example, a query could be "return emails that contain terms m 1 and m 2 and which were received between time t 1 and t 2 ", where t 1 &lt; t 2 . We call this variant a timestamped keyword-search. One solution for verifying such queries could be to embed a timestamp in the documents (e.g., each email message) and have the client do the filtering locally, after he has verifiedusing our scheme-the intersection of the sets that correspond to terms m 1 and m 2 . However, this approach is not operation-sensitive: The intersection can be bigger than the set output after the local filtering, making this solution inefficient. To overcome this inefficiency, we can use a segment-tree data structure <ref type="bibr" target="#b39">[35]</ref>, verifying in this way timestamped keyword-search queries efficiently with O(t log r + δ) complexity, where r is the total number of timestamps we are supporting. This involves building a binary tree T on top of sets of messages sent at certain timestamps and requiring each internal node of T be the union of messages stored in its children. Finally, our method can be used for verifying equi-join queries over relational tables, which boil down to set intersections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we presented an authenticated data structure for the optimal verification of set operations. The achieved efficiency is mainly due to new, extended security properties of accumulators based on pairing-based cryptography. Our solution provides two important properties, namely public verifiability and dynamic updates, as opposed to existing protocols in the verifiable computing model that provide generality and secrecy, but verifiability in a static, secret-key setting only.</p><p>A natural question to ask is whether outsourced verifiable computations with secrecy and efficient dynamic updates are feasible. Analogously, it is interesting to explore whether other specific functionalities (beyond set operations) can be optimally and publicly verified. Finally, according to a recently proposed definition of optimality <ref type="bibr" target="#b37">[33]</ref>, our construction is nearly optimal: verification and updates are optimal, but not queries. It is interesting to explore whether an optimal authenticated sets collection data structure exists, i.e., one that asymptotically matches the bounds of the plain sets collection data structure, reducing the query time from O(N log 2 N ) to O(N ).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>then the algorithm accepts, else it rejects. Lemma 3 (Polynomial coefficients verification). Let b = [b n , b n-1 , . . . , b 0 ] and x = [x 1 , x 2 , . . . , x n ]. Algorithm certify(b, x, pk) has O(n) complexity. Also, if accept ← certify(b, x, pk), then b n , b n-1 , . . . , b 0 are the coefficients of the polynomial n i=1 (x i + s) with probability Ω(1neg(k)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>1. {sk, pk} ← genkey(1 k ): On input the security parameter k, it outputs a secret key sk and a public key pk; 2. {auth(D 0 ), d 0 } ← setup(D 0 , sk, pk): On input a (plain) data structure D 0 and the secret and public keys, it computes the authenticated data structure auth(D 0 ) and the respective digestd 0 of it; 3. {D h+1 , auth(D h+1 ), d h+1 , upd} ← update(u, D h , auth(D h ), d h ,sk, pk): On input an update u on data structure D h , the authenticated data structure auth(D h ), the digest d h , and the secret and public keys, it outputs the updated data structure D h+1 along with the updated authenticated data structure auth(D h+1 ), the updated digest d h+1 and some relative information upd; 4. {D h+1 , auth(D h+1 ), d h+1 } ← refresh(u, D h , auth(D h ), d h , upd, pk): On input an update u on data structure D h , the authenticated data structure auth(D h ), the digest d h , relative information upd (output by update), and the public key, it outputs the updated data structure D h+1 along with the updated authenticated data structure auth(D h+1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 .</head><label>1</label><figDesc>First, the algorithm uses the coefficients b = [b δ , b δ-1 , . . . , b 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 1 ) 2 ) 3 ) 4 )</head><label>1234</label><figDesc>Coefficients b δ , b δ-1 , . . . , b 0 of polynomial (y 1 + s)(y 2 + s) . . . (y δ + s) that is associated with the union U = {y 1 , y 2 , . . . , y δ }. (Accumulation values acc(S j ), j = 1, . . . , t, which are associated with sets S j , along with their respective correctness proofs Π j , both output of algorithm queryTree(j, D h , auth(D h ), pk). (Membership witnesses W yi,S k of y i , i = 1, . . . , δ (see Equation1), which prove that y i belongs to some set S k , 1 ≤ k ≤ t, and which are computed with O(N log N ) total complexity and have O(δ) total group complexity (Lemma 2). (Subset witnesses W Sj ,U , j = 1, . . . , t, which are associated with sets S i and union U and prove that U is a superset of S j , 1 ≤ k ≤ t, and which are computed with O(N log N ) total complexity and have O(t) total group complexity (Lemma 2).Algorithm {accept, reject} ← verify(q, α, Π, d h , pk): (Union): Verifying the result of a union query includes the following steps. (1) First, the algorithm uses b = [b δ , b δ-1 , . . . , b 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Asymptotic access and group complexities of various ADS schemes for intersection queries on t = O(1) sets in a collection of m sets with answer size δ. Here, M is the sum of sizes of all the sets and 0 &lt; &lt; 1 is a constant. Also, all sizes of the intersected or updated sets are Θ(n), |Π| denotes the size of the proof, and CR stands from "collision resistance".</figDesc><table><row><cell></cell><cell cols="2">setup update, refresh</cell><cell>query</cell><cell>verify, |Π|</cell><cell>assumption</cell></row><row><cell cols="3">[23,38] m + M log n + log m</cell><cell>n + log m</cell><cell>n + log m</cell><cell>Generic CR</cell></row><row><cell>[26]</cell><cell>m + M</cell><cell>m + M</cell><cell>n</cell><cell>n</cell><cell>Strong RSA</cell></row><row><cell>[29]</cell><cell>m t + M</cell><cell>m t</cell><cell>1</cell><cell>δ</cell><cell>Discrete Log</cell></row><row><cell cols="2">this work m + M</cell><cell>1</cell><cell>n log 3 n + m log m</cell><cell>δ</cell><cell>Bilinear q-Strong DH</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Let ASC be an ADS scheme {genkey, setup, update, refresh, query, verify}, k be the security parameter, ν(k) be a negligible function and {sk, pk} ← genkey(1 k ). Let also Adv be a probabilistic polynomial-time adversary that is only given pk. The adversary has unlimited access to all algorithms of ASC, except for algorithms setup and update to which he has only oracle access. The adversary picks an initial state of the data structure D 0 and computes D 0 , auth(D 0 ), d 0 through oracle access to algorithm setup. Then, for i = 0, . . . , h = poly(k), Adv issues an update u i in the data structure D i and computes D i+1 , auth(D i+1 ) and d i+1 through oracle access to algorithm update. Finally the adversary picks an index 0 ≤ t ≤ h + 1, and computes a query q, an answer α and a proof Π. We say that the ADS scheme ASC is secure if for all k ∈ N, for all {sk, pk} output by algorithm genkey, and for any probabilistic polynomial-time adversary Adv it holds that Pr {q, Π, α, t} ← Adv(1 k , pk); accept ← verify(q, α, Π, d t , pk); reject ← check(q, α, D t ).</figDesc><table><row><cell>≤ ν(k) . (2)</cell></row></table><note><p>Definition 3 (Security).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>outputting information upd of O(1) group complexity; (iv) refresh is O(1);(3) For all queries q (intersection/union/subset/difference), constructing the proof with algorithm query has O(N log 2 N log log N + tm log m) access complexity, algorithm verify has O(t+δ) access complexity and the proof Π(q) has O(t+δ) group complexity;<ref type="bibr" target="#b3">(4)</ref> The group complexity of the authenticated data structure auth(D) is O(m + M ).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>P. Rogaway (Ed.): CRYPTO 2011, LNCS 6841, pp. 91-110, 2011. c International Association for Cryptologic Research 2011</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>Conveying the trust clients have in the source, the authentic digest is assumed to be publicly available; in practice, a time-stamped and digitally signed digest is outsourced to the server.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>Indeed, memory checking might require secret memory, e.g., as in the PRF construction in<ref type="bibr" target="#b7">[7]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>We use the term "access complexity" instead of the "query complexity" used in memory checking<ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b15">14]</ref> to avoid ambiguity when referring to algorithm query of the ADS scheme. We also require that each memory cell can store up to O(poly(log n)) bits, a word size used in<ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b15">14]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Function f : N → R is neg(k) if and only if for any nonzero polynomial p(k) there exits N such that for all k &gt; N it is f (k) &lt; 1/p(k).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>x∈S i (x + s) is called characteristic polynomial of set Si in the literature (e.g., see<ref type="bibr" target="#b29">[25]</ref>).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>However, the plain q-strong Diffie-Hellman assumption<ref type="bibr" target="#b32">[28]</ref> suffices to prove just the collision resistance of the bilinear-map accumulator.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>This choice simplifies the exposition; however, by using some collision-resistant hash function, universe U can be set to Zp -{s}.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>Digest d(r) is a "secure" succinct description of the set collection data structure. Namely, the accumulation tree protects the integrity of values acc(Si), 1 ≤ i ≤ m, and each accumulation value acc(Si) protects the integrity of the elements contained in set Si.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9"><p>Note that these update computations are efficient because update has access to secret key s.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_10"><p>Note that information upd is not required for the execution of refresh, but is rather used for efficiency. Without access to upd, algorithm refresh could compute the updated values d(vj ) using polynomial interpolation, which would have O(m log m) complexity (see Lemma 2).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_11"><p>This is becausenj log nj ≤ log N nj = N log N .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_12"><p>Algorithm certify is used to achieve optimal verification and avoid an O(δ log δ) FFT computation from scratch.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_13"><p><ref type="bibr" target="#b14">13</ref> Group element δ i=0 g s i b i = g (y 1 +s)(y 2 +s)...(y δ +s) is computed once with O(δ) complexity.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_14"><p>Note here that since the sets are picked by the adversary, we have to make sure that no element in any set is equal to s, the trapdoor of the scheme (see definition of the bilinear-map accumulator domain). However, this event occurs with negligible probability since the sizes of the sets are polynomially-bounded and s is chosen at random from a domain of exponential size.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was supported in part by the U.S. National Science Foundation under grants CNS-1012060 and CNS-1012798 and by the Kanellakis Fellowship and the Center for Geometric Computing at Brown University, the RISCS Center at Boston University and NetApp. The authors thank Michael T. Goodrich for useful discussions. The views in this paper do not necessarily reflect the views of the sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">From secrecy to soundness: Efficient verification via secure computation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Applebaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ishai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kushilevitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICALP 2010</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Abramsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gavoille</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Kirchner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Meyer Auf Der Heide</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Spirakis</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6198</biblScope>
			<biblScope unit="page" from="152" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient data authentication in an environment of untrusted third-party distributors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Atallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="696" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic universal accumulators for DDH groups and their application to attribute-based anonymous credential systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Susilo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Fischlin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">5473</biblScope>
			<biblScope unit="page" from="295" to="308" />
			<date type="published" when="2009">2009. 2009</date>
			<publisher>Springer</publisher>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>CT-RSA</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m">Modern Information Retrieval</title>
		<meeting><address><addrLine>Reading</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley Publishing Company</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A new paradigm for collision-free hashing: Incrementality at reduced cost</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Micciancio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 1997</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Fumy</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">1233</biblScope>
			<biblScope unit="page" from="163" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Verifiable delegation of computation over large datasets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benabbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vahlis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Cryptology Conference</title>
		<imprint>
			<publisher>CRYPTO</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Checking the correctness of memories</title>
		<author>
			<persName><forename type="first">M</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gemmell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="225" to="244" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Short signatures without random oracles and the SDH assumption in bilinear groups</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Boyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cryptology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="177" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Conjunctive, subset, and range queries on encrypted data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Waters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TCC 2007</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Vadhan</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4392</biblScope>
			<biblScope unit="page" from="535" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiple denominations in E-cash with compact transaction data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Canard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FC 2010</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Sion</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6052</biblScope>
			<biblScope unit="page" from="82" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Memory delegation</title>
		<author>
			<persName><forename type="first">K.-M</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Cryptology Conference</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>CRYPTO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved delegation of computation using fully homomorphic encryption</title>
		<author>
			<persName><forename type="first">K.-M</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO 2010</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Rabin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">6223</biblScope>
			<biblScope unit="page" from="483" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Supporting non-membership proofs with bilinear-map accumulators</title>
		<author>
			<persName><forename type="first">I</forename><surname>Damgård</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Triandopoulos</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/" />
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2008">2008/538. 2008</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How efficient can memory checking be?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vaikuntanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TCC 2009</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5444</biblScope>
			<biblScope unit="page" from="503" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient private matching and set intersection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pinkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2004</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Cachin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Camenisch</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3027</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Non-interactive verifiable computing: Outsourcing computation to untrusted workers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gentry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO 2010</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Rabin</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6223</biblScope>
			<biblScope unit="page" from="465" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An efficient dynamic and distributed cryptographic accumulator</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hasic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISC 2002</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Gligor</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2433</biblScope>
			<biblScope unit="page" from="372" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implementation of an authenticated dictionary with skip lists and commutative hashing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwerin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DARPA Information Survivability Conference and Exposition II (DISCEX II)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="68" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Super-efficient verification of dynamic outsourced databases</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Triandopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CT-RSA 2008</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Malkin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">4964</biblScope>
			<biblScope unit="page" from="407" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient authenticated data structures for graph connectivity and geometric search problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Triandopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="505" to="552" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Certifying algorithms for recognizing interval graphs and permutation graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Mcconnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Spinrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Discrete Algorithms (SODA)</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="158" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Universal accumulators with efficient nonmembership proofs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACNS 2007</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Katz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Yung</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4521</biblScope>
			<biblScope unit="page" from="253" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A general model for authenticated data structures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Martel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nuckolls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Devanbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Stubblebine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="41" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A certified digital signature</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO 1989</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Brassard</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">435</biblScope>
			<biblScope unit="page" from="218" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Set reconciliation with nearly optimal communication complexity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trachtenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zippel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2213" to="2218" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Trust-preserving set operations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Morselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Keleher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Computer Communications, INFOCOM</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Certificate revocation and certificate update</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Accumulators from bilinear pairings and applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CT-RSA 2005</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Menezes</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3376</biblScope>
			<biblScope unit="page" from="275" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Authenticating query results in edge computing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="560" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Time and space efficient algorithms for two-party authenticated data structures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICICS 2007</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Qing</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Imai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4861</biblScope>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cryptography for efficiency: Authenticated data structures based on lattices and parallel online memory checking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/" />
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2011">2011/102 (2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Authenticated hash tables</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Triandopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Computer and Communications Security (CCS)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="437" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Optimal authenticated data structures with multilinear forms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Triandopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pairing 2010</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Joye</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Miyaji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Otsuka</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6487</biblScope>
			<biblScope unit="page" from="246" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Computational complexity of Fourier transforms over finite fields</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Preparata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">139</biblScope>
			<biblScope unit="page" from="740" to="751" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Computational Geometry: An Introduction</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Preparata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Shamos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Authenticated data structures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESA 2003</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Di Battista</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2832</biblScope>
			<biblScope unit="page" from="2" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Certification and authentication of data structures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Triandopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Alberto Mendelzon Workshop on Foundations of Data Management</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Authenticated join processing in outsourced databases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kalnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Management of Data (SIGMOD)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="5" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient verification of shortest path search via authenticated hints</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mouratidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
