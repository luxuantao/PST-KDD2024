<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Heterogeneous Multitask Learning with Joint Sparsity Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaolin</forename><surname>Yang</surname></persName>
							<email>xyang@stat.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seyoung</forename><surname>Kim</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Machine Learning Department Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
							<email>epxing@cs.cmu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Machine Learning Department Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Heterogeneous Multitask Learning with Joint Sparsity Constraints</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEEFA5364A1C210D88508C171E41CC08</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multitask learning addresses the problem of learning related tasks that presumably share some commonalities on their input-output mapping functions. Previous approaches to multitask learning usually deal with homogeneous tasks, such as purely regression tasks, or entirely classification tasks. In this paper, we consider the problem of learning multiple related tasks of predicting both continuous and discrete outputs from a common set of input variables that lie in a highdimensional feature space. All of the tasks are related in the sense that they share the same set of relevant input variables, but the amount of influence of each input on different outputs may vary. We formulate this problem as a combination of linear regressions and logistic regressions, and model the joint sparsity as L 1 /L ∞ or L 1 /L 2 norm of the model parameters. Among several possible applications, our approach addresses an important open problem in genetic association mapping, where the goal is to discover genetic markers that influence multiple correlated traits jointly. In our experiments, we demonstrate our method in this setting, using simulated and clinical asthma datasets, and we show that our method can effectively recover the relevant inputs with respect to all of the tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multitask learning, one is interested in learning a set of related models for predicting multiple (possibly) related outputs (i.e., tasks) given a set of input variables <ref type="bibr" target="#b3">[4]</ref>. In many applications, the multiple tasks share a common input space, but have different functional mappings to different output variables corresponding to different tasks. When the tasks and their corresponding models are believed to be related, it is desirable to learn all of the models jointly rather than treating each task as independent of each other and fitting each model separately. Such a learning strategy that allows us to borrow information across tasks can potentially increase the predictive power of the learned models.</p><p>Depending on the type of information shared among the tasks, a number of different algorithms have been proposed. For example, hierarchical Bayesian models have been applied when the parameter values themselves are thought to be similar across tasks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14]</ref>. A probabilistic method for modeling the latent structure shared across multiple tasks has been proposed <ref type="bibr" target="#b15">[16]</ref>. For problems of which the input lies in a high-dimensional space and the goal is to recover the shared sparsity structure across tasks, a regularized regression method has been proposed <ref type="bibr" target="#b9">[10]</ref>.</p><p>In this paper, we consider an interesting and not uncommon scenario of multitask learning, where the tasks are heterogeneous and bear a union support. That is, each task can be either a regression or classification problem, with the inputs lying in a very high-dimensional feature space, but only a small number of the input variables (i.e., predictors) are relevant to each of the output variables (i.e., responses). Furthermore, we assume that all of the related tasks possibly share common relevant predictors, but with varying amount of influence on each task.</p><p>Previous approaches for multitask learning usually consider a set of homogeneous tasks, such as regressions only, or classifications only. When each of these discrete or continuous prediction tasks is treated separately, given a high-dimensional design, the lasso method that penalizes the loss function with an L 1 norm of the parameters has been a popular approach for variable selection <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b10">11]</ref>, since the L 1 regularization has the property of shrinking parameters corresponding to irrelevant predictors exactly to zero. One of the successful extensions of the standard lasso is the group lasso that uses an L 1 /L 2 penalty defined over predictor groups <ref type="bibr" target="#b14">[15]</ref>, instead of just the L 1 penalty ubiquitously over all predictors. Recently, a more general L 1 /L q -regularized regression scheme with q &gt; 0 has been thoroughly investigated <ref type="bibr" target="#b16">[17]</ref>. When the L 1 /L q penalty is used in estimating the regression function for a single predictive task, it makes use of information about the grouping of input variables, and applies the L 1 penalty over the L q norm of the regression coefficients for each group of inputs. As a result, variable selection can be effectively achieved on each group rather than on each individual input variable. This type of regularization scheme can be also used against the output variables in a single classification task with multi-way (rather than binary) prediction, where the output is expanded from univariate to multivariate with dummy variables for each prediction category. In this situation the group lasso can promote selecting the same set of relevant predictors across all of the dummy variables (which is desirable since these dummy variables indeed correspond to only a single multi-way output). In our multitask learning problem, when the L 1 /L 2 penalty of group lasso is used for multitask regression <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b0">1]</ref>, the L 2 norm is applied to the regression coefficients for each input across all tasks, and the L 1 norm is applied to these L 2 norms, playing the role of selecting common input variables relevant to one or more tasks via a sparse union support recovery. Since the parameter estimation problem formulated with such penalty terms has a convex objective function, many of the algorithms developed for a general convex optimization problem can be used for solving the learning problem. For example, an interior point method and a preconditioned conjugate gradient algorithm have been used to solve a large-scale L 1 -regularized linear regression and logistic regression <ref type="bibr" target="#b7">[8]</ref>. In <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref>, a coordinate-descent method was used in solving an L 1 -regularized linear regression and generalized linear models, where the soft thresholding operator gives a closed-form solution for each coordinate in each iteration.</p><p>In this paper, we consider the more challenging, but realistic scenario of having heterogenous outputs, i.e., both continuous and discrete responses, in multitask learning. This means that the tasks in question consist of both regression and classification problems. Assuming a linear regression for continuous-valued output and a logistic regression for discrete-valued output with dummy variables for multiple categories, an L 1 /L q penalty can be used to learn both types of tasks jointly for a sparse union support recovery. Since the L 1 /L q penalty selects the same relevant inputs for all dummy outputs for each classification task, the desired consistency in chosen relevant inputs across the dummy variables corresponding to the same multi-way response is automatically maintained. We consider particular cases of L 1 /L q regularizations with q = 2 and q = ∞.</p><p>Our work is primarily motivated by the problem of genetic association mapping based on genomewide genotype data of single nucleotide polymorphisms (SNPs), and phenotype data such as disease status, clinical traits, and microarray data collected over a large number of individuals. The goal in this study is to identify the SNPs (or inputs) that explain the variation in the phenotypes (or outputs), while reducing false positives in the presence of a large number of irrelevant SNPs from the genomescale data. Since many clinical traits for a given disease are highly correlated, it is greatly beneficial to combine information across multiple such related phenotypes because the inputs often involve millions of SNPs and the association signals of causal (or relevant) SNPs tend to be very weak when computed individually. However, statistically significant patterns can emerge when the joint associations to multiple related traits are estimated properly. Over the recent years, researchers started recognizing the importance of the joint analysis of multiple correlated phenotypes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref>, but there has been a lack of statistical tools to systematically perform such analysis. In our previous work <ref type="bibr" target="#b6">[7]</ref>, we developed a regularized regression method, called a graph-guided fused lasso, for multitask regression problem that takes advantage of the graph structure over tasks to encourage a selection of common inputs across highly correlated traits in the graph. However, this method can only be applied to the restricted case of correlated continuous-valued outputs. In reality, the set of clinical traits related to a disease often contains both continuous-and discrete-valued traits. As we demonstrate in our experiments, the L 1 /L q regularization for the joint regression and classification can successfully handle this situation.</p><p>The paper is organized as follows. In Section 2, we introduce the notation and the basic formulation for joint regression-classification problem, and describe the L 1 /L ∞ and L 1 /L 2 regularized regressions for heterogeneous multitask learning in this setting. In Section 3, we formulate the parameter estimation as a convex optimization problem, and present an interior-point method for solving it. Section 4 presents experimental results on simulated and asthma datasets. In Section 5, we conclude with a brief discussion of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Joint Multitask Learning of Linear Regressions and Multinomial Logistic Regressions</head><p>Suppose that we have K tasks of learning a predictive model for the output variable, given a common set of P input variables. In our joint regression-classification setting, we assume that the K tasks consist of K r tasks with continuous-valued outputs and K c tasks with discrete-valued outputs of an arbitrary number of categories.</p><p>For each of the K r regression problems, we assume a linear relationship between the input vector X of size P and the kth output Y k as follows:</p><formula xml:id="formula_0">Y k = β (r) k0 + Xβ (r) k + , k = 1, ..., K r ,</formula><p>where</p><formula xml:id="formula_1">β (r) k = (β (r) k1 , . . . , β (r)</formula><p>kP ) represents a vector of P regression coefficients for the kth regression task, with the superscript (r) indicating that this is a parameter for regression; β (r) k0 represents the intercept; and denotes the residual.</p><p>Let y k = (y k1 , . . . , y kN ) represent the vector of observations for the kth output over N samples; and X represent an N × P matrix X = (x 1 , . . . , x N ) of the input shared across all of the K tasks, where x i = (x i1 , . . . , x iP ) denotes the ith sample. Given these data, we can estimate the β (r) k 's by minimizing the sum of squared error:</p><formula xml:id="formula_2">L r = K r k=1 (y k -1β (r) k0 -Xβ (r) k ) • (y k -1β (r) k0 -Xβ (r) k ),<label>(1)</label></formula><p>where 1 is an N -vector of 1's.</p><p>For the tasks with discrete-valued output, we set up a multinomial (i.e., softmax) logistic regression for each of the K c tasks, assuming that the kth task has M k categories:</p><formula xml:id="formula_3">P (Y k = m|X = x) = exp (β (c) k0 + xβ (c) km ) 1 + M k -1 l=1 exp (β (c) k0 + xβ (c) kl ) , for m = 1, . . . , M k -1, P (Y k = M k |X = x) = 1 1 + M k -1 l=1 exp (β (c) k0 + xβ (c) kl ) , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where β</p><formula xml:id="formula_5">(c) km = (β (c) km1 , . . . , β (c) kmP ) , m = 1, . . . , (M k -1)</formula><p>, is the parameter vector for the mth category of the kth classification task, and β (c) k0 is the intercept. Assuming that the measurements for the K c output variables are collected for the same set of N samples as in the regression tasks, we expand each output data y ki for the kth task of the ith sample into a set of M k binary variables y ki = (y k1i , . . . , y kM k i ), where each y kmi , m = 1, . . . , M k , takes value 1 if the ith sample for the kth classification task belongs to the mth category and value 0 otherwise, and thus m y kmi = 1. Using the observations for the output variable in this representation and the shared input data X, one can estimate the parameters β (c) km 's by minimizing the negative log-likelihood given as below:</p><formula xml:id="formula_6">L c = - N i=1 Kc k=1 M k -1 m=1 y kmi (β (c) k0 + P j=1 x ij β (c) kmj ) -log 1 + M k -1 m=1 exp (β (c) k0 + P j=1 x ij β (c) kmj ) . (3)</formula><p>In this joint regression-classification problem, we form a global objective function by combining the two empirical loss functions in Equations ( <ref type="formula" target="#formula_2">1</ref>) and ( <ref type="formula">3</ref>):</p><formula xml:id="formula_7">L = L r + L c . (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>This is equivalent to estimating the β (r) k 's and β (c) km 's independently for each of the K tasks, assuming that there are no shared patterns in the way that each of the K output variables is dependent on the input variables. Our goal is to increase the performance of variable selection and prediction power by allowing the sharing of information among the heterogeneous tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Heterogeneous Multitask Learning with Joint Sparse Feature Selection</head><p>In real-world applications, often the covariates lie in a very high-dimensional space with only a small fraction of them being involved in determining the output, and the goal is to recover the sparse structure in the predictive model by selecting the true relevant covariates. For example, in a genetic association mapping, often millions of genetic markers over a population of individuals are examined to find associations with the given phenotype such as clinical traits, disease status, or molecular phenotypes. The challenge in this type of study is to locate the true causal SNPs that influence the phenotype. We consider the case where the related tasks share the same sparsity pattern such that they have a common set of relevant input variables for both the regression and classification tasks and the amount of influence of the relevant input variables on the output may vary across the tasks. We introduce an L 1 /L q regularization to the problem of the heterogeneous multitask learning in Equation ( <ref type="formula" target="#formula_7">4</ref>) as below:</p><formula xml:id="formula_9">L = L r + L c + λP q , (<label>5</label></formula><formula xml:id="formula_10">)</formula><p>where P q is the group penalty to the sum of linear regression loss and logistic loss, and λ is a regularization parameter which determines the sparsity level and could be chosen by cross validation. We consider two extreme cases of the L 1 /L q penalty for group variable selection in our problem which are L ∞ norm and L 2 norm across different tasks in one dimension.</p><formula xml:id="formula_11">P ∞ = P j=1 max k,m |β (r) kj |, |β (c) kmj | or P 2 = P j=1 |β (r) j , β (c) j | L2 ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_12">β (r) j , β (c)</formula><p>j are vector of parameters over all regression and classification tasks, respectively, for the jth dimension. Here, the L ∞ and L 2 norms over the parameters across different tasks can regulate the joint sparsity among tasks. The L 1 /L ∞ and L 1 /L 2 norms encourage group sparsity in a similar way in that the β (r) kj 's and β (c) kmj 's are set to 0 simultaneously for all of the tasks for dimension j if the L ∞ or L 2 norm for that dimension is set to be 0. Similarly, if the L 1 operator selects a non-zero value for the L ∞ or L 2 norm of the β (r) kj 's and β (c) kmj 's for the jth input, the same input is considered as relevant possibly to all of the tasks, and the β (r) kj 's and β (c) kmj 's can have any non-zero values smaller than the maximum or satisfying the L 2 -norm constraints. The L 1 /L ∞ penalty tends to encourage the parameter values to be the same across all tasks for a given input <ref type="bibr" target="#b16">[17]</ref>, whereas under L 1 /L 2 penalty the values of the parameters across tasks tend to be more different for a given input than in the L 1 /L ∞ penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Optimization Method</head><p>Different methods such as gradient descent, steepest descent, Newton's method and Quasi-Newton method can be used to solve the problem in Equation <ref type="bibr" target="#b4">(5)</ref>. Although second-order methods have a fast convergence near the global minimum of the convex objective functions, they involve computing a Hessian matrix and inverting it, which can be infeasible in a high-dimensional setting. The coordinate-descent method iteratively updates each element of the parameter vector one at a time, using a closed-form update equation given all of the other elements. However, since it is a first-order method, the speed of convergence becomes slow as the number of tasks and dimension increase. In <ref type="bibr" target="#b7">[8]</ref>, the truncated Newton's method that uses a preconditionor and solves the linear system instead of inverting the Hessian matrix has been proposed as a fast optimization method for a very large-scale problem. The linear regression loss and logistic regression loss have different forms. The interior method optimizes their original loss function without any transformation so that it is more intuitive to see how the two heterogeneous tasks affect each other.</p><p>In this section, we discuss the case of the L 1 /L ∞ penalty since the same optimization method can be easily extended to handle the L 1 /L 2 penalty. First, we re-write the problem of minimizing Equation ( <ref type="formula" target="#formula_9">5</ref>) with the nondifferentiable L 1 /L ∞ penalty as</p><formula xml:id="formula_13">minimize L r + L c + λ P j=1 u j subject to max k,m |β (r) kj |, |β (c) kmj | &lt; u j , for j = 1, . . . , P, k = 1, . . . , K r + K c . (<label>7</label></formula><formula xml:id="formula_14">)</formula><p>Further re-writing the constraints in the above problem, we obtain 2•P • (K r + Kc k=1 (M k -1)) inequality constraints as follows:</p><formula xml:id="formula_15">-u j &lt; β (r) kj &lt; u j , for k = 1, . . . , K r , j = 1, . . . , P, -u j &lt; β (c) kmj &lt; u j , for k = 1, . . . , K c , j = 1, . . . , P, m = 1, . . . , M k -1.</formula><p>Using the barrier method <ref type="bibr" target="#b2">[3]</ref>, we re-formulate the objective function in Equation ( <ref type="formula" target="#formula_13">7</ref>) into an unconstrained problem given as</p><formula xml:id="formula_16">L Barrier = L r + L c + λ P j=1 u j + K r k=1 P j=1 I -(-β (c) kj -u j ) + I -(β (c) kj -u j ) + Kc k=1 M k -1 m=1 P j=1 I -(-β (c) kmj -u j ) + I -(β (c) kmj -u j ),</formula><p>where</p><formula xml:id="formula_17">I -(x) = 0 x ≤ 0 ∞ x &gt; 0 .</formula><p>Then, we apply the log barrier function</p><formula xml:id="formula_18">I -(f (x)) = -(1/t) log(-f (x))</formula><p>, where t is an additional parameter that determines the accuracy of the approximation.</p><p>Let Θ denote the set of parameters β (r) k 's and β (c) km 's. Given a strictly feasible Θ, t = t (0) &gt; 0, µ &gt; 1, and tolerance &gt; 0, we iterate the following steps until convergence.</p><p>Step 1 Compute Θ * (t) by minimizing L Barrier , starting at Θ.</p><p>Step 2 Update: Θ := Θ * (t)</p><p>Step 3 Stopping criterion: quit if m/t &lt; where m is the number of constraint functions.</p><p>Step 4 Increase t: t := tµ</p><p>In Step 1, we use the Newton's method to minimize L Barrier at t. In each iteration, we increase t in Step 4, so that we have a more accurate approximation of</p><formula xml:id="formula_19">I -(u) through I -(f (x)) = -(1/t) log(-f (x)).</formula><p>In Step 1, we find the direction towards the optimal solution using Newton's method:</p><formula xml:id="formula_20">H ∆β ∆u = -g,</formula><p>where ∆β and ∆u are the searching directions of the model parameters and bounding parameters. The g in the above equation is the gradient vector given as g = [g (r) , g (c) , g (u) ] T , where g (r) has K r components for regression tasks, g (c) has K c × (M k -1) components for classification tasks, and H is the Hessian matrix given as: where R and L are second derivatives of the parameters β for regression tasks in the form of R =</p><formula xml:id="formula_21">H =     R 0 D (r) 0 L D (c) D (r) D (c) F     ,</formula><formula xml:id="formula_22">∇ 2 L r + ∇ 2 P g | ∂β (r) ∂β (r) , L = ∇ 2 L c + ∇ 2 P g | ∂β (c) ∂β (c) , D = ∇ 2 P g | ∂β∂u and F = D (r) + D (c) .</formula><p>In the overall interior-point method, the process of constructing and inverting Hessian matrix is the most time-consuming part. In order to make the algorithm scalable to a large problem, we use a preconditionor diag(H) of the Hessian matrix H, and apply the preconditioned conjugate-gradient algorithm to compute the searching direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We demonstrate our methods for heterogeneous multitask learning with L 1 /L ∞ and L 1 /L 2 regularizations on simulated and asthma datasets, and compare their performances with those from solving two types of multitask-learning problems for regressions and classifications separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Simulation Study</head><p>In the context of genetic association analysis, we simulate the input and output data with known model parameters as follows. We start from the 120 haplotypes of chromosome 7 from the population of European ancestry in HapMap data <ref type="bibr" target="#b11">[12]</ref>, and randomly mate the haplotypes to generate genotype data for 500 individuals. We randomly select 50 SNPs across the chromosome as inputs. In order to simulate the parameters β (r) k 's and β (c) km 's, we assume six regression tasks and a single classification task with five categories, and choose five common SNPs from the total of 50 SNPs as relevant covariates across all of the tasks. We fill the non-zero entries in the regression coefficients β km 's such that the five categories are separated in the output space. Given these inputs and the model parameters, we generate the output values, using the noise for regression tasks distributed as N (0, σ 2 sim ). In the classification task, we expand the single output into five dummy variables representing different categories that take values of 0 or 1 depending on which category each sample belongs to. We repeat this whole process of simulating inputs and outputs to obtain 50 datasets, and report the results averaged over these datasets.</p><p>The regularization paths of the different multitask-learning methods with an L 1 /L ∞ regularization obtained from a single simulated dataset are shown in Figure <ref type="figure" target="#fig_0">1</ref>. The results from learning all of the tasks jointly are shown in Figures <ref type="figure" target="#fig_0">1(a</ref>) and 1(c) for regression and classification tasks, respectively, whereas the results from learning the two sets of regression and classification tasks separately are shown in Figures <ref type="figure" target="#fig_0">1(b</ref>) and 1(d). The red curves indicate the parameters for true relevant inputs, and the blue curves for true irrelevant inputs. We find that when learning both types of tasks jointly, the parameters of the irrelevant inputs are more reliably set to zero along the regularization path than learning the two types of tasks separately.</p><p>In order to evaluate the performance of the methods, we use two criteria of sensitivity/specificity plotted as receiver operating characteristic (ROC) curves and prediction errors on test data. To obtain ROC curves, we estimate the parameters, sort the input-output pairs according to the magnitude of the estimated β  We vary the sample size to N = 100 and 200, and show the ROC curves for detecting true relevant inputs using different methods in Figure <ref type="figure">2</ref>. We use σ sim = 1 to generate noise in the regression tasks. Results for the regression and classification tasks with N = 100 are shown in Figure <ref type="figure">2</ref>(a) and (b) respectively, and similarly, the results with N = 200 in Figure <ref type="figure">2</ref>(c) and (d). The results with L 1 /L ∞ penalty are shown with color blue and green to compare the homogeneous and heterogeneous methods. Red and yellow are results using the L 1 /L 2 penalty. Although the performance of learning the two types of tasks separately improves with a larger sample size, the joint estimation performs significantly better for both sample sizes. A similar trend can be seen in the prediction errors for the same simulated datasets in Figure <ref type="figure">3</ref>.</p><p>In order to see how different signal-to-noise ratios affect the performance, we vary the noise level to σ 2 sim = 5 and σ 2 sim = 8, and plot the ROC curves averaged over 50 datasets with a sample size N = 300 in Figure <ref type="figure" target="#fig_4">4</ref>. Our results show that for both of the signal-to-noise ratios, learning regression and classification tasks jointly improves the performance significantly. The same observation can be made from the prediction errors in Figure <ref type="figure" target="#fig_5">5</ref>. We can see that the L 1 /L 2 method tends to improve the variable selection, but the tradeoff is that the prediction error will be high when the noise level is low. While L 1 /L ∞ has a good balance between the variable selection accuracy and prediction error at a lower noise level, as the noise increases, the L 1 /L 2 outperforms L 1 /L ∞ in both variable selection and prediction accuracy.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis of Asthma Dataset</head><p>We apply our method to the asthma dataset with 34 SNPs in the IL4R gene of chromosome 11 and five asthma-related clinical traits collected over 613 patients. The set of traits includes four continuous-valued traits related to lung physiology such as baseline predrug FEV1, maximum FEV1, baseline predrug FVC, and maximum FVC as well as a single discrete-valued trait with five categories. The goal of this analysis is to discover whether any of the SNPs (inputs) are influencing each of the asthma-related traits (outputs). We fit the joint regression-classification method with L 1 /L ∞ and L 1 /L 2 regularizations, and compare the results from fitting L 1 /L ∞ and L 1 /L 2 regularized methods only for the regression tasks or only for the classification task. We show the estimated parameters for the joint learning with L 1 /L ∞ penalty in Figure <ref type="figure" target="#fig_6">6</ref>(a) and the separate learning with L 1 /L ∞ penalty in Figure <ref type="figure" target="#fig_6">6(b)</ref>, where the first four rows correspond to the four regression tasks, the next four rows are parameters for the four dummy variables of the classification task, and the columns represent SNPs. We can see that the heterogeneous multitask-learning method encourages to find common causal SNPs for the multiclass classification task and the regression tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we proposed a method for a recovery of union support in heterogeneous multitask learning, where the set of tasks consists of both regressions and classifications. In our experiments with simulated and asthma datasets, we demonstrated that using L 1 /L 2 or L 1 /L ∞ regularizations in the joint regression-classification problem improves the performance for identifying the input variables that are commonly relevant to multiple tasks.</p><p>The sparse union support recovery as was presented in this paper is concerned with finding inputs that influence at least one task. In the real-world problem of association mapping, there is a clustering structure such as co-regulated genes, and it would be interesting to discover SNPs that are causal to at least one of the outputs within the subgroup rather than all of the outputs. In addition, SNPs in a region of chromosome are often correlated with each other because of the non-random recombination process during inheritance, and this correlation structure, called linkage disequilibrium, has been actively investigated. A promising future direction would be to model this complex correlation pattern in both the input and output spaces within our framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The regularization path for L 1 /L ∞ -regularized methods. (a) Regression parameters estimated from the heterogeneous task learning method, (b) regression parameters estimated from regression tasks only, (c) logistic-regression parameters estimated from the heterogeneous task learning method, and (d) logistic-regression parameters estimated from classification tasks only. Blue curves: irrelevant inputs; Red curves: relevant inputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>k</head><label></label><figDesc>'s with values uniformly distributed in the interval [a, b] with 5 ≤ a, b ≤ 10, and the non-zero entries in the logistic-regression parameters β (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(r) kj 's and β (c) kmj 's, and compare the sorted list with the list of input-output pairs with true non-zero β (r) kj 's and β (c) kmj 's.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>ROC curves for detecting true relevant input variables when the sample size N varies. (a) Regression tasks with N = 100, (b) classification tasks with N = 100, (c) regression tasks with N = 200, and (d) classification tasks with N = 200. Noise level N (0,1) was used. The joint regression-classification methods achieve nearly perfect accuracy, and their ROC curves are completely aligned with the axes.'M' indicates homogeneous multitask learning, and 'HM' heterogenous multitask learning (This notation is the same for the following other figures). Prediction errors when the sample size N varies. (a) Regression tasks with N =100, (b) classification tasks with N = 100, (c) regression tasks with N = 200, and (d) classification tasks with N = 200. Noise level N (0,1) was used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>ROC curves for detecting true relevant input variables when the noise level varies. (a) Regression tasks with noise level N (0, 5), (b) classification tasks with noise level N (0, 5), (c) regression tasks with noise level N (0, 8), and (d) classification tasks with noise level N (0, 8). Sample size N =300 was used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>)Figure 5 :</head><label>5</label><figDesc>Prediction errors when the noise level varies. (a) Regression tasks with noise level N (0, 5 2 ), (b) classification tasks with noise level N (0, 5 2 ), (c) regression tasks with noise level N (0, 8 2 ), and (d) classification tasks with noise level N (0, 8 2 ). Sample size N =300 was used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Parameters estimated from the asthma dataset for discovery of causal SNPs for the correlated phenotypes. (a) Heterogeneous task learning method, and (b) separate analysis of multitask regressions and multitask classifications. The rows represent tasks, and the columns represent SNPs.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments EPX is supported by grant NSF DBI-0640543, NSF DBI-0546594, NSF IIS-0713379, NIH grant 1R01GM087694, and an Alfred P. Sloan Research Fellowship.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Convex multi-task feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="272" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Task clustering and gating for bayesian multitask learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Heskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="83" to="99" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex Optimization</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Variations in dna elucidate molecular networks that cause disease</title>
		<author>
			<persName><forename type="first">V</forename><surname>Emilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thorleifsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Leonardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Helgason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Walters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunnarsdottir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">452</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="423" to="428" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Regularization paths for generalized linear models via coordinate descent</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<idno>703</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical estimation of correlated genome associations to a quantitative trait network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genetics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1000587</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An interior-point method for large-scale l1-regularized logistic regression</title>
		<author>
			<persName><forename type="first">K</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1519" to="1555" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Joint covariate selection for grouped classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<idno>743</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">High-dimensional union support recovery in multivariate regression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast optimization methods for l1 regularization: a comparative study and two new approaches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning</title>
		<meeting>the European Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The International HapMap Consortium. A haplotype map of the human genome</title>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">437</biblScope>
			<biblScope unit="page" from="1399" to="1320" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning gaussian processes from multiple tasks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwaighofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning</title>
		<meeting>the 22nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Model selection and estimation in regression with grouped variables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="67" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Flexible latent variable models for multi-task learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="221" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Grouped and hierarchical model selection through composite absolute penalties</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<idno>703</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Integrating large-scale functional genomic data to dissect the complexity of yeast regulatory networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Drees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Brem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kruglyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bumgarner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Schadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Genetics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="854" to="861" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
