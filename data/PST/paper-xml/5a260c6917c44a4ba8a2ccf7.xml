<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pierre-Marc</forename><surname>Jodoin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Infocomm Research</orgName>
								<orgName type="institution">A*STAR</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jinghong</forename><surname>Zheng</surname></persName>
							<email>jzheng@i2r.a-star.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Infocomm Research</orgName>
								<orgName type="institution">A*STAR</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F21DDD8AF47F5E0BECDC5C1EFDE286CE</idno>
					<idno type="DOI">10.1109/TIP.2017.2750418</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE execution of visual activities such as object detec- tion and recognition depends heavily on the perception of outdoor natural scenes. Unfortunately, images of outdoor scenes are often degraded in bad weather conditions such as haze, fog, smoke, rain and so on. The light is blended with ambient light reflected from other directions into the line of sight by atmospheric particles. The irradiance received by the camera from the scene point is attenuated along the line of sight. As such, the objects captured under the bad weather conditions suffer from low contrast, faint color, and shifted luminance <ref type="bibr" target="#b0">[1]</ref>. Haze removal can significantly increase the contrasts of the objects, and correct the color distortion caused by the airlight. Therefore, haze removal is highly demanded in image processing and computer vision applications <ref type="bibr" target="#b1">[2]</ref>.</p><p>Many single image haze removal algorithms were proposed due to their broad applications. Based on an observation that a haze-free image has higher contrast than its haze image, an interesting single image haze removal algorithm was proposed in <ref type="bibr" target="#b2">[3]</ref> by maximizing the local contrast of the restored image using markov random field. Although the algorithm in <ref type="bibr" target="#b2">[3]</ref> is able to achieve visually compelling results, it tends to produce over-saturated images which might not be physically valid. A haze image is interpreted by Fattal in <ref type="bibr" target="#b3">[4]</ref> through an image formation model that accounts for both surface shading and scene transmission. Under an assumption that the transmission and surface shading are locally uncorrelated, the airlightalbedo ambiguity is resolved. The algorithm in <ref type="bibr" target="#b3">[4]</ref> produced impressive results except in presence of heavy haze. Inspired by the widely used dark-object subtraction technique <ref type="bibr" target="#b4">[5]</ref>, a novel dark channel prior based haze removal algorithm was proposed in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>. The dark channel prior is based on an observation that it is very often that some pixels of haze-free outdoor images have very low intensity in at least one color (RGB) channel. The algorithm is physically valid and can handle distant objects even in images with heavy haze. However, noise in bright regions including the sky could be amplified by using the algorithm in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref> even though a lower bound was introduced for the transmission map in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>. Based on observations that the color of the scene fades under the influence of the haze and the brightness increases at the same time producing the high value of the difference, a simple color attenuation prior was proposed in <ref type="bibr" target="#b7">[8]</ref>, and a linear model was then built up to represent the relationship between the depth and the brightness as well as the saturation using the prior. The linear model was finally adopted to design a single image haze removal algorithm with the help of the guided image filtering (GIF) in <ref type="bibr" target="#b6">[7]</ref>. The algorithm in <ref type="bibr" target="#b7">[8]</ref> is simple and it also avoids amplification of noise in the sky region. In addition, the haze is removed well if it is light. However, the quality of the dehazed images needs to be improved if the haze is heavy. This is because the coefficients of the linear model and the scattering coefficient of the atmosphere are fixed for the algorithm in <ref type="bibr" target="#b7">[8]</ref> while their values should be adaptive to the haze degree of the input image. It is interesting but challenging to properly determine the coefficients of the linear model and the scattering coefficient of the atmosphere for the algorithm in <ref type="bibr" target="#b7">[8]</ref>. Inspired by an observation in <ref type="bibr" target="#b8">[9]</ref> that single image haze removal can be regarded as a type of spatially varying detail enhancement, a neat framework was proposed in <ref type="bibr" target="#b10">[11]</ref> by introducing a local edge-preserving smoothing based method to estimate the transmission map of a haze image. However, local edge-preserving smoothing techniques such as the GIF in <ref type="bibr" target="#b6">[7]</ref> and the weighted GIF (WGIF) in <ref type="bibr" target="#b8">[9]</ref> could over smooth images <ref type="bibr" target="#b11">[12]</ref>, especially in areas of fine structure. An example is given in Fig. <ref type="figure" target="#fig_1">1</ref>. The GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref> are adopted to study single image haze removal. As shown in the zoom-in regions, the hair of the human subject is over smoothed by both the GIF and the WGIF. Therefore, both the GIF and the WGIF could not preserve the fine structure even though they are very simple.</p><p>In this paper, a fast globally guided image filter (G-GIF) is introduced to address the problem. The proposed G-GIF is inspired by the GIF in <ref type="bibr" target="#b6">[7]</ref>, the WGIF in <ref type="bibr" target="#b8">[9]</ref>, and the gradient domain image processing algorithms in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, and <ref type="bibr" target="#b13">[14]</ref>. Two major objectives of the GIF and WGIF are: 1) to transfer the structure of the guidance image to the input image; and 2) to smooth the transferred image so as to produce the output image. Both the objectives are achieved simultaneously in the GIF and WGIF. They are achieved separately in the proposed G-GIF. The proposed filter is composed of a global structure transfer filter and a global edge-preserving smoothing filter. Inputs of the structure transfer filter are an image to be filtered and a guidance vector field. The structure is defined by the guidance vector field and it is transferred to the image to be filtered by the structure transfer filter. Unlike the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref>, the structure transfer filter is formulated as a quadratic optimization problem. Unlike the gradient domain image processing algorithms in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b13">[14]</ref>, the structure filter is formulated in the hybrid gradient and image domain. As such, the proposed hybrid optimization problem can be easily solved by using the separating approach in <ref type="bibr" target="#b14">[15]</ref> even though it is a global optimization problem while the separating approach is not applicable to the gradient domain image processing algorithms in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b13">[14]</ref>. The speed of the structure transfer filter is thus comparable to those of the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref>, and is much faster than the gradient domain image processing algorithms in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b13">[14]</ref>. The proposed edge-preserving smoothing filter is inspired by the weighted least square (WLS) filter in <ref type="bibr" target="#b15">[16]</ref> and the detail extraction problem in <ref type="bibr" target="#b16">[17]</ref>. Inputs of the smoothing filter are an image to be smoothed and the guidance vector field. Similar to the structure transfer filter, the smoothing filter is also formulated as a quadratic optimization problem. It is worth noting that the WLS filter in <ref type="bibr" target="#b15">[16]</ref> is a special case of the proposed edge-preserving smoothing filter. Due to the separating approach, the speed of the smoothing filter is also comparable to those of the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref>. As illustrated in Fig. <ref type="figure" target="#fig_1">1</ref>, the proposed G-GIF preserves the fine structure better than the GIF and WGIF.</p><p>The G-GIF is then applied to study single image haze removal. The proposed haze removal algorithm is based on the concepts of minimal color channel <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref> and simplified dark channel in <ref type="bibr" target="#b8">[9]</ref>. The simplified dark channel is decomposed into a base layer and a detail layer via the proposed G-GIF, and the base layer is used to estimate the transmission map. To avoid introducing artifacts to the dehazed image, the structure of the base layer (or the structure of the transmission map) is required to match the structure of the haze image. Since the structure of the haze image is preserved better by the minimal channel than the simplified dark channel <ref type="bibr" target="#b10">[11]</ref>, the minimal color channel is selected to generate the guidance vector field. Once the transmission map is estimated from the base layer, it can be used to recover the haze image. Experimental results show that the dehazed images by the proposed algorithm are sharper than those dehazed images by the algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref>. It should be pointed out that the computational cost of the proposed algorithm is about the double of the algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref>. Overall, there are two major contributions in this paper. One is the proposed G-GIF which preserves fine structures better than the GIF and WGIF. The other is a new single image haze removal algorithm based on the proposed G-GIF which can be applied to improve the sharpness of dehazed images.</p><p>The rest of this paper is organized as follows. Limitation of the GIF and WGIF is given in Section II. The detail of the proposed G-GIF is provided in Section III. Section IV includes an application of the proposed G-GIF in single image haze removal. Experimental results are given in Section V to illustrate the efficiency of the proposed haze removal algorithm. Concluding remarks are provided in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LIMITATION OF THE GIF AND WGIF</head><p>In both the GIF <ref type="bibr" target="#b6">[7]</ref> and the WGIF <ref type="bibr" target="#b8">[9]</ref>, a guidance image G is used which could be identical to the image X to be filtered. It is assumed that the output image Ẑ is a linear transform of G in a predefined window ζ ( p ): The values of a p and b p in the GIF <ref type="bibr" target="#b6">[7]</ref> are then obtained by minimizing a cost function E(a p , b p ) which is defined as</p><formula xml:id="formula_0">Ẑ( p) = a p G( p) + b p , ∀ p ∈ ζ ( p ),<label>(1)</label></formula><formula xml:id="formula_1">E = p∈ ζ ( p ) [(a p G( p) + b p -X ( p)) 2 + λa 2 p ],<label>(2)</label></formula><p>where λ is a regularization parameter penalizing large a p . An edge-aware weighting G ( p ) is defined in the WGIF [9] by using local variances of 3 × 3 windows of all pixels as  follows:</p><formula xml:id="formula_2">G ( p ) = 1 N N p=1 σ 2 G,1 ( p ) + ε σ 2 G,1 ( p) + ε , (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>where ε is a small constant and its value is selected as (0.001 × L) 2 while L is the dynamic range of the input image.</p><p>The edge-aware weighting G ( p ) in Equation ( <ref type="formula" target="#formula_2">3</ref>) is incorporated into the cost function E(a p , b p ) in Equation ( <ref type="formula" target="#formula_1">2</ref>). As such, the values of a p and b p in the WGIF <ref type="bibr" target="#b8">[9]</ref> are then obtained by minimizing a new cost function E(a p , b p ) which is defined as</p><formula xml:id="formula_4">E = p∈ ζ ( p ) [(a p G( p) + b p -X ( p)) 2 + λ G ( p ) a 2 p ].<label>(4)</label></formula><p>The optimal values of a p and b p are computed by solving the optimization problem (2) or the optimization problem (4). The output image Ẑ ( p) is finally given as follows: [9]</p><formula xml:id="formula_5">Ẑ ( p) = āp G( p) + bp , (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where āp and bp are the mean values of a p and b p in the window computed as</p><formula xml:id="formula_7">āp = 1 | ζ ( p)| p ∈ ζ ( p) a p (6) bp = 1 | ζ ( p)| p ∈ ζ ( p) b p ,<label>(7)</label></formula><p>and</p><formula xml:id="formula_8">| ζ ( p )| is the cardinality of ζ ( p ).</formula><p>As an illustration, both the GIF and the WGIF are applied to study single image haze removal. Four different choices of ζ are tested and they are 7, 15, 30, and 60. Readers are invited to view the electronic version of the full-size figures in order to better appreciate the differences among images. It is shown in Fig. <ref type="figure" target="#fig_3">2</ref> that the morphological artifacts are reduced if the value of ζ is increased. However, the hair of the human subject becomes smoothed or even over smoothed when the value of ζ is increased. The same phenomenon is observed for the GIF in Fig. <ref type="figure" target="#fig_4">3</ref>. It is worth noting that the maximal filter is enabled for all the experimental results in Fig. <ref type="figure" target="#fig_4">3</ref>.</p><p>Here the maximal filter is obtained by replacing the minimal operation in the equation ( <ref type="formula" target="#formula_33">21</ref>) by the maximal operation. It is shown in Fig. <ref type="figure" target="#fig_5">4</ref> that the morphological artifacts are indeed reduced by the maximal filter. Unfortunately, the hair of the human subject is further over-smoothed by it. The maximal filter is thus not enabled provided that it is specified in this paper. The WGIF is taken as example to show the effect of the average operations in the Equations ( <ref type="formula">6</ref>) and <ref type="bibr" target="#b6">(7)</ref>. It is shown in Fig. <ref type="figure" target="#fig_6">5</ref> that the fine structures are preserved better while the morphological artifacts become more visible by  <ref type="formula">6</ref>) and ( <ref type="formula" target="#formula_7">7</ref>) while the morphological artifacts become more visible.</p><p>disabling the average operations in the Equations ( <ref type="formula">6</ref>) and <ref type="bibr" target="#b6">(7)</ref>. Clearly, both the GIF <ref type="bibr" target="#b6">[7]</ref> and the WGIF <ref type="bibr" target="#b8">[9]</ref> can over smooth images, especially in areas of fine structures. This is due to the large value of ζ and the average operations in the Equation ( <ref type="formula">6</ref>) and ( <ref type="formula" target="#formula_7">7</ref>). In the next subsection, a new G-GIF is proposed to address the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GLOBALLY GUIDED IMAGE FILTERING</head><p>Inspired by the GIF in <ref type="bibr" target="#b6">[7]</ref>, the WGIF in <ref type="bibr" target="#b8">[9]</ref>, the gradient domain image processing algorithms in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, and <ref type="bibr" target="#b13">[14]</ref>, the WLS filter in <ref type="bibr" target="#b15">[16]</ref> and the quadratic optimization problem in <ref type="bibr" target="#b16">[17]</ref>, a new type of GIFs is proposed in this section. Unlike the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref>, the proposed filter is a global filter and it is thus called the G-GIF. Inputs of the proposed G-GIF are an image to be filtered and a guidance vector field while inputs of the GIF and WGIF are an image to be filtered and a guidance image. The structure is defined by the guidance vector field. The proposed G-GIF is composed of a global structure transfer filter and a global edge-preserving smoothing filter. The function of the structure transfer filter is to transfer the predefined structure to the image to be filtered while the function of the smoothing filter is to smooth the transferred image so as to produce the output image.</p><p>The structure transfer filter is inspired by the GIF in <ref type="bibr" target="#b6">[7]</ref>, the WGIF in <ref type="bibr" target="#b8">[9]</ref>, and the gradient domain image processing algorithms in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, and <ref type="bibr" target="#b13">[14]</ref>. The inputs of the structure transfer filter are an image to be filtered and a guidance vector field. The structure to be transferred is defined by the the guidance vector field. The objective of the structure transfer filter is to transfer the structure to the image to be filtered. The structure transfer filter is formulated as a global optimization problem. The cost function is composed of two terms. One term is in image domain and it measures the fidelity of the output image to the image to be filtered. The other is in gradient domain and it specifies the structure of the output image. The former is defined as</p><formula xml:id="formula_9">E 1 (O, X) = p (O( p) -X ( p)) 2 , (<label>8</label></formula><formula xml:id="formula_10">)</formula><p>where X is an image to be filtered. The term E 1 (O, X) implies that the output image O is required to approximate the image to be filtered as much as possible. Let V = (V h , V v ) be the guidance vector field. The latter is defined as</p><formula xml:id="formula_11">E 2 (O, V ) = p ∇ O( p) -V ( p) 2 , (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>where ∇ O is the gradient field of the output image O. The term E 2 (O, V ) means that the structure of the output image O matches the guidance vector filed as much as possible <ref type="bibr" target="#b13">[14]</ref>.</p><p>The overall cost function is computed as</p><formula xml:id="formula_13">E(O) = λE 1 (O, X) + E 2 (O, V ), (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>where λ is a non-negative constant and its function is to obtain a trade-off between the two terms.</p><p>It should be pointed out that 1) the proposed cost function E(O) is the same as the cost function in <ref type="bibr" target="#b13">[14]</ref> if the value of λ is 0; and 2) the proposed cost function E(O) is similar to the cost function in <ref type="bibr" target="#b16">[17]</ref> when all pixel values in the input image are zeros. This implies that the cost functions in <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b16">[17]</ref> can be regarded as special cases of the proposed cost function.</p><p>Using matrix notation, the cost function E(O) can be rewritten as</p><formula xml:id="formula_15">λ(O -X) T (O -X) + (D x O -V h ) T (D x O -V h ) + (D y O -V v ) T (D y O -V v ), (<label>11</label></formula><formula xml:id="formula_16">)</formula><p>where the matrices D x and D y are discrete differentiation operators.</p><p>The vector O that minimizes the cost function is uniquely defined as the solution of the linear equation</p><formula xml:id="formula_17">(λI + D T x D x + D T y D y )O = λX + D T x V h + D T y V v , (<label>12</label></formula><formula xml:id="formula_18">)</formula><p>where I is an identity matrix. It can be easily verified that the matrix (λI</p><formula xml:id="formula_19">+ D T x D x + D T y D y ) is non-singular if λ is positive while the matrix (D T x D x + D T y D y</formula><p>) is singular. Thus, a fast separating method like the method in <ref type="bibr" target="#b17">[18]</ref> is applicable to solve the above linear equation due to the non-singularity of the matrix (λI + D T</p><p>x D x + D T y D y ) with a positive λ. However, the separating method in <ref type="bibr" target="#b17">[18]</ref> is not applicable if the value of λ is 0. This is because that the matrix (D T x D x + D T y D y ) is singular. Thus, it is much easier to solve the proposed optimization problem based on the cost function <ref type="bibr" target="#b9">(10)</ref> than the optimization problem in <ref type="bibr" target="#b13">[14]</ref>.</p><p>As an illustration, the structure transfer filter is applied to estimate the transmission map of a haze image. As shown in Fig. <ref type="figure" target="#fig_7">6</ref>, the structure of the haze image is indeed transferred to the simplified dark channel by the structure transfer filter. Even though the structure of the vector field V is transferred into the output image O * by the structure transfer filter, the output image O * sometimes needs to be smoothed. An example is given in Fig. <ref type="figure" target="#fig_8">7</ref>. Clearly, the quality of  the dehazed image is significantly dropped if the output image O * is not smoothed. To achieve the objective, the output image O * is decomposed into two layers via an edgepreserving smoothing filter. Inspired by the WLS filter in <ref type="bibr" target="#b15">[16]</ref> and the quadratic optimization problem in <ref type="bibr" target="#b16">[17]</ref>, a new edgepreserving smoothing filter is formulated as</p><formula xml:id="formula_20">min ϕ p [(ϕ( p)-O * ( p)) 2 +γ ( ( ∂ϕ( p) ∂ x ) 2 |V h ( p)| θ + + ( ∂ϕ( p) ∂ y ) 2 |V v ( p)| θ + )],<label>(13)</label></formula><p>where γ , θ , and are three constants.</p><p>As shown in the Equation ( <ref type="formula" target="#formula_20">13</ref>), the inputs of the edgepreserving smoothing filter are an image to be smoothed and a vector field. It can be easily checked that when the vector field is given by</p><formula xml:id="formula_21">V h ( p) = ∂ O * ( p) ∂ x ; V v ( p) = ∂ O * ( p) ∂y , (<label>14</label></formula><formula xml:id="formula_22">)</formula><p>the proposed cost function in Equation ( <ref type="formula" target="#formula_20">13</ref>) is the same as the cost function in <ref type="bibr" target="#b15">[16]</ref>. This implies that the WLS filter in <ref type="bibr" target="#b15">[16]</ref> is a special case of the proposed one. Similarly, using the matrix notation, the above cost function can be rewritten as</p><formula xml:id="formula_23">(ϕ -O * ) T (ϕ -O * ) + γ (ϕ T D T x B x D x ϕ + ϕ T D T y B y D y ϕ),</formula><p>where the matrices B x and B y are given as The vector ϕ that minimizes the cost function is uniquely defined as the solution of the linear equation</p><formula xml:id="formula_24">B x = diag{ 1 |V h ( p)| θ + }; B y = diag{ 1 |V v ( p)| θ + }.<label>(15)</label></formula><formula xml:id="formula_25">(I + γ (D T x B x D x + D T y B y D y ))ϕ = O * . (<label>16</label></formula><formula xml:id="formula_26">)</formula><p>Similarly, by using a fast separate method like the method in <ref type="bibr" target="#b17">[18]</ref>, the above linear equation can be solved very fast. As shown in <ref type="bibr" target="#b17">[18]</ref>, the speed of the fast WLS is almost the same as those of the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref>. The speeds of both the proposed structure filter and the edge-preserving smoothing filter are comparable to the speed of the fast WLS. Therefore, the complexity of the proposed G-GIF is about the double of the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref>. In the next section, the proposed G-GIF will be applied to design a single image haze removal algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SINGLE IMAGE HAZE REMOVAL</head><p>VIA THE G-GIF In this section, a simple single image haze removal algorithm is introduced by using the proposed G-GIF and the Koschmiedars law <ref type="bibr" target="#b21">[22]</ref>. The global atmospheric light A c (c ∈ {r, g, b}) is empirically determined by using a hierarchical searching method based on the quad-tree subdivision <ref type="bibr" target="#b22">[23]</ref>. The value of the transmission map t ( p) is then According to the Koschmiedars law <ref type="bibr" target="#b21">[22]</ref>, a haze image is generally modeled by</p><formula xml:id="formula_27">X c ( p) = Z c ( p)t ( p) + A c (1 -t ( p)), (<label>17</label></formula><formula xml:id="formula_28">)</formula><p>where c ∈ {r, g, b} is a color channel index, X c is a haze image, Z c is a haze-free image, A c is the global atmospheric light, and t is the medium transmission describing the portion of the light that is not scattered and reaches the camera. Unlike the decomposition model in <ref type="bibr" target="#b10">[11]</ref>, it is assumed that the values of A r , A g and A b are estimated before the simplified dark channel is computed. Fortunately, this is not problem by using the method in <ref type="bibr" target="#b22">[23]</ref> to estimate the values of A r , A g and A b . It should be pointed out that the methods in <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, and <ref type="bibr" target="#b8">[9]</ref> are not applicable because the global atmospheric light is needed to estimate before the dark channel is computed.</p><p>A simple haze image model is derived by using the simplified dark channels of the normalized haze image X/A and the normalized haze-free image Z /A. Let Xm ( p) and Zm ( p) be defined as</p><formula xml:id="formula_29">Xm ( p) = min{ X r ( p) A r , X g ( p) A g , X b ( p) A b },<label>(18)</label></formula><formula xml:id="formula_30">Zm ( p) = min{ Z r ( p) A r , Z g ( p) A g , Z b ( p) A b },<label>(19)</label></formula><p>Xm and Zm are called the minimal color components of the images X A and Z A , respectively <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>. Since the transmission map t ( p) is independent of the color channels r, g, and b, it can be derived from the haze image model in Equation <ref type="bibr" target="#b16">(17)</ref> that the relationship between the minimal color components Xm and Zm is given as</p><formula xml:id="formula_31">Xm ( p) = (1 -t ( p)) + Zm ( p)t ( p). (<label>20</label></formula><formula xml:id="formula_32">)</formula><p>Let ζ ( p) be a square window centered at the pixel p of a radius ζ . The simplified dark channels of the normalized images X A and Z A are then defined as <ref type="bibr" target="#b8">[9]</ref> </p><formula xml:id="formula_33">J Z d ( p) = min p ∈ ζ ( p) { Zm ( p )}, (<label>21</label></formula><formula xml:id="formula_34">)</formula><formula xml:id="formula_35">J X d ( p) = min p ∈ ζ ( p) { Xm ( p )}, (<label>22</label></formula><formula xml:id="formula_36">)</formula><p>where the value of ζ is fixed at 7 in this paper.</p><p>Since the value of t ( p) is usually constant in the neighborhood ζ ( p), it can be derived from Equation (20) that</p><formula xml:id="formula_37">J X d ( p) = (1 -t ( p)) + J Z d ( p)t ( p). (<label>23</label></formula><formula xml:id="formula_38">)</formula><p>Compared with the decomposition model in <ref type="bibr" target="#b10">[11]</ref>, the model in the Equation ( <ref type="formula" target="#formula_37">23</ref>) can be applied to improve the robustness of single image haze removal algorithm as shown in Fig. <ref type="figure" target="#fig_9">8</ref>. For example, the color is slightly over-saturated by the model in <ref type="bibr" target="#b10">[11]</ref> as shown in Fig. <ref type="figure" target="#fig_9">8</ref>(e) and the zoom-in region in Fig. <ref type="figure" target="#fig_9">8(b</ref>). The problem is overcome by the proposed decomposition model as illustrated in Fig. <ref type="figure" target="#fig_9">8</ref>(f) and the zoom-in region in Fig. <ref type="figure" target="#fig_9">8(c</ref>). The image to be filtered is J X d and the guidance vector field is defined as ∇ Xm . The structure of ∇ Xm is transferred to the image J</p><formula xml:id="formula_39">X d via min O {λE 1 (O, J X d ) + E 2 (O, ∇ Xm )}, (<label>24</label></formula><formula xml:id="formula_40">)</formula><p>where the value of λ is selected as 1/2048 for all the experimental results in this paper provided that its value is specified. The output image O * is further smoothed as</p><formula xml:id="formula_41">min ϕ p [(ϕ( p)-O * ( p)) 2 +γ ( ( ∂ϕ( p) ∂ x ) 2 | ∂ Xm ( p) ∂ x | θ + + ( ∂ϕ( p) ∂ y ) 2 | ∂ Xm ( p) ∂ y | θ + )],<label>(25)</label></formula><p>where the values of γ , θ , and are respectively selected as 2048, 13/8, and 1/64 for all the experimental results in this paper provided that their values are specified.</p><p>The optimal value of the transmission map t ( p) is then computed as</p><formula xml:id="formula_42">t * ( p) = 1 -ϕ * ( p). (<label>26</label></formula><formula xml:id="formula_43">)</formula><p>Similar to the algorithm in <ref type="bibr" target="#b10">[11]</ref>, the proposed algorithm includes an adaptive sky-region compensation term to detect sky region in a haze image. The value of transmission map is further tuned in the sky region to avoid amplifying noise in the sky region. Finally, the scene radiance Z ( p) is recovered by Fig. <ref type="figure" target="#fig_1">11</ref>. Comparison of the proposed haze removal algorithm and the haze removal algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref> via three haze images. (a, f, k) three images with haze; (b, g, l) de-hazed images by the algorithm in <ref type="bibr" target="#b6">[7]</ref>; (c, h, m) de-hazed images by the algorithm in <ref type="bibr" target="#b7">[8]</ref>; (d, i, n) de-hazed images by the algorithm in <ref type="bibr" target="#b10">[11]</ref>; (e, j, o) de-hazed images by the proposed algorithm.</p><formula xml:id="formula_44">Z c ( p) = X c ( p) -A c t * ( p) + A c . (<label>27)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>In this section, different choices of λ in the Equation ( <ref type="formula" target="#formula_39">24</ref>) as well as γ , θ , and in the Equation ( <ref type="formula" target="#formula_41">25</ref>) are first tested. It is shown in Fig. <ref type="figure" target="#fig_10">9</ref> that the proposed G-GIF is not sensitive to the choices of λ in the Equation ( <ref type="formula" target="#formula_39">24</ref>) as well as γ , θ , and in the Equation <ref type="bibr" target="#b24">(25)</ref>.</p><p>The proposed G-GIF is also compared with the GIF in <ref type="bibr" target="#b6">[7]</ref> and the WGIF in <ref type="bibr" target="#b8">[9]</ref> by using them to study single image haze removal. It is shown in Fig. <ref type="figure" target="#fig_11">10</ref> that the proposed G-GIF preserves the structure of branches and leafs better than the GIF and WGIF. It is also illustrated in Fig. <ref type="figure" target="#fig_1">1</ref> that the proposed G-GIF preserves the structure of hair of the human subject better than the GIF and WGIF. Therefore, the proposed G-GIF preserves fine structure better than the GIF and WGIF.</p><p>The proposed haze removal algorithm is then compared with three state-of-the-art haze removal algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref> by testing three haze images. The guidance image is selected as the minimal color channel of the haze image for all the algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref>. All the settings of the parameters are selected according to the algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref>. It is demonstrated in Fig. <ref type="figure" target="#fig_1">11</ref> that the algorithm in <ref type="bibr" target="#b6">[7]</ref> removes haze better than other haze removal algorithms but it amplifies noise in brightest regions. It is demonstrated in Figs. 11 that the algorithm in <ref type="bibr" target="#b7">[8]</ref> preforms Fig. <ref type="figure" target="#fig_4">13</ref>. Comparison of the proposed haze removal algorithm and the haze removal algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref> via three haze images with large sky regions. (a, f, k) four images with haze; (b, g, l) de-hazed images by the algorithm in <ref type="bibr" target="#b6">[7]</ref>; (c, h, m) de-hazed images by the algorithm in <ref type="bibr" target="#b7">[8]</ref>; (d, i, n) de-hazed images by the algorithm in <ref type="bibr" target="#b10">[11]</ref>; (e, j, o) de-hazed images by the proposed algorithm.</p><p>smoothing filter. The speed of the proposed algorithm is about double of the algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b10">[11]</ref>. Therefore, the proposed algorithm is more suitable for applications on PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND DISCUSSION</head><p>A new globally guided image filtering is introduced in this paper. The proposed filter can be applied to produce sharper images and preserves details in regions of fine structure visibly better than the existing locally guided image filtering. It is applied to study single image haze removal. Experimental results demonstrate that the proposed haze removal algorithm indeed improves visual quality of dehazed images.</p><p>Besides single image haze removal, there are many applications of the proposed filters. For example, the filter can be applied to study panorama imaging <ref type="bibr" target="#b23">[24]</ref>, edge-aware smoothing pyramid for exposure fusion <ref type="bibr" target="#b24">[25]</ref>, detail enhancement, image matting, HDR compression, feathering, high resolution up-sampling, and so on. We will study these applications in our future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Single</head><label></label><figDesc>Image De-Hazing Using Globally Guided Image Filtering Zhengguo Li, Senior Member, IEEE, and Jinghong Zheng, Member, IEEE Abstract-Local edge-preserving smoothing techniques such as guided image filtering (GIF) and weighted guided image filtering (WGIF) could not preserve fine structure. In this paper, a new globally guided image filtering (G-GIF) is introduced to overcome the problem. The G-GIF is composed of a global structure transfer filter and a global edge-preserving smoothing filter. The proposed filter is applied to study single image haze removal. Experimental results show that fine structure of the dehazed image is indeed preserved better by the proposed G-GIF and the dehazed images by the proposed G-GIF are sharper than those dehazed images by the existing GIF. Index Terms-Globally guided image filtering, structure transfer, edge-preserving smoothing, single image haze removal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison of the GIF, the WGIF and the G-GIF. (a) a haze image; (b) a dehazed image by the GIF; (c) a dehazed image by the WGIF; (d) a dehazed by the G-GIF. Both the GIF and the WGIF over smooth the hair of the human subject as illustrated in the zoom-in regions while the problem is overcome by the proposed G-GIF.</figDesc><graphic coords="2,65.99,58.73,117.38,88.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>where ζ ( p ) is a square window centered at the pixel p of a radius ζ . a p and b p are two constants in the window ζ ( p ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Limitation of the WGIF. (a) ζ = 7; (b) ζ = 15; (c) ζ = 30; and (d) ζ = 60. The morphological artifacts are reduced but the hair of the human subject becomes over smoothed if the value of ζ is increased.</figDesc><graphic coords="3,55.43,205.49,122.42,91.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Limitation of the GIF. (a) ζ = 7; (b) ζ = 15; (c) ζ = 30; and (d) ζ = 60. The morphological artifacts are reduced but the hair of the human subject becomes over smoothed if the value of ζ is increased.</figDesc><graphic coords="3,313.55,364.13,122.42,91.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Effect of the maximal filter. (a) a dehazed image with the maximal filter; and (b) a dehazed image without the maximal filter. The morphological artifacts are reduced by the maximal filter but the hair of the human subject is further smoothed heavily.</figDesc><graphic coords="3,439.07,364.13,122.54,91.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Dehazed images by the WGIF without the average operations (6) and (7). (a) ζ = 7; (b) ζ = 15; (c) ζ = 30; and (d) ζ = 60. The fine structures are preserved better by disabling the average operations (6) and (7) while the morphological artifacts become more visible.</figDesc><graphic coords="4,65.99,58.73,117.43,88.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Illustration of the proposed G-GIF by using it to estimate the transmission map of a haze image. (a) a haze image; (b) simplified dark channel of the normalized haze image which is the image to be filtered; (c) output image of the structure transfer filter; and (d) output image of the proposed G-GIF.</figDesc><graphic coords="5,315.71,217.49,79.34,90.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Effect of the global edge-preserving smoothing filter. (a) a dehazed image without the smoothing filter (13); (b) a dehazed image with the smoothing filter (13).</figDesc><graphic coords="5,50.03,217.85,122.52,91.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Two images and their enhanced images via two different decomposition models. (a) an underwater image; (b) an enhanced image via the decomposition model in [11]; and (c) an enhanced image via the proposed model. (d) a haze image; (e) an enhanced image via the decomposition model in<ref type="bibr" target="#b10">[11]</ref>; and (f) an enhanced image via the proposed model. The color is slightly over-saturated by the model in<ref type="bibr" target="#b10">[11]</ref>.</figDesc><graphic coords="5,175.91,217.85,122.52,91.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Different choices of λ in the equation (24) as well as γ , θ , and in the equation (25). (a) λ = 1/2048; (b) λ = 1/512; (c) λ = 1/8192; (d) γ = 512; (e) γ = 1024; (f) γ = 8192; (g) θ = 1; (h) θ = 1.5; (i) θ = 2; (j) = 1/32; (k) = 1/128; and (l) = 1/256. estimated by using the proposed G-GIF. Finally, the scene radiance Z ( p) is recovered.According to the Koschmiedars law<ref type="bibr" target="#b21">[22]</ref>, a haze image is generally modeled by</figDesc><graphic coords="6,58.43,135.89,79.22,59.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Comparison of the proposed G-GIF with the GIF in<ref type="bibr" target="#b6">[7]</ref> and the WGIF in<ref type="bibr" target="#b8">[9]</ref>. (a) a hazed image; (b) a de-hazed image by the GIF in<ref type="bibr" target="#b6">[7]</ref>; (c) a de-hazed images by the WGIF in<ref type="bibr" target="#b8">[9]</ref>; (d) a de-hazed image by the proposed G-GIF. The proposed G-GIF preserves the structure of branches and leafs better than the GIF and WGIF.</figDesc><graphic coords="7,65.03,216.41,93.63,70.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Limitation of the proposed haze removal algorithm. (a) a dehazed image by the proposed algorithm; and (b) a dehazed image by reducing the haze level via an interactive mode.</figDesc><graphic coords="7,317.99,514.61,117.38,102.86" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Jinghong Zheng (S'02-M'09) received the B.Sc. degree in electronic engineering from the Beijing Institute of Technology, Beijing, China, in 2000, and the Ph.D. degree in electronic and electrical engineering from Nanyang Technological University, Singapore, in 2006. Since 2006, she has been a Scientist with the Institute for Infocomm Research, A*STAR, Singapore. She is currently with the Energy Department, Smart Energy and Environment Cluster. Her research interests include forecasting of solar energy, high dynamic range image processing, image fusion and enhancement, in painting, error concealment/resilience of H.264 video, region of interesting video coding, scalable video coding, and video streaming.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>well when the haze is not heavy but the haze is not removed well when the haze is heavy. This is because that the values of α and the coefficients of the linear model are fixed in <ref type="bibr" target="#b7">[8]</ref>. Their values should be adaptive to the haze degree of the input image. It is worth noting that it is challenging to estimate the values of α and the coefficients of the linear model for the algorithm in <ref type="bibr" target="#b7">[8]</ref>. Both the algorithm in <ref type="bibr" target="#b10">[11]</ref> and the proposed algorithm include an adaptive sky-region compensation term to detect sky region in a haze image and the value of transmission map is tuned in the sky region to avoid amplifying noise in the sky region. A drawback of the sky-region compensation term is that the haze might not removed well if there is no sky region in a haze image as shown in Fig. <ref type="figure">11</ref>. This is a limitation of the proposed haze removal algorithm. The problem could be addressed by introducing an interactive mode to the proposed algorithm which allows a user to enable or disable the skyregion compensation term according to her/his preference as shown in Fig. <ref type="figure">12</ref>. Since only the operation in the Equation ( <ref type="formula">27</ref>) is repeated in the interactive mode, the interactive mode in our dehazing apps on smart phones runs in real time.</p><p>All these four haze removal algorithms are also compared by testing three haze images with large sky regions. It is shown in Fig. <ref type="figure">13</ref> that the algorithm in <ref type="bibr" target="#b6">[7]</ref> usually removes haze better than other algorithms while it also amplified noises in the sky regions. The quality of dehazed images by the proposed algorithm is better than the quality of dehazed images by the algorithm in <ref type="bibr" target="#b10">[11]</ref> in the senses that the dehazed images by the proposed algorithm are sharper than those dehazed images by the algorithm in <ref type="bibr" target="#b10">[11]</ref> as demonstrated in Figs. <ref type="figure">11(d</ref>), 11(i), 13(d), 13(i), and 13(n), and the fine structure is preserved better by the proposed algorithm as shown in Figs. <ref type="figure">11(e</ref>), 11(j), 13(e), 13(j), and 13(o). This is because that the WGIF over smoothes the dehazed images, especially in the areas of fine structures. The problem is overcome by the proposed G-GIF.</p><p>The no-reference perceptual fog density assessment metric D in <ref type="bibr" target="#b0">[1]</ref> is also adopted to compare the four haze removal algorithms. The metric in <ref type="bibr" target="#b0">[1]</ref> does not require the original foggy image. A lower value of D implies better defogging performance. It is demonstrated in Table <ref type="table">I</ref> that the algorithm in <ref type="bibr" target="#b6">[7]</ref> is ranked the first for four images and the proposed algorithm is ranked the first for two images. The proposed algorithm is ranked the first on average. Both the haze removal algorithm in <ref type="bibr" target="#b10">[11]</ref> and the proposed haze removal algorithm include the adaptive sky-region compensation term. Clearly, the experimental results in Table <ref type="table">I</ref> show that the proposed G-GIF indeed outperforms the WGIF.</p><p>Overall, the proposed algorithm preserves details in regions of fine structure visibly better than the algorithms in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>. On the other hand, since the proposed G-GIF is composed of a structure transfer filter and an edge-preserving </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Referenceless prediction of perceptual fog density and perceptual image defogging</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3888" to="3901" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chromatic framework for vision in bad weather</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)<address><addrLine>Hilton Head Island, SC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">Jun. 2000</date>
			<biblScope unit="page" from="598" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visibility in bad weather from a single image</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Single image dehazing</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An improved dark-object subtraction technique for atmospheric scattering correction of multispectral data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Chavez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="459" to="479" />
			<date type="published" when="1988-04">Apr. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Single image haze removal using dark channel prior</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2341" to="2353" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Guided image filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1397" to="1409" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A fast single image haze removal algorithm using color attenuation prior</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3522" to="3533" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Weighted guided image filtering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="129" />
			<date type="published" when="2015-01">Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gradient domain guided image filtering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4528" to="4539" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Edge-preserving decomposition-based single image haze removal</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5432" to="5441" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">High quality depth map upsampling for 3D-TOF cameras</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis<address><addrLine>Colorado Springs, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="1623" to="1630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient domain high dynamic range compression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="67" to="68" />
			<date type="published" when="2002-07">Jul. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Poisson image editing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gangnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="318" />
			<date type="published" when="2003-07">Jul. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain transform for edgeaware image and video processing</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S L</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Edge-preserving decompositions for multi-scale tone and detail manipulation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Farbman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detail-enhanced exposure fusion</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahardja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4672" to="4676" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast global image smoothing based on weighted least squares</title>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5638" to="5653" />
			<date type="published" when="2014-12">Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast visibility restoration from a single color or gray level image</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Tarel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hautiere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-10">Sep./Oct. 2009</date>
			<biblScope unit="page" from="2201" to="2208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast single image dehazing using iterative bilateral filter</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhihui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhiqiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Inf</title>
		<meeting>Int. Conf. Inf<address><addrLine>Wuhan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-12">Dec. 2010</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast image dehazing using guided joint bilateral filter</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6-8</biblScope>
			<biblScope unit="page" from="713" to="721" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Theorie der horizontalen sichtweite</title>
		<author>
			<persName><forename type="first">H</forename><surname>Koschmider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contrib. Phys. Free Atmos</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="171" to="181" />
			<date type="published" when="1924">1924</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimized contrast enhancement for real-time image and video dehazing</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-D</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="410" to="425" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Instant color matching for mobile panorama imaging</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6" to="10" />
			<date type="published" when="2015-01">Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Detail-enhanced multi-scale exposure fusion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1243" to="1252" />
			<date type="published" when="2017-03">Mar. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
