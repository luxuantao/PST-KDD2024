<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Diffusion Scattering Graph Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ke</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Jiangsu Provincal Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinyan</forename><surname>Pu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Jiangsu Provincal Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiaxing</forename><surname>Li</surname></persName>
							<email>jiaxingli@seu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Jiangsu Provincal Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiasong</forename><surname>Wu</surname></persName>
							<email>jswu@seu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Jiangsu Provincal Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huazhong</forename><surname>Shu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Jiangsu Provincal Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Youyong</forename><surname>Kong</surname></persName>
							<email>kongyouyong@seu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">Jiangsu Provincal Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Diffusion Scattering Graph Neural Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph neural network (GNN) is popular now to solve the tasks in non-Euclidean space and most of them learn deep embeddings by aggregating the neighboring nodes. However, these methods are prone to some problems such as over-smoothing because of the single-scale perspective field and the nature of low-pass filter. To address these limitations, we introduce diffusion scattering network (DSN) to exploit high-order patterns. With observing the complementary relationship between multilayer GNN and DSN, we propose Hierarchical Diffusion Scattering Graph Neural Network (HDS-GNN 1 ) to efficiently bridge DSN and GNN layer by layer to supplement GNN with multi-scale information and band-pass signals. Our model extracts node-level scattering representations by intercepting the low-pass filtering, and adaptively tunes the different scales to regularize multi-scale information. Then we apply hierarchical representation enhancement to improve GNN with the scattering features. We benchmark our model on nine real-world networks on the transductive semisupervised node classification task. The experimental results demonstrate the effectiveness of our method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As the generalization of CNN to non-Euclidean space, Graph Neural Networks (GNNs) have been widely studied in recent years. Starting from the success of GCN on semisupervised node-level task <ref type="bibr" target="#b5">[Kipf and Welling, 2017]</ref>, various efficient graph-based models have been proposed to solve graph-related tasks, such as link prediction <ref type="bibr">[Zhang and Chen, 2018]</ref>, node classification <ref type="bibr" target="#b13">[Veličković et al., 2018]</ref>, graph classification <ref type="bibr">[Lee et al., 2019]</ref>. Based on these fundamental tasks, GNNs are widely applied in various fields, such as traffic forecasting <ref type="bibr" target="#b5">[Jiang and Luo, 2021]</ref> and neuroscience <ref type="bibr" target="#b7">[Kong et al., 2021]</ref>.</p><p>Most existing GNNs encode graph representation in message passing criteria, i.e. propagating and aggregating neighboring nodes to learn deep representations of the central node <ref type="bibr" target="#b5">[Kipf and Welling, 2017;</ref><ref type="bibr" target="#b4">Hamilton et al., 2017;</ref><ref type="bibr" target="#b13">Veličković et al., 2018]</ref>. However, recent studies reveal that GNN acts as actually a low-pass filter on graph signal <ref type="bibr" target="#b8">[Li et al., 2018;</ref><ref type="bibr">Nt and Maehara, 2019;</ref><ref type="bibr" target="#b0">Balcilar et al., 2021a]</ref>, which makes nodes undistinguishable when stacking multiple layers, and leads to oversmoothing problem. Additionally, GNNs usually perform on a fixed range of neighbors and directly aggregate the shallow representations of the neighboring nodes. This kind of approaches lack multi-scale information for learning intrinsic properties and is limited to a local receptive field, which prevents information propagation over long distances.</p><p>To overcome the weaknesses mentioned above, we introduce diffusion scattering network (DSN) <ref type="bibr" target="#b2">[Gama et al., 2018]</ref> to provide multi-scale band-pass signals for GNNs. DSN is a variant of scattering network <ref type="bibr" target="#b10">[Mallat, 2012]</ref> that utilizes diffusion wavelet <ref type="bibr" target="#b1">[Coifman and Maggioni, 2006]</ref> to perform multi-scale analysis and build stable representations of graph signals. Some recent works have studied the application of scattering networks to graph tasks. <ref type="bibr" target="#b3">[Gao et al., 2019;</ref><ref type="bibr">Zou and Lerman, 2020]</ref> aggregates the wavelet coefficients built from all scattering paths to just one representation. <ref type="bibr" target="#b2">[Gama et al., 2018]</ref> builds a diffusion GNN that only applies the first layer of scattering network as the convolution operator, and each layer of the model corresponds to a different scattering scale. <ref type="bibr" target="#b11">And [Min et al., 2020;</ref><ref type="bibr" target="#b12">Min et al., 2021]</ref> only select the scattering features which are built through several pre-defined paths to provide fragmented band-pass signals.</p><p>Most of these works rely on the handcrafted scattering features and none of them make use of the hierarchical properties of the scattering network, which is also important for a distinguishable representation.</p><p>Our method is elicited by an interesting observation between multi-layer GNN and DSN, that is the deeper layers of GNN continually smooth the signals while the deeper layers of DSN extract finer signals. And this observation naturally leads to a hierarchical fusing approach. In this work, we propose a novel graph learning model named Hierarchical Diffusion Scattering Graph Neural Network (HDS-GNN) to build the adaptive node-level scattering features, and bridge DSN and GNN by fusing representations layer by layer. Additionally, we adaptively weigh the different scales to strengthen the useful scales and reduce the impact of noise.</p><p>In summary, our contributions in this work are:</p><p>• By intercepting the low-pass filtering in the scattering network, we extract node-level information from DSN, which also contains multi-scale band-pass signals. The experimental results demonstrate the effectiveness of our model, as well as a significant improvement over the backbone GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Note. When we consider a graph G = {V, E, W}, it usually contains three elements: nodes, edges and edge weights. Every node v i ∈ V has a d-dimension feature x i and X ∈ R n×d is the feature matrix of all nodes. Every edge (v i , v j ) ∈ E where i = j is an undirected edge connecting v i and v j with an edge weight ω ij ∈ W. Also, the connectivity of G can be represented by an adjacency matrix A or a weighted adjacency matrix W . For node-level task, every node has a class label y i ∈ Y ; for graph-lavel task, every graph has a class label Y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Neural Network</head><p>Graph neural network is well-studied recently to embed graph structured data. Most current GNNs <ref type="bibr" target="#b5">[Kipf and Welling, 2017;</ref><ref type="bibr" target="#b13">Veličković et al., 2018;</ref><ref type="bibr" target="#b4">Hamilton et al., 2017]</ref> follow message passing mechanism which aggregates the local neighborhoods and updates the target node:</p><formula xml:id="formula_0">H (l+1) v = upd(H (l) v , agg({H (l) u , u ∈ N (v)})<label>(1)</label></formula><p>where H v denotes the representation of node v; agg(...) aggregates the neighbor nodes N (v), which can be replaced by any neighbor sampling method, and outputs a message; upd(v, message) updates H v according to the message and v itself. For example, <ref type="bibr">GCN [2017]</ref> set l) ; GAT <ref type="bibr">[2018]</ref> learns coefficients in agg based on attention mechanism.</p><formula xml:id="formula_1">agg = u 1/ (d u + 1)(d v + 1)H (l) u and upd = (1/(d v + 1)H (l) v + agg)Θ (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Diffusion Scattering Network</head><p>The scattering transform <ref type="bibr" target="#b10">[Mallat, 2012;</ref><ref type="bibr" target="#b1">Bruna and Mallat, 2013]</ref> is a multi-resolution analysis method to build stable representations of images (such as translation invariance and rotation invariance) with wavelets. And the diffusion scattering network generalizes it to the non-Euclidean domain by leveraging graph diffusion wavelet.</p><p>The graph diffusion wavelet is defined by the power of diffusion operator to accomplish multi-resolution analysis. The symmetric diffusion operator defined in <ref type="bibr" target="#b2">[Gama et al., 2018]</ref> is:</p><formula xml:id="formula_2">T sym = 1 2 (I + D − 1 2 W D − 1 2 )</formula><p>; and the random walk operator defined in <ref type="bibr" target="#b3">[Gao et al., 2019]</ref> is:</p><formula xml:id="formula_3">T rw = 1 2 (I + W D −1 )</formula><p>, where both D denote the digonal degree matrix. With the multiple powers of the diffusion operator, a series of multiscale wavelet filters can be constructed according to <ref type="bibr" target="#b1">[Coifman and Maggioni, 2006]</ref> :</p><formula xml:id="formula_4">ψ 0 = I − T, ψ j = T 2 j−1 (I − T 2 j−1 ) = T 2 j−1 − T 2 j (2)</formula><p>where j denotes orders. Then, we can build a filter bank Ψ = {ψ 0 , . . . , ψ J } with both spatial and spectral localization. The diffusion wavelet coefficients are obtained with the filter bank:</p><formula xml:id="formula_5">Ψ J (G, x) = {ψ 0 x, . . . , ψ J x}. The diffusion scattering transform Φ J,L (G, x</formula><p>) is constructed by cascading the wavelet operator Ψ, a point-wise nonlinearity operator ρ and a low-pass operator U , where L denotes layers and J denotes orders. The scattering representation of each layer in the scattering network is:</p><formula xml:id="formula_6">     φ 0 = U x, φ 1J = U ρΨ J (G, x) = U ρΨx φ lJ = U ρΨ . . . ρΨx = U (ρΨ) l x, 0 ≤ l &lt; L (3)</formula><p>3 Graph Signal Processing in GNN and DSN</p><p>Due to the aggregation of direct neighbors, GNNs actually act as a low-pass filter on spectral <ref type="bibr" target="#b0">[Balcilar et al., 2021a;</ref><ref type="bibr">Nt and Maehara, 2019;</ref><ref type="bibr" target="#b8">Li et al., 2018]</ref> which smoothes the graph signal, and the smoothness is also considered as the key to success of GNNs <ref type="bibr" target="#b0">[Balcilar et al., 2021b]</ref>. This success is based on a premise that adjacent nodes are similar, which is not completely feasible for some real-world networks, e.g., nodes of different classes connected together <ref type="bibr" target="#b13">[Xu et al., 2019]</ref>. This kind of connectivity corresponds to highfrequency signals in the spectral domain, and reasonable use of these signals can be an effective way to enhance GNNs. In addition, as GNN going deeper, the signal is smoother. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, the low-pass band of GCN is narrowed layer by layer. This leads to a worse ability to distinguish nodes and eventually leads to oversmoothing. As introduced above, graph scattering network extracts multi-scale band-pass signals by cascading wavelet operators and is able to provide high frequency signals that GNN lacks. Recent works <ref type="bibr" target="#b11">[Min et al., 2020;</ref><ref type="bibr" target="#b12">Min et al., 2021]</ref>   <ref type="figure">(</ref> )</p><formula xml:id="formula_7">Inter-scale weighting Graph diffusion scattering network 𝜓 0 𝜓 1 𝜓 2 ( ) 𝐿 0 𝐿 1 𝐿 2 W (0) W (1) W (2) ( ) graph convolution (backbone) (…) concatenation 𝐻 (1) = (𝑆 (0) ||𝐻 (0) ) input Hierarchical enhancement 𝐻 (3) = (𝑆 (2) ||𝐻 (2) ) 𝑌(output) classifier ( ) Λ Λ 𝐻 (0) (input) 𝑆 0 𝑆 1 𝑆 2 𝐹 (2)</formula><p>𝐹 ( <ref type="formula" target="#formula_0">1</ref>) 𝐹 ( <ref type="formula">0</ref>) 𝐻 (2) = (𝑆 (1) ||𝐻 ( <ref type="formula" target="#formula_0">1</ref>) )</p><p>Figure <ref type="figure" target="#fig_3">2</ref>: The architecture of proposed HDS-GNN. Illustration for J = 3 and L = 3. The input graph G on both sides is the same. The one on the left is the input of the scattering network, and the other one on the right is the input of the backbone GNN. For the first layer L0, only one scale representation F 0 is obtained so that there is no need for inter-scale weighting. For deeper layers, the shared weight Λ is applied for different scales. At the last layer, we connect a classifier (i.e., a GCN layer) to achieve the node classification task.</p><p>to each layer of GNN, and do not consider the progressive relationship between layers, that is, the deeper layer of scattering network can extract more refined features. As shown in Figure <ref type="figure" target="#fig_0">1</ref>(c), our method provide finer scattering features for smoother GNN features as the network deepens. This allows the model to maintain sufficiently subtle differences when smooth the overall signal. Our follow-up experiments verifies this observation.</p><p>4 The Proposed Method  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Node-Level Features of the Scattering Network</head><p>In this subsection, we first discuss the properties of the diffusion scattering network (DSN) and then introduce our approach to obtaining node-level scattering features.</p><p>Diffusion operator T is constructed by normalized adjacency matrix, and represents diffusion probabilities within one hop (or random walk probability within one step); similarly, T k represents probabilities within k hops (i.e. k steps).</p><p>T k x can be seen as a low-pass filter due to the sum operation on every row of x. As shown in Equ.2, the wavelet operator ψ j = T 2 j−1 − T 2 j represents the difference in probability distribution between radius 2 j−1 and 2 j , and ψ j x represents the band-pass signals between the scale 2 j−1 and 2 j ; the base of 2 is for convenient calculation. The signal can be iteratively decomposed by cascading the nonlinearity and wavelet operators to build a multilayer network. The deeper layer can be considered as an enhancement of the previous one, which captures finer information on the previous layer. Similar to the structure of convolution neural network, which typically is convolution-activation-pooling, diffusion scattering network also consists of three parts: wavelet operators Ψ, nonlinearity ρ, low-pass operator U . Figure <ref type="figure" target="#fig_4">3</ref> shows the detailed steps in one layer of the scattering network. The network extracts the node-level rich features after Ψ and ρ, and then builds the graph-level stable features after U . To accomplish nodes-level tasks, we apply absolute value as the nonlinearity and take the node-level rich features directly as the scattering features:</p><formula xml:id="formula_8">𝚲 = {𝜆 0 , 𝜆 1 , 𝜆 2 } 𝐹 𝒫 2 (2) ( ) … 𝜆 0 𝜆 1 𝜆 2 𝚲 Shared</formula><formula xml:id="formula_9">F (0) (G, x) = x, F (l) (G, x) = |Ψ * F (l−1) | = |Ψ * | . . . |Ψx| . . . ||<label>(4)</label></formula><p>where | • | is point-wise absolute value operator and F (l) is the scattering features in layer l of the scattering network. Each layer of scattering features contains a set of band-pass signal information from scale 1, namely 2 0 , to scale 2 J . These multi-scale features correspond to neighbors from near to far in the spatial domain, and frequency bands from high to low in the spectral domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Shared Weighting Across Scales</head><p>The previous subsection discusses the scattering network from a horizontal perspective, i.e., the information of every layer and the relationship between layers. From the vertical perspective, the diffusion scattering network is built as a tree structure, so we use "parent" and "child" to represent the relationship between nodes. In this section, we introduce the shared weighting to adaptively regularize different scales.</p><p>As shown in Figure <ref type="figure" target="#fig_5">4</ref>, we set a learnable weight Λ = {λ 0 , ..., λ J } for every scale to make an adaptive use of them. In this way, the scales containing useful details will be enlarged, while the scales containing noise will be reduced. The main purpose of Λ is to weight different "scales", namely inter-scale weighting. Therefore, Λ is applied to the child nodes from the same parent node and shared across parent nodes in the whole tree, namely global shared weights. Considering the progressive relationship between model layers, the weight sharing is also applied within each layer, namely layer-wise shared weights. Then, a linear projection is ap-plied on the weighted representation with a learnable matrix Θ ∈ R d×F hid , where F hid is the dimension of hidden features.</p><p>In order to formulate this step, we first define the node in the scattering network. Every non-root node in the scattering network is produced by a sequence of wavelet decomposition, which is a permutation of wavelet operators in the filter bank. We denote this sequence with a scattering path p = (ψ j1 , ..., ψ j l ) where l is the layer number of the node. And we define the one-step path set as P = {(ψ i ); 0 ≤ i ≤ J}, similarly, the two-step path set is P 2 = {(ψ i , ψ j ); 0 ≤ i, j ≤ J}. For completeness, we define the zero-step path set as ∅, which corresponds to the root of the scattering network. Thus, ∀p ∈ ∅ + P + P 2 + ... + P l and we can use p to correspond to every node in the scattering network. Therefore, the inter-scale weighting is defined as:</p><formula xml:id="formula_10">           S (0) = F (0) Θ (0) S (l) = concat p ∈P l−1 λ k F (l) p +P[k] Θ (l) , 0 ≤ k ≤ J = concat p ∈P l−1 ΛF (l) c(p ) Θ (l) (5)</formula><p>where concat is concatenation operation and S (l) is the weighted DSN feature of layer l; F p denotes the scattering feature of the node that corresponds to scattering path p; c(p) denotes the child nodes of the node p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Hierarchical Representation Enhancement</head><p>As we discussed before, the deeper layer of DSN contains the more refined scales and more detailed information, while the deeper layer of GNN contains smoothness over a wider range, which corresponds to a lower frequency signal. Based on this complementary property between DSN and GNN by layers, we propose to enhance GNN representations with DSN features layer by layer. In particular, we concatenate the representations of DSN and GNN layer by layer to build a new representation:</p><formula xml:id="formula_11">H (l+1) = σ S (l) || GNN A, H (l) (6)</formula><p>where σ(•) is a nonlinear activation function and || represents the concatenation operation. For example, if the <ref type="bibr">GCN [Kipf and Welling, 2017]</ref> is used as the backbone network (HDS-GCN), the propagation process can be described as:</p><formula xml:id="formula_12">H (l+1) = σ S (l) || D − 1 2 AD − 1 2 H (l) Θ (l) (7)</formula><p>After the multi-layer feedforward propagation, the node-level embedding fused with multi-scale band-pass signals can be obtained. Then a classifier is followed to accomplish the downstream task. In particular, one GCN layer is connected to achieve semi-supervised node classification:</p><formula xml:id="formula_13">Ŷ = softmax GCN H (L) (8) L = cross entropy Ŷ [mask, :] , Y [mask, :]<label>(9)</label></formula><p>As shown in Figure <ref type="figure" target="#fig_3">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison Experiment</head><p>We test our model with GCN and GAT as backbones, namely HDS-GCN and HDS-GAT, on the benchmarks mentioned above. Besides, global-shared weighting is denoted by (G) and layer-wise shared weighting is denoted by (L).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>We choose multiple baseline models on node classification task for a comparison: GCN [Kipf and Welling, 2017],</p><p>JKNet <ref type="bibr" target="#b13">[Xu et al., 2018]</ref>, <ref type="bibr">GAT [Veličković et al., 2018]</ref>, AP-PAP <ref type="bibr" target="#b6">[Klicpera et al., 2018]</ref>, LanczosNet <ref type="bibr" target="#b9">[Liao et al., 2019]</ref>, Sc- <ref type="bibr">GCN [Min et al., 2020]</ref> and <ref type="bibr">GSAN [Min et al., 2021]</ref>.</p><p>We keeps the experimental results recorded in the published papers as much as possible, and the rest of the results are retested based on the official codes. For JKNet we reimplement a 2∼4 layers model with pyg <ref type="bibr">[Fey and Lenssen, 2019]</ref> because no official code was found. The hyperparameter tuning of re-testing models follows the same way with our models and the best results are recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As shown in Table <ref type="table" target="#tab_1">1</ref>, our models achieve the highest accuracy in all used datasets. HDS-GCN achieves the best performance on four datasets (Cora, Citeseer, DBLP, Coauthor CS) and HDS-GAT achieves the best performance on the other five (Pubmed, Amazon Computers, Amazon Photo, Cornell, Texas).</p><p>Compared with GCN, our model (HDS-GCN) outperforms by 12.3% at most on Cornell (in absolute accuracy), by 0.9% at least on Pubmed, and by 4.92% on average. Compared with GAT, our model (HDS-GAT) outperforms by 15.8% at most on Texas, by 1.1% at least on Cora, and by 5.87% on average. Our method improves GNN on most datasets, especially on texas and Cornell because these two have more high-frequency information that GNN cannot effectively utilize. It can be noticed that HDS-GAT is outperformed at least 0.4% on Citeseer by GAT. However, in our retesting experiment of GAT with the official code, only an average accuracy  <ref type="bibr">et al., 2020]</ref>, our model also outperforms it by 6.3% at most on Texas, by 0.4% at least on Cora, and by 2.5% on average. This result verifies that more complete scattering features have better expressive ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Submodules</head><p>As introduced before, our model can be regarded as three submodules: diffusion scattering network (DSN), inter-scale weighting (SW) and hierarchical enhancement. In this subsection, we start with the complete proposed model and then remove the sub-modules one by one. The submodule hierarchical enhancement is actually a fusion approach and not capable for this study and it will be evaluated in the next evaluation. In this experiment, we apply global shared weights and set GCN and GAT as the backbones.</p><p>We show the results in Figure <ref type="figure">5</ref>. It is clear that the classification accuracy of the model improves with the addition of every submodule (i.e. from left to right). For most of the datasets, hierarchical scattering features provide more improvement due to the band-pass signals. But for Cora, the scale-weighting provides more improvement, which is because Cora network is assortative <ref type="bibr" target="#b0">[Balcilar et al., 2021b]</ref> and the weighting can reduce some unwanted high-frequency information in the added multi-scale signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Fusion Strategies</head><p>In this subsection, we aim to make an evaluation of "fusion" and answer a question: does it really work to hierarchically fuse finer features to deeper backbone? We first evaluate the role of the fusion method and then evaluate the role of the finer features.</p><p>(1) Global fusion, or non-hierarchical fusion, provides full-scale scattering representations S = concat L−1 l=0 (S l ) to GNN at once. We build two variants to perform comparison. G 0 DS-GNN denotes that S are fused to the first layer of the backbone, i.e. H (0) = (X || S); G L DS-GNN denotes that S are fused to the last layer, i.e. H (L) = H (L−1) || S . The rest of the experimental settings are the same as the last ablation. As shown in Figure <ref type="figure" target="#fig_7">6</ref>, it is obvious that the hierarchical fusion model (blue) outperforms all global fusion models (green). This result demonstrates the effectiveness of hierarchical fusion. Interestingly, in terms of fusing globally, G 0  are outperformed by G L in almost all experiments. This is mainly because, after being filtered by GNN, there is only the low frequency of S left in G 0 , which undoubtedly loses the band-pass signal in S.</p><p>(2) In order to know if finer scattering features improve deeper GNN layers, we replace all of F (l) with only F (i) , i &lt; L for fusing with scale-invariant band-pass signals. As shown in Figure <ref type="figure" target="#fig_7">6</ref>, all the results with scale-invariant signals <ref type="bibr">(yellow)</ref> are lower than the results with finer-by-layers signals (blue), which proves our basic observation. Besides, it can be observed the results with finer features are usually lower, which may be because the shallower GNN layers can only obtain coarser latent representations and cannot effectively use finer features. And another interesting observation from the figure is that GDS-GNN performs better than scale-invariant models in most cases, which indicates the full-scale scattering features are usually better than single-scale features (an exception is on the Cora dataset, which because its homophily makes it insensitive to feature scales and more sensitive to fusion method).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we discuss the limitations of current GNN models and elicit an observation of multi-layer GNN and DSN. Based on this, we propose a novel model (HDS-GNN) to augment GNN representation with node-level scattering representations. For future work, we may explore the efficient calculation and more complex fusion method that would also benefit the model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison in frequency domain</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>extract scattering features with several pre-defined scattering path, resulting in fixed-width band-pass signals, as shown in Figure 1(b). These methods only add fixed scattering features( )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>4.1 The Overall Structure of the Proposed Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>Figure2shows the overall structure of the proposed Hierarchical Diffusion Scattering Graph Neural Network (HDS-GNN), where J = 3, L = 3 for illustration. The model mainly consists of three parts: 1) graph diffusion scattering network, which builds node-level multi-scale rich representation from input graph signal G; 2) inter-scale weighting, which makes an adaptive use of different scales with shared weights; and 3) hierarchical representation enhancement, which supplements GNN with the scattering features layer by layer to build an enhanced representation. Lastly, a classifier is connected for node classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Internal steps of a scattering network layer. The node-level feature (in the dashed box) is extracted for subsequent learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An illustration of shared inter-scale weighting in one layer. For layer-wise weight sharing, Λ is shared within one layer. For global weight sharing, Λ is also shared with other layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Accuracy results of ablation study on fusion methods.Green is for global fusion and yellow is for scale-invariant fusion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>(1)Datasets statistics (row 1-4). (2)Accuracy results (in percentage) on nine benchmarks (the other rows). The top two results are overlined, and the best results are marked in bold. HDS-GNNs are the variants of our model with different backbones. In this experiment, we choose GCN and GAT as the backbones. (G) and (L) represent global shared weights and layer-wise shared weights respectively. Most of the results are from our re-testing with official code; + denotes the results from our re-implementation; * denotes the results from the published papers; OOM denotes Out-of-Memory on our CUDA device.<ref type="bibr" target="#b13">Pei et al., 2019]</ref> for WebKB networks. We test all models 10 times and record the average numbers. We use the Adam as the training optimizer and the tool hyperopt<ref type="bibr" target="#b0">[Bergstra et al., 2013]</ref> for hyper-parameter searching. We set the maximum training epoch to 300 and use early stopping when validation loss does not decrease for consecutive 20 epochs. The learned weights of models used for testing are the checkpoint which has the lowest validation loss in training progress. All the experiments run in PyTorch on NVIDIA 3090.</figDesc><table><row><cell>Datasets</cell><cell cols="4">Cora Citeseer Pubmed DBLP</cell><cell>Amazon Computers</cell><cell>Amazon Photo</cell><cell>Coauthor CS</cell><cell cols="2">Cornell Texas</cell></row><row><cell>Nodes</cell><cell>2,708</cell><cell>3,327</cell><cell>19,717</cell><cell>17,716</cell><cell>13,381</cell><cell>7,487</cell><cell>18,333</cell><cell>183</cell><cell>183</cell></row><row><cell>Edges</cell><cell>5,429</cell><cell>4,732</cell><cell>44,338</cell><cell>105,734</cell><cell>245,778</cell><cell>119,043</cell><cell>81,894</cell><cell>295</cell><cell>309</cell></row><row><cell>Features</cell><cell>1,433</cell><cell>3,703</cell><cell>500</cell><cell>1,639</cell><cell>767</cell><cell>745</cell><cell>6,805</cell><cell>1703</cell><cell>1703</cell></row><row><cell>Classes</cell><cell>7</cell><cell>6</cell><cell>3</cell><cell>5</cell><cell>10</cell><cell>8</cell><cell>15</cell><cell>5</cell><cell>5</cell></row><row><cell>GCN</cell><cell>81.5*</cell><cell>70.3*</cell><cell>79.0*</cell><cell>76.2</cell><cell>83.3</cell><cell>91.7</cell><cell>92.8</cell><cell>52.3</cell><cell>56.9</cell></row><row><cell>JKNet</cell><cell>81.1*</cell><cell>69.8*</cell><cell>78.1*</cell><cell>71.2 +</cell><cell>83.9 +</cell><cell>90.7 +</cell><cell>91.3 +</cell><cell>54.9 +</cell><cell>56.2 +</cell></row><row><cell>GAT</cell><cell>83.0*</cell><cell>72.5*</cell><cell>79.0*</cell><cell>77.4</cell><cell>81.1</cell><cell>91.3</cell><cell>88.4</cell><cell>56.9</cell><cell>57.4</cell></row><row><cell>APPNP</cell><cell>83.3*</cell><cell>71.8*</cell><cell>80.1*</cell><cell>81.1</cell><cell>70.8</cell><cell>90.1</cell><cell>90.2</cell><cell>57.1</cell><cell>56.7</cell></row><row><cell>LanczosNet</cell><cell>79.5*</cell><cell>66.2*</cell><cell>78.3*</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Sc-GCN</cell><cell>84.2*</cell><cell>71.7*</cell><cell>79.4*</cell><cell>81.5*</cell><cell>85.8</cell><cell>92.9</cell><cell>92.1</cell><cell>60.0</cell><cell>60.9</cell></row><row><cell>GSAN</cell><cell>84.0*</cell><cell>71.3*</cell><cell>79.8*</cell><cell>82.6*</cell><cell>81.7</cell><cell>91.1</cell><cell>92.4</cell><cell>62.7</cell><cell>58.2</cell></row><row><cell>HDS-GCN (G)</cell><cell>84.6</cell><cell>72.6</cell><cell>79.9</cell><cell>84.0</cell><cell>86.4</cell><cell>92.7</cell><cell>93.5</cell><cell>64.6</cell><cell>67.3</cell></row><row><cell>HDS-GCN (L)</cell><cell>84.2</cell><cell>73.0</cell><cell>79.6</cell><cell>83.7</cell><cell>86.9</cell><cell>94.2</cell><cell>93.8</cell><cell>63.7</cell><cell>67.2</cell></row><row><cell>HDS-GAT (G)</cell><cell>84.3</cell><cell>72.1</cell><cell>80.6</cell><cell>82.4</cell><cell>89.2</cell><cell>94.4</cell><cell>93.5</cell><cell>64.6</cell><cell>68.2</cell></row><row><cell>HDS-GAT (L)</cell><cell>84.1</cell><cell>71.8</cell><cell>80.3</cell><cell>83.4</cell><cell>89.1</cell><cell>93.7</cell><cell>93.4</cell><cell>65.5</cell><cell>73.6</cell></row><row><cell cols="3">5 Evalution and Experiment</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Experimental Settings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Our experimental setup examines the semi-supervised node</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">classification task in the transductive setting. We use sparse</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">splitting (20 per class/500/1000) [Kipf and Welling, 2017] for</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">citation networks, co-purchase networks and co-authorship</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">network, and use dense splitting (60%/20%/20%) [</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>, Ŷ ∈ R n×C is the output of the classifier, where C is the number of classes; L is cross entropy loss for node classification; mask is the node mask that only makes training nodes visible. Datasets We choose nine benchmarks for experiments: (1) four citation networks: Cora, Citeseer, Pubmed [Sen et al., 2008] and DBLP [Bojchevski and Günnemann, 2018]; (2) two co-purchase networks: Amazon Computers and Amazon Photo [Shchur et al., 2018]; (3) one co-authorship network: Coauthor CS [Shchur et al., 2018]. (4) two WebKB networks: Cornell and Texas [Peiet al., 2019]. The statistical summary can be found in Table1.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by grant BE2019748 Natural Science Foundation of Jiangsu Province and grant 62171125,31800825,31640028 National Natural Science Foundation of China.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures</title>
		<author>
			<persName><surname>Balcilar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
				<imprint>
			<publisher>Aleksandar Bojchevski and Stephan Günnemann</publisher>
			<date type="published" when="2013">2021a. 2021. 2021b. 2021. 2013. 2013. 2018. 2018</date>
			<biblScope unit="page" from="115" to="123" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">Bruna</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mallat</forename><forename type="middle">;</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Maggioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
				<imprint>
			<publisher>Coifman and Maggioni</publisher>
			<date type="published" when="2006">2013. 2013. 2006. 2006. 2019</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="53" to="94" />
		</imprint>
	</monogr>
	<note>Invariant scattering convolution networks</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Diffusion scattering transforms on graphs</title>
		<author>
			<persName><surname>Gama</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geometric scattering for graph data analysis</title>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="2122" to="2131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Luo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.11174</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2021. 2021. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Graph neural network for traffic forecasting: A survey</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Predict then propagate: Graph neural networks meet personalized pagerank</title>
		<author>
			<persName><surname>Klicpera</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional network for diagnosis and treatment response prediction of major depressive disorder from functional connectivity</title>
		<author>
			<persName><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Inyeop Lee, and Jaewoo Kang</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2021. 2021. 2019</date>
			<biblScope unit="page" from="3734" to="3743" />
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Lanczosnet: Multi-scale deep graph convolutional networks</title>
		<author>
			<persName><surname>Liao</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stéphane Mallat. Group invariant scattering</title>
		<author>
			<persName><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1331" to="1398" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Scattering gcn: Overcoming oversmoothness in graph convolutional networks</title>
		<author>
			<persName><forename type="first">Min</forename></persName>
		</author>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="14498" to="14508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Geometric scattering attention networks</title>
		<author>
			<persName><forename type="first">Min</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09550</idno>
	</analytic>
	<monogr>
		<title level="m">Hoang Nt and Takanori Maehara. Revisiting graph neural networks: All we have is low-pass filters</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2021. 2021. 2019</date>
			<biblScope unit="page" from="8518" to="8522" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Graph convolutional networks using heat kernel for semi-supervised learning</title>
		<author>
			<persName><forename type="first">Pei</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS workshop</title>
				<editor>
			<persName><forename type="first">Bingbing</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Qi</forename><surname>Cao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Keting</forename><surname>Cen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</editor>
		<imprint>
			<publisher>Dongmian Zou and Gilad Lerman</publisher>
			<date type="published" when="2008">2019. 2019. 2008. 2008. 2018. 2018. 2018. 2018. 2018. 2018. 2019. 2019. 2018. 2018. 2020. 2020</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1046" to="1074" />
		</imprint>
	</monogr>
	<note>AI magazine</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
