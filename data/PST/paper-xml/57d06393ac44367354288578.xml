<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Algorithm for Predicting the Intelligibility of Speech Masked by Modulated Noise Maskers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jesper</forename><surname>Jensen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<settlement>Aalborg</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Cees Taal is with Quby Labs</orgName>
								<orgName type="institution">Joan</orgName>
								<address>
									<addrLine>Muyskenweg 22, The Netherlands</addrLine>
									<postCode>1096 CJ</postCode>
									<settlement>Amsterdam</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Cees</forename><forename type="middle">H</forename><surname>Taal</surname></persName>
							<email>chtaal@gmail.com.</email>
							<affiliation key="aff0">
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<settlement>Aalborg</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Algorithm for Predicting the Intelligibility of Speech Masked by Modulated Noise Maskers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">13AC24B051A0DDCE79F5C860BB296A5D</idno>
					<idno type="DOI">10.1109/TASLP.2016.2585878</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2016.2585878, IEEE/ACM Transactions on Audio, Speech, and Language Processing This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TASLP.2016.2585878, IEEE/ACM Transactions on Audio, Speech, and Language Processing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Intelligibility listening tests are necessary during development and evaluation of speech processing algorithms, despite the fact that they are expensive and time-consuming. In this paper, we propose a monaural intelligibility prediction algorithm, which has the potential of replacing some of these listening tests. The proposed algorithm shows similarities to the Short-Time Objective Intelligibility (STOI) algorithm but works for a larger range of input signals. In contrast to STOI, Extended STOI (ESTOI) does not assume mutual independence between frequency bands. ESTOI also incorporates spectral correlation by comparing complete 400-ms length spectrograms of the noisy/processed speech and the clean speech signals. As a consequence, ESTOI is also able to accurately predict the intelligibility of speech contaminated by temporally highly modulated noise sources in addition to noisy signals processed with time-frequency weighting. We show that ESTOI can be interpreted in terms of an orthogonal decomposition of short-time spectrograms into intelligibility subspaces, i.e., a ranking of spectrogram features according to their importance to intelligibility. A free Matlab implementation of the algorithm is available for non-commercial use at http://kom.aau.dk/ ∼ jje/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>When developing speech communication systems for human receivers, listening tests play a major role both for monitoring progress in the development phase and for verifying the performance of the final system. Often, listening tests are used to quantify aspects of speech quality and speech intelligibility. Although listening tests constitute the only tool available for measuring ground-truth end-user impact, they are timeconsuming, they may require special auditory stimuli data and test equipment, and they require the availability of a group of typical end-users. For these reasons, listening tests are costly and can typically not be employed many times during the development phase of a speech communication system. Hence, cheaper alternatives or supplements are of interest.</p><p>In this paper, we focus on intrusive, monaural intelligibility prediction models, i.e., algorithms which -rather than conducting an actual listening test -predict the outcome of the listening test based on the auditory stimuli of the test. Historically, two lines of research serve as the foundation for existing intelligibility prediction models: i) the Articulation Index (AI) <ref type="bibr" target="#b0">[1]</ref> by French and Steinberg <ref type="bibr" target="#b1">[2]</ref>, which was later refined and standardized as the Speech Intelligibility Index (SII) <ref type="bibr" target="#b2">[3]</ref>, and ii) the Speech Transmission Index (STI) <ref type="bibr" target="#b3">[4]</ref> by Steeneken and Houtgast <ref type="bibr" target="#b4">[5]</ref>.</p><p>AI and SII were developed with simple linear signal degradations, e.g., additive noise, in mind. To estimate intelligibility, the methods divide the signal under analysis into frequency subbands and assume that each subband contributes independently to intelligibility. The contribution of a subband is found by estimating the long-term speech and noise power within the subband to arrive at the long-term subband signal-to-noise ratio (SNR). Then, subband SNRs are limited to the range from -15 to +15 dB, normalized to a value between 0 and 1, and combined as a perceptually weighted average. STI extends the range of distortions to include convolutive noise, e.g., reverberant speech and effects of room acoustics. STI is based on the observation that reverberation and/or additive noise tend to reduce the depth of temporal signal modulations compared to the clean, undistorted reference signal. To measure changes in the modulation transfer function, STI generates bandpass filtered noise probe signals at different center-frequencies, and amplitude-modulates each such signal at different modulation frequencies relevant to speech intelligibility. Each modulated probe signal is then passed through the communication channel in question (e.g. characterised by a room impulse response), and the reduction in modulation depth is finally translated into an intelligibility index.</p><p>Despite the importance of AI and SII, the methods have a number of limitations. First, they require the long-term spectrum of the additive noise signal to be known in advance. Secondly, since the methods rely on long-term statistics, they cannot discern modulated noise signals from un-modulated ones, when their long-term spectra are identical. In other words, the intelligibility of speech contaminated by modulated and un-modulated noise is judged to be identical, although it is well-known that this is generally not the case, e.g. <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. Finally, AI and SII are not directly applicable to signals which have been passed through some non-linear processing stage before presentation to the listener, because in this case it is no longer clear which noise spectrum to use.</p><p>Various methods have been proposed to reduce the limitations mentioned above and extend the range of acoustic situations for which intelligibility prediction can be made. In <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr">Rhebergen et. al.</ref> proposed the Extended SII (ESII), which avoids the use of long-term noise spectra in SII. Specifically, ESII divides the masker signal into short time frames (9-20 ms) and averages the SII computed for each frame individually, to predict intelligibility for fluctuating noise sources. In a somewhat similar manner, the Glimpse Model by Cooke <ref type="bibr" target="#b7">[8]</ref> uses realizations of speech and additive noise signals to estimate the glimpse percentage, i.e., the fraction of timefrequency tiles whose SNR exceeds a certain threshold, which is then translated to an intelligibility estimate. The Coherence SII (CSII) by Kates et. al. <ref type="bibr" target="#b8">[9]</ref> extends SII to better take into account various non-linear distortions, including center-and peak-clipping. Similarly, Goldsworthy et. al. <ref type="bibr" target="#b9">[10]</ref> proposed a modified STI approach, speech STI (sSTI), which replaces the traditional noise probe signals with actual speech signals. This was done to better take into account the effect of nonlinear distortions such as envelope clipping <ref type="bibr" target="#b10">[11]</ref>, and dynamic amplitude compression <ref type="bibr" target="#b11">[12]</ref>.</p><p>More recently, methods have emerged which are inspired by both original lines of research. For example, Jørgensen et. al. <ref type="bibr" target="#b12">[13]</ref> decompose the speech signal and an additive noise masker in a modulation filter bank. Intelligibility prediction is then based on the envelope power SNR at the output of this filter bank. Taal et. al. <ref type="bibr" target="#b13">[14]</ref> proposed the Short-Time Objective Intelligibility (STOI) measure, which extracts temporal envelopes of undistorted and noisy/processed speech signals in frequency subbands. The envelopes are then subject to a clipping procedure, compared using short-term linear correlation coefficients, and a final intelligibility prediction is constructed simply as an average of the correlation coefficients. STOI has proven to be able to predict quite accurately the intelligibility of speech in many acoustic situations, including the speech output of mobile phones <ref type="bibr" target="#b14">[15]</ref>, noisy speech processed by ideal timefrequency masking and single-channel speech enhancement algorithms <ref type="bibr" target="#b13">[14]</ref>, speech processed by cochlear implants <ref type="bibr" target="#b15">[16]</ref>, and STOI appears robust to different language types incl. Danish <ref type="bibr" target="#b13">[14]</ref>, Dutch <ref type="bibr" target="#b16">[17]</ref>, and Mandarin <ref type="bibr" target="#b17">[18]</ref>. Although STOI performs well in many cases, some of the algorithmic choices, e.g. the use of a linear correlation coefficient as a basic distance measure, are less well motivated from a theoretical point of view. However, in <ref type="bibr" target="#b16">[17]</ref> Jensen et. al. proposed the Speech Intelligibility prediction based on Mutual Information (SIMI) method, which suggests that characteristics of STOI may be explained using information theoretic arguments.</p><p>STOI, and several of the methods described above, show only weak links to the properties of the auditory system, and much more elaborate models have been proposed, e.g. <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. For example, the Hearing-Aid Speech Perception Index (HASPI) by Kates et. al. <ref type="bibr" target="#b19">[20]</ref> employs level-and hearingprofile dependent auditory filterbanks to compute quantities resembling mel-frequency cepstral coefficients (MFCCs) for the clean reference signal and the noisy/processed signal, respectively. Then, long-term correlations between clean and noisy/processed MFCCs are computed, before the average across the cepstral dimension is found. Finally, this cepstral correlation average is combined with estimates of the auditory signal coherence for low-, mid-, and high-intensity signal regions <ref type="bibr" target="#b8">[9]</ref>, to form an intelligibility index.</p><p>Existing intelligibility prediction methods may be divided into two classes: 1) methods which require that the target speech signal and the distorting component (e.g., the additive noise) are available in separation, e.g., <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b12">[13]</ref> and 2) methods which do not impose this requirement, e.g., <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b16">[17]</ref>. Class-1 methods have the advantage that they can use the access to speech and noise realizations to compute SNR realizations in different time-frequency regions and find an intelligibility index based on these. Class-2 methods, on the other hand, cannot observe SNRs directly, but must rely on features estimated from, generally, limited data, e.g., short-time correlations estimated from the noisy/processed and clean speech signal. The disadvantage of Class-1 methods is that they are not applicable to non-linearly processed noisy speech signals, because in this situation noise and speech signals are not readily available in separation. Class-2 methods are more generally applicable, i.e., also to noisy signals, which have been non-linearly processed.</p><p>As reported in <ref type="bibr" target="#b20">[21]</ref>, STOI -and as we show in Sec. IV -other Class-2 methods have limitations for target speech signals in additive noise sources with strong temporal modulations, as e.g. a single competing speaker. To demonstrate this point, Fig. <ref type="figure" target="#fig_4">1</ref> shows an example of intelligibility predicted by STOI vs. actual intelligibility, measured in listening tests with speech signals degraded by 10 highly modulated masker signals at different SNRs (details are given in Table <ref type="table">I</ref> and will be discussed later). Clearly, STOI performs less well in this situation: the linear correlation coefficient between predicted and measured intelligibility is as low as ρ = 0.47.</p><p>In this paper, we propose a new Class-2 intelligibility predictor -ESTOI (Extended Short-Time Objective Intelligibility) -which, unlike many existing Class-2 methods, works well for highly modulated noise sources as the example above   <ref type="bibr" target="#b13">[14]</ref>) for speech in ten different additive, modulated noise sources (6 SNRs each). Linear correlation coefficient between measured and predicted intelligibility is ρ = 0.47. For more information on noise sources, see Table <ref type="table">I</ref>. modulation frequencies relevant for speech intelligibility <ref type="bibr" target="#b13">[14]</ref>. To understand the differences between STOI and ESTOI, let us first interpret, how STOI computes a correlation coefficient for a 384 ms analysis window. STOI first computes linear correlation coefficients for each subband between undistorted and noisy/processed signals<ref type="foot" target="#foot_1">2</ref> ; this is equivalent to computing inner products between mean-and variance-normalized envelope signals. To find a correlation coefficient for the 384 ms analysis window, STOI then averages these temporal correlation coefficients across frequency, an operation which implies independent frequency band contributions to intelligibility, and which is not in line with literature, e.g., <ref type="bibr" target="#b21">[22]</ref>. ESTOI shares the first step with STOI: mean-and variance-normalization is applied to subband envelopes. However, rather than computing the average inner products between these normalized envelopes, and relying on the additive-intelligibility-across-frequency assumption as is done in STOI, ESTOI instead computes spectral correlation coefficients, which are finally averaged across time within the 384 ms analysis segment. This allows ESTOI to better capture the effect of time-modulated noise maskers, where spectral correlation 'in the dips' is often preserved <ref type="bibr" target="#b22">[23]</ref>. We show that ESTOI may be interpreted in terms of an orthogonal decomposition of energy-normalized spectrograms, i.e., a decomposition into "intelligibility subspaces" which are each ranked according to their (estimated) contribution to intelligiblity. This decomposition is important in understanding ESTOI and in linking its performance to perceptual studies with human listeners. Specifically, analysis of the spectrograms related to each intelligibility subspace shows that the spectro-temporal modulation frequencies, which are judged by ESTOI to be important for speech intelligibility, agree with the results of experimental studies of human sensitivity to spectrotemporal modulations <ref type="bibr" target="#b23">[24]</ref>.</p><p>The paper is structured as follows. In Sec. II we describe the ESTOI predictor. In Sec. III we interpret the predictor in terms of orthogonal intelligibility subspaces. Sec. IV evaluates the performance of ESTOI, and compares it to a range of existing algorithms. Finally, Sec. V concludes the work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED MODEL</head><p>The overall structure of the proposed intelligibility predictor, ESTOI, is outlined in Fig. <ref type="figure">2</ref>. ESTOI is a function of the noisy/processed signal under study x(n), and the clean, undistorted speech signal s(n). The goal of ESTOI is to produce a scalar output d, which is monotonically related to the intelligibility of x(n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Time-Frequency Normalized Spectrograms</head><p>Let us assume that s(n) and x(n) are perfectly timealigned, and that regions where s(n) shows no speech activity (e.g., pauses between sentences) have been removed from both signals. In the following, we present expressions related to the clean signal s(n); similar expressions hold for the noisy/processed signal x(n). Let S(k, m) denote the shorttime Fourier transform (STFT) of s(n), that is</p><formula xml:id="formula_0">S(k, m) = N ′ -1 n=0 s(mD + n)w(n)e -j2πkn/N ′ ,</formula><p>where k and m denote the frequency bin index and the frame index, respectively, and D and N ′ denote the the frame shift in samples and FFT order, respectively. Finally, w(n) is an analysis window.</p><p>To model crudely the signal transduction in the cochlear inner hair cells, a one-third octave band analysis is approximated by summing STFT coefficient energies,</p><formula xml:id="formula_1">S j (m) = k∈CBj |S(k, m)| 2 , j = 1, . . . , J,</formula><p>where j is the one-third octave band index, CB j denotes the index set of STFT coefficients related to the jth one-third octave frequency band, and J denotes the number of subbands. Let us collect spectral values S j (m) for each frequency band j = 1, . . . , J, and across a time segment of N spectral samples, and arrange these in a short-time spectrogram matrix</p><formula xml:id="formula_2">S m =    S 1 (m -N + 1) • • • S 1 (m) . . . . . . S J (m -N + 1) • • • S J (m)    .</formula><p>Hence, the jth row of S m represents the temporal envelope of the signal in subband j. Typical parameter choices are J = 15 and N = 30 (corresponding to 384 ms) <ref type="bibr" target="#b13">[14]</ref>. The noisy/processed short-time spectrogram matrix X m is defined analogously.</p><p>ESTOI operates on mean-and variance-normalized rows and columns of S m (and X m ) as follows. Let</p><formula xml:id="formula_3">s j,m = [S j (m -N + 1) S j (m -N + 2) • • • S j (m)] T</formula><p>denote the jth row of the spectrogram matrix S m . The jth mean-and variance-normalized row of S m is given by</p><formula xml:id="formula_4">sj,m = 1 (s j,m -µ sj,m ) s j,m -µ sj,m 1 ,<label>(1)</label></formula><p>where y = y T y is the vector 2-norm, 1 is an all-one vector, and µ sj,m is the sample mean given by Note that the sample mean and variance of the elements in vector sj,m is zero and one, respectively. The mean and variance-normalized rows xj,m of the noisy/processed signal are defined similarly. As mentioned, this row-normalization procedure is similar to the one used in STOI. Specifically, STOI uses an intermediate temporal correlation coefficient for the jth subband in the mth time segment, which can be expressed as the inner product of normalized vectors,</p><formula xml:id="formula_5">µ sj,m = 1 N N -1 m ′ =0 S j (m -m ′ ).<label>(2)</label></formula><formula xml:id="formula_6">sT j,m xj,m .<label>(3)</label></formula><p>However, as mentioned, in ESTOI we do not use Eq. ( <ref type="formula" target="#formula_6">3</ref>) directly, but introduce a spectral normalization as follows. Let us first define the row-normalized spectrogram matrix</p><formula xml:id="formula_7">Sm =    sT 1,m . . . sT J,m    .</formula><p>Then, let šn,m denote the mean-and variance-normalized nth column, n = 1, . . . , N of matrix Sm , where the normalization is carried out analogously to Eqs. ( <ref type="formula" target="#formula_4">1</ref>) and ( <ref type="formula" target="#formula_5">2</ref>). We finally define the row-and column-normalized matrix Šm as</p><formula xml:id="formula_8">Šm = [š 1,m • • • šN,m ] .</formula><p>Hence, the columns of Šm represent unit-norm, zero-mean normalized spectra (which themselves are computed from normalized temporal envelopes). The row-and columnnormalized matrix Xm of the noisy/processed signal in time segment m is defined in a similar manner. Fig. <ref type="figure" target="#fig_0">3</ref> demonstrates the effect of the various normalizations on example clean and noisy spectrograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Intelligibility index</head><p>The row-and column-normalized matrices Šm and Xm serve as the basis for the proposed intelligibility predictor. In particular, we define an intermediate intelligibility index, related to time segment m, simply as</p><formula xml:id="formula_9">d m = 1 N N n=1 šT n,m xn,m .<label>(4)</label></formula><p>Since šn,m and xn,m , n = 1, . . . , N are unit-norm vectors, each term in the sum may be recognized as the (signed) length of the orthogonal projection of the noisy/processed vector xn,m onto the clean vector šn,m or vice versa. It follows that -1 ≤ šT n,m xn,m ≤ 1. Similarly, d m may be interpreted as the (signed) length of these projections, averaged across time within a time segment. In low-noise situations where xn,m ≈ šn,m , then d m will be close to its maximum average projection length of 1, whereas if the elements of xn,m and šn,m are uncorrelated, then d m ≈ 0, i.e., the vectors are approximately orthogonal. Also, from the definitions of šn,m and xn,m , d m may be interpreted simply as sample correlation coefficients of the columns of Sm and Xm (i.e., spectra which have been normalized according to their subband envelopes), averaged across the N frames within a segment.</p><p>For simplicity, the intelligibility index related to the entire noisy/processed signal of interest is then defined as the temporal average of the intermediate intelligibility indices,</p><formula xml:id="formula_10">d = 1 M M m=1 d m ,<label>(5)</label></formula><p>where M is the number of time segments in the signal of</p><formula xml:id="formula_11">interest. Since -1 ≤ d m ≤ 1, it follows that -1 ≤ d ≤ 1.</formula><p>C. Implementation ESTOI operates at a sampling frequency of 10 kHz to ensure that the frequency region relevant for speech intelligibility is covered <ref type="bibr" target="#b1">[2]</ref>; all signals are resampled to this frequency before applying the method. Then, signals are divided into frames of 256 samples, using a frame shift of D = 128, the frames are windowed with a Hann window, and an FFT of order N ′ = 512 is applied. Before computing the intelligibility index, frames with no speech content are discarded. These are identified as the frames of the reference speech signal s(n) with energy less than 40 dB than the signal frame with maximum energy. DFT coefficients of speech active frames are grouped into J = 15 one-third octave bands, with center frequencies of 150 Hz and approximately 4.3 kHz, for the lowest and highest band, respectively. Finally, time segments of length N = 30 (corresponding to 384 ms) are used (for further details on this choice, we refer to Sec. IV-C). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ORTHOGONAL INTELLIGIBILITY SUBSPACES</head><p>In this section we present interpretations of Eqs. ( <ref type="formula" target="#formula_9">4</ref>) and ( <ref type="formula" target="#formula_10">5</ref>) which provide insights into ESTOI. Specifically, we show that ESTOI can be interpreted in terms of a decomposition of (row-and column-normalized) noisy/processed short-time spectrograms into orthogonal one-dimensional subspaces. The decomposition assigns an intelligibility score to each such subspace, so that the sum of all the subspace intelligibilities equals the total intermediate intelligibility d m of the noisy/processed short-time spectrogram. The decomposition therefore allows us to rank each subspace according to their (predicted) contribution to intelligibility, revealing which spectro-temporal features are predicted to be important to intelligibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preliminaries</head><p>To focus our exposition, we re-write the expression for d m (Eq. ( <ref type="formula" target="#formula_9">4</ref>)) using the columns of the row-and columnnormalized matrices Xm and Šm . Let us concatenate the N columns of Šm into a supervector</p><formula xml:id="formula_12">šm = šT 1,m . . . šT N,m T ,</formula><p>where šm ∈ ℜ N J×1 . A similar definition holds for the noisy/processed supervector xm . Furthermore, let us collect supervectors for each segment m as columns in super matrices. The clean speech super matrix Š ∈ ℜ N J×M is given by Š = š1 , . . . , šM .</p><p>The noisy/processed matrix X is defined similarly. The intermediate intelligibility index d m (Eq. ( <ref type="formula" target="#formula_9">4</ref>)) may then be written as</p><formula xml:id="formula_13">d m = 1 N šT m xm ,<label>(6)</label></formula><p>and inserting this into Eq. ( <ref type="formula" target="#formula_10">5</ref>) leads to</p><formula xml:id="formula_14">d = 1 M N Tr ŠT X ,<label>(7)</label></formula><p>where </p><p>where e T i e j = δ(i, j) are orthonormal vectors, and P l = e l e T l is an orthogonal projection matrix onto the one-dimensional subspace spanned by e l . Since each noisy/processed supervector xm describes a time-frequency region of N × J one-third octave spectral values, Eq. ( <ref type="formula" target="#formula_15">8</ref>) provides -when the basis vectors e l are specified -a decomposition of a noisy/processed time-frequency region into mutually orthogonal one-dimensional subspaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Intelligibility Subspace Decomposition</head><p>Our goal is to determine the orthogonal basis vectors e l in Eq. ( <ref type="formula" target="#formula_15">8</ref>), ordered according to their (estimated) impact on intelligibility: first, we find the basis vector e 1 , which carries most intelligibility on average across noisy/processed spectrograms. Next, we find the basis vector e 2 , orthogonal to e 1 , which carries most intelligibility. This procedure is repeated for the remaining dimensions , leading to an orthogonal subspace decomposition in terms of intelligibility.</p><p>To do this, insert Eq. ( <ref type="formula" target="#formula_15">8</ref>) into Eq. ( <ref type="formula" target="#formula_14">7</ref>),</p><formula xml:id="formula_16">d = 1 N M Tr ŠT X = 1 2N M Tr ŠT X + XT Š = 1 2N M Tr ŠT l P l X + XT ( l P l ) T Š = 1 2N M Tr ( X ŠT + Š XT ) l P l = 1 2N M N J l=1 e T l ( X ŠT + Š XT )e l ,<label>(9)</label></formula><p>where we used that Tr A = Tr A T , that summation and trace are linear operators whose order can be interchanged, that l P l = ( l P l ) T is a symmetric matrix by definition, and that Tr ABC = Tr CAB = Tr BCA.</p><p>We can now perform the orthogonal intelligibility subspace decomposition described above by solving the following sequence of problems,</p><p>Step 1:</p><formula xml:id="formula_17">max e1 1 2N M e T 1 ( X ŠT + Š XT )e 1 , such that e T 1 e 1 = 1.</formula><p>Steps (l = 2, . . . , N J):</p><formula xml:id="formula_18">max e l 1 2N M e T l ( X ŠT + Š XT )e l such that e T l e l = 1,</formula><p>and e l ⊥ e 1 , . . . , e l-1 .</p><p>It may be recognized that the solution vectors e l are the eigenvectors of the symmetric matrix 1 2N M X ŠT + Š XT . The symmetry of this matrix ensures that a) the eigenvectors are mutually orthogonal, and b) the eigenvalues are realvalued, which allows a simple ranking of subspaces according to their contribution to intelligibility.</p><p>Note that inserting Eq. ( <ref type="formula" target="#formula_15">8</ref>) with the found vectors e l in Eq. ( <ref type="formula" target="#formula_13">6</ref>) allows us to express the intermediate intelligibility index d m in terms of a sum of orthogonal intelligibility subspaces. Note also that since the lth eigenvalue λ l of the matrix</p><formula xml:id="formula_19">1 2N M X ŠT + Š XT satisfies 1 2N M ( X ŠT + Š XT )e l = λ l e l ,</formula><p>then it follows that</p><formula xml:id="formula_20">λ l = 1 2N M e T l ( X ŠT + Š XT )e l .</formula><p>Comparison to Eq. <ref type="bibr" target="#b8">(9)</ref> shows that</p><formula xml:id="formula_21">d = N J l=1 λ l .</formula><p>In other words, the total estimated intelligibility of the signal in question is completely determined by the eigenvalues of the sample cross-correlation matrix 1 2N M ( X ŠT + Š XT ). Specifically, the contribution to intelligibility by the lth subspace is given by the corresponding eigenvalue λ l , and the sum of all eigenvalues equals the total intelligibility index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Intelligibility Subspaces -Example</head><p>To demonstrate the intelligibility subspace decomposition we construct noisy (but in this example unprocessed) speech signals by adding noise to clean speech signals. Specifically, we study the impact of adding a 100 % intensity-modulated, lowpass filtered noise sequence to 1680 signals from the TIMIT <ref type="bibr" target="#b24">[25]</ref> data base. The noise is a Gaussian white noise sequence (sampling rate of f s = 16000 Hz), filtered through a first-order IIR low-pass filter with a 3dB cut-off frequency at approximately 80 Hz (pole location at p = 0.97). Then, this lowpass filtered noise is amplitude modulated by the sequence</p><formula xml:id="formula_22">a(n) = 1 + sin(2πf mod /f s n + φ), n = 0, . . . , N s ,</formula><p>with a modulation frequency of f mod = 5 Hz, N s is the sequence length corresponding to the duration of the speech signal in question, and φ is a uniformly distributed random phase value, drawn independently for each sentence. The noise is scaled to form an SNR of -10 dB for each sentence.</p><p>Based on this set of noisy signals, we apply the intelligibility subspace decomposition described above. Fig. <ref type="figure" target="#fig_3">4</ref> (lower-right) shows the N J = 450 eigenvalues λ l in descending order for the decomposition of d. In this example, the 11 dominant subspaces carry 46% of the total estimated intelligibility, while 115 dimensions carry 90%. Fig. <ref type="figure" target="#fig_3">4</ref> shows the basis vectors of the 11 dominant subspaces. The subspaces are characterized by regular spectro-temporal patterns, apparently with low spectrotemporal modulation frequencies.</p><p>Frequency analysis across the temporal dimension of each of the subfigures reveal temporal modulation frequenciesaveraged across the acoustic frequency axis -ranging from 2.1 Hz to 5.8 Hz. This modulation frequency range is well-known to be particularly important for intelligibility. Specifically, Drullman et. al. showed that intelligibility can be degraded significantly, if modulations in the frequency range of approximately 3-8 Hz are not preserved <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Similarly, Elliot and Theunissen found temporal modulation frequencies in the range 1-7 Hz to be most important for speech intelligibility <ref type="bibr" target="#b23">[24]</ref>, while Kates and Arehart found frequencies less than 12.5 Hz to carry most information about intelligibility <ref type="bibr" target="#b27">[28]</ref>.</p><p>Applying Fourier transforms to the columns of each subspace spectrogram in Fig. <ref type="figure" target="#fig_3">4</ref> and computing the average magnitude spectrum shows maximum spectral modulations in the range 0.2-0.7 cycles/kHz. As for the temporal modulation content, these numbers are quantitatively well in line with the results in <ref type="bibr" target="#b23">[24]</ref> who report spectral modulation frequencies &lt; 1 cycle/kHz to be most important for speech intelligibility <ref type="foot" target="#foot_2">3</ref> .</p><p>While the eigenvalues λ l of the sample correlation matrix 1 2N M ( X ŠT + Š XT ) tend to be positive, a small subset of the lowest eigenvalues can be negative. In other words, the signal components represented by the corresponding subspaces degrade intelligibility as estimated by the model. For many practical situations, however, the impact of these negative intelligibility subspaces is small. For example, in Fig. <ref type="figure" target="#fig_3">4</ref>, where the global SNR is -10 dB, the 15 smallest eigenvalues are negative -their sum is approximately -0.001, which is 0.3% of the total estimated intelligibility index. Generally speaking, the number and the impact of these negative intelligibility subspaces increases with decreasing SNR. For simple additive and stationary noise maskers, e.g., a single constant-frequency masker tone which occupy the same time-frequency region for all time segments, it can be verified that the time-frequency pattern of this masker may be represented well using the negative subspaces as basis functions. For non-stationary noise sources, on the other hand, e.g., the modulated low-pass noise used in Fig. <ref type="figure" target="#fig_3">4</ref>, the negative subspaces do, generally, not represent the spectro-temporal noise pattern in a particular segment. Rather, the negative subspaces represent the average spectro-temporal pattern of the noise within many time segments, across which the noise does not necessarily occupy the same time-frequency region in each time segment. Finally, Fig. <ref type="figure" target="#fig_5">5</ref> shows the intelligibility subspace decomposition for speech in natural noise, namely a noise recorded in a busy office cafeteria <ref type="bibr" target="#b28">[29]</ref>. While details obviously differ from the decomposition in Fig. <ref type="figure" target="#fig_3">4</ref>, the main features of the dominant subspaces are the same: temporal modulation frequencies are in the range 2.0-5.7 Hz, while spectral modulations are in the range 0.2-0.8 cycles/kHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SIMULATION RESULTS</head><p>In this section, we present a number of intelligibility listening tests for evaluating the proposed method. Furthermore, we study the performance as a function of the segment length N and the test signal duration. Finally, we compare the performance of ESTOI to a range of existing speech intelligibility predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Signals and Processing Conditions</head><p>We study the performance of ESTOI using the results of five intelligibility tests with speech signals subjected to various noise sources and processing conditions. The first two tests used various additive noise sources with strong temporal modulations; we include these in the study to verify the ability of ESTOI to operate in this domain, and to verify the results reported in <ref type="bibr" target="#b20">[21]</ref> that established intelligibility predictors work less well here. The third test used stationary and non-stationary additive noise sources, with less temporal modulations; quite some existing methods work well for this common class of noise sources, and it is important to establish that ESTOI does so too. The fourth and fifth intelligibility test used processed noisy speech signals for which STOI works exceptionally well, while many other methods fail. As before, it is important to establish the performance of ESTOI in this situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Additive Noise Set I:</head><p>The first set of signals consist of ten mainly non-stationary noise sources with significant modulation content, cf. Table <ref type="table">I</ref> where ω denotes the angular modulation frequency, and φ ∈ [-π; π[ is a random phase-value, drawn independently for each signal generation. To construct machine gun noise macgun with sufficient masking power, the original machine gun noise signal from the Noisex database <ref type="bibr" target="#b30">[31]</ref> was divided into succesive 20 ms frames, and frames with energy less than 40 dB of the maximum frame energy were removed.</p><p>Speech signals from the Dantale II sentence test <ref type="bibr" target="#b31">[32]</ref> were added to randomly selected sections of each of the ten noise sources at six different SNRs (cf. Table <ref type="table">I</ref>). The SNRs were chosen so that, for each noise source, some noisy signals were almost perfectly intelligible, whereas others were essentially unintelligible. The total number of conditions was therefore 10 noise types x 6 SNRs = 60 conditions. Each condition was repeated 3 times (with different speech and noise realizations) leading to a total of 180 sentences to be judged per subject. The presentation order of noise types, SNRs, and repetitions was randomized. The sample rate was 20 kHz.</p><p>We conducted a closed Danish speech-in-noise intelligibility test, cf. <ref type="bibr" target="#b32">[33]</ref>. The Dantale II sentences consist of five words with a correct grammatical structure. Candidate words were arranged in an 10-by-5 matrix on a computer screen, such that each of the five columns encompassed exactly the 10 possible alternatives for the corresponding word. Each column was extended with one entry, which allowed the subject to answer "Don't know". For each 5-word sentence, the subject must select via a graphical user interface the words that she heard. Subjects were seated in a sound treated room, where signals were presented diotically through headphones (Sennheiser HD 280 Pro). The icra1 noise at the SNR of -8 dB was used to calibrate the presentation level to 65 dB (A). The subjects were allowed to adjust this level during a training session prior to the actual test. Twelve native Danish speaking subjects (normal-hearing, age range 26-44 years, 2 females, 10 males) participated in the test. The subjects volunteered for the experiments and were not paid for their participation.</p><p>2) Additive Noise Set II: The second data set, consisting of speech in additive fluctuating noise sources, is described in <ref type="bibr" target="#b6">[7]</ref>. We use Maskers 1-13 <ref type="bibr" target="#b6">[7]</ref>, which include low-pass filtered unmodulated Gaussian noise, and various amplitude modulated Gaussian noise signals, including sinusoidally amplitudemodulated signals (modulation frequencies: 2.1, 4.9, 10.2, 19.9 Hz, and modulation depths of ± 6 dB, ± 12 dB, and ± 100%), and three irregularly modulated noise signals found by adding the sinus-modulators with random initial phases. The speech material used was the Swedish version of the Hagerman material <ref type="bibr" target="#b33">[34]</ref>, which is similar in structure to the Dantale 2 set used above. For each noise source, noisy speech signals were generated with an SNR of -15 dB, and the corresponding speech intelligibility was recorded ( [7, Fig. <ref type="figure" target="#fig_5">5]</ref>). Hence, the number of conditions equalled 11 noise sources x 1 SNR = 11 conditions. Intelligibility tests were conducted with i) eleven young (17-33 years), normal hearing listeners, and ii) twenty elderly (54-69 years), normal hearing listeners (the study also included elderly, hearing-impaired listeners, but results of these tests are not used in this paper). The sample rate used was 20 kHz. For more details, we refer to <ref type="bibr" target="#b6">[7]</ref>.</p><p>3) Additive Noise Set III: We include a third additive noise set, for which many existing intelligibility predictors work well, see e.g. <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b16">[17]</ref> and the references therein. The data set encompasses Dantale 2 speech sentences contaminated by four additive noise sources: i) speech-shaped Gaussian noise, ii) car cabin noise recorded when driving on the highway, iii) bottling hall noise, and iv) cafeteria noise consisting of a conversation between a female and a male speaker, i.e., twotalker speech babble <ref type="bibr" target="#b34">[35]</ref>. The noisy signals were generated with SNRs from -20 dB to 5 dB in steps of 2.5 dB, so the total number of conditions equals 4 noise types x 11 SNRs </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise Name Description SNR [dB] icra1</head><p>Unmodulated speech-shaped (male) Gaussian noise from the ICRA corpus (Track 1) <ref type="bibr" target="#b29">[30]</ref>.</p><p>-17:3:-2. = 44 conditions. Fifteen listeners participated in the test. For more details, we refer to <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Ideal Time-Frequency Segregation:</head><p>The fourth data set consists of the noisy signals from Additive Noise Set III, processed using the ideal time-frequency segregation (ITFS) technique <ref type="bibr" target="#b35">[36]</ref>. Kjems <ref type="bibr" target="#b34">[35]</ref> processed noisy signals with two different ITFS algorithms called ideal binary mask (IBM) and target binary mask (TBM), and used eight different variants of each algorithm (reflected by the LC parameter, i.e., the threshold for which the algorithm suppresses a given timefrequency tile or not). Three different SNRs were used, leading to a total number of (4 noise types (IBM) + 3 noise types (TBM)<ref type="foot" target="#foot_3">4</ref> ) x 8 LC x 3 SNRs = 168 test conditions. Fifteen normal hearing subjects participated in the test. The sample rate was 20 kHz. More details are available in <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Single-Channel Noise Reduction:</head><p>The last data set consists of noisy speech signals processed with three singlemicrophone noise reduction algorithms <ref type="bibr" target="#b36">[37]</ref>. The three algorithms are all non-linear and aim at finding binary or soft minimum mean-square error (MMSE) estimates of the shorttime spectral amplitude (STSA). We include this data set, </p><note type="other">Intelligibility Subspace 1</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Prediction of Absolute Intelligibility and Figures of Merit</head><p>Most intelligibility prediction methods (including ESTOI) do not predict intelligibility, i.e., the fraction of words understood, per se. Instead, they output a scalar Ĩ which, ideally, is monotonically related to absolute intelligibility I 5 . The monotonic mapping between predictor output and absolute 5 We use the symbol Ĩ to represent the output of any intelligibility predictor (including ESTOI), while we reserve the symbol d for the particular scalar output produced by ESTOI.</p><p>intelligibility is generally hard to derive analytically, but in <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b37">[38]</ref> it was proposed to use the following logistic map,</p><formula xml:id="formula_23">Î = 100 1 + exp a Ĩ + b , (<label>10</label></formula><formula xml:id="formula_24">)</formula><p>where a, b ∈ ℜ are constants that depend on the test material, test paradigm, etc., and which are estimated to fit the intelligibility data at hand. To quantify the performance of intelligibility predictors, we use four figures of merit (see <ref type="bibr" target="#b16">[17]</ref> for exact definitions): i) the linear correlation coefficent ρ pre between average intelligibility scores obtained in listening tests, and the outcomes Ĩ of the intelligibility predictors before applying the logistic map (Eq. ( <ref type="formula" target="#formula_23">10</ref>)), ii) the linear correlation coefficient ρ between average intelligibility scores and the outcomes Î of the intelligibility predictors, i.e., after the logistic map, iii) the root meansquare prediction error σ between measured and predicted intelligibility, and iv) Kendalls rank correlation coefficient (τ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Impact of Segment Length and Signal Duration</head><p>1) Sensitivity to segment length N : ESTOI was developed with simplicity in mind and has few free parameters. This section studies the performance of ESTOI as a function of the segment length N for the various noise/processing situations in the five data sets described above. In particular, for a given data set, and for a given choice of the segment length N , the proposed method was applied to compute an intelligibility index for each test condition in that data set. Then, the free parameters a, b, of the logistic function, Eq. ( <ref type="formula" target="#formula_23">10</ref>), were fitted to map the predicted intelligibility indices to absolute intelligibility as measured in a listening test. Finally, the performance in terms of ρ, σ, and τ was computed.</p><p>Fig. <ref type="figure" target="#fig_6">6</ref> shows the performance in terms of ρ as a function of segment length N (in the range N = 5, . . . , 60 corresponding to durations of 64 -768 ms). Clearly, the proposed method is fairly insensitive to the exact choice of the segment length N . In fact, for 20 ≤ N ≤ 50 (corresponding to durations of 256-640 ms), the proposed method gives excellent performance with values of ρ &gt; 0.9. The lower performance for N &lt; 20 may be explained by the fact that with these short segment lengths, the method is less able to capture low-frequency temporal modulations, which are important for speech intelligibility <ref type="bibr" target="#b13">[14]</ref>. While the discussion above focused on prediction performance in terms of ρ, similar conclusions may be drawn from performance analysis based on σ and τ (not shown). Based on these observations, a value of N = 30 (384 ms) is used in the remainder of the simulation experiments. 2) Sensitivity to duration of test signals: For highly modulated, additive noise sources, the instantaneous SNR can vary significantly across a short time span. For example, a sinusoidally amplitude-modulated noise source could completely mask the target signal at one instant, while leaving it essentially un-masked half a period later (cf. Fig. <ref type="figure" target="#fig_0">3</ref>). Hence, the speech intelligibility for a particular short speech signal is highly dependent on the (random) location of the high SNR region with respect to the speech signal. Since our goal is to estimate the average speech intelligibility, we would therefore expect it to be necessary to average across many noise realizations, or, equivalently, to use longer test speech signals, than would e.g. be necessary for unmodulated noise sources. In this section we therefore study the sensitivity of the proposed method with respect to test signal duration t sig .</p><p>To do so, we generated speech signals contaminated by two additive noise sources: speech-shaped stationary noise, and synthetic 1-person babble (the icra4 noise source from <ref type="bibr" target="#b29">[30]</ref>). The noise sources were scaled to achieve SNRs of -10 dB and -23 dB, respectively, corresponding approximately to the 50% speech reception threshold (SRT) (the SNR needed to achieve a recognition rate of 50%) for these noise sources. Noise and clean signals were generated in corresponding pairs with various durations in the range 1 --80 secs. Noisy signals were generated by adding the clean and noise signals.</p><p>Clean and noisy signals were then passed through ESTOI. For comparison, the clean and noise signals were passed through the Extended Speech Intelligibility Index (ESII) algorithm <ref type="bibr" target="#b2">[3]</ref> (see Sec. IV-D for implementational details). For each signal duration, n real = 100 different realizations of the clean/noisy signal pairs were evaluated.</p><p>It is of interest to study to which extent an intelligibility prediction Ĩn (t sig ) based on a single (the nth) test signal realization of duration t sig lies in the neighborhood of the ensemble-average, i.e., the average predictor value µ Ĩ(tsig ) = 1 n real n Ĩn (t sig ) across many realizations n real of test signal pairs. To do so, let us define the sample standard deviation</p><formula xml:id="formula_25">σ Ĩ(tsig ) = 1 n real n Ĩn (t sig ) -µ Ĩ(tsig ) 2 ,</formula><p>and let us define the relative standard deviation as</p><formula xml:id="formula_26">ǫ(t sig ) = σ Ĩ(tsig ) /µ Ĩ(tsig) × 100 [%].</formula><p>Figs. 7a) shows ǫ(t sig ) for ESII and ESTOI for unmodulated speech-shaped noise, while Fig. <ref type="figure" target="#fig_7">7b</ref>) shows the results for babble noise. From Fig. <ref type="figure" target="#fig_7">7</ref> three conclusions can be drawn. First, as expected, the relative standard deviation declines with signal duration. Secondly, for a given test signal duration, ESII has lower relative standard deviation than ESTOI. This is because ESII makes explicit use of its access to the clean speech signal and the noise signal in separation to accurately compute SNRs in different time-frequency regions, and subsequently compute an intelligibility index based on these (i.e,. ESII is a Class-1 method as discussed in the Introduction). ESTOI, on the other hand, does not make use of the access to the separated clean and noise components and is therefore more generally applicable, e.g., to non-linearly processed signals (i.e., it is a Class-2 method). This generality comes with the price of an increase in the estimation standard deviation. Thirdly, as expected, for a given test signal duration, the estimation standard deviation is higher for modulated than for non-modulated noise, both for ESII and ESTOI.</p><p>It is hard to decide a priori on a sufficient test signal duration, because a) this depends on the noise signal statistics in a non-trivial manner, and b) the noise statistics are unavailable to the proposed method. Hence, the test signal duration should simply be chosen as long as practically possible, and generally no less than some tens of seconds. Note that long test signals can be generated by concatenating several of the, potentially short, speech sentences used in the intelligibility test. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison to Existing Methods</head><p>We compare the proposed intelligibility prediction method to reference methods from the literature. The methods are outlined in Table <ref type="table">II</ref>. The methods CSII-BIF and STI-NCM-BIF are referred to as CSII mid , W 4 , p = 1 and NCM, W</p><p>i , p = 1.5, respectively, in <ref type="bibr" target="#b38">[39,</ref><ref type="bibr">Table IV]</ref>. We implemented the GLIMPSE method <ref type="bibr" target="#b7">[8]</ref> using the one-third-octave filter bank used in ESTOI. The speech glimpse percentage was defined here as the percentage of time-frequency units with a local SNR exceeding -8 dB (this threshold was chosen because it lead to best performance in terms of ρ, σ, and τ ). Our implementation of the ESII algorithm computes the per-frame SII based on one-third octave filtering, and outputs the average of the perframe SIIs. The implementation uses stationary speech-shaped Gaussian noise instead of undistorted real speech signals as input (as specified in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b5">[6]</ref>), but excludes the upward-spreadof-masking functionality as defined in <ref type="bibr" target="#b2">[3]</ref>, because this appears to degrade performance. As in <ref type="bibr" target="#b5">[6]</ref>, we use the band importance functions derived for the test stimuli of the Speech in the Presence of Noise (SPIN) test ( [3, Table <ref type="table">B</ref>.1]) and <ref type="bibr" target="#b39">[40]</ref>.</p><p>Tables III-VI summarize performance in terms of ρ pre , ρ, σ, and τ , respectively, for the intelligibility predictors for the various additive noise and processing conditions. The ρ, σ, and τ , values are found by fitting a, b to the data sets in question. To identify statistically significant differences between ρ-values (Table <ref type="table" target="#tab_6">IV</ref>), pairwise comparisons using the Williams t-test <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b42">[43]</ref> were performed within each data set between the predictor with the largest ρ and the others (Bonferroni correction for multiple comparisons). Methods which do not perform statistically significantly worse than the method with highest ρ (p &lt; 0.05) are indicated with (*) in Table <ref type="table" target="#tab_6">IV</ref>. In addition, a statistical analysis of significance was applied to the root mean-square prediction errors σ (Table <ref type="table" target="#tab_7">V</ref>) as follows (see <ref type="bibr" target="#b43">[44]</ref> for a brief outline of this approach). For each prediction method and for each of the five listening tests, the free parameters a, b in the logistic function were fitted to n -1 data points, where n denotes the number of conditions for a specific data set. Then this logistic function was applied to the left-out data point Ĩi , where i is the index of the left-out data point, to find a prediction Îi of the left-out subject result I i . The procedure was repeated for all data points, resulting in prediction errors e i = I i -Îi , i = 1, • • • , n. Our goal is to compare the magnitude of these prediction errors across prediction methods. The data e 2 i for each intelligibility predictor and for each data set did not pass a chi-square goodnes-offit test for normality (p &lt; 0.05). Hence, a Kruskal-Wallis test was performed, rejecting for each data set the hypothesis that the median of e 2 i is identical for all prediction methods (p &lt; 10 -5 ). A multiple pairwise comparison test (Tukey HSD) was applied to identify prediction methods which, for a particular data set, performed statistically significantly worse than the method with lowest σ (p &lt; 0.05). The result of this comparison is indicated with (*) in Table <ref type="table" target="#tab_7">V</ref>.</p><p>From these tables, a number of observations can be made. First, focusing on the highly non-stationary noise conditions, i.e., Additive Data Sets I and II, it is clear that ESTOI, GLIMPSE, and ESII appear to work quite well. The fact that GLIMPSE and ESII can work well in these conditions is well in line with results reported in <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b5">[6]</ref>, respectively. On the other hand, existing methods such as STOI and SIMI, which are known to work well for other less non-stationary noise sources and for various processing conditions, do not work well for the highly fluctuating noise sources: SIMI shows correlation values ρ ≈ 0, while STOI shows large but negative correlations for these data sets in Table <ref type="table" target="#tab_5">III</ref>. This indicates that the STOI output Ĩ decreases for increasing measured intelligibility (the fact that the same entry in Table <ref type="table" target="#tab_6">IV</ref> is positive is because the logistic map from Ĩ to Î in this situation maps low Î values to high Ĩ values, and vice versa).</p><p>It is interesting to note that ESTOI (and ESII and GLIMPSE), perform well for Additive Noise II, both for young and for elderly normal-hearing subjects. While the basic intelligibility predictors are unchanged, each intelligibility predictor employs a different logistic map (i.e., constants a and b in Eq. ( <ref type="formula" target="#formula_23">10</ref>)) for the different subject groups, because the 30% speech reception threshold was 6 dB higher for the elderly compared to the young subjects. It appears that the SRT differences between these normal-hearing subject groups (e.g., differences in higher auditory stages, which are not captured by a standard listening test used to establish whether a subject is normal hearing or not) are well-modeled simply by changing the logistic map.</p><p>Secondly, for the less fluctuating (but still non-stationary) noise sources in Additive Noise Set III, most methods work well. In fact, for this data set, several intelligibility predictors, including ESTOI, show values of ρ &gt; 0.95, and σ values at or below 10%. Note that SII, which relies on long-term noise spectra, also works well in this situation.</p><p>For noisy signals processed with ideal time-frequency segregation and single-channel noise reduction, ESTOI, SIMI, and STOI work well with ρ &gt; 0.94. It is interesting to note that for single-channel noise reduced signals, STI-NCM-BIF works exceptionally well (ρ &gt; 0.97): an explanation is that STI-NCM-BIF was developed with this particular processing type in mind; also note that STI-NCM-BIF does not show this level of performance for any other noise/processing condition.</p><p>In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STOI</head><p>The short-time objective intelligibility measure <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CSII-MID</head><p>The mid-level coherence speech intelligibility index (SII) <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CSII-BIF</head><p>The coherence SII with signal-dependent band importance functions <ref type="bibr" target="#b38">[39]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STI-NCM</head><p>The normalized covariance speech transmission index (STI) <ref type="bibr" target="#b9">[10]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STI-NCM-BIF</head><p>The normalized covariance STI with signaldependent band-importance functions <ref type="bibr" target="#b38">[39]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NSEC</head><p>The normalized subband envelope correlation method <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIKNN</head><p>Intelligibility prediction based on a k-nearest neighbor estimate of mutual information (MIKNN) <ref type="bibr" target="#b45">[46]</ref>. GLIMPSE * Implementation of Cooke's glimpse method <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SII *</head><p>The Critical-Band SII with SPIN band-importance functions ( [3, Table <ref type="table">B</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We presented an algorithm for monaural, intrusive intelligibility prediction: given undistorted reference speech signals and their noisy, and potentially non-linearly processed, counterparts, the algorithm estimates the average intelligibility of the latter, across a group of normal-hearing listeners. The proposed algorithm, which is called ESTOI (Extended Short-Time Objective Intelligibility), may be interpreted in terms of an orthogonal decomposition of energy-normalized shorttime spectrograms into "intelligibility subspaces", i.e., onedimensional subspaces which are ranked according to their importance wrt. intelligibility. This intelligibility subspace decomposition indicates, that the proposed algorithm favors spectro-temporal modulation patterns, which are known from literature to be important for intelligibility. The proposed intelligibility predictor has only one free parameter, the segment length N , i.e., the duration across which the shorttime spectrograms are computed. We show, via simulation experiments, that performance is fairly insensitive to the exact choice of this parameter, and that durations in the range 256-640 ms lead to best performance -this allows the algorithm to capture relatively low-frequency modulation content, while still being able to adapt to changing signal characteristics. We study the performance of ESTOI in predicting the results of five different intelligibility listening tests: two with tempo-rally highly modulated additive noise sources, one with more moderately modulated, additive noise sources, and two with noisy signals processed by ideal time-frequency masking and single-channel non-linear noise reduction algorithms, respectively. Compared to a range of existing speech intelligibility prediction algorithms, ESTOI performs well across all listening tests.</p><p>The present study has focused on speech intelligibility prediction performance within data sets, that each contain signals with similar distortions or processing types (e.g., additive, modulated noise or noisy speech processed by ideal time-frequency segregation (ITFS) algorithms, etc.). It is a topic for future research to study the performance of the proposed intelligibility predictor across data sets with different distortion and processing types. Compared to the present study, this would require conduction of larger intelligibility tests, where these different distortion or processing types are included in the same listening test.</p><p>A Matlab implementation of the proposed algorithm is available for non-commercial use at http://kom.aau.dk/ ∼ jje/. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Short-time spectrograms for clean speech time segment (left column) and noisy time segment (right column) for additive, speech-shaped, sinusoidal amplitude-modulated Gaussian noise (modulation frequency of 5 Hz, SNR = -10 dB). a), b) Time domain segments. c), d) DFT shorttime spectrograms |S(k, m)|, |X(k, m)| (dB scale), computed by applying an N ′ = 512 point FFT to zeropadded, Hann windowed, time-domain frames of 256 samples (25.6 ms) with an overlap of D = 128 samples.e), f) third-order octave filterbank spectrograms Sm, Xm (dB scale). g), h) spectrograms with mean-and variance-normalized rows Sm, Xm (linear scale). i), j) spectrograms with mean-and variance-normalized rows and columns, Šm, Xm (linear scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Tr(•) denotes the matrix trace operator. Let us introduce the following orthogonal decomposition of the noisy/processed supervectors xm ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>. The icra signals are synthetic speech signals constructed by filtering Gaussian noise sequences through bandpass filters with time-varying gain to construct signals with speech-like spectro-temporal properties [30]. The snam signals are 100% sinusoidally, intensity-modulated speech-shaped noise signals. The signals are constructed by point-wise multiplication of the unmodulated speech-shaped noise signal icra1 with the modulation sequence a(n) = 1 + sin(2πωn + φ),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Decomposition of d for speech in additive, speech-shaped, sinusoidally amplitude-modulated Gaussian noise (f mod = 5 Hz, SNR = -10 dB). Basis functions e l of the 11 dominant intelligibility subspaces and decomposition of d in terms of eigenvalues λ l (lower right).</figDesc><graphic coords="8,119.53,334.73,111.27,54.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>icra4 1 -</head><label>1</label><figDesc>person babble (female) from the ICRA corpus (Track 4). -29:3:-14. icra6 2-persons babble (1 male and 1 female) from the ICRA corpus (Track 6) -24:3:-9. icra7 6-persons babble from the ICRA corpus (Track 7) -19:3:-4. snam2 100 % intensity-modulated versions of icra1. Modulation frequency 2 Hz. -27:3:-12. snam4 As above with modulation frequency 4 Hz. -23:3:-8. snam8 As above with modulation frequency 8 Hz. -25:3:-10. snam16 As above with modulation frequency 16 Hz. -22:3:-7. macgun (Modified) machine gun noise from the Noisex corpus [31]. -37:3:-22. destop Destroyers operation room noise from the Noisex corpus [31]. -14:3:1. Table I NOISE SOURCES AND SNR RANGES USED FOR INTELLIGIBILITY TEST WITH Additive Noise Set I. NOTATION x : y : z INDICATES SNRS FROM x TO z (BOTH INCLUDED) IN STEPS OF y DB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FreqFigure 5 .</head><label>5</label><figDesc>Figure 5. Decomposition of d for speech in cafeteria noise [29], SNR = -10 dB. Basis functions e l of the 11 dominant intelligibility subspaces and decomposition of d in terms of eigenvalues λ l (lower right).</figDesc><graphic coords="9,114.79,337.71,112.45,55.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Speech intelligibility prediction performance (in terms of ρ) as a function of segment length N for various noise/processing conditions. For Additive Noise Set II, we used the signals and listening test results for the young, normal-hearing listeners to avoid a cluttered plot. N = 30 corresponds to a segment duration of 384 ms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Relative standard deviation ǫ(t sig ) of speech intelligibility predictors ESII and ESTOI, as a function of test signal duration t sig . a) Speechshaped stationary noise (SNR = -10 dB), b) icra4-noise (synthetic 1-person babble) [30] (SNR = -23 dB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1 </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Finally, the intermeditate indices are averaged to form the final intelligibility index d. More details are given in Sec. II. Signal examples of the various stages are shown in Fig. 3.</figDesc><table><row><cell></cell><cell></cell><cell>S j (m)</cell><cell>S m</cell><cell></cell><cell></cell></row><row><cell>s(n)</cell><cell>Cochlear</cell><cell>Envelope</cell><cell>Time</cell><cell>Row-and Col.-</cell><cell>Šm</cell></row><row><cell></cell><cell>Filterbank</cell><cell>Extraction</cell><cell>Segmentation</cell><cell>Normalization</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Avg. Projection Length</cell><cell>d m 1 M</cell><cell>m d m</cell><cell>d</cell></row><row><cell></cell><cell>Cochlear</cell><cell>Envelope</cell><cell>Time</cell><cell>Row-and Col.-</cell><cell></cell></row><row><cell>x(n)</cell><cell>Filterbank</cell><cell>Extraction</cell><cell>Segmentation</cell><cell>Normalization</cell><cell>Xm</cell></row><row><cell></cell><cell></cell><cell>X j (m)</cell><cell>X m</cell><cell></cell><cell></cell></row><row><cell cols="7">Figure 2. The proposed intelligibility predictor, ESTOI, is a function of the noisy/processed signal x(n) and clean speech signal s(n). First, the signals</cell></row><row><cell cols="7">are passed through a one-third octave filter bank, and the temporal envelopes of each subband signal are extracted. The resulting clean and noisy/processed</cell></row><row><cell cols="7">short-time envelope spectrograms are time-and frequency-normalized before the "distance" between them is computed, resulting in intermediate, short-time</cell></row><row><cell cols="2">intelligibility indices dm.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table III PERFORMANCE</head><label>III</label><figDesc>OF INTELLIGIBILITY PREDICTORS IN TERMS OF ρpre, I.E., THE LINEAR CORRELATION COEFFICIENT BETWEEN MEASURED INTELLIGIBILITY AND PREDICTOR OUTPUTS Ĩ , CF.<ref type="bibr" target="#b9">(10)</ref>.</figDesc><table><row><cell></cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>ITFS</cell><cell>SC-NR</cell></row><row><cell></cell><cell>Set I</cell><cell>Set II (Young)</cell><cell>Set II (Elderly)</cell><cell>Set III</cell><cell></cell><cell></cell></row><row><cell>ESTOI</cell><cell>0.846</cell><cell>0.877</cell><cell>0.900</cell><cell>0.864</cell><cell>0.919</cell><cell>0.955</cell></row><row><cell>SIMI</cell><cell>0.483</cell><cell>-0.028</cell><cell>-0.253</cell><cell>0.931</cell><cell>0.934</cell><cell>0.974</cell></row><row><cell>STOI</cell><cell>0.477</cell><cell>-0.797</cell><cell>-0.789</cell><cell>0.887</cell><cell>0.931</cell><cell>0.983</cell></row><row><cell>CSII-MID</cell><cell>0.671</cell><cell>0.002</cell><cell>-0.020</cell><cell>0.784</cell><cell>0.440</cell><cell>0.794</cell></row><row><cell>CSII-BIF</cell><cell>0.717</cell><cell>0.578</cell><cell>0.696</cell><cell>0.883</cell><cell>0.541</cell><cell>0.843</cell></row><row><cell>STI-NCM</cell><cell>0.480</cell><cell>-0.354</cell><cell>-0.657</cell><cell>0.880</cell><cell>0.731</cell><cell>0.844</cell></row><row><cell>STI-NCM-BIF</cell><cell>0.519</cell><cell>-0.033</cell><cell>-0.153</cell><cell>0.784</cell><cell>0.568</cell><cell>0.974</cell></row><row><cell>NSEC</cell><cell>0.572</cell><cell>-0.309</cell><cell>-0.349</cell><cell>0.924</cell><cell>0.871</cell><cell>0.638</cell></row><row><cell>MIKNN</cell><cell>0.552</cell><cell>0.755</cell><cell>0.770</cell><cell>0.732</cell><cell>0.824</cell><cell>0.847</cell></row><row><cell>GLIMPSE</cell><cell>0.850</cell><cell>0.851</cell><cell>0.850</cell><cell>0.845</cell><cell>-</cell><cell>-</cell></row><row><cell>SII</cell><cell>0.541</cell><cell>-0.101</cell><cell>-0.112</cell><cell>0.723</cell><cell>-</cell><cell>-</cell></row><row><cell>ESII</cell><cell>0.807</cell><cell>0.816</cell><cell>0.849</cell><cell>0.701</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>ITFS</cell><cell>SC-NR</cell></row><row><cell></cell><cell>Set I</cell><cell>Set II (Young)</cell><cell>Set II (Elderly)</cell><cell>Set III</cell><cell></cell><cell></cell></row><row><cell>ESTOI</cell><cell>0.915  *</cell><cell>0.895  *</cell><cell>0.916  *</cell><cell>0.960  *</cell><cell>0.948  *</cell><cell>0.981  *</cell></row><row><cell>SIMI</cell><cell>0.514  *</cell><cell>0.027  *</cell><cell>0.238  *</cell><cell>0.975  *</cell><cell>0.958  *</cell><cell>0.970  *</cell></row><row><cell>STOI</cell><cell>0.477  *</cell><cell>0.809  *</cell><cell>0.799  *</cell><cell>0.967  *</cell><cell>0.961  *</cell><cell>0.987  *</cell></row><row><cell>CSII-MID</cell><cell>0.766  *</cell><cell>0.000  *</cell><cell>0.018  *</cell><cell>0.948  *</cell><cell>0.454  *</cell><cell>0.799  *</cell></row><row><cell>CSII-BIF</cell><cell>0.745  *</cell><cell>0.607  *</cell><cell>0.791  *</cell><cell>0.978  *</cell><cell>0.539  *</cell><cell>0.850  *</cell></row><row><cell>STI-NCM</cell><cell>0.525  *</cell><cell>0.364  *</cell><cell>0.660  *</cell><cell>0.935  *</cell><cell>0.727  *</cell><cell>0.844  *</cell></row><row><cell>STI-NCM-BIF</cell><cell>0.524  *</cell><cell>0.003  *</cell><cell>0.147  *</cell><cell>0.813  *</cell><cell>0.586  *</cell><cell>0.976  *</cell></row><row><cell>NSEC</cell><cell>0.619  *</cell><cell>0.315  *</cell><cell>0.356  *</cell><cell>0.953  *</cell><cell>0.868  *</cell><cell>0.625  *</cell></row><row><cell>MIKNN</cell><cell>0.722  *</cell><cell>0.780  *</cell><cell>0.808  *</cell><cell>0.902  *</cell><cell>0.881  *</cell><cell>0.870  *</cell></row><row><cell>GLIMPSE</cell><cell>0.872  *</cell><cell>0.872  *</cell><cell>0.875  *</cell><cell>0.912  *</cell><cell>-</cell><cell>-</cell></row><row><cell>SII</cell><cell>0.674  *</cell><cell>0.098  *</cell><cell>0.107  *</cell><cell>0.964  *</cell><cell>-</cell><cell>-</cell></row><row><cell>ESII</cell><cell>0.845  *</cell><cell>0.844  *</cell><cell>0.872  *</cell><cell>0.818  *</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table IV PERFORMANCE</head><label>IV</label><figDesc>OF INTELLIGIBILITY PREDICTORS Î IN TERMS OF LINEAR CORRELATION COEFFICIENT ρ. SUPERSCRIPTS * INDICATE METHODS WHICH DO NOT PERFORM STATISTICALLY SIGNIFICANTLY WORSE THAN THE METHOD WITH THE HIGHEST ρ FOR A GIVEN DATA SET (SEE TEXT FOR DETAILS).</figDesc><table><row><cell></cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>ITFS</cell><cell>SC-NR</cell></row><row><cell></cell><cell>Set I</cell><cell>Set II (Young)</cell><cell>Set II (Elderly)</cell><cell>Set III</cell><cell></cell><cell></cell></row><row><cell>ESTOI</cell><cell>11.49  *</cell><cell>7.63  *</cell><cell>7.03  *</cell><cell>10.26  *</cell><cell>9.93  *</cell><cell>3.76  *</cell></row><row><cell>SIMI</cell><cell>24.92  *</cell><cell>17.09  *</cell><cell>17.01  *</cell><cell>8.13  *</cell><cell>8.91  *</cell><cell>4.72  *</cell></row><row><cell>STOI</cell><cell>25.53  *</cell><cell>10.06  *</cell><cell>10.54  *</cell><cell>9.24  *</cell><cell>8.61  *</cell><cell>3.09  *</cell></row><row><cell>CSII-MID</cell><cell>18.69  *</cell><cell>17.10  *</cell><cell>17.50  *</cell><cell>11.47  *</cell><cell>27.72  *</cell><cell>11.65  *</cell></row><row><cell>CSII-BIF</cell><cell>19.39  *</cell><cell>13.62  *</cell><cell>11.03  *</cell><cell>7.54  *</cell><cell>26.23  *</cell><cell>10.20  *</cell></row><row><cell>STI-NCM</cell><cell>24.78  *</cell><cell>15.93  *</cell><cell>13.18  *</cell><cell>12.75  *</cell><cell>21.39  *</cell><cell>10.38  *</cell></row><row><cell>STI-NCM-BIF</cell><cell>24.74  *</cell><cell>17.09  *</cell><cell>17.32  *</cell><cell>21.08  *</cell><cell>25.23  *</cell><cell>4.22  *</cell></row><row><cell>NSEC</cell><cell>22.89  *</cell><cell>16.23  *</cell><cell>16.36  *</cell><cell>10.89  *</cell><cell>15.51  *</cell><cell>15.12  *</cell></row><row><cell>MIKNN</cell><cell>20.19  *</cell><cell>10.74  *</cell><cell>10.37  *</cell><cell>15.92  *</cell><cell>14.68  *</cell><cell>9.55</cell></row><row><cell>GLIMPSE</cell><cell>14.22  *</cell><cell>8.37  *</cell><cell>8.51  *</cell><cell>14.85  *</cell><cell>-</cell><cell>-</cell></row><row><cell>SII</cell><cell>21.56  *</cell><cell>17.02  *</cell><cell>17.40  *</cell><cell>9.76  *</cell><cell>-</cell><cell>-</cell></row><row><cell>ESII</cell><cell>15.59  *</cell><cell>9.20  *</cell><cell>8.59  *</cell><cell>20.82  *</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table V PERFORMANCE</head><label>V</label><figDesc>OF INTELLIGIBILITY PREDICTORS Î IN TERMS OF ROOT MEAN-SQUARE PREDICTION ERROR σ. SUPERSCRIPTS * INDICATE METHODS WHICH DO NOT PERFORM STATISTICALLY SIGNIFICANTLY WORSE THAN THE METHOD WITH THE LOWEST σ FOR A GIVEN DATA SET (SEE TEXT FOR DETAILS).</figDesc><table><row><cell></cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>Add. Noise</cell><cell>ITFS</cell><cell>SC-NR</cell></row><row><cell></cell><cell>Set I</cell><cell>Set II (Young)</cell><cell>Set II (Elderly)</cell><cell>Set III</cell><cell></cell><cell></cell></row><row><cell>ESTOI</cell><cell>0.748</cell><cell>0.590</cell><cell>0.667</cell><cell>0.816</cell><cell>0.775</cell><cell>0.842</cell></row><row><cell>SIMI</cell><cell>0.354</cell><cell>0.077</cell><cell>0.256</cell><cell>0.825</cell><cell>0.767</cell><cell>0.884</cell></row><row><cell>STOI</cell><cell>0.376</cell><cell>0.436</cell><cell>0.436</cell><cell>0.818</cell><cell>0.798</cell><cell>0.905</cell></row><row><cell>CSII-MID</cell><cell>0.609</cell><cell>0.026</cell><cell>0.026</cell><cell>0.863</cell><cell>0.335</cell><cell>0.600</cell></row><row><cell>CSII-BIF</cell><cell>0.580</cell><cell>0.410</cell><cell>0.487</cell><cell>0.846</cell><cell>0.408</cell><cell>0.684</cell></row><row><cell>STI-NCM</cell><cell>0.328</cell><cell>0.180</cell><cell>0.590</cell><cell>0.818</cell><cell>0.538</cell><cell>0.684</cell></row><row><cell>STI-NCM-BIF</cell><cell>0.276</cell><cell>0.085</cell><cell>0.077</cell><cell>0.643</cell><cell>0.385</cell><cell>0.853</cell></row><row><cell>NSEC</cell><cell>0.514</cell><cell>0.077</cell><cell>0.128</cell><cell>0.854</cell><cell>0.695</cell><cell>0.505</cell></row><row><cell>MIKNN</cell><cell>0.554</cell><cell>0.436</cell><cell>0.410</cell><cell>0.751</cell><cell>0.689</cell><cell>0.684</cell></row><row><cell>GLIMPSE</cell><cell>0.673</cell><cell>0.461</cell><cell>0.385</cell><cell>0.742</cell><cell>-</cell><cell>-</cell></row><row><cell>SII</cell><cell>0.260</cell><cell>0.330</cell><cell>0.128</cell><cell>0.822</cell><cell>-</cell><cell>-</cell></row><row><cell>ESII</cell><cell>0.653</cell><cell>0.564</cell><cell>0.359</cell><cell>0.685</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table VI PERFORMANCE</head><label>VI</label><figDesc>OF INTELLIGIBILITY PREDICTORS IN TERMS OF Î KENDALL'S RANK CORRELATION COEFFICIENT τ .</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The algorithm name ESTOI follows the terminology introduced by Rhebergen et. al., who used the name Extended SII (ESII) for their algorithm to improve the performance of SII for modulated noise maskers<ref type="bibr" target="#b5">[6]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We ignore the clipping procedure used in STOI in this description.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that an accurate comparison is difficult: the results in<ref type="bibr" target="#b23">[24]</ref> are based on spectro-temporal analyses of log-magnitude spectra computed in a uniformfrequency filter bank, whereas the proposed method operates on linear, but energy-normalized one-third octave band magnitude spectra.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The IBM and TBM algorithms are identical for speech-shaped noise.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank four anonymous reviewers whose constructive comments helped improve the presentation of this work. Discussions with Dr. Gaston Hilkhuysen, Dr. Thomas Ulrich Christiansen, and Asger Heidemann Andersen are greatly acknowledged. Finally, the authors wish to thank Dr. Jalal Taghia for making the Matlab code of his intelligibility predictor publicly available.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">American National Standard Methods for the Calculation of the Articulation Index</title>
		<idno>ANSI S3.5</idno>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>American National Standards Institute</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Factors governing the intelligibility of speech sounds</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Steinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="119" />
			<date type="published" when="1947">1947</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">ANSI S3.5, Methods for the Calculation of the Speech Intelligibility Index</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>American National Standards Institute</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>American National Standards Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sound System Equipment -Part 16: Objective Rating of Speech Intelligibility by Speech Transmission Index</title>
		<idno>IEC60268-16</idno>
	</analytic>
	<monogr>
		<title level="j">International Electrotechnical Commission</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Geneva</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A physical method for measuring speech-transmission quality</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J M</forename><surname>Steeneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Houtgast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="318" to="326" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A speech intelligibility index based approach to predict the speech reception threshold for sentences in fluctuating noise for normal-hearing listeners</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Rhebergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Versfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2181" to="2192" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Masking of speech by amplitudemodulated noise</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Å</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Arlinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="518" to="529" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A glimpsing model of speech perception in noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cooke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1562" to="1573" />
			<date type="published" when="2006-03">March 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coherence and the speech intelligibility index</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Arehart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2224" to="2237" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis of of speech-based speech transmission index methods with implications for nonlinear operations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Goldsworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3679" to="3689" />
			<date type="published" when="2004-12">December 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Temporal envelope and fine structure cues for speech intelligibility</title>
		<author>
			<persName><forename type="first">R</forename><surname>Drullmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="585" to="592" />
			<date type="published" when="1995-01">January 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The effect of multichannel dynamic compression on speech intelligibility</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hohmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kollmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1191" to="1195" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predicting speech intelligibility based on the signal-to-noise envelope power ratio after modulation-frequency selective processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jørgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1475" to="1487" />
			<date type="published" when="2011-09">September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Taal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hendriks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heusdens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio., Speech, Language Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2125" to="2136" />
			<date type="published" when="2011-09">September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Speech intelligibility evaluation for mobile phones</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jørgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cubick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Acustica United With Acustica</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1016" to="1025" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Objective Quality and Intelligibility Prediction for Users of Assistive Listening Devices</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Parsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Arehart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hazrati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Scollie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE SP Mag</title>
		<imprint>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2015-03">March 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Speech intelligibility prediction based on Mutual Information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio., Speech, Language Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="430" to="440" />
			<date type="published" when="2014-02">February 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluation of objective intelligibility prediction measures for noise-reduced signals in mandarin</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal essing</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="4465" to="4469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Speech intelligibility predictions in hearing-impaired listeners based on a psychoacoustically motivated perception model</title>
		<author>
			<persName><forename type="first">I</forename><surname>Holube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kollmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1703" to="1716" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Hearing-Aid Speech Perception Index (HASPI)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Arehart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="75" to="93" />
			<date type="published" when="2014-12">Nov.-Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Effects of manipulating the signal-to-noise envelope power ratio on speech intelligibility</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jørgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Decorsière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1401" to="1410" />
			<date type="published" when="2015-03">March 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mutual dependence of the octave-band weights in predicting speech intelligibility</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Steeneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Houtgast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech communication</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="123" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Speech reception thresholds in noise with and without spectral and temporal dips for hearing-impaired and normally hearing people</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="577" to="587" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Modulation Transfer Function for Speech Iintelligibility</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Theunissen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS -Computational Biology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2009-03">March 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Timit, Acoustic-Phonetic Continuous Speech Corpus</title>
		<author>
			<persName><surname>Darpa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">October 1990, NIST Speech Disc 1-1.1</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Effect of temporal envelope smearing on speech reception</title>
		<author>
			<persName><forename type="first">R</forename><surname>Drullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Festen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Plomp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="1053" to="1064" />
			<date type="published" when="1994-02">February 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effect of reducing slow temporal modulation on speech reception</title>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="2670" to="2680" />
			<date type="published" when="1994-02">February 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comparing the information conveyed by envelope modulation for speech intelligibility, speech quality, and music quality</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Arehart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2470" to="2482" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Diverse Environments Multichannel Acoustic Noise Database (DEMAND): A database of multichannel environmental noise recordings</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thiemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st International Congress on Acoustics</title>
		<meeting>21st International Congress on Acoustics<address><addrLine>Montreal, Canada, 2013, HAL Id</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page">796707</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ICRA noises: Artificial Noise Signals with Speech-like Spectral and Temporal Properties for Hearing Instrument Assessment</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Dreschler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Verschuure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ludvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Audiology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="148" to="157" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J M</forename><surname>Steeneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="251" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Design, optimization and evaluation of a Danish sentence test in noise</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wagener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Josvassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ardenkjaer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Audiol</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Development of a speech in noise test (matrix)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Houben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Dreschler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verschuure</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-06">June 2007</date>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
	<note>in 8th EFAS Congress, 10th DGA Congress</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sentences for testing speech intelligibility in noise</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hagerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand. Audiol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Role of mask pattern in intelligibility of ideal binary-masked nosy speech</title>
		<author>
			<persName><forename type="first">U</forename><surname>Kjems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1415" to="1426" />
			<date type="published" when="2009-09">September 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Isolating the energetic component of speech-on-speech masking with ideal timefrequency segregation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brungart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4007" to="4018" />
			<date type="published" when="2006-12">December 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Spectral Magnitude Minimum Mean-Square Error Estimation Using Binary and Continuous Gain Functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hendriks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio., Speech, Language Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="102" />
			<date type="published" when="2012-01">January 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An Evaluation of Objective Quality Measures for Speech Intelligibility Prediction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Taal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hendriks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heusdens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kjems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech. Brighton, UK: ISCA</title>
		<meeting>Interspeech. Brighton, UK: ISCA</meeting>
		<imprint>
			<date type="published" when="2009-10">September 6-10 2009</date>
			<biblScope unit="page" from="1947" to="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Objective measures for predicting speech intelligibility in noisy conditions based on new band-importance functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Loizou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3387" to="3405" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Standardization of a test of speech perception in noise</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bilger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Speech Hear. Res</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="32" to="48" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The comparison of regression variables</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Stat. Society, Ser. B</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="396" to="399" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Tests for Comparing Elements of a Correlation Matrix</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Steiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="251" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Comparing Dependent Correlations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of General Psychology</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<title level="m">Pattern Classification</title>
		<imprint>
			<publisher>John Wiley and Sons, Inc</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A simple correlation-based model of intelligibility for nonlinear speech enhancement and separation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P W</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th European Signal Processing Conference</title>
		<meeting>17th European Signal essing Conference</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1849" to="1853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The Netherlands, and an External Associate Professor with Aalborg University. Currently, he is a Senior Researcher with Oticon A/S, Copenhagen, Denmark, where his main responsibility is scouting and development of new signal processing concepts for hearing aid applications. He is also a Professor with the Section for Information Processing (SIP), Department of Electronic Systems, at Aalborg University. His main interests are in the area of acoustic signal processing, including signal retrieval from noisy observations, coding, speech and audio modification and synthesis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Taghia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">he was with the Center for Person Kommunikation (CPK), Aalborg University, as a Ph.D. student and Assistant Research Professor. From 2000 to 2007, he was a Post-Doctoral Researcher and Assistant Professor with Delft University of Technology</title>
		<meeting><address><addrLine>Aalborg, Denmark; Delft</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">January 2014. 1996 and 2000. 1996 to 2000</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="6" to="16" />
		</imprint>
	</monogr>
	<note>Jesper Jensen Jesper Jensen received the M.Sc. degree in electrical engineering and the Ph.D. degree in signal processing from Aalborg University. intelligibility enhancement of speech signals, signal processing for hearing aid applications, and perceptual aspects of signal processing</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From 2013 he worked in industry with Philips Research, Eindhoven, the Netherlands as a research scientist in the field of biomedical signal processing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cees</surname></persName>
		</author>
		<author>
			<persName><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From 2012 to 2013 he held Postdoc positions at the Sound and Image Processing</title>
		<title level="s">Cees) H. Taal received the B.S. and M.A. degrees in arts and technology from the Utrecht School of Arts</title>
		<meeting><address><addrLine>Utrecht; Delft, The Netherlands; Leiden, the Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007 and 2012</date>
		</imprint>
		<respStmt>
			<orgName>Royal Institute of Technology (KTH), Stockholm, Sweden and the Leiden University Medical Center</orgName>
		</respStmt>
	</monogr>
	<note>The Netherlands, in 2004 and his M.Sc. and Ph.D. degree in computer science from the Delft University of Technology. Currently, he is at Quby, Amsterdam, the Netherlands performing R&amp;D as a DSP expert applying signal processing to smart-home applications, e.g., thermostats and power monitoring</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
