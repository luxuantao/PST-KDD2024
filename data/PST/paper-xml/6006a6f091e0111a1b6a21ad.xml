<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FREE LUNCH FOR FEW-SHOT LEARNING: DISTRIBUTION CALIBRATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shuo</forename><surname>Yang</surname></persName>
							<email>shuo.yang@student.uts.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Data Engineering</orgName>
								<orgName type="institution">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
							<email>lu.liu@student.uts.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">Australian Artificial Intelligence Institute</orgName>
								<orgName type="institution">University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Xu</surname></persName>
							<email>min.xu@uts.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Data Engineering</orgName>
								<orgName type="institution">University of Technology Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FREE LUNCH FOR FEW-SHOT LEARNING: DISTRIBUTION CALIBRATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples, then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-theart accuracy on two datasets (5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Learning from a limited number of training samples has drawn increasing attention due to the high cost of collecting and annotating a large amount of data. Researchers have developed algorithms to improve the performance of models that have been trained with very few data. <ref type="bibr" target="#b3">Finn et al. (2017)</ref>; <ref type="bibr" target="#b23">Snell et al. (2017)</ref> train models in a meta-learning fashion so that the model can adapt quickly on tasks with only a few training samples available. <ref type="bibr" target="#b6">Hariharan &amp; Girshick (2017)</ref>; <ref type="bibr" target="#b27">Wang et al. (2018)</ref> try to synthesize data or features by learning a generative model to alleviate the data insufficiency problem. <ref type="bibr" target="#b17">Ren et al. (2018)</ref> propose to leverage unlabeled data and predict pseudo labels to improve the performance of fewshot learning.</p><p>While most previous works focus on developing stronger models, scant attention has been paid to the property of the data itself. It is natural that when the number of data grows, the ground truth distribution can be more accurately uncovered. Models trained with a wide coverage of data can generalize well during evaluation. On the other hand, when training a model with only a few training data, the model tends to overfit on these few samples by minimizing the training loss over these samples. These phenomena are illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. This biased distribution based on a few examples can damage the generalization ability of the model since it is far from mirroring the ground truth distribution from which test cases are sampled during evaluation.</p><p>Here, we consider calibrating this biased distribution into a more accurate approximation of the ground truth distribution. In this way, a model trained with inputs sampled from the calibrated distribution can generalize over a broader range of data from a more accurate distribution rather than only fitting itself to those few samples. Instead of calibrating the distribution of the original data space, we try to calibrate the distribution in the feature space, which has much lower dimensions and is easier to calibrate <ref type="bibr" target="#b29">(Xian et al. (2018)</ref>). We assume every dimension in the feature vectors follows a Gaussian distribution and observe that similar classes usually have similar mean and variance of the feature representations, as shown in Table <ref type="table" target="#tab_0">1</ref>. Thus, the mean and variance of the Gaussian distribution can be transferred across similar classes <ref type="bibr" target="#b21">(Salakhutdinov et al. (2012)</ref>). Meanwhile, the statistics can be estimated more accurately when there are adequate samples for this class. Based on these observations, we reuse the statistics from many-shot classes and transfer them to better estimate the distribution of the few-shot classes according to their class similarity. More samples can be generated according to the estimated distribution which provides sufficient supervision for training the classification model.</p><p>In the experiments, we show that a simple logistic regression classifier trained with our strategy can achieve state-of-the-art accuracy on two datasets. Our distribution calibration strategy can be paired with any classifier and feature extractor with no extra learnable parameters. Training with samples selected from the calibrated distribution can achieve 12% accuracy gain compared to the baseline which is only trained with the few samples given in a 5way1shot task. We also visualize the calibrated distribution and show that it is an accurate approximation of the ground truth that can better cover the test cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Few-shot classification is a challenging machine learning problem and researchers have explored the idea of learning to learn or meta-learning to improve the quick adaptation ability to alleviate the few-shot challenge. One of the most general algorithms for meta-learning is the optimizationbased algorithm. <ref type="bibr" target="#b3">Finn et al. (2017)</ref> and <ref type="bibr" target="#b7">Li et al. (2017)</ref> proposed to learn how to optimize the gradient descent procedure so that the learner can have a good initialization, update direction, and learning rate. For the classification problem, researchers proposed simple but effective algorithms based on metric learning. MatchingNet <ref type="bibr" target="#b26">(Vinyals et al., 2016)</ref> and ProtoNet <ref type="bibr" target="#b23">(Snell et al., 2017)</ref> learned to classify samples by comparing the distance to the representatives of each class. Our distribution calibration and feature sampling procedure does not include any learnable parameters and the classifier is trained in a traditional supervised learning way.</p><p>Another line of algorithms is to compensate for the insufficient number of available samples by generation. Most methods use the idea of Generative Adversarial Networks (GANs) <ref type="bibr" target="#b5">(Goodfellow et al., 2014)</ref> or autoencoder <ref type="bibr" target="#b18">(Rumelhart et al., 1986)</ref> to generate samples <ref type="bibr" target="#b32">(Zhang et al. (2018)</ref>; <ref type="bibr" target="#b2">Chen et al. (2019b)</ref>; <ref type="bibr" target="#b22">Schwartz et al. (2018)</ref>; <ref type="bibr" target="#b4">Gao et al. (2018)</ref>) or features <ref type="bibr" target="#b29">(Xian et al. (2018)</ref>; <ref type="bibr" target="#b31">Zhang et al. (2019)</ref>) to augment the training set. Specifically, <ref type="bibr" target="#b32">Zhang et al. (2018)</ref> and <ref type="bibr" target="#b29">Xian et al. (2018)</ref> proposed to synthesize data by introducing an adversarial generator conditioned on tasks. <ref type="bibr" target="#b31">Zhang et al. (2019)</ref> tried to learn a variational autoencoder to approximate the distribution and predict labels based on the estimated statistics. The autoencoder can also augment samples by projecting between the visual space and the semantic space <ref type="bibr" target="#b2">(Chen et al., 2019b)</ref> or encoding the intra-class deformations <ref type="bibr" target="#b22">(Schwartz et al., 2018)</ref>. <ref type="bibr" target="#b10">Liu et al. (2019b)</ref> and <ref type="bibr" target="#b9">Liu et al. (2019a)</ref> propose to generate features through the class hierarchy. While these methods can generate extra samples or features for training, they require the design of a complex model and loss function to learn how to generate. However, our distribution calibration strategy is simple and does not need extra learnable parameters.</p><p>Data augmentation is a traditional and effective way of increasing the number of training samples. <ref type="bibr" target="#b15">Qin et al. (2020)</ref> and <ref type="bibr" target="#b0">Antoniou &amp; Storkey (2019)</ref> proposed the used of the traditional data augmentation technique to construct pretext tasks for unsupervised few-shot learning. <ref type="bibr" target="#b27">Wang et al. (2018)</ref> and <ref type="bibr" target="#b6">Hariharan &amp; Girshick (2017)</ref> leveraged the general idea of data augmentation, they designed a hallucination model to generate the augmented version of the image with different choices for the model's input, i.e., an image and a noise <ref type="bibr" target="#b27">(Wang et al., 2018)</ref> or the concatenation of multiple features <ref type="bibr" target="#b6">(Hariharan &amp; Girshick, 2017)</ref>. <ref type="bibr" target="#b13">Park et al. (2020)</ref> tried to augment feature representations by sampling from an estimated variance. These methods learn to augment from the original samples or their feature representation while we try to estimate the class-level distribution and thus can eliminate the inductive bias from a single sample and provide more diverse generations from the calibrated distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MAIN APPROACH</head><p>In this section, we introduce the few-shot classification problem definition in Section 3.1 and details of our proposed approach in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PROBLEM DEFINITION</head><p>We follow a typical few-shot classification setting. Given a dataset with data-label pairs D = {(x i , y i )} where x i ∈ R d is the feature vector of a sample and y i ∈ C, where C denotes the set of classes. This set of classes is divided into base classes C b and novel classes C n , where</p><formula xml:id="formula_0">C b ∩ C n = ∅ and C b ∪ C n = C.</formula><p>The goal is to train a model on the data from the base classes so that the model can generalize well on tasks sampled from the novel classes. In order to evaluate the fast adaptation ability or the generalization ability of the model, there are only a few available labeled samples for each task T . The most common way to build a task is called an N-way-K-shot task <ref type="bibr" target="#b26">(Vinyals et al. (2016))</ref>, where N classes are sampled from the novel set and only K (e.g., 1 or 5) labeled samples are provided for each class. The few available labeled data are called support set S = {(x i , y i )} N ×K i=1 and the model is evaluated on another query set</p><formula xml:id="formula_1">Q = {(x i , y i )} N ×K+N ×q i=N ×K+1</formula><p>, where every class in the task has q test cases. Thus, the performance of a model is evaluated as the averaged accuracy on (the query set of) multiple tasks sampled from the novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DISTRIBUTION CALIBRATION</head><p>As introduced in Section 3.1, the base classes have a sufficient amount of data while the evaluation tasks sampled from the novel classes only have a limited number of labeled samples. The statistics of the distribution for the base class can be estimated more accurately compared to the estimation based on few-shot samples, which is an ill-posed problem. As shown in Table <ref type="table" target="#tab_0">1</ref>, we observe that if we assume the feature distribution is Gaussian, the mean and variance with respect to each class are correlated to the semantic similarity of each class. With this in mind, the statistics can be transferred from the base classes to the novel classes if we learn how similar the two classes are. In the following sections, we discuss how we calibrate the distribution estimation of the classes with only a few samples (Section 3.2.2) with the help of the statistics of the base classes (Section 3.2.1). We will also elaborate on how do we leverage the calibrated distribution to improve the performance of few-shot learning (Section 3.2.3).</p><p>Note that our distribution calibration strategy is over the feature-level and is agnostic to any feature extractor. Thus, it can be built on top of any pretrained feature extractors without further costly finetuning. In our experiments, we use the pretrained WideResNet following previous work <ref type="bibr" target="#b12">(Mangla et al. (2020)</ref>). The WideResNet is trained to classify the base classes, along with a self-supervised pretext task to learn the general-purpose representations suitable for image understanding tasks. Please refer to their paper for more details on training the feature extractor. Calibrate the mean µ and the covariance Σ for class yi using xi with Equation 6 4:</p><p>Sample features for class yi from the calibrated distribution as Equation <ref type="formula">7</ref>5: end for 6: Train a classifier using both support set features and all sampled features as Equation 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">STATISTICS OF THE BASE CLASSES</head><p>We assume the feature distribution of base classes is Gaussian. The mean of the feature vector from a base class i is calculated as the mean of every single dimension in the vector:</p><formula xml:id="formula_2">µ i = ni j=1 (x j ) n i ,<label>(1)</label></formula><p>where x j is a feature vector of the j-th sample from the base class i and n i is the total number of samples in class i. As the feature vector x j is multi-dimensional, we use covariance for a better representation of the variance between any pair of elements in the feature vector. The covariance matrix Σ i for the features from class i is calculated as:</p><formula xml:id="formula_3">Σ i = 1 n i − 1 ni j=1 (x j − µ i ) (x j − µ i )</formula><p>T .</p><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">CALIBRATING STATISTICS OF THE NOVEL CLASSES</head><p>Here, we consider an N-way-K-shot task sampled from the novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tukey's Ladder of Powers Transformation</head><p>To make the feature distribution more Gaussian-like, we first transform the features of the support set and query set in the target task using Tukey's Ladder of Powers transformation <ref type="bibr" target="#b24">(Tukey (1977)</ref>). Tukey's Ladder of Powers transformation is a family of power transformations which can reduce the skewness of distributions and make distributions more Gaussian-like. Tukey's Ladder of Powers transformation is formulated as:</p><formula xml:id="formula_4">x = x λ if λ = 0 log(x) if λ = 0 (3)</formula><p>where λ is a hyper-parameter to adjust how to correct the distribution. The original feature can be recovered by setting λ as 1. Decreasing λ makes the distribution less positively skewed and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Calibration through statistics transfer</head><p>Using the statistics from the base classes introduced in Section 3.2.1, we transfer the statistics from the base classes which are estimated more accurately on sufficient data to the novel classes. The transfer is based on the Euclidean distance between the feature space of the novel classes and the mean of the features from the base classes µ i as computed in Equation <ref type="formula" target="#formula_2">1</ref>. Specifically, we select the top k base classes with the closest distance to the feature of a sample x from the support set:</p><formula xml:id="formula_5">S d = {− µ i − x 2 | i ∈ C b },<label>(4)</label></formula><formula xml:id="formula_6">S N = {i | − µ i − x 2 ∈ topk(S d )},<label>(5)</label></formula><p>where topk(•) is an operator to select the top elements from the input distance set S d . S N stores the k nearest base classes with respect to a feature vector x. Then, the mean and covariance of the distribution is calibrated by the statistics from the nearest base classes: where α is a hyper-parameter that determines the degree of dispersion of features sampled from the calibrated distribution.</p><formula xml:id="formula_7">µ = Σ i∈S N µ i + x k + 1 , Σ = Σ i∈S N Σ i k + α,<label>(6)</label></formula><p>For few-shot learning with more than one shot, the aforementioned procedure of the distribution calibration should be undertaken multiple times with each time using one feature vector from the support set. This avoids the bias provided by one specific sample and potentially achieves more diverse and accurate distribution estimation. Thus, for simplicity, we denote the calibrated distribution as a set of statistics. For a class y ∈ C n , we denote the set of statistics as S y = {(µ 1 , Σ 1 ), ..., (µ K , Σ K )}, where µ i , Σ i are the calibrated mean and covariance, respectively, computed based on the i-th feature in the support set of class y. Here, the size of the set is the value of K for an N-way-K-shot task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">HOW TO LEVERAGE THE CALIBRATED DISTRIBUTION?</head><p>With a set of calibrated statistics S y for class y in a target task, we generate a set of feature vectors with label y by sampling from the calibrated Gaussian distributions:</p><formula xml:id="formula_8">D y = {(x, y)|x ∼ N (µ, Σ), ∀(µ, Σ) ∈ S y }.</formula><p>(7) Here, the total number of generated features per class is set as a hyperparameter and they are equally distributed for every calibrated distribution in S y . The generated features along with the original support set features for a few-shot task is then served as the training data for a task-specific classifier. We train the classifier for a task by minimizing the cross-entropy loss over both the features of its support set S and the generated features D y :</p><formula xml:id="formula_9">= (x,y)∼ S∪D y,y∈Y T − log Pr(y|x; θ),<label>(8)</label></formula><p>where Y T is the set of classes for the task T . S denotes the support set with features transformed by Turkey's Ladder of Powers transformation and the classifier model is parameterized by θ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we answer the following questions:</p><p>• How does our distribution calibration strategy perform compared to the state-of-the-art methods?  <ref type="formula">2018</ref>)) and CUB <ref type="bibr" target="#b28">(Welinder et al. (2010)</ref>). miniImageNet and tieredImageNet have a brand range of classes including various animals and objects while CUB is a more fine-grained dataset that includes various species of birds. Datasets with different levels of granularity may have different distributions for their feature space. We want to show the effectiveness and generality of our strategy on all three datasets.</p><p>miniImageNet is derived from ILSVRC-12 dataset <ref type="bibr" target="#b19">(Russakovsky et al., 2014)</ref>. It contains 100 diverse classes with 600 samples per class. The image size is 84 × 84 × 3. We follow the splits used in previous works <ref type="bibr" target="#b16">(Ravi &amp; Larochelle, 2017)</ref>, which split the dataset into 64 base classes, 16 validation classes, and 20 novel classes.</p><p>tieredImageNet is a larger subset of ILSVRC-12 dataset <ref type="bibr" target="#b19">(Russakovsky et al., 2014)</ref>, which contains 608 classes sampled from hierarchical category structure. Each class belongs to one of 34 higherlevel categories sampled from the high-level nodes in the ImageNet. The average number of images in each class is 1281. We use 351, 97, and 160 classes for training, validation, and test, respectively.</p><p>CUB is a fine-grained few-shot classification benchmark. It contains 200 different classes of birds with a total of 11,788 images of size 84 × 84 × 3. Following previous works <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref>, we split the dataset into 100 base classes, 50 validation classes, and 50 novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">EVALUATION METRIC</head><p>We use the top-1 accuracy as the evaluation metric to measure the performance of our method. We report the accuracy on 5way1shot and 5way5shot settings for miniImageNet, tieredImageNet and CUB. The reported results are the averaged classification accuracy over 10,000 tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">IMPLEMENTATION DETAILS</head><p>For feature extractor, we use the WideResNet trained following previous work <ref type="bibr" target="#b12">(Mangla et al. (2020)</ref>). For each dataset, we train the feature extractor with base classes and test the performance using novel classes. Note that the feature representation is extracted from the penultimate layer (with a ReLU activation function) from the feature extractor, thus the values are all non-negative so that the inputs to Tukey's Ladder of Powers transformation in Equation 3 are valid. At the distribution calibration stage, we compute the base class statistics and transfer them to calibrate novel class distribution for each dataset. We use the LR and SVM implementation of scikit-learn <ref type="bibr" target="#b14">(Pedregosa et al. (2011)</ref>) with the default settings. We use the same hyperparameter value for all datasets except for α. Specifically, the number of generated features is 750; k = 2 and λ = 0.5. α is 0.21, 0.21 and 0.3  for miniImageNet, tieredImageNet and CUB, respectively. The source code is available at: https: //github.com/ShuoYang-1998/ICLR2021-Oral_Distribution_Calibration <ref type="table" target="#tab_2">3</ref> presents the 5way1shot and 5way5shot classification results of our method on miniImageNet, tieredImageNet and CUB. We compare our method with the three groups of the fewshot learning method, optimization-based, metric-based, and generation-based. Our method can be built on top of any classifier, and we use two popular and simple classifiers, namely SVM and LR to prove the effectiveness of our method. Simple linear classifiers equipped with our method perform better than the state-of-the-art few-shot classification method and achieve the best performance on 1-shot and 5-shot settings of miniImageNet, tieredImageNet and CUB. The performance of our distribution calibration surpasses the state-of-the-art generation-based method by 10% for the 5way1shot setting, which proves that our method can handle extremely low-shot classification tasks better. Compared to other generation-based methods, which require the design of a generative model with extra training costs on the learnable parameters, simple machine learning classifier with DC is much more simple, effective and flexible and can be equipped with any feature extractors and classifier model structures. Specifically, we show three variants, i.e, Maximum likelihood with DC, SVM with DC, Logistic Regression with DC in Table <ref type="table" target="#tab_2">2 and Table 3</ref>. A simple maximum likelihood classifier based on the calibrated distribution can outperform previous baselines and training a SVM classifier or Logistic Regression classifier using the samples from the calibrated distribution can further improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">COMPARISION TO STATE-OF-THE-ART Table and Table</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">VISUALIZATION OF GENERATED SAMPLES</head><p>We show what the calibrated distribution looks like by visualizing the generated features sampled from the distribution. In Figure <ref type="figure" target="#fig_2">2</ref>, we show the t-SNE representation (van der Maaten &amp; Hinton  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Backbones</head><p>without DC with DC conv4 <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref> 42.11 ± 0.71 54.62 ± 0.64 (↑ 12.51) conv6 <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref> 46.07 ± 0.26 57.14 ± 0.45 (↑ 11.07) resnet18 <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref> 52.32 ± 0.82 61.50 ± 0.47 (↑ 9.180) WRN28 <ref type="bibr" target="#b12">(Mangla et al., 2020)</ref> 54.53 ± 0.56 64.38 ± 0.63 (↑ 9.850) WRN28 + Rotation Loss <ref type="bibr" target="#b12">(Mangla et al., 2020)</ref> 56.37 ± 0.68 68.57 ± 0.55 (↑ 12.20) (2008)) of the original support set (a), the generated features (b,c) as well as the query set (d). Based on the calibrated distribution, the sampled features form a Gaussian distribution and more samples (c) can have a more comprehensive representation of the distribution. Due to the limited number of examples in the support set, only 1 in this case, the samples from the query set usually cover a greater area and are a mismatch with the support set. This mismatch can be fixed to some extent by the generated features, i.e., the generated features in (c) can overlap areas of the query set. Thus, training with these generated features can alleviate the mismatch between the distribution estimated only from the few-shot samples and the ground truth distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">APPLICABILITY OF DISTRIBUTION CALIBRATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applying distribution calibration on different backbones</head><p>Our distribution calibration strategy is agnostic to backbones / feature extractors. Table <ref type="table" target="#tab_4">5</ref> shows the consistent performance boost when applying distribution calibration on different feature extractors, i.e, four convolutional layers (conv4), six convolutional layers (conv6), resnet18, WRN28 and WRN28 trained with rotation loss. Distribution calibration achieves around 10% accuracy improvement compared to the backbones trained with different</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applying distribution calibration on other baselines</head><p>A variety of works can benefit from training with the features generated by our distribution calibration strategy. We apply our distribution calibration strategy on two simple few-shot classification algorithms, Baseline <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref> and Baseline++ <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref>. Table <ref type="table" target="#tab_5">6</ref> shows that our distribution calibration brings over 10% of accuracy improvement on both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">EFFECTS OF FEATURE TRANSFORMATION AND TRAINING WITH GENERATED FEATURES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>Table <ref type="table" target="#tab_3">4</ref> shows the performance when our model is trained without Tukey's Ladder of Powers transformation for the features as in Equation 3 and when it is trained without the generated features as in Equation <ref type="formula">7</ref>. It is clear that there is a severe decline in performance of over 10% if both are not used in the 5way1shot setting. The ablation of either one results in a performance drop of around 5% in the 5way1shot setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choices of Power for Tukey's Ladder of Powers Transformation</head><p>The left side of Figure <ref type="figure" target="#fig_3">3</ref> shows the 5way1shot accuracy when choosing different powers for the Tukey's transformation in Equation 3 when training the classifier with the generated features (red) and without (blue). Note that when the power λ equals 1, the transformation keeps the original feature representations. There is a consistent general tendency for training with and without the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>without DC with DC Baseline <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref> 42.11 ± 0.71 54.62 ± 0.64 (↑ 12.51) Baseline++ <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref> 48.24 ± 0.75 61.24 ± 0.37 (↑ 13.00) generated features and in both cases, we found λ = 0.5 is the optimum choice. With the Tukey's transformation, the distribution of query set features in target tasks become more aligned to the calibrated Gaussian distribution, thus benefits the classifier which is trained on features sampled from the calibrated distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of generated features</head><p>The right side of Figure <ref type="figure" target="#fig_3">3</ref> analyzes whether more generated features results in consistent improvement in both cases, namely when the features of support and query set are transformed by Tukey's transformation (red) and when they are not (blue). We found that when the number of generated features is below 500, both cases can benefit from more generated features. However, when more features are sampled, the performance of the classifier tested on untransformed features begins to decline. By training with the generated samples, the simple logistic regression classifier has a 12% relative performance improvement in a 1-shot classification setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">OTHER HYPER-PARAMETERS</head><p>We select the hyperparameters based on the performance of the validation set. The k base class statistics to calibrate the novel class distribution in Equation 5 is set to 2. Figure <ref type="figure">4</ref> shows the effect of different values of k. The α in Equation 6 is a constant added on each element of the estimated covariance matrix, which can determine the degree of dispersion of features sampled from the calibrated distributions. An appropriate value of α can ensure a good decision boundary for the classifier. Different datasets have different statistics and an appropriate value of α may vary for different datasets. Figure <ref type="figure">5</ref> explores the effect of α on all three datasets, i.e. miniImageNet, tieredImageNet and CUB. We observe that in each dataset, the performance of the validation set and the novel (testing) set generally has the same tendency, which indicates that the variance is dataset-dependent and is not overfitting to a specific set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORKS</head><p>We propose a simple but effective distribution calibration for few-shot classification. Without complex generative models, training loss and extra parameters to learn, a simple logistic regression trained with features generated by our strategy outperforms the current state-of-the-art methods by ∼ 5% on miniImageNet. The calibrated distribution is visualized and demonstrates an accurate estimation of the feature distribution. Future works will explore the applicability of distribution calibration on more problem settings, such as multi-domain few-shot classification, and more methods, such as metric-based meta-learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Novel class</head><p>Top  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D THE SIMILARITY LEVEL ANALYSIS</head><p>We found that the higher similarities between the retrieved base class distribution and the novel class ground-truth distribution, the higher the performance improvement our method will bring as shown in Table <ref type="table" target="#tab_7">9</ref>. The results in the table are under 5-way-1-shot setting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Training a classifier from few-shot features makes the classifier overfit to the few examples (Left). Classifier trained with features sampled from calibrated distribution has better generalization ability (Right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>Training procedure for an N-way-K-shot task Require: Support set features S = (xi, y) N ×K i=1 Require: Base classes' statistics {µi} |C b | i=1 , {Σi} |C b | i=1 1: Transform (xi) N ×K i=1 with Tukey's Ladder of Powers as Equation 3 2: for (xi, yi) ∈ S do 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure 2: t-SNE visualization of our distribution estimation. Different colors represent different classes. ' ' represents support set features, 'x' in figure (d) represents query set features, ' ' in figure (b)(c) represents generated features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Left: Accuracy when increasing the power in Tukey's transformation when training with (red) or without (blue) the generated features. Right: Accuracy when increasing the number of generated features with the features are transformed by Tukey's transformation (red) and without Tukey's transformation (blue).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: The effect of different values of k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The</figDesc><table><row><cell></cell><cell cols="2">class mean similar-</cell></row><row><cell cols="3">ity ("mean sim") and class vari-</cell></row><row><cell cols="3">ance similarity ("var sim") be-</cell></row><row><cell cols="3">tween Arctic fox and different</cell></row><row><cell>classes.</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Arctic fox</cell></row><row><cell></cell><cell cols="2">mean sim var sim</cell></row><row><cell>white wolf</cell><cell>97%</cell><cell>97%</cell></row><row><cell>malamute</cell><cell>85%</cell><cell>78%</cell></row><row><cell>lion</cell><cell>81%</cell><cell>70%</cell></row><row><cell>meerkat</cell><cell>78%</cell><cell>70%</cell></row><row><cell>jellyfish</cell><cell>46%</cell><cell>26%</cell></row><row><cell>orange</cell><cell>40%</cell><cell>19%</cell></row><row><cell>beer bottle</cell><cell>34%</cell><cell>11%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>5way1shot and 5way5shot classification accuracy (%) on miniImageNet and CUB with 95% confidence intervals. The numbers in bold have intersecting confidence intervals with the most accurate method. Maximum Likelihood with DC (Ours) 66.91 ± 0.17 80.74 ± 0.48 77.22 ± 0.14 89.58 ± 0.27 SVM with DC (Ours) 67.31 ± 0.83 82.30 ± 0.34 79.49 ± 0.33 90.26 ± 0.98 Logistic Regression with DC (Ours) 68.57 ± 0.55 82.88 ± 0.42 79.56 ± 0.87 90.67 ± 0.35</figDesc><table><row><cell>Methods</cell><cell cols="2">miniImageNet 5way1shot 5way5shot</cell><cell cols="2">CUB 5way1shot 5way5shot</cell></row><row><cell>Optimization-based</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MAML (Finn et al. (2017))</cell><cell cols="4">48.70 ± 1.84 63.10 ± 0.92 50.45 ± 0.97 59.60 ± 0.84</cell></row><row><cell>Meta-SGD (Li et al. (2017))</cell><cell cols="4">50.47 ± 1.87 64.03 ± 0.94 53.34 ± 0.97 67.59 ± 0.82</cell></row><row><cell>LEO (Rusu et al. (2019))</cell><cell cols="2">61.76 ± 0.08 77.59 ± 0.12</cell><cell>-</cell><cell>-</cell></row><row><cell>E3BM (Liu et al. (2020b))</cell><cell cols="2">63.80 ± 0.40 80.29 ± 0.25</cell><cell>-</cell><cell>-</cell></row><row><cell>Metric-based</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Matching Net (Vinyals et al. (2016))</cell><cell cols="4">43.56 ± 0.84 55.31 ± 0.73 56.53 ± 0.99 63.54 ± 0.85</cell></row><row><cell>Prototypical Net (Snell et al. (2017))</cell><cell cols="4">54.16 ± 0.82 73.68 ± 0.65 72.99 ± 0.88 86.64 ± 0.51</cell></row><row><cell>Baseline++ (Chen et al. (2019a))</cell><cell cols="4">51.87 ± 0.77 75.68 ± 0.63 67.02 ± 0.90 83.58 ± 0.54</cell></row><row><cell cols="3">Variational Few-shot(Zhang et al. (2019)) 61.23 ± 0.26 77.69 ± 0.17</cell><cell>-</cell><cell>-</cell></row><row><cell>Negative-Cosine(Liu et al. (2020a))</cell><cell cols="4">62.33 ± 0.82 80.94 ± 0.59 72.66 ± 0.85 89.40 ± 0.43</cell></row><row><cell>Generation-based</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MetaGAN (Zhang et al. (2018))</cell><cell cols="2">52.71 ± 0.64 68.63 ± 0.67</cell><cell>-</cell><cell>-</cell></row><row><cell>Delta-Encoder (Schwartz et al. (2018))</cell><cell>59.9</cell><cell>69.7</cell><cell>69.8</cell><cell>82.6</cell></row><row><cell>TriNet (Chen et al. (2019b))</cell><cell cols="4">58.12 ± 1.37 76.92 ± 0.69 69.61 ± 0.46 84.10 ± 0.35</cell></row><row><cell>Meta Variance Transfer (Park et al. (2020))</cell><cell>-</cell><cell>67.67 ± 0.70</cell><cell>-</cell><cell>80.33 ± 0.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>5way1shot and 5way5shot classification accuracy (%) on tieredImageNet<ref type="bibr" target="#b17">(Ren et al., 2018)</ref>. The numbers in bold have intersecting confidence intervals with the most accurate method.</figDesc><table><row><cell>Methods</cell><cell>tieredImageNet 5way1shot 5way5shot</cell></row><row><cell>Matching Net (Vinyals et al. (2016))</cell><cell>68.50 ± 0.92 80.60 ± 0.71</cell></row><row><cell cols="2">Prototypical Net (Snell et al. (2017)) 65.65 ± 0.92 83.40 ± 0.65</cell></row><row><cell>LEO (Rusu et al. (2019))</cell><cell>66.33 ± 0.05 82.06 ± 0.08</cell></row><row><cell>E3BM (Liu et al. (2020b))</cell><cell>71.20 ± 0.40 85.30 ± 0.30</cell></row><row><cell>DeepEMD (Zhang et al., 2020)</cell><cell>71.16 ± 0.87 86.03 ± 0.58</cell></row><row><cell cols="2">Maximum Likelihood with DC (Ours) 75.92 ± 0.60 87.84 ± 0.65</cell></row><row><cell>SVM with DC (Ours)</cell><cell>77.93 ± 0.12 89.72 ± 0.37</cell></row><row><cell>Logistic Regression with DC (Ours)</cell><cell>78.19 ± 0.25 89.90 ± 0.41</cell></row><row><cell cols="2">• What does calibrated distribution look like? Is it an accurate approximation for this class?</cell></row><row><cell cols="2">• How does Tukey's Ladder of Power transformation interact with the feature generations?</cell></row><row><cell cols="2">How important is each in relation to performance?</cell></row><row><cell>4.1 EXPERIMENTAL SETUP</cell><cell></cell></row><row><cell>4.1.1 DATASETS</cell><cell></cell></row></table><note>We evaluate our distribution calibration strategy on miniImageNet<ref type="bibr" target="#b16">(Ravi &amp; Larochelle (2017)</ref>), tieredImageNet(Ren et al. (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Ablation study on miniImageNet 5way1shot and 5way5shot showing accuracy (%) with 95% confidence intervals.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>5way1shot classification accuracy (%) on miniImageNet with different backbones.</figDesc><table><row><cell>Tukey transformation Training with generated features</cell><cell>miniImageNet 5way1shot 5way5shot</cell></row><row><cell></cell><cell>56.37 ± 0.68 79.03 ± 0.51</cell></row><row><cell></cell><cell>64.30 ± 0.53 81.33 ± 0.35</cell></row><row><cell></cell><cell>63.70 ± 0.38 82.26 ± 0.73</cell></row><row><cell></cell><cell>68.57 ± 0.55 82.88 ± 0.42</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>5way1shot classification accuracy (%) on miniImageNet with different baselines using distribution calibration.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>-1 base class similarity Top-2 base class similarity DC improvement</figDesc><table><row><cell>malamute</cell><cell>93%</cell><cell>85%</cell><cell>↑ 21.30%</cell></row><row><cell>golden retriever</cell><cell>85%</cell><cell>74%</cell><cell>↑ 18.37%</cell></row><row><cell>ant</cell><cell>71%</cell><cell>67%</cell><cell>↑ 9.77%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 :</head><label>9</label><figDesc>Performance improvement with respect to the similarity level between a query novel class and the most similar base classes.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base class distribution</head><p>Novel class distribution Novel class distribution after Tukey's Transformation   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A AUGMENTATION WITH NEAREST CLASS FEATURES</head><p>Instead of sampling from the calibrated distribution, we can simply retrieve examples from the nearest class to augment the support set. Table <ref type="table">7</ref> shows the comparison of training using samples from the calibrated distribution, the different number of retrieved features from the nearest class, and only using the support set. We found the retrieved features can improve the performance compared to only using the support set but can damage the performance when increasing the number of retrieved features, where the retrieved samples probably serve as noisy data for tasks targeting different classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DISTRIBUTION CALIBRATION WITHOUT NOVEL FEATURE</head><p>We calibrate the novel class mean by averaging the novel class mean and the retrieved base class means in Equation <ref type="formula">6</ref>. Table <ref type="table">8</ref> shows the distribution calibration without averaging novel feature, in which the calibrated mean is calculated as µ =  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Assume, augment and learn: Unsupervised few-shot metalearning via random labels and data augmentation</title>
		<author>
			<persName><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Chiang</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multilevel semantic feature augmentation for one-shot learning</title>
		<author>
			<persName><forename type="first">Zitian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4594" to="4605" />
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Low-shot learning via covariance-preserving adversarial augmentation networks</title>
		<author>
			<persName><forename type="first">Hang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Zareian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Low-shot visual recognition by shrinking and hallucinating features</title>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Meta-sgd: Learning to learn quickly for few shot learning</title>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Negative margin matters: Understanding margin in few-shot classification</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Prototype propagation networks (PPN) for weakly-supervised few-shot learning on category graph</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning to propagate for graph meta-learning</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An ensemble of epoch-wise empirical bayes for fewshot learning</title>
		<author>
			<persName><forename type="first">Yaoyao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Charting the right manifold: Manifold mixup for few-shot learning</title>
		<author>
			<persName><forename type="first">Puneet</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nupur</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><surname>Vineeth N Balasubramanian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Meta variance transfer: Learning to augment from the others</title>
		<author>
			<persName><forename type="first">Seong-Jin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seungju</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Won</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Insoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhwan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hae</forename><forename type="middle">Beom</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jae-Joon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Diversity helps: Unsupervised few-shot learning via distribution shift-based data augmentation</title>
		<author>
			<persName><forename type="first">Tiexin</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning Representations by Back-propagating Errors</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR, abs/1409.0575</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dushyant</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">One-shot learning with a hierarchical nonparametric bayesian model</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML workshop</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Delta-encoder: an effective sample synthesis method for few-shot object recognition</title>
		<author>
			<persName><forename type="first">Eli</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivan</forename><surname>Harary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mattias</forename><surname>Marder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Bronstein</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Exploratory data analysis. Addison-Wesley Series in Behavioral Science</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<ptr target="https://cds.cern.ch/record/107005" />
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Low-shot learning from imaginary data</title>
		<author>
			<persName><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Caltech-UCSD Birds 200</title>
		<author>
			<persName><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>CNS-TR-2010-001</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Feature generating networks for zero-shot learning</title>
		<author>
			<persName><forename type="first">Yongqin</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeynep</forename><surname>Akata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deepemd: Few-shot image classification with differentiable earth mover&apos;s distance and structured classifiers</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Variational few-shot learning</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenglong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Metagan: An adversarial approach to few-shot learning</title>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
