<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaborative learning with corrupted labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-02-13">February 13, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yulin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Gao</forename><surname>Huang</surname></persName>
							<email>gaohuang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shiji</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Neural</forename><surname>Networks</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Training</forename><surname>Samples</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Collaborative learning with corrupted labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-02-13">February 13, 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.neunet.2020.02.010</idno>
					<note type="submission">Received date : 29 March 2019 Revised date : 14 February 2020 Accepted date : 18 February 2020 Preprint submitted to Neural Networks</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep neural networks</term>
					<term>Corrupted labels</term>
					<term>Robustness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks (DNNs) have achieved remarkable success in the past few years <ref type="bibr" target="#b9">(He et al., 2016;</ref><ref type="bibr" target="#b11">Huang et al., 2017;</ref><ref type="bibr" target="#b37">Simonyan and Zisserman, 2015;</ref><ref type="bibr" target="#b32">Ren et al., 2015;</ref><ref type="bibr" target="#b37">Silver et al., 2016;</ref><ref type="bibr" target="#b36">Schmidhuber, 2015)</ref>. They can learn highly generalizable representations when fueled by large scale datasets with precise annotations, such as ImageNet <ref type="bibr" target="#b3">(Deng et al., 2009)</ref> and COCO <ref type="bibr" target="#b23">(Lin et al., 2014)</ref>. However, collecting high-quality labeled data is usually very time-consuming and costly <ref type="bibr" target="#b43">(Tao and Dai, 2019;</ref><ref type="bibr" target="#b44">Tavanaei et al., 2019)</ref>. In contrast, obtaining coarsely labeled data, e.g., images retrieved by search engines <ref type="bibr" target="#b21">(Li et al., 2017)</ref>, web social data, Flickr tags <ref type="bibr" target="#b45">(Vahdat, 2017)</ref>, is a relatively easier task. Unfortunately, DNNs are easy to overfit the label noise in the dataset, and thus achieve poor generalization performance. In fact, it has been proved that DNNs have the capacity to overfit even completely random labels <ref type="bibr" target="#b49">(Zhang et al., 2017)</ref>. Therefore, training DNNs reliably on datasets with corrupted labels remains challenging <ref type="bibr" target="#b38">(Sogawa et al., 2013;</ref><ref type="bibr" target="#b50">Zhang and Sabuncu, 2018)</ref>.</p><p>To address the aforementioned challenge, a number of methods have been proposed in recent years <ref type="bibr" target="#b4">(Frenay and Verleysen, 2014;</ref><ref type="bibr" target="#b5">Ghosh et al., 2017;</ref><ref type="bibr" target="#b31">Ren et al., 2018;</ref><ref type="bibr" target="#b18">Kumar et al., 2010;</ref><ref type="bibr" target="#b20">Li et al., 2018;</ref><ref type="bibr" target="#b13">Jiang et al., 2018;</ref><ref type="bibr" target="#b51">Zhao et al., 2019)</ref>. Popular approaches include designing robust loss functions <ref type="bibr" target="#b5">(Ghosh et al., 2017)</ref>, reweighting samples <ref type="bibr" target="#b31">(Ren et al., 2018)</ref>, and learning with meta-learning <ref type="bibr" target="#b20">(Li et al., 2018;</ref><ref type="bibr" target="#b13">Jiang et al., 2018)</ref>. However, existing approaches mainly focus on identifying and leveraging only correctly annotated samples, and meantime filtering out mislabeled data or reducing its influence. In fact, mislabeled data may contain useful information that could further improve the performance of the model. Ideally, if we could map some of the mislabeled data to their true labels, better generalization can be expected.</p><p>In this paper, we propose a collaborative learning (co-learning) algorithm, to gradually refine the labels in datasets with corrupted labels, such that the model could leverage both correctly labeled data and mislabeled data. Co-learning is motivated by the self-training algorithm <ref type="bibr" target="#b52">(Zhu, 2006;</ref><ref type="bibr" target="#b22">Li et al., 2008;</ref><ref type="bibr" target="#b34">Rosenberg et al., 2005;</ref><ref type="bibr" target="#b33">Riloff and Jones, 1999)</ref>, which uses the prediction of models with high confidence to produce pseudo labels for unlabeled samples. The algorithm then alternates between training the model and updating the pseudo labels.</p><p>Similarly, co-learning iteratively finds samples with high prediction confidence, and changes their labels from the original ones to the model prediction. However, the proposed algorithm differs from self-training in several important aspects. First, we noticed that deep models can easily overfit most of the training samples with high confidence -even those with wrong labels, rendering the confidence-based relabelling mechanism ineffective. Inspired by the intriguing phenomenon that DNNs tend to learn meaningful patterns before overfitting to noise during the course of training <ref type="bibr" target="#b0">(Arpit et al., 2017)</ref>, we trigger the relabelling operation early in the training stage, before the network starting to overfit noise. Such an on-the-fly relabelling process not only is more efficient than self-training, but also ensures the model prediction confidence is reliable. Second, the relabelling operation in the proposed algorithm is less aggressive than self-training. We linearly increase the importance of the pseudo labels, while gradually decrease the importance of original labels, to create a safe transit for the model from the latter to the former. Third, to prevent the model from amplifying its own mistakes, which is common in self-training, we adopt a network with two separate branches, each of which generates pseudo labels for the other. The two branches tend to make different mistakes with stochastic training techniques like dropout <ref type="bibr" target="#b19">(Lan et al., 2018;</ref><ref type="bibr" target="#b41">Szegedy et al., 2016;</ref><ref type="bibr" target="#b12">Huang et al., 2018)</ref>. Therefore, co-learning is stable even a large portion of the labels are corrupted.</p><p>We validate co-learning on several widely used image classification benchmarks including CIFAR, SVHN and MNIST under uniform and background label noise. Experimental results show that our method is able to significantly improve the robustness of DNNs compared with other state-of-the-art algorithms. Notably, co-learning is effective even a validation set with true labels is absent.</p><p>The rest of this paper is organized as follows. Section 2 reviews related work on this topic. Section 3 presents the network architecture and training methods for co-learning in detail. Section 4 presents our experimental results and empirical analysis, and Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Many approaches have been proposed to improve the robustness of DNNs against label noise. In this section, we give a brief review of relative work.</p><p>Estimating noise distribution. Many existing work focused on estimating the noise distribution. To make the problem tractable, a common assumption is that the distribution of corrupted labels only depends on their true labels, but independent of the samples. Based on this assumption, a confusion matrix can be introduced to describe the label noise <ref type="bibr" target="#b39">(Sukhbaatar et al., 2018)</ref>, and many existing work is dedicated to estimate this matrix <ref type="bibr" target="#b29">(Patrini et al., 2017;</ref><ref type="bibr" target="#b10">Hendrycks et al., 2018;</ref><ref type="bibr" target="#b14">Jindal et al., 2016)</ref>. As true labels can be seen as latent variables, EM-based algorithms are also proposed to handle the label noise with probabilistic models <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven, 2017;</ref><ref type="bibr" target="#b15">Khetan et al., 2018;</ref><ref type="bibr" target="#b47">Xiao et al., 2015)</ref>. In addition, recent work also models the label noise via more complicated distributions, which takes the instances distribution into consideration <ref type="bibr" target="#b45">(Vahdat, 2017)</ref>. However, estimating the label noise distribution is usually challenging in practice, especially when deep learning approaches are involved. Moreover, model-based methods may suffer from a lack of representation power and can not handle complex conditions well.</p><p>Sample reweighting and pruning. Another popular approach to handle corrupted labels is sample reweighting or pruning. <ref type="bibr" target="#b31">Ren et al. (2018)</ref> propose a meta-learning method to reweight training samples based on their gradient directions. <ref type="bibr" target="#b13">Jiang et al. (2018)</ref> train an auxiliary LSTM-based MentorNet to reweight samples. Both of them need an additional set of samples with true labels to identify wrong labels. <ref type="bibr" target="#b26">Liu and Tao (2014)</ref> propose an optimal importance weighting paradigm for robust training on corrupted labels, based on the belief that samples with high loss values are likely to be unreliable and should be down-weighted or pruned <ref type="bibr" target="#b50">(Zhang and Sabuncu, 2018;</ref><ref type="bibr" target="#b18">Kumar et al., 2010;</ref><ref type="bibr" target="#b28">Northcutt et al., 2017;</ref><ref type="bibr" target="#b2">Chang et al., 2017)</ref>. Adding pre-defined curriculums in loss functions to dynamically adjust weights of samples is also proved to be effective <ref type="bibr" target="#b25">(Lin et al., 2017;</ref><ref type="bibr" target="#b13">Jiang et al., 2018;</ref><ref type="bibr" target="#b1">Bengio et al., 2009)</ref>. From the perspective of loss functions, many robust forms are designed to reduce the effect of label noise <ref type="bibr" target="#b50">(Zhang and Sabuncu, 2018;</ref><ref type="bibr" target="#b5">Ghosh et al., 2017)</ref>. One disadvantage of these methods is that they tend to ignore the information of samples with wrong Branch I learns from both the original partially corrupted labels and the pseudo labels given by Branch II. A dynamic loss function is proposed for Branch I to perform a linear transit from the former to the latter. The two branches work collaboratively to recover true labels of mislabeled samples and prevent amplifying their own mistakes meanwhile. Through co-learning, the model could leverage both correctly labeled data and mislabeled data to improve its performance.</p><p>labels. The proposed co-learning algorithm can effectively map some of the mislabeled samples to their true labels, and involve them in the training process to achieve better performance.</p><p>Correcting wrong labels. There are also approaches aiming to correct wrong labels as our co-learning algorithm. <ref type="bibr" target="#b30">Reed et al. (2014)</ref> combine original labels and model predictions linearly in training target. But here the combination ratio is fixed as a hyper-parameter, which is not flexible enough to model each specific sample. <ref type="bibr">Han et al. (2018)</ref> let two networks teach each other using samples that are highly confident. But without a proper collaborative mechanism, the two networks may result in similar errors and negatively influence each other, especially for the training set with a large portion of corrupted labels. <ref type="bibr" target="#b46">Veit et al. (2017)</ref> trains an auxiliary cleaning network jointly with a classifier to clean up labels. Generally, most existing work does not pay much attention to correcting corrupted labels. We argue that instead of pruning or down-weighting samples that are likely to be mislabeled, we could dynamically refine the labels to exploit more information from the dataset. Compared with existing approaches which also aim to leverage mislabeled samples, we have developed novel techniques to prevent the model from amplifying its own error, leading to an algorithm that could hand datasets with high label noise rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Collaborative Learning</head><p>In this section, we present the co-learning algorithm in detail, including the network architecture, the relabeling mechanism and the dynamic loss function. We also discuss our motivations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>We give an overview of the proposed co-learning algorithm in Figure <ref type="figure" target="#fig_0">1</ref>. Co-learning iteratively refines the labels of training samples and updates model parameters, in a way similar to self-training <ref type="bibr" target="#b52">(Zhu, 2006;</ref><ref type="bibr" target="#b22">Li et al., 2008;</ref><ref type="bibr" target="#b34">Rosenberg et al., 2005;</ref><ref type="bibr" target="#b33">Riloff and Jones, 1999)</ref>. However, in order to prevent the deep model from overfitting to the noise easily and amplifying its own mistakes, we introduce two innovations. First, we design a deep network architecture with two separate branches, (Branch I (B1) and Branch II (B2) as shown in Figure <ref type="figure" target="#fig_0">1</ref>), and let them generate pseudo labels to supervise each other. As the model is trained with stochastic techniques like dropout, two separate branches tend to make different mistakes <ref type="bibr" target="#b19">(Lan et al., 2018;</ref><ref type="bibr" target="#b41">Szegedy et al., 2016;</ref><ref type="bibr" target="#b12">Huang et al., 2018)</ref>. Collaboratively they could significantly reduce the risk of amplifying a branch's own mistakes and achieve stronger robustness. Second, we introduce a dynamic loss function that generate pseudo labels on-the-fly according to the model's predictions, and gradually shift from receiving supervision from the original labels to learning from the pseudo labels. It is inspired by the intriguing phenomenon observed by <ref type="bibr" target="#b0">Arpit et al. (2017)</ref> that DNNs tend to learn meaningful patterns before overfitting to corrupted labels. With the dynamic loss function, co-learning can quickly learn generalization representations from the training set, while gradually correcting mislabeled data, and further learning from the refined dataset. We introduce the main components of co-learning in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Network Architecture</head><p>The proposed network architecture is shown in Figure <ref type="figure" target="#fig_0">1</ref>. The two branches, i.e., B1 and B2, have identical structure and share a common stem sub-network. They are trained simultaneously, but with different loss functions. Such a structure has at least two advantages: 1) Due to diverse stochastic regularization mechanisms (e.g. dropout) adopted to train the models, the two branches tend to converge to different local minima and make different mistakes <ref type="bibr" target="#b19">(Lan et al., 2018;</ref><ref type="bibr" target="#b41">Szegedy et al., 2016)</ref>. Therefore, pseudo labels generated from each other tend to be more reliable. It is more robust than using a single model as in traditional self-training, which usually suffers from the own-mistake amplification phenomenon; 2) The common stem network receives gradients from both branches, which contributes to learning more robust low-level patterns. It is also computationally more efficient than training two completely different networks.</p><p>In our experiments, the network is modified from classical convolutional networks such as ResNets <ref type="bibr" target="#b9">(He et al., 2016)</ref> and Wide ResNets <ref type="bibr" target="#b48">(Zagoruyko and Komodakis, 2016)</ref>. We simply duplicate the final convolutional group (conv4) to build the two branches B1 and B2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Relabelling Mechanism</head><p>Aiming at obtaining pseudo labels with higher label accuracy compared with original corrupted labels, we implement a widely-used confidence based thresholding mechanism, shown on the right half of Figure <ref type="figure" target="#fig_0">1</ref>. The method picks samples with high prediction confidence, and changes their original labels to model predictions. As mentioned, we trigger the relabelling operation early in the training process, before the model overfit to label noise. Therefore, the model predictions are reliable to correct wrong labels.</p><p>Consider training a deep model on the training set D = {(x 1 , y 1 ) , . . . , (x n , y n )}, where x i denotes i th train sample and y i ∈ Y = {1, . . . , C} denotes its original label over a total number of C classes. Let θ stem , θ 1 and θ 2 denote the parameters of the stem network, B1 and B2. Branch θ k outputs classification prediction confidence p k ic for a sample x i on c th class through a softmax layer:</p><formula xml:id="formula_0">p k ic = e g c (x i ,θstem,θ k ) C j=1 e g j (x i ,θstem,θ k ) , c ∈ Y, k ∈ {1, 2},<label>(1)</label></formula><p>where g c (x i , θ stem , θ k ) is the classification results for the c th class output by branch k with input x i , and p k i corresponds to the softmax probability vector.</p><p>Then the predictions of two branches are used to update the labels of training samples by:</p><formula xml:id="formula_1">ỹk i =    arg max c∈Y p k ic max c∈Y p k ic ≥ η y i max c∈Y p k ic &lt; η , k ∈ {1, 2},<label>(2)</label></formula><p>where ỹk i is the pseudo label for input x i generated by branch k that takes the model prediction into account. The confidence threshold η is a hyper-parameter to determine whether the model prediction should be used to generate pseudo labels.</p><p>Intuitively, the relabelling mechanism improves the robustness against label noise in a way similar to the bootstrap algorithm <ref type="bibr" target="#b35">(Rubin, 1981)</ref>. Based on the model's predictions, pseudo labels with less noise compared with the original training set can be obtained. These pseudo labels are then applied to update parameters reciprocally. Consequently, the training set is gradually refined and the model could actively leverage all the training samples, even those originally associated with wrong labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>J o u r n a l P r e -p r o o f</p><p>Journal Pre-proof</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Dynamic Loss Function</head><p>The two branches are trained simultaneously with different loss functions, which are shown as L 1 i and L 2 i in Figure <ref type="figure" target="#fig_0">1</ref>. They produce pseudo labels to supervise each other.</p><p>Algorithm 1 Training algorithm for co-learning 1: Input: D, η, λ 2: Initialization: Randomly initialize θ stem , θ 1 and θ 2 3: for t = 0 to T do 4:</p><formula xml:id="formula_2">for minibatch {(x i , y i )} N in D do 5: Compute p 1 i , p 2 i for each (x i , y i ) 6: if t ≤ T 0 : /* Warm-up Stage */ 7: L = 1 N N i=1 L warm−up i 8:</formula><p>else: /* Co-learning Stage */ 9:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compute ỹ1</head><p>i , ỹ2 i using Eq. ( <ref type="formula" target="#formula_1">2</ref>)</p><formula xml:id="formula_3">10: L = 1 N N i=1 (L 1 i + L 2 i ) 11: end if 12: θ k ← θ k − α t ∇ θ k L, k ∈ {1, 2} 13: θ stem ← θ stem − αt 2 ∇ θstem L 14:</formula><p>end for 15: end for 16: Output: θ stem , θ 1 First, the Branch II (B2) learns completely from the pseudo labels generated by Branch I (B1), which can be viewed as learning from a less noisy dataset. Meanwhile, its gradient will be back-propagated to the common stem network to learn general low-level features. Specifically, the loss function is given by</p><formula xml:id="formula_4">L 2 i = L(ỹ 1 i , p 2 i ), (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where L is the standard cross-entropy loss (L(y i , p i ) = −ln(p iyi )).</p><p>Second, the Branch I (B1) is supervised by a dynamic loss function. The motivation is that we find that naively implementing the ing algorithm may create wrong labels permanently, which will never be able to recover (experimental results are presented in Section 4.4). Therefore, we design a dynamic loss function to facilitate a safe transit from learning from original labels to learning from pseudo labels. The importance of original labels decreases linearly during the training process, while the importance of pseudo labels gradually rises: Note that λ can be larger than 1, where B1 is only supervised by pseudo labels in the last few epochs.</p><formula xml:id="formula_6">L 1 i = (1 − r(t)) * L(y i , p 1 i ) + r(t) * L(ỹ 2 i , p 1 i ),<label>(4)</label></formula><formula xml:id="formula_7">r(t) = min{λ * t − T 0 T − T 0 , 1},<label>(5)</label></formula><p>Warm-up stage. A precondition of co-learning is that neural networks have obtained discriminative ability to some extent. Apparently, it is meaningless to perform relabelling at the very beginning of training, when the model predictions are close to random. Therefore, the first 10% epochs of the training process are introduced as the warm-up stage, when only L(y i , p k i ) is used for training:</p><formula xml:id="formula_8">L warm−up i = L(y i , p 1 i ) + L(y i , p 2 i ).<label>(6)</label></formula><p>It's observed that involving warm-up stage contributes to a stable training process with good generalization performance.</p><p>J o u r n a l P r e -p r o o f</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Journal Pre-proof</head><p>We summarize the co-learning algorithm in Alg 1. In both the warm-up stage and the co-learning stage, the two branches are trained simultaneously. As the stem network θ stem receives gradients from both branches, the learning rate to update its parameters is half of that of the two branches. Once the training completes, either branch can be deployed as the final classifier as they would converge to having similar performance. In our experiments, we always use the results of B1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head><p>In this section, we empirically evaluate the effectiveness of the proposed co-learning method, and compare it against state-of-the-art robust learning algorithms, on several image classification tasks. We test our algorithm under both uniform and background label noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup Details and Baselines</head><p>Dataset. The two CIFAR datasets <ref type="bibr" target="#b16">(Krizhevsky and Hinton, 2009)</ref> consist of 32x32 colored natural images with 10 classes (CIFAR-10) and 100 classes (CIFAR-100), respectively. Both datasets contain 50,000 images for training and 10,000 for testing. For preprocessing, the data is normalized with channel means and standard deviations. We adopt a standard data augmentation scheme widely-used for them: random 32x32 cropping with 4-pixel padded and random horizontal flipping <ref type="bibr" target="#b13">(Jiang et al., 2018;</ref><ref type="bibr" target="#b50">Zhang and Sabuncu, 2018;</ref><ref type="bibr" target="#b29">Patrini et al., 2017;</ref><ref type="bibr" target="#b42">Tanaka et al., 2018)</ref>. The MNIST dataset consists of 32x32 images of handwritten digits with 10 classes, 60000 for training and 10000 for testing. Following <ref type="bibr" target="#b50">Zhang and Sabuncu (2018)</ref>, we apply exactly the same pre-processing and augmentation techniques on MNIST as on CIFAR. The Street View House Numbers (SVHN) dataset <ref type="bibr" target="#b27">(Netzer et al., 2011)</ref> consists of 32x32 colored images of digits. 73,257 images for training, 26,032 images for testing and 531,131 images for additional training are provided. Following <ref type="bibr" target="#b11">Huang et al. (2017)</ref>, we use all the training data without any data augmentation. For all experiments, we test the performance of the network on the test sets provided by the datasets. Some of our experiments on CIFAR use a correctly annotated validation set to tune the values of the hyper-parameters. In these cases, we hold out 5000 images from the training set as the validation set, and use the remaining 45000 images to train the network. For experiments without the validation set, we use the same 45000 images for training. On MNIST and SVHN, we use all the provided training data for training.</p><p>Noise settings. Following <ref type="bibr" target="#b31">Ren et al. (2018)</ref>, we design two label noise distribution forms: 1) Uniform: True label is uniformly replaced by other labels with the probability ρ (Noise rate). 2) Background : True label is replaced by a single background label with the probability ρ. This type of noise is pretty common and challenging as it's a combination of label imbalance and label noise <ref type="bibr" target="#b31">(Ren et al., 2018)</ref>.</p><p>Baselines. Our method is compared with several state-of-the-art methods to make DNN robust against label noise. b1) MentorNet <ref type="bibr" target="#b13">(Jiang et al., 2018)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof</p><p>Table <ref type="table">1</ref>: Test accuracy on CIFAR with uniform label noise. We report the result of the last epoch. The noise rate ρ denotes the ratio of wrong labels. For self-paced learning and MentorNet, we cite results reported in <ref type="bibr" target="#b13">(Jiang et al., 2018)</ref>. For other methods, we report results of our implementations. Following <ref type="bibr" target="#b13">(Jiang et al., 2018)</ref> For b1) and b2), we directly cite the results reported in <ref type="bibr" target="#b13">(Jiang et al., 2018)</ref>. For a fair comparison, we also use ResNets with wide filters mentioned in their paper and apply exactly the same training details as <ref type="bibr" target="#b13">(Jiang et al., 2018)</ref>. The conv4 group of the network is duplicated as B1 and B2. For other methods, we report the results of our implementations. For b3), we set q = 0.7, which is reported to be the best setting in <ref type="bibr" target="#b50">(Zhang and Sabuncu, 2018)</ref>. For b4), we assume that noise rate has been known, and initialize the noise adaptation layer with uniform noise as suggested in <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven, 2017)</ref>. For b5), we use the best β (β = 0.8 for Reed-hard and β = 0.95 for Reed-soft) reported in <ref type="bibr" target="#b30">(Reed et al., 2014)</ref>. For b6), we use hyper-parameters recommended by <ref type="bibr">Han et al. (2018)</ref>.</p><p>Training details. Wide-ResNet (WRN) <ref type="bibr" target="#b48">(Zagoruyko and Komodakis, 2016)</ref> and ResNet-32 <ref type="bibr" target="#b9">(He et al., 2016)</ref> are implemented in this paper. WRN is used in experiments on CIFAR under uniform label noise. ResNet-32 is used in experiments on MNIST and SVHN under uniform label noise and experiments under background label noise. The models are trained with a Nesterov momentum <ref type="bibr" target="#b40">(Sutskever et al., 2013)</ref> of 0.9, a dropout rate of 0.3 and a l2 weight decay of 1e-4. The mini-batch size is set as 100 for a total number of 160 epochs. The learning rate is set to 0.1 initially, and is divided by 10 after the 80 th and 120 th epoch, respectively.</p><p>Hyper-parameter. As MentorNet-DD <ref type="bibr" target="#b13">(Jiang et al., 2018)</ref> uses additional samples with accurate labels to learn data-driven curriculums, following them we also split 5000 images from the training set as our validation set to tune hyper-parameters. The details have been presented above. All results using this validation set are presented in BLUE. With this setting, η is selected from {0.2, 0.3, 0.4} and λ is selected from [0.5, 1.5]. As there is usually no access to a validation set with clean labels to search for optimal hyper-parameters, we also report results with fixed hyper-parameters. These results are compared with methods without using a clean validation set. Under all uniform noise except ρ = 0.8, we use η = 0.2 and λ = 1.3, which gives a good balance between learning from original labels and pseudo labels. For situations with uniform noise ρ = 0.8 and background noise, as they are extremely noisy, we use η = 0.3 and λ = 0.8. Empirically, we observe that with smaller λ, the model tends to overfit the original label noise. With larger λ, on the other hand, overfitting rarely happens, but the risk of generating wrong pseudo labels increases, which also degrades the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results under Uniform Noise</head><p>Experimental results on CIFAR under uniform noise are summarized in Table <ref type="table">1</ref>. One can observe that co-learning outperforms other methods under most of the settings. For example, under noise rate ρ = 0.4, co-learning based on the WRN-58 model achieves 89.4% and 72.8% test accuracy on CIFAR-10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof  and CIFAR-100, respectively, which are significantly higher than that obtained by Self-paced learning and MentorNet-PD. Co-learning based on the WRN-28 yields even more notable improvement over competitive baselines. On CIFAR-10 with ρ = 0.6, co-learning outperforms the best baseline algorithm co-teaching by 5.7% (80.0% v.s. 74.3%) in terms of test accuracy. On the more challenging CIFAR-100 dataset with 100 classes, co-learning also outperforms state-of-the-art approaches. For ρ = 0.6, co-learning enhances the test accuracy by 3.6% compared with the L q loss. We do observe two cases (WRN-58 on CIFAR-10 under noise rate 0.8, and WRN-28 on CIFAR-100 under noise rate 0.8) where our algorithm does not yield competitive results. We conjecture that when the noise rate is extremely high, co-learning may generate wrong pseudo labels, and overfit to them. Nevertheless, in the rest cases co-learning gives the highest test accuracy among all the algorithms, demonstrating remarkable robustness.  <ref type="bibr" target="#b6">(Goldberger and Ben-Reuven, 2017)</ref> Reed soft <ref type="bibr" target="#b30">(Reed et al., 2014)</ref> 88.0% 73.4% Reed hard <ref type="bibr" target="#b30">(Reed et al., 2014)</ref> 85.9% 64.1% Lq loss <ref type="bibr" target="#b50">(Zhang and Sabuncu, 2018)</ref> 87.2% 63.0% Co-learning 88.2% 82.9%</p><p>Moreover, although the performance of all methods degrades when ρ rises, co-learning is relatively more robust against high noise rate. Its test accuracy only declines by 12.5% when ρ increases from 0.2 to 0.6 on the CIFAR-10 dataset (with WRN-28).</p><p>Empirical results on MNIST and SVHN are shown in Table <ref type="table">.</ref> 2. Consistent observations to CIFAR that co-learning significantly outperforms baselines in most situations can also be obtained on these two datasets. On SVHN with ρ = 0.6 and ρ = 0.8, co-learning yields improvements of 6.9% and 14.9% in terms of the test accuracy compared with the best baselines, L q J o u r n a l P r e -p r o o f Journal Pre-proof loss and Reed-hard, respectively. Though L q loss and co-teaching show competitive performance versus co-learning with low noise rates, co-learning achieves much higher test accuracies than them with larger ρ.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> presents the test accuracy of the algorithms during the training process on CIFAR and MNIST. We can observe that co-learning shows high robustness against overfitting. The test accuracy of Reed-hard, Reed-soft and S-model decreases right after the learning rate drops. Their generalization performance only slightly surpasses that of the basic model. Notably, among these algorithms, L q loss performs the best. It even achieves slightly higher test accuracy than co-learning around the 80 th epoch on CIFAR. However, its accuracy gradually drops afterwards, which indicates overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results under Background Noise</head><p>Results of co-learning and other state-of-the-art algorithms under background label noise on CIFAR-10 are presented in Table <ref type="table" target="#tab_3">3</ref>. Co-learning ranks the top among all the methods, showing its robustness against background noise. Notably, although L q loss performs effective under uniform label noise, it fails to achieve competitive results under background label noise. The reason might be that its mechanism of focusing on samples with small loss value makes it less stable for imbalance datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>To get a better understanding of the components in co-learning, we test the performance of several variants under 40% uniform label noise on CIFAR-10, with a WRN-28 model and the same training configurations as above: (1) Basic applies a standard WRN-28 and the cross entropy loss. (2) Co-learning implements the full co-learning algorithm illustrated above. (3) Without warm-up skips the warm-up stage by setting T 0 to 0. (4) Single B1 and Single B2 use only the single B1 or B2 as high-level branch (trained with its own loss), respectively. Relabelling is based on its own predictions. ( <ref type="formula" target="#formula_7">5</ref> The test and training accuracy of these variants are shown in Figure <ref type="figure" target="#fig_3">3</ref>. Several interesting observations can be obtained from the plots. Firstly, basic DNNs exhibit severe overfitting to label noise, with the train accuracy approaching 100% while the test accuracy dropping to approximate 60%. On the other hand, co-learning achieves the highest test accuracy and get a train accuracy at about 60%, which matches the ratio of correctly labeled data in the training set. This shows that co-learning learns to refined the label effectively, without overfitting to the mislabeled samples. Secondly, the warm-up stage has relatively small effect on the robustness of the model. However, it indeed improves the final test accuracy noticeably. Thirdly, Single B2 and Double B2s fail to learn meaningful representations right after the warm-up stage. This might be explained by the fact that B2 learns completely from pseudo labels, and its errors are amplified significantly. Figure <ref type="figure">4</ref>: Performance of B1 and B2 under 40% uniform noise. Our method performs little overfitting to error labels and fit only the correct distribution, therefore improving robustness. This is realized through a bootstrap manner, proven by the increasing accuracy of pseudo labels.</p><p>Finally, although the training of B1 involves both pseudo labels and original labels, Single B1 and Double B1s still overfit the noise severely.</p><p>To further understand the co-learning algorithm, we split the training data into two subsets: correctly labeled data and mislabeled data. Figure <ref type="figure">4</ref>(a) shows the training accuracy on the two subsets for basic DNNs, B1 and B2 of co-learning under 40% uniform label noise on the CIFAR-10 dataset.</p><p>The results show that although basic DNNs are able to fit correct labels perfectly, it also learns to fit the randomly labeled samples with almost 100% accuracy. This phenomenon is in line with that observed by <ref type="bibr" target="#b49">Zhang et al. (2017)</ref> that DNNs are able fit random noise. We also observed similar results as in <ref type="bibr" target="#b0">(Arpit et al., 2017)</ref> that DNNs tend to learn meaningful patterns from correctly labeled samples firstly, while overfit to noise in a later stage. In contrast, co-learning achieves high training accuracy on the subset of correctly labeled data, while spends little effort on fitting the wrong labels. presents the accuracy of pseudo labels generated from B1 and B2, and the test accuracy of B1 and B2. We can see that the accuracy of pseudo labels steadily increases throughout the training process, and is slightly higher than the prediction accuracy from the two branches. This demonstrates that the bootstrap mechanism of co-learning is indeed effective. Predictions from the model generate pseudo labels with higher accuracy, which, in turn, are applied to train the model and contribute to predictions with higher test accuracy. In this way, the model leverages both correctly labeled and mislabeled samples, and the generalization performance is improved iteratively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Hyper-parameter Sensitivity</head><p>We further study the hyper-parameter sensitivity of co-learning in this subsection. We test the model performance by varying the values of η and λ in the co-learning algorithm, under 40% label noise on MNIST. The results are shown in Figure <ref type="figure" target="#fig_5">5</ref>. From the results we can see that the model performance is stable when η ranges from 0.2 to 0.4, which indicates η is a relatively less sensitive hyper-parameter. Co-learning performs robust against the change of λ when λ is small and its performance reaches the peak when λ approaches 1. In contrast, the test accuracy degrades significantly when λ grows larger than 1.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this paper, we proposed a co-learning algorithm to train DNNs robustly on datasets with corrupted labels. Inspired by the self-training algorithm, we refine the corrupted labels according to the model's prediction confidence. To obtain reliable pseudo labels without overfitting to label noise, we implement a relabelling operation on-the-fly and realize a less aggressive shift from learning from original labels to learning from pseudo labels. To avoid amplifying a model's own mistakes, we design a deep network with two separate branches and let them generate pseudo labels to supervise each other in a collaborative manner. Through co-learning, the model is able to safely recover the true labels of mislabeled data, and learn from them. Empirically, co-learning obtains significant better results than state-of-the-art algorithms with various deep models and different datasets.</p><p>In the future, we will focus on implementing the co-learning algorithm with various types of label noise, other than uniform noise and background noise. In addition, we will explore involving interesting mechanisms like adversarial attacks in co-learning to further improve its performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of the co-learning algorithm. The network has two separate branches (Branch I and Branch II) with identical network structures. They share a common stem network, but are trained with different loss functions, and thus learn their own high-level features. Branch II are supervised by pseudo labels generated by Branch I, which contains less label noise.Branch I learns from both the original partially corrupted labels and the pseudo labels given by Branch II. A dynamic loss function is proposed for Branch I to perform a linear transit from the former to the latter. The two branches work collaboratively to recover true labels of mislabeled samples and prevent amplifying their own mistakes meanwhile. Through co-learning, the model could leverage both correctly labeled data and mislabeled data to improve its performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where t, T and T 0 denote the current training epoch, the total number of training epochs and the start epoch 140 of the co-learning stage. The hyper-parameter λ determines the ratio held by pseudo labels in this procedure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Test accuracy curves of different methods over training epochs under 40% uniform label noise</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>)Figure 3 :</head><label>3</label><figDesc>Figure 3: Ablation study results with WRN-28 on CIFAR-10 under 40% uniform label noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>labels' accuracy and the test accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Sensitivity of co-learning on MNIST</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>10 J o u r n a l P r e -p r o o f Journal Pre-proof</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, results presented in BLUE use 5000 images with true labels as a validation set to select hyper-parameters, while others use constant hyper-parameters. The best results in each group are bold-faced.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Noise Rate ρ</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Method</cell><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell></cell><cell cols="2">CIFAR-100</cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell></row><row><cell></cell><cell>Basic</cell><cell>81.2%</cell><cell>57.6%</cell><cell>42.3%</cell><cell>17.5%</cell><cell>63.2%</cell><cell>47.1%</cell><cell>29.2%</cell><cell>11.1%</cell></row><row><cell></cell><cell>S-Model (Goldberger and Ben-Reuven, 2017)</cell><cell>83.0%</cell><cell>64.2%</cell><cell>43.3%</cell><cell>19.3%</cell><cell>49.1%</cell><cell>43.7%</cell><cell>28.4%</cell><cell>9.4%</cell></row><row><cell>WRN-28</cell><cell>Reed soft(Reed et al., 2014) Reed hard(Reed et al., 2014)</cell><cell>83.3% 80.6%</cell><cell>63.7% 62.8%</cell><cell>43.6% 42.8%</cell><cell>18.6% 34.0%</cell><cell>63.3% 63.6%</cell><cell>51.2% 47.8%</cell><cell>33.6% 29.9%</cell><cell>13.5% 11.7%</cell></row><row><cell></cell><cell>Lq loss(Zhang and Sabuncu, 2018) Co-teaching(Han et al., 2018)</cell><cell>92.3% 85.1%</cell><cell>85.2% 86.1%</cell><cell>63.7% 74.3%</cell><cell>26.5% 23.7%</cell><cell>73.3% 61.4%</cell><cell>67.5% 58.5%</cell><cell>56.2% 43.6%</cell><cell>23.9% 20.8%</cell></row><row><cell></cell><cell>Co-learning</cell><cell>92.5%</cell><cell>90.7%</cell><cell>80.0%</cell><cell>43.5%</cell><cell>73.5%</cell><cell>67.9%</cell><cell>59.8%</cell><cell>12.1%</cell></row><row><cell></cell><cell>Self-paced (Kumar et al., 2010)</cell><cell>89%</cell><cell>85%</cell><cell>-</cell><cell>28%</cell><cell>70%</cell><cell>55%</cell><cell>-</cell><cell>13%</cell></row><row><cell></cell><cell>MentorNet-PD(Jiang et al., 2018)</cell><cell>91%</cell><cell>77%</cell><cell>-</cell><cell>33%</cell><cell>72%</cell><cell>56%</cell><cell>-</cell><cell>14%</cell></row><row><cell>WRN-58</cell><cell>Co-learning</cell><cell>93.1%</cell><cell>89.4%</cell><cell>-</cell><cell>18.9%</cell><cell>74.9%</cell><cell>72.8%</cell><cell>-</cell><cell>30.9%</cell></row><row><cell></cell><cell>MentorNet-DD(Jiang et al., 2018)</cell><cell>92%</cell><cell>89%</cell><cell>-</cell><cell>49%</cell><cell>73%</cell><cell>68%</cell><cell>-</cell><cell>35%</cell></row><row><cell></cell><cell>Co-learning</cell><cell>93.3%</cell><cell>91.2%</cell><cell>-</cell><cell>49.2%</cell><cell>75.8%</cell><cell>73.0%</cell><cell>-</cell><cell>32.8%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Test accuracy on MNIST and SVHN with uniform label noise. We report the result of the last epoch with the ResNet-32 model. The noise rate ρ denotes the ratio of wrong labels. The best results in each group are bold-faced.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Noise Rate ρ</cell></row><row><cell>Model</cell><cell></cell><cell></cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MNIST</cell><cell>SVHN</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Basic</cell><cell></cell><cell></cell><cell></cell><cell cols="2">97.9%</cell><cell>96.7%</cell><cell>94.8%</cell><cell>78.7%</cell><cell>85.3%</cell><cell>63.2%</cell><cell>41.2%</cell><cell>19.3%</cell></row><row><cell></cell><cell cols="5">Reed soft(Reed et al., 2014)</cell><cell></cell><cell cols="2">98.7%</cell><cell>98.5%</cell><cell>97.7%</cell><cell>90.7%</cell><cell>87.3%</cell><cell>76.5%</cell><cell>48.4%</cell><cell>19.4%</cell></row><row><cell>ResNet-32</cell><cell cols="6">Reed hard(Reed et al., 2014) Lq loss(Zhang and Sabuncu, 2018) Co-teaching(Han et al., 2018)</cell><cell cols="2">99.0% 99.2% 99.0%</cell><cell>98.6% 98.9% 98.8%</cell><cell>98.1% 98.1% 98.6%</cell><cell>95.9% 88.5% 59.5%</cell><cell>85.1% 94.4% 93.5%</cell><cell>71.5% 89.7% 90.5%</cell><cell>56.9% 82.3% 72.1%</cell><cell>74.5% 40.4% 30.3%</cell></row><row><cell></cell><cell></cell><cell cols="3">Co-learning</cell><cell></cell><cell></cell><cell cols="2">99.4%</cell><cell>99.2%</cell><cell>99.1%</cell><cell>98.2%</cell><cell>93.6%</cell><cell>91.8%</cell><cell>89.2%</cell><cell>89.4%</cell></row><row><cell>Test Accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell><cell>120</cell><cell>140</cell><cell>160</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Training Epochs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Test accuracy under background label noise on CIFAR-10, based on the ResNet-32 model. The best accuracies are boldfaced.</figDesc><table><row><cell>Method</cell><cell cols="2">ρ = 0.2 ρ = 0.4</cell></row><row><cell>Basic</cell><cell>82.5%</cell><cell>52.2%</cell></row><row><cell>S-Model</cell><cell>87.7%</cell><cell>54.4%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the Key Projects of Ministry of Science and Technology of China under Grant 2018AAA0101604 and 2018YFB1702903, and the National Natural Science Foundation of China under Grant 61906106 and 61936009.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of interests</head><p>☒ The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p><p>☐The authors declare the following financial interests/personal relationships which may be considered as potential competing interests:</p><p>J o u r n a l P r e -p r o o f</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Closer Look at Memorization in Deep Networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Machine Learning</title>
				<meeting>the 26th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active bias: Training more accurate neural networks by emphasizing high variance samples</title>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1002" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: A survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Frenay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<idno type="ISSN">2162-237X</idno>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust Loss Functions under Label Noise for Deep Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th Conference on Artificial Intelligence</title>
				<meeting>the 31th Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">February 4-9, 2017. 2017</date>
			<biblScope unit="page" from="1919" to="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ben-Reuven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="10456" to="10465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Densely Connected Convolutional Networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2261" to="2269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Condensenet: An efficient densenet using learned group convolutions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2752" to="2761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning deep networks from noisy labels with dropout regularization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nokleby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 16th International Conference on Data Mining (ICDM)</title>
				<imprint>
			<date type="published" when="2016-12">Dec 2016</date>
			<biblScope unit="page" from="967" to="972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning From Noisy Singly-labeled Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J o u r n a l P r e -p r o o f Journal Pre-proof</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-paced learning for latent variable models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Knowledge Distillation by On-the-Fly Native Ensemble</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7517" to="7527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kankanhalli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.05214</idno>
		<title level="m">Learning to Learn from Noisy Labeled Data. arXiv e-prints, art</title>
				<imprint>
			<date type="published" when="2018-12">Dec. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">WebVision Database: Visual Learning and Understanding from Web Data. arXiv e-prints, art</title>
				<imprint>
			<date type="published" when="2017-08">Aug. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A self-training semi-supervised svm algorithm and its application in an eeg-based brain computer interface speller system</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1285" to="1294" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.0312</idno>
		<title level="m">Microsoft COCO: Common Objects in Context. arXiv e-prints, art</title>
				<imprint>
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T.-Y</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Focal Loss for Dense Object Detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
				<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2999" to="3007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="461" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Northcutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Chuang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.01936</idno>
		<imprint>
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to Reweight Examples for Robust Deep Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning dictionaries for information extraction by multi-level bootstrapping</title>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=315149.315364" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth National Conference on Artificial Intelligence and the Eleventh Innovative Applications of Artificial Intelligence Conference Innovative Applications of Artificial Intelligence, AAAI &apos;99/IAAI &apos;99</title>
				<meeting>the Sixteenth National Conference on Artificial Intelligence and the Eleventh Innovative Applications of Artificial Intelligence Conference Innovative Applications of Artificial Intelligence, AAAI &apos;99/IAAI &apos;99<address><addrLine>Menlo Park, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="474" to="479" />
		</imprint>
	</monogr>
	<note>American Association for Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semi-supervised self-training of object detection models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACVMOT.2005.107</idno>
	</analytic>
	<monogr>
		<title level="m">2005 Seventh IEEE Workshops on Applications of Computer Vision (WACV/MOTION&apos;05</title>
				<imprint>
			<date type="published" when="2005-01">Jan 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The bayesian bootstrap. The annals of statistics</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="130" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">org/10.1016/j.neunet.2014.09.003</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0893608014002135" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<idno type="ISSN">0893-6080</idno>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grewe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis ; Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2016. 2015</date>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note>Very deep convolutional networks for large-scale image recognition</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Active learning for noisy oracle via density power divergence</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ueno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Washio</surname></persName>
		</author>
		<idno type="DOI">org/10.1016/j.neunet.2013.05.007</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0893608013001378" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<idno type="ISSN">0893-6080</idno>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="133" to="143" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Training Convolutional Networks with Noisy Labels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</editor>
		<meeting>the 30th International Conference on Machine Learning<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2013-06">Jun 2013</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="17" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discriminative multi-source adaptation multi-feature co-regression for visual classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<idno type="DOI">org/10.1016/j.neunet.2019.02.007</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0893608019300693" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<idno type="ISSN">0893-6080</idno>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="96" to="118" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep learning in spiking neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tavanaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghodrati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Kheradpisheh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masquelier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maida</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2018.12.002</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0893608018303332" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<idno type="ISSN">0893-6080</idno>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="47" to="63" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Toward robustness against label noise in training deep discriminative neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural 12 Pre-proof Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5596" to="5605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning From Noisy Large-Scale Datasets With Minimal Supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alldrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Krasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6575" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
				<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2016-09">September 2016</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="87" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8792" to="8802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning joint space-time-frequency features for eeg decoding on small labeled data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2019.02.009</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0893608019300711" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<idno type="ISSN">0893-6080</idno>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="67" to="77" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
		<respStmt>
			<orgName>Computer Science, University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
