<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shape retrieval using triangle-area representation and dynamic space warping</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Naif</forename><surname>Alajlan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">King Saud University</orgName>
								<address>
									<postBox>P.O. Box 800</postBox>
									<postCode>11421</postCode>
									<settlement>Riyadh</settlement>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ibrahim</forename><surname>El</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>Ont</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mohamed</forename><forename type="middle">S</forename><surname>Kamel</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>Ont</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Freeman</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>Ont</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shape retrieval using triangle-area representation and dynamic space warping</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3AF7F3C01E1515933E0E0D4B0A8A43EC</idno>
					<idno type="DOI">10.1016/j.patcog.2006.12.005</idno>
					<note type="submission">Received 18 April 2006; received in revised form 23 November 2006; accepted 4 December 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Shape matching</term>
					<term>Shape retrieval</term>
					<term>Dynamic space warping</term>
					<term>Dynamic programming</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a shape retrieval method using triangle-area representation for nonrigid shapes with closed contours. The representation utilizes the areas of the triangles formed by the boundary points to measure the convexity/concavity of each point at different scales (or triangle side lengths). This representation is effective in capturing both local and global characteristics of a shape, invariant to translation, rotation, and scaling, and robust against noise and moderate amounts of occlusion. In the matching stage, a dynamic space warping (DSW) algorithm is employed to search efficiently for the optimal (least cost) correspondence between the points of two shapes. Then, a distance is derived based on the optimal correspondence. The performance of our method is demonstrated using four standard tests on two well-known shape databases. The results show the superiority of our method over other recent methods in the literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The ever growing number of images generated everyday has motivated researchers to develop, evaluate and implement sophisticated algorithms for the retrieval of images from large databases based on their content rather than their textual annotations alone. Among other generic image features that are used to achieve this objective, like color and texture, shape is considered the most promising for the identification of entities in an image. It can be argued that most real subjects are identified easily using only their silhouettes. A user survey in Ref. <ref type="bibr" target="#b0">[1]</ref> indicated that 71% of the users were interested in retrieval by shape.</p><p>The representation of shapes requires a number of criteria to be satisfied for reliable shape matching and retrieval. It should be invariant to geometrical transformations, such as rotation, scale, translation, and skew. In addition, a shape representation should satisfy the following criteria: high discrimination capability, computational efficiency, robustness to distortion and noise, compactness, generality of the application, and handling large image databases without heavy degradation in the performance. These criteria are also required by the MPEG-7 standard for measuring the similarity between shapes <ref type="bibr" target="#b1">[2]</ref>.</p><p>Global shape descriptors are generally robust to moderate amounts of noise. However, they face major difficulties in capturing fine details of shape boundaries. On the other hand, local shape descriptors are superior in describing fine details, but they are usually sensitive to noise. Therefore, in our opinion, the two requirements (the robustness to noise and the discrimination of fine details) conflict with each other and the choice between them is context-dependent unless another semanticbased measure is employed to distinguish between noise and fine details information.</p><p>In previous works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, the zero crossings of the trianglearea representation (TAR) were used, at multi-scale wavelet levels (called MTAR), to construct the MTAR images. The matching of the MTAR images was based on the peaks and locations of the concavity maxima in the images. In this paper, the TAR is utilized in order to derive multi-scale, affineinvariant descriptors for 2D closed-boundary shapes where the triangle areas at each boundary point are used in the matching via dynamic programming (DP). Many researchers adopted the areas of the triangles between boundary points for shape representation <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. In this paper, all possible scale levels are systematically used for computing the TAR, whereas the method of Ref. <ref type="bibr" target="#b6">[7]</ref> uses selected scale levels. Besides, the trianglearea normalization is made locally per scale in this paper, whereas the normalization is made globally in Ref. <ref type="bibr" target="#b6">[7]</ref>. The local normalization ensures equal contribution of different scale levels during the matching process and prevents the domination of scale levels yielding large areas. TAR provides useful information about shape features such as the convexity/concavity at each boundary point; therefore, TAR provides high discrimination capability. For shape matching, a DP algorithm, which is called dynamic space warping (DSW), is employed to find the best alignment between two shape representations.</p><p>The main contribution of the technique presented in this paper is its ability to provide higher retrieval accuracy than all published methods based on the MPEG-7 Core Experiment CE-shape-1 part B retrieval test <ref type="bibr" target="#b10">[11]</ref> which constitutes the most comprehensive shape retrieval test in the literature so far. Besides, TAR exhibits high robustness to the affine transformation. TAR is also robust against noise and moderate amounts of deformations. Regarding the computational complexity, the matching complexity of our algorithm is O(N 2 ), where N is the number of the boundary points.</p><p>The remainder of this paper is organized as follows. Section 2 reviews the related work in the literature. The TAR representation is presented in Section 3. Then, Section 4 describes our DSW matching algorithm. Section 5 discusses the computational complexity of our approach and Section 6 includes the experimental results. Finally, Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>The literature on 2D shape representation and matching is relatively huge. Good review papers can be found in Refs. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. However, we focus our review here on selected methods that are based on DP for two main reasons. The first is their close relation with our work. The second reason is that DP-based methods generally offer better performance than other methods which do not use DP.</p><p>Bartolini et al. proposed a method for shape matching and retrieval based on the Fourier descriptors that is called WARP <ref type="bibr" target="#b13">[14]</ref>. They chose to use the phase of the Fourier descriptors and claimed to outperform the state-of-the-art Fourier-based methods. At first, the low-frequency coefficients are normalized in terms of translation, scale and rotation. For matching, the inverse DFT is used to obtain normalized versions of the original contours in the spatial domain. Then, a DP method is employed to find the similarity between the two transformed contours. Although this technique outperformed other Fourierbased methods, the authors reported less retrieval accuracy than the curvature scale-space (CSS) method <ref type="bibr" target="#b14">[15]</ref>.</p><p>Ling and Jacobs were mainly motivated by computing a distance for articulated shapes <ref type="bibr" target="#b15">[16]</ref>. The inner distance, which is the length of the shortest path between two boundary points within the shape boundary, was derived to be invariant to shape articulation. The authors claim that the inner distance is the natural replacement to the well-known Euclidean distance. In order to apply the inner distance for shape matching and retrieval, the authors extended the shape context method <ref type="bibr" target="#b16">[17]</ref> using this distance and called it inner-distance shape context (IDSC). Then, DP is used for matching shapes after calculating the IDSC distances. The retrieval performance on the MPEG-7 data set is 85.4% which is the highest published performance so far.</p><p>Adamek and O'Connor proposed a multi-scale representation for a single closed contour that makes use of both concavities and convexities of all contour points <ref type="bibr" target="#b17">[18]</ref>. It is called multi-scale convexity concavity (MCC) representation where different scales are obtained by smoothing the boundary with Gaussian kernels of different widths. Then, a new measure for the curvature was proposed that is based on the relative displacement of a contour point with respect to its position in the preceding scale level. This idea is motivated by the observation that when smoothing a closed contour, convex and concave points are moved inside and outside the contour, respectively. Afterwards, the matching is done using a DP approach. The MCC was able to achieve 84.9 retrieval accuracy on the MPEG-7 data set. However, the MCC suffers from being computationally expensive, O(N 3 ) where N is the number of contour points.</p><p>Petrakis et al. proposed an approach for matching open and closed shapes using DP <ref type="bibr" target="#b18">[19]</ref>. In their approach, implicit multiscale matching takes place through matching merged contour segments in order to avoid the cost of computing the scale space explicitly. The DP algorithm examines all possible merges of small segments of one shape to match with larger segments of the other and selects the best merge. The authors did not report superior performance over other existing methods. Other limitations of this method include the lack of robustness to the general affine transformation and the high computational complexity of the matching process.</p><p>Sebastian et al. proposed a curve alignment approach, which is called curve edit distance (CED), for matching open and closed curves <ref type="bibr" target="#b19">[20]</ref>. In their method, the correspondence between the points of the two curves is controlled by the relative difference in their spatial location and their curvature. Then, a matching function is defined as the minimum cost of such correspondence. The search for the optimal correspondence is made efficient by decomposing each curve into segments, which is ideally solved using DP. Moreover, merging, deletion and addition of curve segments are allowed in order to account for shape deformations. The complexity of this method is O(N 2 log N) for closed curves and the authors reported 78.2 accuracy for MPEG-7 part B retrieval test.</p><p>Arica and Vural proposed another descriptor for closed contours based on the curvature information of all boundary points, which is called beam angle statistics (BAS) <ref type="bibr" target="#b20">[21]</ref>. In BAS, the curvature at each boundary point is viewed as a random variable that draws its values from the angles between each equallydistant neighboring points at that point. Then, few order moments are computed for the random variable at each point. For measuring the similarity, DP is used to find the best correspondence that minimizes the Euclidean distance between the signatures of two shapes. The authors reported 82.4% accuracy using the MPEG-7 part B retrieval test.</p><p>In another recent work, Latecki et al. presented a shape matching approach that works directly on the closed boundaries <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. It is based on visual parts (VP), where (part of) a database shape is simplified in the context of the query shape prior to their matching. The simplification process includes the elimination of particular points from the database shape such that the similarity to the query shape is maximized. The main disadvantage of this method is the high computational complexity of the matching algorithm, which is O(N 3 log N) where N is the number of the boundary points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TAR of closed boundaries</head><p>Many researchers have used the area of the triangle, formed by the boundary points, as the basis for shape representations, for example <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. These methods use a global measure for the signature normalization. In this paper, a shape representation that is based on the area of the triangle is introduced, which is called TAR. Unlike previous methods, the signature at each scale, i.e., triangle side length, is normalized locally based on that scale. Fig. <ref type="figure" target="#fig_0">1</ref> shows the difference between local and global normalization of the triangle areas (here, t s is the triangle side length, n is the boundary point index, and N is the number of boundary points). Clearly, the local normalization provides higher discrimination between shape properties at different scales. Unlike some other shape description methods, which use a finite number of discriminative boundary points (such as corners or inflection points), our representation equally employs all boundary points in a systematic way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">TAR signatures</head><p>The TAR signature is computed from the area of the triangles formed by the points on the shape boundary. Each contour point is represented by its x and y coordinates and  separated parameterized contour sequences x n and y n are obtained and re-sampled to N points. Then, the curvature of the contour point (x n , y n ) is measured using the TAR as follows.</p><p>For each three consecutive points (x n-t s , y n-t s ), (x n , y n ), and (x n+t s , y n+t s ), where n ∈ 1, N and t s ∈ 1, T s is the triangle side length. <ref type="foot" target="#foot_0">1</ref> The signed area of the triangle formed by these points is given by</p><formula xml:id="formula_0">TAR(n, t s ) = 1 2</formula><p>x n-t s y n-t s 1</p><p>x n y n 1 x n+t s y n+t s 1 .</p><p>(</p><formula xml:id="formula_1">)<label>1</label></formula><p>When the contour is traversed in counter clockwise direction, positive, negative and zero values of TAR mean convex, concave and straight-line points, respectively. Fig. <ref type="figure" target="#fig_2">2</ref>  The circled point on the boundary is the middle point, which is also considered as the inflection point for the TAR signature.</p><p>boundaries. More specifically, for a closed contour of N points:</p><formula xml:id="formula_2">TAR(n, t s )= ⎧ ⎪ ⎨ ⎪ ⎩ -TAR(n, N + 1 -t s ) t s = 1 . . . N-1 2 , 0 a t t s = N 2 and N is even, does not exist at t s = N 2 and N is odd,<label>(2)</label></formula><p>where (N -1)/2 is the floor value of (N -1)/2. The first line in Eq. ( <ref type="formula" target="#formula_2">2</ref>) shows the odd symmetry property of the triangle area versus the triangle side length t s . Also, at t s equals the middle point of the boundary, the value of the triangle area depends on N, the total number of points on that boundary. If N is odd, then there will be no zero-crossing points on the area curve. Usually, researchers tend to use an even number of points on the shape boundary. In this case, the inflection (zero-crossing) point exists at t s = N/2, where TAR(n, N/2) = 0. Fig. <ref type="figure">3</ref> illustrates the odd symmetry property of the TAR signature that is computed for only one point on the shape boundary of the Misk shape. A complete 3D plot of the TAR signatures for the Misk shape is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The two plots shows the difference between local (up) and global (bottom) normalization of the signatures. In this paper, the local normalization is performed at each scale (or triangle side length) with respect to the maximum area at that scale. In Refs. <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>, the normalization was carried out by dividing on the total sum of the signatures, i.e., global.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">TAR under general affine transformations</head><p>For a 2D shape, represented by its contour sequences, x n and y n , and subjected to an affine transformation, the relation between the original and the distorted sequences is given by</p><formula xml:id="formula_3">xn ŷn = a b c d x n y n + e f ,<label>(3)</label></formula><p>where x and ŷ are the affine distorted sequences, e and f represent translation, and a, b, c and d reflect scale, rotation and shear. The effect of the translation parameters is easily eliminated by normalizing the shape boundary with respect to its centroid. This normalization is achieved by subtracting from each boundary sequence its mean value. By substituting (3) into (1), we obtain</p><formula xml:id="formula_4">TAR(n, t s ) = (ad -bc)TAR(n, t s ), (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>where TAR is the affine transformed version of TAR. It is clear that TAR is relatively invariant to the affine transformations. Absolute invariance can be achieved by dividing TAR by its maximum value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Shape matching using DSW</head><p>In this section, a brief review about the origin of dynamic time warping<ref type="foot" target="#foot_1">2</ref> (DTW) and how some researchers applied it to the shape matching problem is presented. Then, the description of our DSW algorithm to measure the similarity between two shapes based on their TARs is given followed by the definition of the distance function. Finally, an indexing scheme using geometric features is shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">DTW in shape matching</head><p>The idea of using DP for matching 1D sequences originally came from the speech recognition community <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref> where optimal alignment between two 1D sequences is searched via DP, which was called DTW. In the past few years, several researchers adopted DTW for 1D sequences alignment and matching <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>. Unlike the Euclidean distance that provides one-to-one alignment, nonlinear alignment can be achieved by the DTW, where one point on the sequence can be aligned to one or more points on another sequence.</p><p>Recently, many researchers have applied DTW in the 2D shape matching problem. In Ref. <ref type="bibr" target="#b18">[19]</ref>, a DP table is used to find the least cost match between segments of two curves. Merging of segments is allowed during the matching to facilitate a more meaningful correspondence between segments. However, this increases the complexity of matching. In the MCC method <ref type="bibr" target="#b17">[18]</ref>, their DP algorithm searches for the optimal correspondence between the N-points boundaries. A window, which limits the optimal path to be around the diagonal, is used to make the search more efficient. Another constraint that limits a single point of one contour to correspond to a maximum of two points on the other contour is enforced, which limits the generality of the method and demands more computations. On an attempt to reduce the size of the DP search space, WARP method <ref type="bibr" target="#b13">[14]</ref> applies DTW on normalized points after applying the inverse discrete Fourier transform. In Ref. <ref type="bibr" target="#b19">[20]</ref>, the optimal path in the DP table is used to define an edit distance metric that transforms one shape into the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Finding the minimum cost distance using DSW</head><p>Now, we describe our DSW algorithm that is used to compute the distance between two closed contours based on their TARs. At first, it is necessary to define the distance between two individual contour points. Let TAR A (n, t s ) and TAR B (n, t s ) be the TARs for shapes A and B, respectively, where n ∈ 1, N is the index of the boundary points and t s ∈ 1, T s is the triangle side length. Then, the distance between the two contour points n ∈ A and m ∈ B is defined as</p><formula xml:id="formula_6">D(n, m) = 1 T s T s t s =1 |TAR A (n, t s ) -TAR B (m, t s )|,<label>(5)</label></formula><p>Then, an N × N distance table, DT, is constructed to find the optimal correspondence between the points of the two contours.</p><p>The columns of DT represent the points of one contour and the rows represent the points of the other. Initially, the elements of DT are set as</p><formula xml:id="formula_7">DT initial (n, m) = ⎧ ⎪ ⎨ ⎪ ⎩ 0 max(1, n -w + 1) m min(N, n + w -1), ∞ otherwise,<label>(6)</label></formula><p>where n, m ∈ 1, N , w is a predefined diagonal width for DT as illustrated in Fig. <ref type="figure" target="#fig_4">4</ref>, and max(a, b) and min(a, b) are the maximum and minimum values of a and b, respectively. Only the elements of DT that fall within w are updated during the DSW search. This initialization of DT avoids computing the distances between all the points of two contours and restricts the distance computation to only those points which are more likely correspond to each other. Therefore, the computational complexity is largely reduced while more meaningful correspondences are obtained.</p><p>Starting at an arbitrary TAR point for both contours A and B, the DT is searched, through the diagonal window of width w, left-to-right and up-to-bottom starting from the upper-left element, as shown in Fig. <ref type="figure" target="#fig_4">4</ref>. The first row and first column elements are initialized as the distance between the corresponding points using <ref type="bibr" target="#b4">(5)</ref>. Then, the rest of the zero-valued elements of DT are updated as The least cost path through the DT is the value of element DT(N, N ), which corresponds to the best matching between the two TAR points according to the selected starting points. However, it is clear that the established correspondence is sensitive to the starting point of each TAR. In order to achieve starting point (or rotation) invariance, it is sufficient to fix the starting point of one TAR and try all N starting points of the other TAR. Moreover, invariance to the mirror transformation can be obtained by flipping the points of one TAR and repeat the search for the N starting points again. The final least cost correspondence is taken as the minimum value of DT(N, N ) among all 2N runs of the DSW table search, denoted by DT min .</p><formula xml:id="formula_8">DT (n, m) = D(n, m) + min ⎧ ⎪ ⎨ ⎪ ⎩ DT (n -1, m), DT (n -1, m -1), DT (n, m -1). (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">The distance measure</head><p>Following the approach presented in Ref. <ref type="bibr" target="#b17">[18]</ref>, the distance (D dis ) is chosen as the minimum cost distance DT min , normalized by the shape complexity (SC) of each contour. The motivation behind this normalization is based on the observation that the sensitivity of the human perception to the boundary variations reduces as the SC increases. Here, the SC is considered as the average, over all boundary points, of the absolute differences between the maximum and minimum TAR values at all scale levels (or triangle side lengths): s</p><formula xml:id="formula_9">SC = 1 N N n=1 max 1 t s T s {TAR(n, t s )} -min 1 t s T s {TAR(n, t s )} . (<label>8</label></formula><formula xml:id="formula_10">)</formula><p>Then, the distance between two shapes, A and B, is given by where DT min (A, B) is the minimum cost distance between shapes A and B, computed using the DSW table search, and SC A and SC B are the complexities of shapes A and B, respectively. A constant K is added to prevent the domination of the denominator when the complexities are very small. In our experiments, K is set to 1. Fig. <ref type="figure" target="#fig_5">5</ref> shows two examples, from the MPEG-7 CE-shape-1 database, of similar shapes with small and large shape complexities, respectively.</p><formula xml:id="formula_11">D dis (A, B) = DT min (A, B) K + SC A + SC B ,<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Indexing using geometric features</head><p>In many practical applications, it is highly desired that the shape descriptor provides means for indexing in order to organize the database efficiently. Abbasi et al. <ref type="bibr" target="#b14">[15]</ref> used a set of global features, i.e., circularity, eccentricity (E), and aspect ratio (AR), at an initial stage to discard very dissimilar shapes and increase the discrimination power of the descriptor. Jain and Vailaya <ref type="bibr" target="#b27">[28]</ref> used invariant moments and histograms of edge directions for fast pruning of the database.</p><p>In our method, a set of simple geometric features are used to further increase the discrimination ability of the distance, which includes AR, E, and solidity (S). These features include considerable information about the global properties of a shape. However, since some dissimilar shapes have comparable global features, the indexing using the global features comes at the price of the accuracy. Therefore, the final distance between shapes A and B is given as</p><formula xml:id="formula_12">D f (A, B) = ar |AR A -AR B | + e |E A -E B | + s |S A -S B | + D dis (A, B),<label>(10)</label></formula><p>where AR A , E A , and S A are the AR, E, and S of shape A (same for shape B), and ar , e and s are the associated weights. Our experiments show that (10) performs effectively under a wide range of the weight values, which supports the generality of our approach. In our experiments, unless otherwise mentioned, the weight values are ar = 4.1, e = 2.3 and s = 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Computational complexity</head><p>The complexity of each of the TAR and the matching stage is evaluated separately. It should be noted that the complexity of the matching stage is more critical since the TARs of the database images can be computed prior to the time of the matching, whereas the matching usually takes place between the query image and most (if not all) the database images.</p><p>The TAR computation involves calculating the triangle area, according to (1), at each of the N points of the boundary. In addition, at each boundary point, the triangle area is calculated at different scales (or triangle side lengths). Typically, there are (N -1)/2 scales (see Section 3.1). Therefore, the computational complexity of the TAR stage is O(N • (N -1)/2) or O(N 2 ).</p><p>For the matching function given by Eq. ( <ref type="formula" target="#formula_12">10</ref>), each of the first three terms involves a single computation of the absolute difference operation; therefore, the forth term D dis given by Eq. ( <ref type="formula" target="#formula_11">9</ref>) governs the complexity of the matching stage. Furthermore, each of the SC terms SC A and SC B in Eq. ( <ref type="formula" target="#formula_11">9</ref>) requires O(N) complexity as given by Eq. ( <ref type="formula" target="#formula_9">8</ref>). For the minimum cost distance term DT min , the DSW table search is restricted within the diagonal w-width window; thus, the DSW table search complexity is O(wN) (usually w&gt;N ). Since the DSW search is repeated for N starting points, the complexity becomes O(wN 2 ). Finally, by considering the flipping operation, the total complexity of the matching stage turns out to be O(2wN 2 ) or O(N 2 ) (for N = 128, our experiments show that w = 3 is good enough and larger w does not achieve better results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental results</head><p>In this section, the performance of our method is demonstrated using four standard experiments on two shape databases. The first database is the well-known MPEG-7 CE-shape-1 database <ref type="bibr" target="#b28">[29]</ref> which consists of 1400 images semantically classified into 70 classes. This database contains a mixture of natural and man-made objects under various rigid and nonrigid deformations (a sample of the database is shown in Fig. <ref type="figure" target="#fig_6">6</ref>). The other database is the Kimia's database <ref type="bibr" target="#b29">[30]</ref> which contains 99 images for nine categories as shown in Fig. <ref type="figure">7</ref>. There are 11 images for each category and most of the images are partially occluded. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Robustness to scaling and rotation</head><p>Here, the results of our method, according to the MPEG-7 CE-shape-1 part A1 (for scaling) and part A2 (for rotation) tests, are presented. The database used in part A1 includes 420 shapes, 70 basic shapes from the MPEG-7 CE-shape-1 database (one shape per class) and five derived shapes from each basic shape by scaling the images with factors 2, 0.3, 0.25, 0.2, and 0.1. Each of the 420 shapes was used as a query and the number of correct matches were founded among the first six retrieved shapes.</p><p>Similarly, the database used for part A2 test consists of 420 shapes as in part A1, but the derived images are obtained by rotating each basic image with angles 9 • , 36 • , 45 • , 90 • , and 150 • . The correct matches were evaluated as in part A1.</p><p>Table <ref type="table" target="#tab_0">1</ref> summarizes the results of both tests for our method along with three other methods from the literature. The CSS  <ref type="bibr" target="#b13">[14]</ref> (%) <ref type="bibr" target="#b21">[22]</ref> (%) <ref type="bibr" target="#b19">[20]</ref> (%) <ref type="bibr" target="#b30">[31]</ref> (%) <ref type="bibr" target="#b20">[21]</ref> (%) <ref type="bibr" target="#b17">[18]</ref> (%) <ref type="bibr">[</ref> method is due to Mokhtarian et al. <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b14">15]</ref> and has been selected as the MPEG-7 standard for the boundary-based shape descriptor after comprehensive experiments. The other two methods are the BAS <ref type="bibr" target="#b20">[21]</ref> and the VP <ref type="bibr" target="#b21">[22]</ref> (see Section 2 for details).</p><p>The results in the table clearly shows that the DSW matching given by Eq. ( <ref type="formula" target="#formula_11">9</ref>) performs better than the others even without using the global parameters of the shapes. Using DSW+global given by Eq. ( <ref type="formula" target="#formula_12">10</ref>) further improves the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Similarity retrieval test</head><p>The retrieval effectiveness of our method is evaluated using the MPEG-7 CE-shape-1 part B test (also called bulls-eye test), which is the main part of CE-Shape-1. All the 1400 images of the MPEG-7 database were used here. Each image was used as a query; then, the number of correct matches was counted in the first 40 retrieved shapes. As stated in <ref type="bibr" target="#b28">[29]</ref>, a 100% retrieval rate in this case is not possible using only the shape information since many classes contain very different objects. In our opinion, this shape retrieval test is the most challenging in the literature so far.</p><p>Table <ref type="table">2</ref> shows the results of our DSW method and many recent methods; namely, BAS <ref type="bibr" target="#b20">[21]</ref>, CSS <ref type="bibr" target="#b30">[31]</ref>, VP <ref type="bibr" target="#b21">[22]</ref>, MCC <ref type="bibr" target="#b17">[18]</ref>, WARP <ref type="bibr" target="#b13">[14]</ref>, IDSC <ref type="bibr" target="#b15">[16]</ref>, and CED <ref type="bibr" target="#b19">[20]</ref> (see Section 2). The best performance based on the bulls-eye test was reported as 85.4 <ref type="bibr" target="#b15">[16]</ref>. Our DSW method achieves high retrieval accuracy (85.03%) even without using the global parameters. When the global parameters are incorporated in the matching function, our method outperforms all existing methods in the retrieval accuracy. Fig. <ref type="figure">8</ref> shows the breakdown of the total retrieval rate into the retrieval rates for each class for both DSW+Global and the MCC method <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Retrieval using the Kimia's database</head><p>In this test, the Kimia's database <ref type="bibr" target="#b29">[30]</ref> is used. As shown in Fig. <ref type="figure">7</ref>, partial occlusion is the main factor of variation among shapes of the same category. Each shape in the database is considered as a query and the first 10 retrieved shapes, excluding the query, are determined. Then, the correct retrievals for each ranking, over all 99 shapes, are counted. Table <ref type="table" target="#tab_2">3</ref> summarizes these results for the DSW and three other methods. Note that the maximum number of correct retrievals in each case is 99. The shock graph edit (SGE) method <ref type="bibr" target="#b29">[30]</ref> breaks down a shape's skeleton into parts (or shocks) and represents them as graph nodes and their relations as graph edges; thus, it handles partial occlusions explicitly. The SGE outperforms the shape context method <ref type="bibr" target="#b16">[17]</ref> in this test. However, the performance of the SGE method on the MPEG-7 part B test was not reported. In contrast, the IDSC method <ref type="bibr" target="#b15">[16]</ref> slightly outperforms the SGE method. Table <ref type="table" target="#tab_2">3</ref> also shows the results of DSW given by Eq. ( <ref type="formula" target="#formula_11">9</ref>), DSW+Global given by Eq. ( <ref type="formula" target="#formula_12">10</ref>) with same parameter set of the previous tests, and DSW + Global * given by Eq. ( <ref type="formula" target="#formula_12">10</ref>) with parameters tuned up specifically for this test (as in the IDSC method <ref type="bibr" target="#b15">[16]</ref>). For the latter case the weight values are ar = 1.6, e = 0.6 and s = 2. Our method achieves satisfactory performance without adjusting the parameters and achieves comparable performance to the IDSC method when the parameters are tuned up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Concluding remarks</head><p>In this paper, we presented a closed-boundary shape representation that employs the triangle, formed by the boundary points at different scales, to measure the convexity/concavity of each boundary point. For the matching, the optimal correspondence between the points of two shapes is searched efficiently using a DSW algorithm. Based on the established correspondence, a distance is derived. Global features (AR, E, and S) of the shapes are incorporated in the distance to further increase the discrimination ability and to facilitate the indexing in large shape databases. The proposed technique is invariant to translation, rotation, and scaling and robust against noise and moderate amounts of noise and occlusion. For the MPEG-7 CE-shape-1 part B test, which is considered the most comprehensive shape retrieval test yet, our method outperforms all existing methods by a good margin.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>TARFig. 1 .</head><label>1</label><figDesc>Fig. 1. The 3D plots of the TAR signatures (t s = 1-63 and N = 128) for the shape in Fig. 3. The two plots differ only in the normalization method of the signatures. TAR signatures normalized locally per scale (top) and normalized globally according to [7] (bottom).</figDesc><graphic coords="3,167.24,545.57,292.02,134.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 TAR</head><label>1</label><figDesc>TAR Signature (t s = 1) Boundary sequence, n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Three different types of the triangle-area values and the TAR signature for the hammer shape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 TriangleFig. 3 .</head><label>23</label><figDesc>Fig. 3. Illustration of the odd symmetry of the triangle-area signatures. Two virtual triangles are shown (top) for computing the TAR signature (bottom).The circled point on the boundary is the middle point, which is also considered as the inflection point for the TAR signature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. DSW table.</figDesc><graphic coords="6,40.08,71.73,236.52,216.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. Two examples of similar shapes with small shape complexities (a and b) and with large shape complexities (c and d). The shape identifier in the MPEG-7 CE-shape-1 database is shown above each shape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Samples of the MPEG-7 CE-shape-1 database.</figDesc><graphic coords="7,318.11,71.20,237.60,229.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Comparison of the results of different methods on the MPEG-7 CE-shape-1 part A test</figDesc><table><row><cell>Test</cell><cell cols="2">BAS (%) [21]</cell><cell cols="2">CSS (%) [31]</cell><cell cols="2">VP (%) [22]</cell><cell>DSW (%)</cell><cell></cell><cell>DSW+Global (%)</cell></row><row><cell>Part A1</cell><cell>90.87</cell><cell></cell><cell>92.86</cell><cell></cell><cell>88.65</cell><cell></cell><cell>95.1</cell><cell></cell><cell>98.02</cell></row><row><cell>Part A2</cell><cell>100</cell><cell></cell><cell>100</cell><cell></cell><cell>100</cell><cell></cell><cell>100</cell><cell></cell><cell>100</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Comparison of the results of different methods on the MPEG-7 CE-shape-1 part B (bulls-eye) test</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Test</cell><cell>WARP</cell><cell>VP</cell><cell>CED</cell><cell>CSS</cell><cell>BAS</cell><cell>MCC</cell><cell>IDSC</cell><cell>DSW</cell><cell>DSW + Global</cell></row><row><cell></cell><cell>(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Results on Kimia database of 99 shapes. The table shows the number of correct retrievals, over all 99 shapes, at different rankings</figDesc><table><row><cell>Method</cell><cell cols="3">Ranking of the retrieved shape</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1st</cell><cell>2nd</cell><cell>3rd</cell><cell>4th</cell><cell>5th</cell><cell>6th</cell><cell>7th</cell><cell>8th</cell><cell>9th</cell><cell>10th</cell></row><row><cell>Shape context [17]</cell><cell>97</cell><cell>91</cell><cell>88</cell><cell>85</cell><cell>84</cell><cell>77</cell><cell>75</cell><cell>66</cell><cell>56</cell><cell>37</cell></row><row><cell>SGE [30]</cell><cell>99</cell><cell>99</cell><cell>99</cell><cell>98</cell><cell>98</cell><cell>97</cell><cell>96</cell><cell>95</cell><cell>93</cell><cell>82</cell></row><row><cell>IDSC [16]</cell><cell>99</cell><cell>99</cell><cell>99</cell><cell>98</cell><cell>98</cell><cell>97</cell><cell>97</cell><cell>98</cell><cell>94</cell><cell>79</cell></row><row><cell>DSW</cell><cell>99</cell><cell>99</cell><cell>96</cell><cell>97</cell><cell>96</cell><cell>94</cell><cell>91</cell><cell>84</cell><cell>70</cell><cell>45</cell></row><row><cell>DSW + Global</cell><cell>99</cell><cell>99</cell><cell>99</cell><cell>96</cell><cell>95</cell><cell>97</cell><cell>95</cell><cell>84</cell><cell>71</cell><cell>50</cell></row><row><cell>DSW + Global  *</cell><cell>99</cell><cell>99</cell><cell>99</cell><cell>98</cell><cell>98</cell><cell>97</cell><cell>98</cell><cell>95</cell><cell>93</cell><cell>80</cell></row><row><cell>See text for details.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Here, t s refers to the separation between the indices of the current point and any of its equally-separated neighbors (representing the triangle vertices) in the parameterized boundary sequence.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In this paper, the analogous terminology DSW is used instead of DTW since still images are space variant as opposed to speech which is time variant.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Dr. Tomasz Adamek and Dr. Noel O'Connor for providing the MCC results illustrated in Fig. <ref type="figure">8</ref>. This research is supported by the Natural Sciences and Engineering Research Council (NSERC) of Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using pen-based outlines for objectbased annotation and image-based queries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>De Leau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vuurpijl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Information and Information Systems, Third International Conference</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martinez</surname></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG11</idno>
		<title level="m">Mpeg-7 overview</title>
		<imprint>
			<publisher>International Organisation for Standardisation, Coding of Moving Pictures and Audio</publisher>
			<date type="published" when="2003-03">March 2003</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>version 9</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust multiscale triangle-area representation for 2d shapes</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">El</forename><surname>Rube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alajlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<meeting><address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
			<biblScope unit="page" from="545" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient multiscale shape-based representation and retrieval</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">El</forename><surname>Rube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alajlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Recognition (ICIAR)</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Kweon, 2-d object recognition using invariant contour descriptor and projective refinement</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="441" to="445" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An affine-invariant active contour model (ai-snake) for model-based segmentation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H S</forename><surname>Ip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Affine invariant image retrieval by correspondence matching of shapes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H S</forename><surname>Ip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="489" to="499" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Affine invariant detection of perceptually parallel 3d planar curves</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H S</forename><surname>Ip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Teoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1909" to="1918" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coarse-to-fine multiscale affine invariant shape matching and classification</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">El</forename><surname>Rube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th International Conference on Pattern Recognition (ICPR)</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="163" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Affine invariant multiscale waveletbased shape matching algorithm</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">El</forename><surname>Rube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Canadian Conference on Computer and Robot Vision (CRV)</title>
		<meeting><address><addrLine>London, Ont., Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="217" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Mpeg Home</forename><surname>The</surname></persName>
		</author>
		<author>
			<persName><surname>Page</surname></persName>
		</author>
		<ptr target="http://www.chiariglione.org/mpeg" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey of shape analysis techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Loncaric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="983" to="1001" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Review of shape representation and description techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Warp: accurate retrieval of shapes using phase of fourier descriptors and time warping distance</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ciaccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="142" to="147" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Curvature scale space image in shape similarity retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MultiMedia Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="467" to="476" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using the inner distance for classification of articulated shapes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="719" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="509" to="522" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A multiscale representation method for nonrigid shapes with a single closed contour</title>
		<author>
			<persName><forename type="first">T</forename><surname>Adamek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>O'connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Techol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="742" to="753" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Matching and retrieval of distorted and occluded shapes using dynamic programming</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G M</forename><surname>Petrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diplaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1501" to="1516" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On aligning curves</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="124" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bas: a perceptual shape descriptor based on the beam angle statistics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Arica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vural</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Lett</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9-10</biblScope>
			<biblScope unit="page" from="1627" to="1639" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Shape similarity measure based on correspondence of visual parts</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lakamper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1185" to="1190" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Optimal partial shape similarity, Image Vision Comput</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lakamper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wolter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Minimum prediction residual principle applied to speech recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Itakura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust. Speech Signal Process. ASSP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="52" to="72" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dynamic programming algorithm optimization for spoken word recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust. Speech Signal Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Deller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Proakis</surname></persName>
		</author>
		<title level="m">Discrete-Time Processing of Speech Signals</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley-IEEE Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>reprint edtion</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Alignment of curves by dynamic time warping</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1251" to="1276" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Shape-based retrieval: a case study with trademark image databases</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vailaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1369" to="1390" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Shape descriptors for non-rigid shapes with a single closed contour</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lakamper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Eckhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="424" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recognition of shapes by editing their shock graphs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="550" to="571" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bober</surname></persName>
		</author>
		<title level="m">Curvature Scale Space Representation: Theory, Applications, and MPEG-7 Standardization</title>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">He is a member of the board of directors and co-founder of Virtek Vision Inc. of Waterloo. His research interests are in computational intelligence, pattern recognition and distributed and multi-agent systems. He has authored and co-authored over 200 papers in journals and conference proceedings, two patents and numerous technical and industrial project reports. About the Author-GEORGE FREEMAN received the B.Sc. and Ph.D. degrees in Electrical Engineering from the University of Waterloo in 1979 and 1984, respectively. He then joined the Continuous Speech Recognition Group at the IBM</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">He is the Editor-in-Chief of the International Journal of Robotics and Automation, Associate Editor of the IEEE Transactions of SMC Part A, the Intelligent Automation and Soft Computing, Pattern Recognition Letters, and the International Journal of Image and Graphics. He also served as an Associate Editor of Simulation, the Journal of The Society for Computer Simulation. Prof. Kamel is a member of ACM, AAAI, and IEEE</title>
		<meeting><address><addrLine>Riyadh, Saudi Arabia; Waterloo, Ontario, Canada; Riyadh, Saudi Arabia; Hamilton, Canada; Yorktown Heights, New York</addrLine></address></meeting>
		<imprint>
			<publisher>Watson Research Center</publisher>
			<date type="published" when="1970">1998 and 2003. 2006. 2007. 1970. 1974. 1981. September 1985</date>
		</imprint>
		<respStmt>
			<orgName>degrees in Electrical Engineering from King Saud University ; University of Waterloo ; Department of Electrical Engineering, King Saud University ; Computation from McMaster University ; Computer Science from the University of Toronto, Canada ; Department of Electrical and Computer Engineering at the University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note>where he worked on statistical language modeling and parallel implementations of speech recognition. he has been with the. where he is currently an Associate Professor. In 1993/94, he spent a one-year sabbatical leave consulting for NCR Canada Limited, (Waterloo, Ont.) on the use of fractal and wavelet compression for scanned-document images. His current research interests are in signal processing, particularly lossless or near-lossless data compression and articulation-based hidden Markov modelling for speech processing</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
