<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Collective Approach to Scholar Name Disambiguation</title>
				<funder ref="#_CyaV55h">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
				<funder ref="#_JynwzMR">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dongsheng</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shuai</forename><surname>Ma</surname></persName>
							<email>mashuai@buaa.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yaowei</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chunming</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
							<email>xzhang@ist.psu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jinpeng</forename><surname>Huai</surname></persName>
							<email>huaijp@buaa.edu</email>
						</author>
						<author>
							<persName><forename type="first">?</forename><forename type="middle">D</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ying</forename><surname>Zhang1</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Wang2</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Information Sciences and Technology</orgName>
								<orgName type="institution">Pennsylvania State University</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Beijing Advanced Innovation Center for Big Data and Brain Computing</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">DMKD TODS ICDE SIGMOD</orgName>
								<address>
									<addrLine>Wei Xu1 Haixun Wang2 Ying Zhang3 Wei Wang2 Wei Wang3 Haixun Wang4 P2 Wei Wang4, P1 Ying Zhang1 Wei Xu1 Haixun Wang2 Ying Zhang3</addrLine>
									<postCode>P3 P4</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Collective Approach to Scholar Name Disambiguation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TKDE.2020.3011674</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2020.3011674, IEEE Transactions on Knowledge and Data Engineering</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Name Disambiguation</term>
					<term>Collective Clustering</term>
					<term>Information Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scholar name disambiguation remains a hard and unsolved problem, which brings various troubles for bibliography data analytics. Most existing methods handle name disambiguation separately that tackles one name at a time, and neglect the fact that disambiguation of one name affects the others. Further, it is typically common that only limited information is available for bibliography data, e.g., only basic paper and citation information is available in DBLP. In this study, we propose a collective approach to name disambiguation, which takes the connection of different ambiguous names into consideration. We reformulate bibliography data as a heterogeneous multipartite network, which initially treats each author reference as a unique author entity, and disambiguation results of one name propagate to the others of the network. To further deal with the sparsity problem caused by limited available information, we also introduce word-word and venue-venue similarities, and we finally measure author similarities by assembling similarities from four perspectives. Using real-life data, we experimentally demonstrate that our approach is both effective and efficient.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Scholar name ambiguity is a common data quality problem for digital libraries such as DBLP <ref type="bibr" target="#b0">[1]</ref>, Google Scholar <ref type="bibr" target="#b1">[2]</ref> and Microsoft Academic Search [3], and has raised various troubles in scholar search, document retrieval and so on <ref type="bibr" target="#b19">[21]</ref>, <ref type="bibr" target="#b22">[24]</ref>, <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b42">[44]</ref>. For example, we read an interesting paper written by "Wei Wang" in DBLP, and we want to find more his/her publications. However, over 200 authors share the same name "Wei Wang" in DBLP <ref type="bibr" target="#b17">[19]</ref>, and the total number of their publications is over 2,000. Hence, it is timeconsuming to find those publications written by the "Wei Wang" in whom we are interested. It is also common that only limited information is available in bibliography data. For example, DBLP only provides basic paper and citation information, e.g., author names, publication title, venue and publication year, but no author affiliations, homepages and publication abstracts. This makes name disambiguation even more challenging to attack.</p><p>Most existing methods tackle name disambiguation separately <ref type="bibr" target="#b3">[5]</ref>, <ref type="bibr" target="#b4">[6]</ref>, <ref type="bibr" target="#b7">[9]</ref>, <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b11">[13]</ref>, <ref type="bibr" target="#b13">[15]</ref>, <ref type="bibr" target="#b15">[17]</ref>, <ref type="bibr" target="#b16">[18]</ref>, <ref type="bibr" target="#b17">[19]</ref>, <ref type="bibr" target="#b27">[29]</ref>, <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b33">[35]</ref>, <ref type="bibr" target="#b34">[36]</ref>, <ref type="bibr" target="#b35">[37]</ref>, <ref type="bibr" target="#b36">[38]</ref>, <ref type="bibr" target="#b37">[39]</ref>, <ref type="bibr" target="#b38">[40]</ref>, <ref type="bibr" target="#b42">[44]</ref>. For each name to be disambiguated, these methods only deal with the papers having that author name. However, by tackling each name separately and independently, these methods neglect the connection between these sub-problems. For example, coauthors, which are used as a strong evidence in many methods <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b37">[39]</ref>, may also be ambiguous. Fig. <ref type="figure" target="#fig_11">1</ref> is an example to demonstrate this problem, which shows two papers written by "Ying Zhang" and "Wei Xu" in DBLP. When disambiguating the name "Wei Xu", single Figure <ref type="figure" target="#fig_11">1</ref>: Example taken from DBLP name disambiguation methods consider two "Ying Zhang" (author references) as the same person (author entity). As a result, these two "Wei Xu" have the same coauthor. Hence, it is very likely that they refer to the same person. In fact, there are two different "Wei Xu" and two different "Ying Zhang" in this example. More troubles may appear when multi-hop coauthorships are used as features <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b30">[32]</ref>. For instance, "Jianxin Li" in the University of Western Australia is a coauthor and 2-hop coauthor of "Wei Wang" in the University of New South Wales, and "Jianxin Li" in Beihang University is a 2-hop coauthor of "Wei Wang" in UCLA.</p><p>Contributions &amp; Roadmap. To this end, we propose a collective approach to dealing with scholar name disambiguation using only the limited information common available for bibliography data.</p><p>(1) We propose an iterative method via collective clustering, referred to as NDCC, to deal with scholar name disambiguation (Sections 3 and 5). Our collective clustering method uses a heterogeneous multipartite network model, and the disambiguation results of one name affect the others. By representing each author reference as a unique author in the beginning, NDCC alleviates the problem caused by ambiguous coauthor names. In each iteration, a name is disambiguated, and the network is updated (author nodes merging) according to the disambiguation result. The process repeats until the network converges.</p><p>(2) We develop a novel metric for determining the author similarity by assembling the similarities of four features (i.e., coauthors, venues, titles and coauthor names) available in bibliography data (Section 4). Here we differentiate coauthors from coauthor names, as the latter is an ambiguous feature. To overcome the sparsity of certain venues and title words, a word embedding method is utilized to capture the semantic similarity of words, and the similarity of venues is measured by the degree of common authors between the authors who publish papers in the two venues.</p><p>(3) We conduct comprehensive experimental studies (Section 6) on three real-life datasets (AMiner, ACM, and DBLP) to evaluate NDCC. We find that our method NDCC is both effective and efficient, compared with the state-ofthe-art methods CE <ref type="bibr" target="#b5">[7]</ref>, GHOST <ref type="bibr" target="#b9">[11]</ref>, CSLR <ref type="bibr" target="#b17">[19]</ref>, MIX <ref type="bibr" target="#b16">[18]</ref>, and AM <ref type="bibr" target="#b42">[44]</ref>. Specifically, (a) NDCC on average improves the Macro-F1 over (CE, GHOST, CSLR, MIX, AM) by (17.87%, 23.25%, 16.65%, 45.39%, 21.24%) on AMiner, (25.36%, 24.26%, 14.16%, 37.46%, 14.96%) on ACM, and (13.11%, 23.31%, 8.47%, 50.37%, 9.86%) on DBLP, respectively. (b) NDCC is on average <ref type="bibr" target="#b16">(18,</ref><ref type="bibr">195,</ref><ref type="bibr" target="#b17">19)</ref> times faster than (CE, CSLR and MIX) on AMiner, <ref type="bibr" target="#b13">(15,</ref><ref type="bibr" target="#b6">8)</ref> times faster than (CE, MIX) on ACM, and 10 times faster than MIX on DBLP, respectively. (c) While GHOST and AM on (AMiner, ACM, DBLP), CSLR on (ACM, DBLP) and CE on DBLP can not finish within 6 hours, NDCC finished on (AMiner, ACM, DBLP) in (98, 543, 2106) seconds, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM FORMULATION</head><p>In this section, we first introduce basic notations and then present a formal definition of scholar name disambiguation.</p><p>Basic notations. For bibliography data D, each citation record contains title, author names, venue, and publication year. We use the Heterogeneous Information Networks (HINs), which are used widely in complex network analysis <ref type="bibr" target="#b18">[20]</ref>, <ref type="bibr" target="#b41">[43]</ref>, to model D. Considering that there are no direct relations among nodes with the same type, we refer to this type of HINs as heterogeneous multipartite networks, which is formally defined as follows.</p><p>A heterogeneous multipartite network is an HIN <ref type="bibr" target="#b28">[30]</ref> whose node set can be divided into several disjoint sets V 0 , V 1 , . . . , V n such that each edge connects a node in V i to another in V j with i = j. Node sets V 0 , V 1 , . . . , V n are called the parts of the network, and the node types in the same part are identical.</p><formula xml:id="formula_0">A P T V W AP W P T W P V</formula><p>Figure <ref type="figure">3</ref>: Heterogeneous multipartite network for scholar name disambiguation. There are four parts: author (A), paper (P ), venue (V ) and title word (T ), and their relationships are labeled with the corresponding adjacency matrices.</p><p>We consider each author reference as a unique author entity initially, then the bibliography data is represented as a 4-part heterogeneous multipartite network, containing the sets of author nodes (A), paper nodes (P ), venue nodes (V ) and title word nodes (T ). Fig. <ref type="figure">3</ref> shows the network schema <ref type="bibr" target="#b28">[30]</ref> of the heterogeneous multipartite network for scholar name disambiguation, where there are three types of edges in this network, i.e., edges connecting author nodes to paper nodes, paper nodes to venue nodes and paper nodes to word nodes. We use three matrices to represent the heterogeneous multipartite network G: W AP , W P T and W P V , storing author-paper edges, paper-(title) word edges and paper-venue edges in heterogeneous multipartite network G, respectively.</p><p>We now formalize scholar name disambiguation with the definition of heterogeneous multipartite networks.</p><p>Problem statement. Given a heterogeneous multipartite network G, the task of scholar name disambiguation is to adjust author nodes and edges between author and paper nodes, such that for each author a in A, the set of paper nodes P a connected to a ideally contains all and only those papers written by author a.</p><p>Besides the relationships directly available from the network G, we also use the following indirect relationships for the author similarity computation.</p><p>(1) Matrix W AA is for valid coauthorship in G, where the entry W AA i,j is the times that authors i and j collaborates. A coauthor relation is valid if two authors have different names. Note that, it is possible that a paper is written by more than one author with the same name. However, we cannot distinguish them without additional information, such as email addresses. In this case, we just keep an arbitrary author reference and neglect the others. We also dismiss self-coauthorships by setting all</p><formula xml:id="formula_1">W AA i,i = 0, such that W AA = W AP ? (W AP ) T -diag(W AP ? (W AP ) T ). (2) Matrix W AA 2</formula><p>is for 2-hop coauthorship in G, where W AA 2 i,j is the number of valid 2-hop coauthorship paths connecting authors i and j. To avoid the redundant information, we only consider valid 2-hop coauthorship paths connecting two authors <ref type="bibr" target="#b9">[11]</ref>. Specifically, a valid 2-hop coauthorship path in G is an AP AP A path a i -p i -a j -p j -a k , where a i = a j , a i = a k , a j = a k and p i = p j .</p><p>(3) Matrices W AN and W AN 2  , obtained from matrices W AA and W AA 2  , are for (author, coauthor name) relations and (author, 2-hop coauthor name) relations, respectively. (4) Matrices W AV and W AT are for (author, venue) relations and (author, word) relations, respectively. W AV a,v is the number of papers that author a publishes in venue v, </p><formula xml:id="formula_2">W AV = W AP ? W P V and W AT = W AP ? W P T .</formula><p>(5) Considering that title words or venues may be limited to an author's publications, we expand these words and venues by considering their similar words and venues. We use matrices W T T and W V V for word-word similarity and venue-venue similarity, respectively. We calculate these two matrices as preprocessing steps before name disambiguation. We present (author, similar word) relations and (author, similar venue) relations with matrices W AST and W ASV , respectively, such that W AST = W AT ? W T T and</p><formula xml:id="formula_3">W ASV = W AV ? W V V .</formula><p>Table <ref type="table" target="#tab_0">1</ref> lists the main symbols and their definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SOLUTION FRAMEWORK</head><p>In this section, we introduce our solution framework NDCC, as illustrated in Fig. <ref type="figure" target="#fig_1">4</ref>.</p><p>(1) Data representation. We represent the bibliography data as a heterogeneous multipartite network, which brings a couple of benefits. First, scholar name disambiguation is formulated with a single network. Specifically, the author nodes in the network are either single author references or atomic clusters (each has several closely related author references) in the beginning. This is a good way to alleviate the error propagation problem caused by ambiguous coauthor names. We disambiguate author names by updating the network, and the final network represents disambiguation results. Second, it is flexible to incorporate extra types of entities such as affiliations and homepages when available.</p><p>(2) Similarity measurement. Because of the ambiguity of coauthor names, such as "Ying Zhang" and "Wei Xu" illustrated in Fig. <ref type="figure" target="#fig_11">1</ref>, we differentiate coauthors from coauthor names. Then, we determine the author similarity by assembling the similarities from four perspectives (coauthor, venue, title, and coauthor name). It is common that some authors only publish a small number of papers. In this case, venues and title words of their papers are not enough to capture their preferences and research interests, especially in the initial heterogeneous multipartite network, where each  author node may only connect to a small number of paper nodes. To alleviate this sparsity problem, we extend the words for authors by considering the words similar to their title words, so do venues. We compute the venue-venue and word-word similarities before name disambiguation begins, as a preprocessing step.</p><p>(3) Collective clustering. Obviously, the name disambiguation for one name may influence the others. For example, in Fig. <ref type="figure" target="#fig_0">2</ref>, merging of "Haixun Wang2" and "Haixun Wang4" leads to new common coauthor to "Wei Wang2" and "Wei Wang4", which affects the disambiguation of the name "Wei Wang". On the other hand, the disambiguation result of "Haixun Wang" is also affected by its coauthors. Based on the above observation, we propose a bottomup collective clustering method to deal with scholar name ambiguity. In collective clustering, the disambiguation of one name affects others by changing the structure of the heterogeneous multipartite network. We iteratively select an author name and calculate the pairwise similarities of its author nodes. We then merge the pairs of author nodes with high similarity scores and update the network accordingly. Each name needs to be disambiguated several times until it is fully disambiguated. To determine the stop condition, we estimate the number of authors for each name. A name is considered to be fully disambiguated if the number of its author nodes reaches the estimated number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AUTHOR SIMILARITY MEASUREMENT</head><p>In this section, we present the author similarity measurement. First, we introduce the preprocessing step to deal with the sparsity problem, which is incorporated into author similarities. Then we propose a novel metric to assemble the similarities from four perspectives: coauthors, venues, titles and coauthor names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dealing with Sparsity</head><p>As pointed out in Section 3, some authors only connect to a small number of paper nodes, especially in the initial heterogeneous multipartite network. It is hard to make a good judgment for these authors. To deal with this sparsity problem, we introduce word-word and venue-venue similarities to expand the limited information.</p><p>(1) Word-word similarity. The title is an important feature to calculate pairwise similarities of authors for name disambiguation. The traditional unigram model treats each word separately and neglects their correlations. It is likely that two titles, which do not share common words, are correlated. For example, one title contains the word "hardware" and the other contains the word "circuit". Both are related to computer hardware. In this case, the traditional unigram model returns a low similarity score. In <ref type="bibr" target="#b16">[18]</ref>, <ref type="bibr" target="#b17">[19]</ref>, the string level or character level tolerance is used when comparing two titles. However, these methods cannot capture the semantic relation between two words either.</p><p>We propose to use Word2vec <ref type="bibr" target="#b23">[25]</ref>, which is an effective word embedding method, to capture the semantic correlations between words. It takes a text corpus as input and maps each word in the text corpus to a vector in a low dimensional space. First, we normalize all titles using NLTK <ref type="bibr" target="#b6">[8]</ref> by turning them into lowercase, removing punctuation, tokenizing and removing stop words. All normalized titles are used as the training text corpus for Word2vec. Then the cosine similarity of word vectors is used as the wordword similarity, which is stored in a matrix denoted by W T T . We keep the pairs whose similarity scores are larger than a threshold ? t , and disregards the others by setting the similarity scores to zeroes.</p><p>(2) Venue-venue similarity. We expand venues for each author, based on an observation that two venues are similar if a large portion of authors both publish papers in these two venues. For example, "SIGMOD" and "VLDB" are both top database conferences, and many authors publish papers in both venues. Hence, "SIGMOD" and "VLDB" are two similar venues. Based on this observation, we propose to use the Jaccard index of authors to measure venue-venue similarity. Formally, given two venues i and j, N i and N j represent the sets of author names who publish at least one paper in i and j, respectively. The similarity between venue i and j is defined as</p><formula xml:id="formula_4">W V V i,j = |N i ? N j | |N i ? N j| .</formula><p>Here we only keep venue pairs with their similarity scores larger a threshold ? v , and neglect the others by setting their scores to 0 in W V V .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Author Similarity Assembling</head><p>The author similarity is assembled by four similarities (coauthor, venue, title, and coauthor name). Given two authors i and j with the same name n, inspired by <ref type="bibr" target="#b17">[19]</ref>, we consider each pair and define the author similarity as:</p><formula xml:id="formula_5">sim = x =y sim x ? sim y ,<label>(1)</label></formula><p>where x, y ? {n, t, v, a} and sim a , sim n , sim t , sim v are coauthor, coauthor name, title and venue similarities, respectively. We omit (i, j) in Eq. ( <ref type="formula" target="#formula_5">1</ref>) as well as equations in the sequel for simplicity. We argue that two authors are likely to be the same person if they are similar in at least two aspects. For example, in Fig. <ref type="figure" target="#fig_0">2</ref>, "Haixun Wang2" and "Haixun Wang4" are similar in terms of coauthor names and venues, so it is likely that they are the same person. On the other hand, in Fig. <ref type="figure" target="#fig_11">1</ref>, although these two "Wei Xu" are similar in the perspective of coauthor name, they are not similar in other perspectives. Thus, they are unlikely to be the same author.</p><p>Intuitively, the more two authors share the same related entities (coauthors, title words, venues, and coauthor names), the more similar they are. Histogram intersection kernel is a common way to measure this similarity between two histograms <ref type="bibr" target="#b29">[31]</ref>. Besides, similar to IDF <ref type="bibr" target="#b14">[16]</ref>, weights of different entities should be normalized by their frequencies. For example, if a coauthor publishes a lot of papers, then it should be considered as a weak evidence comparing to those who only publish one or two papers. Since productive authors are believed to be experts connecting different communities, they likely collaborate with two or more authors with the same name. For instance, "Haixun Wang" in WeWork has over 100 papers, and collaborates both with "Wei Wang" in UCLA and "Wei Wang" in UNSW. From the title perspective, common words, such as "approach" and "system" are less representative comparing to uncommon words like "disambiguation" and "collective". So we differentiate weights of words by assuming that the more frequently a word appears in titles, the less important the word is as evidences. The other two perspectives, i.e., venues and coauthor names, follow similar principles.</p><p>(1) Coauthor similarity. Based on the above observations, we use the normalized histogram intersection kernel to calculate the coauthor similarity sim a , defined as</p><formula xml:id="formula_6">sima = k 1 d A k min(W AA i,k , W AA j,k ) + t(n){ k 1 d A k min(W AA i,k , W AA 2 j,k ) + k 1 d A k min(W AA 2 i,k , W AA j,k ))},<label>(2)</label></formula><p>where</p><formula xml:id="formula_7">t(n) = 1 if kn ? ? 0 otherwise</formula><p>. Here d A k is the number of papers written by author k, which serves the normalization factor, and ? is a threshold determining whether to use multi-hop coauthorships. The first part of the right side of Eq. ( <ref type="formula" target="#formula_6">2</ref>) measures the similarity between coauthors of i and j. The second considers multi-hop coauthors. Comparing with (1-hop) coauthor, multi-hop coauthors are less evidential. We notice that for names with high ambiguities, such as "Wei Wang", using weak evidential features like multi-hop coauthors may introduce errors and decrease the accuracy performance. Thus, for these names, we neglect the multihop coauthorship, and only use the first part.</p><p>The other similarity scores, i.e., Coauthor name, title, and venue similarities, are defined similarly.</p><p>(2) Coauthor name similarity.</p><formula xml:id="formula_8">simn = m 1 d N m min(W AN i,m , W AN j,m ) + t(n){ m 1 d N m min(W AN i,m , W AN 2 j,m ) + m 1 d N m min(W AN 2 i,m , W AN j,m )},<label>(3)</label></formula><p>where t(n) is the same as the one in Eq. ( <ref type="formula" target="#formula_6">2</ref>), and d N m is the number of papers written by authors with name m.</p><p>(3) Title similarity.</p><formula xml:id="formula_9">simt = t 1 d T t min(W AT i,t , W AT j,t ) + { t 1 d T t min(W AT i,t , W AST j,t ) + t 1 d T t min(W AST i,t , W AT j,t )},<label>(4)</label></formula><p>where d T t is the number of papers containing the word t, and we use the bag-of-words model to represent titles. The first part of the right side of Eq. ( <ref type="formula" target="#formula_9">4</ref>) measures the similarity between words both author i and j used in their paper titles. The second part takes similar words into consideration.</p><p>(3) Venue similarity.</p><formula xml:id="formula_10">simv = v 1 d V v min(W AV i,v , W AV j,v ) + { v 1 d V v min(W AV i,v , W ASV j,v ) + v 1 d V v min(W ASV i,v , W AV j,v )},<label>(5)</label></formula><p>where d V v is the number of papers published in venue v. The first part of the right side of Eq. ( <ref type="formula" target="#formula_10">5</ref>) measures the similarity between venues where both author i and j publish papers in. The second part considers similar venues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">COLLECTIVE CLUSTERING</head><p>In this section, we first introduce the collective clustering algorithm with speeding-up strategies for scholar name disambiguation. Our method follows a bottom-up fashion. In the beginning, each author reference is considered as an individual author entity. Different from the densitybased clustering method, such as DBSCAN, where distances between points (or nodes) remain unchanged, our collective clustering method dynamically updates similarities during the disambiguation process. We also analyze its convergence rate as well as time and space complexities of NDCC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Atomic Cluster Generation</head><p>For scholar name disambiguation, some author references can be easily clustered together. For example, papers "Clustering by pattern similarity in large data sets", and "Improving performance of bicluster discovery in a large data set" share the same author names "Jiong Yang", "Wei Wang" and "Haixun Wang". There is a strong probability that these two "Wei Wang" are the same person because they have two identical coauthor names. These two author references form an atomic cluster. Generating atomic clusters as the bootstrap can reduce the size of the initial network, and improve the efficiency. Bootstrap strategies, such as rule based methods, are used widely in the previous name disambiguation methods <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b35">[37]</ref>. Note that using improper rules may include false positive pairs and impair the accuracy performance, such as the example shown in Fig. <ref type="figure" target="#fig_11">1</ref>. Thus, we adopt a highly restrictive rule to generate atomic clusters to significantly alleviate this problem. Inspired by the above observations, two author references are assigned to the same atomic clusters if they share at least two coauthor names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Author Number Estimation</head><p>As mentioned in the framework in Section 3, the estimated number of authors for each name is used as the stop condition, essentially a cluster estimation problem <ref type="bibr" target="#b8">[10]</ref>, <ref type="bibr" target="#b24">[26]</ref> Specifically, a name is considered as fully disambiguated if the number of authors of this name reaches the estimated one. Inspired by name ambiguity estimation in <ref type="bibr" target="#b17">[19]</ref>, we introduce a statistical method, which is based on the statistics of author names in the bibliography data.</p><p>In most cases, a name consist of a fixed number of components. For instance, an English name has three parts: the first name, middle name and last name, and a Chinese name consists of the first name and last name. We assume that these parts are chosen independently from different multinomial distributions, and the probability of a full name Algorithm 1: Collective Clustering is the joint probability of its components <ref type="bibr" target="#b17">[19]</ref>. Here we use the two-component names as an example to explain the main idea. Given a name n, its first name and last name are denoted by F (n) and L(n), which are independently drawn from multinomial distributions M ulti F and M ulti L , respectively. The probability of an author with name n is</p><formula xml:id="formula_11">Input: W AP , W P T , W P V , W V V , W T T , k Output: W AP of the final network G 1 Use BFS to calculate W AA , W AA 2 , W AT , W AST , W AV , W ASV ; 2 Initialize</formula><formula xml:id="formula_12">P r(n) = M ulti F (F (n))?M ulti L (L(n)).</formula><p>Then, the number of authors with name n is k n = P r(n) e?N ke , where ke is the number of authors with name e, and e?N ke is the total number of authors in the bibliography data. Since ke is unknown, we use its estimate k e instead.</p><p>Parameters of M ulti F are estimated by the maximum likelihood estimation. Specifically, ? f , the probability of a first name f appears, is estimated by ? f = n?N,F (n)=f kn e?N ke . So do parameters in M ulti L . We use an EM-like method to update k and parameters in M ulti F and M ulti L iteratively. Specifically, in the beginning, we set k n = 1 for each name n. At each expectation step, we fix parameters in M ulti F and M ulti L , and update k. During iterations, it is possible that</p><formula xml:id="formula_13">k n &lt; 1 or k n &gt; |A (0) n |, where |A (0)</formula><p>n | is the number of atomic author clusters of name n. In this case, we round k n to 1 if k n &lt; 1, and |A (0) n | for the second case. At each maximization step, we update parameters in M ulti F and M ulti L with the k fixed. Expectation and maximization steps are alternatively repeated until k converges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Algorithm</head><p>Given an initial heterogeneous multipartite network G, which is created directly from the bibliography data with bootstrap, as well as the preprocessing results: W V V , W T T and k, collective clustering returns the final author-paper matrix, where each author node represents an author entity in the real world, and connects to all its paper nodes only.</p><p>In collective clustering, disambiguation of one name affects the others by updating the structure of the heterogeneous multipartite network G. In each iteration, we focus on a name n, instead of directly employing hierarchical clustering methods to merge the author nodes with name n, until the number reaches k n . We merge the top K pairs with the highest similarity scores. Here we choose K as the half of the difference between the current author number and the estimated one. Formally,</p><formula xml:id="formula_14">K = |An| -kn 2 ,<label>(6)</label></formula><p>where |A n | is the number of authors with name n in this iteration. Our framework also supports other choices of K, and we leave this part as future work. Each name is disambiguated iteratively until it is fully disambiguated, i.e., the number of its authors reaches the estimated number. The final network is the disambiguation result.</p><p>Observe that it is time-consuming to re-calculate matrices such as W AA and W AA 2 in each iteration when network G is updated for the merging of author nodes, we introduce speeding-up strategies for the computation. We calculate and store those matrices such as W AA and W AA 2 as a preprocessing step before iterations, and update them inside iterations. Considering the sparsity and dynamics of matrices, we use lists of treemaps to store W AA , W AA 2 , W AT , W AST , W AV and W ASV . Specifically, for each author name, we maintain a list of its author nodes. Each author node contains six treemaps to store the corresponding rows in these metrics, respectively. Considering that the author name is just an attribute attached to the author node, we do not store W AN and W AN 2  , as they can be extracted directly from W AA and W AA 2 , respectively. We now explain the detail of our collective clustering. Algorithm 1 shows its overall process. First, it uses breadthfirst search to calculate all the metrics such as W AA , W AA 2 from the input (line 1), and then uses a queue que to store the names to be disambiguated, which is initiated by pushing all names in the bibliography data, except those with only one paper (lines 2-6). Our method iteratively disambiguates author names (lines 7-18). While que is not empty, it pops out a name from que, denoted by n (line 8), and assigns A n the list of author nodes with name n (line 9). If the size of A n is no larger than k n , then the name n is believed to be fully disambiguated. In this case, it just continues to deal with the next name (lines 10-11). Otherwise, it calculates the number of pairs to be merged in this iteration by Eq. ( <ref type="formula" target="#formula_14">6</ref>), denoted by K (line 12). It then calculates pairwise author similarity scores in A n , and finds K-th largest score t by using a K-size minimum heap (lines <ref type="bibr" target="#b11">[13]</ref><ref type="bibr" target="#b12">[14]</ref>. Then it merges author pairs whose similarity scores are no less than t, and updates the network G (equally, the matrix W AP ) accordingly (lines <ref type="bibr" target="#b13">[15]</ref><ref type="bibr" target="#b14">[16]</ref>. It also needs to update W AA etc. (line 17). Then it pushes n into que, and waits for disambiguation results of the remaining names (line 18). After all names have been processed, it finally returns the disambiguation result W AP (line 19).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Matrix Updates</head><p>Next, we present the updating rules for matrices W AA , W AA 2 , W AT , W AST , W AV and W ASV . Given authors i and j to be merged, without loss of generality, we assume that j is merged to i, and the updated i is denoted by ?.</p><p>By the definition, the author-paper matrix W AP is updated as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?AP</head><p>k,p =</p><formula xml:id="formula_15">W AP i,p + W AP j,p if k = ? W AP k,p otherwise<label>(7)</label></formula><p>, where a hat denotes the updated matrix.</p><p>The author-author matrix W AA is updated as follows.</p><formula xml:id="formula_16">?AA k,l = ? ? ? ? ? ? ? ? ? 0 if k = l W AA i,l + W AA j,l if k = ?, k = l W AA k,i + W AA k,j if l = ?, k = l W AA k,l otherwise (8)</formula><p>Correctness of Eq. ( <ref type="formula">8</ref>): Correctness of Eq. ( <ref type="formula">8</ref>) can be proved by combining the definition of W AA and Eq. <ref type="bibr" target="#b5">(7)</ref>.</p><p>As the merging of two author nodes incorporates new 2-hop coauthorships, matrix W AA 2 is updated as follows. </p><formula xml:id="formula_17">?AA 2 k,l = ? ? ? ? ? ? ? ? ? 0 k = l W AA 2 i,l + W AA 2 j,l if k = ?, k = l W AA 2 k,i + W AA 2 k,j if l = ?, k = l W AA 2 k,l + W AA i,k ? W AA j,l + W AA i,l ? W AA j,k otherwise<label>(9)</label></formula><formula xml:id="formula_18">?AA 2 k,l = | P2 ?,l | = |P 2 i,l ? P 2 j,l | = |P 2 i,l | + |P 2 j,l | = W AA 2 i,l + W AA 2 j,l .</formula><p>(</p><formula xml:id="formula_19">) If l = ?, then ?AA 2 k,l = | P2 k, ?| = |P 2 k,i ? P 2 k,j | = |P 2 k,i | + |P 2 k,j | = W AA 2 k,i + W AA 2 k,j .<label>2</label></formula><p>(3) Otherwise</p><formula xml:id="formula_20">?AA 2 k,l = | P2 k,l | = |{p|p ? P2 k,l , ? ? p} ? {p|p ? P2 k,l , ? ? p}| = |{p|p ? P 2 k,l , i ? p} ? {p|p ? P 2 k,l , j ? p}| + |P k,i | ? |P j,l | + |P k,j | ? |P i,l | + |{p|p ? P 2 k,l , i, j ? p}| = |P k,i | ? |P j,l | + |P k,j | ? |P i,l | + |P 2 k,l | = W AA i,k ? W AA j,l + W AA i,l ? W AA j,k + W AA 2 k,l .</formula><p>Similarly, we update ?AV , ?ASV , ?AT and ?AST by</p><formula xml:id="formula_21">?AV k,v = W AV i,v + W AV j,v if k = ? W AV k,v otherwise ?ASV k,v = W ASV i,v + W ASV j,v if k = ? W ASV k,v otherwise ?AT k,t = W AT i,t + W AT j,t if k = ? W AT k,t otherwise ?AST k,t = W AST i,t + W AST j,t if k = ? W AST k,t otherwise<label>(10)</label></formula><p>Correctness of Eq. ( <ref type="formula" target="#formula_21">10</ref>): Since W P V is static, we can prove the correctness of updating W AV by combining definition of W AV and updating rules of W AP . Considering W V V is also static, we can prove the correctness of updating rule for W ASV by definition of W ASV and updating rules of W AV . Similarly, we can prove the correctness of updating rules for W AT and W AST . After merging author j to author i, we delete the corresponding rows and columns from the updated matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Convergence and Complexity Analyses</head><p>We denote the set of author nodes in the initial heterogeneous multipartite network by A (0) . It is easy to find that the size of A is non-increasing. Thus, it is obvious that collective clustering converges.</p><p>We denote the largest number of papers written by the authors with the same name as , and then prove the bound of the number of iterations as the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1 (Iteration number). The iteration number of collective clustering is no more than |N |(log( ) + 2).</head><p>Proof. We denote the iteration number by T N and the number of iterations dealing with name n by T n . Then T N = n?N T n . We also denote the number of authors with name n after the i-th iteration dealing with n by |A</p><formula xml:id="formula_22">(i) n |. Initially, |A (0)</formula><p>n | is the number of atomic authors with name n. According to Eq. ( <ref type="formula" target="#formula_14">6</ref>), A</p><formula xml:id="formula_23">(i+1) n = |A (i) n | - |A (i) n |-kn<label>2</label></formula><p>. Then we have</p><formula xml:id="formula_24">|A (i) n | = |A (0) n |-kn 2 i + k n and T n = log(|A (0) n | -k n ) + 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Finally, we have</head><formula xml:id="formula_25">T N = n T n = n ( log(|A (0) n | -k n ) + 1) ? 2|N | + n log(|A (0) n |) ? 2|N | + n log( ) = |N |(log( ) + 2).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The time complexity of collective clustering is</head><formula xml:id="formula_26">O( 2 log( )(H + |A (0) | log( ))), where H = n (|A (0) n | 2</formula><p>) is the number of atomic author pairs sharing the same names. The space complexity is O(|A (0) | 2 ). More specifically, We use the same notations as the proof of Theorem 1. We assume that each paper has no more than ? keywords in its title, and has no more than ? authors. The time complexity of creating initial matrices is O(|A (0) |( 2 ? 2 log( ?) + ? log( ?))). Since elements in treemaps are sorted, we only need to traverse the corresponding treemaps to calculate the author similarity, which takes linear time w.r.t.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTAL STUDY</head><p>In this section, we present an extensive experimental study of NDCC. Using three real datasets, we conduct four sets of experiments to evaluate (1) the effectiveness and efficiency of NDCC versus state-of-the-art methods CE <ref type="bibr" target="#b5">[7]</ref>, GHOST <ref type="bibr" target="#b9">[11]</ref>, CSLR <ref type="bibr" target="#b17">[19]</ref>, MIX <ref type="bibr" target="#b16">[18]</ref>, and AM <ref type="bibr" target="#b42">[44]</ref>, (2) the effectiveness of author number estimation, (3) effects of important components in NDCC, and (4) the impacts of parameters on accuracy and efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Settings</head><p>We first introduce our experimental settings. Datasets. We use three commonly used real-life datasets AMiner (http://www. aminer.org) <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b31">[33]</ref>, <ref type="bibr" target="#b32">[34]</ref>, <ref type="bibr" target="#b35">[37]</ref> , ACM (http://dl.acm.org) <ref type="bibr" target="#b35">[37]</ref> and DBLP (http://dblp.unitrier.de) <ref type="bibr" target="#b17">[19]</ref> for scholar name disambiguation. Different from previous works that use small size subsets, we build datasets from the whole public available meta-data files directly. The statistics of these datasets are listed in Table <ref type="table" target="#tab_3">2</ref>.</p><p>The test set comes from https://aminer.org/disambiguation, commonly used in name disambiguation tasks <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b35">[37]</ref>. It contains 6,730 labeled papers of 110 author names. We compare the labeled papers with each dataset and use their overlapped ones as the corresponding testing dataset. We use the Macro-F1 score to evaluate the effectiveness. Comparison algorithms. Although NDCC can be easily extended to incorporate other information like affiliations, paper abstracts, homepages, and email addresses, the datasets that we use only contain citation information, like many other digital libraries. Thus, we dismiss baselines relying on these external features <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b35">[37]</ref>, <ref type="bibr" target="#b36">[38]</ref>. Besides, some methods require the number of authors for each name <ref type="bibr" target="#b36">[38]</ref>, <ref type="bibr" target="#b37">[39]</ref>, which is unavailable in practice. Thus, we compare 1041-4347 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. NDCC with the following state-of-the-art methods, which can determine the author numbers automatically and use citation information only.</p><p>(1) CE <ref type="bibr" target="#b5">[7]</ref> is a collective entity resolution method for relational data. Its similarity function considers both attributes and relational information, and a greedy agglomerative clustering method is used to merge the most similar clusters.</p><p>(2) GHOST <ref type="bibr" target="#b9">[11]</ref> is a graph-based method employing coauthorship only. Its similarity function considers both quantity and quality (length) of paths, and an affinity propagation clustering method is used to generate clusters of author references of the focused name.</p><p>(3) CSLR <ref type="bibr" target="#b17">[19]</ref> first groups the author references based on coauthorships to generate initial clusters. Then these clusters are merged by venue-based and title-based similarities.</p><p>(4) MIX <ref type="bibr" target="#b16">[18]</ref> is a supervised method. Random forests are used to calculate pairwise distances, and DBSCAN is used to group the author references. For effectiveness evaluation, we randomly choose 5 (other) labeled names as the training set for each author name to be disambiguated. For efficiency evaluation, we randomly choose 5 labeled names to train the model and use the others for testing.</p><p>(5) AM <ref type="bibr" target="#b42">[44]</ref> is the method deployed in AMiner to tackle the name disambiguation. A representation learning method is used to include global and local information. An end-toend method is proposed to estimate author numbers. We train the model with 500 labeled author names reported in their paper. For a fair comparison, we dismiss non-citation features, including abstracts and affiliations. Implementation. In NDCC, the threshold for word-word similarity ? t is set to 0.75, the threshold for venue-venue similarity ? v is set to 0.02, and the threshold for using weak evidence ? is set to 20. For the other methods, all parameters are set to their default values. All experiments are conducted on a machine with 2 Intel Xeon E5-2630 2.4GHz CPUs and 64 GB of Memory, running 64-bit windows 7. Each experiment is repeated 5 times, and the average is reported here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Results</head><p>We next present our findings. Exp-1: Performance comparison with baselines. In the first set of experiments, we evaluate the effectiveness and efficiency of NDCC against CE, GHOST, CSLR, MIX and AM. Exp-1.1: Accuracy performance comparison. The accuracy results for all methods in three datasets are shown in Table <ref type="table" target="#tab_4">3</ref> and Table <ref type="table" target="#tab_5">4</ref>. In practice, the disambiguation of a name is much challenging if a large number of papers are written by authors with the same name. Thus, we rank the author names in the test set based on paper numbers and list the Macro-F1 scores of the top 10 names with the largest number of papers in Table <ref type="table" target="#tab_4">3</ref>. The number of real authors for each name and the corresponding total number of publications are listed in Table <ref type="table" target="#tab_6">5</ref>. To demonstrate the effeteness of NDCC on the whole dataset, we vary M from 10 to 100 and report results of the top M names in Table <ref type="table" target="#tab_5">4</ref>. For each row, the top performer is highlighted in the bold font. We observe that NDCC consistently outperforms baselines. NDCC achieves the best performances on 8, 6 and 6 out of 10 names listed in Table <ref type="table" target="#tab_4">3</ref> in AMiner, ACM and DBLP, respectively. With the top 100 names as the testing dataset, NDCC improves the Macro-F1 over (CE, GHOST, CSLR, MIX, AM) by (17.87%, 23.25%,16.65%,45.39%, 21.24%) on AMiner, (25.36%, 24.26%, 14.16%, 37.46%, 14.96%) on ACM, and (13.11%, 23.31%, 8.47%, 50.37%, 9.86%) on DBLP, on average, respectively. MIX adopts random forests to learn pairwise similarities, which works well when many features are available, such as abstract, and affiliation <ref type="bibr" target="#b16">[18]</ref>. While, in this study, we address the scholarly name disambiguation problem in a more challenging setting, where only basic citation features are available. We observe that in this setting, a large number of pairwise similarities are 0. As a result, in most cases, MIX achieves high precision scores with very low recall scores, leading to its low F1 scores. GHOST only uses coauthorships, which explains its unsatisfactory accuracy performance. Besides, 3 and 4-hop coauthorships used in GHOST are weak evidences. The ambiguity of (multi-hop) coauthors further harms the accuracy results. CE neglects the venue-venue and word-word similarities, which leads to its low F1 scores. CSLR is a single name disambiguation method that also considers the similarity between venues and words to alleviate the problem caused by limited information. NDCC outperforms it by (28.07%, 25.32% and 11.71%) on (AMiner, ACM, DBLP), which justifies the advantage of collective clustering. Without external information, AM still achieves relatively good results, compared with other baselines. However, this method neglects 2-hop coauthors, which are important features when only citation information is available.</p><p>Exp-1.2: Efficiency performance comparison. Among the chosen baselines, only CE and GHOST analyze the time complexity <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b9">[11]</ref>. The time complexity of CE is O(|A (0) |k log |A (0) |), where |A (0) | is the number of atomic authors, and k is largest number of buckets that a buckets connects to <ref type="bibr" target="#b5">[7]</ref>. It is difficult to exactly compare CE and our method because of k, which is unique to the method. The time complexity of GHOST is O(N 2 ), where N is the number of names to be disambiguated, and is the largest number of papers written by authors with the same name. Although it is theoretically efficient, as a single name disambiguation method, GHOST has to extract a subgraph for each name, which is time consuming in practice.</p><p>To empirically evaluate the efficiency of NDCC, we extract several subsets from AMiner (ACM, DBLP) with different sizes by author names. First, we generate several subsets of author names from AMiner ( ACM, DBLP), with sizes ranging from 50 to 1M (2M and 1.8M on ACM and DBLP, respectively). To maintain the consistency among these sets, we make sure that smaller sets are subsets of the bigger ones. For each set of author names, we extract all papers written by authors in this set to generate the corresponding subset. In this way, we make sure that the generated subsets are dense. Although AM is deployed with thousands of millions of papers, it is not efficient to compute the clustering from scratch due to the local linkage learning and IO overhead <ref type="bibr" target="#b42">[44]</ref>. Indeed, this method even cannot disambiguate all names in the smallest dataset AMiner within 12 hours. Thus, its running time is not reported here.</p><p>The results show that NDCC is more efficient than the baseline methods. (a) NDCC is <ref type="bibr" target="#b16">(18,</ref><ref type="bibr">195,</ref><ref type="bibr" target="#b17">19)</ref> times faster than (CE, CSLR and MIX) on AMiner, (15, 8) times faster than    Exp-2: Effectiveness of estimating author numbers. In the second set of experiments, we evaluate the effectiveness of NDCC in estimating author numbers. We note that the test dataset does not cover all authors in the datasets, and only part of the authors are labeled. For example, there are over 120 authors with the name "Lei Wang" in DBLP, but only 106 of them are labeled. Thus, We cannot evaluate the estimation method directly by comparing the estimated author numbers with labeled authors. Instead, given a name, we compare the number of clusters of the labeled papers with the number of labeled authors to verify the effectiveness of the proposed estimating method. We list the results of the top 10 names in the test set in Table <ref type="table" target="#tab_6">5</ref>. We find that, in most cases, our method achieves reasonable estimating results: #detected Authors #labelled Authors ? (0.5, 2). Besides, the numbers of detected authors are usually larger than the true values. The reason is that authors may change their affiliations and research interests at the same time. In this case, it is hard for name disambiguation methods to tell whether papers published in two periods are written by the same person with limited information.</p><p>Exp-3: Insight of effectiveness. In the third set of experiments, we analyze the effectiveness of each step in NDCC by comparing with its variants. Specifically, we introduce word-word and venue-venue similarities to alleviate the sparsity problem, a new metric to compute the author similarity by considering different aspects, a statistical method to accurately estimate author numbers, and a collective approach to clustering. Since we have two parameters, ? t and ? v , to control the usage of word-word similarities and 1041-4347 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.  venue-venue similarities, we left the evaluations of these two steps in the parameter studies. We adopt three variants, NDCC un, NDCC ave, and NDCC nc to evaluate effects of author similarity computation, author number estimation, and collective clustering, respectively. With the top 100 author names, we compare these variants with NDCC in three datasets. The comparison results are shown in Fig. <ref type="figure" target="#fig_8">6</ref>. Exp-3.1: Effectiveness of author similarity computation. We consider four features to determine the author similarity. Normalized histogram intersection kernels are adopted, which consider the importance of each word, venue, coauthor, and coauthor name. To demonstrate its effectiveness, we compare NDCC with its variant, denoted by NDCC un, which adopts (unnormalized) histogram intersection kernels. As shown in Fig. <ref type="figure" target="#fig_8">6</ref>, normalization in author similarity computations improves the F1 scores by (4.43%, 2.34%, and 1.69%) on three datasets, respectively. Exp-3.2: Effectiveness of author number estimation. To demonstrate the effects of author number estimation, we compare NDCC with its variant NDCC ave, which adopts a simple way to estimate the author numbers. From the test set, we know that on average, each author writes r = 4.87 papers. NDCC ave estimates the number of authors for each name n with # authors = (# papers written by name n)/r. From Fig. <ref type="figure" target="#fig_8">6</ref>, we can see that NDCC outperforms NDCC ave by (6.95%, 0.19%, and 7.48%) on (AMiner, ACM, and DBLP), respectively. The comparison demonstrates the importance of precise estimation of author numbers. Exp-3.3: Effectiveness of collective clustering. To show the effects of collective clustering, we compare NDCC to its noncollective variant, denoted as NDCC nc. NDCC nc disambiguates author names one by one and neglects the ambiguity of coauthor names. Fig. <ref type="figure" target="#fig_8">6</ref> shows that by disambiguating author names separately and independently, NDCC nc achieves much worse performances. On the other hand, by considering their relations and disambiguate all names collectively, NDCC improves the Macro-F1 over NDCC nc by (11.1%, 18.7% and 20.3%) on (AMiner, ACM, and DBLP), respectively. The significant improvements show the advantage of collective clustering. Exp-4: Impacts of parameters. In this set of experiments, we evaluate the effectiveness of including word-word and venue-venue similarity, as well as the impacts of parameters on accuracy and efficiency of NDCC. The parameter ? t controls the number of non-zero elements in W T T , which is the number of similar word pairs. Similarly, ? v determines the number of similar venue pairs, and ? is the parameter determining whether to use multi-coauthorship and multicoauthor names as features. Exp-4.1: Impacts of ? t . To evaluate the impacts of word-word similarity, we vary ? t from 0.5 to 1, and fix other parameters to their default values. With ? t increasing, fewer similar pairs of words are taken into consideration. ? t = 1 means that we dismiss the word-word similarity. The accuracy and running time results of NDCC w.r.t. ? t in AMiner, ACM and DBLP are plotted in Fig. <ref type="figure" target="#fig_10">7</ref>  The results show that (a) including word-word similarity can increase the accuracy performance of NDCC. Specifically, it improves F1 scores up to (0.59%, 2.21%, 0.26%) on (AMiner, ACM, DBLP), respectively, (b) small ? t , such as 0.5, which means words pairs with low similarities are also considered, may decrease the accuracy results, (c) NDCC achieves relatively high accuracy in a wide range of ? t , (d) the running time decreases with increasing ? t because larger ? t reduces the number of non-zero elements of W T T . Exp-4.2: Impacts of ? v . To evaluate the impacts of venue- venue similarity, we vary ? v from 0.01 to 0.1 by step 0.01 and fix other parameters to their default values. Since most similarity scores of venue pairs are located in the range of (0, 0.1), we just range ? v up to 0. The results tell us that (a) the usage of venue similarity can improve the accuracy performance significantly. Specifically, it improves the F1 scores up to (7.28%, 4.58%, 3.09%)   on (AMiner, ACM, DBLP), respectively, (b) when ? v is small, venue pairs with low similar scores are involved, which may decrease the accuracy results, (c) NDCC achieves relatively high F1 scores in a wide range of ? v , (d) the running time goes down as ? v increases, because higher threshold means that less similar venue pairs are considered. Exp-4.3: Impacts of ?. To evaluate the impacts of ?, we vary ? from 1 to 100 <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">5,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr">50,</ref><ref type="bibr">100)</ref> and fix other parameters to their default values. The accuracy results and running time of NDCC w.r.t. ? on three datasets are plotted in Fig. <ref type="figure" target="#fig_2">9</ref>.</p><p>The results show that (a) NDCC is robust to ?, (b) when ? is very large, for example, 100, (author, 2-hop coauthor) and (author, 2-hop coauthor name) relationships are used in similarity calculation for high ambiguous names, which impairs the accuracy performance. At the same time, it leads to more running time. Summary. From these tests, we find the followings.</p><p>(1) Our approach NDCC is effective for scholar name disambiguation. Macro-F1 scores of NDCC are consistently higher than the compared methods in all datasets.</p><p>(2) Our approach NDCC is also very efficient. With speeding up strategies, NDCC could finish on DBLP, which contains over 3 million papers, within an hour.</p><p>(3) The author numbers detected by NDCC are reasonable. (4) We provide insights of NDCC by experimentally demonstrating the effectiveness of its each step.</p><p>(5) Strategies dealing with sparsity improve the accuracy performance. Besides, NDCC introduces thresholds to wordword similarity, venue-venue similarity and author similarity measurement for the sake of practicability and flexibility of real-life applications. We have experimentally shown that NDCC is robust to these parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>In general, existing work for scholar name disambiguation can be divided into two classes: supervised <ref type="bibr" target="#b2">[4]</ref>, <ref type="bibr" target="#b13">[15]</ref>, <ref type="bibr" target="#b15">[17]</ref>, <ref type="bibr" target="#b16">[18]</ref>, <ref type="bibr" target="#b33">[35]</ref>, <ref type="bibr" target="#b36">[38]</ref>, <ref type="bibr" target="#b38">[40]</ref>, <ref type="bibr" target="#b42">[44]</ref> and unsupervised <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b7">[9]</ref>, <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b17">[19]</ref>, <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr" target="#b27">[29]</ref>, <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b32">[34]</ref>, <ref type="bibr" target="#b35">[37]</ref>, <ref type="bibr" target="#b37">[39]</ref>, <ref type="bibr" target="#b39">[41]</ref>, <ref type="bibr" target="#b40">[42]</ref>. Supervised methods use labeled data to train a classifier, e.g., SVM <ref type="bibr" target="#b36">[38]</ref> and random forests <ref type="bibr" target="#b15">[17]</ref>, <ref type="bibr" target="#b16">[18]</ref>, <ref type="bibr" target="#b33">[35]</ref>, which is then used to assign publications to different author entities. However, labeling data is time-consuming and impractical when the bibliography data is large. Unsupervised methods use clustering, e.g., agglomerative clustering <ref type="bibr" target="#b7">[9]</ref>, <ref type="bibr" target="#b17">[19]</ref>, <ref type="bibr" target="#b37">[39]</ref>, affinity propagation <ref type="bibr" target="#b9">[11]</ref> and Markov clustering <ref type="bibr" target="#b39">[41]</ref>, or topic modeling <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr" target="#b27">[29]</ref> to divide the set of author references into different subsets. Our work belongs to the second category.</p><p>There are three kinds of evidences that are commonly explored by disambiguation methods <ref type="bibr" target="#b10">[12]</ref>: citation information <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b36">[38]</ref>, web information <ref type="bibr" target="#b17">[19]</ref>, affiliation <ref type="bibr" target="#b3">[5]</ref>, and implicit evidence <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr" target="#b27">[29]</ref>. Citation information is extracted directly from citation records, including author names, title, venue, publication year. Our work only uses citation information, and applies to most digital libraries. It is also known that the usage of new evidence, e.g., wiki <ref type="bibr" target="#b17">[19]</ref>, abstracts <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b35">[37]</ref>, and homepages <ref type="bibr" target="#b35">[37]</ref>, usually improves the disambiguation performance. These methods are orthogonal to our method and can be combined to further improve the performance of our method.</p><p>Most existing name disambiguation methods are designed to tackle single name ambiguity and dismiss their connections. While in this study, we focus on scholar name disambiguation in a collective way. There are also some collective entity resolution methods that can be used to solve multiple name disambiguation problem <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b12">[14]</ref>, <ref type="bibr" target="#b25">[27]</ref>. However, they are not designed for scholar name disambiguation, as they mainly aim to deal with duplication problems in relational databases caused by different forms of the same names. Most of them need another clean knowledge base (KB) <ref type="bibr" target="#b12">[14]</ref>, <ref type="bibr" target="#b25">[27]</ref>, which is unavailable in most cases. <ref type="bibr" target="#b5">[7]</ref> is a collective entity resolution method without a KB. However, it needs to store all pairs of similar author references and their similarity scores in a single queue. Its high space complexity keeps it away from large-scale data analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS</head><p>Considering the connections of scholar names, we have proposed a collective approach to scholar name disambiguation. We have developed a novel metric to determine the author similarity by assembling the similarities of four features (coauthors, venues, titles and coauthor names). To deal with the sparsity problem, we have also introduced word-word and venue-venue similarities. As is shown in the experimental study, NDCC is both effective and efficient for scholar name disambiguation.</p><p>Our collective clustering method may have the potential for a more general setting, where multiple clustering problems need to be solved jointly, such as community detection in multiple networks <ref type="bibr" target="#b20">[22]</ref>, <ref type="bibr" target="#b21">[23]</ref>. A couple of topics need further investigation. First, we are to combine new evidence to further improve the performance of our method. Second, we are to study NDCC in a dynamic scenario.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example heterogeneous multipartite network, such that the left represents the initial scholarly data, and the right represents the final disambiguation results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Framework of NDCC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Correctness of Eq. ( 9 ):</head><label>9</label><figDesc>We denote the set of valid coauthor paths and valid 2-hop coauthor paths connecting author k and l by P k,l and P 2 k,l , respectively. We use a ? p if path p contains author a, and use hats to represent the updated sets. Then W AA k,l = |P k,l | and W AA 2 k,l = |P 2 k,l |. By the definition of the valid 2-hop coauthor path, if k = l, we have ?AA 2 k,l = | P2 k,l | = 0. Next, we discuss the other cases where k = l. (1) If k = ?, then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>time to find the K-th largest similarity score. Putting these together, the time complexity of collective clustering is O( 2 log( )(H + |A (0) | log( ))), where H = n (|A (0) n | 2 ) is the number of atomic author pairs sharing the same names. It takes O(|A (0) | + |P |(1 + ? + ?)) space to store G and preprocessing results, and O(|A (0) |( 2 ? 2 + ?)) space to store the other matrices. By considering ? and ? as constants, the space complexity is O(|A (0) | 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2020.3011674, IEEE Transactions on Knowledge and Data Engineering IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, JULY 2020</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Running time on AMiner, ACM and DBLP w.r.t. the network size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2020.3011674, IEEE Transactions on Knowledge and Data Engineering IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Comparison between NDCC and its variants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) and Fig. 7(b), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Accuracy and efficiency w.r.t. ? t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>1 .</head><label>1</label><figDesc>The accuracy and running time results of NDCC w.r.t. different ? v on AMiner, ACM and DBLP are plotted in Fig. 8(a) and Fig. 8(b), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Accuracy and efficiency w.r.t. ? v .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Main symbols</figDesc><table><row><cell>Symbols</cell><cell>Definitions</cell></row><row><cell>G</cell><cell>heterogeneous multipartite networks</cell></row><row><cell>A, P , V , T</cell><cell>set of author/paper/venue/word nodes in G</cell></row><row><cell>A (0)</cell><cell>set of author nodes in the initial network</cell></row><row><cell>N</cell><cell>set of author names in the bibliography data</cell></row><row><cell>W AP</cell><cell></cell></row><row><cell>W P T</cell><cell>adjacency matrices for (A-P), (P-T) and (P-V)</cell></row><row><cell>W P V</cell><cell></cell></row><row><cell>W T T</cell><cell>matrices for word-word similarity</cell></row><row><cell>W V V</cell><cell>matrices for venue-venue similarity</cell></row><row><cell>W AA</cell><cell>matrices for coauthorships</cell></row><row><cell>W AA 2</cell><cell>matrices for 2-hop coauthorships</cell></row><row><cell>W AN</cell><cell>matrices for (author, coauthor name) relations</cell></row><row><cell>W AN 2</cell><cell>matrices for (author, 2-hop coauthor name) relations</cell></row><row><cell>W AV</cell><cell>matrices for (author, venue) relations</cell></row><row><cell>W ASV</cell><cell>matrices for (author, similar venue) relations</cell></row><row><cell>W AT</cell><cell>matrices for (author, word) relations</cell></row><row><cell>W AST</cell><cell>matrices for (author, similar word) relations</cell></row><row><cell>d A , d V , d T</cell><cell>vector for degree of each author/venue/word node</cell></row><row><cell>d N</cell><cell>vector for number of papers of each name</cell></row><row><cell>k</cell><cell>vector for estimated author number of each name</cell></row></table><note><p>and W AT a,t is the times that author a uses word t. That is,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>an empty queue que; 3 foreach author name n do An ? the list of authors with name n; An ? the list of authors with name n; AA , W AA 2 , W AT , W AST , W AV and W ASV with Eq. (8, 9, 10);</figDesc><table><row><cell>5</cell><cell>if |An| &gt; 1 then</cell></row><row><cell>6</cell><cell>que.push(n);</cell></row><row><cell cols="2">7 while que is not empty do</cell></row><row><cell>8</cell><cell>n ? que.pop();</cell></row><row><cell>10</cell><cell>if |An| ? kn then</cell></row><row><cell>11</cell><cell>Continue</cell></row><row><cell>12 13</cell><cell>K ? |An|-kn 2 Calculate author pairwise similarities in An with Eq. ;</cell></row><row><cell></cell><cell>(1);</cell></row><row><cell>14</cell><cell>t ? the K-th largest pairwise similarity score;</cell></row><row><cell>15</cell><cell>Merge author pairs whose similarity scores are no</cell></row><row><cell></cell><cell>less than t;</cell></row><row><cell>18</cell><cell>que.push(n);</cell></row></table><note><p>4 9 16 Update the author-paper matrix W AP with Eq. (7); 17 Update W 19 Return W AP .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Statistics of real-life bibliography datasets</figDesc><table><row><cell>Name</cell><cell>|P |</cell><cell>|T |</cell><cell>|V |</cell><cell>|N |</cell></row><row><cell>AMiner</cell><cell>1,397,240</cell><cell>233,503</cell><cell>16,442</cell><cell>1,062,896</cell></row><row><cell>ACM</cell><cell>2,381,719</cell><cell>327,287</cell><cell>273,274</cell><cell>2,002,754</cell></row><row><cell>DBLP</cell><cell>3,566,329</cell><cell>251,429</cell><cell>12,486</cell><cell>1,871,439</cell></row><row><cell cols="5">the sizes of treemaps. So it takes O( 2 ? 2 + ?) time to</cell></row><row><cell cols="5">calculate the similarity of two authors. For each pair of</cell></row><row><cell cols="5">author nodes to be merged, based on Eq. (8, 9, 10), it takes</cell></row><row><cell cols="5">O( 2 ? log( ?) + ? log( ?)) time to update matrices as well</cell></row><row><cell cols="5">as G. In most cases, a paper contains no more than 10</cell></row><row><cell cols="5">authors, and no more than 10 keywords. Treating ? and ? as</cell></row><row><cell cols="5">constants, the time complexities of calculating the similarity</cell></row><row><cell cols="5">of two authors and merging two author nodes are O( 2 )</cell></row><row><cell cols="5">and O( 2 log( )), respectively. From Theorem 1, each name</cell></row><row><cell cols="5">n is disambiguated log(|A (0) n | -k n ) + 1 times. In the i-th</cell></row><row><cell cols="4">iteration dealing with name n, it takes O(|A</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison of accuracy performance with the top 10 names using Macro-F1 scores (%)</figDesc><table><row><cell>Name</cell><cell>CE</cell><cell>GHOST</cell><cell cols="2">AMiner CSLR MIX</cell><cell>AM</cell><cell>NDCC</cell><cell>CE</cell><cell>GHOST</cell><cell cols="2">ACM CSLR</cell><cell>MIX</cell><cell>AM</cell><cell>NDCC</cell><cell>CE</cell><cell>GHOST</cell><cell cols="2">DBLP CSLR MIX</cell><cell>AM</cell><cell>NDCC</cell></row><row><cell>Wen Gao</cell><cell>64.0</cell><cell>46.1</cell><cell>87.3</cell><cell>8.8</cell><cell>83.6</cell><cell>91.8</cell><cell>90.4</cell><cell>48.9</cell><cell>90.7</cell><cell></cell><cell>8.1</cell><cell>89.3</cell><cell>96.2</cell><cell>91.9</cell><cell>79.7</cell><cell>95.4</cell><cell>3.8</cell><cell>73.0</cell><cell>96.3</cell></row><row><cell>Lei Wang</cell><cell>41.8</cell><cell>20.3</cell><cell>53.2</cell><cell>39.0</cell><cell>21.2</cell><cell>59.7</cell><cell>7.8</cell><cell>24.0</cell><cell>23.8</cell><cell cols="2">48.7</cell><cell>26.1</cell><cell>55.1</cell><cell>14.4</cell><cell>15.2</cell><cell>57.2</cell><cell>29.9</cell><cell>18.7</cell><cell>77.4</cell></row><row><cell>David E. Goldberg</cell><cell>85.2</cell><cell>73.0</cell><cell>81.0</cell><cell>7.6</cell><cell>96.6</cell><cell>98.3</cell><cell>82.9</cell><cell>74.5</cell><cell>91.9</cell><cell></cell><cell>8.1</cell><cell>93.8</cell><cell>98.5</cell><cell>79.3</cell><cell>73.9</cell><cell>97.1</cell><cell>5.7</cell><cell>100.0</cell><cell>100.0</cell></row><row><cell>Yu Zhang</cell><cell>52.8</cell><cell>30.9</cell><cell>53.2</cell><cell>50.0</cell><cell>34.1</cell><cell>67.2</cell><cell>10.7</cell><cell>25.2</cell><cell>41.4</cell><cell cols="2">48.4</cell><cell>28.3</cell><cell>68.8</cell><cell>16.6</cell><cell>15.7</cell><cell>68.2</cell><cell>33.3</cell><cell>31.5</cell><cell>57.3</cell></row><row><cell>Jing Zhang</cell><cell>43.7</cell><cell>33.1</cell><cell>56.3</cell><cell>54.3</cell><cell>31.7</cell><cell>50.3</cell><cell>14.0</cell><cell>22.2</cell><cell>53.0</cell><cell cols="2">56.9</cell><cell>33.6</cell><cell>67.4</cell><cell>20.7</cell><cell>12.7</cell><cell>63.7</cell><cell>46.3</cell><cell>22.6</cell><cell>61.8</cell></row><row><cell>Lei Chen</cell><cell>51.8</cell><cell>36.6</cell><cell>76.0</cell><cell>13.1</cell><cell>28.1</cell><cell>72.4</cell><cell>53.5</cell><cell>39.4</cell><cell>78.1</cell><cell cols="2">12.1</cell><cell>26.4</cell><cell>72.2</cell><cell>59.5</cell><cell>46.1</cell><cell>75.1</cell><cell>8.0</cell><cell>38.1</cell><cell>70.1</cell></row><row><cell>Yang Wang</cell><cell>36.4</cell><cell>40.0</cell><cell>29.6</cell><cell>18.6</cell><cell>19.1</cell><cell>42.6</cell><cell>19.4</cell><cell>36.4</cell><cell>34.7</cell><cell cols="2">20.3</cell><cell>30.0</cell><cell>34.9</cell><cell>38.1</cell><cell>62.8</cell><cell>43.5</cell><cell>23.7</cell><cell>22.6</cell><cell>44.1</cell></row><row><cell>Bing Liu</cell><cell>56.3</cell><cell>40.8</cell><cell>61.0</cell><cell>6.3</cell><cell>53.1</cell><cell>62.2</cell><cell>47.3</cell><cell>49.1</cell><cell>70.3</cell><cell></cell><cell>5.3</cell><cell>82.6</cell><cell>73.6</cell><cell>61.6</cell><cell>42.7</cell><cell>68.9</cell><cell>5.0</cell><cell>67.9</cell><cell>73.1</cell></row><row><cell>Hao Wang</cell><cell>35.8</cell><cell>41.5</cell><cell>48.1</cell><cell>43.7</cell><cell>33.8</cell><cell>59.4</cell><cell>13.6</cell><cell>39.4</cell><cell>52.3</cell><cell cols="2">62.9</cell><cell>35.1</cell><cell>56.5</cell><cell>20.6</cell><cell>14.4</cell><cell>48.4</cell><cell>37.9</cell><cell>43.0</cell><cell>57.3</cell></row><row><cell>Gang Chen</cell><cell>43.4</cell><cell>46.5</cell><cell>57.7</cell><cell>46.7</cell><cell>20.7</cell><cell>59.7</cell><cell>44.7</cell><cell>59.4</cell><cell>50.1</cell><cell cols="2">44.6</cell><cell>22.4</cell><cell>62.7</cell><cell>56.7</cell><cell>46.1</cell><cell>61.1</cell><cell>17.9</cell><cell>37.5</cell><cell>66.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison of accuracy performance using Macro-F1 scores (%)</figDesc><table><row><cell># Top Names</cell><cell>CE</cell><cell>GHOST</cell><cell cols="2">AMiner CSLR MIX</cell><cell>AM</cell><cell>NDCC</cell><cell>CE</cell><cell>GHOST</cell><cell cols="2">ACM CSLR</cell><cell>MIX</cell><cell>AM</cell><cell>NDCC</cell><cell>CE</cell><cell>GHOST</cell><cell cols="2">DBLP CSLR MIX</cell><cell>AM</cell><cell>NDCC</cell></row><row><cell>10</cell><cell>51.1</cell><cell>40.9</cell><cell>60.3</cell><cell>28.8</cell><cell>45.5</cell><cell>66.4</cell><cell>38.4</cell><cell>41.9</cell><cell>58.6</cell><cell cols="2">31.5</cell><cell>46.8</cell><cell>68.6</cell><cell>45.9</cell><cell>40.9</cell><cell>67.9</cell><cell>21.1</cell><cell>45.4</cell><cell>73.1</cell></row><row><cell>20</cell><cell>48.8</cell><cell>44.8</cell><cell>60.7</cell><cell>24.5</cell><cell>45.0</cell><cell>67.7</cell><cell>34.1</cell><cell>43.2</cell><cell>56.2</cell><cell cols="2">32.1</cell><cell>45.1</cell><cell>71.8</cell><cell>45.6</cell><cell>42.6</cell><cell>70.1</cell><cell>22.3</cell><cell>47.5</cell><cell>71.9</cell></row><row><cell>30</cell><cell>49.0</cell><cell>50.7</cell><cell>56.8</cell><cell>24.4</cell><cell>52.0</cell><cell>70.8</cell><cell>35.6</cell><cell>49.1</cell><cell>56.4</cell><cell cols="2">31.6</cell><cell>54.6</cell><cell>72.4</cell><cell>52.6</cell><cell>51.8</cell><cell>71.1</cell><cell>21.9</cell><cell>54.8</cell><cell>77.7</cell></row><row><cell>40</cell><cell>53.0</cell><cell>52.0</cell><cell>57.6</cell><cell>27.9</cell><cell>49.8</cell><cell>70.5</cell><cell>40.0</cell><cell>51.8</cell><cell>57.6</cell><cell cols="2">35.0</cell><cell>54.5</cell><cell>72.1</cell><cell>56.3</cell><cell>53.3</cell><cell>72.0</cell><cell>25.6</cell><cell>57.7</cell><cell>79.7</cell></row><row><cell>50</cell><cell>52.6</cell><cell>51.9</cell><cell>58.2</cell><cell>27.9</cell><cell>51.5</cell><cell>72.0</cell><cell>42.7</cell><cell>52.8</cell><cell>58.3</cell><cell cols="2">35.2</cell><cell>55.7</cell><cell>75.0</cell><cell>58.4</cell><cell>54.6</cell><cell>73.9</cell><cell>26.2</cell><cell>61.3</cell><cell>79.9</cell></row><row><cell>60</cell><cell>54.9</cell><cell>51.2</cell><cell>58.4</cell><cell>30.0</cell><cell>52.0</cell><cell>73.0</cell><cell>46.5</cell><cell>53.3</cell><cell>60.0</cell><cell cols="2">35.8</cell><cell>57.3</cell><cell>76.0</cell><cell>61.4</cell><cell>53.4</cell><cell>74.1</cell><cell>27.3</cell><cell>63.7</cell><cell>79.5</cell></row><row><cell>70</cell><cell>57.3</cell><cell>52.1</cell><cell>58.3</cell><cell>30.0</cell><cell>52.7</cell><cell>74.5</cell><cell>49.2</cell><cell>52.9</cell><cell>60.2</cell><cell cols="2">37.4</cell><cell>58.2</cell><cell>76.9</cell><cell>63.9</cell><cell>54.6</cell><cell>74.4</cell><cell>28.3</cell><cell>66.3</cell><cell>80.9</cell></row><row><cell>80</cell><cell>58.3</cell><cell>52.4</cell><cell>58.4</cell><cell>30.4</cell><cell>54.3</cell><cell>74.6</cell><cell>51.1</cell><cell>53.4</cell><cell>61.2</cell><cell cols="2">38.6</cell><cell>60.2</cell><cell>77.2</cell><cell>66.7</cell><cell>56.7</cell><cell>73.9</cell><cell>28.6</cell><cell>68.3</cell><cell>81.0</cell></row><row><cell>90</cell><cell>57.6</cell><cell>52.2</cell><cell>57.9</cell><cell>30.1</cell><cell>54.9</cell><cell>75.5</cell><cell>51.2</cell><cell>52.8</cell><cell>60.6</cell><cell cols="2">38.7</cell><cell>61.5</cell><cell>76.9</cell><cell>66.9</cell><cell>56.8</cell><cell>73.0</cell><cell>29.5</cell><cell>69.7</cell><cell>80.9</cell></row><row><cell>100</cell><cell>58.0</cell><cell>52.7</cell><cell>59.3</cell><cell>30.6</cell><cell>54.7</cell><cell>76.0</cell><cell>52.1</cell><cell>53.2</cell><cell>61.8</cell><cell cols="2">40.0</cell><cell>62.5</cell><cell>77.5</cell><cell>67.7</cell><cell>57.5</cell><cell>72.3</cell><cell>30.4</cell><cell>70.9</cell><cell>80.8</cell></row><row><cell>10 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Statistics of the top 10 names in the test set and detected author numbers in three datasets</figDesc><table><row><cell>Name</cell><cell cols="3">#Authors # Papers AMiner</cell><cell>ACM</cell><cell>DBLP</cell></row><row><cell>Wen Gao</cell><cell>10</cell><cell>461</cell><cell>12</cell><cell>12</cell><cell>21</cell></row><row><cell>Lei Wang</cell><cell>106</cell><cell>289</cell><cell>91</cell><cell>98</cell><cell>122</cell></row><row><cell>David E. Goldberg</cell><cell>3</cell><cell>211</cell><cell>4</cell><cell>4</cell><cell>18</cell></row><row><cell>Yu Zhang</cell><cell>65</cell><cell>209</cell><cell>62</cell><cell>87</cell><cell>99</cell></row><row><cell>Jing Zhang</cell><cell>76</cell><cell>198</cell><cell>61</cell><cell>74</cell><cell>93</cell></row><row><cell>Lei Chen</cell><cell>35</cell><cell>179</cell><cell>39</cell><cell>34</cell><cell>52</cell></row><row><cell>Yang Wang</cell><cell>48</cell><cell>177</cell><cell>52</cell><cell>59</cell><cell>68</cell></row><row><cell>Bing Liu</cell><cell>16</cell><cell>171</cell><cell>32</cell><cell>29</cell><cell>23</cell></row><row><cell>Hao Wang</cell><cell>46</cell><cell>165</cell><cell>48</cell><cell>55</cell><cell>73</cell></row><row><cell>Gang Chen</cell><cell>40</cell><cell>163</cell><cell>35</cell><cell>44</cell><cell>57</cell></row><row><cell cols="6">(CE, MIX) on ACM, 10 times faster than MIX on DBLP, on</cell></row><row><cell cols="6">average, respectively. (b) While GHOST on (AMiner, ACM,</cell></row><row><cell cols="6">DBLP), CSLR on (ACM, DBLP) and CE on DBLP could</cell></row><row><cell cols="6">not finish in 6 hours, NDCC could finish on (AMiner, ACM,</cell></row><row><cell cols="5">DBLP) in (98, 543, 2106) seconds, respectively.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2020.3011674, IEEE Transactions on Knowledge and Data Engineering IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, JULY 2020</figDesc><table /><note><p><p>Authorized licensed use limited to: CALIFORNIA INSTITUTE OF TECHNOLOGY. Downloaded on September 27,2020 at 13:14:04 UTC from IEEE Xplore. Restrictions apply.</p>1041-4347 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, JULY 2020</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Authorized licensed use limited to: CALIFORNIA INSTITUTE OF TECHNOLOGY. Downloaded on September 27,2020 at 13:14:04 UTC from IEEE Xplore. Restrictions apply.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work is supported in part by <rs type="funder">National Key R&amp;D Program of China</rs> <rs type="grantNumber">2018AAA0102301</rs>, and <rs type="grantNumber">NSFC 61925203 &amp; U1636210 &amp; 61421003</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CyaV55h">
					<idno type="grant-number">2018AAA0102301</idno>
				</org>
				<org type="funding" xml:id="_JynwzMR">
					<idno type="grant-number">NSFC 61925203 &amp; U1636210 &amp; 61421003</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dblp</surname></persName>
		</author>
		<ptr target="http://dblp.uni-trier.de/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Google</forename><surname>Scholar</surname></persName>
		</author>
		<ptr target="https://scholar.google.com/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Use of researchgate and google cse for author name disambiguation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Abdulhayoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thijs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1965" to="1985" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Effective unsupervised author disambiguation with relative frequencies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Backes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JCDL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Alleviating poor context with background knowledge for named entity disambiguation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barrena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Collective entity resolution in relational data</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDD</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Author disambiguation by hierarchical agglomerative clustering with adaptive stopping criterion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Dragut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ouzzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving spectral clustering with deep embedding and cluster estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sathe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Shim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On graph-based name disambiguation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JDIQ</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A brief survey of automatic methods for author name disambiguation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gonc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Laender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Named entity disambiguation for little known referents: a topic-based approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Collective entity resolution with multi-focal attention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ringaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Elm-based name disambiguation in bibliography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WWW</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="253" to="263" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m">Data mining: concepts and techniques</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large scale author name disambiguation in digital libraries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Treeratpituk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE BigData</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online person name disambiguation with constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Treeratpituk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCDL</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Author name disambiguation using a new categorical distribution similarity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Semisupervised clustering in attributed heterogeneous information networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Athena: A ranking enabled scholarly search system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust multinetwork clustering via joint cross-domain cluster alignment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep multigraph clustering via attentive cross-graph association</title>
		<author>
			<persName><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Query independent scholarly article ranking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimating the optimal number of clusters k in a dataset using data depth</title>
		<author>
			<persName><forename type="first">C</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Baidari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="132" to="140" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A probabilistic model for linking named entities in web text with heterogeneous information networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A latent topic model for complete entity resolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient topic-based unsupervised name disambiguation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Councill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JCDL</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Mining Heterogeneous Information Networks: Principles and Methodologies. Synthesis Lectures on Data Mining and Knowledge Discovery</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Color indexing. IJCV</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A unified probabilistic framework for name disambiguation in digital library</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A unified framework for name disambiguation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Disambiguating authors in academic publications using random forests</title>
		<author>
			<persName><forename type="first">P</forename><surname>Treeratpituk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JCDL</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Named entity disambiguation for questions in community question answering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adana: Active name disambiguation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Object distinction: Distinguishing objects with identical names</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Name disambiguation in anonymized graphs using network embedding</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bayesian non-exhaustive classification a case study: Online name disambiguation using temporal record streams</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Name disambiguation from link data in a collaboration graph</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>ASONAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Andmc: An algorithm for author name disambiguation based on molecular cross clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xinhua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DASFAA</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Deep collective classification in heterogeneous information networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Name disambiguation in aminer: Clustering, maintenance, and human in the loop</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
