<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VFH*: Local Obstacle Avoidance with Look-Ahead Verification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Iwan</forename><surname>Ulrich</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Michigan Dept. of Mechanical Engineering and Applied Mechanics</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Johann</forename><surname>Borenstein</surname></persName>
							<email>johannb@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Michigan Dept. of Mechanical Engineering and Applied Mechanics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">VFH*: Local Obstacle Avoidance with Look-Ahead Verification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0B2B39647D134805ABDACF5086D4D5AD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an enhancement to the earlier developed Vector Field Histogram (VFH) method for mobile robot obstacle avoidance. The enhanced method, called VFH*, successfully deals with situations that are problematic for purely local obstacle avoidance algorithms. The VFH* method verifies that a particular candidate direction guides the robot around an obstacle. The verification is performed by using the A* search algorithm and appropriate cost and heuristic functions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Many mobile robot systems combine a global pathplanning module with a local obstacle avoidance module to perform navigation. While the global path planner determines a suitable path based on a map of the environment, the obstacle avoidance algorithm determines a suitable direction of motion based on recent sensor data. Obstacle avoidance is performed locally in order to ensure that real-time constraints are satisfied. A fast update rate of the obstacle avoidance algorithm is required to allow the robot to safely travel at high speeds.</p><p>In 1985, Khatib presented the concept of artificial potential fields, which was the first real-time obstacle avoidance algorithm for mobile robots as well as for manipulators <ref type="bibr" target="#b5">[6]</ref>. Around the same time, Moravec and Elfes pioneered the concept of certainty grids, a widely popular map representation that is well suited for sensor data accumulation and sensor fusion <ref type="bibr" target="#b9">[10]</ref>. By integrating the concept of potential fields with the concept of certainty grids, Borenstein and Koren developed the Virtual Force Field method <ref type="bibr" target="#b0">[1]</ref>. However, based on their experiments, they discovered and analyzed substantial shortcomings that are inherent to the concept of potential fields <ref type="bibr" target="#b6">[7]</ref>. In order to overcome these shortcomings, they then developed the Vector Field Histogram (VFH), a method that looks for gaps in locally constructed polar histograms <ref type="bibr" target="#b1">[2]</ref>. VFH was less likely to get trapped in local minima and allowed robots to travel at faster speeds without becoming unstable <ref type="bibr" target="#b8">[9]</ref>.</p><p>Due to its advantages, VFH became a popular obstacle avoidance method. However, its wide use resulted in the discovery of shortcomings. Several researchers, some of them inspired by their experiments with VFH, then developed algorithms based on the novel concept of the Steer Angle Field approach <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11]</ref>. We experienced similar problems with the original VFH method when we implemented it in the GuideCane, a special type of mobile robot for the guidance of the blind <ref type="bibr" target="#b2">[3]</ref>. Instead of changing the underlying concept of VFH, we overcame its problems with four incremental improvements, which led to VFH+ <ref type="bibr" target="#b11">[12]</ref>. First, VFH+ takes into account the width of the mobile robot by using an implicit configuration space approach without explicitly building the Cspace <ref type="bibr" target="#b7">[8]</ref>. Second, VFH+ takes into account the robot trajectory. This improvement is particularly useful at high speed when the minimum steering radius can no longer be neglected. Third, VFH+ results in a trajectory that is less oscillatory due to a threshold hysteresis. Fourth, VFH+ is able to commit to a direction due to an improved direction selection, which is based on a cost function.</p><p>Although we were satisfied with the performance of VFH+ in general, the algorithm sometimes made undesirable choices. Because these situations occurred rarely, the underlying problem was only discovered after extensive testing of the GuideCane. In the next section we will give a detailed description of such a situation that is problematic for a purely local obstacle avoidance algorithm like VFH+. Section 3 outlines the VFH* algorithm, which overcomes this problem with look-ahead verification. Section 4 explains the purpose of the search parameters, while Section 5 describes the VFH* algorithm in detail. Section 6 presents experimental results, and the paper ends with a conclusion in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PURELY LOCAL OBSTACLE AVOIDANCE</head><p>VFH+ sometimes fails to choose the most appropriate direction because of its purely local nature. The inherent problem of purely local obstacle avoidance algorithms can best be explained with an example. Fig. <ref type="figure" target="#fig_0">1</ref> shows a situation where a mobile robot travels down a corridor and encounters two obstacles in its path. Obstacles are shown in black, while the configuration space is shown in gray. Although VFH+ uses the concept of con-figuration space only implicitly, the configuration space is drawn explicitly for better visualization.</p><p>The large circle drawn in a dashed line shows the approximate distance at which an obstacle triggers an avoidance maneuver. At the position shown in the example, VFH+ detects two openings. While the opening to the left results in the undesirable trajectory A, the opening to the right results in trajectory B, which at point p eventually turns into the desirable trajectory C. Unfortunately, both trajectories A and B appear equally appropriate to VFH+. In problematic situations like this, VFH+ would thus select the appropriate direction on average only 50% of the time.</p><p>It is important to note that we expect the same problem to occur with other purely local obstacle avoidance algorithms, such as those based on the steer angle field approach. The underlying problem is that purely local systems only consider the immediate effects of their selected trajectory without verifying its consequence.</p><p>It is also important to note that a larger trigger distance would not eliminate the problem. The same problem would simply occur earlier in the process. Unless the circle was extremely large, the mobile robot would still have two choices when it encounters the obstacle. A large trigger distance is also not practical, because obstacle avoidance maneuvers would start unnecessarily early. Moreover, a large trigger distance might lead the system to no longer detect existing openings and falsely report a trap situation.</p><p>The VFH* algorithm described in this paper overcomes problematic situations like this one most of the time by combining VFH+ with the A* search algorithm. VFH* does so by projecting the trajectory of the robot several steps ahead and evaluating the consequences. While VFH* is no longer purely local, it is still a local algorithm and thus performs in real-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE VFH* ALGORITHM</head><p>The VFH+ method builds a polar histogram around the robot's current position, looks for openings in the histogram, and then determines between one and three suitable directions for each opening. VFH+ also assigns a cost value to each of these primary candidate directions. VFH+ then selects the primary candidate direction with the lowest cost as its new direction of motion.</p><p>In contrast, VFH* analyzes the consequences of heading towards each primary candidate direction before making a final choice for the new direction of motion. For each primary candidate direction, VFH* computes the new position and orientation that the robot would have after moving for a projected step distance d s . At every projected position, VFH+ is again used to construct a new polar histogram based on the map information. This histogram is then analyzed for candidate directions, called projected candidate directions. By repeating this process n g times, we build a search tree of depth n g , where the end nodes (goals) correspond to a total projected distance of d t = n g •d s .</p><p>The goal of this search process is to find a suitable projected trajectory of distance d t . Nodes in the search tree represent the projected positions and orientations of the mobile robot. Arcs represent the candidate directions leading from one position to another.</p><p>For every candidate direction c, a cost g(c) is calculated similar to the cost function used in VFH+. The cost associated with a node is simply the sum of the costs of the branches leading back to the start node. The primary candidate direction that leads to the end node with the smallest total cost is then selected as the new direction of heading ϕ d .</p><p>For an easier understanding of the concept, we have described VFH* as if it was based on the breadth-first search (BFS) algorithm. Actually, VFH* employs the A* search method and uses a heuristic function h(c) that is similar to the cost function of VFH+. The priority value for each node is then defined by f(c) = g(c) + h(c). Because it takes much less time to compute the heuristic function than to expand a node, A* is much faster than BFS for our application. Like BFS, A* is optimal and complete, because our heuristic function never overestimates the cost to reach the goal state. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SEARCH PARAMETERS</head><p>The key parameters of VFH* are the total projected distance d t , the projected step distance d s , and the goal depth n g . These parameters are related to each other through:</p><formula xml:id="formula_0">d t = n g ⋅ d s .</formula><p>The goal depth is proportional to the total projected distance d t . The higher d t is selected, the larger the total look-ahead, and the better the results of VFH* are. However, if this parameter is selected too high, the obstacle avoidance algorithm is slowed down substantially. It is not recommended to choose a value for the total projected distance that exceeds the range of the robot's sensors, unless the robot has an accurate map of a mainly static environment. The selection of d t is thus a trade-off between the speed and the quality of the algorithm. If possible, this parameter should be set close to the range of the robot's sensors.</p><p>The goal depth is inversely proportional to the projected step distance d s . If d s is selected too large, the new position might be incorrectly projected through or right into an obstacle. If d s is selected too small, the effect of a single projection is too small, resulting in a high value for n g . This would result in an unnecessary deep search tree, which would substantially slow down the obstacle avoidance algorithm. The selection of d s is thus a tradeoff between the speed and the validity of the algorithm. Based on our experiments, we recommend setting this parameter equal to the diameter of the robot.</p><p>It is important to note that the VFH+ method is a special case of the VFH* method, where n g is set equal to one, such that d t is equal to d s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">THE EXPANSION STEP</head><p>The expansion of a node n i consists of building the polar histogram at the node's projected position (x i ,y i ), determining the corresponding candidate directions, calculating the projected position and orientation of the following nodes, determining the cost of reaching these nodes, and determining their heuristic values.</p><p>The first two steps, building the polar histogram and determining the corresponding candidate directions, are performed in the same way as in the VFH+ algorithm. The three remaining steps are described in detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Projection of Position and Orientation</head><p>The computation of the projected position (x i+1 ,y i+1 ) and orientation θ i+1 for a candidate direction can be done in several ways. In our approach, the projected robot tra-jectory is approximated by arcs of a circle and straight lines. This is the same model that we used in VFH+ to take into account the robot trajectory. This approximation is a suitable trade-off between algorithm accuracy and speed. Example trajectories are shown in Fig. <ref type="figure" target="#fig_1">2</ref>: The parameters of this trajectory model are the projected step distance d s and the minimum steering radii r r and r l for right and left turns respectively. For a given candidate direction, the algorithm first determines if the robot can reach this orientation during the projected step distance. If not, the projected trajectory is simply approximated by a curve with constant curvature. It is also necessary to distinguish between candidate directions to the right and to the left of the robot. Thus, we end up with four sets of equations. The maximum directions to the right and to the left are defined by:</p><formula xml:id="formula_1">r s i r r d - = θ θ l s i l r d + = θ θ (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Cost Function</head><p>The cost function for a primary candidate direction c 0 leading from the root node at depth zero to a successor node is identical to the one used in the VFH+ method:</p><p>( ) ( )</p><formula xml:id="formula_2">1 , 0 3 0 2 0 1 0 0 , , , ) ( - ∆ ⋅ +       ∆ ⋅ + ∆ ⋅ = n d n t k c c k c c g µ α θ µ µ (2)</formula><p>with:</p><formula xml:id="formula_3">( )       + - - - - = ∆ α α 0 2 1 0 2 1 2 1 2 1 360 , 360 , min , c c c c c c c c (3)</formula><p>where:</p><p>α: angular resolution of histogram θ n : current orientation k t : target direction divided by α k d,n-1 : previously selected direction of motion / α The three terms of the cost function retain the same purpose as in the VFH+ method. While the first term is responsible for the goal-oriented behavior, the two other terms make the robot commit to a direction. For a goaloriented robot, we still have the following condition:</p><formula xml:id="formula_4">µ µ µ 1 2 3 &gt; + [condition 1]</formula><p>For a projected candidate direction c i of a node at depth i larger than zero, we propose a slightly modified cost function as follows:</p><formula xml:id="formula_5">( ) ( ) { } [ t e t i i i i k k k c c g , , , max ) ( 1 ∆ ∆ ⋅ ′ ⋅ = µ λ ( )    ∆ ⋅ ′ +       ∆ ⋅ ′ + -1 3 2 , , i i i i c c c µ α θ µ (4)</formula><p>with:</p><formula xml:id="formula_6">        - - - = + + i i i i e x x y y k 1 1 arctan (5)</formula><p>and:</p><formula xml:id="formula_7">0 1 &lt; ≤ λ (6)</formula><p>The first term of (4) again represents the cost associated with the deviation from the target direction, resulting in the goal-oriented behavior. However, this term is slightly different for a projected candidate direction than it is for a primary candidate direction. In the case of a projected candidate direction, this term also considers the effective direction of motion k e , or in other words, the forward progress of a trajectory. There is an important difference between a candidate direction c i and the corresponding effective direction of motion k e . Ideally, we want them both to be in the same direction as the target direction. However, depending on the robot's current orientation and situation, it is possible for one of them to be equal to the target direction while the other one largely deviates from it. If we did not consider the effective direction of motion, a part of the projected trajectory could have very low cost even though it does not make any forward progress at all. Fig. <ref type="figure" target="#fig_2">3</ref> shows an example, where the cost associated with the first term would be zero. By including the effective direction of motion in the first term, the cost of this trajectory becomes high, as it provides no forward progress at all.</p><p>It is important to note that for a primary candidate direction the first term of the cost function does not include the effective direction of motion. As the robot has no control over the current orientation, there is no reason to associate a cost with the effective direction of motion of a primary candidate direction. In contrast, the robot has some control over its projected trajectory. Therefore, it makes sense to associate a cost with the effective direction of motion of a projected candidate direction.</p><p>The second and third term have a different meaning for a projected candidate direction than for a primary candidate direction. In the case of a primary candidate direction, these terms represent a short-term memory effect that makes the robot commit to a direction. In the case of a projected candidate direction, the second and third term represent a cost associated with the smoothness of a projected trajectory.</p><p>The higher µ 1 ' is, the more goal oriented the robot's behavior is. The higher µ 2 ' and µ 3 ' are, the more the robot tries to find a smooth path. Only the relative values of these parameters are important, not their absolute values. For a goal-oriented robot, the following condition must be satisfied:</p><formula xml:id="formula_8">′ &gt; ′ + ′ µ µ µ 1 2 3 [condition 2]</formula><p>To emphasize the importance of a primary candidate direction over a projected candidate direction, the following condition must also be satisfied:</p><formula xml:id="formula_9">µ µ 1 1 ≥ ′ [condition 3]</formula><p>Experiments with the GuideCane and simulations have shown that a good set of parameters for a goaloriented mobile robot is:</p><formula xml:id="formula_10">µ 1 = 5 µ 2 = 2 µ 3 = 2 µ 1 ' = 5 µ 2 ' = 1 µ 3 ' = 1 (7)</formula><p>Another important parameter is the discount factor λ , which we set to 0.8 in our experiments. Instead of giving equal weight to all candidate directions independent of their depth i, they are weighted by a factor λ i . There are three reasons for the introduction of this factor.</p><p>First, it decreases the problem of a fixed goal depth n g with a sharp cut-off. Without λ, all branches would have the same weight and the obstacle avoidance algorithm would not always behave as desired. An example of such a case with n g set to 7 is shown in Fig. <ref type="figure" target="#fig_3">4</ref>, where the goal direction is indicated by k t . Without λ, the total cost of trajectory B would be cheaper than the one of trajectory A. As a result, the robot keeps moving towards the right without making any forward progress towards the goal direction. Without λ, the obstacle avoidance algo- rithm has the undesired tendency to find trajectories that stop shortly before being influenced by an obstacle. If n g was increased by one, trajectory B would become much more costly. However, even if trajectory B became more costly than trajectory A, the obstacle avoidance algorithm would pick trajectory C as its cheapest trajectory, again trying to stop shortly before being influenced by an obstacle. By introducing λ, the cut-off at the last branch is less sharp, as the weight of the last branch becomes relatively small. Consequently, trajectory A of our example becomes cheaper than trajectory B.</p><p>Second, the discount factor λ compensates somewhat for the uncertainty of the map information. Due to its sensors and the stochastic map building process, the mobile robot is more certain about its immediate surroundings. The further the projected position is away from the current position, the more uncertain the content of the map is at that position.</p><p>Finally, not using a discount factor is identical to using a discount factor with a value equal to one. With λ, we have more control over the weights of the branches at different depths, and we gain more control over the search algorithm's behavior. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The Heuristic Function</head><p>The heuristic function h(c) is the estimated cost of the cheapest path from a node n i to the goal state. A function is an admissible heuristic if it never overestimates the cost to reach the goal. With condition 2 satisfied, the cost is minimal if the robot can head towards the target direction k t at every following node. We can thus get a simple admissible heuristic by replacing c i in the cost function with k t :</p><formula xml:id="formula_11">( )       ∆ ⋅ ′ +       ∆ ⋅ ′ ⋅ = -1 3 2 , , ) ( i t i t i i i c k k n h µ α θ µ λ (8)</formula><p>This heuristic only considers the cost associated with the next branch. It does not consider the cost associated with the effective direction of motion. Therefore, this heuristic is not optimal as it underestimates the minimum cost to reach a goal node. However, this heuristic is admissible and computationally very efficient.</p><p>A better admissible heuristic that considers the cost associated with the effective direction of motion is:</p><formula xml:id="formula_12">( ) ( )       ∆ ⋅ ′ +       ∆ ⋅ ′ + ∆ ⋅ ′ ⋅ = -1 3 2 1 , , , ) ( i t i t t e i i i c k k k k n h µ α θ µ µ λ (9)</formula><p>with:</p><formula xml:id="formula_13">        - - - = + + i i i i e x x y y k 1 1 arctan based on c i = k t (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>This heuristic is better but computationally more expensive than the previous one. It is still not optimal because it only considers the minimum cost associated with the next branch. To compute an optimal heuristic value, one could simply expand (without building the polar histogram and determining the corresponding candidate directions) the current node until reaching the goal depth by using the target direction k t as the candidate direction at each node. By summing up the corresponding costs, we could get the optimal heuristic value. Yet, this heuristic requires more computational power.</p><p>The difference between these heuristics is a trade-off between quality and speed of the heuristic function. However, the heuristic has no influence on the resulting direction of heading. The first heuristic is currently implemented in the GuideCane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The Branching Factor</head><p>By reducing the branching factor b of the search tree, the search algorithm becomes faster and requires less memory. The branching factor can be reduced by eliminating redundant nodes.</p><p>Each node has a number of successor nodes equal to the number of its candidate directions. Because the projected step distance d s is usually small, several projected positions and orientations of successor nodes can be identical. All candidate directions that exceed θ r have the same projected position and orientation. Similarly, all candidate directions that exceed θ l have common values for the projected position and orientation. To reduce the branching factor, all but the cheapest candidate direction for each side can be eliminated. The explanation for the validity of this approach is simple. Consider a node with several candidate directions that exceed θ l . As their projected positions and orientations are identical, their polar histograms will also be identical. Therefore, the remaining search trees will be identical for all these candidate directions. Only the third term of the cost function asso-ciated with these branches would be different. As long as condition 2 is satisfied, the costs associated with the nodes of the search tree that starts at the candidate direction with the lowest cost are always lower than the corresponding nodes of the other candidate directions. Due to this node elimination method, the branching factor b is rarely larger than three.</p><p>Another speed improvement was achieved by e xpanding the search tree only if there is more than one primary candidate direction. With only one primary candidate direction, there is no need to expand the search tree, as the robot has only one choice anyway.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL RESULTS</head><p>The advantage of VFH* over VFH+ depends mainly on the goal depth n g , which is proportional to the distance of look-ahead verification. Although we have tested VFH* with the GuideCane, we prefer to show results from a simulated obstacle course for a better comparison. In tests with the GuideCane, the VFH* method performed equally well as long as the obstacles were detected by the robot's ultrasonic sensors. Fig. <ref type="figure">5</ref> shows the trajectories of VFH* with four different goal depth values. Figure <ref type="figure">6</ref> shows the search trees at critical or interesting positions. In all our experiments, we used the first heuristic.</p><p>Figure <ref type="figure">5a</ref> shows the trajectory of VFH+. As e xplained previously, VFH* with a goal depth of one is identical to VFH+. Shortly after avoiding the first two obstacles, VFH+ encounters a problematic situation that is similar to the one described in Section 2. When the horizontal wall triggers an obstacle avoidance maneuver, VFH+ makes an unfortunate choice and heads to the left. At the position shown in Fig. <ref type="figure">5a</ref>, VFH+ slows down or stops the robot, as its minimum turning radius is too large for avoiding the corner on either side. In the case of a holonomic or a differential-drive configuration, the robot needs to substantially slow down, thus reducing its minimum turning radius. In the case of a car-like configuration with a non-zero minimum turning radius, the robot needs to stop, back up, and then proceed to the right. With either configuration, it would have been better to turn to the right earlier.</p><p>Figure <ref type="figure">5b</ref> shows the trajectory of VFH* with a goal depth of two. Due to the look-ahead verification, VFH* makes the correct decision and turns to the right. Figure <ref type="figure">6a</ref> shows the search tree at the time when this critical decision happens. After driving around the horizontal wall, VFH* guides the robot into a shallow dead-end. At the position shown in Fig. <ref type="figure">5b</ref>, VFH* detects that the robot entered a dead-end. Thus, the robot needs to back up or turn if its minimum turning radius permits it.</p><p>Figure <ref type="figure">5c</ref> shows the trajectory with a goal depth of five. In this case, the goal depth is large enough to even avoid the dead-end. Figure <ref type="figure">6b</ref> shows the search tree at the position when VFH* detects the dead-end and decides to avoid it by turning left. The depth of the deadends that can be avoided with VFH* is proportional to the value of the goal depth. However, it is clear that dead-ends can only be avoided if the range of the robot's sensors is farther than the depth of the dead-end, or if the dead-end is represented in a given map.</p><p>Figure <ref type="figure">5d</ref> shows the trajectory with a goal depth of ten. In this case, VFH* already detects at the very beginning that it is better to turn right than left. In addition, the dead-end avoidance maneuver is initiated much earlier. The search trees at the two critical positions are illustrated in Fig. <ref type="figure">6c</ref>.</p><p>Figure <ref type="figure">5</ref> shows that the higher n g is selected, the better VFH* performs. However, this improvement is at the expense of computational time. Table <ref type="table" target="#tab_0">1</ref>  The black curve indicates the projected trajectory of the selected primary candidate direction. The gray lines show the expanded tree branches of the trajectories with higher total costs than the trajectory in black.</p><p>column averages the computation time over a densely cluttered obstacle course, excluding the times when there was only one primary candidate direction. The third column shows the maximum observed required computation time, ranging from 6 to 242 ms. In summary, the VFH* method is fast as long as the goal depth n g is kept small. The average execution time is very short even with a goal depth as high as ten. However, the critical value is the maximum execution time, which limits the goal depth for an application. The maximum required time could be decreased by applying additional branching factor reduction techniques and by optimizing the software. Tests with both the simulated and the real GuideCane have shown that a goal depth of just two is often sufficient to deal with problematic situations. As the GuideCane's on-board computer is clocked at only 66 MHz, we selected a value of two for the goal depth in the current i mplementation. With the range of the GuideCane's sonars, a goal depth between 3 and 5 would be optimal. However, the corresponding worst-case execution time is too slow with the current on-board computer to allow safe travel at high speed.</p><p>Similar to VFH+, the VFH* method is not very sensitive to its parameter values, and only little time is usually required for parameter tuning. As long as conditions 1 to 3 are satisfied and the parameter values are selected reasonably, the VFH* method performs well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>This paper presented VFH*, a local obstacle avoidance algorithm that uses look-ahead verification to consider more than the robot's immediate surroundings. While VFH* has the same obstacle avoidance performance as VFH+ for regular obstacles, VFH* is capable of dealing with problematic situations that would require the robot to substantially slow down or even stop. Experimental tests with the real GuideCane and simulations have proved to be very successful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This research was funded by the Whitaker Foundation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Problematic situation for purely local obstacle avoidance algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Trajectory approximation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Trajectory part with zero "target direction" cost</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Situation that requires the discount factor λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure5cshows the trajectory with a goal depth of five. In this case, the goal depth is large enough to even avoid the dead-end. Figure6bshows the search tree at the position when VFH* detects the dead-end and decides to avoid it by turning left. The depth of the deadends that can be avoided with VFH* is proportional to the value of the goal depth. However, it is clear that dead-ends can only be avoided if the range of the robot's sensors is farther than the depth of the dead-end, or if the dead-end is represented in a given map.Figure5dshows the trajectory with a goal depth of ten. In this case, VFH* already detects at the very beginning that it is better to turn right than left. In addition, the dead-end avoidance maneuver is initiated much earlier. The search trees at the two critical positions are illustrated in Fig.6c.Figure5shows that the higher n g is selected, the better VFH* performs. However, this improvement is at the expense of computational time. Table1shows an execution time comparison based on the GuideCane's embedded computer, a PC 486 running at 66 MHz. The second</figDesc><graphic coords="6,318.96,328.32,56.16,117.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>VFH* execution time.</figDesc><table><row><cell>ng</cell><cell>Taverage</cell><cell>Tmaximum</cell></row><row><cell>1</cell><cell>3 ms</cell><cell>6 ms</cell></row><row><cell>2</cell><cell>5 ms</cell><cell>11 ms</cell></row><row><cell>3</cell><cell>8 ms</cell><cell>22 ms</cell></row><row><cell>4</cell><cell>10 ms</cell><cell>39 ms</cell></row><row><cell>5</cell><cell>12 ms</cell><cell>82 ms</cell></row><row><cell>10</cell><cell>30 ms</cell><cell>242 ms</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time Obstacle Avoidance for Fast Mobile Robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1179" to="1187" />
			<date type="published" when="1989-10">Sept./Oct. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Vector Field Histogram -Fast Obstacle Avoidance for Mobile Robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="278" to="288" />
			<date type="published" when="1991">June1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The GuideCane -A Computerized Travel Aid for the Active Guidance of Blind Pedestrians</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ulrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. on Robotics and Automation</title>
		<imprint>
			<biblScope unit="page" from="1283" to="1288" />
			<date type="published" when="1997-04">April 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust Obstacle Avoidance in Unknown and Cramped Environments</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lawitzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. C onf. on Robotics and Automation</title>
		<imprint>
			<biblScope unit="page" from="2412" to="2417" />
			<date type="published" when="1994-05">May 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The dynamic window approach to collision avoidance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Magazine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="33" />
			<date type="published" when="1997-03">March 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-Time Obstacle Avoidance for Manipulators and Mobile Robots</title>
		<author>
			<persName><forename type="first">O</forename><surname>Khatib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1985-03">March 1985</date>
			<biblScope unit="page" from="500" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Potential Field Methods and Their Inherent Limitations for Mobile Robot Navigation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1991-04">April 1991</date>
			<biblScope unit="page" from="1398" to="1404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spatial Planning: A Configuration Space Approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="108" to="120" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Comparison of Realtime Obstacle Avoidance Methods for Mobile Robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Manz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liscano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Robotics</title>
		<imprint>
			<date type="published" when="1991-06">June 1991</date>
			<pubPlace>Toulouse, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">High resolution maps from wide angle sonar</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Moravec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elfes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1985-03">March 1985</date>
			<biblScope unit="page" from="116" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Curvature-Velocity Method for Local Obstacle Avoidance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Simmons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1996-04">April 1996</date>
			<biblScope unit="page" from="3375" to="3382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">VFH+: Reliable Obstacle Avoidance for Fast Mobile Robots</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="1572" to="1577" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
