<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StatCache: A Probabilistic Approach to Efficient and Accurate Data Locality Analysis</title>
				<funder>
					<orgName type="full">Parallel and Scientific Computing Institute</orgName>
					<orgName type="abbreviated">PSCI</orgName>
				</funder>
				<funder>
					<orgName type="full">Sun Microsystems, Inc.</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Erik</forename><surname>Berg</surname></persName>
							<email>erikberg@it.uu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<postBox>P.O. Box 337</postBox>
									<postCode>SE-751 05</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<postBox>P.O. Box 337</postBox>
									<postCode>SE-751 05</postCode>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">StatCache: A Probabilistic Approach to Efficient and Accurate Data Locality Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The widening memory gap reduces performance of applications with poor data locality. Therefore, there is a need for methods to analyze data locality and help application optimization. In this paper we present Stat-Cache, a novel sampling-based method for performing data-locality analysis on realistic workloads. StatCache is based on a probabilistic model of the cache, rather than a functional cache simulator. It uses statistics from a single run to accurately estimate miss ratios of fully-associative caches of arbitrary sizes and generate working-set graphs.</p><p>We evaluate StatCache using the SPEC CPU2000 benchmarks and show that StatCache gives accurate results with a sampling rate as low as ?? . We also provide a proof-of-concept implementation, and discuss potentially very fast implementation alternatives.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most modern high performance computers use cache memories to bridge the widening gap between DRAM access time and processor cycle time. This causes poor performance in many memory-intensive applications. Therefore, we need efficient methods to locate and explain cache-related performance bottlenecks.</p><p>Cache misses can be divided into conflict, capacity and cold misses. These different types of cache misses have different causes and are subsequently reduced using different methods. For example conflict misses can often be reduced by padding data structures, while blocking is efficient in reducing capacity misses. This paper focuses on the often dominating capacity misses, and to reduce these misses we need to improve application data locality. To quantify the data locality, we can study the miss ratio of fully-associative caches and plot working-set graphs, that is, the miss ratio of a fullyassociative cache plotted as a function of its size.</p><p>Simulating fully-associative caches is timeconsuming.</p><p>For long-running applications, the simulation time is often unbearable. Two common methods to reduce simulation time is time sampling and set sampling, but both have drawbacks <ref type="bibr" target="#b10">[11]</ref>. Time sampling often requires very long warm-up periods, and set sampling is often very sensitive to unrepresentative set selection.</p><p>We present StatCache, a novel probabilistic approach to estimate miss ratios of fully-associative caches. Rather than implementing a functional fully-associative cache simulator, StatCache uses a probabilistic model of a fully-associative cache to estimate its miss ratio. A major advantage is that it is based on a statistic that is easy to sample. In the paper, we show that StatCache gives accurate results with an overall sampling rate as low as ?? . We present a proof-of-concept implementation with an average execution-time slowdown of only 5.8 times, and suggest other potentially very fast implementations. While this paper focuses on program optimization and tuning, the method could prove useful in other areas as well, such as workload characterization in computer architecture. An extended version of this paper is available as a technical report <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">StatCache</head><p>StatCache is a method for analyzing run-time data locality and cache behavior. It monitors the addresses of the memory read and write operations of an application and models its data cache behavior. In this sense Stat-Cache is comparable to trace-driven cache simulation, but StatCache is based on a probabilistic model of the cache, rather than a functional simulator. The probabilistic model uses the fact that a piece of data is less likely to reside in the cache the longer time it has been </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>unused.</head><p>StatCache is divided into a run-time part and a postprocessing part. During run time, StatCache collects a cache-size-independent easy-to-sample data-access statistic. However, it is not possible to directly read out quantitative cache performance from the run-time statistic. Therefore, StatCache incorporates a post-processing system that applies the probabilistic cache model to the collected statistics and estimates average cache miss ratios of arbitrary-sized fully-associative caches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Run-time Statistics</head><p>The application StatCache examines reads and writes memory. This gives a sequence of memory addresses, called address trace. The addresses in the trace are enumerated from ? to AE, where AE is the total number of read and write operations the application performs. We will refer to addresses in the address trace as memory references, or simply references. StatCache considers the addresses of different data words within the same cache-line-sized piece of memory to be equal. The method currently do not consider timing effects and treats read and write operations equally.</p><p>Reuse distance is the run-time statistic that StatCache uses. It is defined as follows: Assume that the references and ( ) access the same cache-line-sized piece of memory, , and that there are no intermediate references to . Then the reuse distance of reference is ?, that is, the reuse distance is the number of intermediate memory references. Figure <ref type="figure" target="#fig_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>illustrates this. Assume the application accesses the cache lines</head><p>The arrows indicate reuse, and the numbers next to the arrows indicate the reuse distance. Note that this differs from the stack distance in that it counts all intermediate references, not just different ones. For example the stack distance of reference 6 is only 2 <ref type="bibr" target="#b19">[20]</ref> .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reuse Distance Histogram</head><p>The distribution of reuse distances can be viewed as a histogram. We call such a histogram , and let ??? be the number of memory references with reuse distance zero, ??? the number of memory references with reuse distance one, and so on. Figure <ref type="figure">2</ref> shows two examples of such histograms for the SPEC benchmarks art and equake.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sampling</head><p>The simple definition of the reuse distance makes sampling easy. The post-processing part of StatCache does not need the reuse distance of every memory reference, but base its miss-ratio estimates on reuse-distance distributions, like those shown in Figure <ref type="figure">2</ref>. Such distributions can be estimated by measuring the reuse distance of only a small fraction of all memory references. In Figure <ref type="figure">2</ref>, there are two versions of the reusedistance histogram for each benchmark, one based on the reuse distance of every reference, and one approx-imation based on sampling. The shape of the sampled and original distributions are very similar despite an overall sampling rate of only one in ten thousand.</p><p>StatCache implements sampling by monitoring randomly selected references. The run-time system in Stat-Cache needs the following support mechanisms to do this:</p><p>A sample selector The sample selector selects random load and store instructions and start monitoring the cache-line-sized piece of data that is read or written by that instruction.</p><p>A watchpoint mechanism The watchpoint mechanism monitors the selected cache-line-sized pieces of memory and informs the StatCache run-time system when the application accesses monitored memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A memory reference counter</head><p>The StatCache run-time system uses the memory reference counter to calculate reuse distances.</p><p>Figure <ref type="figure">3</ref> illustrates how these mechanisms are used. The sample selector first selects a memory reference to study and the StatCache run-time system sets a watchpoint on the corresponding cache-line-sized piece of memory. This happens at reference 1 in the example. The watchpoint then detects when the application attempts to access the same cache line again and reports to the run-time system, reference 6 in the figure. The run-time system uses the reference counter to calculate the reuse distance and records the result. It may be necessary to have several active watchpoints at a time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Post-processing</head><p>The post-processing system in StatCache uses a probabilistic model to estimate cache miss ratios from the run-time statistic, that is, the reuse-distance histogram, described earlier.</p><p>Assume that a cache is fully associative, has ? cache lines and uses random replacement policy. The probability is ?? ? ?? that a cache line remains in the cache after one cache miss and ?? ? ? ? ? after ? cache misses.</p><p>Let ??? be the probability that a cache line does not remain in the cache after ? cache misses, i.e.</p><formula xml:id="formula_0">??? ? ? ? ? ?<label>(1)</label></formula><p>Next, assign a stochastic variable to every memory reference. Let</p><formula xml:id="formula_1">? if reference results in a cache miss ? otherwise A i-A(i)-1 D i-A(i) C i-A(i)+1 . . . C i-1 A i Cache line Ref. counter B i+1 Reuse distance is A(i) #cache misses E(X i-A(i) +X i-A(i)+1 +...+X i-2 +X i-1 )</formula><p>Figure <ref type="figure">4</ref>. Estimating cache misses using reuse distance.</p><p>and let ? be a function such that ?</p><p>? ?.</p><p>We want an estimate of ? , that is, the probability that reference causes a cache miss. First, let ? ? be the reuse distance of reference . Then use the reuse distance to find the previous reference that accessed the same cache line, this is reference ? ? ?. ?</p><p>? ? ?</p><p>?</p><formula xml:id="formula_2">??? ? ? ? ? ? ? ? ? ? ? ? ? ? ??? ? ? ? ? ? ? ?</formula><p>estimates the number of actual misses in the interval. Function 1 gives an estimate of ? :</p><formula xml:id="formula_3">? ?? ? ? ? ? ? ??? ? ? ? ? ? ? ? ? (2)</formula><p>We can now sum both sides of this expression from 1</p><p>to AE, which gives:</p><formula xml:id="formula_4">AE ? ? AE ? ?? ? ? ? ? ? ??? ? ? ? ? ? ? ? ? (3)</formula><p>This expression gives a relation between all ? , but it contains too many unknowns to deduce a formula for the overall miss ratio. Therefore, assume for now, that the overall miss ratio, ?, does not change over time, which means that</p><formula xml:id="formula_5">? ? ? ?? ? ? ? ? ? ? ? ? ? ?<label>(4)</label></formula><p>where ?</p><p>? ? ? AE.</p><p>Note that the argument of in expression 3 contains</p><p>? ? terms. We apply assumption 4 and get</p><formula xml:id="formula_6">? ? ? ? ? ? ??? ? ? ? ? ? ? ? ? ? ??. Furthermore, the left side of expression 3 becomes equal to AE ? ?. Thus AE ? ? AE ?</formula><p>? ? ? ? ?? <ref type="bibr" target="#b4">(5)</ref> Consider the sum in this expression. The number of terms with ? ? equal to some constant ?, is equal to the number of memory references with reuse distance ?. The run-time statistic, the histogram , tells us that there are ??? memory references with reuse distance ?. This allows expression 5 to be rewritten as ?AE ??? ??? ? ??? ???? ? ??? ???? ? <ref type="bibr" target="#b5">(6)</ref> StatCache solves this equation for ? and the solution is an approximation to the miss ratio. The formula is implicit, but is easy to solve with numerical methods.</p><p>Our early experiments showed that equation 6 gives accurate results for applications that satisfy the assumption that the miss ratio does not change over time, but the accuracy is poor for other applications. The solution is to approximate the varying miss ratio with a piecewise constant function. StatCache splits the execution into small time slots and generates a histogram for each slot. It then estimates the miss ratio of each time slot with equation 6 and finally calculates the average over all time slots to get an overall miss ratio.</p><p>We use a time slot length of about 200k references in this paper. This gives a rather rough histogram approximation, but our experiments showed that it was best to use short time slots. Also, the shorter the time slot is, the more miss ratios are used in the calculation of the average overall miss ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Generating Working-Set Graphs</head><p>The number of cache lines, ?, can be set arbitrarily when solving equation 6. Thus, a single run generates all information needed to calculate miss ratios of fully associative caches of arbitrary sizes. By solving equation 6 for different values of ?, working set graphs can easily be generated. Note that the number of cache lines, ?, need not be a power of 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Cold Misses</head><p>StatCache will simply ignore all references to memory that have not been accessed before, because the reuse distance is not defined for the first references to a piece of data. Therefore, the miss ratios StatCache gives will not include cold misses. However, the number of cold misses is usually small, so the effect can often be ignored. The good thing is that capacity misses are separated from both conflict misses and cold misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head><p>We have evaluated StatCache by comparing it to a functional cache simulator. The evaluation is based on trace-driven simulation, using traces generated by the Simics <ref type="bibr" target="#b16">[17]</ref> full system simulator. It simulates a Sun UltraSPARC II workstation-like computer. We simulate both StatCache and the fully-associative caches we compare with so that the StatCache method as such may be evaluated, and exclude possible deficiencies in an implementation. To cut simulation time, we used the twenty benchmarks from the SPEC CPU2000 suite that are available with large reduced input data sets <ref type="bibr" target="#b11">[12]</ref>. The length of the reduced traces are between ? ? ?? and ?? ? ?? references.</p><p>The StatCache simulator sequentially reads the trace and increments a common memory reference counter for every memory reference. Using a random generator it samples memory references and adds their addresses and the corresponding value of the memory reference counter to a list of watchpoints. When an address from the trace matches a watchpoint, the reuse distance is added to a reuse distance histogram, like that in Figure <ref type="figure">2</ref>, and the watchpoint is removed. The execution is split into time slots as described in section 2.4 to get accurate miss ratio estimates.</p><p>We have also simulated fully-associative caches with random replacement from 2 K Byte to 4M Byte using the traces from Simics. The miss ratios Stat-Cache computes exclude cold misses, and to examine the effect of this, the results come in two flavors, with cold misses (FA RND) or without cold misses (FA RND NOCOLD). If the cold misses are negligible we only present miss ratios including cold misses, otherwise we present both results. Fully associative caches with LRU replacement (FA LRU) have also been simulated to investigate if there is a significant difference between the LRU and random replacement policies. The cache line size is 32 bytes throughout the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">StatCache Accuracy</head><p>Figures 5 shows miss ratios of fully associative caches with random replacement (FA RND) compared to miss ratios estimated by StatCache using a sampling rate of ?? . StatCache manages to accurately estimate the absolute values of the miss ratios, to capture the overall shape of the working set graphs well, and to give stable, smooth curves. In the case of art, twolf, and vpr route, they are almost identical. For perlbmk, the curves deviate between 2K Byte and 4K Byte because we have only simulated fully associative caches with power-of-two sizes. Note that the low sampling ratio gives only 9000 -80000 samples per application, which is less than the warm up period for large caches. Equake, mcf and mesa have a large fraction of cold misses. For these applications we also show graphs for fully associative caches with the cold misses removed (FA RND NOCOLD).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Impact of Replacement Policy</head><p>Using random or LRU-replacement policy have little effect on the miss ratio for most applications, but small differences exist, as Figure <ref type="figure">6</ref> shows. For bzip2 graphic, LRU-replacement gives a smaller miss ratio for small caches, but the difference vanishes as the cache size grows.</p><p>For art, LRU-replacement policy tend to give larger miss ratios for caches between 256K byte and 1M byte. This is typical of applications that traverse large amounts of data without reusing them for a long time. Compare with Figure <ref type="figure">2</ref>, where the reuse-distance histogram of art has a bump for large reuse distances. For some applications, like gzip program, the difference is very small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>An implementation of StatCache must provide the sampling and watchpoint mechanisms, and the memory reference counter described in section 2.3.</p><p>The proof-of-concept implementation is based on code instrumentation. We use the SAIT <ref type="bibr" target="#b8">[9]</ref> SPARC assembly code instrumentation tool to insert a small piece of code, called snippet, next to every load and store instruction. The application is first compiled into assembly code using the usual C or F90 compiler, then instrumented, and finally compiled into object files that are linked with the StatCache runtime system.</p><p>The inline code snippet first decrements the reference counter. If the reference counter reaches zero it calls a sample handler that sets a watchpoint on the accessed cache line and resets the reference counter with a random value that indicates when the next sample should be taken. The snippet also uses a hash table to check for watchpoints and, if it is a hit, calls a watchpoint handler. The watchpoint handler removes the watchpoint, calculates and records the reuse distance, and updates the hash table.</p><p>The performance is mostly determined by the watchpoint mechanism that must check every memory access, but efficient watchpoint mechanisms may be available in hardware. Most modern processors have at least a few programmable hardware watchpoints, and the MMU and memory protection system may be used to implement watchpoints.</p><p>We used the SPEC reference inputs to evaluate the performance of the proof-of-concept implementation on ten benchmarks 1 . We run the benchmarks on a Sun E450 with four 450MHz Ultra SPARC II CPUs. The average slowdown was 5.8 times on optimized code 2 .</p><p>Figure <ref type="figure" target="#fig_5">7</ref> shows the working-set graph of ammp generated by the proof-of-concept implementation and reference input. Observe that the shape of the curve and the absolute values deviate from the results presented in Figure <ref type="figure">5</ref>. This emphasizes the importance of performing measurements on realistic data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>There are several ways to investigate an applications memory and cache behavior, each modelling different 1 168.wupwise, 171.swim, 172.mgrid, 173.applu, 177.mesa,  178.galgel, 179.art, 183.equake, 187.facerec, and 301.apsi 2 The uninstrumented code we used as baseline were compiled with Sun Forte C and Fortran compiler, version 5.4 and 7 respectively. Compiler flags for C/Fortran: -xO5 -xarch=v8plus. Same or lower optimization were used for instrumented codes. levels of detail: full system computer simulation, instruction set simulation, user level simulation or code instrumentation, source code instrumentation, trap driven cache simulation and measurements on hardware using hardware profiling support.</p><p>Full system simulators include Simics <ref type="bibr" target="#b16">[17]</ref> and SimOS <ref type="bibr" target="#b14">[15]</ref>. They allow very detailed cache simulations, but suffer from large slowdown. Many tools have been built using binary code instrumentation tools like DIOTA <ref type="bibr" target="#b15">[16]</ref>, ATOM <ref type="bibr" target="#b6">[7]</ref> or EEL <ref type="bibr" target="#b12">[13]</ref>. Examples are SIGMA <ref type="bibr" target="#b5">[6]</ref>, CPROF <ref type="bibr" target="#b13">[14]</ref> and MemSpy <ref type="bibr" target="#b17">[18]</ref> <ref type="bibr" target="#b18">[19]</ref>. These tools are much faster than simulators, but their slowdowns are still considerable, between 5 and 50 times is common. They can simulate caches to the desired detail, but cannot capture operating system interaction. Source instrumentation have also been explored, for example in MHSIM <ref type="bibr" target="#b9">[10]</ref>.</p><p>Trace sampling is used to speed up cache hierarchy simulation. It can be applied to all levels of detail of computer and application simulation. The common methods of sampling are time sampling <ref type="bibr">[22][11]</ref> [5] <ref type="bibr" target="#b7">[8]</ref> and set sampling <ref type="bibr" target="#b10">[11]</ref>  <ref type="bibr" target="#b4">[5]</ref>.</p><p>Hardware monitoring tools collect statistics from hardware and present the information in aggregated form to the user. Examples are DCPI <ref type="bibr" target="#b0">[1]</ref>, which uses an advanced hardware support to collect detailed information to the programmer, and PAPI <ref type="bibr" target="#b2">[3]</ref> which is a common programming interface to access hardware monitoring aids. Histogramming and tracing hardware may be used to detect for example cache conflicts <ref type="bibr" target="#b20">[21]</ref> and locate problem areas <ref type="bibr" target="#b3">[4]</ref>. The execution time overhead is very small, but they can only provide information about the configuration of the current machine. Interference between different applications may also be a problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we have presented StatCache, a novel sampled-based method to analyze data locality. Based on sparse discrete samples of memory references and measurement of their reuse distances, StatCache estimates miss ratios of fully associative caches of arbitrary sizes and generates working set graphs. This information is useful for the study of application data locality.</p><p>We have evaluated the method using the SPEC CPU2000 benchmarks, and shown that StatCache gives accurate results with a sampling rate as low as ?? . Our investigations also indicate that the replacement policy has limited impact on the shape of the working set graph of the benchmarks in this study. Finally, we have presented a proof-of-concept implementation capable of analyzing realistic workloads with an average slowdown of only 5.8 times, and discussed very fast implementations alternatives.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The figure illustrates the reuse distances. The arrows indicate reuse of cache lines, and the numbers next to the arrows are the corresponding reuse distances assigned to the memory references pointed at by the arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 . 7 Figure 3 .</head><label>273</label><figDesc>Figure 2. Reuse-distance histograms for the benchmarks art and equake. The diagram shows two graphs for each benchmark, one based on every reuse distance, and one based on sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 4 illustrates this. The sum</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Figure 5. StatCache compared to fully-associative caches with random replacement (labeled FA RND). The graphs show the miss ratio as a function of cache size for 20 benchmarks. Stat-Cache accurately estimates the miss ratio of the fully-associative cache and the general behavior is well captured. The graphs for equake and mcf show that StatCache does not measure cold misses. StatCache is much closer to the graphs without cold misses (FA RND NOCOLD) than the graphs that include cold misses (FA RND).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. The output from the proof-ofconcept implementation running ammp with reference input. Observe that the shape of this graph is different from the corresponding graph for ammp in Figure 5. This emphasizes the importance of performing measurements on realistic data sets.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>We would like to thank <rs type="person">Oskar Grenholm</rs> for assistance on the instrumentation tool, <rs type="person">Allan Gut</rs> for valuable comments on the mathematical content and <rs type="person">Mathias Spjuth</rs> for providing the traces. This work is supported in part by <rs type="funder">Sun Microsystems, Inc.</rs>, and the <rs type="funder">Parallel and Scientific Computing Institute (PSCI), Sweden</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Continuous profiling: Where have all the cycles gone?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Berc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sites</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vandevoorde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Waldspurger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weihl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">StatCache: A probabilistic approach to efficient and accurate data locality analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
		<idno>2003-058</idno>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Information Technology, Uppsala University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A scalable cross-platform infrastructure for application performance tuning using hardware counters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SuperComputing</title>
		<meeting>SuperComputing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using hardware performance monitors to isolate memory bottlenecks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hollingsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing</title>
		<meeting>Supercomputing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combining trace sampling with single pass methods for efficient cache simulation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="714" to="720" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SIGMA: A simulator infrastructure to guide memory analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ekanadham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hollingsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SuperComputing</title>
		<meeting>SuperComputing</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ATOM: A flexible interface for building high performance program analysis tools</title>
		<author>
			<persName><forename type="first">A</forename><surname>Eustace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Winter</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="303" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cache miss equations: A compiler framework for analyzing and tuning memory behavior</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="703" to="746" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simple and efficient instrumentation for the DSZOOM system</title>
		<author>
			<persName><forename type="first">O</forename><surname>Grenholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Master&apos;s thesis</title>
		<meeting><address><addrLine>Sweden, De</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>School of Engineering, Uppsala University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tools for application-oriented performance tuning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whalley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 ACM International Conference on Supercomputing</title>
		<meeting>the 2001 ACM International Conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A comparison of trace-sampling techniques for multimegabyte caches</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="664" to="675" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adapting the SPEC 2000 benchmark suite for simulation-based computer architecture research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aj Kleinosowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Meares</surname></persName>
		</author>
		<author>
			<persName><surname>Lilja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Workload Characterization, International Conference on Computer Design (ICCD)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">EEL: Machineindependent executable editing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schnarr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGPLAN Conference on Programming Language Design and Implementation</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cache profiling and the SPEC benchmarks: A case study</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using the SimOS machine simulator to study complex systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Devine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bugnion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Herrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Modelling and Computer Simulation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="78" to="103" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DIOTA: Dynamic instrumentation, optimization and transformation of applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Maebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ronsse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">De</forename><surname>Bosschere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compendium of Workshops and Tutorials. Held in conjunction with PACT&apos;02: International Conference on Parallel Architectures and Compilation Techniques</title>
		<editor>
			<persName><forename type="first">M</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Kaeli</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2002-09">September 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SimICS/sun4m: A virtual workstation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moestedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dahlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lundholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenstr?m</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Grahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Usenix Annual Technical Conference</title>
		<meeting>the Usenix Annual Technical Conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mem-Spy: Analyzing memory system bottlenecks in programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMETRICS International Conference on Modeling of Computer Systems</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tuning memory performance of sequential and parallel programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="32" to="40" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluation techniques for storage hierarchies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gecsei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Slutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Traiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="78" to="117" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SMP system interconnect instrumentation for performance analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Noordergraaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing</title>
		<meeting>Supercomputing</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A model for estimating trace-sample miss ratios</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1991-05-21">1991. May 21-24, 1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
