<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5781003A74D2D5C6510D3BB9F2066F95</idno>
					<idno type="DOI">10.1109/MCOM.2018.1800153</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>0163-6804/18/$25.00 © 2018 IEEE</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AbstrAct</head><p>Advances in software defined radio (SDR) technology allow unprecedented control on the entire processing chain, allowing modification of each functional block as well as sampling the changes in the input waveform. This article describes a method for uniquely identifying a specific radio among nominally similar devices using a combination of SDR sensing capability and machine learning (ML) techniques. The key benefit of this approach is that ML operates on raw I/Q samples and distinguishes devices using only the transmitter hardware-induced signal modifications that serve as a unique signature for a particular device. No higher-level decoding, feature engineering, or protocol knowledge is needed, further mitigating challenges of ID spoofing and coexistence of multiple protocols in a shared spectrum. The contributions of the article are as follows: (i) The operational blocks in a typical wireless communications processing chain are modified in a simulation study to demonstrate RF impairments, which we exploit. (ii) Using an overthe-air dataset compiled from an experimental testbed of SDRs, an optimized deep convolutional neural network architecture is proposed, and results are quantitatively compared with alternate techniques such as support vector machines and logistic regression. (iii) Research challenges for increasing the robustness of the approach, as well as the parallel processing needs for efficient training, are described. Our work demonstrates up to 90-99 percent experimental accuracy at transmitter-receiver distances varying between 2-50 ft over a noisy, multi-path wireless channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IntroductIon</head><p>Emerging applications in the context of smart cities, autonomous vehicles, the Internet of Things, and complex military missions, among others, require reconfigurability both at the systems and the protocol level within its communications architecture. These advances rely on a critical enabling component, namely, software defined radio (SDR): this allows cross-layer programmability of the transceiver hardware using high-level directives <ref type="bibr" target="#b0">[1]</ref>. The promise of intelligent or so-called cognitive radios builds on the SDR concept, where the radio is capable of gathering contextual information and adapting its own operation by changing the settings on the SDR based on what it perceives in its surroundings.</p><p>In many mission-critical scenarios, problems in authenticating devices, ID spoofing, and unauthorized transmissions are major concerns. Moreover, high-bandwidth applications are causing a spectrum crunch, leading network providers to explore innovative spectrum sharing regimes in the TV whitespace and the sub-6 GHz bands. In all of the above, identifying the type of protocol in use and the specific radio transmitter (among many other nominally similar radios) become important.</p><p>Our work on SDR-enabled device fingerprinting tackles these two scenarios by learning characteristic features of the transmitters in a pre-deployment training phase, which is then exploited during actual network operation. We recognize that SDRs come in diverse form factors with varying onboard computational resources. Thus, for general-purpose use, any device fingerprinting approach must be computationally simple once deployed in the field. For this reason, we propose machine learning (ML) techniques, specifically, deep convolutional neural networks (CNNs), and experimentally demonstrate near-perfect radio identification performance in many practical scenarios.</p><p>Overview of our approach: ML techniques have been remarkably successful in image and speech recognition; however, their utility for device-level fingerprinting by feature learning has yet to be conclusively demonstrated. True autonomous behavior of SDRs, not only in terms of detecting spectrum usage, but also in terms of self-tuning a multitude of parameters and reacting to environmental stimulus, is now a distinct possibility. We collect over 20  10 6 RF I/Q samples over multiple transmission rounds for each transmitter-receiver pair composed of off-the-shelf USRP SDRs. The SDRs transmit standards-compliant IEEE 802.11ac physical layer waveforms to create a database of received signals. These I/Q samples carry embedded signatures characteristic of different active transmitter hardware, but are also subject to alterations introduced by the wireless channel. The approach of providing raw time series radio signal by treating the complex data as a dimension of two real valued I/Q inputs to the CNN is motivated by modulation classification <ref type="bibr" target="#b1">[2]</ref>. It has been found to be a promising technique for feature learning on large time series data. We develop a CNN architecture composed of multiple convolutional and max-pooling layers optimized for the task of radio fingerprinting. We partition the collected samples into separate Shamnaz Riyaz, Kunal Sankhe, Stratis Ioannidis, and Kaushik Chowdhury</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RADIO COMMUNICATIONS</head><p>The authors describe a method for uniquely identifying a specific radio among nominally similar devices using a combination of SDR sensing capability and machine learning (ML) techniques.</p><p>The key benefit of this approach is that ML operates on raw I/Q samples and distinguishes devices using only the transmitter hardware-induced signal modifications that serve as a unique signature for a particular device. Contributions and paper structure: Our work makes the following key contributions. We survey and classify existing approaches. We design a simulation model of a typical wireless communications processing chain in MATLAB, and then modify the ideal operational blocks to demonstrate the RF impairments that we wish to learn. We describe the data gathering process for training the classifier. We architect and experimentally validate an optimized deep CNN for radio fingerprinting, and quantitatively compare this approach with support vector machines and logistic regression. Finally, research challenges for increasing the robustness of our approach are listed, and the conclusions are drawn. In summary, our CNN design demonstrates up to 90-99 percent experimental accuracy at transmitter-receiver distances varying between 2-50 ft over a noisy multi-path wireless channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>relAted Work</head><p>The key idea behind radio fingerprinting is to extract unique patterns (or features) and use them as signatures to identify devices. A variety of features at the physical (PHY) layer, medium access control (MAC) layer, and upper layers have been utilized for radio fingerprinting <ref type="bibr" target="#b2">[3]</ref>. Simple unique identifiers such as IP addresses, MAC addresses, and international mobile station equipment identity (IMEI) numbers can easily be spoofed. Location-based features such as radio signal strength (RSS) and channel state information (CSI) are susceptible to mobility and environmental changes. We are interested in studying those features that are inherent to a device's hardware, which are also unchanging and not easily replicated by malicious agents. We classify existing approaches in Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>supervIsed leArnIng</head><p>This type of learning requires a large collection of labeled samples prior to network deployment for training the ML algorithm.</p><p>Similarity-Based: Similarity measurements involve comparing the observed signature of the given device with the references present in a master database. In <ref type="bibr" target="#b3">[4]</ref>, a passive fingerprinting technique is proposed that identifies the wireless device driver running on an IEEE 802.11-compliant node by collecting traces of probe request frames from the devices. A supervised Bayesian approach is used to analyze the collected traces and generate the device driver fingerprint. Reference <ref type="bibr" target="#b4">[5]</ref> describes a passive blackbox-based technique that uses TCP or UDP packet inter-arrival time to determine the type of access points using wavelet analysis. However these techniques rely on prior knowledge of vendor-specific features.</p><p>Classification-Based: There are several studies on supervised learning that exploit RF features such as I/Q imbalance, phase imbalance, frequency error, and received signal strength, to name a few.</p><p>Conventional: This form of classification examines a match with pre-selected features using domain knowledge of the system; that is, the dominant feature(s) must be known a priori. Reference <ref type="bibr" target="#b5">[6]</ref> proposes classification by extracting the known preamble within a packet and computing spectral components. A set of log-spectral-energy features are given as input to the k-nearest neighbors (k-NN) discriminatory classifier. PARADIS <ref type="bibr" target="#b6">[7]</ref> fingerprints 802.11 devices based on modulation-specific errors in the frame using support vector machine (SVM) and k-NN algorithms with an accuracy of 99 percent. In <ref type="bibr" target="#b7">[8]</ref>, a technique for physical device and device-type classification called GTID using artificial neural networks is proposed. This method exploits variations in clock skews as well as hardware compositions of the devices. In general, as multiple different features are used, selecting the right set of features is a major challenge. This also causes scalability problems when large numbers of devices are present, leading to increased computational complexity in training.</p><p>Deep Learning: Deep learning offers a powerful framework for a supervised learning approach. It can learn functions of increasing complexity, leverages large datasets, and greatly increases the number of layers, in addition to neurons within a layer. References <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref> apply deep learning at the physical layer, specifically focusing on modulation recognition using CNNs. They classify 11 different modulation schemes. However, this approach does not identify a device, as we do here, but only the modulation type used by the transmitter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>unsupervIsed leArnIng</head><p>Unsupervised learning is effective when there is no prior label information about devices. In <ref type="bibr" target="#b9">[10]</ref>, an infinite hidden Markov random field (iHMRF)-based online classification algorithm is proposed for wireless fingerprinting using unsupervised clustering techniques and batch updates. Transmitter characteristics are used in <ref type="bibr" target="#b10">[11]</ref> where a non-parametric Bayesian approach (namely, an infinite Gaussian mixture model) classifies multiple devices in an unsupervised, passive manner.</p><p>Transmitter identification using deep learning architectures is still in a nascent stage. Our work focuses on generation and processing of large numbers of RF I/Q samples to train the classifiers and eventually identify the devices uniquely.  [10] iHMRF <ref type="bibr" target="#b10">[11]</ref> Nonparametric Bayesian <ref type="bibr" target="#b5">[6]</ref> Frequency domain approach <ref type="bibr" target="#b6">[7]</ref> PARADIS <ref type="bibr" target="#b7">[8]</ref> GTID <ref type="bibr" target="#b1">[2]</ref> Modulation recognition -CNN <ref type="bibr" target="#b8">[9]</ref> Deep learning -physical layer cAuses of HArdWAre ImpAIrments</p><p>Using the MATLAB Communications System Toolbox, we simulate a typical wireless communications processing chain (Fig. <ref type="figure" target="#fig_2">2</ref>, with the shifts in the received complex valued I/Q samples), and then modify the ideal operational blocks to introduce RF impairments, typically seen in actual hardware implementations. This allows us to individually study the I/Q imbalance, phase noise, carrier frequency and phase offset, and nonlinearity of power amplifier, and harmonic and power amplifier distortions. I/Q imbalance: Quadrature mixers that convert baseband to RF and vice versa are often impaired by gain and phase mismatches between the parallel sections of the RF chain dealing with the in-phase (I) and quadrature (Q) signal paths. The analog gain is never the same for each signal path, and the difference between their amplitude causes amplitude imbalance. In addition, the delay is never exactly 90°, which causes phase imbalance.</p><p>Phase Noise: The up-conversion of a baseband signal to a carrier frequency f c is performed at the transmitter by mixing the baseband signal with the carrier signal. Instead of generating a pure tone at frequency f c (i.e., e j 2 pfct ), the generated tone is actu-ally e j 2 pfct+f(t) , where f(t) is a random phase noise. The phase noise introduces a rotational jitter. Phase noise is expressed in units of dBc per Hertz, which represents the noise power relative to the carrier contained in a 1 Hz bandwidth centered at a certain offset from the carrier. Typical value of phase noise level is in the range [-100, -48] dBc/Hz, with frequency offset in the range <ref type="bibr">[20,</ref><ref type="bibr">200]</ref> Hz.</p><p>Carrier Frequency and Phase Offset: The performance of crystal oscillators used for generating the carrier frequency is specified with an accuracy in parts per million (ppm). The difference in transmitter and receiver carrier frequencies is referred to as carrier frequency offset.</p><p>Harmonic Distortions: The harmonics in a transmitted signal are caused by nonlinearities in the transmitter-side digital-to-analog converters. Harmonic distortion is measured in terms of total harmonic distortion, which is a ratio of the sum of the powers of all harmonic components to the power of the fundamental frequency of the signal. This distortion is usually expressed in either percentage or in dB relative to the fundamental component of the signal.</p><p>Power amplifier distortions: Power amplifier (PA) nonlinearities mainly appear when the amplifier is operated in its nonlinear region (i.e., close to its maximum output power), where significant compression of the output signal occurs.</p><p>The distortions of the PA are generally modeled using AM/AM (amplitude to amplitude) and AM/ PM (amplitude to phase) curves. AM/AM causes amplitude distortion, whereas AM/PM introduces phase shift. The nonlinearity of amplifier is modeled using cubic polynomial and hyperbolic tangent methods using the third-order input intercept point (IIP3) parameter. IIP3, expressed in dBm, represents a scalar specifying the third order intercept.</p><p>dAtA collectIon for deep leArnIng experImentAl setup for trAce dAtA collectIon</p><p>We study the performance of different learning algorithms, including linear SVM, logistic regression, and CNNs, using I/Q samples collected from an experimental setup of USRP SDRs, shown in Fig. <ref type="figure" target="#fig_3">3</ref>. For the purpose of data collection at the receiver end, we use a fixed USRP B210. For the transmitter we use five different devices of the same family, USRP B210.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>protocols of operAtIon</head><p>We transmit different physical layer frames defined by IEEE 802.11ac on each transmitter SDR. These frames are generated using the MATLAB WLAN Systems toolbox and are standards-compliant.</p><p>The data frames generated are random since we intend to transmit any data streams. These protocol frames are then streamed to the selected SDR for over-the-air wireless transmission. The receiving SDR samples the incoming signals at 1.92 MS/s sampling rate at center frequency of 2.45 GHz for WiFi. The collected complex I/Q samples are partitioned into subsequences. For our experimental study, we set a fixed subsequence length of 128, additional details of which are described later. Overall, we collect approximately 20 million samples for each of the five SDRs.</p><p>storAge And processIng</p><p>The samples are further analyzed offline over:</p><p>• Workstations with typical configurations of Core-i7 processor, 8 GB RAM, and flashbased 512 GB storage • Northeastern's Discovery cluster that has 16 compute nodes with a NVIDIA Tesla K40m GPU each These nodes have 48 logical cores each, and on each node the GPU has 2880 CUDA computing cores. Each node has 128 GB of RAM configuration and dual Intel E5 2650 CPUs @ 2.00 GHz processor. These GPU servers are on a 10 Gb/s TCP/IP backplane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>cnn-bAsed rAdIo fIngerprIntIng</head><p>The success of CNNs in the vision and speech domains motivates our investigation in using CNNs for radio fingerprinting. The proposed method consists of two stages: a training stage and an identification stage. In the former, the CNN is trained using raw IQ samples collected from each SDR transmitter to solve a multi-class classification problem. In the identification stage, raw IQ samples of the unknown transmitter are fed to the trained neural network, and the transmitter is identified based on observed value at the output layer. In this section, we first describe the CNN architecture and then present preprocessing of input data necessary to improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>cnn ArcHItecture</head><p>Our CNN architecture is inspired in part by Alex-Net <ref type="bibr" target="#b11">[12]</ref>, which shows remarkable performance in image recognition. As shown in Fig. <ref type="figure">4a</ref>, our network has four layers, consisting of two convolutional layers and two fully connected or dense layers. The input to the CNN is a windowed sequence of raw IQ samples with length 128. Each complex value is represented as a two-dimensional real value, which results in the dimension of our input data growing to 2  128. This is then fed to the first convolution layer.</p><p>The convolution layer is the core building block of the CNN, whose primary purpose is to extract features from the input data. It consists of a set of spatial filters (also called kernels, or simply filters) that perform a convolution operation over input data. The operation of the convolution filter is shown with an example in Fig. <ref type="figure">4b</ref> for intuitive understanding. A filter of size 2  2 is convolved with input data of size 4  4 by sliding across its dimension to produce a two-dimensional feature map. A stride is the sliding interval of the filter and determines the dimension of the feature map. Our example shows stride 1 producing a feature map of dimension 3  3. Each convolution layer consists of a set of such filters, which in turn operates independently to produce a set of two-dimensional feature maps. Our CNN architecture is composed of the convolution layer followed by an activation step that performs a pre-determined nonlinear transformation on each element of the feature map. There are many possible activation functions, such as sigmoid and tanh; we use the rectified linear unit (ReLU), as CNNs with ReLU train faster compared to alternatives. As shown in Fig. <ref type="figure">4c</ref>, ReLU outputs max(x, 0) for an input x, replacing all negative values in the feature map by zero.</p><p>The convolution layer is generally followed by a pooling layer. Its functionality is to: • Introduce shift invariance • Reduce the dimensionality of the rectified feature maps of the preceding convolution layer while retaining the most important information We choose a pooling layer with filters of size 2  2 and stride 2, which downsamples the feature maps by 2 along both dimensions. Among different filter operations (e.g., average, sum), max pooling gives better performance. As shown in Fig. <ref type="figure">4d</ref>, max pooling of size 2  2 with stride 2 selects the maximum element in the non-overlapping regions (shown with different colors). Thus, it reduces the dimensionality of the feature map, which in turn reduces the number of parameters and computations in the network. The output of the second pooling layer is provided as input to the fully connected layer. A fully connected or dense layer is a traditional multi layer perceptron (MLP), where the neurons have full connections to all activation steps in the previous layer, similar to regular neural networks. Its primary purpose is to perform the classification task on high-level features extracted from the preceding convolution layers. At the output layer, a softmax activation function is used. The classifer with softmax activation function gives probabilities (e.g., [0.9, 0.09, 0.01] for three class labels).</p><p>Next, we discuss the selection hyperparameters of CNN to optimize the performance, followed by preprocessing of input data necessary for proper operation of CNN, and finally, the shift-invariance property of our classifier.</p><p>Model Selection: We start with a baseline architecture consisting of two convolution layers and two dense layers, then progressively vary the hyperparameters to analyze their effect on the performance. The first parameter is the number of filters in the convolution layers. We observe that the number of filters within a range of (30-256) provide reasonably similar performance. However, since the number of computations increases with an increase in the number of filters, we set 50 filters in both convolution layers for balancing the performance and computational cost. Similar-ly, we set 1  3 and 2  3 as the filter size in the first and second convolution layers, respectively, since larger filter size does not offer significant performance improvement. Furthermore, increasing the number of convolution layers from 2 to 4 shows no improvement in the performance, which justifies continuation with two convolution layers. We then try to analyze the effect of the number of neurons in the first dense layer by varying it between 64 and 1024. Interestingly, we find that increasing the number of neurons beyond 256 does not improve the performance. Therefore, we set 256 neurons in the first dense layer. After finalizing the architecture and parameters of CNN, we carefully select the regularization parameters as follows: We use a dropout rate of 25 percent after the first and second convolution layers and a dropout rate of 50 percent at the first dense layer. In addition, we use an l 2 regularization parameter l = 0.0001 to avoid over-fitting.</p><p>Preprocessing Data: Our experimental studies conducted on different representative classes of ML algorithms demonstrate significant performance improvement by choosing deep CNN. However, to ensure scalable performance over a large number of devices, our CNN architecture needs to be modified. In addition, our input I/Q sequences, which represent a time-trace of collected samples, need to be suitably partitioned and augmented beyond a stream of raw I/Q samples.</p><p>Our classifiers operate on sequences of I/Q samples of a fixed length. In general, given sequences of length L, we can create N = L/l subsequences of length l by partitioning the input stream. We thus create Ll subsequences by sliding a window of length l over the larger sequence (or stream) of I/Q samples. Training classifiers over small subsequences leads to more training data points, which in turn yields a low variance but potentially high bias in the classification result. Conversely, large sequences may lead to high variance and low bias. We set 128 as sequence length. From a wireless communications viewpoint, the channel remains invariant in smaller durations of time. Hence, the ability to operate on smaller subsequences carved out of in-order received samples allows us to estimate the complex coefficients representing the wireless channel. Thus we train our classifiers over the input I/Q sequences by treating each real and imaginary part of a sample as two inputs, leading to a training vector of 2  l samples for a sequence of length l.</p><p>Shift Invariance: Another prominent characteristic of our CNN classifier, both with respect to our final goal of identifying the transmitting device and in terms of feature extraction, is shift invariance. In short, all events described earlier can occur at an arbitrary position in a given I/Q sequence. A classifier should be able to detect a device-specific impairment irrespective of whether it occurs at, say, the 1st or 15th position of an I/Q sequence. Convolved weights in each layer detect signals in arbitrary positions in the sequence, and a max-pool layer passes the presence of a signal to a higher layer irrespective of where it occurs. To enhance the shift-invariance property of our classifier during training, we train it over sliding windows of length l as shown in Fig. <ref type="figure" target="#fig_5">5</ref>, rather than partitioned windows: this further biases the trained classifiers to shift-invariant configurations. CNN vs. Conventional Algorithms: We first measure the performance of our dataset using SVM and logistic regression for the classification of nominally similar devices. We extract several features such as amplitude, phase, and fast Fourier transform (FFT) values along with mean, standard deviation, normalized phase, and absolute normalized frequency components from the raw I/Q samples and built a rich set of features to train the classifiers. We obtain the classification accuracy for identification among 2, 3, 4, and 5 devices. As seen in Fig. <ref type="figure" target="#fig_6">6a</ref>, accuracy measure with SVM and logistic regression algorithms for 2 devices is 55 percent, and it decreases further as the number of devices increases. The performance deterioration can be clearly seen in Fig. <ref type="figure" target="#fig_6">6a</ref>. We then train our CNN classifier using raw data to classify the same set of devices. With our deep CNN network, we are able to achieve 98 percent accuracy for five devices, as opposed to less than 33 percent for the shallow learning SVM and logistic regression algorithms.</p><p>Impact of Distance on Radio Fingerprinting: We run experiments to collect data over a distance ranging between 2-50 ft over steps of 4 ft to evaluate the impact of distance (and possible multipath effect due to reflections) on classification accuracy. Figure <ref type="figure" target="#fig_6">6b</ref> demonstrates the accuracy measure for the classification of four devices using CNN. It achieves classification accuracy greater than 95 percent up to the distance of 34 ft. In addition, the observed signal-to-noise ratio (SNR) and analytical SNR (calculated using a free-space path model) are shown in the same plot to elucidate the effect of received SNR on the classification accuracy. It is evident that the classification is robust against the fluctuations in SNR that occur due to path loss and multipath fading up to the distance of 34 ft.</p><p>Receiver Operating Characteristics for Radio Fingerprinting: We obtained false positive rate and true positive rate to measure AUC. Figure <ref type="figure" target="#fig_6">6c</ref> shows the ROC curve for four similar WiFi devices. We can see that the CNN model works extremely well, as AUC ranges between 0.93 and 1. The AUC attained for each device is 0.964, 0.936, 1, and 0.994, respectively. This demonstrates that CNN is an effective model for radio fingerprinting. Additionally, training our CNN net- I/Q samples after sliding  </p><formula xml:id="formula_0">N ••• ••• 129 128 ••• 2 1 M ••• ••• ••• 256 ••• 129 128 ••• 1 Sliding operation</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>reseArcH cHAllenges</head><p>We now discuss the challenges associated with the implementation of CNNs for radio fingerprinting. In our experiments, we set the partition length as 128 through a rectangular windowing process. However, identifying the optimal length is a critical research objective and should be dependent on the channel coherence time. Varied CNN architectures may lead to significantly different results. Finding an optimal architecture that enhances device classification is an open research issue. A related challenge is obtaining the right balance between training time and classification accuracy. Increasing the depth of the CNN beyond a certain point may not help the classification; in fact, there are risks of over-fitting the training set, as we found in some of our early experiments. Our work focuses on training the model with actual experimental data, while a large body of earlier works attempt to solve a similar problem using synthetic data. There is no standard dataset to benchmark the performance of our classifier, and releasing all datasets in widely accepted formats is essential for correct replication of experiments. Finally, as a future objective, our goal is to validate the performance of our classifier to identify large numbers of devices at different distances than those for which it was trained. This may also require us to effect major changes in the architecture to increase robustness to signal amplitude and channel variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>conclusIon</head><p>We propose a radio fingerprinting approach based on deep learning CNN architecture to train using I/Q sequence examples. Our design enables learning features embedded in the signal transformations of wireless transmitters, and identifies specific devices. Furthermore, we have shown that our approach of device identification with CNN outperforms alternate ML techniques such as SVM and logistic regression for the identification of five nominally similar devices. Finally, we experimentally validate the performance of our design on a dataset collected over a range of distances, 2 ft to 50 ft. We observe that detection accuracy decreases as the distance between transmitter and receiver increases and that computational resources such as Keras running with GPU support speed up the training time. Our future work involves increasing the robustness of the CNN architecture to allow scaling up to correct identification of thousands of similar radios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. RF fingerprinting classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Typical transceiver chain with various sources of RF impairments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Data collection using SDR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 . 1 results</head><label>41</label><figDesc>Figure 4. a) Our proposed CNN architecture used for RF fingerprinting; b) convolution operation: filters strided over input sequences to generate feature map; c) ReLU operation performed on feature maps to introduce nonlinearity; d) an illustrative example of max pooling operation reducing the dimensionality of the activation map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. An illustration of sliding operation using a window of length 128 over I/Q sequences to enable shift-invariance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. a) The accuracy comparison of SVM, logistic regression, and CNN for 2-5 devices using 5-fold cross-validation; b) the plot of accuracy obtained using CNN for 4 devices over different distances between transmitter and receiver; c) ROC curves for 4 devices under CNN classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>work over a large dataset with Keras takes significantly less time compared to any of the other aforementioned algorithms.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AcknoWledgment</head><p>This work is supported by DARPA under grant N66001-17-1-4042. We are grateful to Dr. Tom Rondeau, program manager at DARPA, for his insightful comments and suggestions that significantly improved the quality of the work. references</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>bIogrApHIes Shamnaz mohammed Riyaz (mohammedriyaz.s@husky.neu.edu) is currently pursuing an M.S. degree in the Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts. She works under the guidance of Prof. Kaushik Chowdhury in the field of machine learning for wireless communication. Her research interests include deep learning for radios, wireless network security, and parallel processing for big data analysis.</p><p>Kunal SanKhe (sankhe.ku@husky.neu.edu) is currently pursuing a Ph.D. degree in the Department of Electrical and Computer Engineering, Northeastern University. He works under the guidance of Prof. Kaushik Chowdhury in the field of wireless communication. His current research efforts are focused on implementing a software-defined wireless charging system, developing a cross-layer communication framework for the Internet of Things, and investigating the application of machine learning in the domain of wireless communication.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>StRatiS ioannidiS</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Software Radio Architecture: A Mathematical Perspective</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mitola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JSAC</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="514" to="538" />
			<date type="published" when="1999-04">Apr 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convolutional Radio Modulation Recognition Networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Corgan</surname></persName>
		</author>
		<idno>abs/1602.04105</idno>
		<ptr target="http://arxiv.org/abs/1602.04105" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Device Fingerprinting In Wireless Networks: Challenges and Opportunities</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="104" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Passive Data Link Layer 802.11 Wireless Device Driver Fingerprinting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Franklin</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1267336.1267348" />
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Conf. USENIX Security Symp</title>
		<meeting>15th Conf. USENIX Security Symp</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
	<note>ser. USENIX-SS&apos;06</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Passive Approach to Wireless Device Fingerprinting</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beyah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/IFIP Int&apos;l. Conf. Dependable Systems Networks</title>
		<imprint>
			<biblScope unit="page" from="383" to="392" />
			<date type="published" when="2010-06">2010. June 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Radio Transmitter Fingerprinting: A Steady State Frequency Domain Approach</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">O</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008-09">2008. Sept. 2008</date>
			<publisher>IEEE VTC-Fall</publisher>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wireless Device Identification with Radiometric Signatures</title>
		<author>
			<persName><forename type="first">V</forename><surname>Brik</surname></persName>
		</author>
		<idno type="DOI">10.1145/1409944.1409959</idno>
		<ptr target="http://doi.acm.org/10.1145/1409944.1409959" />
	</analytic>
	<monogr>
		<title level="m">Proc. 14th ACM Int&apos;l. Conf. Mobile Computing and Networking, ser. MobiCom &apos;08</title>
		<meeting>14th ACM Int&apos;l. Conf. Mobile Computing and Networking, ser. MobiCom &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="116" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gtid: A Technique for Physical Device and Device Type Fingerprinting</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Uluagac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beyah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Dependable and Secure Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="519" to="532" />
			<date type="published" when="2015-09">Sept. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An Introduction to Machine Learning Communications Systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
		<idno>abs/1702.00832</idno>
		<ptr target="http://arxiv.org/abs/1702.00832" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On Passive Wireless Device Fingerprinting Using Infinite Hidden Markov Random Field</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Device Fingerprinting to Enhance Wireless Security Using Nonparametric Bayesian Method</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2011-04">2011. Apr. 2011</date>
			<biblScope unit="page" from="1404" to="1412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imagenet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2999134.2999257" />
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int&apos;l. Conf. Neural Info. Processing Systems</title>
		<meeting>25th Int&apos;l. Conf. Neural Info. essing Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
