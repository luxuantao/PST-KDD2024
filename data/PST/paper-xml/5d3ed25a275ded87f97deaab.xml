<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shaohua</forename><surname>Fan</surname></persName>
							<email>fanshaohua92@163.com</email>
						</author>
						<author>
							<persName><forename type="first">Junxiong</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaotian</forename><surname>Han</surname></persName>
							<email>hanxiaotian.h@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
							<email>shichuan@bupt.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Linmei</forename><surname>Hu</surname></persName>
							<email>hulinmei1991@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Biyu</forename><surname>Ma</surname></persName>
							<email>biyu.mby@alibaba-inc.com</email>
						</author>
						<author>
							<persName><forename type="first">Yongliang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><surname>Metapath</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Alibaba Group Hangzhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">-guided Heterogeneous Graph Neu-ral Network for Intent Recommendation. In The 25th ACM SIGKDD Con-ference on Knowledge Discovery and Data Mining (KDD &apos;19)</orgName>
								<address>
									<addrLine>August 4-8, 9 pages</addrLine>
									<postCode>2019</postCode>
									<settlement>Anchorage, New York</settlement>
									<region>AK, NY</region>
									<country>USA. ACM, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3292500.3330673</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender Systems</term>
					<term>Intent Recommendation</term>
					<term>Heterogeneous Information Network</term>
					<term>Graph Neural Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the prevalence of mobile e-commerce nowadays, a new type of recommendation services, called intent recommendation, is widely used in many mobile e-commerce Apps, such as Taobao and Amazon. Different from traditional query recommendation and item recommendation, intent recommendation is to automatically recommend user intent according to user historical behaviors without any input when users open the App. Intent recommendation becomes very popular in the past two years, because of revealing user latent intents and avoiding tedious input in mobile phones. Existing methods used in industry usually need laboring feature engineering. Moreover, they only utilize attribute and statistic information of users and queries, and fail to take full advantage of rich interaction information in intent recommendation, which may result in limited performances. In this paper, we propose to model the complex objects and rich interactions in intent recommendation as a Heterogeneous Information Network. Furthermore, we present a novel Metapath-guided Embedding method for Intent Recommendation (called MEIRec). In order to fully utilize rich structural information, we design a metapath-guided heterogeneous Graph Neural Network to learn the embeddings of objects in intent recommendation. In addition, in order to alleviate huge learning parameters in embeddings, we propose a uniform term embedding mechanism, in which embeddings of objects are made up with the same term embedding space. Offline experiments on real large-scale data show the superior performance of the proposed MEIRec, compared to representative methods. Moreover, the results of online experiments on Taobao e-commerce platform show that MEIRec</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With the development of mobile Internet, the focus of e-commerce has moved from personal computers to smart phones, and various mobile e-commerce platforms have emerged. The benefits of recommendation systems are well recognized as a basic service of e-commerce platforms, which provide personalized recommendation sticking to user's preference. In the past two years, a novel recommendation service (named as intent recommendation in this paper), in many e-commerce Apps (e.g., Taobao and Amazon) have emerged, which automatically recommends user intent (presented as several words) in a search box according to users' historical behaviors when users open an e-commerce App. There are several reasons for the boom of intent recommendation in the era of mobile Internet. First, since typing words on mobile devices is more difficult than on desktop computers, intent recommendation can save user time without any input, which will raise user activity and stickiness. Second, users may have no apparent intent or do not know how to describe their intent, a personalized intent recommendation can help users find what they really need.</p><p>Figure <ref type="figure">1</ref> illustrates an intent recommendation example on the Taobao mobile App. According to user historic information, an intent (e.g., presented as "air jordan") will be automatically recommended in the search box when a user opens the App. If the user clicks the search button, he/she will jump to the corresponding item list page. In intent recommendation system, the historic information can be roughly categorized into two types. The first type is attribute data, containing attribute information of objects, such as user profiles and item attributes. The other type is interaction data, containing triple interaction among users, items, and queries, such as user click (item) logs, user search (query) logs, and query guide (item) logs.</p><p>In this paper, we define the intent recommendation as follows: automatically recommend a personalized intent for a user according to his/her historical behaviors without query input. Here, in our application scenario, intent is presented as query, consisting of several words or terms simply and directly reflecting user intent. However, intent recommendation is different from traditional query recommendation/suggestion <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22]</ref> in the following two aspects. (1) It recommends queries according to user behaviors (i.e., interactions), rather than similar previous queries. (2) It also does not need users to input partial query. Also unlike previous study on mobile query recommendation <ref type="bibr" target="#b23">[24]</ref> which considers only userlocation-query relation, intent recommendation provides a flexible framework to consider complex interactions on heterogeneous objects in real systems. It is also different from item recommendation in several ways. (1) Our intent recommendation needs to consider the interactions among triple-objects (i.e., users, items and queries), rather than binary interactions between users and items in item recommendation. (2) Different from atomic and static items in item recommendation, intent (i.e., query constituted by words) always changes dynamically.</p><p>Existing methods for intent recommendation used in industry, such as Taobao and Amazon, usually extract handcrafted features, and then feed these features to a classifier, e.g., GBDT <ref type="bibr" target="#b6">[7]</ref> and XG-Boost <ref type="bibr" target="#b3">[4]</ref>. These methods heavily rely on domain knowledge and need laboring feature engineering. They only utilize attribute and statistic information of users and queries, and fail to take full advantage of the rich interaction information among objects. However, the interaction information is very abundant in real systems, and it is really critical to capture user intent.</p><p>As a general information modeling method, Heterogeneous Information Network (HIN) <ref type="bibr" target="#b17">[18]</ref>, consisting of multiple types of objects and links, has been widely applied to many data mining tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>. In this paper, we propose to model the intent recommendation system with a HIN, through which we can flexibly exploit its rich interaction information. As shown in Figure <ref type="figure">2</ref>(a), obviously, HIN clearly demonstrates objects in intent recommendation (e.g., users, items and queries) and their interaction relations, such as "user click item", "user search query" and "query guide item". Although, some HIN based recommendation methods have been proposed <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>, they mainly employ metapath based features through exploiting the interaction relations between users and items, which makes them hardly handle the triple-object interactions in intent recommendation.</p><p>In this paper, we present a novel Metapath-guided Embedding method for Intent Recommendation (called MEIRec). In order to fully utilize rich interaction information in intent recommendation, we propose to learn structural feature representations of users and queries with heterogeneous Graph Neural Network (GNN). Concretely, we present the metapath-guided neighbours to aggregate rich neighbour information, where different aggregation functions are designed according to the characteristics of different types of neighboring information. In addition, in order to handle large-scale data involved in intent recommendation, considering that both queries and titles of items consist of a limited number of terms, we design a uniform term embedding mechanism, in which embeddings of users and queries are made up with the same term embedding space. With the static features used in existing systems, as well as the embeddings of users and queries learned from interaction information, we build a prediction model for intent recommendation.</p><p>The major contributions of this paper are summarized as follows:</p><p>• We propose an important, but seldom exploited, intent recommendation problem, which automatically recommends a personalized intent according to user's historical behaviors. • We present a novel MEIRec model with GNN. Through modeling intent recommendation system as a HIN, MEIRec utilizes metapath-guided neighbours to exploit rich interaction information in HIN. Moreover, a uniform term embedding mechanism is designed to greatly reduce the parameter space. • Extensive offline experiments on a large-scale real data show that our MEIRec outperforms the representative baselines.</p><p>We also conduct online experiments on Taobao e-commerce platform. The results show that our model significantly improves key metrics considered by the platform. Particularly, the platform attracts the 2.66% of new users to search the recommended query with the help of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>In this section, we define some basic concepts used in our model. DEFINITION 1. Intent Recommendation. Given a set &lt;U, I, Q, W, A, B&gt;, where U = {u 1 , • • • , u p } denotes the set of p users,</p><formula xml:id="formula_0">I = {i 1 , • • • , i q } denotes the set of q items, Q = {q 1 , • • • , q r }</formula><p>denotes the set of r queries, W = {w 1 , • • • , w n } denotes the set of n terms, A denotes the attributes associated with objects, and B denotes the interaction behaviors between different types of objects.</p><p>In our application, a query q ∈ Q or an item i ∈ I , is constituted by several terms w ∈ W. The purpose of intent recommendation is to recommend the most related intent (i.e., query) q ∈ Q to a user u ∈ U. Taking Figure <ref type="figure">1</ref> for example, for a user u ∈ U, when he refreshes the App, we can utilize information from A and B to calculate the preference score of u for a candidate query q ∈ Q, and recommend the query with the highest score as user intent to the user u. It is worth noting that the recommended query reflects user intent through exploiting user historical interaction information. Moreover, the recommended query may be not previous queries, but new phrases generated by the combination of existing terms.</p><p>We model our recommendation task in the setting of Heterogeneous Information Network (HIN) <ref type="bibr" target="#b19">[20]</ref>. A HIN is defined as a graph G = (V , E), which has more than one node type or link type. In HIN, network schema is proposed to describe the meta structure of a network, which describes the object types and their interaction relations. The metapath <ref type="bibr" target="#b19">[20]</ref>, a relation sequence connecting two objects, is proposed to capture the structural and semantic relation between objects.</p><p>Figure <ref type="figure">2</ref>(a) shows a toy example of HIN and Figure <ref type="figure">2</ref>(b) is the corresponding network schema. We can see that the network consists of multiple types of objects (e.g, User (U), Item (I), Query (Q)) and their rich interaction relations. We are particularly interested in the metapaths that start from users and queries in our application, which can reveal semantic relations for users and queries. For example in Figure <ref type="figure">2</ref>(c), "U ser − Item − Query (UIQ)" metapath indicates user clicks items, and these items are guided by some queries. And "Query − U ser − Item (QUI)" indicates a query is searched by some users, and these users also click some items recently. DEFINITION 2. Metapath-guided Neighbors. Given an object o and a metapath ρ (start form o) in a HIN, the metapath-guided neighbors is defined as the set of all visited objects when the object o walks along the given metapath ρ. In addition, we denote the i-th step neighbors of object o as <ref type="figure">2</ref>(a) as an example, given the metapath "U ser − Item − Query (UIQ)" and a user u 2 , we can get metapath-guided neighbors as</p><formula xml:id="formula_1">N i ρ (o). Specifically, N 0 ρ (o) is o itself. Taking Figure</formula><formula xml:id="formula_2">N 1 UIQ (u 2 ) = {i 1 , i 2 }, N 2 UIQ (u 2 ) = {q 1 , q 2 , q 3 }.</formula><p>Then, all the metapath-guided neighbors of u 2 are denoted as</p><formula xml:id="formula_3">N UIQ (u 2 ) = {N 0 UIQ (u 2 ), N 1 UIQ (u 2 ), N 2 UIQ (u 2 )} = {u 2 , i 1 , i 2 , q 1 , q 2 , q 3 }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE MEIREC MODEL</head><p>In this section, we present the proposed model Metapath-guided Embedding for Intent Recommendation (MEIRec).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The basic idea of the proposed model MEIRec is to design a heterogeneous GNN for enriching the representations of users and queries.</p><p>With the help of HIN built from intent recommendation system, MEIRec leverages metapaths to guide the selection of different-step neighbors and designs a heterogeneous GNN to obtain the rich embeddings of users and queries. Moreover, we represent different types of objects with uniform term embedding for less parameters learning, since queries and titles of items are constituted by a small number of terms.</p><p>Figure <ref type="figure" target="#fig_1">3</ref> shows the overall framework of MEIRec. First, we use the triple-object HIN containing &lt;user, item, query&gt; as input. Second, we use the uniform term embedding to generate the initial embeddings of items and queries. Third, we aggregate the information of metapath-guided neighbors to learn the embeddings of users and queries via heterogeneous GNN. After that, we fuse the embeddings of users and queries based on different metapaths, respectively. Finally, with the fused embeddings of users and queries, accompanying with static features of users and queries, we predict the probability that a user will search a specific query. We illustrate these steps in detail in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Uniform Term Embedding</head><p>In previous neural-network based recommendation, every user or query should have an unique embedding. In the intent recommendation scenario, there are billions of users and queries. If we employ traditional collaborative filtering or neural-network based methods to represent all users and queries, it will make the number of parameters tremendous. Note that queries and titles of items are constituted by terms and the number of terms is not many. So we propose to represent the queries and items with a small number of term embeddings. And thus we only need to learn the term embeddings, rather than all object embeddings. This method is able to significantly reduce the number of parameters.</p><p>Specifically, we extract terms from the queries and items' titles , and build a term lexicon</p><formula xml:id="formula_4">W = {w 1 , w 2 , • • • , w n−1 , w n }.</formula><p>Note that queries and items (i.e., their titles) are the combination of several terms. For example, as shown in Figure <ref type="figure" target="#fig_1">3</ref>(a)-(b), query "Hand Bag" is constituted by terms "Hand" and "Bag", and item "LV Hand Bag" is constituted by terms "LV", "Hand" and "Bag". Since the number of the lexicon W is far less than the number of the queries and users, the uniform term embedding can significantly reduce the number of learned parameters. More importantly, the new queries that have never been searched before can be represented by these terms.</p><p>We will illustrate how the uniform term embedding works with two examples query q 2 and item i 2 shown in Figure <ref type="figure" target="#fig_1">3</ref>(b), the query q 2 is constituted by the term set {w 1 , w n } and the item i 2 has the term set {w 1 , w n−1 , w n }. We use multi-hot encoding to represent the query q 2 and item i 2 as following:</p><formula xml:id="formula_5">{w 1 , w 2 , • • • , w n−1 , w n } q 2 = (1, 0, • • • , 0, 1) i 2 = (1, 0, • • • , 1<label>, 1).</label></formula><p>(</p><formula xml:id="formula_6">)<label>1</label></formula><p>Terms are important words or phrases. We use the AliWS (Alibaba Word Segmenter) to segment the queries and items' titles and select important words or phrases which contains rich meanings A term embedding f : M → R d , where M represents the dictionary of term words, is a parameterized function mapping all the terms to d-dimensional distributional vectors. In the look-up layer, the queries or items are represented as combination of term embeddings to extract their semantic information. Then we aggregate the term embeddings to get the embeddings of queries or items as following:</p><formula xml:id="formula_7">E q 2 = д(e w 1 , e w n ), E i 2 = д(e w 1 , e w n−1 , e w n ),<label>(2)</label></formula><p>where e w i is the embedding of term w i and the д(•) means the operation function applied to the terms. In our experiments, we adopt the average function. By using the terms from the same lexicon, we obtain the embeddings of queries and items in a uniform term embedding space. Thus, term embeddings can be optimized by the embeddings of all objects simultaneously. This leads to that term embeddings contain the user-query and user-item interaction information in the embedding layer. Moreover, we only need to learn term embeddings with a small size (it is about 280000, compared to near ten millions of objects, in our experiments), which significantly reduces the complexity of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Metapath-guided Heterogeneous Graph Neural Network</head><p>Inspired by the basic idea of the GCNs which generates object embeddings based on local neighbors <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21]</ref>, we first propose a UIQ path UQI path metapath-guided heterogeneous GNN. That is, we leverage metapaths to obtain different-step neighbors of an object, and the embeddings of users and queries are the aggregation of their neighbors under different metapaths. We present a toy example in Figure <ref type="figure" target="#fig_2">4</ref> to illustrate this process. Here we describe how to obtain the embedding U 2 of user u 2 based on multiple metapaths, such as UIQ and UQI. We first illustrate how we aggregate neighbor information along path UIQ. We use the uniform term embedding to obtain the initial embeddings of queries. And then we aggregate the metapath-guided neighbors to get the metapath-guided embedding of user u 2 . According to the network structure in Figure <ref type="figure">2</ref>(a), we get the 1-st step neighbors set of u 2 , N 1 UIQ (u 2 ) = {i 1 , i 2 }. For each node i k in the neighbors set N 1 UIQ (u 2 ), we extract the 2-nd step neighbor set N 2 UIQ (u 2 ) = {q 1 , q 2 , q 3 }. After we obtain the 1-st step and 2-nd step neighbors set of u 2 , we aggregate the embeddings of 2-nd step neighbors to obtain the 1-st step neighbors' embeddings. In this example, we aggregate the embedding of query q 1 to obtain the item i 1 's embedding, and aggregate the embeddings of queries q 2 and q 3 to obtain the item i 2 's embedding. Finally, we aggregate the embeddings of 1-st step neighbors {i 1 , i 2 } to obtain embedding U UIQ 2 of user u 2 . Following this process, we can get different metapath-guided embeddings of u 2 , such as U UQI 2 . Then we aggregate all the metapath-guided embeddings to get final embedding of u 2 (i.e., U 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">User Modeling</head><p>In our model, we aggregate the information of different-step neighbors to obtain the representation U i of user u i via metapath-guided heterogeneous GNN. In this subsection, we show the how MEIRec models user embedding in detail.</p><p>As shown in the upper box in Figure <ref type="figure" target="#fig_1">3</ref>(c), in order to get the embedding U i of user u i , we select metapaths starting from target user. We first search different-step neighbors along the metapath, and then aggregate the embeddings of neighbors step by step. Taking the metapath UIQ (meaning user clicks the items which had been guided by queries) for example, we can obtain different-step neighbors of a user u i . After we get the 1-st step and 2-nd step neighbors set, we aggregate the embeddings of 2-nd step neighbors (query) to obtain the 1-st step neighbors' (item) embeddings and the embedding I UIQ j of item i j in N 1 UIQ (u i ) based on the metapath UIQ is:</p><formula xml:id="formula_8">I UIQ j = д(E q 1 , E q 2 , • • • ),<label>(3)</label></formula><p>where д(•) is the aggregation function. According to characteristics of neighbors, we design different functions and in our model we adopt the average function which gains an impressive performance in our experiments. And the queries {q 1 , q 2 , • • • } are the neighbors of item i j .</p><p>Next, we aggregate 1-st step neighbors' (item) embeddings to obtain the embedding U UIQ i of user u i :</p><formula xml:id="formula_9">U UIQ i = д(I UIQ 1 , I UIQ 2 , • • • ),<label>(4)</label></formula><p>where the items {i 1 , i 2 , • • • } are the neighbors of user u i . Since users click queries or items with timestamp, we model the neighbors of users (i.e., items or queries) as a sequence data. Recurrent Neural Network (RNN), especially the Long Short Term Memory (LSTM) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref> has been proved to perform well for sequential data. So MEIRec leverages the LSTM to dynamically model the neighbors of users. That is, the aggregation function д(•) is LSTM for the neighbors of users.</p><p>Then we obtain the fused user embedding by aggregating embeddings based on different metapaths {ρ 1 , ρ 2 , • • • , ρ k }:</p><formula xml:id="formula_10">U i = д(U ρ 1 i , U ρ 2 i , • • • , U ρ k i ),<label>(5)</label></formula><p>where the ρ is metapath starting from user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Query Modeling</head><p>Similar to user information aggregation, we also obtain the fused query embedding</p><formula xml:id="formula_11">Q i based on metapaths {ρ 1 , ρ 2 , • • • , ρ k }: Q i = д(Q ρ 1 i , Q ρ 2 i , • • • , Q ρ k i ),<label>(6)</label></formula><p>where the ρ is the metapath starting from query. Note that the neighbors of queries (i.e., items and users ) are not presented in the time order. So in our model, we leverage the Convolutional Neural Network (CNN) to dynamically model the neighbors of queries. That is, the aggregation function д(•) is CNN for the neighbors of queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Optimization Objective</head><p>In our model, we predict the probability ŷij of user u i search the query q j which is in the range of [0,1] to ensure that the output value is a probability. Through aggregating the neighbors of user and query, we obtain the fused user embedding U i for user u i and fused query embedding Q j for query q j . In addition, there are raw static features used in traditional methods, include attributes of users (queries) and static features from interaction information. We feed these static features to a Multi-Layer Perceptron for obtaining the representation of the static features S i j . Then, we concatenate the embeddings of user, query and static features to fuse them. Finally, we feed the fused embeddings into MLP layers to get the predict score ŷij . Then we have:</p><formula xml:id="formula_12">ŷij = siдmoid(f (U i ⊕ Q j ⊕ S i j )),<label>(7)</label></formula><p>where the f (•) is the MLP layers with only one output, siдmoid(•) is the sigmoid layer, and ⊕ is the embedding concatenate operation. The loss function of our model is a point-wise loss function in Equation <ref type="formula" target="#formula_13">8</ref>.</p><formula xml:id="formula_13">J = i,j ∈Y∪Y − y i j loд ŷij + (1 − y i j )loд(1 − ŷij ) ,<label>(8)</label></formula><p>where y i j is the label of the instance (i.e. 1 or 0) and the Y and the Y − are the positive and negative instances set, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Model Analysis</head><p>Here we analyze the parameter space complexity of MEIRec. For simplicity, we assume that there are M (billion-level) objects and N (100K-level) terms. In addition, suppose that there are h hidden layers with n neurons in our model and we set the dimension of the embedding to d. We compare the parameter space complexity between traditional latent factor and MEIRec. We first analyze the parameter space complexity of the traditional latent factor model which learns the embeddings of users and queries. The parameters to learn consists of two parts: embedding matrix and weight matrix of the hidden layer. much smaller than traditional methods. The smaller parameter space complexity of MEIRec means small computational space and high learning efficiency, which makes it suitable for large-scale data for real applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OFFLINE EXPERIMENTS 4.1 Dataset</head><p>We collect a real-world large-scale dataset from Taobao mobile application from Android and IOS online. We first extract 42 static features for user, including gender, age, purchasing power, etc and 39 static features for query, including length, term size, CTR, etc. And we construct a HIN based on interaction data collected during 10 days, consisting of about 100 million queries, 400 million users and 400 million items. In addition, the HIN contains about 4 billion search relations between users and queries, 20 billion click relations between users and items, and 4 billion guide relations between items and queries. The network constitutes structural information for the training and validation samples. Next, we introduce how to construct training and validation samples. We utilize the interaction data during 5 days. Specifically, each raw interaction record in the collected dataset contains &lt;user, recommended query, timestamp, label&gt; representing that the recommended query has been shown to user at timestamp. And the label indicates whether the user clicks the recommended query. To better understand the performance of our proposed model, we validate our model on different scales of data. In our offline experiments, we use training data for different time periods (from 1 to 5 days) to predict the next one-day. Therefore, we have three datasets with different scales marked as 1-day, 3-day and 5-day. To get more robust results, we vary the size of the each training set from 40% to 100%. The detailed statistics of the data are shown in Table <ref type="table" target="#tab_0">1</ref>. Besides, in order to get term lexicon, we first use the AliWS to segment the context of queries and titles of items to obtain a term lexicon, and select 280,000 terms to meet the needs of Alibaba e-commerce.</p><p>Our datasets have the following unique characteristics. First, the datasets are large enough, and contain millions of users and queries in both of training and validation set. Second, our datasets contain about half to three quarters new users in validation set. Third, as the density (i.e., (#interactions of users and queries)/(#users * #queries)) shown in Table <ref type="table" target="#tab_0">1</ref>, the datesets are extremely sparse. These characteristics of data bring great challenges to our model design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines and Evaluation Metrics</head><p>To validate the effectiveness of our proposed model, we use the popular models used in industry (e.g., LR, DNN, and GBDT) with different feature settings and a popular neural network based model NeuMF. Note that those query recommendation models are not included because of not suitable for our problem setting, and some recent fancy models are also excluded due to not handling largescale data.</p><p>• LR <ref type="bibr" target="#b14">[15]</ref>: It is a linear model with static features.</p><p>• DNN: With the same input setting as LR, we implement the deep neural network with 3 layers MLP.</p><p>• GBDT <ref type="bibr" target="#b6">[7]</ref>: It is a scalable tree-based model for feature learning and classification task. We feed static features into GBDT. Here we feed it with the structural information (interactions between users and queries), since it cannot be fed the static features. • MEIRec: It's our model with the input of the static features and structural information.</p><p>In our experiments, we use Area Under receiver operator characteristic Curve (AUC) <ref type="bibr" target="#b12">[13]</ref> to evaluate the performance of different models for comparison. The large AUC value means better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Detailed Implementation</head><p>We implement the proposed method based on Tensorflow <ref type="bibr" target="#b0">[1]</ref>. For our method, we set the dimension of term embedding as 64. We use a single-layer LSTM with 64 hidden neurons to model the user-querysequence and user-item-sequence and use a single-layer CNN to aggregate queries' neighbors. For GBDT, the tree number is set as 200. For Deepwalk/MetaPath2vec, the dimension of embeddings is set as 32. For all the methods, in the training stage, we randomly initialize the model parameters with a Gaussian distribution, and optimize the model with mini-batch Adam <ref type="bibr" target="#b10">[11]</ref>. We set the batch size as 512, and set the learning rate as 0.001. All the experiments are performed in Nvidia Tesla P100 Cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Evaluation</head><p>The performances of MEIRec and the baselines are reported in Table <ref type="table" target="#tab_2">2</ref>. The major findings from the experimental results can be summarized as follows:</p><p>(1) MEIRec significantly outperforms all the compared baselines. Compared to the best performance of baselines (i.e., GBDT + MP or GBDT + DW, indicated with "*" at    leverage static features and interaction relations for improving prediction performance. And compared with pre-training embedding methods (i.e., LR/DNN/GBDT+ DW and LR/DNN/GBDT+ MP), our model learns the embeddings in a task-guided (i.e., classification objective) way, which is more effective to learn embeddings for the query task intent recommendation.</p><p>(2) Among these baselines, we find that the order of overall performances is as follows: at method level, GBDT &gt; DNN &gt; LR &gt; NeuMF. Due to that NeuMF cannot learn the embeddings of new users and new queries appeared in the validation set, new objects' embeddings will be random variables, which makes the worst performances of NeuMF. For this problem, GBDT is a good classification model to fuse feature information, which makes it achieve good performances. That is the reason why it is widely used in real systems. And at feature level, (static features + heterogeneous embeddings) based methods &gt; (static features + homogeneous embeddings) based methods &gt; static features based methods. This ranking indicates that fusing more information could usually get better performances. And we can also find that, using heterogeneous network embedding (i.e., MetaPath2vec) can get better performances than homogeneous network embedding (i.e., Deepwalk). It demonstrates that we should consider heterogeneity of objects in HIN for better performances. At both levels, we conclude that choosing a model plays a key role in intent recommendation, and adopting appropriate methods to fuse more information could significantly improve the performance. As a consequence, the MEIRec achieves best performances, due to the heterogeneous GNN model and utilization of rich heterogeneous interactions.</p><p>(3) As the scale of data increasing, our model outperforms the best baselines with an increased margin (from 2.1% to 4.3%). The result further confirms that our model is more scalable for largescale datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Effect of Aggregation Methods</head><p>In our model, we enrich the information of users and queries by capturing their neighbor information along the given metapath. In order to explore the effect of different neighbor aggregation functions, we design different variants of MEIRec as follows.</p><p>• MEIRec st ats : It only uses the static features.</p><p>• MEIRec stru : It only uses the structural information.</p><p>• MEIRec avд : Both structural information and static features are used. We use the AVE function (i.e., average operation on aggregated embeddings) to aggregate the neighbors of both users and queries in this model. The AUC comparisons of our proposed method with different aggregation methods are shown in Figure <ref type="figure" target="#fig_3">5</ref>. We can see that the methods which only use static or structural information (i.e., MEIRec st ats , MEIRec stru ) get worse results than the methods using both information. MEIRec stru outperforms MEIRec st ats (same as DNN), indicating structural information is more powerful than static features for this task, and our structural fusing strategy is effective. The performance of MEIRec st ats also indicates that static information have limited effect on the results of MEIRec. Moreover, the results of MEIRec avд confirm that use more information of both is significantly better than the methods only using one single kind of features. On the other hand, the model MEIRec lstm and MEIRec gain more improvements than MEIRec avд , indicating that it is necessary to leverage different aggregation functions for different types of neighbors. In our model, for user side, the LSTM function capture time-sequence information for user behaviors, such as user click item sequence and user search query sequence. And for query side, the unordered functions (i.e., CNN or AVG) are good enough to aggregate the neighbor information of query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Effect of Different Metapaths</head><p>In our model, we aggregate different types of neighbors guided by metapaths to improve the recommendation performance. To further investigate the effect of different metapaths on learned embeddings for the intent recommendation task, we observe the performance of MEIRec through adding four informative metapaths one by one. The four metapaths are UQI, QIQ, QUI, and UIQ, and they are added into the model by their order.</p><p>Figure <ref type="figure" target="#fig_4">6</ref>(a) is the AUC performance of MEIRec with additive metapaths. The results shown in three datasets demonstrate the performance of our proposed model stably increases as we add metapaths one by one. Moreover, Figure <ref type="figure" target="#fig_4">6</ref>(b) is the AUC improvements of the variants (i.e., +QIQ, +QUI, +UIQ) against the model only using the first metapath (i.e., +UQI). One can also see that the performance of MEIRec with more metapaths gradually increases as the scale of data increases. The results indicate that when we deal with large-scale data, MEIRec with more metapaths usually yields better performances. This gain demonstrates that adding new informative metapaths plays an important role in learning taskrelated embeddings. Note that we only employ four representative metapaths in experiments due to the limitation of experimental settings. However, MEIRec provides a flexible framework to utilize more metapaths and integrate more heterogeneous interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Effect of the Number of Neighbors</head><p>In this subsection, we conduct a series of experiments on three datasets to evaluate the effect of the number of neighbors on performance. Specifically, for query side, we set the number of neighbors as a fixed value 5, and for user side, we vary the number of neighbors from 3 to 10.</p><p>As illustrated in Figure <ref type="figure" target="#fig_5">7</ref>, for different number of neighbors, the red line represents the AUC performance, and the yellow line indicates the running time. One can see that the performance of our model steadily improves as the number of neighbors grows. Note that, with the increasing neighbors, the performances of MEIRec still increase, but tend to be steady. We only set the maximum number of neighbors as 10, due to the limitation of computation resource. This conforms that the information of neighbors can effectively enhance the representations of users. It also demonstrates that the more local neighbor information is more effective in modeling the user's personalized intent. However, we also notice that  as the number of neighbors grows, the running time of the model also increases. Therefore, in order to tradeoff between accuracy and running time, we usually set the number of neighbors as 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ONLINE EXPERIMENTS</head><p>To furtherly evaluate the proposed model, we conduct online experiments in Taobao mobile App. We conduct a bucket testing (i.e., A/B testing) online to test the users' response to our model against baseline. We select one bucket for baseline, and another bucket for our model. And we select the GBDT model for comparison for that GBDT is used in real system. We use the metric CTR, Unique Click, and UCTR to evaluate the online performance, where CTR and UCTR=Unique Click/Unique Visitor indicate change of the click ratio and visit ratio.</p><p>The results are shown in Table <ref type="table" target="#tab_6">3</ref>. We can see that, compared to the GBDT, MEIRec achieves performance improvement in all metrics, which indicates that incorporating interaction information can better capture user latent intent. Our model gains the improvement of 0.70%, 4.79% and 1.54% for Android, IOS and Total respectively in CTR. Since the CTR is to measure the ratio of clicks against impressions, the improvement of CTR shows that our model can greatly improve the user's search experience. In addition, the metric UCTR indicates how many unique visitors click the recommended query, and it gains an improvement of 2.07%, 5.43% and 2.66% for Android, IOS and Total. The improvement of UCTR shows that our model have an advantage in attracting new users to search queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we study the intent recommendation problem which plays an important role in increasing user activity and stickiness in mobile e-commerce. In order to solve the challenges in intent recommendation, we model objects and interactions in intent recommendation system with a HIN and propose a novel metapathguided GNN method for intent recommendation, called MEIRec. MEIRec utilizes metapath-guided neighbours to exploit rich structural information in HIN. Moreover, a uniform term embedding is designed in MEIRec, which not only significantly reduces parameter space, but also makes it suitable for new generated users and queries. The extensive results on offline and online experiments demonstrate the effectiveness of our proposed model.</p><p>The number of visitors who performed a click</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Intent recommendation example on Taobao mobile application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>AppliedFigure 3 :</head><label>3</label><figDesc>Figure 3: The framework of MEIRec.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A toy example of metapath-guided information aggregation. Objects in this example are from Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The AUC comparisons of MEIRec with different aggregation strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performances of MEIRec with additive metapaths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performances of MEIRec with different number of neighbors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : The statistics of the datasets.</head><label>1</label><figDesc></figDesc><table><row><cell>Because N</cell><cell>M, the parameter space complexity of MEIRec is</cell></row></table><note>The parameter space complexity of embedding matrix is O(d * M), while the weight matrix of the hidden layer is O(n * h). So the whole parameter space complexity is O(d * M + n * h). In the real applications, because of the fact that d * M n * h, the parameter space complexity of traditional methods is O(d * M + n * h) ≈ O(d * M). However, it is not the case for our MEIRec. MEIRec uses the uniform term embeddings instead of embeddings of the users and items in the embedding layer, so the parameter space complexity is O(d * N + n * h) ≈ O(d * N ).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>It is the state-of-art neural network method for top-N recommendation.</figDesc><table><row><cell>• LR/DNN/GBDT+ DW: We feed the static features of users</cell></row><row><cell>and queries, as well as the pre-training embeddings learned</cell></row><row><cell>by DeepWalk (DW) [16] from structural information, into</cell></row><row><cell>LR/DNN/GBDT model.</cell></row><row><cell>• LR/DNN/GBDT+ MP: We feed the static features of users</cell></row><row><cell>and queries, as well as the pre-training embeddings learned</cell></row><row><cell>by MetaPath2vec (MP) [6] from structural information, into</cell></row><row><cell>LR/DNN/GBDT model.</cell></row><row><cell>• NeuMF [9]:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 )</head><label>2</label><figDesc>, MEIRec offers an improvement of 2.1%~4.3% in the three datasets. The results show that MEIRec achieves best results by using both static and structural features. It indicates that our model adopts a more principled way to</figDesc><table><row><cell>Applied Data Science Track Paper</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 : The AUC comparisons of different methods. The * indicates the best performance of the baselines. Best results of all methods are indicated in bold. The last row indicates the percentage of improvements gained by the proposed method compared to the best baseline.</head><label>2</label><figDesc>0.7122 * 0.7122 * 0.7124 * 0.7118 * 0.7114 * 0.7114 * 0.7120 *</figDesc><table><row><cell>Method</cell><cell>40%</cell><cell>60%</cell><cell cols="2">1-day</cell><cell>80%</cell><cell>100%</cell><cell>40%</cell><cell>60%</cell><cell cols="2">3-day</cell><cell>80%</cell><cell>100%</cell><cell>40%</cell><cell>60%</cell><cell cols="2">5-day</cell><cell>80%</cell><cell>100%</cell></row><row><cell>NeuMF</cell><cell>0.6014</cell><cell cols="2">0.6066</cell><cell cols="2">0.6136</cell><cell>0.6143</cell><cell>0.6168</cell><cell cols="2">0.6218</cell><cell cols="2">0.6249</cell><cell>0.6291</cell><cell>0.6172</cell><cell cols="2">0.6224</cell><cell>0.6246</cell><cell>0.6295</cell></row><row><cell>LR</cell><cell>0.6854</cell><cell cols="2">0.6838</cell><cell cols="2">0.6884</cell><cell>0.6889</cell><cell>0.6844</cell><cell cols="2">0.6863</cell><cell cols="2">0.6857</cell><cell>0.6865</cell><cell>0.6817</cell><cell cols="2">0.6831</cell><cell>0.6827</cell><cell>0.6836</cell></row><row><cell>LR+DW</cell><cell>0.6878</cell><cell cols="2">0.6904</cell><cell cols="2">0.6898</cell><cell>0.6930</cell><cell>0.6888</cell><cell cols="2">0.6896</cell><cell cols="2">0.6898</cell><cell>0.6900</cell><cell>0.6838</cell><cell cols="2">0.6842</cell><cell>0.6863</cell><cell>0.6867</cell></row><row><cell>LR+MP</cell><cell>0.6918</cell><cell cols="2">0.6936</cell><cell cols="2">0.6950</cell><cell>0.6969</cell><cell>0.6919</cell><cell cols="2">0.6930</cell><cell cols="2">0.6933</cell><cell>0.6933</cell><cell>0.6874</cell><cell cols="2">0.6890</cell><cell>0.6898</cell><cell>0.6899</cell></row><row><cell>DNN</cell><cell>0.6939</cell><cell cols="2">0.6981</cell><cell cols="2">0.6991</cell><cell>0.6997</cell><cell>0.6966</cell><cell cols="2">0.6985</cell><cell cols="2">0.6999</cell><cell>0.7008</cell><cell>0.6996</cell><cell cols="2">0.7011</cell><cell>0.7017</cell><cell>0.7029</cell></row><row><cell>DNN+DW</cell><cell>0.6962</cell><cell cols="2">0.6980</cell><cell cols="2">0.7003</cell><cell>0.7024</cell><cell>0.7005</cell><cell cols="2">0.7017</cell><cell cols="2">0.7024</cell><cell>0.7030</cell><cell>0.7017</cell><cell cols="2">0.7029</cell><cell>0.7040</cell><cell>0.7047</cell></row><row><cell>DNN+MP</cell><cell>0.6984</cell><cell cols="2">0.6992</cell><cell cols="2">0.7024</cell><cell>0.7057</cell><cell>0.7025</cell><cell cols="2">0.7040</cell><cell cols="2">0.7051</cell><cell>0.7057</cell><cell>0.7017</cell><cell cols="2">0.7044</cell><cell>0.7060</cell><cell>0.7069</cell></row><row><cell>GBDT</cell><cell>0.7071</cell><cell cols="2">0.7071</cell><cell cols="2">0.7067</cell><cell>0.7073</cell><cell>0.7070</cell><cell cols="2">0.7071</cell><cell cols="2">0.7072</cell><cell>0.7071</cell><cell>0.7067</cell><cell cols="2">0.7068</cell><cell>0.7072</cell><cell>0.7066</cell></row><row><cell>GBDT+DW</cell><cell>0.7114</cell><cell cols="6">0.7119 0.7112  *  0.7118  *  0.7109</cell><cell cols="2">0.7106</cell><cell cols="2">0.7106</cell><cell>0.7104</cell><cell>0.7109</cell><cell cols="2">0.7112</cell><cell>0.7109</cell><cell>0.7114</cell></row><row><cell cols="17">GBDT+MP 0.7111 0.7123  MEIRec 0.7122  *  0.7127  *  0.7110 0.7273 0.7302 0.7339 0.7346 0.7352 0.7369 0.7380 0.7390 0.7372 0.7401 0.7409 0.7425</cell></row><row><cell>Improvement</cell><cell>2.1%</cell><cell>2.5%</cell><cell></cell><cell></cell><cell>3.2%</cell><cell>3.2%</cell><cell>3.2%</cell><cell>3.5%</cell><cell></cell><cell></cell><cell>3.6%</cell><cell>3.7%</cell><cell>3.6%</cell><cell>4.0%</cell><cell></cell><cell>4.1%</cell><cell>4.3%</cell></row></table><note>*  </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>•</head><label></label><figDesc>MEIRec lstm : It uses the structural information and static features. We use LSTM to aggregate the neighbors of users and use AVE to aggregate the neighbors of queries in this model.• MEIRec: It is the proposed model MEIRec.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Applied Data Science Track Paper KDD '19, August 4-8, 2019, Anchorage, AK, USA</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 : Online A/B testing experiments results.</head><label>3</label><figDesc></figDesc><table><row><cell>Data</cell><cell>Methods</cell><cell>CTR</cell><cell>Unique Click</cell><cell>UCTR</cell></row><row><cell></cell><cell>GBDT</cell><cell>1.746%</cell><cell>256,116</cell><cell>13.939%</cell></row><row><cell>Android</cell><cell>MEIRec</cell><cell>1.758%</cell><cell>260,634</cell><cell>14.229%</cell></row><row><cell></cell><cell>Improvement</cell><cell>0.70%</cell><cell>1.76%</cell><cell>2.07%</cell></row><row><cell></cell><cell>GBDT</cell><cell>0.7687%</cell><cell>62,462</cell><cell>5.2579%</cell></row><row><cell>IOS</cell><cell>MEIRec</cell><cell>0.8056%</cell><cell>65,895</cell><cell>5.5436%</cell></row><row><cell></cell><cell>Improvement</cell><cell>4.79%</cell><cell>5.50%</cell><cell>5.43%</cell></row><row><cell></cell><cell>GBDT</cell><cell>1.4035%</cell><cell>318,578</cell><cell>10.5252%</cell></row><row><cell>Total</cell><cell>MEIRec</cell><cell>1.4252%</cell><cell>326,529</cell><cell>10.8052%</cell></row><row><cell></cell><cell>Improvement</cell><cell>1.54%</cell><cell>2.50%</cell><cell>2.66%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is supported in part by the National Natural Science Foundation of China (No. 61772082, 61806020, 61702296), the National Key Research and Development Program of China (2017YFB0803304), the Beijing Municipal Natural Science Foundation (4182043), the Fundamental Research Funds for the Central Universities, and the BUPT Excellent Ph.D. Students Foundation (No. CX2019127).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>ICLR. 651-665</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Context-aware query suggestion by mining click-through and session data</title>
		<author>
			<persName><forename type="first">Huanhuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="875" to="883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">metapath2vec: Scalable representation learning for heterogeneous networks</title>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName><surname>Jerome H Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of statistics</title>
		<imprint>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Aspect-Level Deep Collaborative Filtering via Heterogeneous Information Networks</title>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3393" to="3399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno>WWW. 173-182</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cash-out User Detection based on Attributed Heterogeneous Information Network with a Hierarchical Attention Mechanism</title>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">AUC: a misleading measure of the performance of predictive distribution models</title>
		<author>
			<persName><forename type="first">Jorge</forename><forename type="middle">M</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Jiménez-Valverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raimundo</forename><surname>Real</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Global ecology and Biogeography</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey of query recommendation techniques for data warehouse exploration</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elsa</forename><surname>Negre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDA</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="119" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="841" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Heterogeneous information network embedding for recommendation</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey of heterogeneous information network analysis</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="17" to="37" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic path based personalized recommendation on weighted heterogeneous information networks</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yading</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="453" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Pathsim: Meta path-based top-k similarity search in heterogeneous information networks</title>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="992" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Attention Network</title>
		<author>
			<persName><forename type="first">Wang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Houye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Shi Chuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cui</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><forename type="middle">P</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Yanfang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Mining search engine query logs for query recommendation</title>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olfa</forename><surname>Nasraoui</surname></persName>
		</author>
		<idno>WWW. 1039-1040</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Metagraph based recommendation fusion over heterogeneous information networks</title>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dik</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Mobile Query Recommendation via Tensor Function Learning</title>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihua</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yueting</forename><surname>Zhuang</surname></persName>
		</author>
		<idno>IJCAI. 4084-4090</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m">Applied Data Science Track Paper KDD &apos;19</title>
				<meeting><address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">August 4-8, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
