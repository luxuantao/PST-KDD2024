<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">T</forename><surname>Reeves</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Research and Development</orgName>
								<orgName type="institution">Lueasfilm Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ricki</forename><surname>Blan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Dept. of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5795B6D9CBF7E1C809F168B3905FAC59</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>1.3.3 [Computer Graphics]: Picture/Image Generation -Display algorithms</term>
					<term>1.3.5 [Computer Graphics]: Computational Geometry and Object Modelling -Curve, surface, solid, and object representations -Modelling packages</term>
					<term>1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism -Animation -Colour, shading, shadowing, and texture Design, Algorithms, Performance Analysis stochastic modelling, approximation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detail enhances the visual richness and realism of computergenerated images. Our stochastic modelling approach, called particle systems, builds complex pictures from sets of simple, volume-filling primitives. For example, structured particle systems have been used to generate trees and a grass-covered forest floor. Particle systems can produce so much irregular, three-dimensional detail that exact shading and visible surface calculations become infeasible. We describe approximate and probabilistic algorithms for shading and the visible surface problem. Because particle systems algorithms generate richlydetailed images, it is hard to detect any deviation from an exact rendering. Recent work in stochastic modelling also enables us to model complex motions with random variation, such as a field of grass blowing in the breeze. We analyze the performance of our current algorithms to understand the costs of our stochastic modelling approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Natural, as opposed to man-made, objects exhibit an immense variety of irregular shapes and random variation in their detail. To represent this variety in synthetic images, we would like to have models that are not entirely deterministic. The use of stochastic models has recently been advanced as an approach to creating naturalistic detail in computer-generated images <ref type="bibr" target="#b5">[5]</ref>. The idea of "data amplification" is fundamental to stochastic modelling algorithms, as well as to other classes of algorithms described by Smith <ref type="bibr" target="#b13">[13]</ref>. A simple data base specifies the general characteristics of the modelled object, and detail is Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.</p><p>Â© 1985 ACM 0-89791-166-0/85/007/0313 $00.75 generated algorithmically to describe the object fully. A complicated image can be generated from a small data base, and the amount of detail can vary with the displayed size of the object.</p><p>The best-known examples of stochastic modelling are the fractal algorithms of Fournier, Fussell, and Carpenter <ref type="bibr" target="#b5">[5]</ref>,</p><p>inspired by the mathematics of Mandelbrot <ref type="bibr">[9]</ref>, and the particle systems described by Reeves <ref type="bibr" target="#b12">[12]</ref>. Particle systems represent objects as clouds of primitive particles that occupy their volumes, rather than using more classical surface-based representations such as polygons, patches, and quadric surfaces. A particle system is not a static entity, as its paxticle~ can move and change form with the passage of time. The position, orientation, attributes, and dynamics of each particle are defined by a set of constrained stochastic processes.</p><p>Particle systems are important for three reasons. First, because a particle is much simpler than most graphical primitives, many more can be drawn in a given amount of computation time. Hence, a more complex and detailed image can be generated. Second, particle systems are both procedural and stochastic. By employing data amplification techniques, they require less human design time than conventional modelling methods. Third, particle systems can be used to model objects that change form over a period of time. In our experience, it is more di$cult to represent complex dynamics of this form with surface-based modelling techniques. This paper presents several new results in particle systems that were left as future research in our previous paper <ref type="bibr" target="#b12">[12]</ref>. These results were used in the film The Adventures of Andre and Wally B. <ref type="bibr" target="#b7">[7]</ref> to generate three-dimensional background images of a forest and of grass covering its floor. An example is shown in Figure <ref type="figure">1</ref>.</p><p>Our new algorithms generate more sophisticated particle systems with greater internal structure. The strength of these stochastic modelling algorithms is their ability to transform a small set of simple constraints into a complete description of complex objects. The problem is that they create so much irregular, three-dimensional detail that exact visible surface and shading calculations become infeasible. Our solution is to exploit the visual complexity of the models by adopting approximate and probabilistic algorithms. The rich detail in the images tends to mask deviations from an exact rendering. We also present some recent work in stochastic modelling that enables us to model more complex motions, such as a field of grass blowing in the breeze. Finally, we analyze the performance of our current algorithms and discuss the potential gains of haxdware support for rendering particle systems.</p><p>Several other researchers have modelled and rendered images of trees and vegetation. Brooks et. al. <ref type="bibr" target="#b3">[3]</ref> at MAGI extended a combinatorial geometry system to model simple trees. Marshall et. al. <ref type="bibr" target="#b10">[10]</ref> from Ohio State University used a procedural technique to generate polygonal models of trees. Both of these early efforts produced deterministic models of individual trees, whereas our algorithms create large groups of trees with stochastic variation.</p><p>More recently, Aono and Kunii <ref type="bibr" target="#b1">[1]</ref> developed geometric models that are based on botanical descriptions of trees and that exhibit accurate branching structures. Their research emphasizes issues in modelling; our work is more strongly oriented towards creating complex, coloured images. Gardner [0] has simulated scenes of trees and terrain using textured qu~dric surfaces; his approach is more efficient than ours, but it creates objects that are less highly detailed. <ref type="bibr">Smith 113]</ref> described a modelling technique called graftals that represents plants using Lindenmayer systems. Bloomenthal <ref type="bibr" target="#b2">[2]</ref> has created remarkably realistic images of trees, based on finely-detailed surface-oriented representations. Both Smith and gloomenthal emphasize the detailed structure of individual plants, whereas we take a more global view of a forest environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">S t r u c t u r e d P a r t i c l e S y s t e m s</head><p>Particle systems were first used to model a wall of fire in the Genesis sequence from the film Star Trek II: The Wrath o f Khan <ref type="bibr" target="#b11">[11]</ref>. The fire is modelled as particles of light that move in three-space. Each particle system resembles a miniature volcano from which many particles explode upwards, eventually falling to the planet's surface due to the pull of gravity. A frame from this sequence, such as Figure <ref type="figure">2</ref>, displays the trajectories of the visible particles during the time that the imaginary camera shutter is open to record the frame. The trajectories are approximated by a sequence of straight line segments, one per frame. Thus, a motion-blurred line is drawn to represent each particle. Associated with each fire particle is a set of parameters that describe its position and characteristics: the location from which it erupted, its initial velocity, and attributes such as colour and size. At generation time, the parameters are assigned initial values, drawn from a random distribution. Each particle is generated and transformed through time independent of all other particles.</p><p>The particle systems that model natural phenomena such as trees and grass are more structured, and, consequently, the particles are not independent. Each tree is drawn as a set of line segments, and possibly small circles, that constitutes its branches and leaves. Many complex relationships exist among the particles representing the branches and leaves of a tree, as together they must form a cohesive three-dimensional object. The rest of this section describes new techniques and types of controls for generating structured particle "systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Trees</head><p>The first step in modelling a forest scene is to populate the forest with individual trees, creating a tree data base that contains the location and type of each tree. The specifications in this pre-computed data base are subsequently used to generate and render the trees, frame-by-frame, during a second stage of the computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Creating the Forest</head><p>Sometimes the scene designer wishes to place each tree exactly, perhaps to simulate some real environment. The designer positioned the trees in Figure <ref type="figure" target="#fig_2">3</ref> with an interactive model editor to ensure that they fit into the scene with other, separatelycomputed elements.</p><p>When a vast number of trees are to be modelled, as in Figure <ref type="figure">4</ref>, it is more practical to generate their locations procedurally with special-purpose programs. Our tree placement program requires four types of input: a grid size that controls the spacing between trees, a parameter that specifies the minimum distance between any pair of trees, one or more regions on the horizontal plane that will be filled with trees, and a terrain map that provides the elevation of points on the plane. The program creates at most one tree per grid point, generating random displacements independently in the x and y dimensions to offset the actual location of the tree from the given point. Should parts of the forest become more crowded than the minimum spacing parameter allows, grid points are left empty.</p><p>T h e layout of a landscape can be controlled even when the placement algorithm is stochastic. For example, texture maps can direct the program to leave the terrain bare where meadows, streams, or other open areas exist. An even more sophisticated placement algorithm could be based on empirical forestry models and consider factors such as elevation, water drainage, and sunlight to determine the density of growth.</p><p>Tree type selection is performed at the same time as tree placement. Each tree is assigned a type (e.g., maple, spruce, or aspen) either interactively or procedurally. The stochastic methods used for Figure <ref type="figure">4</ref> distribute the deciduous trees more densely in the valleys and evergreen trees more densely on the hills. The probability that a tree is evergreen increases with the elevation; we use a random number to choose among the possible tree types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">G e n e r a t i n g â¢ T r e e</head><p>The particle systems program processes the trees in the data base serially; it generates a complete model for each tree and then renders the model. Starting with the main trunk, the algorithm constructs the tree by recursively generating subbranches. The data structure for the model is a tree in which each node describes a branch segment.</p><p>Before invoking the recursive branch generation procedure, the algorithm stochastically assigns a set of initial characteristics and dimensions. Some of these dimensions are illustrated in Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>The values for these parameters are randomly drawn from distributions associated with the tree's type. For example, the following equation determines the height of a tree:</p><formula xml:id="formula_0">Helfht ~ MeanHelght + Rand() X DeltaHeight</formula><p>where Rand() is a procedure returning a pseudo-random number uniformly distributed between -1.0 and +1.0. One parameter may depend on another. For example, the global width controls the breadth of the primary branches; this parameter is stochastically set to a fraction of the tree's height according to the equation:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeanHeifht and</head><p>Width ~ Height X (MeanWidth + Rand() X DeltaWidth ) MeanWidth is 0.6 for the deciduous trees, and 0.5 for the ever- greens. DeltaWidth is 0.05 for the deciduous trees, and 0.25 for the evergreens.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>@ S I G G R A P H '85</head><p>The relationship between parameters need not be linear. For example, branches are tapered by decreasing the thickness as the distance d from the base of the branch increases, according to the equation:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>/length-d thickneso ~ thickneso 6 X V l~ngth</head><p>where Icnfth is the total length of the branch and thickness b is the thickness at its base.</p><p>The height of the lowest branch is stochastically set to a fraction of the tree's height. The distance between two subbranches is drawn from a distribution that depends on the tree type and the thickness of the parent branch. Another control indicates whether branches occur singly or in whorls.</p><p>The parameters of the branch length distribution depend on the dimensions of the tree, as illustrated in Figure <ref type="figure" target="#fig_5">5</ref>. An approximate bounding volume for the tree is computed from its height and width; its shape varies with the tree type, conical for evergreens and elliptical for deciduous trees. For each branch, we select a branching uncle from a distribution associated with the tree type. We next compute MeanLength, the distance to the surface of the bounding volume from the position where the branch meets the trunk. The actual length of any branch is taken from a distribution centered on MeanLenfth.</p><p>A recursive algorithm generates sub-branches. We sample a distribution to obtain the ratio between the diameters of the parent and each sub-branch. The sub-branch inherits many parameters from its parent, but some controls are adjusted to the dimensions of the child. For example, sub-branches are spaced more closely together as the branch thickness decreases. The recursion stops either when a branch reaches a minimum thickness or at a specified maximum depth of recursion.</p><p>Characteristically, aspen trees, such as in Figure <ref type="figure" target="#fig_2">3</ref>, have forked branches, but our evergreens do not. For each species, we specify a probability that a branch forks. A parent-child relationship exists between a branch and its sub-branch, but two forks of a branch have a sibling relationship and share probability distributions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J width height</head><p>The colours in the image vary from tree to tree. The exact shades are offset by random amounts from mean values characteristic of the tree type. Two tables of eolours are established for each tree, and the thickness of the branch determines which table is used. Colours for the trunk and main branches are taken from one table, and colours for the leaves from the other. Alternatively, one table may be used for old wood and the other for new.</p><p>The branch-generatlon algorithm produces trees with a regular structure, unlike real trees that have been affected by their environment and natural disasters. We simulate these effects by post-processing the three-dimensional description of the tree. Separate algorithms bend tree branches to simulate the effects of gravity, prevailing winds, and prevailing sunlight direction. Another algorithm randomly warps branches to simulate a form of catastrophe theory.</p><p>Finally leaves or needles are added to the branches that have no sub-branches. The stochastic parameters that control the placement and characteristics of leaves are: shape, orientation, spacing, density, colour, and location.</p><p>All of the random variables for the images in this paper were drawn from uniform distributions, as described above. In tuning the parameters, we concentrated more on visual results than on actual botanical data. Other, more accurate, dlstributious should be explored in the future.</p><p>Particle systems can be combined with elements computed using other techniques. For example, the tree trunks in Figure <ref type="figure" target="#fig_2">3</ref> were modelled as truncated, solid cones and rendered with conventional texture-mapping techniques.</p><p>Approximately 1.1 million particles compose the trees in Figure <ref type="figure" target="#fig_2">3</ref>. Nearly sixty megabytes of binary data were generated from only twenty-one thousand bytes of input, resulting in a data amplification factor of over three thousand. The expansion factor is, naturally, less for scenes in which each object occupies only a small area of the screen. The input for the trees in Figure <ref type="figure">4</ref> was expanded by only a factor of four to generate fourteen megabytes of data; however, the input data base itself was generated procedurally from a much smaller specification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Grass</head><p>The images of grass result from an extension of the work reported earlier by Reeves <ref type="bibr" target="#b12">[12]</ref>. Clumps of grass are scattered randomly over the input terr'aln. A texture map, with a bird'seye view of the terrain, optionally specifies the locations of bare spots or different types of grasses. Some stochastic parameters specify global parameters for an entire clump of grass: its position, orientation, area, density, and type.</p><p>Each clump contains many separate blades of grass. Both the structure of the clumps and the geometry of the individual blades are simpler than the models used for trees. Stochastic processes determine the number of blades within the clump and the characteristics for each blade: position, height, thickness, curvature, orientation, and colour. Short, straight-line particles approximate each blade's parabolic arc. Stochastic bends and kinks added to some blades of grass enhance the realism of the image. Simple flowers are created by adding yellow or blue particles to some blades of grass.</p><p>Eighteen thousand clumps of grass are visible in Figure <ref type="figure" target="#fig_2">3</ref>. A total of 733,887 particles were drawn to render the grass. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Shading Models for Paxtiele Systems</head><p>The fire particle systems require only simple shading calculations, because each particle is modelled as an independent light source <ref type="bibr" target="#b12">[12]</ref>. Each fire particle is stochastically assigned an initial colour that changes over time according to a simple linear relationship that simulates cooling. The tree and grass particle systems reflect rather than emit light; they consequently require a more sophisticated shading model with ambient, diffuse, and specular shading components. For more realistic rendering, the shading algorithm also provides self-shadowing, external shadows, and coloured light sources.</p><p>A single tree may be composed of over one million independent particles. It would be a formidable task to shade each particle exactly, calculating whether it is in shadow and determining if it should be highlighted. In fact, unless the camera points directly at the sun from within the tree, it is almost impossible to tell whether or not any one leaf should be in shadow. Our solution is to use a probabilistic shading model for both the trees and the grass. For example, the particle's position and orientation determine the p-gbability that it is in shadow. We calculate this probability and then use a random number to decide whether or not to render the particle as if it were in shadow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Trees</head><p>Trees are self-shadowing, as branches and leaves of the tree shadow other parts of the same tree. In a forest, a tree is also shadowed externally by neighbouring trees. Our shading functions provide ambient, diffuse, and specular components and also approximate both forms of shadowing.</p><p>Highlights occur where the tree's branches or leaves are exposed directly to sunlight. This condition is most likely to exist close to the outer edge of the tree in the direction of the sun. Accordingly, the diffuse shading component for a particle varies with the distance into the tree from the light source, dd, as shown in Figure <ref type="figure">0</ref> Self-shadowing is simulated primarily by controlling the ambient shading component. The ambient component for a particle drops off exponentially as the distance into the tree, d,, increases. This dist, ance, as shown in Figure O, is independent of the position of the light source and represents the shortest distance from the particle to a point on the tree's bounding volume in a direction parallel to the ground. Another parameter, Amh, sets a minimum for the ambient component and guarantees that there is some light even in the deepest interior of the tree. The ambient component equation is therefore:</p><p>A -~max(e -Bd', Amin)</p><p>A different problem is to add external shadows, those cast by other trees. Again, we use an approximation technique because exact computation of the shadows would be very expensive. The locations and heights of any trees positioned between a specified tree and the light source define a plane that skims the top of neighbouring trees and passes through the light source. An example is shown in Figure <ref type="figure">7</ref>. Particles above this plane are in full sunlight, so the specular, diffuse, and ambient shading components all contribute to the shading calculation. The probability that sunlight reaches other parts of the tree decreases for particles located below the plane. If a particle is more than a specified distance below the plane, only the ambient shading component is used. For particles lying in between, a random number is selected to decide if the diffuse and specular components contribute to the shading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U U Figure 7. External Shadow Plane</head><p>To heighten the visual effect of the images in Andr~ and WalIv B., we used different colours for different types of light. A yellowish tinge to the diffuse and specular components prcntuced an early morning sunrise warmth, and a bluish tinge to the ambient component of the light gave us a look inspired by the landscape artistry of Maxfield Parrish <ref type="bibr" target="#b8">[8]</ref>. Figure <ref type="figure">8</ref> shows trees shaded with the techniques described in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Grass</head><p>A similar stochastic algorithm shades the grasses. The contributions of both the diffuse and ambient components depend on the distance from the top of the clump of grass to the particle in question, decreasing exponentially as the depth incre~es. The difference between the two is that the diffuse component drops off much more quickly than the ambient component. As with trees, each lighting component can have a different colour.</p><p>The strongest visual effects are due to the shading function that casts tree shadows onto the grass. The principle idea behind our algorithm is a form of ray casting. We view the particle from the light source to see if it is visible through the trees. If the particle is not visible, it is in shadow. A simple and effective device for implementing this idea is the shadow mask. Our method is similar to a technique used by Lance Williams <ref type="bibr" target="#b15">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>@ S I G G R A P H '85</head><p>To create the shadow mask for a scene, we first compute an orthographic image of the trees from the direction of the light source. We then extract the silhouette information from this image and form a texture map. Before shading each particle of grass, we transform its position by this same orthographic transformation, effectively calculating a view of the particle from the light source. The calculated screen coordinates index into the shadow mask texture map to obtain a value that indicates how much the particle is in shadow. In the final colour computation, this value determines how much of the diffuse lighting component to use. If the particle is completely in shadow, only the ambient shading component is used. A single, pre-computed shadow mask is used for all frames in which the positions of the trees and of the light source remain constant. The shadow mask texture map in Figure <ref type="figure">9</ref> was used to shade the grass element in Figure <ref type="figure">10</ref>.</p><p>The shadow mask technique effectively represents the shadows of trees on the grass because the trees are always between the grass and the sun. In general, the shadow mask technique works only if the objects casting the shadow are completely between the light source and the surface on which the shadow is east. This limitation arises because the texture map that stores the shadow mask is only two-dimensional. Three-dimensional texture maps that store both depth and coverage information could solve this problem, but we have not explored this area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Visible Surface Determination</head><p>Our previous research essentially ignored the visible surface problem with particle systems. The fires of Star Trek II, as shown in Figure <ref type="figure">2</ref>, were composed of light-emitting particles. When several particles overlapped in a pixel, their eolours were simply added together. With light-reflecting particles, such as those of the trees and gyms. one vartiele can obscure another by being in front of it with respect to the selected camera position. We must now solve the visible surface problem.</p><p>The following sections describe two slightly different visible surface algorithms, one for the trees and one for the grass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Trees</head><p>Consider a forest scene containing many trees. .As we have seen, our stochastic generation algorithms usually attain a significant amount, of data amplification, it is not feasible to generate particles for all trees in an image and then perform a traditional visible surface algorithm on themâ¢ Instead, we employ a painter's algorithm approach. We first sort all trees in the scene into a back-to-front order with respect to screen depth. Then, for each tree in turn, we generate a stochastic model, shade it, and render it into the image on top of any trees that have been previously rendered. As soon as a tree has been rendered, its data is discarded.</p><p>The accuracy of this back-to-front approach relies on the assumption that the bounding volumes of the trees do not intersect. While this assumption is inaccurate for forests in general, interesting images can be made with tree databases that tonform to this restriction. The grass visible surface algorithm of the next section removes this non-intersecting restriction but is slightly more expensive.</p><p>Rendering each individual tree is not trivial either, as some branches of the tree obscure others. Within a tree we also apply a form of painter's algorithm that depends on a bucket sort. The bounding volume of the tree defines a set of buckets that are indexed by the eye space z distance of the particle -that is, by its depth into the scene. As a particle is generated, it is transformed into two-dimensional screen space and inserted into the bucket list corresponding to its average eye space z distance. After all particles have been generated, they are drawn in back-to-front bucket order on top of any particles that have already been rendered into the image. All particles are drawn as small, antialiased circles or short, antialiased straight line segments. This bucket sort is another inexpensive but sureessful approximation. A completely accurate comparison sort of all the particles in a scene would require O(nlogn) operations, where n is the number of particles. The approximate algorithm is linear in the number of particles, assuming that the trees have been sorted previously. Therefore, it requires only O(rnlogrn + n) operations, where m, the number of trees, is much smaller than n. If we skipped the preliminary sort of the trees, a bucket sort of all particles could be accomplished with O(n } operations, but the memory costs would be much greater. For our forest scenes, n typically ranges between 1.0 and 1.7 million. In contrast, m is usually less than 10,000, and, in close-up scenes such as Figure <ref type="figure">11</ref>, it is only 195. We have never noticed any anomalies attributable to the bucket sort in any of our static or dynamic images. We commonly use about 2000 buckets. Even for a large tree, spanning fifty feet of depth, each bucket would cover a small area, about 0.3 inches. Since the images are so complex to start with, any imperfections are very difficult to detect as long as they are consistent from frame to frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.~ Grass</head><p>We cannot create the appearance of a continuous carpet of grass without allowing clumps of grass to intersect. The visible surface algorithm for grass is more sophisticated than for trees because it permits intersecting clumps. The algorithm sorts the clumps of grass back-to-front and then calculates the bounding box of each clump in eye space. The clumps are generated in the back-to-front order, and the particles are entered into the bucket sort list. The difference is that the bucket list is not flushed and drawn at the end of each clump as it is at the end of each tree. Instead, only some of the buckets are drawn at the end of each clump. A bucket is drawn only if none of the bounding boxes from the remaining clumps overlaps it in eyespace z distance. Because the clumps are sorted, it is trivial to test for this condition.</p><p>Whenever the rear-most buckets are drawn, the range of the entire bucket list slides forward in eye-space z depth. Any undrawn particles remaining in the list may need to be reassigned to different buckets. This algorithm is more expensive th::a the non-intersecting tree algorithm because of two additional tasks -checking for overlapping buckets and reassigning particles when the range of the bucket list changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Complex Particle System Dynamics</head><p>The particle dynamics of the fires <ref type="bibr" target="#b11">[11]</ref> were simple --each particle independently followed a parabolic trajectory. In the film The Adventures off Andr~ and Wall V B., the tree and grass elements were still. Since then, we have added realistic dynamics to depict a field of tall grasses blowing in the breeze. Stochastic models represent two phenomena, gusts of wind and the motion of wind-blown blades of grass.</p><p>The first step is to model wind. The scene designer specifies the terrain, a prevailing wind direction, and the average wind speed. A program generates wave fronts of particles that travel across the terrain. Each particle represents a small, localized gust of wind. The waves of particles display random variation, moving roughly parallel to the specified wind direction. New waves arrive at a rate that matches a specified wind gust frequency.</p><p>A g, ind map is a two-dimensional, top-down view of the terrain that specifies the wind intensity at discrete grid points. Letting the waves of particles move through time, we build a wind map for each frame of the animated sequence. The intensity of the wind at a particular location and time is determined by the number of wind gust particles close to the grid point. Stochastic processes also model the reaction of the blade of grass as it is hit by a gust of wind. The simulated motion has the following key features:</p><p>â¢ The blade bends around an axis that is perpendicular to the wind direction and passes through the blade's base.</p><p>â¢ The amount of bending depends on the intensity of the gust of wind.</p><p>â¢ The amount of bending increases with the distance from the ground, so that the bl:~de is stiffest at its base.</p><p>â¢ Over time and in the absence of other gusts, the blade returns to its original position following a damped sinusoldal motion called a bending function.</p><p>â¢ The effects of successive gusts of wind axe additive. At each frame, a bending function is generated and remembered for subsequent frames. The effective bending function at a given frame is the sum of all active bending functions.</p><p>The use of a two-dimensional wind map limits the motion of the wind to a plane. However, the algorithm achieves a threedimensional look by tying each blade of grass to the ground and varying the degree of bending over the length of the blade.</p><p>Stochastic processes add further variation to the motion. For example, all blades do not bend exactly perpendicular to the wind direction, and blades close together use slightly different wind gust intensities. A blade of grass is bent by transforming the particles that represent it, taking care to keep them connected.</p><p>We can experiment with stochastic wind functions and wind maps, watching the wind patterns flow in real time on our vector display system. After adjusting the controls interactively, we can re-compute the motion in a few minutes to inspect the results. A short animated film of blowing grass has been computed. Figure <ref type="figure">12</ref> is one frame from the film.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Performance of Particle Systems Algorithms</head><p>In order to characterize the performance of particle systems algorithms, we measured the execution of four programs that produced different types of stoch~tic elements. All programs were run under Berkeley 4.2 UNIX ~ on an essentially idle VAX 11/750 with floating point accelerator and 4Mb of memory. The programs were written in C, except for some assemblylanguage routines for mathematical functions and matrix manipulation. We computed the elements twice, once storing the images in the virtual memory of the user process, as reported in Table <ref type="table">1</ref>, and once using a frame buffer with microcode linedrawing routines (which we call an enhanced frame buffer). All images were computed at 512 by 512 resolution.</p><p>Execution profiling explains where the cpu time is spent in the four programs. Table <ref type="table" target="#tab_0">2</ref> shows the distribution of the user cpu time among three major phases of computation, described below: I. generate, 2. shade and render, and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">draw particles</head><p>The unaccounted time wad consumed by global initialization, argument parsing, and sorting the data base. We also omit the time spent drawing trunks on the Near Trees, because they were not modelled by particle systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Generate</head><p>The details of model generation depend on the type of object being modelled. For example, one-fifth of the tree generation time is spent in the sin and cos routines, computing branch vectors based on the angle a branch makes with the trunk or parent branch. Simpler stochastic processes are used to generate the Fire element.</p><p>Model generation uses random numbers extensively. The incremental pseudo-random number generator in our math library takes about twenty-seven minutes to compute the twenty million random numbers used for the trees in Figure <ref type="figure">4</ref>. in contrast, inline code accessing a pre-eomputed table of a few hundred random numbers takes less than four minutes. The table-driven approach creates satisfactory visual diversity and can provide, at approximately equal cost, random numbers drawn from any type of distribution. The visual success of this optimization has been observed by others <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b13">13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Shade and Render</head><p>The second phase performs shading and perspective calculations, clips particles, and sorts them into screen-depth buckets. Perspective and clipping routines typically take between five and ten percent of the program's total running time. Shading also consumes about five to ten percent of the compute time for the trees and grass. Less time was spent shading the Far Trees than the Near Trees because simpler lighting models were used and external shadows were omitted. The least amount of time was spent on the shade and render phase for the Fire element, because it has the simplest shading models and requires no visible-surface calculations.</p><p>Floating point, matrix and mathematical library routines accounted for about one-fifth of the total user time. These routines are called during both of the first two phases, but not in the final phase which uses only screen coordinates. Additional floating point operations are performed by in-line code in pro cedures outside the math and matrix libraries. For example, we examined a procedure that accounts for one-third of the tree generation time. More than three-fourths of the instructions in its inner loop were floating point instructions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Far Trees</head><note type="other">Near Trees Grass Fires Figure 4 Fifnre 3 Figure 8 Figure e</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Draw Particles</head><p>The" final phase takes as input the description of particle primitives in two-dimensional screen coordinates and draws the primitives into the frame buffer. Our enhanced frame buffers have microcode routines for drawing anti-aliased lines and circles.</p><p>The host provides the x and y coordinates for line endpoints, the width of the line, and its eolour; the frame buffer then determines whicl~ pixels to modify. When a virtual frame buffer is used, both line-drawing calculations and address computation are performed in software, and drawing particles is the most expensive phase of the computation. As Tables <ref type="table" target="#tab_0">2</ref> and<ref type="table">3</ref> show, the frame buffer successfully takes over much of this work, leaving the host cpu to spend most of its time generating, shading, and rendering the model. Furthermore, the real frame buffer provides physical memory for the entire image and reduces the operating system costs for virtual memory management.</p><p>Far  <ref type="table">3</ref>. User time with and without a real frame buffer An important advantage of the virtual frame buffer is its ability to store data of an arbitrary precision. The particle systems algorithm builds up a picture by repeatedly adding very small amounts of colour to a pixel. Experience indicates that eight bits per primary eolour, while sufficient for displaying a finished image, are inadequate for computing some images. A real frame buffer with twelve to sixteen bits per colour and functions for drawing anti-aliascd particle primitives would provide valuable hardware support for rendering particle systems.</p><p>Table <ref type="table" target="#tab_0">2</ref> shows that Near Trees consumed proportionally more particle drawing time than Far Trees. Because the Near Trees particles appear larger on the screen, the line drawing calculations for each particle take longer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Summary</head><p>Notably, no single phase of the computation dominates. Theoretical results obtained by Fournier show that the cost to compute a stochastic parametric surface by a frartal subdivision algorithm is linear in the number of points to be displayed <ref type="bibr" target="#b5">[5]</ref>. He argues that if the subdivision algorithm is implemented etnciently, the time required to generate the model should be less than the time to transform, shade, and display it. From our measurements, we similarly conclude that the cost of creating an image with particle systems is not specifically due to the expense of generating the stochastic model, but is more generally explained by the inherent need to process a great deal of complexity in all phases of image creation. Even when we offload most of the costs of drawing primitives to the frame buffer, more time is typically required to manage, draw, and render the model than to generate it.</p><p>It is difficult to compare our measurements with the costs of creating synthetic images using traditional models. Images as complex as our forest scenes have rarely been modelled without using stochastic, or other algorithmic, methods to generate detail. When they have, the modelling effort must typically be measured in human design time. The costs of shading, visible surface calculations, and rendering are also difficult to compare with previous work, because few other measurements are available. Crow <ref type="bibr" target="#b4">[4]</ref> and Whitted and Weimer <ref type="bibr" target="#b14">[14]</ref> have published some measurements for pictures using conventional models, but their images were much simpler than ours. An interesting area for future work is the measurement and performance analysis of more general-purpose modelling and rendering software. We are currently investigating this area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>We have demonstrated that particle systems are able to model complex and structured objects. Simple primitives, given a set of relationships that bind them into a cohesive whole, can be used to produce complex models with extensive and varied detail. These relationships must specify the constraints by which millions of particles are dependent on one another. Because our new particle systems are more structured and dependent, we have developed more sophisticated algorithms to model their dynamics.</p><p>Particle systems were first used to model an amorphous phenomenon, fire, and it seemed natural to use a volume-filling representation. The tree and grass images demonstrate that volume-filling representations, such as particle systems, can effectively model solid objects. Such objects arc conventionally modelled by surface-based techniques or solid geometry.</p><p>Procedural modelling techniques can be used to create models with more detail than a human designer could ever specify, and stochastic approaches can provide a rich variety of detail. Unfortunately, it is infeasible to compute exact solutions to the visible surface and shading problems for the enormous amount of detail that we can generate. Our algorithms are based on the belief that exact solutions arc not always necessary in scenes with great visual complexity. We described an approximate painter's algorithm for visible surface determination and introduced probabilistic approaches to shading. Shadow masks, implemented as texture maps, simplified the task of adding shadows to the image.</p><p>Performance analysis shows that the computation is distributed relatively evenly among the three major phases of our particle systems algorithms: model generation, shading and rendering, and particle drawing. In particular, the cost of gener.~ting complex, structured models does not dominate the computation, as one might expect. Instead, the expense arises from the need to process a vast amount of three-dimensional detail throughout all phases of the computation in order to create the visual richness that we desire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O SIG GR</head><note type="other">llm i m AP i| H '85</note></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>F</head><label></label><figDesc>i g u r e I . Forest Scene from The Adventures of AndrE and Walllt B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>DeltaHeifht are specified for the tree type; they represent the mean height and the maximum difference from the mean. If the height is distributed uniformly between a+b a and b, then MeanHeight is T ' and DeltaHeiffht is I ~-a l In Figure 3, the deciduous trees have a MeanHelght 2 of 60 and a Deltalteight of 12; the evergreen trees also have a MeanHeioht of 00, but a DeltaHeight of 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>F i g u r e 3 .</head><label>3</label><figDesc>Andrd's Forest F i g u r e 2. Frame from Star Trek II: The Wroth o f Khan</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>F</head><label></label><figDesc>i g u r e 4. Tree-covered Hills at Sunrise</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>.......................</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Dimensions Used in Tree Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Distances Used by Tree Shading Algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>F</head><label></label><figDesc>i g u r e 8. Shaded Trees F i g u r e I I . Close-up Forest Scene F i g u r e 9. Shadow Mask F i g u r e 12. Still from Film of Blowing Gram F i g u r e 10. Grass Element Shadowed by Shadow Mask</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 2</head><label>2</label><figDesc></figDesc><table><row><cell>number of frames</cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>1</cell><cell>1</cell><cell></cell><cell>11</cell></row><row><cell cols="2">user cpu time (hh:mm:ss)</cell><cell>5:31:18</cell><cell></cell><cell cols="2">10:27:27</cell><cell>4:44:31</cell><cell></cell><cell>52:50</cell></row><row><cell>memory (Mh)</cell><cell></cell><cell>4.95</cell><cell></cell><cell cols="2">10.17</cell><cell>--</cell><cell></cell><cell>5.04</cell></row><row><cell>lines drawn (1000'~)</cell><cell></cell><cell>592</cell><cell></cell><cell></cell><cell>1067</cell><cell>416</cell><cell></cell><cell>268</cell></row><row><cell cols="2">lines per frame (lOOO's)</cell><cell>592</cell><cell></cell><cell></cell><cell>1067</cell><cell>416</cell><cell></cell><cell>24</cell></row><row><cell cols="5">TABLE 1. Overall measurements for particle systems programs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">without frame buffer</cell><cell></cell><cell cols="3">with enhanced frame buffer</cell><cell></cell></row><row><cell cols="2">Far Trees</cell><cell cols="2">Near Trees ....... Grass</cell><cell>Fires</cell><cell>Fail" Trees</cell><cell>Near Trees</cell><cell>Grass</cell><cell>Fires</cell></row><row><cell>generate</cell><cell>32.5</cell><cell>11.4</cell><cell>13.8</cell><cell>28.3</cell><cell>47.6</cell><cell>18.6</cell><cell>25.0</cell><cell>37.9</cell></row><row><cell>shade and render</cell><cell>25.1</cell><cell>28.4</cell><cell>32.3</cell><cell>23.6</cell><cell>30.3</cell><cell>45.1</cell><cell>57.6</cell><cell>30.1</cell></row><row><cell>draw particles</cell><cell>33.2</cell><cell>49.9</cell><cell>51.6</cell><cell>41.0</cell><cell>14.8</cell><cell>19.6</cell><cell>13.2</cell><cell>23.6</cell></row><row><cell>total</cell><cell>90.8</cell><cell>89.7</cell><cell>97.7</cell><cell>92.9</cell><cell>92.7</cell><cell>' '83.3</cell><cell>95.8</cell><cell>91.6</cell></row></table><note><p>. Percent of user time spent in each phase of computation | UNIX is a trademark of Bell Labor~torles.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>g. Acknowledgements</head><p>We would like to thank the members of the Computer Graphics Project of Lucasfilm Ltd for forming a stimulating and enjoyable working environment. John Lasseter contributed significantly to the visual design of the forest scenes and provided welcome encouragement. Eben Ostby developed special compositing software for the forest backgrounds. The shading algorithms profited from our discussions with Rob Cook. The work of the second author was supported in part by a State of California Microelectronics fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bibliography</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Botanical tree image generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Kunii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="10" to="34" />
			<date type="published" when="1984-05">May 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling natural trees with space curves</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bloomenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1985-07">July 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An extension of the combinatorial geometry technique for modeling vegetation and terrain features</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Murarka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Onuoha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Steingurg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974-06">June 1974</date>
			<publisher>Mathematical Applications Group, Inc</publisher>
		</imprint>
		<respStmt>
			<orgName>USA Ballistic Research Laboratories</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A more flexible image generation environment</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Crow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGtL4PH 8P~ Computer Graphics</title>
		<imprint>
			<date type="published" when="1982-07">July 1982</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="9" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computer rendering of stochastic models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fournier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fus~ell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="371" to="384" />
			<date type="published" when="1982-06">June 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Simulation of natural scenes using textured quadric surfaces</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 8~</title>
		<imprint>
			<date type="published" when="1984-07">July 1984</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Lucasfilm</forename><surname>Ltd</surname></persName>
		</author>
		<title level="m">The Adventures o/Andr~ and Wally B., (film)</title>
		<imprint>
			<date type="published" when="1984-08">Aug. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mazfield</forename><surname>Parrish</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Watson-Guptill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fractale: Form, chance and dimension</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Mandelbrot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<pubPlace>Freeman, San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Procedure models for generating three-dimensional terrain</title>
		<author>
			<persName><forename type="first">B</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="154" to="162" />
			<date type="published" when="1980-07">July 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Genesis Demo from Star Trek II: The Wrath of Khan</title>
		<author>
			<persName><surname>Paramount</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Video Review Number 11</title>
		<imprint>
			<date type="published" when="1982-06">June 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Particle systems--A technique for modelling a class of fuzzy objects, S]GGRAPH 83</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Reeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="359" to="376" />
			<date type="published" when="1983-07">July 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Plants, fractals, and formal languages, SIG-GRAPH 84</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1984-07">July 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A software testbed for the development of 3d raster graphics systems</title>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>~eimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="43" to="58" />
			<date type="published" when="1982-01">Jan. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Casting curved shadows on eurved surfaces</title>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics I~</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="270" to="274" />
			<date type="published" when="1978-08">Aug. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
