<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Efficient Meta-lock for Implementing Ubiquitous Synchronization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ole</forename><surname>Agesen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sun Microsystems Laboratories One Network Drive Burlington</orgName>
								<address>
									<postCode>01803-0902</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Detlefs</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sun Microsystems Laboratories One Network Drive Burlington</orgName>
								<address>
									<postCode>01803-0902</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alex</forename><surname>Garthwaite</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sun Microsystems Laboratories One Network Drive Burlington</orgName>
								<address>
									<postCode>01803-0902</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ross</forename><surname>Knippep</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sun Microsystems Laboratories One Network Drive Burlington</orgName>
								<address>
									<postCode>01803-0902</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ramakrishna+</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sun Microsystems Laboratories One Network Drive Burlington</orgName>
								<address>
									<postCode>01803-0902</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Derek</forename><surname>White</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sun Microsystems Laboratories One Network Drive Burlington</orgName>
								<address>
									<postCode>01803-0902</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">+Sun Microsystems</orgName>
								<address>
									<addrLine>901 San Antonio Road</addrLine>
									<postCode>94303-4900</postCode>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Efficient Meta-lock for Implementing Ubiquitous Synchronization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">52C4CEC7E16D69413C2C967ECB95CB40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>object-oriented language implementation</term>
					<term>synchronization</term>
					<term>concurrent threads</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Programs written in concurrent object-oriented languages, especially ones that employ thread-safe reusable class libraries, can execute synchronization operations (lock, notify, etc.) at an amazing rate. Unless implemented with utmost care, synchronization can become a performance bottleneck. Furthermore, in languages where every object may have its own monitor, per-object space overhead must be minimized. To address these concerns, we have developed a meta-lock to mediate access to synchronization data. The meta-lock is fast (lock + unlock executes in 11 SPARCTM architecture instructions), compact (uses only two bits of space), robust under contention (no busy-waiting), and flexible (supports a variety of higher-level synchronization operations). We have validated the meta-lock with an implementation of the synchronization operations in a high-performance product-quality JavaTM virtual machine and report performance data for several large programs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Shared-memory multi-processor systems have become mainstream, even in the personal computer market. Simultaneously, the concurrent object-oriented JavaTM programming language [3] has experienced explosive growth. As a result, significant effort is being devoted to implementing both the sequential and parallel features of this language, e.g., <ref type="bibr">[4,</ref><ref type="bibr" target="#b13">18,</ref><ref type="bibr" target="#b14">19,</ref><ref type="bibr" target="#b21">25,</ref><ref type="bibr">281</ref>. This paper focuses on the latter area, proposing a new implementation of synchronization operations that, we believe, possesses an attractive set of trade-offs between space, time, and assumptions about the underlying hardware. Implementors of the Java language's synchronization operations are challenged on two fronts: l Frequency. Most Java-based programs synchronize extremely frequently. This occurs because standard class libraries, including commonly used data types such as vectors and buffers, Permission to make digital or hard copies of all or pan of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advant -age and that copies bear this notice and the full citation on the first page.</p><p>To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. OOPSLA '99 11/99 Denver, CO, USA Q 1999 ACM l-58113-238-7/99/0010...55.00</p><p>have been designed for the general multi-threaded case. To give just one example, we measured the SPECjvm98 version of javac <ref type="bibr">[29]</ref>, a source-to-bytecode compiler, and found that on a high-performance virtual machine featuring exact garbage collection and other innovations (E.G.C.JVM'), this program executes 765,000 synchronization operations per second.</p><note type="other">l</note><p>Ubiquity. The Java language, unlike most concurrent languages, does not define a particular type of synchronizable object such as a monitor or a mutex. Instead, all objects, including, for example, strings and arrays, can be synchronized upon. This design offers the programmer a simpler and more regular language, but presents an obstacle to the language implementor: synchronization must be implemented at a low per-object space cost. More precisely, the ability to synchronize must be provided at a low space cost; actual synchronization can use additional space since, in practice, programs synchronize on a small fraction of objects. For example, javac, discussed above, synchronizes on about 6% of allocated objects.</p><p>Frequency demands time-efficiency while ubiquity demands space-efficiency, This paper presents a new synchronization scheme that, we believe, attains good all-around performance: synchronization executes at close to the speed of the hardware operations while reserving only two bits in each object. Our algorithm, in its basic form, uses a two-level ("meta") locking scheme, with an optional extension that fuses the two levels for higher performance in uncontended cases.</p><p>We assume the arbitrary interleaving implied by preemptive thread scheduling: no other assumption makes sense on multiprocessors, and, moreover, even on uniprocessors lack of preemption can lead to unfair (and unintuitive) thread scheduling. It may seem that synchronization operations could be elided for many programs with only a single thread. In reality, however, no program written in the Java language is single-threaded, since, in addition to the main thread created by user code, the class libraries create special threads to handle finalization and various forms of weak references <ref type="bibr" target="#b26">[30]</ref>. More significantly, perhaps, commonly used graphics libraries, such as the Abstract Windows Toolkit (AWT), create threads.</p><p>1. E.G.C.JVM, our research JVM, known in other publications as EVM and ExactVM, is embedded in Sun's Java 2 SDK Production Release, available at http://www.sun.com/solaris/java/. Henceforth, the term "JVM" will refer to implementations of the Java Virtual Machine specification.</p><p>The rest of this paper is organized as follows. Section 2 informally describes the Java language's synchronization operations, at both the source and bytecode levels. Section 3 reviews previous work most closely related to our synchronization algorithm. Section 4 describes our basic two-level algorithm, and Section 5 discusses extensions, including a fast path that fuses the primary and metalock levels, and other optimizations that are important for good performance. Section 6 presents performance data to quantify the behavior of our algorithm. Section 7 offers final conclusions and some directions for further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>Java virtual machines (JVMs) do not execute source code directly. Instead, they execute bytecode obtained from binary class-files that are produced by a source-to-bytecode compiler such as javac. Thus, JVMs must implement the bytecode-level synchronization operations, not the source-level synchronization operations. The distinction is important because the bytecode-level operations are more general than the source-level operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Source-level synchronization</head><p>The Java language provides mutual exclusion in two syntactic forms. A synchronized method of an object obtains a lock on the object, executes the method, and releases the lock. A synchronized statement, synchronize (exp) I . ..actions... I, evaluates the expression to obtain an object that is locked for the duration of the specified actions.</p><p>The synchronization operations in the Java language are reentrant (recursive): synchronized statements on the same object can nest, synchronized methods can invoke other synchronized methods, and the two can be mixed. Consequently, the underlying lock and unlock operations must do some form of counting. Both synchronized methods and statements are "block structured," forcing perfect nesting of locking operations. At the source level, there is no way to express unbalanced locking operations. In particular, exception-throwing and returning out of locked regions unlock as necessary. However, as we shall see below, the story is different at the bytecode level.</p><p>To facilitate communication between threads, the Java language defines wait, notify, and notifyAl operations. Like locking, these operations are performed relative to an object. Prior to executing wait and no tify[All], a thread must first lock the target object. Informally, wait fully releases the lock and suspends the current thread. This allows other threads to obtain the lock. The waiting thread becomes eligible to run again when another thread performs a notify operation on the object, a specified time has elapsed, or an asynchronous interrupt is delivered to the thread. The notify operation wakes one waiting thread, whereas not i f yAl1 wakes all waiting threads (when no threads are waiting, both operations are no-ops). When a waiting thread wakes up, it reacquires the lock the same number of times it held it prior to wait. The lock reacquisition puts the thread into competition with other threads attempting to acquire the lock, including both other awakened waiters and threads attempting to execute a synchronized method or statement. Once a waiting thread has reacquired the lock, the wait operation completes. To simplify matters, in this paper we shall not discuss interrupts further, except to note that in most of our implementation, an interrupt is handled similarly to a time-out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Bytecode-level synchronization</head><p>Having described synchronization at the source level, we now turn to the bytecode level. In bytecode, method synchronization is performed as part of the call/return sequence: if the ace-synchronized attribute is set on a method, the call sequence must acquire the lock (one more time) and the return sequence must release it once. Statement synchronization is expressed using a bytecode pair, moni torenter and monitorexit, which lock and unlock, respectively, the object referenced by a value popped from the JVM's "operand stack." Unfortunately, while the bytecode representation of synchronized methods is inherently well-nested, there is no such guarantee for moni torenter and monitorexit. Nothing prevents bytecode from containing instruction sequences like "lock A, lock B, unlock A, unlock B," which has no equivalent Java source code. The loss of block structure at the bytecode level makes it difficult to stack allocate locking-related data structures. Consequently, to handle non-LIFO locking and unlocking, our implementation uses a free-list allocator (see Section 5.1).</p><p>Conceivably, a static analysis of bytecode could conservatively "pair up" monitorenter and monitorexit instructions in most cases, allowing subsequent execution to assume perfect nesting. We would expect this analysis to succeed most of the time on bytecode resulting from translation of Java source code. In general, however, the problem is undecidable, and it would be incorrect to reject bytecode for which the analysis fails, because such bytecode is still legal in the sense that it passes the bytecode verifier <ref type="bibr" target="#b17">[22]</ref>. To further complicate the picture, JNI, the Java Native Interface, grants native code access to synchronization in the form of lock and unlock operations, so even if all bytecode can be shown to be structured, a fall-back mechanism would still be needed for synchronization by native code.</p><p>Finally, the wait and not ify <ref type="bibr">[All]</ref> operations have no direct representation at the bytecode level, but instead are implemented as native methods of the top-most class (j ava . lang . Ob j ect).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>There is a large general literature on synchronization primitives and their implementation. <ref type="bibr">Dijkstra [lo]</ref> and Lamport <ref type="bibr" target="#b15">[20]</ref> present subtle algorithms that achieve mutual exclusion assuming only that individual reads and writes are atomic. Fortunately, modem architectures provide composite instructions such as compare-and-swap that read and write a memory location in a single atomic step, greatly simplifying the mutual exclusion problem and eliminating the need for such subtlety. We shall refer to the composite atomic instructions simply as "atomic instructions." Weakly consistent memory models, which allow different processors to observe memory operations as occurring in different orders, may require the use of memory barrier instructions to reintroduce consistency, whether using individual reads and writes or atomic instructions.</p><p>In its broad structure, our meta-lock resembles the MCS-lock of Mellor-Crummey and Scott <ref type="bibr" target="#b20">[24]</ref>. The MCS-lock uses an atomic swap for lock acquisition and an atomic compare-and-swap (CAS) for lock release in much the same way as does our meta-lock algorithm. The MCS-lock has many of the same properties as our meta-lock, including starvation freedom and FIFO access to the lock. However, the details are quite different and, in particular, contention results in busy-waiting. Also, space-efficiency is not as extreme a concern in the context of their work. Brinch Hansen [ 121 and Hoare <ref type="bibr" target="#b9">[14]</ref> coined the term monitor, and provided the nomenclature used by the Java language. There are several ways, however, in which the monitors in the Java language differ from the original: any object may be used as a monitor, monitors may be entered recursively, and monitors provide a single implicit, rather than possibly several explicit, "condition variables" [ 131. Birrell gives an excellent tutorial on programming with "standard" synchronization primitives [6]. As we have discussed, the synchronization primitives of the Java platform are difficult to implement in a manner that is both time-and space-efficient. Scalability to multiprocessor systems is another important concern. We shall now discuss some previous implementations focusing on the approach they take to trading off these concerns.</p><p>The original JDKTM implementation of the Java virtual machine <ref type="bibr" target="#b17">[22]</ref> provides a space-efficient monitor implementation, but one that is not particularly time-efficient or scalable. This design requires that each object has a unique identifier valid over its lifetime. The actual implementation uses an object table whose entries are called handles, providing an extra level of indirection to facilitate object compaction. The handle address of an object remains constant during the object's lifetime, and can therefore serve as a unique identifier. A global table called the monitor cache maps object handle addresses to monitor structures that can be used to perform the actual synchronization operations. When a thread synchronizes on an object, it first ensures that the monitor cache maps the object to a monitor, creating and installing the monitor in the table if necessary. This approach has no fixed per-object space cost, using only space proportional to the number of entries in the monitor cache. However, it is fairly time-inefficient, since each synchronization operation must first do (at least) a table lookup to locate the monitor associated with the object. Further, it is not very scalable. The monitor cache is a global data structure that is accessed concurrently. To make this concurrent access safe, the monitor cache is protected by a lock. Thus, all synchronization operations obtain a single lock, an obvious source of contention. The monitor cache locking also adds some cost in the uncontended <ref type="bibr">Bacon et al. [4]</ref> propose a clever scheme motivated by many of the same concerns as ours. In this design, 24 bits of each object header are devoted to locking. One bit indicates whether the object has a thin or fat lock, If it has a thin lock, then all necessary locking information is contained in the remaining 23 bits. If it has a fat lock, then the remaining 23 bits are an index into an array of pointers to fat lock structures that, much like monitors, hold the necessary data for the synchronization operations. Thin locks are used as long as the lock is uncontended, and is not recursively locked more times than can be represented in a count field of the thin lock; if either condition is violated, the lock representation is "inflated." This design does well at optimizing the expected common case of uncontended locking and unlocking. Locking requires a small number of instructions, with only one atomic instruction in the fast path, and unlocking requires no atomic instruction. However, thin locks leave some issues to be addressed: l Contention. When there is contention on a lock for the first time, all threads that do not acquire the lock must busy-wait (a.k.a. spin) until the lock is released. Unbounded busy-waiting is generally undesirable but, as the authors point out, busywaiting is done at most once in the lifetime of a given object.</p><p>Still, it would not be hard to construct a program that does contended locking on many short-lived objects, causing a great deal of busy-waiting. l Lack of dejation. Lock dejlation is not discussed; once a lock becomes fat, it remains fat. While this is not an issue for most programs, one could imagine a long-lived program in which many long-lived objects are locked with contention at some point in their lifetimes. Absent some form of deflation, such a program would consume a large amount of memory for fat locks.</p><p>l Space consumption. Thin locks use 24 bits. This is a significant overhead since the average object size for most programs is quite small [9].</p><p>Joy and Steele <ref type="bibr" target="#b11">[16]</ref> describe a synchronization scheme that uses atomic instructions to arbitrate locking. A per-thread cache of the last locked object allows recursive locking to be optimized. This scheme does not address notification or waiting operations, and uses busy-waiting to resolve contention. Joy [ 151 and Joy and Van Hoff [ 171 describe schemes in which locked objects are enlarged to contain monitor structures, and are given altered virtual function tables whose entries for the "lock" operation assume that the object already contains monitor information.</p><p>In other related work, monitor implementations have been proposed that exploit cooperative thread scheduling [ 191 or make special provision for faster execution of single-threaded programs <ref type="bibr">[25,</ref> 271. As we have already noted, we assume preemptive scheduling, and desire algorithms that work well for both single-and multithreaded programs, so we shall not discuss these restricted schemes further.</p><p>In [5], Bak describes how an early version of Sun's Java HotSpotTM JVM locks objects by replacing an object header word with a pointer to an external lock structure, displacing the original contents of the header word into the lock structure. Two low-order bits in the header word encode its format. Java HotSpot stack allocates lock structures for efficiency. Furthermore, this stack allocation allows fast recursive locking by enabling efficient verification that an object is locked by the current thread: if the lock structure address is sufficiently close to the current stack pointer to guarantee membership in the same thread stack, the current thread must be the lock owner. Personal communication from Zhang <ref type="bibr" target="#b27">[31]</ref> describes how a more recent version of Java HotSpot uses atomic instructions to arbitrate locking between threads, and to inflate contended locks to full monitors without busy-waiting.</p><p>We borrow Java HotSpot's idea of displacing a header word and using some bits of the word to encode its format and the lock state. We use a different allocation scheme that supports non-blockstructured synchronization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OURALGORITHM</head><p>In any concurrent environment, there must be some protocol observed by threads as they manipulate the synchronization data of objects, that is, the data structures that manage synchronization operations. Typically, the protocol specifies when a thread may access or manipulate an object's synchronization data. For example, the thin-locks approach relies on an invariant whereby only the thread owning the lock on an object may modify that object's synchronization data. Other approaches, like ours, allow any thread to update this information. The key to our approach is a time-and  space-efficient meta-lock that protects the synchronization data of each object. The typical pattern for synchronization operations in our system is:</p><p>1. Obtain the object's meta-lock to ensure exclusive access to the object's synchronization data.</p><p>2. Manipulate the synchronization data of that object. This operation should be fast.</p><p>3. Release or hand off the object's meta-lock.</p><p>Meta-locks play a similar role as the auxiliary spin-locks seen in many implementations of POSIX threads [7, 211. These spin-locks provide brief exclusive access to the synchronization state maintained in records representing programmer-level mutexes and con- dition variables.</p><p>We shall use the term "monitor-lock" to denote the lock abstraction exported by the Java virtual machine to avoid confusion with the meta-lock used in its implementation. Because meta-lock acquisition occurs in FIFO order, the above pattern allows a number of fairness policies at the monitor level. The rest of this section describes our algorithm in detail: Section 4.1 presents the data structures involved, Section 4.2 the meta-lock algorithm, Section 4.3 the implementation of the monitor-level lock and unlock operations, and Section 4.4 the implementation of wait and notify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data structures</head><p>Synchronization involves three entities: threads, objects, and lock records. We describe the relevant parts of the data structures that implement them and how they interact during synchronization.</p><p>Threads. We call the data structure that holds thread-specific state an execution environment (EE). Since EES and threads correspond one to one, EE addresses are well-suited as unique thread identifiers. Figure <ref type="figure">1</ref> shows the fields in EES that the synchronization code uses. The steady-state (and initial) value is FALSE for the boolean fields and NULL for the pointer fields. The (POSIX-style) mutexes and condition variables in the EES are used to avoid busy-waiting when contention requires threads to wait for their turn to lock an object, while other fields serve to exchange information between threads synchronizing on the same object.  long as no thread synchronizes on them, and return to NEUTRAL once synchronization ceases. A monitor-locked object is in the LOCKED state. The high 30 bits of the multi-use word hold a pointer to synchronization data (a lock record, see below) that indicates which thread owns the monitor-lock and also stores the displaced hash and age information. The WAITERS state is entered when a thread releases the monitor-lock while other threads are waiting to acquire the lock or to be notified: the object is no longer monitor-locked, but fhe remainder of the multi-use word still points to a lock record. The fourth and final state, BUSY, indicates that the object is meta-locked. In this case, the high part of the multi-use word contains the EE of the thread that has the meta-lock or the EE of a thread attempting to acquire the meta-lock, as will be explained in Section 4.2</p><p>Lock records. Most synchronization data is kept not in objects but in LockRecords. A lock record represents a thread for the purpose of synchronization on a particular object. Figure <ref type="figure" target="#fig_1">3</ref> shows the fields of a lock record: the owner thread, the number of times the thread has locked the object (recall that monitor-locks are recursive), a field for the displaced hash and age information, a queue field for linking the lock records of all threads that synchronize on a given object, and a free-list field for linking lock records when they are not in use (see Section 5.1). Figure <ref type="figure" target="#fig_1">3</ref> also shows an object with three lock records on its lock queue. In this example, the state is LOCKED, so one of the lock records belongs to a thread that holds the monitor-lock. In our implementation, new lock records are appended to the end of the queue (FIFO order) and stay in order, except that when a thread acquires the monitor-lock, it moves its lock record to the front so that the first lock record of a locked object always belongs to the thread that holds the monitorlock.</p><p>4.2 Meta-locking: exclusive access to synchronization data An object's meta-lock protects its synchronization data, which we can now define precisely as comprising the multi-use word, including the lock queue pointer (when there is one) and the lock records in that queue. For example, if a thread wants to place a lock record in the queue to wait for its turn to acquire the monitor-lock, it meta-locks the object to gain exclusive access to the queue, appends its lock record, and then releases the meta-lock. Similarly, to read or write the hash code of an object, meta-locking must be done (though it is possible to optimize reads of immutable fields, like the hash code, most of the time).</p><p>The meta-lock mechanism provides two routines for higher-level locking to use: getMetaLock (1 acquires the meta-lock and returns the previous (non-BUSY) value of the multi-use word, while releaseMetaLock ( ) releases the meta-lock and sets the multi-use word of the object to a value appropriate to the new state of the synchronization data. This new value may be any non-BUSY value; the operation might release the lock and restore the displaced multi-use word bits and the NEUTRAL lock state, or it might change the queue pointer to point to a new lock record, or it might leave the multi-use word unchanged. In any case, call this new multi-use word value the release bits of the operation.</p><p>Figure <ref type="figure">5</ref> shows the Bow chart for obtaining and releasing an object's meta-lock. There is a slow path for each operation when contention occurs. For reference, the source code for these operations.can be found in the appendix.</p><p>A thread attempts to gain the meta-lock by using an atomic swap operation to replace the object's multi-use word with a word consisting of a reference to the thread's EE and the low-order bits representing the BUSY state. If the word returned by the swap operation has low-order bits in any state other than BUSY, the thread has acquired the meta-lock and may proceed. However, if the returned word's low-order bits indicate the object is BUSY, then some other thread holds the me&amp;lock, so the current thread fol-Iows the slow path for meta-lock acquisition. As Figure <ref type="figure" target="#fig_2">4</ref> shows, the threads contending for the meta-lock are totally ordered by the order in which the swap instructions occurred. The first thread in this order knows, since it acquired the meta-lock, that it has no pre-owner I lockBits' lockBits' lockBits: valuebeforemeta-lock I I meta-locked object successor rt----) predecessor decessor, and every other thread knows its predecessor from the EE in the lockBits word read by the swap instruction.</p><p>To accomplish the meta-lock release, a thread uses an atomic compare-and-swap (CAS) operation to atomically compare the current contents of the object's multi-use word with what it had written there (i.e., its EE and the BUSY state) and, if it is still the same, write the release bits. If the comparison fails, then some other thread has attempted to obtain the meta-lock and is now waiting for its turn. In this case, the releasing thread will "hand off' the meta-lock to the next thread in the order induced by the swap operations, by taking the slow path for meta-lock release. The releasing thread must also hand off the release bits to the acquiring thread, so the acquiring thread will obtain the bits that would have been written had there been no contention for the me&amp;t-lock.</p><p>The main complication in the slow-path meta-lock hand-off is that each thread in the atomic swap total order knows the identity of its predecessor, but not of its successor. Because of this asymmetry, the hand-off from a predecessor to its successor synchronizes using state in the predecessor's EE. As we saw in Figure <ref type="figure">1</ref>, that state includes a mutex and condition variable pair metaLockMuteximetalockcondvar, a field to record the successor's EEL and several booleans used to coordinate the transfer of the value of the release bits. The mutex is used to ensure that the threads participating in the hand-off update the other fields in the correct order.</p><p>The condition variable is used to block whichever thread enters the hand-off first until the other thread is ready to complete the transaction.</p><p>The hand-off protocol proceeds in one of two ways, as shown in the two cases highlighted in Figure <ref type="figure">5</ref>. The predecessor thread releasing the meta-lock and the successor thread attempting to acquire it "race" to acquire the predecessor thread's mutex. If the successor thread wins the race, it will change the predecessor's SUCCEE field from the default value of NULL to the address of its own EE. If the predecessor thread wins the race, it will set it's own bitsForGrab field to TRUE. Thus, each thread may determine whether it won the race by noting whether the competitor has made the corresponding change.</p><p>Case 1: successor (acquiring) thread wins race. When the successor thread obtains the mutex and its predecessor's bitsForGrab field is FALSE, it knows it acquired the mutex first, In this event, it updates the predecessors's succEE, and waits for the predecessor to complete the transaction. When the predecessor acquires the mutex, it notes from the non-NULL value in its SUCCEE field that the successor went first, and therefore completes the meta-lock hand-off by setting the successor's metaLockBits to the release bits, setting gotMetaLockSlow to indicate that those bits are valid, and waking the successor by signalling metaLockCondvar. Finally, the predecessor releases the mutex, allowing the successor to continue, having acquired the meta-lock.</p><p>Case 2: predecessor (releasing) rhread wins race. Here the predecessor thread determines that it acquired the mutex first by noting that its succEE field is still NULL. It does not know the identity of its successor, but it knows that the successor knows its identity. Thus, it sets the metaLockBits field of its EE to the proper release bits value, and sets the bitsForGrab field to TRUE to indicate that those bits are valid, and waits for the successor to read the bits (releasing the mutex in the process). The successor thread obtains the mutex, sees that its predecessor's bitsForGrab is TRUE, and thus realizes that it has acquired the mutex second, and that the release bits are available in its predecessor's metalock-Bits field. It copies those bits, resets the predecessor's bits-ForGrab to the default value of FALSE to indicate that the handoff is complete, signaIs its predecessor's condition variable to inform it of that fact, and, finally, releases the mutex.</p><p>The meta-lock protocol guarantees that threads obtain the metalock in the order determined by the execution of the atomic swap operations. A thread need only wait for threads ahead of it in the swap order, so if no thread blocks indefinitely while holding the meta-lock, all threads attempting to acquire the meta-lock will eventually succeed. An informal proof that the meta-lock guarantees mutual exclusion and freedom from lockout can be found in our Sun Labs Technical Report <ref type="bibr">[ 11.</ref> The hand-off protocol is somewhat complicated, but it avoids pitfalls that occur if simple busy-waiting is used. If n acquiring threads busy-wait for the meta-lock when there is contention, then even with fair thread scheduling there can be a delay for the next thread to acquire the lock proportional to n thread time slices. If thread scheduling isn't fair at all, then the delay may he unbounded. On the other hand, bounded busy-waiting (using the hand-off protocol if still locked) can be useful. A scheme where an acquiring thread yields when it detects meta-lock contention is much simpIer, but works only if the operating system's yield call guarantees that all other threads will run before the acquiring thread is run again. Otherwise the thread holding the meta-lock might starve.</p><p>Armed with our meta-lock, we now proceed to implement the monitor operations: lock, unlock, wait, and notify. Because the meta-lock arbitrates access among contending threads, we can implement monitor operations using a number of different data structures and offer a variety of semantics <ref type="bibr">[8]</ref>. We have chosen an implementation that uses a simple linked list of lock records and gives equal preference to awakened waiters and newly arrived threads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Locking and unlocking objects</head><p>Acquiring and releasing the monitor-lock of an object corresponds to entering and exiting the object's monitor. Figure <ref type="figure">6</ref> shows the fast-path implementation for these operations. Most commonly, the object being monitor-locked is either unlocked-in a NEU-TRAL or WAITERS state-or being locked recursively. In these cases, the locking thread simply updates the object's synchronization data; it need not interact with other threads. Likewise, when unlocking an object, there are two cases that involve no interaction with other threads: the unlocking thread has recursively locked the object, in which case it simply decrements the lock count; or there are no other threads attempting to acquire a singly-held lock, in which case it restores the displaced multi-use word value, which has the NEUTRAL lock state.</p><p>The remaining cases involve threads contending for the monitorlock; see Figure <ref type="figure" target="#fig_3">7</ref>. Much as in meta-lock hand-off, we use a perthread mutex and condition variable to coordinate acquiring and releasing threads. When a thread attempts to acquire a monitorlock but finds it locked, it suspends on a condition variable in its own EE, waiting to be signalled by a lock-releasing thread that it should re-attempt the acquisition. When the acquiring thread receives this signal, it repeats the lock-acquisition slow path: it acquires the object's meta-lock and checks the object's lock state. If the state is now different from LOCKED, it adjusts the synchronization data to indicate that it holds the monitor-lock and releases the meta-lock; if the state is LOCKED, the thread releases the metalock and waits again.</p><p>To release a contended monitor-lock, a thread first obtains the meta-lock. Then it removes its own lock record from the queue. Subsequently, it calls wakeupEE ( 1 to find the first thread on the lock queue that is waiting to acquire the lock. If there is such a thread, it is signalled. Then, the releasing thread performs a metalock release to write out the shortened lock queue and set the lock state to WALTERS. (We have elided code that optimizes away redundant signalling on waiting threads.) Thus, at the monitor-lock level, unlike the meta-lock level, we do not use a hand-off: the releasing thread does not give the monitor-lock to a waiting thread but merely invites the waiting thread to re-attempt the acquisition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Waiting and notifying</head><p>Figure <ref type="figure" target="#fig_4">8</ref> shows the remaining two monitor operations: wait and notify. The Java language specification requires that the thread performing them must hold the object's monitor-lock, otherwise the operations throw an exception. A thread waits by acquiring the meta-lock, setting the isWaitingForNoti fy field in its EE, and releasing the monitor-lock and meta-lock (i.e., setting the lock state to WAITERS). It then waits until a notification operation makes it a potential lock contender again, and some monitor-lock release operation signals it to actively contend, or until some amount of time specified in the wait operation has elapsed. A notifying thread similarly acquires the meta-lock. Then it walks the  queue of lock records, looking for threads waiting for notification-ones whose isWaitingForNotify field is TRUE-and resetting this boolean to indicate that they have been notified. The notify ( ) operation finds the first such thread and resets its boolean; not i f yA11 ( ) traverses the entire lock queue. Finally, the notifying thread releases the meta-lock.</p><p>Since some styles of concurrent programming result in a high frequency of notifications, our implementation has further optimized the notify code (the optimization is not shown in the figure). The idea is that a simple read of the multi-use word most of the time suffices to grab the root of the lock queue. If the read fetches a word in LOCKED state, the notifying thread can verify that it holds the monitor-lock and walk the queue without holding the metalock. The correctness of this optimization relies on two properties: a new thread waiting for a notify cannot appear in the queue (because the notifying thread holds the monitor-lock), and other threads that join the queue do so at the end (so the queue is never disconnected). See also Section 5.3 for an alternative implementation in which notify does no queue walking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXTENSIONS TO THE BASIC ALGORITHM</head><p>In this section, we discuss extensions to our algorithm, related to management of lock records and optimization of cases where we may safely avoid meta-locking because the change in the object's lock state requires only one word to be updated. We also demonstrate the flexibility of our approach and outline how to implement it on hardware that does not provide atomic CAS or SWAP operations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Lock record allocation</head><p>As we discussed in Section 3, each of the locking schemes we know about, including the present one, at least occasionally allocates data structures related to locking. This section discusses how those data structures are allocated and deallocated. The original JDK implementation allocates monitors globally, causing serialization of monitor cache operations and resulting scalability bottlenecks. Periodically, unused monitors are reclaimed. The thin locks scheme globally allocates "fat locks," which remain allocated for the lifetime of the associated object [4].</p><p>In our scheme, lock records are the unit of allocation. Each thread has a set of lock records for its exclusive use, linked together in a free list. Lock records on a thread's free list have as many fields as possible preinitialized: the owner field points to the owning thread, the count fields contains 1, which is the proper count when locks are first acquired, and the queue field contains NULL because uncontended locking is most frequent (separation of the free-list link and the queue link, see Figure <ref type="figure" target="#fig_1">3</ref>, allows the queue field to be preset to NULL). Lock record allocation is optimized to avoid any test for an empty free list; instead, an attempt to dereference a NULL pointer generates a signal. The signal handler recognizes the situation, refills the thread's lock record free list, and retries the operation. Threads start with 8 free lock records and add an exponentially increasing number each time they exhaust the free list.</p><p>When a thread unlocks an object, the lock record used by the thread to accomplish the locking is returned to the thread's free list. In our current implementation, the set of lock records allocated to a given thread only grows; there is no provision for removing lock records from a thread's free list if the thread briefly locks many objects: but usually locks few. This is not so bad; the "high water mark" of allocated lock records is limited by the product of the thread stack size and the maximum lexical nesting depth of synchronized statements (at least for bytecode created by compiling Java language source code, as discussed in Section 2.2). If we wished to add a mechanism to return lock records on free lists to the global memory pool, it would be a simple matter to do so as part of garbage collection, as long as we can guarantee that no thread is accessing the lock record free list during garbage collection. Our system has a general mechanism for restricting when garbage collection occurs that can be used to provide this guarantee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Extra fast locking and unlocking of uncontended objects</head><p>We can optimize the algorithm further in the case of uncontended objects. This optimization fuses the meta-lock and monitor-lock operations into a single step. With this optimization, a thread attempting to lock an object reads the object's multi-use word. If the object's lock state is NEWTRAL, then an "extra fast" path is tried. The thread copies the hash and age bits into a fresh lock record and builds a new multi-use value containing the lock record address and the LOCKED state. A CAS instruction is then used to atomically change the multi-use word to the new value if it has not changed since it was read. If the CAS succeeds, then the object is locked; otherwise, the normal meta-locking protocol is used. With this optimization, the extra fast path for locking uses one atomic instruction rather than the two needed for meta-locking and metaunlocking and the total number of instructions is smaller (15 SPARC instructions).</p><p>A similar extra fast path for unlocking is slightly more complicated. When the extra fast locking path succeeds, the only lock record in its queue is that of the locking thread; the queue field of that lock record is NULL. Another thread may add a lock record to the qpeue, changing this queue field at any time. So the extra fast unlocking path must atomically change the multi-use word of the object back to its original contents, but only if the queue field of the first lock record remains NULL. Unfortunately, this "doublecompare-and-swap" operation is not supported in most architectures (though it is not completely unheard of; see <ref type="bibr">[ 111)</ref>. TO get around this, we add a new constraint to the slow path. We require that lock records be allocated with eight-byte alignment, so that three bits are zero in the address of a lock record. In the LOCKED state, this extra bit is used to summarize the state of the queue field of the first lock record: we maintain the invariant that when the bit is 0, the queue field is NULL. If the bit is 1, the queue may be non-NULL. Thus, the first thread to enqueue a lock record after the ini-tia1 one is required to set this bit when releasing the meta-lock. Once this invariant may be assumed, we can construct an extra fast unlock path: check the locking depth, decrementing it and retuming if it is greater than one. Otherwise, construct the expected current value of the multi-use word (pointer to same lock record, queue field bit still clear, LOCKED state), and the desired new value (original multi-use bits, NEUTRAL state), and perform a CAS instruction to write the new value if the current value is still the expected value. If no other thread has enqueued a lock record, then the CAS succeeds and the object is unlocked; otherwise, we revert to the normal meta-locking protocol. If recursive locking were found to be very rare, this proposal could be extended to also summarize the lock count in the extra bit, so that a zero bit observed by an unlocking thread implied both a NULL queue field and a lock count of 1, eliminating the explicit test for recursion.</p><p>The instruction count of the extra fast unlocking sequence is similar to that of extra fast locking, and both use a single atomic instruction. The thin locks scheme uses no atomic instruction in unlocking, but, as we have discussed, pays for that lack with the possibility of unbounded busy-waiting. We feel that in many situations the trade-offs made in our algorithm will be more desirable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Flexibility</head><p>One of the main advantages we have claimed for the meta-locking approach is flexibility. This flexibility results from the fact that we place few constraints on the nature of the data structures protected by the meta-lock. Specifically, it enables separation of mechanism and policy, to allow implementation of a variety of monitor semantics.</p><p>We have tested this flexibility claim to some extent in an attempt to address two potential shortcomings of our simple linked-list data structure: lack of fairness and long searches through queues. First, consider fairness. Motivated by Buhr et al., who classify and compare a spectrum of monitor "styles" that offer different trade-offs between performance and fairness [8], we programmed a version that gives preference to awakened waiters (so-called "priority nonblocking monitors"). To provide this preference, we replaced the single queue with three queues, holding entering, waiting, and awakened threads, respectively. Now it is possible to find and give preference to awakened waiters without searching. Similarly, notify ( ) can execute in constant time, by moving the first thread from the waiting queue to the awakened queue. Second, consider contention. To allow threads to append lock records to queues without having to search to the end of the queue, a search which could become costly if queues get long, we kept head and tail pointers for each of the three queues. Tail pointers also allow not ifyAl1 ( ) to run in constant time, regardless of the number of threads waiting, via list concatenation. While this alternative implementation was straightforward, performance turned out to be inferior to our single-queue system because greater fairness incurs a higher context switch rate and the three-queue data structures were more heavyweight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Hardware without SWAP or CAS</head><p>The meta-lock algorithm relies on two "exotic" atomic operations: SWAP and CAS. First, note that SWAP is easily simulated using CAS: repeatedly read the memory location and CAS until success.</p><p>The CAS operation, or some other sufficiently powerful primitive such as "load-locked/store-conditional," seem to be available on most modem architectures, including mainstream Intel, Ultra-SPARCm, PowerPC, and Alpha microprocessors.</p><p>The JVM in which we implemented our synchronization must run on the previous generation of SPARC processors, which has SWAP but does not have CAS. While correctness cannot be compromised, it was deemed acceptable to trade away some performance and scalability on this older hardware. We first dropped the extra fast synchronization optimization because it relies directly on CAS. Next, we modified getMetaLock ( ) to use a test-and-set protocol (where "set" means swapping out the locked value 1 and "test" means obtaining a non-locked value). When the test fails, the thread yields and optionally sleeps (using exponential back-off as in [2]). The corresponding releaseMetaLock ( ) operation simply stores back the release bit pattern, which of course must be different from the locked value 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">PERFORMANCE</head><p>Usually, good performance is taken to mean that both memory and CPUs are used efficiently. Since different systems must make space/time trade-offs differently, we shall consider space and time costs for our synchronization algorithm separately. All our measurements were collected using the E.G.C.JVM on a lightly loaded 4-CPU 296 MHz UltraSPARC system with 2 gigabytes of RAM and Solaris*M 2.6. Some measurements were obtained by adding counters to the code. To minimize the disturbance resulting from the instrumentation, we used per-thread counters that were accumulated into global totals as threads exited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Benchmarks</head><p>Table <ref type="table" target="#tab_5">1</ref> shows the benchmarks we use to assess the performance of our synchronization code. The HelloWorld program shows how the minimal program behaves. The next seven lines show widelyknown SPECjvm98 benchmarks <ref type="bibr">[29]</ref>. Finally, we include a selection of multi-threaded benchmarks, some of which perform sigmficant amounts of I/O and some of which use graphics. The "#lines" column shows the approximate lines of source code in the benchmark itself, excluding class library code. The '#threads" column shows the maximum number of active threads, excluding three system threads (finalizer, reference handler, and signal dispatcher) and a short-lived secondary finalizer thread created by the SPECjvm98 benchmarks. The volano benchmark is VolanoMark version 2.0.0 build 137 <ref type="bibr" target="#b22">[26]</ref>, and the Java Web Server can be found at http://www.sun.comlsoftwareljwebserver/index.html. The execution times in the table are best of two runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Space performance</head><p>We consider separately the space costs of used and unused synchronization capability.</p><p>Cost of used synchronization capability: the cost for objects that are actually synchronized upon. From the description of our algorithm, it follows that this space cost is proportional to the number of lock records in use at any point in time. More precisely, since threads recycle lock records locally rather than globally, we report the number of lock records allocated by the global allocator during the execution of each benchmark. This higher number reflects our implementation more accurately. In the worst case, a program will synchronize on every object allocated (see Section 2.2), making  the worst-case space cost of our algorithm, as well as of any other algorithm that we know of, proportional to the size of the heap.</p><p>Fortunately, this number is far more pessimistic than the behavior typical programs exhibit. Table <ref type="table" target="#tab_6">2</ref> shows that for our benchmarks, the total number of lock records allocated is very small, and pales in comparison with the total number of objects allocated. Moreover, at 24 bytes per lock record, even the worst program seen, the volano server, consumes 77 Kbytes for lock records, a trivial amount compared with the several Mbytes used for objects and thread stacks.</p><p>Cost of unused synchronization capability: the costfor objects that are never synchronized upon. This cost, in our meta-lock scheme, amounts to two bits per object. However, an alternative view is that the cost is either 0 or 1 word, since it is impractical to have objects of fractional word sizes on contemporary hardware. Put differently, if two spare bits can be found in objects without increasing object sizes, our locking algorithm has no space cost for objects that are not synchronized upon. Otherwise, if finding two bits requires increasing the size of objects by a full word, then a different synchronization algorithm that takes advantage of a full word of memory should (probably) be used. Thus, it can be argued, our algorithm has no space overhead for objects that are not synchronized upon. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Time performance</head><p>We study time performance of our algorithm in several ways. First, Section 6.3.1 compares the cost of synchronization in our system with that of the original JVM found in the "JDK 1.2 Reference Release for SolarisTM." For this section, as explained below, we use synthetic benchmarks. Second, Section 6.3.2 studies the behavior of our algorithm on the more realistic programs shown in Table <ref type="table" target="#tab_5">1</ref>, paying special attention to contention and the efficacy of the "extra-fast" optimization. Finally Section 6.3.3 compares the cost of uncontended locking in realistic programs on several VMs. We do not compare the absolute performance of the JVMs since they differ in many other respects than the synchronization code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Time performance comparison with the original JVM</head><p>In this section we compare the speed of our synchronization algorithm, using the extra fast extension, with that of the monitor cache approach in the original JVM. To measure the speed of synchronization rather than the speed of context switching provided by the underlying operating system, we use programs that primarily do 0 I m ' ' ""'I ' ' ' ""'I ' n """I a ' """I ' ' '-+ uncontended synchronization. Section 6.3.2 shows that contention is relatively infrequent for typical Java-based programs, justifying this approach, at least in part.</p><p>Ideally, we would compare different synchronization algorithms directly by implementing them as alternatives in the same virtual machine. In our case, however, this approach was impractical. First, the implementation effort is non-trivial. Second, an algorithm added quickly to a JVM for the purpose of measuring will be at an inherent disadvantage compared with an algorithm that has been tuned with the rest of the system over a long period. Third, it may be technically impossible to keep all other factors constant, since each algorithm may take advantage of features that the other one does not use (e.g., the monitor cache works best in the presence of handles). Since E.G.C.JVM and the original JVM differ in many respects, comparing bottom-line performance does not reveal much about the two systems' synchronization code. Fortunately, a different measurement approach can give us the information we want. Consider a program P -that performs synchronization. Construct the baseline program P , which is just like P , except that all synchronization has been stripped out. Be difference in execution time, sync(P) = time(P) -time(P) , reflects the cost of synchronization. Computing sync(P) for E.G.C.JVM and the original JVM gives numbers that can be compared. The rest of this section takes this approach with simple synthetic benchmarks. Section 6.3.3 takes this approach with more realistic programs.</p><p>To this end, we constructed a set of simple benchmarks: Sync-Method calls a synchronized method; SyncStmt executes a synchronized statement; RecSyncMethod calls two nested synchronized methods on an object; and RecSyncStmf executes a pair of nested synchronized statements on an object. The first two benchmarks measure the cost of a non-recursive lock/unlock pair, and the second two measure the sum of the costs of a non-recursive and recursive lock/unlock pair. Each benchmark completes 10 million iterations, cycling through an array of length N to select the objects to synchronize on. We let N range from 1 to 5 12K and plot the cost per iteration; see Figure <ref type="figure" target="#fig_6">9</ref>. As one would expect, the metalocking scheme delivers unchanged performance regardless of the number of objects synchronized upon whereas the monitor cache approach suffers an increasing slowdown, despite the fact that in all of these tests, no more than one object is locked at any time. The graph also shows that the absolute cost of a synchronization operation in E.G.C.JVM is always significantly lower than in the original JVM. For example, a non-recursive synchronized method call, the most frequent form of synchronization, executes in about 220 ns on E.G.C.JVM but takes 550 ns to 1500 ns on the original JVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Behavior of our algorithm on realistic programs</head><p>Consider now the algorithm's behavior on realistic programs. We first study the "pure" form of the meta-lock algorithm, without extra fast locking and unlocking. In this case, each monitor-level synchronization operation involves a getMetaLock ( ) and releaseMetaLock0 call.Theleft half ofTable shows that the fast path is taken in all but an extremely small fraction of the cases; that is, meta-lock contention is extremely rare. We instrumented only meta-lock acquisition, since the algorithm is such that the numberoffast/slow getMetaLock0 calls equals the number of fast/slow releaseMetaLock ( 1 calls.</p><p>Having confirmed that the meta-locking fast paths dominate, let us study those fast paths on a typical RISC processor. Figure <ref type="figure">10</ref> shows fhe SPARC instructions that result from translating a synchronization operation of the form: multiUseWord = getMetaLock(ee, obj); newMultiUseWord = bodyOfSyncOp(ee, obj, multiUseWord); releaseMetaLock(ee, obj. newMultiUseWord);</p><p>On entry, we assume that register %iO holds the address of the execution environment ee and 3 i 1 holds the address of an object ob j . It takes seven instructions to perform the fast path ge tMe t -aLock{ 1, including extracting the high 30 bits of the multi-use word into one register and the low 2 bits (the lock state) into another. The code for the body of the synchronization operation would follow. At the end, we have 4 instructions for the fast path of releaseMetaLock( ) . This gives us a total of 11 instructions for the fast paths of meta-lock acquisition and release. While a careful analysis of the cycles consumed by an optimal implementation is interesting in the context of a particular architecture, for the present purposes we shall be satisfied with considering the SPARC  <ref type="table" target="#tab_7">3</ref> shows that the speedup results from a significant reduction in the number of meta-locking operations, confirming that monitor-lock contention is indeed rare. However, Table <ref type="table" target="#tab_7">3</ref> also shows that, for some programs, the fall-back case is sufficiently frequent that its performance cannot be neglected. Finally, the similar number of slow meta-lock operations in the left and right halves of Table <ref type="table" target="#tab_7">3</ref> implies that extra fast synchronization does not reduce contention on the meta-lock. (For completeness, we should mention that a few of the meta-lock operations that remain when using extra fast synchronization result from layers in the JVM, such as class loading and JNI, that do not use the extra fast operations.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Comparison with other implementations</head><p>To provide an unsynchronized baseline for realistic programs, we implemented a tool that removes all synchronization operations from class files: the bits that declare methods synchronized are reset, and monitorenter/monitorexit operations are changed into pops. For programs that are essentially-single threaded, such as most of the SpecJVM98 benchmarks, the resulting program still works correctly. A few classes must be excepted from this desynchronization process, including classes involved with finalizer and weak reference handling, and j ava . lang . Thread. However, measurements indicate that almost all locking operations are eliminated: in executions that perform more than one million locking operations, less than 0.1% of the original are executed after desynchronization.</p><p>Given this tool, we can measure the absolute decrease in execution time caused by executing the desynchronized class files instead of the original class files, independent of Java platform. As in Section 6.3.1, this decrease represents the cost of locking for that execution. There were four SpecJVM benchmarks that both did at least one million locking operations and still worked correctly after desynchronization. Table <ref type="table" target="#tab_9">4</ref> compares locking costs for these benchmarks, on three different platforms: E.G.C.JVM, the Java HotSpot Performance Engine for Solaris/SPARC, and the IBM Developer Kit for Windows, Java Technology Edition, Version 1.1.7, which uses the thin-locks scheme. The first line of the figure gives the number of locking operations eliminated by desynchronization for these benchmarks. We measured this on the E.G.C.JVM, and used the same class files for the Java HotSpot/SPARC measurement. We were unable to complete direct measurements of the corresponding numbers for the 1.1.7 platform, but the measurements we did perform lead us to believe that assuming the same number of eliminated lock operations as in E.G.C.JVM is fairly accurate. The remaining lines of Table <ref type="table" target="#tab_9">4</ref> show, for each platform, the decrease in user time, in seconds, for these benchmarks, and the number of cycles per lock/unlock pair implied by the decrease and the number of eliminated locking pairs. (The latter number is shown in italics.) E.G.C.JVM and Java HotSpot/SPARC were run on a ~-CPU 360 Mhz UltraSPARC system running the Solaris OS, and the IBM system was run on a Dell PowerEdge 2200, with 4 300 MHz Pentium processors, under Microsoft Windows NT. Cycles per lock/unlock pair assumes that each processor runs at the listed clock speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I -202jess</head><p>-209-db 213Javac  The strongest conclusion that should be drawn from these measurements is probably that these virtuals machines are fairly similar in efficiency of uncontended locking. Note that the costs on uniprocessor systems could be lower, because of decreased cost of atomic memory instructions. Also, these measurements provide no information about performance in high-contention situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p>We have presented a meta-locking algorithm that supports a variety of higher-level locking protocols, by providing exclusive access to the data structures used in the higher-level protocol. This meta-locking algorithm has several virtues. Like the Java HotSpot system that introduced header word displacement, the meta-locking algorithm is highly space-efficient, requiring only two reserved bits in each object, and a number of lock records that is small for normal programs. It is also reasonably time-efficient in the normal case, requiring 7 instructions to acquire and 4 instructions to release an uncontended meta-lock. Each of those paths includes a single atomic instruction. Finally, it is careful to avoid pathologies when there is contention: the algorithm introduces no busy-waiting, and only very rarely allocates from global memory.</p><p>We have also presented a particular higher-level locking protocol, based on this meta-locking algorithm, for the synchronization primitives of the Java virtual machine. An optimization of this protocol gains the efficiency of avoiding meta-locking in most cases, but the ability to fall back to meta-locking in uncommon cases regularizes and simplifies the protocol.</p><p>Finally, we have implemented and validated the performance of the meta-lock in the context of a high-performance Java virtual machine. Our measurements, which include a study of several multi-threaded programs running on a 4-CPU system, indicate that the meta-lock algorithm operates with a low contention rate to ensure that the fast path strongly dominates the performance. Synthetic benchmarks designed to isolate the cost of synchronization indicate that our scheme outperforms the original monitor cache scheme by a factor of three or more. Measurements on desynchronized benchmarks show that the meta-lock-based monitor implementation in E.G.C.JVM has performance comparable to that of the monitor implementations in two other high-performance JVMs.</p><p>In the future, we may work on extending the extra fast instruction sequences to handle more cases while continuing to use the metalock protocol as a comfortable fall-back. For example, if measurements justify it, extra fast locking could be extended to allow a non-empty queue with lock state WAITERS. We are also investigating whether the high-level synchronization state could be made to influence the order in which threads acquire meta-locks. For example, it might improve efficiency if a thread attempting to release a monitor-Jock could be given preferential treatment at the meta-lock level.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Per-thread (execution environment) fields used for synchronization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. A lock record and how they are chained out of the multi-use word of an object.age information, so we call it the multi-use word. We employ a header word displacement technique invented by our colleague Lars Bak[5]. The two least significant bits in the multi-use word, called the lock bits, hold the lock stare, which serve as a format indicator and simultaneously encode meta-lock information for the object. Figure2also shows the four possible lock states and their formats. Objects are created in the NEUTRAL state (in fact, the majority of objects never leave this state), remain in this state as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Threads contending for a meta-lock.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Slow paths for monitor-lock operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Wait and notify code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Cost of synchronization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>.C.JVM-RecSyncStmt --I--E.G.C.JVM-RecSyncMethod ------E.G.C.JVM-SyncStmt ---. E.G.C.JVM-SyncMethod</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 .</head><label>1</label><figDesc>Characterization of benchmark programs.</figDesc><table><row><cell>1,028 1</cell><cell cols="3">4 72.11 87.9 1</cell></row><row><cell>1 25,211)</cell><cell>11</cell><cell>42.71</cell><cell>48.9)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 .</head><label>2</label><figDesc>Objects allocated, objects synchronized on, and lock records allocated.</figDesc><table><row><cell>(Benchmark</cell><cell cols="2">1 # obiects</cell><cell cols="3">I# obis svnc'ed onI # lock records 1</cell></row><row><cell>IHello</cell><cell>I</cell><cell cols="2">2.076 1</cell><cell>262 (12.6%) 1</cell><cell>401</cell></row><row><cell>-20 I -compress</cell><cell></cell><cell>8,917</cell><cell></cell><cell>936 (10.5%)</cell><cell>40</cell></row><row><cell>-202jess</cell><cell></cell><cell cols="3">7,934,141 6,545 (0.1%)</cell><cell>40</cell></row><row><cell>-209db</cell><cell></cell><cell cols="3">3,213,429 17,123 (0.5%)</cell><cell>40</cell></row><row><cell>-2 1 Sjavac</cell><cell></cell><cell cols="3">5,912,859 351.538 (5.9%)</cell><cell>40</cell></row><row><cell></cell><cell></cell><cell cols="2">12,009 1</cell><cell>994 (8.3%) 1</cell><cell>4</cell></row><row><cell>-227-mtrt</cell><cell></cell><cell>6641,320</cell><cell></cell><cell>1,195 (0.0%)</cell><cell>60</cell></row><row><cell>~-228-iack</cell><cell></cell><cell cols="3">6.841.290 506.157 (7.4%)</cell><cell>40</cell></row><row><cell>~volano client</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>IJWS</cell><cell>I</cell><cell cols="3">1,336,170) 258,960 (19%)1</cell><cell>5401</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 .</head><label>3</label><figDesc>Frequency of meta-lock contention.</figDesc><table><row><cell cols="2">! getMetaLock</cell><cell></cell><cell></cell><cell></cell></row><row><cell>or</cell><cell cols="2">%iO, 3, $10</cell><cell></cell><cell></cell><cell>! %lO = my busy value</cell></row><row><cell>add</cell><cell cols="2">%il, 4, %11</cell><cell></cell><cell></cell><cell>! $11 = multi-use</cell><cell>word address</cell></row><row><cell>swap</cell><cell>[%lll,</cell><cell>%lO</cell><cell></cell><cell></cell><cell>! swap out busy value</cell></row><row><cell>and</cell><cell cols="2">%lO, 3, %12</cell><cell></cell><cell></cell><cell>! %12 = meta-lock</cell><cell>state</cell></row><row><cell>CW</cell><cell>&amp;12, 3</cell><cell></cell><cell></cell><cell></cell><cell>! IS lock state busy?</cell></row><row><cell>beq</cell><cell cols="3">slowGetMetaLockPath</cell><cell></cell></row><row><cell>Sub</cell><cell cols="3">$10, %12, 810</cell><cell></cell><cell>! In delay slot compute high 30 bits</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>! Slow path gets predecessor</cell><cell>EE in $10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>! and synch operation</cell><cell>gets lock</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>! record pointer</cell><cell>or age&amp;hash in %lO</cell></row><row><cell cols="5">. . . %12 = body of synchronization</cell><cell>operation</cell></row><row><cell cols="2">! releaseMetaLock</cell><cell></cell><cell></cell><cell></cell></row><row><cell>or</cell><cell cols="2">%iO, 3, %lO</cell><cell></cell><cell></cell><cell>! $10 = my busy value</cell></row><row><cell>css</cell><cell>[%ll],</cell><cell cols="2">$10, %12</cell><cell></cell><cell>! if [%ll]</cell><cell>== 810 then swap([810],%12j</cell></row><row><cell>cm</cell><cell cols="2">$10, %12</cell><cell></cell><cell></cell><cell>! did we do the swap?</cell></row><row><cell>bne</cell><cell cols="3">slowReleaseMetaLockPath</cell><cell></cell></row><row><cell>! unfilled</cell><cell cols="3">delay slot here</cell><cell></cell></row><row><cell></cell><cell cols="5">Fig. 10. Fast path for a synchronization operation wrapped in meta-lock and unlock.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>I</cell><cell cols="2">without extra fast</cell><cell>I</cell><cell>with extra fast</cell><cell>I</cell></row><row><cell cols="3">IBenchmark Hello</cell><cell cols="3">1 # getMetaL,ock 1 #getMetaLockSlow 1 # getMetaLock 1 #getMetaLockSlow 1 I -I -I -I -J 3,054 0 1,418 0</cell></row><row><cell></cell><cell cols="2">-2Ol-compress</cell><cell></cell><cell></cell><cell>22,180</cell><cell>3</cell><cell>2,269</cell><cell>2</cell></row><row><cell></cell><cell>-202jess</cell><cell></cell><cell></cell><cell cols="2">9,619,742</cell><cell>19</cell><cell>4,171</cell><cell>10</cell></row><row><cell></cell><cell>-209-db</cell><cell></cell><cell cols="3">106,829,540</cell><cell>1</cell><cell>2,024</cell><cell>5</cell></row><row><cell></cell><cell>-2 13javac</cell><cell></cell><cell></cell><cell cols="2">34,380,756</cell><cell>50</cell><cell>39,949</cell><cell>61</cell></row><row><cell></cell><cell cols="2">-222-mpegaudio</cell><cell></cell><cell></cell><cell>22,813</cell><cell>10</cell><cell>2,620</cell><cell>5</cell></row><row><cell></cell><cell>-227-mtrt</cell><cell></cell><cell></cell><cell cols="2">1,424,925</cell><cell>1</cell><cell>2,397</cell><cell>3</cell></row><row><cell></cell><cell>-228jack</cell><cell></cell><cell></cell><cell cols="2">23.851.6001</cell><cell>8</cell><cell>2,979</cell><cell>5</cell></row><row><cell></cell><cell cols="2">-224~richards</cell><cell></cell><cell></cell><cell>70,560 f</cell><cell>59</cell><cell>3,434 I</cell><cell>52</cell></row><row><cell></cell><cell>-233tmix</cell><cell></cell><cell></cell><cell cols="2">8,711,428</cell><cell>1,612</cell><cell>2,183,531</cell><cell>1,730</cell></row><row><cell></cell><cell cols="2">SwingMark</cell><cell></cell><cell cols="2">4,062,787</cell><cell>2,508</cell><cell>465,758</cell><cell>1,977</cell></row><row><cell></cell><cell cols="2">volano server</cell><cell></cell><cell cols="2">9,622,570</cell><cell>587</cell><cell>209,341</cell><cell>542</cell></row><row><cell></cell><cell cols="2">volano client</cell><cell></cell><cell cols="2">9,495,680</cell><cell>6</cell><cell>17,625</cell><cell>3</cell></row><row><cell></cell><cell>JWS</cell><cell></cell><cell></cell><cell cols="2">1,783,691</cell><cell>7,800</cell><cell>162,586</cell><cell>2,743</cell></row></table><note><p><p><p><p>implementation representative of a typical RISC implementation. The most costly instructions are the two atomic instructions, swap in getMetaLock ( ) , and css in releaseMetaLock ( 1.</p>Now consider the performance of the system with extra fast synchronization enabled. Recall that this optimization fuses metalocking and monitor-locking to allow monitor-lock acquisition and release each with a single atomic instruction in uncontended cases, but in contended cases falls back to the meta-lock protocol for a total cost of three atomic instructions. If monitor-lock contention is rare, as Bacon et d's data indicate [4], this will be a net win; otherwise, it could be a loss. Table</p>1</p>shows the bottom line on extra fast synchronization for our benchmarks: no program slows down, and several speed up significantly. Comparing the left and right halves of Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 .</head><label>4</label><figDesc>Comparison of uncontended locking costs on 3 platforms.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Objects. Figure2shows the object layout in our JVM. Because every object may potentially be used for synchronization, it is critical to minimize the per-object space overhead. Objects have twoword headers. The first word points to the object's class. Only the second word is used for synchronization, but it serves other purposes as well, such as holding a hash code* and garbage-collector 2. E.G.C.JVM uses a handle-less copying memory system, so object or handle addresses cannot be used as hash codes.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. Lam Bak, David Dice, David Holmes, Urs Hblzle, Doug Lea, and Hong Zhang provided very useful comments on a draft of the paper. Bill Joy advised us of interesting related work. The anonymous reviewers suggested substantial improvements to the paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Code for Meta-locking</head><p>The C code for fast-path and slow-paths for meta-locking is included for reference.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">An Eflcient Meta-Lock for Implementing Ubiquitous Synchronization</title>
		<author>
			<persName><forename type="first">Ole</forename><surname>Agesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Detlefs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Garthwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Knippel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ramnkrishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>White</surname></persName>
		</author>
		<idno>99-76</idno>
		<ptr target="http://www.sunlabs.com/technical-reports/l999/" />
		<imprint/>
		<respStmt>
			<orgName>Sun Labs</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems, l(l)</title>
		<imprint>
			<biblScope unit="page" from="6" to="16" />
			<date type="published" when="1990-01">January 1990. 1996</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
	<note>Ken Arnold and James Gosling. The Java Programming Language</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lars Bak, presentation on the HotSpot JVM, Panel: The New Crop Of Java Virtual Machines</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">F</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Konuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chet</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><surname>Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SlGPLAN &apos;98 Conference on Object-Oriented Programming Systems, Languages, and Applications</title>
		<meeting>ACM SlGPLAN &apos;98 Conference on Object-Oriented Programming Systems, Languages, and Applications<address><addrLine>Montreal, Canada; Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Andrew Birrell</publisher>
			<date type="published" when="1989">June 1998. October 1998. 1989</date>
			<biblScope unit="page" from="179" to="182" />
		</imprint>
	</monogr>
	<note>Proc. ACM SIGPLAN &apos;98 Conference on Programming Language Design and Implementation (PLDZ). An introduction to Programming with Threads. Digital Systems Research Center report no. 35</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Programming with POSIX@ Threads</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Butenhof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Addison-Wesley Professional Computing Series</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sylvia Dieckmann and Urs Holzle. A Study ofthe Allocation Behavior of the SPECjvm98 Java Benchmarks</title>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Buhr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Fortier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">H</forename><surname>Coffin</surname></persName>
		</author>
		<idno>TRCS98-33</idno>
	</analytic>
	<monogr>
		<title level="j">Monitor Classification. ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="63" to="107" />
			<date type="published" when="1995-03">March 1995. December 1998</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of California, Santa Barbara</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Solution of a Problem in Concurrent Programming Control</title>
		<author>
			<persName><forename type="first">Edsgar</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">569</biblScope>
			<date type="published" when="1965-08">August 1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Synergy Between Non-blocking Synchronization and Operating System Structure</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cireenwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cheriton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Symposium on Operating Systems Design and Implementation (OSDI &apos;96)</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-10">October 1996</date>
			<biblScope unit="page" from="123" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Monitors and Concurrent Pascal: a personal history</title>
		<author>
			<persName><forename type="first">Brinch</forename><surname>Per</surname></persName>
		</author>
		<author>
			<persName><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second ACM SIGPLAN Conference on History of Programming Languages</title>
		<meeting>the Second ACM SIGPLAN Conference on History of Programming Languages</meeting>
		<imprint>
			<date type="published" when="1993-03">March 1993</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
	<note>Published as</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Java&apos;s Insecure Parallelism</title>
		<author>
			<persName><forename type="first">Brinch</forename><surname>Per</surname></persName>
		</author>
		<author>
			<persName><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SZGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="38" to="45" />
			<date type="published" when="1999-04">April 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Monitors: An Operating System Structuring Concept</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A R</forename><surname>Hoare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="549" to="557" />
			<date type="published" when="1974-10">October 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">System and method for space efficient object locking using global and local locks</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">N</forename><surname>Joy</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">670</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">System and method for space and time efficient object locking</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">N</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">L</forename><surname>Steele</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">862</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">System and method for space efficient object locking using a data subarray and pointers</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">N</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Van Hoff</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">701</biblScope>
			<biblScope unit="page">470</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient JavaVM Just-in-Time Compilation</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Krall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Parallel Architectures and Compilation Techniques (PACT&apos;981</title>
		<meeting>International Conference on Parallel Architectures and Compilation Techniques (PACT&apos;981<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-10">October 1998</date>
			<biblScope unit="page" from="12" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Monitors and Exceptions: How to implement Java efficiently</title>
		<author>
			<persName><forename type="first">Andreas Iq-All</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Probst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM 1998 Workshop on Java for High-Perjormance Computing</title>
		<meeting><address><addrLine>Palo Alto, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-03">March 1998</date>
			<biblScope unit="page" from="15" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Fast Mutual Exclusion Algorithm</title>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Lamport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing System 5(I), p. l-l 1</title>
		<imprint>
			<date type="published" when="1987-02">February 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Leroy</surname></persName>
		</author>
		<ptr target="http://pauil-lac.inria.fr/-xleroy/linuxthreads/index.html" />
		<title level="m">The LinuxThreads library</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Java Virtual Machine Spec@cation</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Yellin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">The Java Series</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Eficient Software Synchronization on Large Cache Coherent Multiprocessors</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Landin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SICS Research Report T</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page">28</biblScope>
			<pubPlace>Box</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Swedish Institute of Computer Science</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Sweden</forename><surname>I&amp;a</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-02">February 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">L</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="21" to="65" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Harissa: A Flexible and Efficient Java Environment Mixing Bytecode and Compiled Code</title>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrice</forename><surname>Bellard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Consel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 3rd Conference on Object-Oriented Technologies and Systems (COOTS)</title>
		<meeting>of the 3rd Conference on Object-Oriented Technologies and Systems (COOTS)<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">John</forename><surname>Neffinger</surname></persName>
		</author>
		<ptr target="http://www.javaworld.comljava-worltijw-0%1998/jw-08-volanomark.html" />
		<title level="m">Which Java VM scales best? Java-World</title>
		<imprint>
			<date type="published" when="1998-08">August 1998</date>
		</imprint>
	</monogr>
	<note>See also www.volano.com</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">A</forename><surname>Proebsting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregg</forename><surname>Townsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Bridges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">H</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Newsham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">A</forename><surname>Watterson</surname></persName>
		</author>
		<author>
			<persName><surname>Toba</surname></persName>
		</author>
		<title level="m">Java For Applications-A Way Ahead of Time (WAT) Compiler</title>
		<meeting><address><addrLine>Tucson</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, University of Arizona</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effective Code Generation in a Just-In-Time Java Compiler</title>
		<author>
			<persName><forename type="first">Ah-Reza</forename><surname>Adl-Tabatabai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Ciemiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guei-Yuan</forename><surname>Lueh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vishesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Parakh</surname></persName>
		</author>
		<author>
			<persName><surname>Stichnoth</surname></persName>
		</author>
		<author>
			<persName><surname>Fast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SZGPLAN &apos;98 Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>ACM SZGPLAN &apos;98 Conference on Programming Language Design and Implementation (PLDI)<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="280" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<ptr target="http://www.spec.org/osgljvm98" />
		<title level="m">SPECjvm98 Benchmarks</title>
		<imprint>
			<date type="published" when="1998-08-19">August 19. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Inc. Java 2 on-line documentation: http:fljava.sun.comlproductsljdW1.2Jdocsiapil index</title>
		<imprint/>
		<respStmt>
			<orgName>Sun Microsystems</orgName>
		</respStmt>
	</monogr>
	<note>html</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Hong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lam</forename><surname>Bak</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Personal communication of draft paper: An Efficient Monitor Scheme for the JavarM Virtual Machine</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">All SPARC trademarks are used under license, and are trademarks or registered trademarks of SPARC International, Inc. in the United States and other countries. Products bearing SPARC trademarks are based on an architecture developed by Sun Microsystems</title>
		<author>
			<persName><forename type="first">Sun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Microsystems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jdk</forename><surname>Java</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Java</forename><surname>Hotspot</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Solaris are trademarks or registered trademarks of Sun Microsystems, Inc. in the United States and other countries</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
