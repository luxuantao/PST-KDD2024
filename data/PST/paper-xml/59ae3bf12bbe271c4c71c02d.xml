<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learned Primal-dual Reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jonas</forename><surname>Adler</surname></persName>
							<email>jonasadl@kth.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">KTH -Royal Institute of Technology † Elekta AB</orgName>
								<address>
									<postBox>Box 7593</postBox>
									<postCode>SE-103 93</postCode>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ozan</forename><surname>Öktem</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">KTH -Royal Institute of Technology † Elekta AB</orgName>
								<address>
									<postBox>Box 7593</postBox>
									<postCode>SE-103 93</postCode>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learned Primal-dual Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EBB76792ADDBEAF0664E38301B835C78</idno>
					<idno type="DOI">10.1109/TMI.2018.2799231</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TMI.2018.2799231, IEEE Transactions on Medical Imaging</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Inverse problems</term>
					<term>Tomography</term>
					<term>Deep learning</term>
					<term>Primal-Dual</term>
					<term>Optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose the Learned Primal-Dual algorithm for tomographic reconstruction. The algorithm accounts for a (possibly non-linear) forward operator in a deep neural network by unrolling a proximal primal-dual optimization method, but where the proximal operators have been replaced with convolutional neural networks. The algorithm is trained end-to-end, working directly from raw measured data and it does not depend on any initial reconstruction such as filtered back-projection (FBP).</p><p>We compare performance of the proposed method on low dose computed tomography reconstruction against FBP, total variation (TV), and deep learning based post-processing of FBP. For the Shepp-Logan phantom we obtain &gt; 6 dB PSNR improvement against all compared methods. For human phantoms the corresponding improvement is 6.6 dB over TV and 2.2 dB over learned post-processing along with a substantial improvement in the structural similarity index. Finally, our algorithm involves only ten forward-back-projection computations, making the method feasible for time critical clinical applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In an inverse problem, the goal is to reconstruct parameters characterizing the system under investigation from indirect observations. Such problems arise in several areas of science and engineering, like tomographic imaging where one seeks to visualize the interior structure of an object (2D/3D image) from indirect observations. Imaging technologies of this type, such as computed tomography (CT) and magnetic resonance imaging (MRI) imaging, are indispensable for contemporary medical diagnostics, intervention and monitoring.</p><p>There is by now a rich theory for model driven tomographic image reconstruction. A key component is knowledge about the forward model, which describes the data formation process in absence of noise. In many applications, an explicit forward model can be derived starting out from the underlying physical principles that are utilized by the imaging modality. Another component accounts for the knowledge about the statistical properties of data and a priori information about the image to be recovered.</p><p>A parallel line of development in signal processing has been the usage of deep learning for solving a wide range of tasks that can be cast as supervised learning. The success of these data driven approaches are this far confined to tasks where knowledge about the forward model is not needed, or has little importance. As an example, an entirely data driven approach for tomographic image reconstruction applicable to clinical sized problems has yet to be demonstrated.</p><p>A central question is whether one can combine elements of model and data driven approaches for solving ill-posed inverse problems. In particular, is there a framework for incorporating the knowledge of a forward model when designing a neural network for reconstruction? The Learned Primal-Dual reconstruction method developed in this paper is such a framework. It applies to general inverse problems and it is best described in an abstract setting, so our starting point is to formalize the notion of an inverse problem.</p><p>Mathematically, an inverse problem can be formulated as reconstructing (estimating) a signal f true ∈ X from data g ∈ Y where g = T (f true ) + δg.</p><p>Here, the reconstruction space X and the data space Y are typically Hilbert Spaces, T : X → Y is the forward operator that models how a signal gives rise to data in absence of noise, and δg ∈ Y is a single sample of a Y -valued random variable that represents the noise component of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Variational regularization</head><p>A common model driven approach for solving (1) is to maximize the likelihood of the signal, or equivalently minimizing the negative data log-likelihood <ref type="bibr" target="#b0">[1]</ref>:</p><formula xml:id="formula_1">min f ∈X L T (f ), g .<label>(2)</label></formula><p>This minimization is for typical choices of T ill-posed, that is, a solution (if it exists) is unstable with respect to the data g in the sense that small changes to data results in large changes to a reconstruction. Hence, a maximum likelihood solution typically leads to over-fitting against data.</p><p>Variational regularization, also referred to as model based iterative reconstruction in medical image processing, avoids over-fitting by introducing a functional S : X → R (regularization functional) that encodes a priori information about the true (unknown) f true and penalizes unlikely solutions <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Hence, instead of minimizing only the negative data loglikelihood as in <ref type="bibr" target="#b1">(2)</ref>, one now seeks to minimize a regularized objective functional by solving</p><formula xml:id="formula_2">min f ∈X L T (f ), g + λ S(f ) for a fixed λ ≥ 0.<label>(3)</label></formula><p>In the above, λ (regularization parameter) governs the influence of the a priori knowledge encoded by the regularization functional against the need to fit data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Machine learning in inverse problems</head><p>We here review results on learned iterative schemes, see <ref type="bibr" target="#b3">[4]</ref> for a wider review on machine learning for medical imaging and <ref type="bibr" target="#b4">[5]</ref> for usage of machine learning for solving inverse problems in general.</p><p>Machine learning is widely used for non-linear function approximation under weak assumptions and has recently emerged as the state of the art for several image processing tasks such as classification and segmentation. Applied to the inverse problem in <ref type="bibr" target="#b0">(1)</ref>, it can be phrased as the problem of finding a (non-linear) mapping T † θ : Y → X satisfying the following pseudo-inverse property:</p><formula xml:id="formula_3">T † θ (g) ≈ f</formula><p>true whenever data g is related to f true as in <ref type="bibr" target="#b0">(1)</ref>.</p><p>A key element in machine learning approaches is to parametrize the set of such pseudo-inverse operators by a parameter θ ∈ Θ where Θ is some parameter space and the main algorithmic complication is to select an appropriate structure of T † θ such that, given appropriate training, the pseudo-inverse property is satisfied as well as possible.</p><p>In the context of tomographic reconstruction, three main research directions have been proposed. The first is so called learned post-processing or learned denoisers. Here, the learned reconstruction operator is of the form</p><formula xml:id="formula_4">T † θ = Λ θ • T † where Λ θ : X → X</formula><p>is a learned post-processing operator and T † : Y → X is some approximate pseudo-inverse, e.g. given by filtered back-projection (FBP) in CT reconstruction. This type of method is relatively easy to implement, given that the pseudo-inverse can be applied off-line, before the learning is performed, which reduces the learning to inferring an X → X transformation. This has been investigated by several authors <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p><p>Another method is to learn a regularizer and use this regularizer in a classical variational reconstruction scheme according to <ref type="bibr" target="#b2">(3)</ref>. Examples of this include dictionary learning <ref type="bibr" target="#b8">[9]</ref>, but several alternative methods have been investigated, such as learning a variational auto-encoder <ref type="bibr" target="#b9">[10]</ref> or using a cascade of wavelet transforms (scattering transform) <ref type="bibr" target="#b10">[11]</ref>.</p><p>Finally, some authors investigate learning the full reconstruction operator, going all the way from data to reconstruction. Doing this in one step is typically very computationally expensive and does not scale to the data sizes encountered in tomographic reconstruction. Instead, learned iterative schemes have been studied. These schemes resemble classical optimization methods used for tomographic reconstruction but use machine learning to find the best update in each iteration given the last iterate and results of applying the forward operator and its adjoint as input.</p><p>One of the first works on learned iterative schemes is <ref type="bibr" target="#b11">[12]</ref>, which learns an ADMM-like scheme for MRI reconstruction. A further development along this lines is given in <ref type="bibr" target="#b12">[13]</ref>, which learns over a broader class of schemes instead of ADMMtype of schemes. The application is to finite dimensional inverse problems typically arising in image restoration. This approach was in <ref type="bibr" target="#b4">[5]</ref> further extended to non-linear forward operators in to the infinite dimensional setting, which also applies learned iterative schemes to (non-linear, pre-log) CT. Similar approaches for MRI reconstruction have also been considered <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Here, the situation is simpler than CT reconstruction since the forward operator is approximated by a Fourier transform, i.e. MRI reconstruction amounts to inverting the Fourier transform.</p><p>Given a structure of T † θ , the "learning" part refers to choosing an "optimal" set of parameters θ given some training data, where the concept of optimality is typically quantified through a loss functional that measures the quality of a learned pseudo-inverse T † θ . To define this loss functional, consider a (X × Y )-valued random variable (f, g) with joint probability distribution µ. This could be e.g. the probability distribution of human bodies and corresponding noisy tomographic data. We define the optimal reconstruction operator as the one whose reconstructions have the lowest average mean squared distance to the true reconstructions, where the average is taken w.r.t. µ. Finding this reconstruction operator is then given by selecting the parameters θ ∈ Θ so that the loss functional L(θ) is minimized:</p><formula xml:id="formula_5">L(θ) := E (f,g)∼µ T † θ (g) -f 2 X .<label>(4)</label></formula><p>However, in practice we often do not have access to the probability distribution µ of the random variable (f, g). Instead, we know a finite set of samples (g 1 , f 1 ), . . . , (g N , f N ). In this setting, we replace µ in (4) with its empirical counterpart, so the loss function is replaced with the empirical loss</p><formula xml:id="formula_6">L(θ) := 1 N N i=1 T † θ (g i ) -f i 2 X .<label>(5)</label></formula><p>Since our main goal is to minimize the loss functional, our practical goal is thus two-fold: we want to find a learned reconstruction scheme that minimizes the empirical loss, and we also want it to generalize to new, unseen data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CONTRIBUTION AND OVERVIEW OF PAPER</head><p>This paper proposes the Learned Primal-Dual algorithm, a general framework for solving inverse problems that combines deep learning with model based reconstruction. The proposed learned iterative reconstruction scheme involves convolutional neural networks (CNNs) in both the reconstruction and data space, and these are connected by the forward operator and its adjoint. We train the networks to minimize the mean squared error of the reconstruction and demonstrate that this achieves very high performance in CT reconstruction, surpassing recent learning based methods on both analytical and human data.</p><p>We emphasize that we learn the whole reconstruction operator, mapping data to reconstruction, and not just a postprocessing nor only the prior in isolation.</p><p>In addition, we make all of our code and learned parameters open source so that the community can reproduce the results and apply the methods to other inverse problems <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE LEARNED PRIMAL-DUAL ALGORITHM</head><p>We here introduce how primal-dual algorithms can be learned from data and how this can be used to solve inverse problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Primal-Dual optimization schemes</head><p>In imaging, the minimization in (3) is a large scale optimization problem, which traditionally has been addressed using gradient based methods such as gradient descent or its extensions to higher order derivatives, e.g. quasi-Newton or Newton methods. However, many regularizers of interest result in a non-differentiable objective functional, so gradient based methods are not applicable. A common approach to handle this difficulty is to consider a smooth approximation, which however introduces additional parameters and gives non-exact solutions.</p><p>An alternative approach is to use methods from non-smooth convex optimization. Proximal methods have been developed in order to directly work with non-smooth objective functionals. Here, a proximal step replaces the gradient step. The simplest example of such an algorithm is the proximal point algorithm for minimizing an objective functional G : X → R. It can be seen as the proximal equivalent of the gradient descent scheme and is given by</p><formula xml:id="formula_7">f i+1 = prox τ G (f i )<label>(6)</label></formula><p>where τ ∈ R + is a step size and the proximal operator is defined by</p><formula xml:id="formula_8">prox τ G (f ) = arg min f ∈X G(f ) + 1 2τ f -f 2 X<label>(7)</label></formula><p>While this algorithm could, in theory, be applied to solve (3) it is rarely used directly since <ref type="bibr" target="#b6">(7)</ref> does not have a closed form solution. Proximal primal-dual schemes offer a work around. In these schemes, an auxiliary dual variable in the range of the operator is introduced and the primal (f ∈ X) and dual variables are updated in an alternating manner.</p><p>One well known primal-dual scheme is the primal dual hybrid gradient (PDHG) algorithm <ref type="bibr" target="#b16">[17]</ref>, also known as the Chambolle-Pock algorithm, with a recent extension to nonlinear operators <ref type="bibr" target="#b17">[18]</ref>. The scheme (algorithm 1) is adapted for minimization problems with the following structure:</p><formula xml:id="formula_9">min f ∈X F K(f ) + G(f )<label>(8)</label></formula><p>where K : X → U is a (possibly non-linear) operator, U is a Hilbert space and F : U → R and G : X → R are functionals on the dual/primal spaces. Note that (3) is a special case of (8) if we set F := L( • , g), K := T and G := S.</p><p>In algorithm 1, F * denotes the Fenchel conjugate of F, h ∈ U is the dual variable and</p><formula xml:id="formula_10">[∂ K(f i )] * : U → X is the adjoint of the (Fréchet) derivative of K in point f i .</formula><p>Example: Total variation (TV) regularized CT: The PDHG method has been widely applied to CT <ref type="bibr" target="#b18">[19]</ref>. In CT, the forward operator is given by the ray-transform P : X → Y , which integrates the signal over a set of lines M given by the Algorithm 1 Non-linear primal dual hybrid gradient</p><formula xml:id="formula_11">1: Given: σ, τ &gt; 0 s.t. στ K 2 &lt; 1, γ ∈ [0, 1] and f 0 ∈ X, h 0 ∈ U . 2: for i = 1, . . . do 3: h i+1 ← prox σF * h i + σ K( fi ) 4: f i+1 ← prox τ G f i -τ [∂ K(f i )] * (h i+1 ) 5: fi+1 ← f i+1 + γ(f i+1 -f i ) acquisition geometry. Hence, elements in Y are functions on lines P(f )( ) := f (x)dx for ∈ M.</formula><p>and the adjoint of the derivative is the back-projection <ref type="bibr" target="#b19">[20]</ref>.</p><p>A typical example of variational regularization in imaging is TV regularization, which applies to signals that are represented by scalar functions of bounded variation. The corresponding regularization functional is then given as the 1-norm of the gradient magnitude, i.e. S(f</p><formula xml:id="formula_12">) := ∇f 1 , ∇ : X → X d , d is the dimension of the space.</formula><p>The PDHG method can be used to solve the TV regularized CT optimization problem</p><formula xml:id="formula_13">min f ∈X P(f ) -g 2 2 + λ ∇f 1 .</formula><p>Since the proximal of f → ∇f 1 is hard to compute, the following identification is better suited for recasting the above into (8): ) , h (2) ] := h (1) -g 2 2 + h (2)  1 and G(f ) := 0.</p><formula xml:id="formula_14">K : X → Y × X d as K(f ) := P(f ), ∇f , F [h (1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Learned PDHG</head><p>The aim is to derive a learned reconstruction scheme inspired by PDHG, algorithm 1. We follow the observation in <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, that proximal operators can be replaced by other operators that are not necessarily proximal operators. The aforementioned publications replace a proximal operator with a denoising operator such as Block Matching 3D (BM3D). Our idea is to replace the proximal operators by parametrized operators where the parameters are learned from training data, resulting in a learned reconstruction operator.</p><p>In order to make the learned reconstruction operator well defined and implementable on a computer we also need to select a stopping criterion. Choosing a proper stopping criterion is an active research area, but for simplicity and usability we use a fixed number of iterates. By selecting a fixed number of iterations, the computation budget is also fixed prior to training, which is a highly desirable property in time critical applications.</p><p>Algorithm 2 below outlines the resulting variant of the PDHG algorithm with I iterations in which the primal proximal has been replaced by a learned proximal, Γ θ d and the dual proximal by a learned proximal Λ θ p . Note that in this article we consider only a single forward model and no regularizing operator, so we have K = T , U = Y , but we give the algorithm in full generality for completeness.</p><formula xml:id="formula_15">Algorithm 2 Learned PDHG 1: Initialize f 0 ∈ X, h 0 ∈ U 2: for i = 1, . . . , I do 3: h i+1 ← Γ θ d h i + σ K( fi ), g 4: f i+1 ← Λ θ p f i -τ [∂ K(f i )] * (h i+1 ) 5: fi+1 ← f i+1 + θ(f i+1 -f i ) 6: return f (1) I</formula><p>In algorithm 2, there are several parameters that need to be selected. These are the parameters of the dual proximal, θ d , the primal proximal, θ p , the step lengths, σ, τ and the overrelaxation parameter, θ. In a learned PDHG algorithm these would all be infered, learned, from training data.</p><p>We implemented this algorithm and show its performance in the results section. While the performance was comparable to traditional methods, it did not improve upon the state of the art in deep learning based image reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learned Primal-Dual</head><p>To gain substantial improvements, guided by recent advances in machine learning, the following modifications to the learned PDHG algorithm were done.</p><p>• Following <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b4">[5]</ref>, extend the primal space to allow the algorithm some "memory" between the iterations.</p><formula xml:id="formula_16">f = [f (1) , f (2) , . . . , f (Nprimal) ] ∈ X Nprimal</formula><p>Similarly extend the dual space U to U Ndual . • Instead of explicitly enforcing updates of the form h i + σ K fi , allow the network to learn how to combine the previous update with the result of the operator evaluation. • Instead of hard-coding the over-relaxation fi+1 ← f i+1 + θ(f i+1 -f i ), let the network freely learn in what point the forward operator should be evaluated. • Instead of using the same learned proximal operators in each iteration allow them to differ. This increases the size of the parameter space but it also notably improves reconstruction quality. The above modifications result in a new algorithm, henceforth called the Learned Primal-Dual algorithm, that is outlined in algorithm 3.</p><formula xml:id="formula_17">Algorithm 3 Learned Primal-Dual 1: Initialize f 0 ∈ X Nprimal , h 0 ∈ U Ndual 2: for i = 1, . . . , I do 3: h i ← Γ θ d i h i-1 , K(f<label>(2)</label></formula><p>i-1 ), g 4:</p><formula xml:id="formula_18">f i ← Λ θ p i f i-1 , [∂K(f<label>(1)</label></formula><p>i-1 )] * (h</p><p>i ) 5: return f (1) I 1) Choice of starting point: In theory, the Learned Primal-Dual algorithm can be used with any choice of starting points f 0 and h 0 . The most simple starting point, both from a conceptual and computational perspective, is zero-initialization</p><formula xml:id="formula_20">f 0 = [0, 0, . . . , 0] h 0 = [0, 0, . . . , 0] (<label>9</label></formula><formula xml:id="formula_21">)</formula><p>where 0 is the zero element in the primal or dual space.</p><p>In cases where a good starting guess is available, it would make sense to use it. One such option is to assume that there exists a pseudo-inverse T † , e.g. FBP for CT. For the dual variable, the data g enters into each iterate so there is no need for a good initial guess. This gives the starting point</p><formula xml:id="formula_22">f 0 = [T † (g), T † (g), . . . , T † (g)] h 0 = [0, 0, . . . , 0]<label>(10)</label></formula><p>In our tests we found that providing the Learned Primal-Dual algorithm with such an initial guess marginally decreased training time, but did not give better final results. Given that using the pseudo-inverse T † adds more complexity by making the learned reconstruction operator depend on an earlier reconstruction, we report values only from zero-initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Connection to variational regularization</head><p>We note that by selecting N primal = 2 and N dual = 1 the Learned Primal-Dual algorithm naturally reduces to the classical PDHG algorithm by making the following choices: (1) .</p><formula xml:id="formula_23">Γ θ d i h, K(f (2) ), g = prox σF * g h + σ K(f (2) ) Λ θ p i f (1) f (2) , [∂K(f (1) )] * (h) = prox τ G f (1) -τ [∂K(f (1) )] * (h) (1 + θ) prox τ G f (1) -τ [∂K(f (1) )] * (h) -θf</formula><p>Even if the learned proximal operators do not have explicit access to the proximals, the universal approximation property of neural networks <ref type="bibr" target="#b22">[23]</ref> guarantees that given sufficient training data these equalities can be approximated arbitrarily well.</p><p>A wide range of other optimization schemes can also be seen as special cases of the Learned Primal-Dual algorithm. For example, the gradient descent algorithm with step-length α for solving <ref type="bibr" target="#b7">(8)</ref> is given by</p><formula xml:id="formula_24">f i+1 = f i -α [∂K(f i )] * [∇F](K(f i )) + [∇G](f i )</formula><p>and can be obtained by selecting</p><formula xml:id="formula_25">Γ θ d i h, K(f (2) ), g = [∇F g ](K(f (2) )) Λ θ p i f (1) f (2) , [∂K(f (1) )] * (h) = f (1) -α [∇G](f (1) ) + [∂K(f (1) )] * (h) f (1) -α [∇G](f (1) ) + [∂K(f (1) )] * (h) .</formula><p>More advanced gradient based methods such as Limited memory BFGS are likewise sub-cases obtained by appropriate choices of learned proximal operators. In summary, the Learned Primal-Dual algorithm contains a wide range of optimization schemes as special cases. If the parameters are appropriately selected, then the proposed algorithm should always perform at least as well as current variational regularization schemes given the same stopping criteria, which here is a fixed number of iterates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMPLEMENTATION AND EVALUATION</head><p>We evaluate the algorithm on two low dose CT problems. One simplified using analytical phantoms based on ellipses and one with a more realistic forward model and human phantoms. We briefly describe these test cases and how we implemented the Learned Primal-Dual algorithm. We also describe the methods we compare against.</p><p>A. Test cases a) Ellipse phantoms: This problem is identical to <ref type="bibr" target="#b4">[5]</ref> and we restate it briefly. Training data is randomly generated ellipses on a 128 × 128 pixel domain. The forward operator is the ray transform and hence T = P.</p><p>The projection geometry was a sparse 30 view parallel beam geometry with 182 detector pixels. 5% additive Gaussian noise was added to the projections. Since the forward operator is linear, the adjoint of the derivative is simply the adjoint, which for the ray transform is the back-projection</p><formula xml:id="formula_26">[∂ T (f )] * = P * .</formula><p>b) Human phantoms: In order to evaluate the algorithm on a clinically realistic use-case we consider reconstruction of simulated data from human abdomen CT scans as provided by Mayo Clinic for the AAPM Low Dose CT Grand Challengfe <ref type="bibr" target="#b23">[24]</ref>. The data includes full dose CT scans from 10 patients, of which we used 9 for training and 1 for evaluation. We used the 3 mm slice thickness reconstructions, resulting in 2168 training images, each 512 × 512 pixel in size. Thus, given that we minimize the pointwise error, the total number of datapoints is 512 2 × 2168 ≈ 5 × 10 8 .</p><p>We used a two-dimensional fan-beam geometry with 1000 angles, 1000 pixels, source to axis distance 500 mm and axis to detector distance 500 mm. In this setting, we consider the more physically correct non-linear forward model given by Beer-Lamberts law</p><formula xml:id="formula_27">T (f )( ) = e -µ P(f )( )</formula><p>where the unit of f is g/cm 3 and µ is the mass attenuation coefficient, in this work selected to 0.2 cm 2 /g which is approximately the value in water at x-ray energies. We used Poisson noise corresponding to 10 4 incident photons per pixel before attenuation, which would correspond to a low dose CT scan. We find the action of the adjoint of the derivative by straightforward computation</p><formula xml:id="formula_28">[∂ T (f )] * (g) = -µ P * e -µ P(f )( • ) g( • ) for g ∈ Y .</formula><p>The forward model can also be linearised by applying -log( • )/µ to both the data and forward operator, which then simply becomes the ray-transform as for the ellipse data. We implemented both the pre-log (non-linear) and post-log (linear) forward models and compare their results.</p><p>For validation of the ellipse data case, we simply use the (modified) Shepp-Logan phantom and for the human phantom data we use one held out set of patient data. See 1 for examples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation</head><p>The methods described above were implemented in Python using Operator Discretization Library (ODL) <ref type="bibr" target="#b24">[25]</ref> and Ten-sorFlow <ref type="bibr" target="#b25">[26]</ref>. All operator-related components, such as the forward operator T , were implemented in ODL, and these were then converted into TensorFlow layers using the as_tensorflow_layer functionality of ODL. The neural network layers and training were implemented using Tensor-Flow. The implementation utilizes abstract ODL structures for representing functional analytic notions and is therefore generic and easily adaptable to other inverse problems. In particular, the code can be easily adapted to other imaging modalities.</p><p>We used the ODL operator RayTransform in order to evaluate the ray transform and its adjoint using the GPU accelerated 'astra_gpu' backend <ref type="bibr" target="#b26">[27]</ref>.</p><p>1) Deep neural network and training details: Given the general Learned Primal-Dual scheme in algorithm 3, a parametrization of the learned proximal operators is needed in order to proceed. In many inverse problems, and particularly in CT and MRI reconstruction, most of the useful properties for both the forward operator and prior are approximately translation invariant. For this reason the resulting reconstruction operator should be approximately translation invariant, which indicates that CNNs are suitable for parametrizing the aforementioned reconstruction operator.</p><p>We used learned proximal operators of the form</p><formula xml:id="formula_29">Id + W w3,b3 • A c2 • W w2,b2 • A c1 • W w1,b1</formula><p>where Id is the identity operator that makes the network a residual network. There are two main reasons for choosing such a structure. First, proximal operators (as the name implies) are typically close to the identity and second, there is rich evidence in the machine learning literature <ref type="bibr" target="#b27">[28]</ref> that networks of this type are easier to train. Heuristically this is because each update does not need to learn the whole update, but only a small offset from the identity. Additionally, we used affine operators W wj ,bj parametrized by weights w j and biases b j . The affine operators are defined in terms of so called convolution operators (here given on the primal space, but equivalently on the dual space). These are given as affine combinations of regular convolutions, more specifically:</p><p>W wj ,bj :</p><formula xml:id="formula_30">X n → X m</formula><p>where the k:th component is given by</p><formula xml:id="formula_31">W wj ,bj ([f (1) , . . . , f (n) ]) (k) = b (k) j + n l=1 w (l,k) j * f (l)</formula><p>where b j ∈ R m and w j ∈ X n×m . The non-linearities were chosen to be Parametric Rectified Linear Units (PReLU) functions</p><formula xml:id="formula_32">A cj (x) = x if x ≥ 0 -c j x else.</formula><p>This type of non-linearity has proven successful in other applications such as classification <ref type="bibr" target="#b28">[29]</ref>.</p><p>We let the number of data that persists between the iterates be N primal = N dual = 5. The convolutions were all 3 × 3 pixel size, and the number of channels was, for each primal learned proximal, 6 → 32 → 32 → 5, and for the duals 7 → 32 → 32 → 5 where the higher number of inputs is due to the data g being supplied to the dual proximals.</p><p>We let the number of unrolled iterations be I = 10, that is the operator T and the adjoint of its derivative [∂ T (f</p><formula xml:id="formula_33">(1)</formula><p>i )] * are both evaluated 10 times by the network. Since each iterate involves two 3-layer networks, one for each proximal, the total depth of the network is 60 convolutional layers and the total number of parameters approximately 2.4 • 10 5 . In the context of deep learning, this is a deep network but with a small number of parameters. The network is visualized in fig. <ref type="figure">2</ref>.</p><p>We used the Xavier initialization scheme <ref type="bibr" target="#b29">[30]</ref> for the convolution parameters, and initialized all biases to zero.</p><p>We trained the network by minimizing the empirical loss (5) using training data as explained above using the ADAM optimizer in TensorFlow <ref type="bibr" target="#b30">[31]</ref>. We used 10 5 batches on each problem and used a learning rate schedule according to cosine annealing <ref type="bibr" target="#b31">[32]</ref>, i.e. the learning rate in step t was</p><formula xml:id="formula_34">η t = η 0 2 1 + cos π t t max</formula><p>where the initial learning rate η 0 was set to 10 -3 . We also let the parameter β 2 of the ADAM optimizer to 0.99 and let all other parameters use the default choices. We performed global gradient norm clipping <ref type="bibr" target="#b32">[33]</ref>, limiting the gradient norms to 1 in order to improve training stability and used a batch size of 5 for the ellipse data and 1 for the human phantoms.</p><p>We did not use any regularization of the learned parameters, nor did we utilize any tricks such as dropout or batch normalization. Neither did we perform any data augmentation.</p><p>The training was done using a single GTX 1080 TI GPU and took about 11 hours for the ellipse data and 40 hours for the human phantoms.</p><p>2) Incorporating the forward operator in neural networks: In order to minimize the loss function (4), stochastic gradient descent (SGD) type methods are typically used and these require (an estimate of) the gradient of the loss function</p><formula xml:id="formula_35">[∇L](θ) = E (f,g)∼µ 2[∂ θ T † θ (g)] * T † θ (g) -f , where [∂ θ T † θ (g)] *</formula><p>is the adjoint of the derivative (with respect to θ) of the learned reconstruction operator applied in g, often called gradient in the machine learning literature. This introduces a challenge since it will depends on each component of the neural network, including the learned proximal operators but also the forward operator T and the backward operator [∂T (f )] * , propagated through all I iterations.</p><p>To solve this, we used the built in automatic differentiation functionality of TensorFlow which uses the chain rule (backpropagation). This in turn requires the adjoints of the derivatives of each individual component which for the proximals were computed by TensorFlow and for the operators by ODL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison</head><p>We compare the algorithm to several widely used algorithms, including standard FBP and (isotropic) TV regularized reconstruction. We also compare against several learned schemes. These are briefly summarize here, see the references for full descriptions.</p><p>The FBP reconstructions were done with a Hann filter and used the method fbp_op in ODL. The TV reconstruction was performed using 1000 iterations of the classical PDHG algorithm, implemented in ODL as pdhg. The filter bandwith in the FBP reconstruction and the regularization parameter in the TV reconstruction were selected in order to maximize the peak signal to noise ratio (PSNR).</p><p>The partially Learned Gradient method in <ref type="bibr" target="#b4">[5]</ref> is similar to the algorithm proposed in this article, but differs in that instead of learning proximal operators it learns a gradient operator and the forward operator enters into the neural network through the gradient of the data likelihood. Publicly available code and parameters <ref type="bibr" target="#b33">[34]</ref> were used.</p><p>The next comparison is against a deep learning based approach for post-processing based on a so called U-Net <ref type="bibr" target="#b34">[35]</ref>. Fig. <ref type="figure">2</ref>: Network architecture used to solve the tomography problem. The dual iterates are given in blue boxes, while the primal iterates are in the red boxes. The blue/red boxes all have the same architecture, which is illustrated in the corresponding large boxes. Several arrows pointing to one box indicates concatenation. The initial guesses enter from the left, while the data is supplied to the dual iterates. In the classical PDHG algorithm, the primal iterates would instead of a CNN be given by prox τ G with over-relaxation, and the dual iterates would be given by prox σF * .</p><p>The U-Net was first proposed for image segmentation, but by changing the number of output channels to one, it can also be used for post-processing as was done in <ref type="bibr" target="#b6">[7]</ref>. Here an initial reconstruction is first performed using FBP and a neural network is trained on pairs of noisy FBP images and noiseless/low noise ground truth images, learning a mapping between them. We re-implemented the algorithm from <ref type="bibr" target="#b6">[7]</ref> but found that using the training procedure as stated in the paper gave sub-optimal results. We hence report values from using the same training scheme as for our other algorithms in order to give a more fair comparison.</p><p>Additionally, our comparison includes learned PDHG, algorithm 2, as well as the following two simplified versions of the Learned Primal-Dual algorithm. The first is a Learned Primal algorithm, which does not learn any parameters for the dual proximal, instead it returns the residual</p><formula xml:id="formula_36">Γ θ d i h i-1 , T (f<label>(2)</label></formula><p>i-1 ), g = T (f</p><p>i-1 ) -g The second, FBP + residual denoising algorithm, further simplifies the problem by discarding the forward operator completely, and can be seen as selecting</p><formula xml:id="formula_38">Λ θ p i f i-1 , [∂ T (f<label>(1)</label></formula><p>i-1 )] * (h</p><p>i ) = Λ θ p i f i-1 Since this method does not have access to the data g, we select the initial guess according to a FBP, see <ref type="bibr" target="#b9">(10)</ref>. This makes the algorithm a learned denoiser.</p><p>For the human phantoms we compare both non-linear and linearized versions of the forward operator, but given that training times are noticeably longer, we only compare to the previously established methods of FBP, TV and U-Net denoising.</p><p>All learned algorithms were trained using the same training scheme as outlined in section IV-B1, and measure the runtime, PSNR and the structural similarity index (SSIM) <ref type="bibr" target="#b35">[36]</ref>.</p><p>All methods that we compare against are available in the accompanying source code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head><p>The quantitative results for the ellipse data is given in table <ref type="table">I</ref>, where we can see that the proposed Learned Primal-Dual algorithm out-performs the classical schemes (FBP and TV) significantly w.r.t. the reconstruction error as measured by both PSNR and SSIM. We also note that the Learned Primal-Dual algorithm gives a large improvement over the previous deep learning based methods such as the learned gradient scheme and U-Net based post-processing, giving an improvement exceeding 6 dB. The Learned Primal-Dual algorithm also outperforms the Learned PDHG and the FBP + residual denoising algorithms by wide margins.</p><p>The only method that achieves results close to the Learned Primal-Dual algorithm is the Learned Primal method, but the Learned Primal-Dual algorithm gives a noticeable improvement of 1.3 dB.</p><p>The results are visualized in fig. <ref type="figure">3</ref>. We note that small structures, such as the small inserts, are much more clearly visible in the Learned Primal and Learned Primal-Dual reconstructions than in the other reconstructions. We also note that both the Learned PDHG and Learned Primal reconstruction seem to have a halo artefact close to the outer bone which is absent in the Learned Primal-Dual reconstruction.</p><p>With respect to run-time the learned methods that involve calls to the forward operator (Learned Gradient, PDHG, Primal, Primal-Dual) are slower than the methods that do not (FBP + U-Net denoising, Residual) by a factor ≈ 6. When compared to TV regularized reconstruction all learned methods are at least 2 orders of magnitude faster.</p><p>Quantitative results for the human phantoms data are presented in table II. We note that the FBP reconstruction has a much more competitive image quality than it had for the ellipse data, both quantitatively and visually. It is likely for this reason that the FBP + U-Net denoising performs better than it did on the ellipses, outperforming TV by 4.4 dB. However, if One interesting, and to the best of our knowledge, unique feature of the Learned Primal-Dual algorithm in the field of deep learning based CT reconstruction, is that it gives working directly from data, without any initial reconstruction as input.</p><p>Since the algorithm is iterative, we can visualize the iterates to gain insight into how it works. In fig. <ref type="figure" target="#fig_3">5</ref> we show some iterates with the non-linear forward operator. We note that the reconstruction stays very bad until the 8:th iterate when most structures seem to come in place, but the image is still noisy. Between the 8:th and 10:th iterate, we see that the algorithm seems to perform an edge-enhancing step. It thus seems like the learned iterative scheme works in two steps, first finding the large scale structures and then fine-tuning the details.</p><p>Similarly to the edge-enhancement that seems to be performed in the primal space, we note that in the dual space the sinogram that is back-projected seems to be band-pass filtered to exclude both very low and very high frequencies.</p><p>We note that in the very noisy and under-sampled data used for the ellipse phantoms, the learned algorithms that make use of the forward operator, such as the Learned Gradient, Primal and Primal-Dual algorithms outperform even state of the art post-processing methods by large margins and that in this regimen, TV regularization performs relatively well when compared to post-processing methods. This improvement in reconstruction quality when incorporating the forward operator, while still substantial, is not as large for the human phantom in which the data was less noisy.</p><p>To explain this, we conjecture that in the limit of highly noisy data where the initial reconstruction as given by e.g. FBP becomes very bad, learned schemes that incorporate the forward model and work directly from data, such as the Learned Primal-Dual algorithm, has a considerable advantage over post-processing methods and that this advantage increases with decreasing data quality.</p><p>Further along these lines, note that for the human data the post-processing gives a large improvement in PSNR when compared to TV regularization, which is not necessarily reflected in the SSIM. On the other hand, the Learned Primal-Dual algorithm improves upon both PSNR and SSIM. This can be by explained by the learned post-processing being limited by the information content of the FBP while the Learned Primal-Dual algorithm works directly with data and is thus limited by the information content of the data, which is greater or equal to that of the FBP. In theory, the Learned Primal-Dual algorithm can thus find structures that are not present in the FBP, something post-processing methods cannot.</p><p>In these experiments we found that while the algorithm seems to handle non-linear forward models well, we did not observe any notable performance improvement by doing so. This may indicate that performing reconstructions on post-log data is preferable.</p><p>The structure of the neural network was not extensively finetuned and we suspect that better results could be obtained by a better choice of network for the learned proximal operators. We also observed that the choice of optimizer and learning rate decay had a large impact on the results, and we suspect that further research into how to correctly train learned reconstruction operators will prove fruitful.</p><p>Finally, we observe that the reconstructions, while outperforming all of the compared methods with respect to PSNR and SSIM, suffers from a perceived over-smoothing when inspected visually. We suspect that the particular choice of objective function used in this article, the squared norm (4), is a main cause of this and invite future researchers to implement learned reconstruction operators that use more advanced loss functions such as perceptual losses <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>We have proposed a new algorithm in the family of deep learning based iterative reconstruction schemes. The algorithm is inspired by the PDHG algorithm, where we replace the proximal operators by learned operators. In contrast to several recently proposed algorithms, the new algorithm works directly from tomographic data and does not depend on any initial reconstruction.</p><p>We showed that the algorithm gives state of the art results on a computed tomography problem for both analytical and human phantoms. For analytical phantoms, it improves upon both classical algorithms such as FBP and TV, and post-processing based algorithms by at least 6 dB while also improving the SSIM. The improvements for the human phantom were more modest, but the algorithm still improves upon a TV regularized reconstruction by 6.6 dB and gives an improvement of 2.2 dB when compared to a learned post-processing.</p><p>We hope that this algorithm will inspire further research in Learned Primal-Dual schemes and that the method will be applied to other imaging modalities. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Example of data which are used for training and validation. Top: Randomly generated ellipses. Middle: Validation data, here given by the modified Shepp-Logan phantom. Bottom: Validation data generated from the human phantoms.</figDesc><graphic coords="5,289.49,302.32,182.13,136.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Reconstructions of a human phantom with two zoomed in regions indicated by small circles. The left zoom-in has a true feature whereas texture in right zoom-in is uniform. The window is set to [-200, 200] HU. Among the methods tested, only the Learned Primal-Dual algorithm correctly recovers regions. In the others, the true feature in the left zoom-in is indistinguishable from other false features of same size/contrast and right-zoom in has a streak artifact. Note also the clinically feasible runtime of the Learned Primal-Dual algorithm. To summarize, the Learned Primal-Dual algorithm offers performance advantages over other methods that translate into true clinical usefulness.</figDesc><graphic coords="9,-479.10,-135.21,969.80,727.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Iterates 2, 4, 6, 8 and 10 in the Learned Primal-Dual algorithm when reconstructing the human phantoms using a non-linear forward model. Left: Reconstruction (f (1) i ). Middle: Point of evaluation for the forward operator (f (2) i ). Right: Point of evaluation for the adjoint of the derivative (h (1) i ). Windows selected to cover most of the range of the values.</figDesc><graphic coords="10,296.33,358.48,121.42,91.07" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. ACKNOWLEDGEMENTS</head><p>The work was supported by the Swedish Foundation of Strategic Research grant AM13-0049 and Industrial PhD grant ID14-0055. The work was also supported by Elekta.</p><p>The authors also thank Dr. Cynthia McCollough, the Mayo Clinic, and the American Association of Physicists in Medicine, and acknowledge funding from grants EB017095 and EB017185 from the National Institute of Biomedical Imaging and Bioengineering, for providing the data necessary for performing comparison using a human phantom.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head> <ref type="table">I</ref><p>.</p><p>we look at the SSIM we note that this improvement does not translate as well to the structural similarity, where the method is comparable to TV regularization. Both quantitatively and visually, the linear and non-linear versions of the Learned Primal-Dual algorithm give very similar results. We will focus on the linear version which gave slightly better results.</p><p>The Learned Primal-Dual algorithm gives a 10.5 dB improvement over the FBP reconstruction, a 6.6 dB improvement over TV and 2.2 dB over the U-Net denoiser. This is less than for the ellipse data, but still represents a large improvement. On the other hand, while the U-Net denoiser did not the SSIM as compared to TV regularization, the Learned Primal-Dual algorithm gives a large improvement.</p><p>This improvement is also present in the images when inspected visually in fig. <ref type="figure">4</ref>. In particular, we see that some artifacts visible in the FBP reconstruction are still discernible in the U-Net denoiser and TV reconstructions. Examples streak artifacts, especially around the edges of the phantom and structures spuriously created from noise, such as a line in the muscle above the right bone. These are mostly absent in the Learned Primal-Dual reconstruction. However, we do note that the images do look slightly over-smoothed. Both of these observations become especially apparent if we look at the zoomed in regions, where we note that the Learned Primal-Dual algorithm is able to reconstruct finer detail than the other algorithms, but gives a very smooth texture.</p><p>With respect to the run time, the Learned Primal-Dual is more competitive with the FBP and U-Net denoiser algorithms for full size data than for the ellipse data. This is because the size of the data is much larger, which increases the runtime of the FBP reconstruction, which is also needed to compute the initial guess for the U-Net denoiser. As for the ellipse data, both learned methods outperform TV regularized reconstruction by two orders of magnitude with respect to runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>The results show that the Learned Primal-Dual algorithm outperforms classical reconstruction algorithm by large margins as measured in both PSNR and SSIM and also improves upon learned post-processing methods for both simplified data and for human phantoms. In addition, especially for the 512 × 512 human phantoms, the reconstruction time is comparable with even filtered back-projection and learned post-processing.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Iterative image reconstruction: a point of view</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lantéri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zanni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Interdisciplinary Workshop on Mathematical Methods in Biomedical Imaging and Intensity-Modulated Radiation (IMRT)</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Censor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Louis</surname></persName>
		</editor>
		<meeting>the Interdisciplinary Workshop on Mathematical Methods in Biomedical Imaging and Intensity-Modulated Radiation (IMRT)<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="37" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Engl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neubauer</surname></persName>
		</author>
		<title level="m">Regularization of inverse problems, ser. Mathematics and its Applications</title>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">375</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">O</forename><surname>Scherzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grasmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Grossauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haltmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lenzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Variational Methods in Imaging, ser. Applied Mathematical Sciences</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<date type="published" when="2009">2009</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A perspective on deep imaging</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="8914" to="8924" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Solving ill-posed inverse problems using iterative deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Öktem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Problems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">124007</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network (RED-CNN)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Kalra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep Convolutional Neural Network for Inverse Problems in Imaging</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Froustey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4509" to="4522" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">WaveNet: a deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical physics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="360" to="e375" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Low-dose x-ray ct reconstruction via dictionary learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1682" to="1697" />
			<date type="published" when="2012-09">Sept 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Proximal Operators: Using Denoising Networks for Regularizing Inverse Imaging Problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017-10">October 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Inverse problems with invariant multiscale statistics</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dokmanic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Hoop</surname></persName>
		</author>
		<idno>abs/1609.05502</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep ADMM-Net for compressive sensing MRI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent inference machines for solving inverse problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Putzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>abs/1706.04008</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning a variational network for reconstruction of accelerated mri data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klatzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kobler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Sodickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Knoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep Generative Adversarial Networks for Compressed Sensing Automates MRI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vasanawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zaharchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learned primal-dual reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
		<ptr target="https://github.com/adler-j/learnedprimaldual" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Software</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="145" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A primal-dual hybrid gradient method for nonlinear operators with applications to MRI</title>
		<author>
			<persName><forename type="first">T</forename><surname>Valkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Problems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">55012</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convex optimization problem prototyping for image reconstruction in computed tomography with the Chambolle-Pock algorithm</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Sidky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Jørgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics in Medicine and Biology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="3065" to="3091" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Analytic Tomography, ser. Encyclopedia of mathematics and its applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Markoe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Flexisp: A flexible camera image processing framework</title>
		<author>
			<persName><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pajak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="231" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<author>
			<persName><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The little Engine that Could: Regularization by Denoising (RED)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Approximation capabilities of multilayer feedforward networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="257" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tfg-207a-04: Overview of the low dose ct grand challenge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mccollough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Physics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3759" to="3760" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Öktem</surname></persName>
		</author>
		<ptr target="https://github.com/odlgroup/odl" />
		<title level="m">Operator discretization library (ODL),&quot; Software available from</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yangqing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<idno>ArXiv, no. 1603.04467</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast and flexible X-ray tomography using the ASTRA toolbox</title>
		<author>
			<persName><forename type="first">W</forename><surname>Van Aarle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Palenstijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Janssens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bleichrodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dabravolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beenhouwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Batenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sijbers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Express</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="25" to="129" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the 2015 IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS&apos;10)</title>
		<meeting>the International Conference on Artificial Intelligence and Statistics (AISTATS&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with restarts</title>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno>abs/1608.03983</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Understanding the exploding gradient problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1211.5063</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Solving ill-posed inverse problems using iterative deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
		<ptr target="https://github.com/adler-j/learnedgradienttomography" />
	</analytic>
	<monogr>
		<title level="m">Software available from</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">U-Net: Convolutional Networks for Biomedical Image Segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">April 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016: 14th European Conference</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">October 11-14, 2016. 2016</date>
			<biblScope unit="page" from="694" to="711" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
