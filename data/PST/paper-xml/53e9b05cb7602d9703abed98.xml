<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Polynomial evaluation and interpolation on special sets of points</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-02-10">10 February 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alin</forename><surname>Bostan</surname></persName>
							<email>alin.bostan@stix.polytechnique.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire STIX</orgName>
								<address>
									<addrLine>École polytechnique</addrLine>
									<postCode>91128</postCode>
									<settlement>Palaiseau</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Éric</forename><surname>Schost</surname></persName>
							<email>eric.schost@stix.polytechnique.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire STIX</orgName>
								<address>
									<addrLine>École polytechnique</addrLine>
									<postCode>91128</postCode>
									<settlement>Palaiseau</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Polynomial evaluation and interpolation on special sets of points</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-02-10">10 February 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">25A372A6C7FAE35373710A88BA11351F</idno>
					<idno type="DOI">10.1016/j.jco.2004.09.009</idno>
					<note type="submission">Received 31 January 2004; accepted 6 September 2004</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Polynomial evaluation and interpolation</term>
					<term>Transposition principle</term>
					<term>Polynomial matrix multiplication</term>
					<term>Complexity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We give complexity estimates for the problems of evaluation and interpolation on various polynomial bases. We focus on the particular cases when the sample points form an arithmetic or a geometric sequence, and we discuss applications, respectively, to computations with linear differential operators and to polynomial matrix multiplication.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Let k be a field and let x = x 0 , . . . , x n-1 be n pairwise distinct points in k. Given arbitrary values v = v 0 , . . . , v n-1 in k, there exists a unique polynomial F in k[x] of degree less than n such that F (x i ) = v i , for i = 0, . . . , n -1. Having fixed a basis of the vector space of polynomials of degree at most n -1, interpolation and evaluation questions consist in computing the coefficients of F on this basis from the values v, and conversely.</p><formula xml:id="formula_0">F =f 0 +f 1 (x-x 0 )+f 2 (x-x 0 )(x-x 1 )+• • •+f n-1 (x-x 0 )• • •(x-x n-2 )</formula><p>(1)</p><p>satisfies F (x i ) = v i , for i = 0, . . . , n -1. • Given x 0 , . . . , x n-1 and f 0 , . . . , f n-1 , Newton evaluation consists in computing the values v 0 = F (x 0 ), . . . , v n-1 = F (x n-1 ), where F is the polynomial given by Eq. <ref type="bibr" target="#b0">(1)</ref>.</p><p>Fast algorithms for evaluation and interpolation in the monomial basis were discovered in the seventies and have complexity in O(M(n) log(n)), where M(n) denotes the cost of multiplying univariate polynomials of degree less than n. Using FFT-based multiplication algorithms, M(n) can be taken in O(n log(n) log(log(n))), so the complexity above is nearly optimal, up to logarithmic factors (note that naive algorithms have cost quadratic in n). These fast algorithms are nowadays classical topics covered by most of the computer algebra textbooks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13]</ref> and their practical relevance is recognized.</p><p>In contrast, fast algorithms for Newton evaluation and interpolation are quite recent, despite a potentially vast field of applications. The standard algorithms are based on divided differences and have complexity quadratic in n <ref type="bibr" target="#b23">[23]</ref>. Yet, using a divide-and-conquer approach, the complexity of Newton evaluation and interpolation becomes essentially linear in n: indeed, the algorithms suggested in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">Ex. 15,</ref><ref type="bibr">p. 67</ref>] have complexity in O(M(n) log(n)).</p><p>Such fast algorithms for Newton evaluation and interpolation rely on two additional tasks: the base change between the monomial basis and the Newton basis, and conversely. Algorithms realizing these tasks are detailed for instance in [15, Theorems 2.4 and 2.5]; they also have complexity in O(M(n) log(n)).</p><p>Remark that monomial as well as Newton evaluation and interpolation can also be regarded as base change problems, between monomial or Newton bases on the one hand and Lagrange basis j =0 (x -x j ) j =0 (x 0 -x j ) , j =1 (x -x j ) j =1 (x 1 -x j ) , . . . , j =n-1 (x -x j ) j =n-1 (x n-1 -x j ) associated to the points x 0 , . . . , x n-1 , on the other hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Our contribution</head><p>The core of this paper is the study of the three operations mentioned up to now:</p><p>(1) conversions between Newton and monomial bases, (2) monomial evaluation and interpolation, (3) Newton evaluation and interpolation.</p><p>Our first goal is to propose improved algorithms for some of these operations: specifically, we describe a faster conversion algorithm, from which we deduce an improved Newton interpolation algorithm. When the sample points bear no special structure, our algorithms still have an asymptotic complexity belonging to the class O(M(n) log(n)), but they are faster than the previous ones by a constant factor. To establish comparisons, and for the sake of completeness, we will detail the constants hidden behind the Big-Oh notation in the complexity estimates, for our algorithms as well as for one of <ref type="bibr" target="#b14">[15]</ref>.</p><p>Our second objective is to obtain better algorithms for special cases of evaluation points x. Indeed, it is well known that the divided difference formulas used in Newton interpolation simplify when the points form an arithmetic or a geometric progression; we will show how to obtain improved complexity estimates based on such simplifications. We also discuss applications to computations with linear differential operators and polynomial matrix multiplication.</p><p>Table <ref type="table">1</ref> summarizes the best results known to us on the three questions mentioned above; we now review its columns in turn and detail our contributions. In what follows, all results of type O(M(n) log(n)) are valid when n is a power of 2. The results for the arithmetic progression case additionally require that the base field has characteristic 0 or larger than n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">The general case</head><p>The first column gives estimates for arbitrary sample points; we call this case the general case. In this situation, conversion algorithms and monomial evaluation/interpolation algorithms are designed first, and algorithms for Newton evaluation and interpolation are deduced by composition.</p><p>The conversion algorithm from the Newton to the monomial basis (first row in the table) is from Gerhard <ref type="bibr" target="#b14">[15]</ref>, who also gives its bit complexity when the base field is Q. As to the conversion from the monomial to the Newton basis (second row in the table), our algorithm is new, to the best of our knowledge. It relies on the so-called transposition principle, which  Complexity results on conversions between Newton and monomial bases, monomial evaluation and interpolation, Newton evaluation and interpolation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>General case Newton to monomial basis (N to M)</p><formula xml:id="formula_1">M(n) log(n) + O(M(n))</formula><p>Monomial to Newton basis (M to N)</p><formula xml:id="formula_2">M(n) log(n) + O(M(n))</formula><p>Monomial evaluation (M to V)</p><formula xml:id="formula_3">3 2 M(n) log(n) + O(M(n)) Monomial interpolation (V to M) 5 2 M(n) log(n) + O(M(n)) Newton evaluation (N to V) 2 M(n) log(n) + O(M(n)) Newton interpolation (V to N) 3 M(n) log(n) + O(M(n)) Question Arithmetic case Geometric case N to M M(n) log(n) + O(M(n)) M(n) + O(n) M to N M(n) log(n) + O(M(n)) M(n) + O(n) M to V M(n) log(n) + O(M(n)) M(n) + O(n) V to M M(n) log(n) + O(M(n)) 2 M(n) + O(n) N to V M(n) + O(n) M(n) + O(n) V to N M(n) + O(n) M(n) + O(n)</formula><p>finds its origins in Tellegen's theorem on electrical networks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b38">38]</ref>. Gerhard <ref type="bibr" target="#b14">[15]</ref> also presents an algorithm for this task, but its complexity is higher by a constant factor. The results on monomial evaluation and interpolation (third and fourth rows) appeared in <ref type="bibr" target="#b8">[9]</ref> and improve the classical results by Moenck and Borodin <ref type="bibr" target="#b24">[24]</ref>, Strassen <ref type="bibr" target="#b37">[37]</ref>, Borodin and Moenck <ref type="bibr" target="#b6">[7]</ref> and Montgomery <ref type="bibr" target="#b25">[25]</ref>.</p><p>The last two operations (fifth and sixth rows of the upper table) are Newton evaluation and interpolation; the algorithms for these tasks are easily deduced from those mentioned before (rows 1-4), by composition. Note, however that the constants do not add up, due to some shared precomputations. Recall that these complexity results were already known to lie in the class O(M(n) log(n)), see for instance <ref type="bibr" target="#b4">[5]</ref>; the precise estimate in the fifth row is obtained by combining algorithms of Gerhard <ref type="bibr" target="#b14">[15]</ref> and Bostan et al. <ref type="bibr" target="#b8">[9]</ref>, whereas that in the last row relies on our improved conversion algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">The arithmetic progression case</head><p>In the arithmetic progression case, a sharp complexity statement was given in <ref type="bibr">[15,</ref> Theorems 3.2 and 3.4], which proves that Newton evaluation and interpolation at an arithmetic progression can be done within M(n) + O(n) operations. That article also analyzes the bit complexity when the base field is Q.</p><p>In the arithmetic progression case, the basis conversion algorithms developed in the general case remain unchanged. Using Gerhard's result and these conversion algorithms, we then deduce new, faster algorithms for monomial evaluation and interpolation on an arithmetic progression.</p><p>We apply these algorithms to conversions between the monomial and the falling factorial bases. This yields fast algorithms for computing Stirling numbers, which in turn are the basis for fast computation with linear differential operators. Also, we discuss the transpose of the algorithm of Gerhard <ref type="bibr" target="#b14">[15]</ref>, which is shown to be closely related to an algorithm of Aho et al. <ref type="bibr" target="#b1">[2]</ref> for polynomial shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">The geometric case</head><p>In the geometric progression case, we show that the complexities of Newton evaluation and interpolation drop to M(n) + O(n) as well. The improvements are obtained by (mainly) translating into equalities of generating series the formulas for divided q-differences, similarly to what is done by Gerhard <ref type="bibr" target="#b14">[15]</ref> for the arithmetic case. By considering the transposed problems, we deduce that the conversions between the Newton and the monomial bases can be done with the same asymptotic complexity of M(n) + O(n) operations in the base field.</p><p>These results have consequences for evaluation and interpolation in the monomial basis. It is known <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">28]</ref> that evaluating a polynomial of degree less than n on n points in a geometric progression has cost M(n) + O(n) (the algorithm given by Aho et al. <ref type="bibr" target="#b1">[2]</ref> actually has complexity more than M(n)+O(n), but using the middle product operation of Hanrot et al. <ref type="bibr" target="#b17">[18]</ref> yields the announced complexity bound). A similar result for the inverse problemthat is, interpolation on the monomial basis at points in a geometric progression-was previously not known. Using the Newton basis for intermediate computations, we show that this can be done using 2 M(n</p><formula xml:id="formula_4">) + O(n) operations.</formula><p>Thus, this allows to exhibit special sequences of points, lying in the base field, for which both evaluation and interpolation are cheaper by a logarithmic factor than in the general case. Many algorithms using evaluation and interpolation for intermediate computations can benefit from this. We exemplify this by improving the known complexity results for polynomial matrix multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5.">Organization of the paper</head><p>In Section 2, we recall basic tools for our subsequent algorithms, the construction of the subproduct tree associated to the sample points and the notion of transposed algorithms, and notably transposed multiplication.</p><p>In Section 3, we recall or improve known algorithms for the three operations mentioned up to now, evaluation and interpolation in the monomial and Newton bases, as well as base change algorithms, in the general case of arbitrary sample points.</p><p>In Section 4, we focus on the case when the sample points form an arithmetic sequence, and present an application to computations with linear differential operators. Section 5 is devoted to the special case of evaluation points in a geometric progression; we conclude this section by an application to polynomial matrix multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6.">Technical assumptions</head><p>We suppose that the multiplication time function M fulfills the inequality M(d 1 ) + M(d 2 ) M(d 1 +d 2 ) for all positive integers d 1 and d 2 ; in particular, the inequality M(d/2) 1 2 M(d) holds for all d 1. We also make the hypothesis that M(cd) is in O(M(d)), for all c &gt; 0. The basic examples we have in mind are classical multiplication, for which M(n) ∈ O(n 2 ), Karatsuba's multiplication <ref type="bibr" target="#b22">[22]</ref> with M(n) ∈ O(n 1.59 ) and the FFT-based multiplications <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b33">33]</ref>, which have M(n) ∈ O(n log(n) log(log(n))). Our references for matters related to polynomial arithmetic are the books <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>When designing transposed algorithms, we will impose additional assumptions on the polynomial multiplication algorithm; these assumptions are described in Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>In this section, we introduce two basic tools: the subproduct tree T associated to the points x 0 , . . . , x n-1 and the notion of transposed algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The subproduct tree</head><p>In what follows, we suppose that n is a power of 2. The subproduct tree T associated to x = x 0 , . . . , x n-1 is then a complete binary tree, all whose nodes contain polynomials in k[x]. Let n = 2 m ; then T is defined as follows:</p><p>• If m = 0, then T reduces to a single node, containing the polynomial x -x 0 .</p><p>• If m &gt; 0, let T 0 and T 1 be the trees associated to x 0 , . . . , x 2 m-1 -1 and x 2 m-1 , . . . , x 2 m -1</p><p>respectively. Let M 0 and M 1 be the polynomials at the roots of T 0 and T 1 . Then T is the tree whose root contains the product M 0 M 1 and whose children are T 0 and T 1 .</p><p>Alternately, one can represent the subproduct tree T as a 2-dimensional array T i,j , with 0 i m, 0 j 2 m-i -1. Then</p><formula xml:id="formula_5">T i,j = 2 i (j +1)-1 =2 i j (x -x ).</formula><p>For instance, if m = 2 (and thus n = 4), the tree associated to x 0 , x 1 , x 2 , x 3 is given by</p><formula xml:id="formula_6">T 0,0 = x -x 0 , T 0,1 = x -x 1 , T 0,2 = x -x 2 , T 0,3 = x -x 3 , T 1,0 = (x -x 0 )(x -x 1 ), T 1,1 = (x -x 2 )(x -x 3 ), T 2,0 = (x -x 0 )(x -x 1 )(x -x 2 )(x -x 3 ).</formula><p>The following result was first pointed out by Horowitz <ref type="bibr" target="#b20">[20]</ref>, see also <ref type="bibr" target="#b12">[13]</ref>.</p><p>Proposition 1. The subproduct tree associated to x 0 , . . . , x n-1 can be computed within</p><formula xml:id="formula_7">1 2 M(n) log(n) + O(n log(n)) base field operations.</formula><p>Since in what follows a particular attention is payed to special sets of points x, one may wonder whether the construction of the subproduct tree can be speeded up in such structured situations. If the points x form a geometric sequence, we show that an acceleration (by a logarithmic factor) can indeed be obtained. This result is stated for completeness in Lemma 1 below; however, we will not make use of it in the sequel, since our fast algorithms in Section 5 for evaluation and interpolation on geometric sequences do not rely on the use of subproduct trees. In contrast, in the case of points in an arithmetic progression, we are not able to obtain a similar improvement upon Proposition 1. Note that a gain in the arithmetic case would be of real interest, as some of our algorithms in Section 4 share the construction of T as a precomputation. Lemma 1. Let k be a field and let n be a power of 2. Let x i = q i , i = 0, . . . , n -1 be a geometric progression in k. Then, the nodes of the subproduct tree T associated to x = x 0 , . . . , x n-1 can be computed within M(n</p><formula xml:id="formula_8">) + O(n log(n)) operations in k.</formula><p>Proof. The fact that the points x form a geometric progression implies that, at every level i, the nodes T i,j can be deduced from one another by performing a homothety. Thus, our strategy is to determine the left-side nodes T i,0 first, then to obtain all the other nodes by polynomial homotheties.</p><p>The left-side nodes T i,0 , for 0 i m, have degree 2 i and can be determined (together with the nodes T i,1 ) by a procedure based on the equalities</p><formula xml:id="formula_9">T i,1 (x) = T i,0 (x/q 2 i ) • q 4 i , T i+1,0 (x) = T i,0 (x)T i,1 (x), 0 i m -1 within m-1 i=0 (M(2 i ) + O(2 i )) = M(n) + O(n) operations in k.</formula><p>Then, starting from T i,0 , the remaining desired nodes can be determined using the equality</p><formula xml:id="formula_10">T i,j (x) = T i,0 (x/q 2 i j )q 4 i j for 1 i m -2, 2 j 2 m-i -1 for a total cost of at most m-2 i=1 2 m-i O(2 i ) = O(n log(n)) operations in k.</formula><p>This finishes the proof of the lemma.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remarks. In may happen that one is only interested in the top polynomial</head><formula xml:id="formula_11">T m,0 = (x - x 0 )(x -x 1 ) • • • (x -x n-1 ) (or,</formula><p>equivalently, all the elementary symmetric functions of x 0 , . . . , x n-1 ). Using Proposition 1, it can be computed in 1  2</p><formula xml:id="formula_12">M(n) log(n) + O(n log(n)) base field operations.</formula><p>However, the proof of Lemma 1 shows that better can be done when the points x form a geometric progression, since in this case the construction of the whole tree can be avoided and one can decrease the cost of computing T m,0 to M(n) + O(n). Similarly, if the points x form an arithmetic progression, the polynomial T m,0 can be computed within 2 M(n)+O(n) base field operations, provided k has characteristic zero or larger than n. Indeed, under this hypothesis, the node T i+1,0 can be deduced from T i,0 by a polynomial shift using the fast algorithm of Aho et al. <ref type="bibr" target="#b1">[2]</ref> (which we recall in Section 4).</p><p>As a final remark, note that, for some algorithms presented later, only the even nodes T i,2j from the subproduct tree are necessary. If this is the case, one is led to the natural question: can these polynomials be computed faster than all the subproduct tree? For the moment, we are unable to answer this question satisfactorily, even in the arithmetic and the geometric case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Transposed algorithms</head><p>Introduced under this name by Kaltofen and Shoup, the transposition principle is an algorithmic theorem, with the following content: given an algorithm that performs an (r + n) × n matrix-vector product, one can deduce an algorithm with the same complexity, up to O(r), and which performs the transposed matrix-vector product. See for instance Bürgisser et al. <ref type="bibr" target="#b9">[10]</ref> for a precise statement and Kaltofen <ref type="bibr" target="#b21">[21]</ref> for historical notes and further comments on this question.</p><p>For this result to apply, some restrictions must be imposed on the computational model; for our purposes, it will suffice to impose a condition on the univariate polynomial multiplication algorithm. Namely, we require that to compute the product of a polynomial a by a polynomial b, only linear operations in the coefficients of b are done. This is no strong restriction, since all classical multiplication algorithms mentioned in the introduction satisfy this assumption.</p><p>We can then introduce our basic transposed operation. Let us denote by k[x] i the vector space of polynomials of degree at most i; then given a ∈ k[x] of degree r, we denote by mul t (n, a, .)</p><formula xml:id="formula_13">: k[x] r+n → k[x] n the transpose of the (k-linear) multiplication-by-a map k[x] n → k[x] r+n .</formula><p>Various algorithms for computing the transposed multiplication are detailed in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>. The transposition principle implies that under the assumption above, whatever the algorithm used for polynomial multiplication, the cost of the direct and of the transposed multiplication are equal, up to O(r) operations in k; for instance, if n &lt; r, the complexity of mul t (n, a, .) is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M(r) + O(r).</head><p>All algorithms to be transposed later rely mainly on polynomial multiplication, as well as other basic operations such as multiplication of vectors by diagonal matrices, or additions. We now know how to perform transposed polynomial multiplications, and all other basic operations are easily transposed; following Bostan et al. <ref type="bibr" target="#b8">[9]</ref>, a basic set of mechanical transformations will then easily yield all required transposed algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Algorithms for arbitrary sample points</head><p>In this section, we treat the questions of evaluation and interpolation in the monomial and Newton bases, and base change algorithms, for an arbitrary choice of points x = x 0 , . . . , x n-1 . Recall that n is supposed to be a power of 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Conversions between Newton basis and monomial basis</head><p>We first estimate the complexity for the conversions between monomial and Newton bases. The results are summarized in the theorem below. Theorem 1. Let k be a field, let x = x 0 , . . . , x n-1 be n elements of k and let F ∈ k[x] of degree less than n. Suppose that n is a power of 2 and that the subproduct tree associated to the points x has been precomputed. Then:</p><p>• given the coefficients of F in the Newton basis, one can recover the coefficients of F in the monomial basis using</p><formula xml:id="formula_14">1 2 M(n) log(n) + O(M(n)) operations in k.</formula><p>• given the coefficients of F in the monomial basis, one can recover the coefficients of F in the Newton basis using</p><formula xml:id="formula_15">1 2 M(n) log(n) + O(M(n)) operations in k.</formula><p>Taking into account the complexity of computing the subproduct tree stated in Proposition 1, we obtain the estimates given in the first column, first two rows, in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">From Newton basis to monomial basis</head><p>Let F be a polynomial of degree less than n = 2 m and f = f 0 , . . . , f n-1 its coefficients in the Newton basis. Given f, we want to recover the coefficients of F in the monomial basis. To this effect, we write the equality</p><formula xml:id="formula_16">F = F 0 + (x -x 0 ) • • • (x -x n/2-1 )F 1 , with F 0 = f 0 + f 1 (x -x 0 ) + • • • + f n/2-1 (x -x 0 ) • • • (x -x n/2-2 ), F 1 = f n/2 + f n/2+1 (x -x n/2 ) + • • • + f n-1 (x -x n/2 ) • • • (x -x n-2 ).</formula><p>Using this decomposition, the following conversion algorithm can be deduced. On input the coefficients f = f 0 , . . . , f n-1 and the subproduct tree T associated to the points x 0 , . . . , x n-1 , it outputs the expansion of F on the monomial basis. The following algorithm works "in place", since the input list f is modified at each iteration (for type consistency we might see the input constants as polynomials of degree zero).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NewtonToMonomial(T , f)</head><p>for i ← 0 to m -1 do for j ← 0 to 2 m-i-1 -1 do</p><formula xml:id="formula_17">f j ← f 2j + T i,2j f 2j +1 ; return f 0 ;</formula><p>Let us assume that the even nodes T i,2j of the subproduct tree associated to the points x 0 , . . . , x n-1 have been precomputed. Then, the number of operations in k used by algorithm NewtonToMonomial is upper bounded by</p><formula xml:id="formula_18">m-1 i=0   2 m-i-1 -1 j =0 M(2 i ) + O(2 i )   = 1 2 M(n) log(n) + O(n log(n)).</formula><p>This proves the first part of Theorem 1. This algorithm was already presented in [15, Theorem 2.5], but the more precise complexity estimate given here is needed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Transposed conversion algorithm</head><p>The conversion algorithm described above computes a base change map, which is linear in F. In what follows, we are interested in computing the inverse of this map, that is, the converse base change. As a first step, we now discuss the transposed map.</p><p>Constructing the subproduct tree associated to the points x is a precomputation, which does not depend on the polynomial F, and is not transposed. As to the two nested loops, we use the transposed multiplication introduced previously. With this operation, we obtain by a mechanical transformation the following transposed conversion algorithm: increasing loop indices become decreasing indices, polynomial multiplications become transposed multiplications, and additions become duplications.</p><p>The direct version takes the subproduct tree and a list of coefficients as input and gives its output in the form of a polynomial; the transposed algorithm takes the subproduct tree and a polynomial as input and outputs a list of constant polynomials, that is, of constants.</p><formula xml:id="formula_19">TNewtonToMonomial(T , F ) c 0 ← F; for i ← m -1 downto 0 do for j ← 2 m-i-1 -1 downto 0 do c 2j +1 ← mul t (2 i -1, T i,2j , c j ); c 2j ← c j mod x 2 i ; return c 0 , . . . , c 2 m -1 ;</formula><p>It follows from either a direct analysis or the transposition principle that, if the subproduct tree is already known, the complexity of this algorithm is the same as that of the direct one, that is, 1  2 M(n) log(n) + O(n log(n)) base field operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">From monomial basis to Newton basis</head><p>We can now resume our study of conversion algorithms. Let F be a polynomial of degree less than n, whose coefficients on the monomial basis are known; we want to recover the coefficients of F on the Newton basis 1, x -x 0 , . . . , (x</p><formula xml:id="formula_20">-x 0 ) • • • (x -x n-2 ).</formula><p>A natural way to do that is based on the next remark: if we write F as</p><formula xml:id="formula_21">F = F 0 + (x -x 0 ) • • • (x -x n/2-1 )F 1 ,</formula><p>then it is enough to recover the coefficients of F 0 and F 1 on the Newton bases 1, xx 0 , . . . , (x</p><formula xml:id="formula_22">-x 0 ) • • • (x -x n/2-2 ) and 1, x -x n/2 , . . . , (x -x n/2 ) • • • (x -x n-2 )</formula><p>respectively.</p><p>Using this remark, one can deduce a conversion algorithm based on (recursive) division with quotient and remainder by the even nodes T i,2j , see <ref type="bibr" target="#b14">[15,</ref><ref type="bibr">Theorem 2.4]</ref> for details. Using the idea in <ref type="bibr">[25, pp. 22-24]</ref> to save constant factors in the division by the tree nodes, the cost of the resulting algorithm (without counting the precomputation of the subproduct tree) is upper bounded by 2 M(n</p><formula xml:id="formula_23">) log(n) + O(n log(n)).</formula><p>In what follows, we obtain an algorithm of better complexity by studying the transpose of this conversion algorithm. Indeed, we will show that this transposed map mainly amounts to a conversion from Newton basis to monomial basis on a modified set of points; transposing backwards will yield the desired result. Let us notice that the same approach-that is, looking at the dual problem-was already successfully applied by Bostan et al. <ref type="bibr" target="#b8">[9]</ref> to speed up algorithms for multipoint evaluation in the monomial basis.</p><p>Our starting point is the following result (where we take the usual convention that the empty sum is zero).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2.</head><p>Let A be the matrix of change of base from the monomial basis to the Newton basis associated to x 0 , . . . , x n-1 . Then, for 1 i, j n, the (i, j )th entry of A equals</p><formula xml:id="formula_24">A i,j (x 0 , . . . , x i-1 ) = 0 +•••+ i-1 =j -i x 0 0 x 1 1 • • • x i-1 i-1 .</formula><p>Proof. The proof is an induction on i = 1, . . . , n, with j fixed. For i = 1, A 1,j is the constant coefficient of x j in the Newton basis, that is, x j 0 , so our claim holds. For i &gt; 1, A i+1,j is obtained by computing the ith divided difference of A i,j , that is,</p><formula xml:id="formula_25">A i,j (x 0 , . . . , x i-2 , x i-1 ) -A i,j (x 0 , . . . , x i-2 , x i ) x i-1 -x i , if x i-1 = x i and *A i,j *x i , if x i-1 = x i ,</formula><p>see for instance <ref type="bibr" target="#b23">[23]</ref>. The conclusion follows by an easy computation.</p><p>In this matricial formulation, our primary goal is thus to study the map of multiplication by A. As announced above, we start by considering the transposed map, of multiplication by A t .</p><p>From Lemma 2, we see that modulo x n , the generating series of the columns of A t are all rational and respectively equal</p><formula xml:id="formula_26">1 1 -xx 0 , x (1 -xx 0 )(1 -xx 1 ) , x 2 (1 -xx 0 )(1 -xx 1 )(1 -xx 2 )</formula><p>, . . . .</p><p>Let then f 0 , . . . , f n-1 be in k and f = f 0 , . . . , f n-1 . A direct computation shows that the entries of the product between A t and the vector [f 0 , . . . , f n-1 ] t are the coefficients of 1, x, . . . , x n-1 in the Taylor expansion of</p><formula xml:id="formula_27">G(x) = n-1 j =0 f j x j j =0 (1 -x x) = rev(n -1, Q(x)) rev(n, T m,0 ) ,</formula><p>where</p><formula xml:id="formula_28">Q(x) = f n-1 + f n-2 (x -x n-1 ) + • • • + f 0 (x -x n-1 ) • • • (x -x 1 )</formula><p>and where rev( , P (x)) = x P (1/x) for any P ∈ k[x] and for all deg(P ). The polynomial Q can be obtained by applying the algorithm NewtonToMonomial to the input values f = f n-1 , . . . , f 0 and x = x n-1 , . . . , x 0 . Computing the Taylor expansion to recover G requires one additional power series inversion and one power series multiplication.</p><p>Let us denote by T the subproduct tree associated to x. Then the algorithm above is summarized as follows.</p><formula xml:id="formula_29">TMonomialToNewton( T , f) I ← 1/rev(n, T m,0 ) mod x n ; Q ← NewtonToMonomial( T , f); Q ← rev(n -1, Q); G ← I Q mod x n ; return G;</formula><p>By transposition, we deduce the following algorithm for computing the matrix-vector product by A. All operations that depend linearly in f are transposed, and their order is reversed; thus, we now use as a subroutine the algorithm TNewtonToMonomial presented in the previous paragraphs. Note that the computation of I is not transposed, since it does not depend on f. The resulting algorithm takes as input a polynomial F and returns its coefficients in the Newton basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MonomialToNewton( T , F )</head><formula xml:id="formula_30">I ← 1/rev(n, T m,0 ) mod x n ; Q ← mul t (n -1, I, F ); Q ← rev(n -1, Q); f n-1 , . . . , f 0 ← TNewtonToMonomial( T , Q); return f 0 , . . . , f n-1 ;</formula><p>This algorithm uses the subproduct tree T . However, this is not a strong limitation: if the subproduct tree T associated to the points x 0 , . . . , x n-1 is already known, then T is obtained by reversing the order of the siblings of each node in T .</p><p>To conclude, using the first part of Theorem 1 and either the transposition principle or a direct analysis, we deduce that both algorithms require 1  2 M(n) log(n) + O(M(n)) operations in k, since the additional power series operations have cost in O(M(n)). This is to be compared with the previous estimate of 2 M(n) log(n)+O(n log(n)) for the algorithm based on Euclidean division. This estimate proves the second assertion in Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Completing the table</head><p>We conclude this section by filling the last entries of the first column in Table <ref type="table">1</ref>. Using the results above and the algorithms of Bostan et al. <ref type="bibr" target="#b8">[9]</ref>, this is an immediate task. The constants do not add up, due to the shared precomputation of the subproduct tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Evaluation and interpolation on the monomial basis</head><p>Let F ∈ k[x] be a polynomial of degree less than n, let x 0 , . . . , x n-1 be n pairwise distinct points in k and denote v i = F (x i ). The questions of multipoint evaluation and interpolation in the monomial basis consist in computing the coefficients of F in the monomial representation from the values v 0 , . . . , v n-1 , and conversely.</p><p>Fast algorithms for these tasks were given by Moenck and Borodin <ref type="bibr" target="#b24">[24]</ref> and Borodin and Moenck <ref type="bibr" target="#b6">[7]</ref>, then successively improved by Strassen <ref type="bibr" target="#b37">[37]</ref> and Montgomery <ref type="bibr" target="#b25">[25]</ref>. All these algorithms are based on (recursive) polynomial remaindering and have complexity O(M(n) log(n)). Recently, different algorithms, based on the use of transposed operations, have been designed in [9, Section 6] and led to improved complexity bounds, by constant factors. For the sake of completeness, we summarize the corresponding results of Bostan et al. <ref type="bibr" target="#b8">[9]</ref> in the theorem below: Theorem 2. Let k be a field, let x = x 0 , . . . , x n-1 be pairwise distinct elements of k and let F ∈ k[x] of degree less than n. Suppose that n is a power of 2 and that the subproduct tree associated to the points x has been precomputed. Then:</p><p>• the evaluation of F at the points x can be done using M(n</p><formula xml:id="formula_31">) log(n) + O(M(n)) operations in k.</formula><p>• the interpolation of F at the points x can be done using 2 M(n</p><formula xml:id="formula_32">) log(n) + O(M(n))</formula><p>operations in k.</p><p>Taking into account the complexity of computing the subproduct tree, which is within</p><formula xml:id="formula_33">1 2 M(n) log(n) + O(M(n))</formula><p>operations, we obtain the estimates given in the first column, middle rows, in Table <ref type="table">1</ref>.</p><p>We conclude by a remark. Interpolation requires to evaluate the derivative of n-1 i=0 (x-x i ) on all points x, which contributes for M(n) log(n) + O(M(n)) in the estimate above. In the case of an arithmetic or a geometric progression, these values can be computed in linear time: we refer the reader to Bostan et al. <ref type="bibr" target="#b7">[8]</ref> for the arithmetic case and leave her the geometric case as an exercise. Thus the complexity of interpolation drops to</p><formula xml:id="formula_34">(1/2 + 1) M(n) log(n) + O(M(n)) = 3 2 M(n) log(n) + O(M(n)</formula><p>) in these cases. However, in Sections 4 and 5 we show that one can actually do better in these two special cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Newton evaluation and interpolation</head><p>Combining the results of Sections 3.1 and 3.2, we deduce the following result concerning the complexities of Newton evaluation and interpolation on an arbitrary set of evaluation points.</p><p>Theorem 3. Let k be a field, let x = x 0 , . . . , x n-1 be pairwise distinct elements of k and let F ∈ k[x] of degree less than n. Suppose that n is a power of 2 and that the subproduct tree associated to the points x i has been precomputed. Then:</p><p>• Newton evaluation of F at the points x can be done in 3  2 M(n</p><formula xml:id="formula_35">) log(n) + O(M(n)) opera- tions in k.</formula><p>• Newton interpolation of F at the points x can be done in 5  2 M(n</p><formula xml:id="formula_36">) log(n) + O(M(n)) operations in k.</formula><p>Taking into account the complexity of computing the subproduct tree, this completes the entries of the first column of Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Special case of an arithmetic progression</head><p>In this section we focus on the special case of evaluation points in arithmetic progression, and show that many of the complexity estimates above can be improved in this case.</p><p>We begin by recalling a result taken from Gerhard [15, <ref type="bibr">Section 3]</ref>, which shows that the complexities of Newton evaluation and interpolation drop to M(n) + O(n) in this special case, and we point out the link between these algorithms and the algorithm for shift of polynomials of Aho et al. <ref type="bibr" target="#b1">[2]</ref>. Next, using the transposed algorithm of Section 3.1, we show how to improve (by constant factors) the complexities of evaluation and interpolation in the monomial basis on an arithmetic progression. We conclude by an application to computations with linear differential operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Newton interpolation and evaluation</head><p>We first recall the algorithm of Gerhard <ref type="bibr" target="#b14">[15,</ref><ref type="bibr">Section 3]</ref>: this gives the last two entries of the second column, in Table <ref type="table">1</ref>. For further discussion, we detail the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2. Suppose that k is a field of characteristic 0 or larger than n. Let h be a nonzero element in k. Then, Newton interpolation and evaluation of a polynomial of degree n on the arithmetic sequence</head><formula xml:id="formula_37">x i = x 0 + ih, for i = 0, . . . , n -1 can be done using M(n) + O(n) operations in k.</formula><p>Proof. Let F be a polynomial of degree less than n, v = v 0 , . . . , v n-1 the values F (x i ) and f = f 0 , . . . , f n-1 the coefficients of F on the Newton basis associated to the points x = x 0 , . . . , x n-1 . Evaluating Formula (1) at x, we deduce the following equalities relating the values v and the coefficients f:</p><formula xml:id="formula_38">v 0 = f 0 , v 1 = f 0 + hf 1 , v 2 = f 0 + 2hf 1 + (2h • h)f 2 , v 3 = f 0 + 3hf 1 + (3h • 2h)f 2 + (3h • 2h • h)f 3 . . . .</formula><p>They suggests to introduce the auxiliary sequence w = w 0 , . . . , w n-1 defined by</p><formula xml:id="formula_39">w i = v i i!h i , i = 0, . . . , n -1.</formula><p>Note that the sequences v and w can be deduced from one another for O(n) base field operations. Using the sequence w, the relations above become</p><formula xml:id="formula_40">w i = j +k=i 1 h k k! f j .</formula><p>Introducing the generating series</p><formula xml:id="formula_41">W = n-1 i=0 w i x i , F = n-1 i=0 f i x i , S = n-1 i=0 1 i!h i x i ,</formula><p>all relations above are summarized in the equation W = F S modulo x n . Since S is the truncation of exp(x/ h), its inverse S -1 is the truncation of exp(-x/ h), so multiplying or dividing by S modulo x n can be done in M(n) + O(n) base field operations. We deduce that W and F can be computed from one another using M(n) + O(n) base field operations. This proves the proposition.</p><p>Let us make a few comments regarding the previous algorithm. The problem of Newton evaluation on the arithmetic sequence x i = x 0 + ih is closely related to that of Taylor shift by 1/h. More precisely, the matrix Newton h of Newton evaluation is equal, up to multiplication by diagonal matrices, to the transpose of the matrix Shift 1/h representing the map F (x) → F (x + 1/h) in the monomial basis. Indeed, the following matrix equality is easy to infer:</p><formula xml:id="formula_42">Newton h = Diag 1, h, h 2 , . . . , h n-1 Shift t 1/h Diag 0!, 1!, . . . , (n -1)! . (<label>2</label></formula><formula xml:id="formula_43">)</formula><p>In the same vein, one can also interpret Newton interpolation as the transpose of Taylor shift by -1/h (up to diagonal matrices). A simple way to see this is to take the inverse of Eq. ( <ref type="formula" target="#formula_42">2</ref>) and to use the equality between Shift -1 1/h and Shift -1/h . Now, over fields of characteristic zero or larger than n, a classical algorithm of Aho et al. <ref type="bibr" target="#b1">[2]</ref> solves the Taylor shift problem within M(n</p><formula xml:id="formula_44">) + O(n) operations. Given a degree n -1 polynomial F (x) = n-1 i=0 f i x i , the algorithm in Aho et al. [2] computes the coefficients of Shift 1/h (F ) = F (x + 1/h) by exploiting Taylor's formula Shift 1/h (F ) = n-1 j =0 F (j ) (1/h) x j j !</formula><p>and the fact that</p><formula xml:id="formula_45">F (j ) (1/h) is the coefficient of x n-j -1 in the product n-1 i=0 i! f i x n-i-1 n-1 i=0 x i i! h i .</formula><p>In view of Eq. ( <ref type="formula" target="#formula_42">2</ref>), it is immediate to show that the algorithm for Newton evaluation on an arithmetic progression presented in Proposition 2 can be interpreted as the transposition of the algorithm in Aho et al. <ref type="bibr" target="#b1">[2]</ref> (up to diagonal matrix multiplications) and thus could have been deduced automatically from that algorithm using the effective transposition tools in Bostan et al. <ref type="bibr" target="#b8">[9]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Conversion between monomial and Newton bases</head><p>To fill the second column of Table <ref type="table">1</ref>, our next step is to consider the base change algorithms, which occupy the first and second rows. To perform these conversions, we use the same algorithms as in the case of arbitrary sample points; the complexity results are thus those given in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation and interpolation on the monomial basis</head><p>We conclude this systematic exploration by studying evaluation and interpolation on the monomial basis, for points in an arithmetic progression. A surprising consequence of Proposition 2 is the following corollary: one can speed up both monomial evaluation and interpolation using the Newton basis for intermediate computations. This gives the middle entries of the second column in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 1.</head><p>Let n be a power of 2 and let k be a field of characteristic 0 or larger than n. Let F ∈ k[x] of degree less than n and let x 0 , . . . , x n-1 be an arithmetic progression in k. Then:</p><p>• Given the coefficients of F on the monomial basis, F (x 0 ), . . . , F (x n-1 ) can be computed in M(n <ref type="figure" target="#fig_1">F (x n-1</ref> ), all coefficients of F on the monomial basis can be computed in M(n</p><formula xml:id="formula_46">) log(n) + O(M(n)) base field operations. • Given the values F (x 0 ), . . . ,</formula><formula xml:id="formula_47">) log(n) + O(M(n)) base field operations.</formula><p>The proof comes easily by combining the results of Propositions 1, 2 and Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Applications</head><p>Our initial interest in improving evaluation and interpolation on the points of an arithmetic progression was motivated by the study of linear recurrences with polynomial coefficients presented in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>: the algorithms therein can benefit from any improvement on evaluation and interpolation on an arithmetic progression. The cryptographic-sized record obtained by Bostan et al. <ref type="bibr" target="#b7">[8]</ref> requires to work in degree several tens of thousands, and gaining even a constant factor is interesting in such sizes.</p><p>We conclude this section by describing another application which comes from the domain of exact computations with linear differential operators. While computing with such operators, it is sometimes easier to work with the Euler derivation = x * *x instead of the usual derivation D = * *x (see below for an application example). We now estimate the complexity of performing this base change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2. Let n be a power of 2 and k a field of characteristic zero or larger than n.</head><p>Let L = n-1 i=0 p i (x) i be a linear differential operator with polynomial coefficients of degree at most d, and let q 0 , . . . , q n-1 be the unique polynomials such that</p><formula xml:id="formula_48">L = n-1 i=0 q i (x)D i . Then all q i can be computed in d M(n) log(n) + O(d M(n))</formula><p>operations in k. Let L = n-1 i=0 q i (x)D i be a linear differential operator with polynomial coefficients of degree at most d and let p 0 , . . . , p n-1 be the unique Laurent polynomials in k[x, x -1 ] such that L = n-1 i=0 p i (x) i . Then all p i can be computed in</p><formula xml:id="formula_49">(n + d) M(n) log(n) + O((n + d) M(n)) operations in k.</formula><p>Proof. Converting from the representation in to that in D, or backwards, amounts to compute several matrix-vector products Sv or S -1 v, where S is the n × n matrix</p><formula xml:id="formula_50">S =          1 1 1 1 . . . S 1,n 0 1 3 7 . . . S 2,n 0 0 1 6 . . . S 3,n 0 0 0 1 . . . S 4,n . . . . . . . . . . . . . . . . . . 0 0 0 0 . . . S n,n          .</formula><p>Indeed, one has the equalities, seemingly known by Stirling <ref type="bibr" target="#b35">[35]</ref>, see also <ref type="bibr" target="#b29">[29]</ref>:</p><formula xml:id="formula_51">1 = xD, 2 = xD + x 2 D 2 , 3 = xD + 3 x 2 D 2 + x 3 D 3 , 4 = xD + 7 x 2 D 2 + 6 x 3 D 3 + x 4 D 4 , 5 = xD + 15 x 2 D 2 + 25 x 3 D 3 + 10 x 4 D 4 + x 5 D 5 , . . . . Let thus L = n-1 i=0 p i (x) i , with p i (x) = d j =0 p i,j x j .</formula><p>Then in matrix form, L writes as the product</p><formula xml:id="formula_52">1 x . . . x d •    p 0,0 p 1,0 . . . p n-1,0 . . . . . . . . . . . . p 0,d p 1,d . . . p n-1,d    •      1 . . . n-1      .</formula><p>Thus, the previous equalities show that rewriting L in D amounts to perform d matrix-vector products by the Stirling matrix S, followed by the addition of d polynomials, each of which having at most n non-zero coefficients. Conversely, let L = n-1 i=0 q i (x)D i be written as an operator of order n -1 in D, with coefficients q i (x) = d j =0 q i,j x j that are polynomials of degree at most d. Expressing L in the matricial form:</p><formula xml:id="formula_53">L = x -(n-1) x -(n-2) . . . x d •             0 0 . . . q n-1,0 . . . . . . . . . . . . 0 q 1,0 . . . q n-1,d q 0,0 q 1,1 . . . . . . . . . . . . q 1,d . . . q 0,d 0 . . . 0             •      1 xD . . . x n-1 D n-1     </formula><p>shows that the problem of computing L as an operator in with Laurent polynomial coefficients is reduced to n + d matrix-vector multiplications by the inverse of the Stirling matrix.</p><p>Thus, it suffices to estimate the cost of performing a matrix-vector product by S or its inverse. The entries (S i,j ) of the matrix S are the Stirling numbers of the second kind; they satisfy the recurrence S i,j +1 = S i-1,j + iS i,j (while the entries of S -1 are, up to sign, the Stirling numbers of the first kind). These numbers also represent the coordinates of ordinary powers 1, x, . . . , x n-1 in the falling factorial basis 1,</p><formula xml:id="formula_54">x 1 = x, . . . , x n-1 = x(x -1) • • • (x -n + 2).</formula><p>For instance, for j = 1, . . . , 5 these relations write</p><formula xml:id="formula_55">x 1 = x 1 , x 2 = x 1 + x 2 , x 3 = x 1 + 3 x 2 + x 3 , x 4 = x 1 + 7 x 2 + 6 x 3 + x 4 , x 5 = x 1 + 15 x 2 + 25 x 3 + 10 x 4 + x 5 , . . . .</formula><p>Hence, the entries of the vector Sv represent the coefficients of the polynomial n-1 i=0 v i x i in the Newton basis 1, x 1 , x 2 , . . . . Similarly, computing S -1 v amounts to converting a polynomial from its Newton representation (in the falling factorial basis) to the monomial one. Using the conversion algorithms above, both conversions can be done in complexity M(n) log(n) + O(M(n)), which concludes the proof.</p><p>As an application, recall that the coefficients of a power series i 0 s i x i which is a solution of a linear differential operator L satisfy a linear recurrence, whose coefficients can be read off the coefficients of L when it is written in . More precisely, if L = n-1 i=0 p i (x) i has coefficients p i (x) = d j =0 p i,j x j , then letting p j (x) = n-1 i=0 p i,j x i for 0 j d, the recurrence satisfied by the s i writes</p><formula xml:id="formula_56">p d (i)s i + • • • + p 0 (i + d)s i+d = 0 for all i 0.</formula><p>This remark yields a fast algorithm to convert a linear differential equation of order n-1 in D with polynomial coefficients of degree at most d to the recurrence satisfied by a power series solution. By the previous considerations, its complexity is asymptotic to (n+d) M(n) log(n), up to lower order terms. In comparison, the classical method uses the recurrence</p><formula xml:id="formula_57">n-1 j =0 d k=0 p k,j (i -k + 1)(i -k + 2) • • • (i -k + j)s n+j -k-1 = 0 and amounts to compute the d(n -1) polynomials (x -k + 1)(x -k + 2) • • • (x -k + j),</formula><p>which can be done in complexity of O(dn M(n)). If d and n are of the same order, our method saves a factor of about n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The geometric progression case</head><p>Simplifications in Newton evaluation and interpolation formulas also arise when the sample points form a geometric progression; this was already pointed out in <ref type="bibr" target="#b31">[31]</ref> and references therein, but that article makes no mention of asymptotically fast algorithms.</p><p>In this section, we show that the complexities of Newton evaluation and interpolation on a geometric progression of size n drop to M(n) + O(n). By transposition, we deduce that the conversions between monomial and Newton bases have the same asymptotic cost. Last, as in the previous section, we obtain as corollaries fast algorithms for evaluation and interpolation on the monomial basis: the complexities of both tasks is shown to be in O(M(n)), i.e. better by a logarithmic factor than in the case of arbitrary samples points.</p><p>Thus, geometric progressions should be considered as interesting choices for algorithms relying on evaluation and interpolation techniques. We illustrate this in the case of polynomial matrix multiplication algorithms.</p><p>In all what follows, we actually assume for simplicity that the geometric progression we consider has the form x i = q i , i = 0, . . . , n -1. Treating the general case x i = x 0 q i , with arbitrary x 0 , does not alter the asymptotic estimates, and only burdens the notation. Finally, we mention that many formulas presented below can be thought as q-analogues of those presented in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Newton interpolation and evaluation</head><p>Our first question is that of Newton interpolation and evaluation: the following proposition proves the estimates of the last entry in the third column of Table <ref type="table">1</ref>. Proposition 3. Let k be a field and let q ∈ k such that the elements x i = q i are pairwise distinct, for i = 0, . . . , n -1. Then Newton interpolation and evaluation on the geometric sequence 1, q, . . . , q n-1 can be done using M(n) + O(n) base field operations.</p><p>Proof. Let F be a polynomial of degree less than n, let v = v 0 , . . . , v n-1 be the values F (x i ) and f = f 0 , . . . , f n-1 the coefficients of F on the Newton basis associated to the points x. As in the previous section, we evaluate Formula (1) on the points x, yielding</p><formula xml:id="formula_58">v 0 = f 0 , v 1 = f 0 + (q -1)f 1 , v 2 = f 0 + (q 2 -1)f 1 + (q 2 -1)(q 2 -q)f 2 , v 3 = f 0 + (q 3 -1)f 1 + (q 3 -1)(q 3 -q)f 2</formula><p>+(q 3 -1)(q 3 -q)(q 3 -q 2 )f 3 . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let us introduce the triangular numbers</head><formula xml:id="formula_59">t i = 1 + 2 +• • •+(i -1) = i(i -1)/2</formula><p>, for i 0 and the modified sequence g i = q t i f i , for i = 0, . . . , n -1. Note that all coefficients q t i can be computed in O(n) base field operations, since q t i+1 = q i q t i . Thus, g = g 0 , . . . , g n-1 and f = f 0 , . . . , f n-1 can be computed from one another for O(n) base field operations. With this data, the relations above become v 0 = g 0 , v 1 = g 0 + (q -1)g 1 , v 2 = g 0 + (q 2 -1)g 1 + (q 2 -1)(q -1)g 2 , v 3 = g 0 + (q 3 -1)g 1 + (q 3 -1)(q 2 -1)g 2 + (q 3 -1)(q 2 -1)(q -1)g 3 . . . .</p><p>Next, we introduce the numbers w i defined by</p><formula xml:id="formula_60">w 0 = v 0 , w i = v i (q -1) • • • (q i -1) , i = 1, . . . , n -1.<label>(3)</label></formula><p>As above, w and v can be computed from one another for O(n) base field operations. Using the modified values w i , the relations above become</p><formula xml:id="formula_61">w i = g i + i-1 j =0 1 (q -1) • • • (q i-j -1) g j .</formula><p>We conclude as in the arithmetic case. We introduce the generating series</p><formula xml:id="formula_62">W = n-1 i=0 w i x i , G = n-1 i=0 g i x i , T = 1 + n-1 i=1 1 (q -1) • • • (q i -1) x i ,<label>(4)</label></formula><p>so that the relations above become W = GT modulo x n . All coefficients of the power series T can be obtained in O(n) base field relations. By a classical identity (see for instance <ref type="bibr" target="#b16">[17]</ref> and references therein) the inverse of T modulo x n equals</p><formula xml:id="formula_63">1 + n-1 i=1 q i(i-1) 2 (-1) i (q -1) • • • (q i -1)</formula><p>x i , thus its coefficients can also be obtained in O(n) operations. The conclusion follows.</p><p>For the sake of completeness, we summarize below the algorithm for Newton evaluation on the geometric sequence 1, q, . . . , q n-1 . For a polynomial P, we denote by Coeff(P , i) the coefficient of x i in P. For simplicity, we take as input all powers of q; of course, given q only, they can be computed for n -2 additional multiplications.</p><p>NewtonEvalGeom (1, q, . . . , q n-1 , f 0 , . . . , f n-1 ) q 0 ← 1; u 0 ← 1; g 0 ← f 0 ;</p><formula xml:id="formula_64">for i ← 1 to n -1 do q i ← q i-1 • q i-1 ; u i ← u i-1 • (q i -1); g i ← q i f i ; W ← ( n-1 i=0 g i x i ) • ( n-1 i=0 u -1 i x i ); return u 0 Coeff(W, 0), . . . , u n-1 Coeff(W, n -1);</formula><p>The algorithm for Newton interpolation follows in an analogous manner from the proof of the proposition above. We give it for completeness. <ref type="figure">x</ref>) i q i /u i ); return Coeff(G, 0)/q 0 , . . . , Coeff(G, n -1)/q n-1 ;</p><formula xml:id="formula_65">NewtonInterpGeom(1, q, . . . , q n-1 , v 0 , . . . , v n-1 ) q 0 ← 1; u 0 ← 1; w 0 ← v 0 ; for i ← 1 to n -1 do q i ← q i-1 • q i-1 ; u i ← u i-1 • (q i -1); w i ← v i /u i ; G ← ( n-1 i=0 w i x i ) • ( n-1 i=0 (-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Conversions between monomial and Newton bases</head><p>Our next step is to study the complexity of conversion between monomial and Newton bases. We prove the following result, which completes the first two entries in the last column of Table <ref type="table">1</ref>. Proposition 4. Let k be a field and let q ∈ k such that the elements x i = q i are pairwise distinct, for i = 0, . . . , n -1. Then the conversion between the Newton basis associated to 1, q, . . . , q n-1 and the monomial basis can be done using M(n) + O(n) base field operations.</p><p>The proof comes from considering the transposed of the Newton evaluation and interpolation. Indeed, the following lemma relates these questions to those of conversions between monomial and Newton bases. Lemma 3. Let k be a field, q ∈ k * and r = 1/q. Suppose that 1, q, . . . , q n-1 are pairwise distinct and define the following matrices:</p><p>• Let A be the matrix of base change from the Newton basis associated to 1, q, . . . , q n-1 to the monomial basis. • Let B be the matrix of Newton evaluation at 1, r, . . . , r n-1 .</p><p>• Let D 1 and D 2 be the n × n diagonal matrices</p><formula xml:id="formula_66">D 1 = Diag q i(i-1)/2 i-1 k=1 (q k -1) n i=1</formula><p>and D 2 = Diag (-1) j -1 q (j -1)(j -2) 2 n j =1</p><p>, where we take the usual convention that the empty product is one. Then the matrix equality A = D 1 B t D 2 holds.</p><p>Proof. Given two integers n and k, the q-binomial coefficient <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b30">30]</ref> is defined as</p><formula xml:id="formula_67">n k q = 1-q n 1-q • 1-q n-1 1-q 2 • • • 1-q n-k+1 1-q k , for n k 1, 0 for n &lt; k or k = 0.</formula><p>The following generalization of the usual binomial formula holds:</p><formula xml:id="formula_68">n k=1 1 + q k-1 x = n k=0 n k q q k(k-1) 2 x k . (<label>5</label></formula><formula xml:id="formula_69">)</formula><p>From Eq. ( <ref type="formula" target="#formula_68">5</ref>), it is then easy to deduce that the entries of the matrix A are</p><formula xml:id="formula_70">A i,j = (-1) j -i j -1 i -1 q q (j -i)(j -i-1)/2 .</formula><p>are, up to constant factors b -1 i , given by the coefficients of the transposed multiplication of n-1 i=0 c i x i and 2n-2 i=0 b i x i . Let us now focus on the computation of the inverse chirp transform. The idea is to use the Newton basis for intermediate computations: first perform a Newton interpolation, then perform a conversion from the Newton basis to the monomial basis. Both steps have complexities M(n) + O(n), which gives the estimate of 2M(n) + O(n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Application to polynomial matrix multiplication</head><p>We finally apply the results above to improve the complexity of polynomial matrix multiplication. This problem is important, since polynomial matrix multiplication is a primitive of linear algebra algorithms dealing with polynomial matrices (determinant, inversion, system solving, column reduction, integrality certification, normal forms), see for instance <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b41">41]</ref>. It also occurs during computations of matrix Padé-type approximants <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b40">40]</ref>, recurrences with polynomial coefficients <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref> and linear differential operators.</p><p>Let MM(n, d) represent the number of base field operations required to multiply two n×n matrices with polynomial entries of degree less than d. For simplicity, the cost MM(n, 1) of scalar n × n matrix multiplication will be denoted MM(n). This function is frequently written as MM(n) = O(n ), where 2 &lt; 3 is the so-called exponent of the matrix multiplication, see for instance <ref type="bibr" target="#b9">[10]</ref> or <ref type="bibr" target="#b12">[13]</ref>.</p><p>Cantor and Kaltofen <ref type="bibr" target="#b10">[11]</ref> described an algorithm for multiplying polynomials of degree less than d, with coefficients from an arbitrary (possibly non-commutative) algebra using O(M(d)) algebra operations. Viewing polynomial matrices as polynomials with scalar matrix coefficients, the result in Cantor and Kaltofen <ref type="bibr" target="#b10">[11]</ref> implies that MM(n, d) = O (M(d) MM(n)) . Over base fields of cardinality larger than 2d -2, the use of an evaluation/interpolation scheme allows to uncouple polynomial and matrix products and yields the better bound</p><formula xml:id="formula_71">MM(n, d) = O MM(n) d + n 2 M(d) log(d) . (<label>6</label></formula><formula xml:id="formula_72">)</formula><p>An important remark <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref> (see also <ref type="bibr" target="#b3">[4]</ref>) is that if the base field supports FFT, then choosing the roots of unity as sample evaluation points improves the previous estimate to</p><formula xml:id="formula_73">MM(n, d) = O(MM(n) d + n 2 d log(d)).<label>(7)</label></formula><p>However, the algorithm in <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref> is dependent on the specific use of FFT, which might not be pertinent for polynomials of moderate degrees. In contrast, using evaluation and interpolation at a geometric progression enables us to obtain the following result.    Proof. In both cases, we use evaluation and interpolation on a geometric progression 1, q, . . . , q 2d-2 of size 2d -1. In characteristic 0, we can take q = 2. If k is finite, we take for q a generator of the multiplicative group k * (for practical purposes, we might as well choose q at random, if k has a large enough cardinality).</p><p>Theorem 4 may be seen as an improvement by a log factor of the bound (6), generalizing the bound <ref type="bibr" target="#b6">(7)</ref> to an arbitrary multiplication time M function that satisfies our hypotheses. Still, for polynomial matrices of high degrees, the method in <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref> is better by a constant factor than ours, since the polynomial multiplication uses FFT, and thus itself requires evaluating and interpolating at the roots of unity.</p><p>To conclude this paper, Figs. 1 and 2 display the speed-up obtained using our polynomial matrix multiplication algorithm, versus a naive product (thus, a larger number means a more significant improvement). The matrix sizes vary from 1 to 120, the polynomial degrees vary from 0 to 200, and the base field is Z/pZ, where p is a 32 bit prime. The time ratios are given in the table of Fig. <ref type="figure" target="#fig_1">1</ref> and displayed graphically in Fig. <ref type="figure" target="#fig_2">2</ref>.</p><p>The implementation is made using Shoup's NTL C++ library <ref type="bibr" target="#b34">[34]</ref>; we used a naive matrix multiplication of cubic complexity, and NTL's built-in polynomial arithmetic (for polynomials in the range 0-200, naive, Karatsuba and FFT multiplication algorithms are successively used). The timings are obtained on an Intel Pentium 4 CPU at 2 GHz.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 4 .</head><label>4</label><figDesc>Let n, d 1 and let k be a field of characteristic 0, or a finite field of cardinality at least 2d. Then we have the estimateMM(n, d) = (2d -1) MM(n) + 4 n 2 M(2d) + O(n 2 d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Time ratios between classical and improved polynomial matrix multiplication algorithms. Rows are indexed by the matrix size; columns are indexed by the matrix degree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Speed-up between classical and improved polynomial matrix multiplication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgments</head><p>We thank Pierrick Gaudry, Bruno Salvy and Gilles Villard for useful comments on a first version of this article. Our thanks also go to the referees of this paper for their useful remarks.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>On the other hand, the (i, j ) entry of the matrix representing Newton evaluation with respect to x 0 , . . . , x n-1 is zero if j &lt; i and equals j -1 k=1 x i-1 -x k-1 for all j i 1. Applying this to x i = 1/q i , we get B i,j = (-1) j -1 j -1 k=1 q i-k -1 q i-1 for all j i 1.</p><p>Having the explicit expressions of the entries of A and B allows to write the equality</p><p>from which the lemma follows.</p><p>Thus, up to multiplications by diagonal matrices, the conversion maps between monomial and Newton bases are the transposes of those of Newton evaluation and interpolation, at the cost of replacing q by 1/q. The proof of Proposition 4 is now immediate, since the two diagonal matrices involved can be computed in time O(n).</p><p>For the sake of completeness, we give below the algorithm for the conversion from Newton to monomial basis on the geometric sequence 1, q, . . . , q n-1 . We obtain it using Lemma 3 above and by transposing the algorithm for Newton evaluation on a geometric sequence, as described in the proof of Proposition 3.</p><p>Similarly, the algorithm for the conversion from monomial to Newton basis on a geometric sequence can be deduced using again Lemma 3 and the transposition of the algorithm for Newton interpolation on a geometric sequence given in the proof of Proposition 3.</p><p>We state it below.</p><p>MonomialToNewtonGeom(1, . . . , q n-1 , v 0 , . . . , v n-1 ) q 0 ← 1;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Evaluation and interpolation on the monomial basis</head><p>We now treat the question of fast monomial evaluation and interpolation on a geometric progression. As before, we take x i = q i , i = 0, . . . , n -1, where q ∈ k is such that the elements 1, q, . . . , q n-1 are pairwise distinct.</p><p>It is known that evaluating a polynomial of degree less than n on the geometric progression 1, q, . . . , q n-1 can be done using O(M(n)) operations. This operation, generalizing the discrete Fourier transform, is called the chirp transform and has been independently studied by Rabiner et al. <ref type="bibr" target="#b28">[28]</ref> and Bluestein <ref type="bibr" target="#b5">[6]</ref>, see also <ref type="bibr" target="#b1">[2]</ref>. In contrast, to the best of our knowledge, no algorithm for the inverse operation-interpolation at a geometric progression-has been given yet. Our aim is now to show that the inverse chirp transform can be performed in a similar asymptotic complexity. These results are gathered in the following proposition, which completes the entries of Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 5.</head><p>Let k be a field, let n 0 and let q ∈ k such that the elements x i = q i , for i = 0, . . . , n -1, are pairwise distinct. If F ∈ k[x] has degree less than n then:</p><p>• Given the coefficients of F on the monomial basis, then the values F (x i ), for 0 i n-1, can be computed in M(n) + O(n) base field operations. • Given the values F (x 0 ), . . . , F (x n-1 ), all coefficients of F on the monomial basis can be computed in 2M(n) + O(n) base field operations.</p><p>Proof. The direct chirp transform can be done using the idea introduced in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref> which basically reduces it to a polynomial multiplication. We briefly recall how the algorithm works, following the presentation of <ref type="bibr" target="#b42">[42,</ref><ref type="bibr">Chapter 9]</ref>.</p><p>. For i = 0, . . . , 2n -2, let us introduce the triangular numbers t i = i(i -1)/2 and the sequence b i = q t i ; for i = 0, . . . , n -1 we consider the sequence c i = f i/b i . Note that all the elements q t i+1 , c i and b i can be computed in O(n) base field operations, since q t i+1 = q i q t i . Then, the algorithm is based on the formula F (q i ) = n-1 j =0 f i q ij = b 1 i • n-1 j =0 c j b i+j , which shows that the values F (q i )</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rational solutions of linear differential and difference equations with polynomial coefficients</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Abramov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engl. transl. USSR Comput. Math. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7" to="12" />
			<date type="published" when="1757">1989. 1757</date>
		</imprint>
	</monogr>
	<note>Zh. Vychisl. Mat. i Mat. Fiz.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluating polynomials at fixed sets of points</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Steiglitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="533" to="539" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A uniform approach for Hermite Padé and simultaneous Padé approximants and their matrix-type generalizations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Beckermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Labahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Algorithms</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="45" to="54" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A uniform approach for the fast computation of matrix-type Padé approximants</title>
		<author>
			<persName><forename type="first">B</forename><surname>Beckermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Labahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="804" to="823" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Bini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Polynomial and Matrix Computations</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1994">1994</date>
			<publisher>Birkhäuser, Boston Inc</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A linear filtering approach to the computation of the discrete Fourier transform</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Bluestein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Electroacoustics AU</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="451" to="455" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast modular transforms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Moenck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. System Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="366" to="386" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linear recurrences with polynomial coefficients and computation of the Cartier-Manin operator on hyperelliptic curves</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bostan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gaudry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Schost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Finite Fields andApplications Toulouse 2003</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2948</biblScope>
			<biblScope unit="page" from="40" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tellegen&apos;s principle into practice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bostan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lecerf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Schost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISSAC&apos;03</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="37" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Algebraic complexity theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bürgisser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Shokrollahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Grundlehren der mathematischen Wissenschaften</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<date type="published" when="1997">1997</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On fast multiplication of polynomials over arbitrary algebras</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Cantor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kaltofen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Inform</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="693" to="701" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Approximations and complex multiplication according to Ramanujan</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Chudnovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Chudnovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ramanujan revisited</title>
		<meeting><address><addrLine>Urbana-Champaign, IL; Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1987">1987. 1988</date>
			<biblScope unit="page" from="375" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zur Gathen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gerhard</surname></persName>
		</author>
		<title level="m">Modern Computer Algebra</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Summatio quarundam serierum singularium</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Gauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opera</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="9" to="45" />
			<date type="published" when="1863">1863</date>
			<publisher>Gess. d. Wiss</publisher>
			<pubPlace>Göttingen</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Modular algorithms for polynomial basis conversion and greatest factorial factorization, in: RWCA&apos;00</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gerhard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="125" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the complexity of polynomial matrix computations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Jeannerod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Villard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISSAC&apos;03</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the foundations of combinatorial theory, IV: finite vector spaces and Eulerian generating functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-C</forename><surname>Rota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="239" to="258" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The middle product algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hanrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Quercia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I.Appl.Algebra Eng. Comm. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="415" to="438" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Untersuchungen über die Reihe 1 + (1-q )(1-q ) (1-q)(1-q ) • x + (1-q )(1-q +1</title>
		<author>
			<persName><forename type="first">E</forename><surname>Heine</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Reine Angew. Math</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="285" to="328" />
			<date type="published" when="1847">1847</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A fast method for interpolation using preconditioning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Proc. Lett</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="157" to="163" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Challenges of symbolic computation: my favorite open problems, With an additional open problem by</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kaltofen ; Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Corless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Jeffrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Symbolic Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="891" to="919" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multiplication of multidigit numbers on automata</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karatsuba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ofman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Math. Dokl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="595" to="596" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Knuth</surname></persName>
		</author>
		<title level="m">The Art of Computer Programming</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Seminumerical Algorithms. third ed.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Moenck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borodin</surname></persName>
		</author>
		<title level="m">Fast modular transforms via division, 13th Annual IEEE Symposium on Switching and Automata Theory</title>
		<imprint>
			<date type="published" when="1972">1972</date>
			<biblScope unit="page" from="90" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An FFT extension of the elliptic curve method of factorization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Montgomery</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>Los Angeles, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Greatest factorial factorization and symbolic summation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paule</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Symbolic Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="268" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hypergeometric solutions of linear recurrences with polynomial coefficients</title>
		<author>
			<persName><forename type="first">M</forename><surname>Petkovšek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Symbolic Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="243" to="264" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The chirp z-transform algorithm and its application, Bell System Tech</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Rader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1249" to="1292" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The Umbral Calculus</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<date type="published" when="1984">1984</date>
			<publisher>Academic Press Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Formulae de serierum reversione demonstratio universalis signis localibus combinatorico-analyticorum vicariis exhibita</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Rothe</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1793</biblScope>
			<pubPlace>Leipzig</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On polynomial interpolation at the points of a geometric progression</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Schoenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Roy. Soc. Edinburgh Section A</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="195" to="207" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Schnelle multiplikation von polynomen über Körpern der charakteristik 2</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schönhage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Inform</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="395" to="398" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Schnelle multiplikation großer zahlen</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schönhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Strassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="281" to="292" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">NTL: a library for doing number theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Shoup</surname></persName>
		</author>
		<ptr target="http://www.shoup.net" />
		<imprint>
			<date type="published" when="1996">1996-2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Methodus Differentialis: sive Tractatus de Summatione et Interpolatione Serierum Infinitarum</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stirling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gul. Bowyer, London, Engl. transl. by Holliday, J. The Differential Method: A Treatise of the Summation and Interpolation of Infinite Series</title>
		<imprint>
			<biblScope unit="volume">1749</biblScope>
			<biblScope unit="page">1730</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Storjohann</surname></persName>
		</author>
		<title level="m">High-order lifting, in: ISSAC&apos;02</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="246" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Die Berechnungskomplexität von elementarsymmetrischen Funktionen und von Interpolationskoeffizienten</title>
		<author>
			<persName><forename type="first">V</forename><surname>Strassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="238" to="251" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A general network theorem with applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tellegen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philips Research</title>
		<imprint>
			<biblScope unit="page" from="259" to="269" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report 7</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fast computation of linear generators for matrix sequences and application to the block Wiedemann algorithm</title>
		<author>
			<persName><forename type="first">É</forename><surname>Thomé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISSAC&apos;01</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="323" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Subquadratic computation of vector generating polynomials and improvement of the block Wiedemann algorithm</title>
		<author>
			<persName><forename type="first">É</forename><surname>Thomé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Symbolic Comput</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="757" to="775" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Computing Popov and Hermite forms of polynomial matrices</title>
		<author>
			<persName><forename type="first">G</forename><surname>Villard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISSAC&apos;96</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Prime numbers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pomerance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Computational Perspective</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">545</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
